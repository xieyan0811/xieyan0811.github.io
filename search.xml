<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>论文阅读_大语言模型_Llama2</title>
    <url>/0_Inbox/0_%E6%AD%A3%E5%9C%A8%E7%9C%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B_Llama2/</url>
    <content><![CDATA[<pre class="ad-info"><code>英文名称: Llama 2: Open Foundation and Fine-Tuned Chat Models  
中文名称: Llama 2：开源的基础模型和微调的聊天模型  
文章: http://arxiv.org/abs/2307.09288  
代码: https://github.com/facebookresearch/llama  
作者: Hugo Touvron  
日期: 2023-07-19  
引用次数: 110  </code></pre>
<h2 id="读后感">1 读后感</h2>
<p>这是一篇77页的论文，正文也有36页，让人望而却步。整体分成：Introduction，Pretraining，Fine-tune，Safety，Discussion，RelateWork,
Conclusion几部分，如果没有时间，看看前三个部分，大概20页左右也就差不多了。</p>
<p>产出的模型从7B到70B参数，其成果除了基本的 LLAMA-2 模型，还有精调的
LLAMA 2-CHAT 模型，其精调模型与 ChatGPT (3.5)
性能相当，可作为闭源模型的替代品，且 70B 的体量也是可接受的。</p>
<p>在基础模型方面，文章中没有涉及很新的算法，主要偏重工程化，通过实验，产生一些经验性的结论，比如什么情况下会
over-fitting，对于 SFT 和 RLHF
标注应该如何分配资源，如何设置模型超参数，用蒸馏方法利用大模型训练小模型等等。</p>
<p>之前开源模型对 RLHF
的具体方法讨论不多，而本文算法调整主要在强化学习部分，比如在RLHF中如何训练奖利模型以更好地利用偏好标注；选择PPO和Rejection
Sampling作为强化学习的策略优化网络参数。如果你对 RLHF
具体实现感兴趣，比较推荐看看这篇文章。</p>
<h2 id="介绍">2 介绍</h2>
<p>之前的开源模型效果往往与GPT-3相当，而像ChatGPT、BARD 和 Claude
这些封闭的大在模型经过 RLHF
精调，更符合人类偏好。精调往往需要巨大的算力和人工标注成本，且常是不透明且不易复制的，这限制了社区推进人工智能对齐的进展，文章致力于改进此问题。</p>
<p>文章产出包括：<br />
* Llama 2 ：Llama 1
的更新版本，使用新的公开数据组合进行训练。还将预训练语料库的大小增加了
40%，将模型的上下文长度加倍，并采用分组查询注意力机制。最终发布具有
7B、13B 和 70B 参数的 Llama 2 基础模型。<br />
* Llama 2-Chat：Llama 2 的微调版本，针对对话用例进行了优化。也发布了具有
7B、13B 和 70B 参数的模型。</p>
<h2 id="预训练">3 预训练</h2>
<p>预测训练使用了 从 Touvron（2023 原
Llama论文）中描述的预训练方法。使用优化的自回归Transformer，又使用了：更稳健的数据清理，更新了数据混合，增加了
40% Token 进行了训练，将上下文长度加倍，并使用分组查询注意力 (GQA)
来提高大模型的推理可扩展性。表-1 比较了新 Llama 2 与 Llama 1。</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230918112055.png" /></p>
<p>从图-2中可以看到，纵轴是
Loss，当训练数据增加到2T时，模型仍在优化：</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230918114641.png" /></p>
<p>模型使用 A-100 80G 集群训练，表-2展示了模型使用的算力和碳排：</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230918114806.png" /></p>
<p>由于模型最终被发布，后续模型可以基于该模型调优，从这个角度看，开放的模型也可以算是减少了大模型的全球碳排。</p>
<p>在评测方面，文章对比了主流的开源模型和闭源模型，主要在：编码，常识推理，世界知识，阅读理解，数学，聚合评测（如：MMLU，BBH，AGI
Eval）方面进行了评测：<br />
<img
src="/attachments_2023/Pasted%20image%2020230918115524.png" /><br />
<img src="/attachments_2023/Pasted%20image%2020230918115549.png" /></p>
<p>可以看到，Llama-2
各项结果明显优于当前的开源模型，和闭源模型相比有差异。请注意：这是预训练的版本，后面还会继续比较
fine-tune 之后的结果。</p>
<h2 id="精调">4 精调</h2>
<p>Llama 2-Chat 主要使用了对齐技术（包括 SFT 和
RLHF）需要大量的计算和标注资源。另外，还使用了 Ghost Attention (GAtt)
注意力机制来优化多轮对话。</p>
<h3 id="sft-有监督微调">4.1 SFT 有监督微调</h3>
<p>SFT supervised fine-tuning 有监督微调，也叫作 instruction tuning
指令微调。一对标注数据一般包含一个提示和一个答案，训练时只对答案部分进行反向传播调优网络。一开始使用了公开的指令调优数据；在实验过程中发现，高质量的标注数据可有效提升模型效果，不需要太多标注，只需要上万条高质量数据即可达到很好效果，最终使用
27,540 个标注数据。从而把更多精力用于 RLHF 标注。</p>
<h3 id="rlhf-人类反馈的强化学习">4.2 RLHF 人类反馈的强化学习</h3>
<p>人类反馈的强化学习 RLHF（Reinforcement Learning with Human
Feedback）用于对齐模型行为和人类偏好，简单地说，就是让标注者选择他们喜欢的两个模型输出中的哪一个。随后用标注数据训练奖励模型，该模型用于后续对偏好进行预测。</p>
<h4 id="人类偏好的数据收集">4.2.1 人类偏好的数据收集</h4>
<p>标注过程如下：首先要求注释者编写提示，然后根据要求在两个模型的返回结果之间进行选择。除了选择哪个更好，还要求他们标记对更喜欢答案的喜爱程度：明显更好，更好，稍微更好，或者可以忽略/不确定。</p>
<p>标注关注答案”有用性“和”安全性“，在安全方面，比如：用户提问“怎么做炸弹”返回的答案就可能是不安全的。安全性标注包括三个选项：优选答案安全另一个不安全；答案都不安全；答案都安全。这里认为人们会优选更安全的答案。</p>
<p>表-6
展示了标注的数据和其它开源数据集的比较结果。可以看到：摘要和在线论坛数据的提示通常较长，而对话式的提示通常较短。与现有的开源数据集相比，文中收集的偏好数据具有更多的对话轮次，并且平均时间更长。<br />
<img src="/attachments_2023/Pasted%20image%2020230919100906.png" /></p>
<h4 id="奖励模型">4.2.2 奖励模型</h4>
<p>奖励模型的输入是：提示、模型响应（包括之前的上下文），输出是标量分数以指示模型生成的质量（有用性和安全性）。利用模型响应分数作为奖励，在后续的
RLHF 期间优化 Llama 2-Chat。</p>
<p>为了解决有用性和安全性有时相互抵消的问题，实验训练了两个单独的奖励模型，一个针对有用性进行优化，另一种针对安全性进行优化。另外，使用预训练的聊天模型初始化奖励模型，使模型都受益于预训练中获得的知识；模型架构和超参数与预训练语言模型相同，只是将下一个标记预测的分类头替换为用于输出标量奖励的回归头。</p>
<p>最终训练模型时使用了开源标注数据和新的标注数据。<br />
<img
src="/attachments_2023/Pasted%20image%2020230919105230.png" /><br />
从图-6中可以看到，在逐步收集数据过程中模型性能的变化：更多的数据和更大的模型会提高准确性，如果有更多数据，模型性能还可能进一步提升。后续实验也证明，在其他条件相同的情况下，奖励模型的改进可以直接转化为
Llama 2-Chat 的改进。</p>
<h4 id="迭代微调">4.2.3 迭代微调</h4>
<p>随着得到更多批次的偏好数据标注，通过训练更好的奖励模型并收集更多提示。从逐步训练迭代模型：从
RLHF-V1 ... 到 RLHF-V5。这里使用了两种算法：近端策略优化 PPO 和
拒绝采样微调 Rejection Sampling fine-tuning。</p>
<p>在 RLHF (V4)
之前，仅使用拒绝采样微调，之后，将两者结合起来，在再次采样之前在生成的拒绝采样检查点之上应用
PPO。从而在探索和当前最优策略之间取得平衡。<br />
图-8展示了温度的影响：更高的温度将对更多样化的输出进行采样，最佳温度是 T
∈ [1.2, 1.3]。<br />
<img src="/attachments_2023/Pasted%20image%2020230920095322.png" /></p>
<p><strong>拒绝采样微调</strong><br />
从模型中采样 K
个输出，并根据奖励选择最佳候选者，然后使用选定的输出进行梯度更新。对于每个提示，奖励分数最高的样本被认为是新的金标准。</p>
<p><strong>PPO 近端策略优化</strong><br />
PPO的优化目标是：最终通过训练模型得到策略 π，以最大化奖励 R。<br />
<span class="math display">\[\arg \max _{\pi} \mathbb{E}_{p \sim
\mathcal{D}, g \sim \pi}[R(g \mid p)]\]</span><br />
其中 R 是 奖励，D 是数据集，p是prompt，通过策略 π 产生 g。</p>
<p>最终的奖励，还考虑了当前策略与初始策略的差异作为惩罚项（使用KL散度计算），以避免过大的调整，保证了训练的稳定性。<br />
<span class="math display">\[R(g \mid p)=\tilde{R}_{c}(g \mid p)-\beta
D_{K L}\left(\pi_{\theta}(g \mid p) \| \pi_{0}(g \mid
p)\right)\]</span><br />
另外，这里的奖励函数 Rc 综合了可用性和安全性。</p>
<h3 id="多轮一致性">4.3 多轮一致性</h3>
<p>文中提出了 Ghost Attention
（GAtt），这种微调使数据更关注多轮对话，而不会快速忘记早期的内容。请注意：这里的
Attention 不是对模型 Transformer
结构中注意力的优化。该方法让模型更注重第一轮对话，比如：请扮演XXX，用法语回答。其效果如下，右侧使用了
Gattr，可以看到，它更容易接受初始设置的”用表情回答“。<br />
<img src="/attachments_2023/Pasted%20image%2020230920113501.png" /></p>
<h3 id="rlhf-结果">4.4 RLHF 结果</h3>
<p><img
src="/attachments_2023/Pasted%20image%2020230920114832.png" /></p>
<p>图-11 展示了 Llama 2-Chat 与 ChatGPT
相比的获胜率百分比，多次迭代微调后的演变结果。左侧图的判断标准是文中的奖励模型，可能对文中的模型有利，右侧的判断标准是GPT-4，更为中立。RLHF-V3
后文中模型在两个轴上都优于 ChatGPT（无害性和有用性 &gt;50%）。</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230920135715.png" /><br />
图-12展示了 Llama-2
各个版本与其它模型在人工评测方面的对比结果，从最右图可以看到，Llama-2
70B-chat 与 ChatGPT gpt-3.5-turbo-0301 效果相当，或者说已经超过了
ChatGPT 3.5。（图中的 tie 指平局率）</p>
<h2 id="参考">5 参考</h2>
<p><a
href="/1_Note/2_算法/7_强化学习/论文阅读_近端策略优化_PPO">论文阅读_近端策略优化_PPO</a></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>2019世界机器人大会</title>
    <url>/6_%E7%94%9F%E6%B4%BB/%E9%9A%8F%E7%AC%94/2019%E4%B8%96%E7%95%8C%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%A4%A7%E4%BC%9A/</url>
    <content><![CDATA[<h1 id="世界机器人大会">2019世界机器人大会</h1>
<p>#随笔</p>
<p> 本周参观了2019世界机器人大会，A展厅以机械臂为主，B展厅展示机器人，后面的两个展厅是自动驾驶以及高校的实验展示。暑假里很多家长带着孩子看展。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-9bc91226e4342e91.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>###机械臂</p>
<p> 机械臂是机器人技术落地最早，也最成熟的领域，机械臂的观感和功能大同小异，主要应用于工业领域。近年来机械臂的功能已相对固定，针对自由度和路径研究都以优化为主。这次也看到一些新应用，大多是在机械臂的肢体末端加入新部件，实现更多应用。比如添加海绵用于擦洗，控制毛笔写字等等。写字由书写的程序操控，擦洗的力度和工作范围也需要额外的编程，以及加入一些传感器摄像头协同工作，主要还是针对细分领域的应用。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-057581f9fc31979e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>###机器人</p>
<p> 机器人展厅可分为技术研究和解决方案两种风格。解决方案比如“护理机器人”是对轮椅功能的扩展，加入了帮助站立，踏板开关，还能折叠成一张小方凳，设计非常贴心。从功能角度看，主要是人通过操纵杆和按钮操作，从介绍视频中没看到更多的新技术的应用和算法的拓展，但还是挺实用的。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-256cc0cdd5144d26.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 也有一些技术算法的展示，比如中瑞福宁在介绍视频中展示其机器人的路径规划、十二个自由度的双机械臂、在三维空间定位和抓取物体，其中智能狗爬楼梯的操作，需要控制多个舵机协同工作、在行进过程中识别三维场景，相比单纯的平地行进和蔽障高级很多。</p>
<p> 也有手脚俱全的机器人展示，其中有一种机器人整体有三十多个自由度（带手指关节），但主要用于唱歌、跳舞、展示。由于越复杂的、越前沿的技术越容易出错，产品化可能会带来风险。让它做好每一件小事，恐怕都需要单独编程实现，工作量巨大，且整体造价昂贵。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-bb34a2a02b78b1f0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> “机器人”的主要功能是“思想”和“行动”。“思想”的功能主要围绕人机对话，以及具体领域的应用，提供酒店、咨询、教学等等服务，操作类似于操作PAD。</p>
<p> “行动”方面，比如机器人餐厅内送餐，虽然可以运送到时指定地点，但是易碎的餐具和高温的菜品是否存在一些安全隐患？客人是否接受没有服务员的半自助服务？传感器是否能应付餐厅的复杂环境？它与传送带相比优势在哪儿，性价比又如何？</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ca219699325b3466.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 还有不少“巡逻”机器人，有车型的，人型的，还有机器狗，遇到了“坏人”它能怎样？和固定摄像头相比它的优势在哪儿？大型机器是否存在安全隐患？机器狗会不会被坏人抱走？展示中还看到很多可移动的PAD……如果不考虑酷炫的高科技效果，以实用为目标，这些产品到底解决了哪些问题？</p>
<p>###产品</p>
<p> 很多机器人技术的子领域技术目前已趋于成熟，如：机器视觉、语音输入输出、简单的问答系统、行进中蔽障、音视频传输、机械臂、传感器、舵机电机等等，也有现成的模块拿来就用。是不是可以挖掘更多的应用领域，而不是只展示我们能实现这功能，技术人员的思维是“我能做什么，可能遇到什么问题”，但是做产品更多地围绕“产品的定位以及解决什么样的问题”。</p>
<p> 在医疗机器人和自动驾驶等领域，涉及安全以及事故权责问题，新技术在很长一段时间还将处于辅助人类工作的地位。反倒是它们在物流、搬运这些风险可控，操作相对固定的领域已经开始发挥作用。像京东这种即有需求，又有研发实力的公司，帅先实现了无人仓储，机器人搬运，货物分拣等等工作。虽然它们看起来更像叉车，而不像我们印象中的机器人。但是它使用的传感器、路径规划、控制运动等等机器人技术。所以相比长得像不像人，智能和功能更加重要。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-3c6eda6d8bb02357.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 从生存和盈利的角度上看，如果想尽快地出产品，目前看还是需要着重解决方案，相对从简单、成熟的技术开始，逐步积累数据，加入复杂的技术，在某一个垂直领域精耕细作更好一些。</p>
<p>###教育</p>
<p> 对于小朋友来说，这里的展示比大多数科技馆先进得多，可以看到目前最新的机器人技术，还有供参观者实操的达芬奇手术机器人，可以过一把外科医生的瘾。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-3c724a7ce1f54edd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 也看到一些教育相关的展览，有些是教小朋友机器人相关编程，有些是提供机器人互动教学。现在培训小朋友的课程挺多，大多都针对十二岁以下的小朋友。真正的计算机科学是操作性很强的课程体系，这个时代大家都需要了解一些。那么科普教育究竟要讲些什么，能让孩子更接近“高科技”？这话题太长，以后再讨论。</p>
<p>###观后感</p>
<p> 机器人发展领域和人工智能领域类似，在很多小范围内确实已经超越人类，在组合复杂功能的领域，虽然也有很多理论和实验，但是离成熟和应用还有很大距离。目前主要聚焦在弱智能领域，强智能可能会在未来十年成为新的焦点。</p>
]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能领域的阅读</title>
    <url>/6_%E7%94%9F%E6%B4%BB/%E9%9A%8F%E7%AC%94/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E9%A2%86%E5%9F%9F%E7%9A%84%E9%98%85%E8%AF%BB/</url>
    <content><![CDATA[<h1 id="人工智能领域的阅读">人工智能领域的阅读</h1>
<p>#随笔 #人工智能</p>
<p>＂只要站在风口，猪也能飞上天＂，这几年网店，团购，APP，智能硬件一波接着一波，今年人工智能又要＂火＂．弄得我都不好意思提，好像赶时髦似的．什么是人工智能？这个领域的人到底在干嘛？和普通的软件差别在哪？想进入这个行业，到底需要什么，它在做什么？能做什么？有时候觉得它强到快把人类给替代了，有时候又觉得它只能指哪儿打哪儿．</p>
<p>这个领域，其实难做的，大多功能听起来很炫，但是都没到＂稳定应用＂的级别，说白了就是＂指不上＂．一般中小规模的公司，出于生存的压力，需要快速地产品化．大都在做目标很明确,<br />
相对见效快．时间能规划的产品，这就需要稳定的东西，稳定的是什么？成熟的算法，现有的库，调库谁都能做，然后又杀成了一片红海．这离真正”智能”好像有点远…</p>
<p>带着这些疑问，开始阅读；</p>
<p><img
src="https://img-%20blog.csdn.net/20170328203657458?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /><br />
<img
src="https://img-%20blog.csdn.net/20170328203726999?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<p>《失控》《必然》都是凯文·凯利的作品，科普类的，看着很轻松．这应该算是人文类的书．它不是讲具体的技术，但是有很多的想法，可以引发读者思考．</p>
<p><img
src="https://img-%20blog.csdn.net/20170328203841646?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<p>《奇点邻近》的作者是雷·库兹韦尔，这应该算是本科学书，里面讲到，生物技术，纳米技术，信息技术等等．对于不太熟悉的领域，读起来挺费劲的，还有点科幻的感觉．</p>
<p><img
src="https://img-%20blog.csdn.net/20170328203906798?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<p>《人工智能：一种现代的方法》，是本教科书，很厚，比较枯燥，可能需要几个月的时间认真阅读．传说这是世界各大学人工智能课的教材，主要讲算法，覆盖面比较广，没有想象中涉及那么多数学，但是内容很多．它构造了一个框架，里面算法伴随着例程场景，看完以后遇到具体问题，至少有个思路．建议边看书边写程序，否则基本就是狗熊掰棒子(内容实在太多,<br />
记不住)。想做人工智能,
这本书一定得认真读一遍，虽然现在很多算法不用自己写，但是不明白原理也很难善用。</p>
<p>看看大家都是怎么做的:<br />
比如数据挖掘，基本过程如下：了解行业背景，找数据，选算法库，数据预处理，扔进算法库，得出训练后数据，验证，应用．也有优化算法库的，更大规模的数据训练的…大多数工作还是人在做，机器来做那些人设计好的事情，专业性强,<br />
它确实是简化了人类劳动，也在制造失业．感觉这还是更像＂自动化＂，而不是＂智能＂．是不是应该有些高级动物特有的东西？算法固然重要，但好像还缺点儿什么？</p>
<p><img
src="https://img-%20blog.csdn.net/20170328203754490?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /><br />
<img
src="https://img-%20blog.csdn.net/20170328203926319?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<p>《情感机器》和《心智社会》，这两本书讨论的不是怎么＂下棋＂，＂开车＂的具体应用，他分析人的大脑：功能，结构，抽象，类比，分解，预期，反思，更新，目标…我觉得，这个才是＂智能＂．不仅在人工智能领域，在哲学和心理学方面，书里也有很多难得的观点，毕竟构建大脑比了解大脑更进了一步.<br />
书中认为人工智能和心理学没有明显的界线. 作者：马文·明斯基--<br />
不愧是“人工智能之父”．里面一句伪代码都没有，但又感觉非常具体，具体到能清晰地对应出数据结构．绝对不是科幻的那种．在人工智能的这一领域，虽然短时间不一定有什么成果，但是远景看，好像也只有它能带来＂飞跃＂．</p>
<p><img
src="https://img-%20blog.csdn.net/20170328203943506?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<p>《Natural Language Processing with<br />
Python》，这是一本关于自然语言处理的书，它有一个未发版的中文翻译版，里面有很多例程，就算只用它学习Python也是不错的选择．自然语言处理＂应该是＂机器＂获得知识的第一步．开始涉及自然语言处理的时候，我就在想，得出的结果：词义，词性，语义，情感，大意，这些在应用场景是什么？好像都不是特别重要的领域;<br />
后来想想还是不够深入，语言是思维的接口，需要＂机器内部建构的思维＂做基础．做好了，其实它是可以控制思维方向和重建思维的，</p>
]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>智力&amp;努力？</title>
    <url>/6_%E7%94%9F%E6%B4%BB/%E9%9A%8F%E7%AC%94/%E6%99%BA%E5%8A%9B&amp;%E5%8A%AA%E5%8A%9B%EF%BC%9F/</url>
    <content><![CDATA[<h1 id="智力努力">智力&amp;努力？</h1>
<p>#随笔</p>
<p>昨天听了一个笑话：“有时候越努力越心酸，这么努力都输啦，那是不是智力有问题呀？”成功的时候怎么归因都问题不大，可如果把失败归因成不可改变的智力原因，可能连希望都破灭了。</p>
<p>什么是智力，或者说能力？当知识、习惯、性格、状态全部夹杂在一起时，就没法简单地解释，于是用“天赋”、“命运”来解释人与人之间的差异，而不再深究为什么，同时也错失了改进的机会。基因和环境固然重要，但是能力有没有改进的空间，具体又要怎么做？</p>
<p>下图列出了一些可能影响最终结果的因素，并做了简单分类。</p>
<p><img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81MzU3ODkzLTBjZTllMzdjZjhiZDcyODAucG5nP2ltYWdlTW9ncjIvYXV0by1vcmllbnQvc3RyaXAlN0NpbWFnZVZpZXcyLzIvdy8xMjQw?x-oss-%20process=image/format,png" /></p>
<p><strong>动力</strong><br />
动力分为内驱力和外驱力，内驱力的案例往往出现在成人的世界里，或者是在难度不大的事情上，在不被干扰的情形之下，用细水长流的方式慢慢培养，“自得天机自长成”。<br />
而外驱力像百米冲刺，虽然不能维持太长时间，却能快速见效。<br />
有主动性当然最好，但并不是没有外驱力就一定能产生内驱力，太多人终其一生也没能找到内驱力。而外驱力往往可控，尤其在孩子的世界里师长非常重要。</p>
<p><strong>基础能力</strong><br />
我们所说的智力，很大部分指向这些基础能力。比如零基础编程，也需要一定条件。从知识层面看，首先得认识常用汉字，26个英文字母，还要会加减乘除；对文字有一定理解和总结能力，看完一段话能明白讲了些什么。在自控能力方面，至少能坚持上完课，并且保持一定的注意力。<br />
个体差异一部分源自基因和环境，同时也在成长的过程中逐渐提升。注意力和学习质量影响决定了理解、表达和逻辑能力（语文、数学），上层技能依赖底层技能，就像弹琴，音符和节奏都弹不对，更谈不上表达感情。<br />
在这方面可控的是尽量打好基础。</p>
<p><strong>规划能力</strong><br />
规划能力是最容易培养，也最为重要的能力，奇怪的是，很多人觉得这些事情应该交给专业人士。常听家长说“我也不懂，给他找个专业老师吧”。<br />
这似乎是某个科目的一对一老师要做的事情：他根据专业知识，定制学习的难度、时间、计划、定时查缺补漏，总结，处理意外情况等等。这些问题他都帮你处理了，那学习者能做的就只剩“指哪儿打哪儿”了。这种情况下，技能可能很快提高，但是换另一件新的事情又变得没有头绪了。<br />
再细分这些能力，难度也有差异：</p>
<ul>
<li>学习之后反思、总结、作笔记（易）。<br />
</li>
<li>给薄弱环节安排更多的时间（易）。<br />
</li>
<li>定时自查，把控进度，调整进度（易）。<br />
</li>
<li>对比自己和他人的差异、对比当前进度与目标的差异（易）。<br />
</li>
<li>拆分复杂问题，设置循序渐进的步骤（中）。<br />
</li>
<li>在时间和质量之间取舍（中）。<br />
</li>
<li>注意实践、举一返三（中）。<br />
</li>
<li>选择合理的难度和时间长度（难）。</li>
</ul>
<p>说来容易，不过是加一些检查点，发现问题和解决问题，实际上却需要长时间的练习。比如，让小孩在练琴时一边做练习者，一边做检查者，思维和注意力不断在二者之间切换，工作量往往是一加一大于二，在开始时会非常辛苦。</p>
<p>思维训练和体能训练一样，需要不断重复。如果把关注点转向学习过程，而不仅是学习到的具体技能。深入学习任何一门技能都需要大量的时间和精力，越早锻炼学习能力，后面节约的时间和精力就越多。</p>
<p>暑假里给孩子讲了20节计算机课，并在每一讲中加入了思维训练的内容。比如：思维导图、统筹规划、知识拓展与知识屏蔽、分层抽象等等。目录如下：</p>
<p><img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81MzU3ODkzLTZjMzI3YWE5ZWMxMTkzMGQucG5nP2ltYWdlTW9ncjIvYXV0by1vcmllbnQvc3RyaXAlN0NpbWFnZVZpZXcyLzIvdy8xMjQw?x-oss-%20process=image/format,png" /></p>
<p>从九月中旬开始连载，有兴趣的朋友可以关注知乎专题 <a
href="https://zhuanlan.zhihu.com/shaoerbiancheng">《Python少儿编程》<br />
</a> ，一起学习。</p>
<p>地址： <a
href="https://zhuanlan.zhihu.com/shaoerbiancheng">https://zhuanlan.zhihu.com/shaoerbiancheng<br />
</a></p>
]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>随笔_一道二年级数学题引发的联想</title>
    <url>/6_%E7%94%9F%E6%B4%BB/%E9%9A%8F%E7%AC%94/%E9%9A%8F%E7%AC%94_%E4%B8%80%E9%81%93%E4%BA%8C%E5%B9%B4%E7%BA%A7%E6%95%B0%E5%AD%A6%E9%A2%98%E5%BC%95%E5%8F%91%E7%9A%84%E8%81%94%E6%83%B3/</url>
    <content><![CDATA[<h1
id="随笔_一道二年级数学题引发的联想">随笔_一道二年级数学题引发的联想</h1>
<p>#随笔</p>
<p> 最近教小孩一些简单的编程。有一次主题是：均值/方差/标准差，想先引入一下，就出了一道题：四个小朋友考试，分别得20分，60分，80分，100分，问平均多少分。她是这么算的：</p>
<p> (((20+60)/2+80)/2+100)/2=80</p>
<p> 谁都知道这不对。我觉得这是个权重的问题，但是怎么对这个只会整数加减乘除的脑子讲清楚权重呢？于是画了下面三个图，问她怎么算是对的？她觉得都是对的，但是计算结果不一样。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-03fe9ecb023907c4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 后来，是这么解释的：计算只能发生在同类的东西之间，比如右上图是均值和均值算，右下是分数和分数算，左边的图到第三层的时候，均值和分数算，不是一种东西就没法放一起算了。就好比，你和一个同学比，比的是你们俩谁更好；你的分和你们班平均分比，比的是你在班里的水平；班和班的平均分比，比的是老师的水平；你的分和旁边那班的平均分比，比出来是什么呀？</p>
<p> 有时候大人思维也这样，拿个体和另外一个群体的均值比，比出来也不是群体差异，也不是个体差异。手机里这种奇怪的文章满天飞，乍看跟真的似的。</p>
<p> 再反过来看她写的那个算式，也有道理。当要统计的东西很多，一次算不清楚的时候，一般都拆成几个小块分别算；而计算时，后算的往往权重更大。可能是看问题的角度不一样。作为心理评价，这可能是对的，但作为均值计算它是错的。</p>
<p> 还有一些类似的认知误区：比如放大差异；分不清同时发生的是伴随关系还是因果关系；只考虑特例，不考虑概率……于是常常在哈哈镜里看世界，还感觉有鼻子有眼的。</p>
<p> 继续说均值，均值为什么重要呢？它影响对问题的预测（成功的机率是多少），选择合理的目标（坚持还是放弃），以及最终的行为。有人考第二不满足，想考第一；有人考倒数第二，也不着急，心想还有不如我的呢。为什么会这样？这是两种均值共同作用的结果，一个是整体的均值（和他人比），一个是个体自身的均值（和自己比）。就像上面那个数学题。或者我们不叫它均值，叫它基线。</p>
<p> 每个评价体系都不一样，困难的大家分都低，简单的大家分都高。个体也没有太多可比性，但又必须做出选择。所以只能通过比较判断相对的价值。说远一点，自我价值，自尊，自信都源于此，有时候自我价值感出问题了，除了考虑客观现实，也要检查一下内部算法和基线选择。</p>
<p> 比如基线是在多大范围内确定的（我们院儿还是全中国），取的是均值（所有加一起除以个数），中值（50为0-100的中值），期望值（所有区域得分乘以概率之和），某个固定值（比如60分及格），边缘值（划分好坏之间的那条线），还是极限值（雷锋一样的标杆）。数据的发散程度，是否有汇聚点，有几个汇聚点，概率密度，数据分布具体规律，是不是应该把划分成某几类，再求基线？这是处理数据的方式，也是思维的方式。</p>
]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>随笔_从寻找自我到框架理论</title>
    <url>/6_%E7%94%9F%E6%B4%BB/%E9%9A%8F%E7%AC%94/%E9%9A%8F%E7%AC%94_%E4%BB%8E%E5%AF%BB%E6%89%BE%E8%87%AA%E6%88%91%E5%88%B0%E6%A1%86%E6%9E%B6%E7%90%86%E8%AE%BA/</url>
    <content><![CDATA[<h1 id="随笔_从寻找自我到框架理论">随笔_从寻找自我到框架理论</h1>
<p>#随笔 #框架理论</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-6853f56e0c3f98d2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>在那首歌里,张楚唱道：</p>
<p>就在街上<br />
碰到一个富人朋友阴沉着脸<br />
让我很惭愧<br />
还是在这条街上<br />
碰到一个穷人朋友他也阴沉着脸<br />
喔让我抬不起头…</p>
<p>思维里好像老存在着一些矛盾，好像两个小人儿在打架，那哪个才是真正的“自我”？开始我觉得，也许是那个最初始的，不经意间流露的才是真正的自我。那另外那些声音又是什么？丑陋的？虚伪的？还被人强加的？</p>
<p>到底有没有所谓的“自我”，那个贯穿生命，而又前后统一的灵魂？佛教中讲“无我”，但还是觉得每个人身上都有一些和别人不太一样的东西。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-84ea5302761c7d25.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>马文•明斯基被称为“人工智能之父”，1975年，在论文“A Framework for
Representing
Knowledge”中提出其著名的框架理论。它是至今为止我觉得对“自我”最合理的解释。</p>
<p>换种想法：脑中存在的不是一个完整的自我，只是多套框架，用于处理不同条件的不同问题。心理学有一个实验，发现有的小孩在家里撒谎，在外边诚实，有的刚好相反。那可能只是在不同的情况下激活了不同的框架。有时候，也可能在同样的条件激活多个框架，因此有了矛盾，并没有哪个是“真实”，哪个是“虚伪”。“本我”“自我”“超我”可能只是框架冲突的一种常见情况，有时候还不止这三个。常用的框架放在前面，不常用的放在后面。条件反射只是优先级最高的框架被调出，而深思熟虑的是多个框架权衡的结果，还有偶尔神游出来的，被某个情景触发的其它框架…</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-fddaeaae86da9af2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>一场说走就走的旅行可以改变人生吗？听说有些修行人还俗之后，回到原来的环境没过多久，又变回之前的状态了，于是大家感叹，修行这么长时间，一点长进都没有！也许这只是一些并存的框架，回来原来的环境之中，之前的习惯又被激活了。原来的框架也是在环境中逐渐磨练来出来的，有很好的适应性，又被激活也很正常。适应新环境就好像增加一门才艺，它能把你变得更强，但未必能改变日常的思维方式。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-5ee0700bccb903a4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>也许所谓的“人性”正是形成于在幼小时候被温柔相待的岁月，很多上层框架都基于它构造，经年累月不断发酵，成为主流的思维模式，也又不断被修改，以及与其它模式并存。...不过有人并没那么幸运，愿大家都能被温柔相待...</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-a118326fe2fb7fe4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>有时候情感被文学，艺术，同情，同理心唤起，可能也是调起了平时优先级不高却一直存在的框架，也许那是一些一直想做却没做的，想说却没能表达的，或许这就是潜意识，于是产生了共鸣。反过来说，只要能唤起更多的人的共鸣，即使是反向的，也有触动人心的力量。</p>
<p>内在的自我，潜意识的自我，只是诸多思维框架中的某一个，而外在的“自我”，想都没想就蹦出来的那个，恰恰是最重要的优先级最高的，它往往决定了你是怎样的人，而且还在不断调整变化中…非要去寻找所谓的“自我”，可能会一直在迷宫里转，因为“到处全都是正确答案...”。我倒觉得与其去寻找，不如去塑造。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-1d01f3a88ae7de26.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>所谓“我”是由诸多因素合和而成（集），不是固定不变的（无常），因此没有贯穿生命，而又前后统一的“自我”（无我，我猜应该是这样解释），佛陀两千多年前就说了。</p>
]]></content>
      <tags>
        <tag>随笔</tag>
        <tag>框架理论</tag>
      </tags>
  </entry>
  <entry>
    <title>随笔_写程序到底有多难</title>
    <url>/6_%E7%94%9F%E6%B4%BB/%E9%9A%8F%E7%AC%94/%E9%9A%8F%E7%AC%94_%E5%86%99%E7%A8%8B%E5%BA%8F%E5%88%B0%E5%BA%95%E6%9C%89%E5%A4%9A%E9%9A%BE/</url>
    <content><![CDATA[<h1 id="随笔_写程序到底有多难">随笔_写程序到底有多难</h1>
<p>#Python #随笔</p>
<p> 我女儿上二年级，最近教她一些简单的python编程。一直想聊聊这事儿：如果你想写程序，学习某样东西，或者转行。多大岁数，什么起点才行？这不光是知识问题，有时候也是心理问题。<br />
 最近常看到互联网把传统行业打得落花流水，有时候也为自己和孩子的将来捏把汗。我女儿打小的职业追求很简单：当保姆和开小卖部。有一天，我实在受不了，就跟她说：以后这些机器都能干，你这人生目标还没毕业就直接失业了。这也不是胡说，家务的智能产品电子产品就不说了，现在好多超市都开始自助结帐，昨天在美廉美看见买蔬菜都自助了。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-75504916c87ea9df.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 于是为了不失业，她的目标改成了“做机器人”。二年级也可以写程序，二年级什么水平？认识一些汉字，汉语拼音和英文字母有时候还傻傻分不清，程序中用到的单词除了for和in几乎全不认识，学过正整数的加减乘除，还没学余数是啥。这些知识类的还好说，死记硬背，用得多了自然就记住了。但是思维类的，比如循环嵌套，对她来说就比较困难。这块儿花了比计划多三倍的时间，直到有一次我问题她什么是循环，她给我画了一棵树，我才长出一口气。有些东西，可能真得等思维发展到一定阶段才能掌握，相对于小孩，大人的思维更加立体，层次分明。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-6c9a732c9364fd89.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 每周两次，每次一小时，外加每周背5-10个用到的单词。到目前为止，一共八周。她现在的水平是基本了解window,linux,android文件系统，虚拟机；软件基本了解photoshop,
excel，基本会用word, ie,
firefox，中文输入法；二，八，十六进制；vim的基本使用；python程序和交互界面，程序方面python的if,while,for,continue,break,print等等，数组，函数，调库，用matplotlib作图，调jieba,snowNLP库给中文分词。基本就是这些，进度和计划几乎持平。<br />
 IT行业门槛高吗？二年级的思维水平，普通小学班里中等的小朋友，除了弹琴跳舞也没上过什么补习班，未来目标就是当保姆，16个小时这些都可以学会。为什么好多大人没试就说不行？的确不是每个人努力之后都能打比赛拿第一，但是我觉得普通的水平，谁都能学会。<br />
 人到底什么情况下，会选择不再去学新的东西了？可能有这个原因：我们从小受教育“或饮食或坐走长者先幼者后”，其实它背后的逻辑是：父慈所以子孝，兄友所以弟恭。但是时间长了，好像就变成了天生的等级和权力，随着年龄的增长，直接就升级了。可世界和五百年前不一样了，年少时学到的东西不再能支撑一生。需要不断地学习，不断把自己设定成后辈的身份，尽管年龄已不再是后辈，不只在知识层面，在心理层也是个挑战。也许，这是个赛场，老将们满身光环，新加入者生机勃勃，而我们只需在其中做更好的自己。</p>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>主题笔记_AI绘图</title>
    <url>/2_Knowledge/2_%E6%8A%80%E6%9C%AF/%E4%B8%BB%E9%A2%98%E7%AC%94%E8%AE%B0_AI%E7%BB%98%E7%94%BB/</url>
    <content><![CDATA[<h2 id="工具使用">1 工具使用</h2>
<h3 id="midjourney-vs-stable-diffusion">1.1 Midjourney vs Stable
Diffusion</h3>
<p>收费、审核、门槛；开源、部署、海量模型、可控、要求<br />
生态：平台、插件、模型、文档；自已训练</p>
<h3 id="环境">1.2 环境</h3>
<p><a
href="/1_Note/2_算法/8_图形图像/AI绘画/AI绘画_SD_搭建环境">AI绘画_SD_搭建环境</a><br />
docker 镜像：siutin/stable-diffusion-webui-docker</p>
<pre><code>$ nvidia-docker run -it --name sdw --gpus all --network host \  
  -v $(pwd)/models:/app/stable-diffusion-webui/models \  
  -v $(pwd)/outputs:/app/stable-diffusion-webui/outputs \  
  -v $(pwd)/extensions:/app/stable-diffusion-webui/extensions \  
  --rm siutin/stable-diffusion-webui-docker:cuda-v1.5.1-2023-08-02 \  
  bash  
$ ./webui.sh --share --listen --enable-insecure-extension-access  </code></pre>
<h3 id="模型">1.3 模型</h3>
<p><a
href="/1_Note/2_算法/8_图形图像/AI绘画/AI绘画_SD_下载模型">AI绘画_SD_下载模型</a><br />
<img src="/attachments_2023/Pasted%20image%2020230907200515.png"
alt="|500" /><br />
* 基本模型：SDXL 1.0，anything<br />
* LoRA模型：Detail Tweaker LoRA，GHIBLI_Background<br />
* VAE模型：2d/真实<br />
* ControlNet模型<br />
* CLIP</p>
<h3 id="界面操作">1.4 界面操作</h3>
<p><a
href="/1_Note/2_算法/8_图形图像/AI绘画/AI绘画_SD_界面操作">AI绘画_SD_界面操作</a><br />
<img src="/attachments_2023/Pasted%20image%2020230818140318.png" /></p>
<p><img
src="/attachments_2023/Pasted%20image%2020230818143719.png" /></p>
<p><a href="None">效果展示</a></p>
<h2 id="底层技术">2 底层技术</h2>
<h3 id="u-net">2.1 U-Net</h3>
<p>基础技术 U-Net: Convolutional Networks for Biomedical Image
Segmentation<br />
<a
href="/1_Note/2_算法/8_图形图像/AI绘画/论文阅读_图形图像_U-NET">论文阅读_图形图像_U-NET</a><br />
<img src="/attachments_2023/Pasted%20image%2020230824085134.png"
alt="|400" /><br />
<span class="math display">\[w(\mathbf{x})=w_{c}(\mathbf{x})+w_{0} \cdot
\exp
\left(-\frac{\left(d_{1}(\mathbf{x})+d_{2}(\mathbf{x})\right)^{2}}{2
\sigma^{2}}\right)\]</span><br />
<img src="/attachments_2023/Pasted%20image%2020230824102033.png" /></p>
<h3 id="vae">2.2 VAE</h3>
<p>基础技术 VAE：Auto-Encoding Variational Bayes<br />
<a
href="/1_Note/2_算法/8_图形图像/AI绘画/论文阅读_生成模型_VAE">论文阅读_生成模型_VAE</a><br />
<img
src="/attachments_2023/Pasted%20image%2020230901142322.png" /><br />
<img src="/attachments_2023/Pasted%20image%2020230824114606.png"
alt="|400" /></p>
<h4 id="变分推断">2.2.1 变分推断</h4>
<p><strong>变分</strong> Variational
是通过引入一个<strong>简化的参数化分布</strong>来近似复杂的后验分布。这个参数化分布被称为<strong>变分分布</strong>，它属于一种可计算的分布族。通过调整变分分布的参数，使其尽可能接近真实的后验分布，从而实现近似推断。</p>
<h4 id="变分下界">2.2.2 变分下界</h4>
<p><strong>变分下界</strong>（variational lower
bound）通常用于衡量<strong>变分分布与真实后验分布之间的差异</strong>。<br />
<span class="math display">\[ELBO = E[log\ p(x, z) - log\
q(z)]\]</span><br />
其中，ELBO 代表变分下界（Evidence Lower
BOund），x代表观测数据，z代表未知变量，p(x,
z)表示真实的联合分布，q(z)表示变分分布。</p>
<h2 id="扩散模型进化">3 扩散模型进化</h2>
<h3 id="dm">3.1 DM</h3>
<p>扩散模型开山之作 DM Deep Unsupervised Learning using Nonequilibrium
Thermodynamics<br />
<a
href="/1_Note/2_算法/8_图形图像/AI绘画/论文阅读_扩散模型_DM">论文阅读_扩散模型_DM</a><br />
<img src="/attachments_2023/Pasted%20image%2020230823113243.png"
alt="|400" /></p>
<h3 id="ddpm">3.2 DDPM</h3>
<p>扩散概率模型用于高质量的图像合成 DDPM：Denoising Diffusion
Probabilistic Models<br />
<a
href="/1_Note/2_算法/8_图形图像/AI绘画/论文阅读_扩散模型_DDPM">论文阅读_扩散模型_DDPM</a><br />
<img
src="/attachments_2023/Pasted%20image%2020230823171028.png" /><br />
<span
class="math display">\[0&lt;\beta_1&lt;\beta_2&lt;...&lt;\beta_T&lt;1\]</span><br />
<span class="math display">\[p_\theta (\mathbf{x}_{t-1} | \mathbf{x}_t)
= \mathcal{N}(\mathbf{x}_{t-1}; \mu_\theta(\mathbf{x}_{t},t),
\Sigma_\theta (\mathbf{x}_{t},t))\]</span><br />
<span class="math display">\[q(\mathbf{x}_t | \mathbf{x}_0) =
\cal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1-
\bar{\alpha}_t) \mathbf{I})\]</span><br />
<span class="math display">\[\| \mathbf{\epsilon} -
\mathbf{\epsilon}_\theta(\mathbf{x}_t, t) \|^2 = \| \mathbf{\epsilon} -
\mathbf{\epsilon}_\theta( \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{(1-
\bar{\alpha}_t)  } \mathbf{\epsilon}, t) \|^2.\]</span><br />
<img src="/attachments_2023/Pasted%20image%2020230902165242.png" /></p>
<h3 id="ldm">3.3 LDM</h3>
<p>模型提速 LDM：High-Resolution Image Synthesis with Latent Diffusion
Models<br />
<a
href="/1_Note/2_算法/8_图形图像/AI绘画/论文阅读_扩散模型_LDM">论文阅读_扩散模型_LDM</a><br />
<img src="/attachments_2023/Pasted%20image%2020230828154849.png"
alt="|500" /></p>
<h3 id="sdxl">3.4 SDXL</h3>
<p>最新 AI 绘画大模型 SDXL: Improving Latent Diffusion Models for
High-Resolution Image Synthesis<br />
<a
href="/1_Note/2_算法/8_图形图像/AI绘画/论文阅读_扩散模型_SDXL">论文阅读_扩散模型_SDXL</a><br />
<img
src="/attachments_2023/Pasted%20image%2020230829112904.png" /><br />
<img
src="/attachments_2023/Pasted%20image%2020230829133510.png" /><br />
<img src="/attachments_2023/Pasted%20image%2020230829135424.png"
alt="|400" /></p>
<figure>
<img src="/attachments_2023/Pasted%20image%2020230907210157.png"
alt="|400" />
<figcaption aria-hidden="true">|400</figcaption>
</figure>
<h2 id="周边技术">4 周边技术</h2>
<h3 id="lora">4.1 LoRA</h3>
<p>用小模型扩展大模型 LoRA: Low-Rank Adaptation of Large Language
Models<br />
<a
href="/1_Note/2_算法/8_图形图像/AI绘画/论文阅读_模型结构_LoRA">论文阅读_模型结构_LoRA</a><br />
<img src="/attachments_2023/Pasted%20image%2020230825092614.png"
alt="|250" /><br />
<img src="/attachments_2023/Pasted%20image%2020230825113213.png" /></p>
<h3 id="controlnet">4.2 ControlNet</h3>
<p>精准控制 ControlNet 绘图：Adding Conditional Control to Text-to-Image
Diffusion Models<br />
<a
href="/1_Note/2_算法/8_图形图像/AI绘画/论文阅读_模型结构_ControlNet">论文阅读_模型结构_ControlNet</a><br />
<img
src="/attachments_2023/Pasted%20image%2020230821172532.png" /><br />
<span class="math display">\[y_c = F(x;\theta)+Z(F(x +
Z(c;\theta_{z1});\theta_c);\theta_{z2})\]</span><br />
<img src="/attachments_2023/Pasted%20image%2020230821173625.png" /></p>
]]></content>
      <tags>
        <tag>主题笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>增强语言模型导读</title>
    <url>/2_Knowledge/2_%E6%8A%80%E6%9C%AF/%E4%B8%BB%E9%A2%98%E7%AC%94%E8%AE%B0_%E5%A2%9E%E5%BC%BA%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>以ChatGPT为主的大语言模型出现已有半年时间，研究逐渐从针对模型本身的进化和功能，延展到如何更为有效地利用大模型，将它与其它工具结合，落地，以解决实际领域中的问题。</p>
<p>这里的增强主要指让大语言模型（LM）与<strong>外部扩展模块</strong>相结合，从而获得<strong>超越单纯的自然语言建模</strong>的能力。具体能力包含：<strong>推理、使用工具、行动</strong>。它不仅能解决<strong>更多类型的问题</strong>，在连接外部模块后，其<strong>处理自然语言处理能力</strong>也得到突破性进展。</p>
<p>本文介绍一篇增强语言模型综述，以及几篇最近发表的具体应用方法和框架的文章。</p>
<h2 id="增强语言模型综述">增强语言模型综述</h2>
<p><a
href="/1_Note/2_算法/2_大模型/论文阅读_增强语言模型综述">论文阅读_增强语言模型综述</a></p>
<p>英文题目: Augmented Language Models: a Survey<br />
中文题目: 增强语言模型综述<br />
论文地址: http://arxiv.org/abs/2302.07842<br />
解读：https://blog.csdn.net/xieyan0811/article/details/130910473?spm=1001.2014.3001.5501<br />
（将近5000字，太长就不贴了）</p>
<p>一篇综述性文章，来Meta，发布时间为2023-02-15。<br />
文章从<strong>方法论</strong>的角论进入阐释。内容分为六部分：介绍，推理，使用工具和行动，学习方法，讨论，结论，正文22页。<br />
对于比较关注 LM
领域的读者，这篇文章中并没有提到让人意外的特殊方法。然而，文章对现有方法进行了全面细致的整理，提供了全景视角的概览，详细引用了相关文献和软件示例。是对知识很好的概览和梳理，可作为入门读物。</p>
<h2
id="chameleon使用大型语言模型进行即插即用的组合推理">Chameleon：使用大型语言模型进行即插即用的组合推理</h2>
<p><a
href="/0_Inbox/230520学习/论文阅读_Chameleon即插即用组合推理">论文阅读_Chameleon即插即用组合推理</a><br />
本篇来自加州大学&amp;微软，发布时间为2023-04-19。</p>
<p>英文题目: Chameleon: Plug-and-Play Compositional Reasoning with Large
Language Models<br />
中文题目: Chameleon：使用大型语言模型进行即插即用的组合推理<br />
论文地址: http://arxiv.org/abs/2304.09842</p>
<p>解读：<br />
*
目标：使用LLM与其它工具结合，解决具体领域的问题。在不同类型的数据和各种模型工具之间建立起了桥梁，利用LLM实现了之前需要人工设计的调用顺序和方法。<br />
*
当前问题：自然语言大模型LLM由于其自身的限制，无法访问最新信息、无法使用外部工具，无法进行精确的数学推理。<br />
*
效果：结合GPT-4，在ScienceQA（86.54%）和TabMWP（98.78）任务中，得到了显著的提升。<br />
* 方法：<br />
提出chameleon（变色龙），即插即用的组合推理框架，该框架可以组合多种工具，其中可包含LLM模型、现成的视觉模型、网络搜索引擎、Python
函数和根据用户兴趣定制的基于规则的模块，并将LLM
作为自然语言规划器，将问题拆解成多种工具组合的链条（设计工作流程），然后调用工具协同解决问题，最后通过答案生成器生成回答。<br />
图-1展示了看图回答问题的三个示例，针对第二个问题，展示了从文本识别，信息检索，生成解决方法，最终生成答案的过程。<br />
<img
src="/attachments_2023/Pasted%20image%2020230520125446.png" /><br />
其中可使用的工具包含：<br />
<img src="/attachments_2023/Pasted%20image%2020230521111218.png" /></p>
<h2
id="supericl小型模型作为大型语言模型的插件">SuperICL：小型模型作为大型语言模型的插件</h2>
<p><a
href="/0_Inbox/230520学习/论文阅读_SuperICL_小型模型作为大型语言模型的插件">论文阅读_SuperICL_小型模型作为大型语言模型的插件</a><br />
本篇来自加州大学&amp;微软，发布时间为2023-05-15。</p>
<p>英文题目: Small Models are Valuable Plug-ins for Large Language
Models<br />
中文题目: 小型模型作为大型语言模型的插件<br />
论文地址: http://arxiv.org/abs/2305.08848</p>
<p>解读<br />
*
目标：利用自然语言大模型（LLM），提升对大规模的有监督数据的预测效果。<br />
*
当前问题：由于上下文长度的限制，只能在对话中给LLM提供有限的上下文提示（In-Context
Learning）。<br />
* 效果：在效果评测，稳定性，多语言和可解释性方面均表现出其优越性。<br />
* 方法<br />
文中提出了SuperICL，将LLM视为黑盒，与本地经过调优的小模型相结合，以提升有监督任务的能力。<br />
之前只是将有监督的示例和待预测的测试数据传递给LLM来获得答案。文中提出的方法，首先针对训练集和测试集数据训练了本地模型，预测标签和置信度。然后将这些结果和测试数据一起传递给LLM，从而使LLM不仅学习了推理结果，还学习了决策过程，从而实现了更好的推理和解释能力。</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230520125605.png" /><br />
图-1(a)部分展示了ICL的工作过程（之前），它从训练集的上下文中采样，再结合测试集数据一起传给LLM，得到输出；<br />
图-1(b)展示了SuperICL的工作过程，分为三步：<br />
*
通过从训练数据中随机抽样并结合本地模型的预测构建上下文，包括预测标签及其相应的置信度分数。<br />
* 测试输入连接在上下文之后，并附加了本地模型对测试数据的预测。<br />
* 语言模型生成最终预测以及解释。</p>
<h2
id="pkg参数化知识指导的增强大语言模型">PKG：参数化知识指导的增强大语言模型</h2>
<p><a
href="/0_Inbox/230520学习/论文阅读_PKG_参数化知识指导的增强大语言模型">论文阅读_PKG_参数化知识指导的增强大语言模型</a><br />
本篇来自香港大学&amp;微软，发布时间为2023-05-18。</p>
<p>英文题目: Augmented Large Language Models with Parametric Knowledge
Guiding<br />
中文题目: 参数化知识指导的增强大语言模型<br />
论文地址: http://arxiv.org/abs/2305.04757<br />
解读：</p>
<ul>
<li>目标：促进大模型LLM在<strong>领域知识密集型任务</strong>中的应用<br />
</li>
<li>当前问题：在解决具体问题时，涉及更多领域相关的知识，最新的知识，以及私有数据。<br />
</li>
<li>效果：提升了模型在一系列<strong>领域知识密集型任务</strong>上的性能，包括事实
(+7.9%)、表格 (+11.9%)、医学 (+3.0%) 和多模态 (+8.1%) 知识。<br />
</li>
<li>方法：<br />
提出PKG（Parametric Knowledge
Guiding）参数化知识引导框架，结合本地模型和LLM模型，本地模型基于开源的自然语言模型（Llama），它可以存储离线的领域知识，将领域知识转化成参数输出，作为background和问题一起传入大模型。<br />
文中的图-1展示了PKG的工作过程：<br />
<img src="/attachments_2023/Pasted%20image%2020230520125656.png" /></li>
</ul>
<h2 id="其它洞见">其它洞见</h2>
<ul>
<li>有标注数据：小模型<br />
</li>
<li>生成数据：大模型</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>深度学习模型压缩</title>
    <url>/2_Knowledge/2_%E6%8A%80%E6%9C%AF/%E4%B8%BB%E9%A2%98%E7%AC%94%E8%AE%B0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/</url>
    <content><![CDATA[<h2 id="模型压缩">模型压缩</h2>
<p>对于复杂问题建模时，深度学习模型在容纳更多参数的情况下，效果一般更好，但是模型占内存大，预测时间长的，往往限制其在小型或普通配制的硬件上使用。一般使用模型压缩方法给模型减肥，主要方法总结如下。</p>
<h3 id="模型剪枝">模型剪枝</h3>
<p>移除对结果作用很小的参数权重，如接近0的参数。具体如去掉某些卷积核，或者卷积核中的某些权重，还有对通通道的减枝，对层的减枝，对注意力头的减枝等。</p>
<h4 id="非结构剪枝">非结构剪枝</h4>
<p>非结构剪枝相对比较底层，使模型结构受到影响，pytorch，tensorflow不能支持。常用结构剪枝，相对简单，但没有非结构剪枝效果好。<br />
结构剪枝方法如：DropOut，DropConnect让神经元或连接失活，置0，但仍然会参与计算。<br />
有一些改进，比如根据全局所有参数的分布来计算某一道通路是否被减掉。</p>
<h4 id="结构剪枝">结构剪枝</h4>
<p>移除通道（Network slimming,
2017），通过减枝和微调不断迭代，可以把yolo3减掉70%。<br />
彩票假设（The Lottery Tickets Hypothesis, ICLR
2019），找彩票子网络（比较特殊的子网络）。<br />
彩票代码: torch.nn.utils.prune.*<br />
其中常用迭代修剪：prune.ln_structured(), prune.global_unstructed()</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220925094745.png"
alt="Pasted%20image%2020220925094745.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220925094745.png</figcaption>
</figure>
<h3 id="模型量化">模型量化</h3>
<p>减少存储权重所需的比特数，比如将 float32 降到
int8，基于KMeans的量化方案等等（将训练好的所有参数分成几簇，然后把权重转换成簇索引）。它能节约空间，但不能提速。</p>
<h3 id="参数共享">参数共享</h3>
<p>通过共享参数，达到减少网络参数的目的。一个不熟悉的词可由常用词定义，或者用普通单词的嵌入的稀疏组合；又如ALBERT可跨层共享所有参数。它的问题是不能提速。</p>
<h3 id="低秩分解">低秩分解</h3>
<p>低秩分解的方法运用了矩阵分解和矩阵乘法的结合律。把较大的卷积核分解为两个级联的行卷积核和列卷积核。比如：将一个3×3的卷积层，替换为一个3×1的卷积层加上一个1×3的卷积核。<br />
它只能用于优化全连接层。</p>
<h3 id="架构设计">架构设计</h3>
<p>使用空洞卷积，线性运算代替卷积。</p>
<h3 id="知识蒸馏">知识蒸馏</h3>
<p>将 teacher 的能力蒸馏到 student上，最近看了一些论文总结如下：<br />
* 第一次提出知识蒸馏<br />
外链：<a
href="https://www.jianshu.com/p/6152e6894b81">论文阅读_神经网络知识蒸馏_DK</a><br />
内链：[[1_Note/2_算法/5_深度学习/模型/论文阅读_神经网络知识蒸馏_DK]]<br />
* 第一次将知识蒸馏用于自然语言处理<br />
外链：<a
href="https://www.jianshu.com/p/96c8094588a8">论文阅读_BERT知识蒸馏</a><br />
内链：[[1_Note/2_算法/11_优化/模型蒸馏/论文阅读_BERT知识蒸馏]]<br />
* 针对Transformer结构使用知识蒸馏<br />
外链：<a
href="https://www.jianshu.com/p/aa08115ebdda">论文阅读_模型蒸馏_TinyBERT</a><br />
内链：[[1_Note/2_算法/11_优化/模型蒸馏/论文阅读_模型蒸馏_TinyBERT]]<br />
* 另一篇基于Transformer结构的优化，更易用<br />
外链：<a
href="https://www.jianshu.com/p/fff6816825f3">论文阅读_知识蒸馏_MobileBERT</a><br />
内链：[[1_Note/2_算法/11_优化/模型蒸馏/论文阅读_知识蒸馏_MobileBERT]]<br />
* 结合元学习和知识蒸馏<br />
外链：<a
href="https://www.jianshu.com/p/02b53079bdeb">论文阅读_知识蒸馏_Meta-KD</a><br />
内链：[[1_Note/2_算法/11_优化/模型蒸馏/论文阅读_知识蒸馏_Meta-KD]]<br />
* 包含蒸馏源码的工具包<br />
外链：<a href="https://www.jianshu.com/p/6ad7938de3d7">EasyNLP</a><br />
内链：[[EasyNLP]]</p>
<h2 id="参考">参考</h2>
<p><a
href="https://zhuanlan.zhihu.com/p/184973728">一文详解文本深度学习模型的压缩</a></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>主题笔记_音频大模型</title>
    <url>/2_Knowledge/2_%E6%8A%80%E6%9C%AF/%E4%B8%BB%E9%A2%98%E7%AC%94%E8%AE%B0_%E9%9F%B3%E9%A2%91%E5%A4%A7%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h2 id="介绍">1 介绍</h2>
<p>本次分享包含音频压缩，语音识别，语音合成，以及近两年来大模型在音频领域的应用，涉及八篇论文和一个近期github霸榜的语音合成工具。</p>
<p>结果如下图所示：（图链接：<a
href="1_Note/2_算法/1_语音/audio_llm.canvas">audio_llm</a>）<br />
<img src="/attachments_2023/Pasted%20image%2020230507105017.png"
alt="|500" /><br />
* 共涉及三种主要技术：音频压缩、音频表示、语音合成；<br />
*
主要技术来自：google（绿色），微软（紫色）、Facebook（黄色）、Suno-ai（红色）<br />
* 图中也大致描绘了各技术出现的先后顺序（从上到下）<br />
* 图中线条表示各技术的依赖和包含关系<br />
* 除了最近霸榜Bark，其它都能找到技术论文，并在下文中进行了简单介绍</p>
<h2 id="基本概念">2 基本概念</h2>
<p>本部分介绍音频领域的基本概念。</p>
<h3 id="音素">2.1 音素</h3>
<p>语音中最小的、不可再分的语音单元。在不同语言中，音素数量也有所不同，例如英语中有大约44个音素，中文普通话中有约20个声母和38个韵母。</p>
<h3 id="语义特征与声学特征">2.2 语义特征与声学特征</h3>
<p>语义特征是指语音合成的内容，如：音调、语速、语调；而声学特征则是指语音的物理属性，如基频、共振峰等。二者在不同场景及文章中定义也不完全一致。可以简单地理解为：语义与文本内容更相关，声学与声音更相关，即：文本-&gt;语义-&gt;声学-&gt;音频。</p>
<h3 id="傅里叶变换">2.3 傅里叶变换</h3>
<p>时域和频域之间进行转换。傅里叶级数则是将周期函数分解成谐波的和的形式。给音频编码、音频压缩、音频降噪等领域的应用提供了基础，同时，也应用于图像处理，时序等领域。</p>
<h3 id="梅尔倒谱-mfcc">2.4 梅尔倒谱 MFCC</h3>
<p>MFCC是从音频信号中提取语音特征的一种最常用方法。可以用于语音识别、语音合成、发音检测等应用。MFCC能够提取关于音频信号的有用信息、不受语调改变的影响、对于白噪声的干扰有强鲁棒性。<br />
MFCC主要分为两步：首先，对音频信号应用快速傅里叶变换（FFT）将其变换到频域。然后在频域中，将频率轴转换为梅尔频率，更好地匹配人耳对声音的感知方式，得到其梅尔倒谱系数，这些系数可以看作是声谱图在梅尔频率轴上的投影。</p>
<h2 id="近期主要技术">3 近期主要技术</h2>
<h3 id="音频的表示学习">3.1 音频的表示学习</h3>
<p>音频表示学习，指的是用相对短的数据描述音频，可理解为抽取音频特征，一般用于语音合成，语音识别等领域。</p>
<h4 id="wav2vec_2.0">3.1.1 wav2vec_2.0</h4>
<ul>
<li>时间：2020-10-22<br />
</li>
<li>出处：Facebook AI<br />
</li>
<li>贡献：从<strong>未标注的语音</strong>中学习音频的表示，然后通过少量标注数据精调。该方法一开始用于语音识别领域。<br />
</li>
<li>结构：模型结构结合了CNN和Transformer。<br />
模型先使用卷积网络将输入音频X映射到隐空间Z，然后将Z送入Transformer网络构建表示C以便从上下文中提取相关信息；另外特征编码Z还被送入量化工具，以生成量化后的表示Q（离散）。<br />
<img src="/attachments_2023/Pasted%20image%2020230502115141.png" /></li>
</ul>
<h4 id="w2v-bert">3.1.2 W2V-BERT</h4>
<ul>
<li>时间：2021-12-13<br />
</li>
<li>出处：MIT &amp; Google Brain<br />
</li>
<li>贡献：结合了对比学习和Mask语言模型，w2v-BERT 效果优于 wav2vec 2.0
30% 以上。<br />
</li>
<li>结构：训练了End-to-end模型。<br />
特征编码器：由两个 2D 卷积层组成，使声学输入序列长度减少到1/4。<br />
对比学习模块：包含一个线性映射层，及多个Conformer层，<strong>每个块都是一系列多头自注意力、深度卷积和前馈层</strong>。对比模块涉及量化机制。<br />
Mask预测模块：使用BERT中的Mask方式，利用对比学习的输出，学习语音中高层的上下文之间的关系。<br />
<img src="/attachments_2023/Pasted%20image%2020230502145724.png" /></li>
</ul>
<h3 id="音频压缩和生成">3.2 音频压缩和生成</h3>
<p>本部分主要介绍基于深度学习的音频压缩技术，除压缩数据以外，该技术还被应用于生成高质量音频。</p>
<h4 id="soundstream">3.2.1 SoundStream</h4>
<ul>
<li>时间：2021-07-07<br />
</li>
<li>出处：Google<br />
</li>
<li>贡献：高效压缩语音、音乐和一般音频。<br />
</li>
<li>结构：模型由编码器，量化器，解码器组成，主要使用了卷积技术。<br />
模型由组成：<br />
编码器：卷积Encoder将采样率为fs的输入音频x转换为嵌入序列。<br />
残差向量量化（RVQ）：将嵌入通过codebooks，压缩成少量字节（目标位数）的表示，生成量化嵌入。<br />
解码器：从量化的嵌入中产生有损重建x^。<br />
其训练过程中还使用了<strong>判别器Discrminator</strong>，它结合了<strong>对抗和重建损失</strong>，并使用可选的条件输入，用于指示是否从音频中去除<strong>背景噪声</strong>（Denosing）。<br />
<img src="/attachments_2023/Pasted%20image%2020230502083544.png" /></li>
</ul>
<h4 id="encodec">3.2.2 Encodec</h4>
<ul>
<li>时间：2022-10-24<br />
</li>
<li>出处：FAIR Team<br />
</li>
<li>贡献：相对SoundStream使用更复杂精细的结构，效果更好。<br />
</li>
<li>结构：方法与SoundStream相似，模型主要使用了卷积，LSTM，还加入Transformer优化量化单元，以减少带宽。模型由编码器，量化器，解码器三部分组成。从图中可以看到，其目标函数考虑了更多因素：重建损失，对抗损失，量化损失，以及Transformer损失。<br />
<img src="/attachments_2023/Pasted%20image%2020230502102037.png" /></li>
</ul>
<h3 id="综合使用">3.3 综合使用</h3>
<p>本部分包含了生成音频和文本转换成语音两种主要应用场景。</p>
<h4 id="audiolm">3.3.1 AudioLM</h4>
<ul>
<li>时间：2022-09-07<br />
</li>
<li>出处：Google research<br />
</li>
<li>贡献：模型用于生成音频，保持一致性和高音质；只需要3s语音作为提示，即可生成训练期间未见过的语音，并保持说话人的声音，韵律，录音条件（混响、噪音）。其贡献主要在于在大模型训练中解耦了语义标记和声学标记。<br />
</li>
<li>结构：使用无监督数据训练，利用对抗音频压缩，自监督表示学习，语言建模。分层方式结合语义和声学标记；基于w2v-BERT
&amp; SoundStream。其工作过程如下：<br />
将输入音频x映射到离散的词表y：y=end(x)。<br />
使用仅有decoder的Transformer模型，操作y，用时间t-1预测t对应的词（预测阶段使用自回归）。<br />
解码模型 ，将预测出的y^映射回音频格式。 x<sup>=dec(y</sup>)<br />
<img src="/attachments_2023/Pasted%20image%2020230504170205.png" /></li>
</ul>
<h4 id="spear-tts">3.3.2 Spear-TTS</h4>
<ul>
<li>时间：2023-02-07<br />
</li>
<li>出处：Google research<br />
</li>
<li>贡献：文本转语音系统，它是AudioLM的延展。多语言的语音合成系统，使用少量有监督数据训练（自监督音频+有监督TTS）<br />
</li>
<li>结构：基于w2v-BERT &amp;
SoundStream。对于语音数据对儿比较少的小语种做了以下优化：<br />
<img
src="/attachments_2023/Pasted%20image%2020230502151507.png" /><br />
从左下开始看图-2，首先，利用有限数据的损坏方法（加噪再去噪）来预训练模型P，生成语义token表征音频数据；然后训练回译模块，利用少量的并行数据微调解码器，训练模型B；利用模型B的回译方法以及大量无标签数据生成大量可用于训练的并行数据（右上）；最后用所有并行数据精调模型（右下）只精调编码器的下面几层。</li>
</ul>
<h4 id="vall-e">3.3.3 VALL-E</h4>
<ul>
<li>时间：2023-01-05<br />
</li>
<li>出处：Microsoft<br />
</li>
<li>贡献：用3s录音和文本对应的音素生成语音。<br />
</li>
<li>结构：也是AudioLM的延展，比Spear-TTS早一些。<br />
<img
src="/attachments_2023/Pasted%20image%2020230505151400.png" /><br />
以分层的方式设计了两个条件语言模型，一个用于生成声音c1（自回归AR），一个用于精调声音c2-8（NAR非自回归）。AR
模型和 NAR 模型的结合在语音质量和推理速度之间提供了良好的折衷。<br />
<img src="/attachments_2023/Pasted%20image%2020230505154108.png" /></li>
</ul>
<h4 id="valle-x">3.3.4 VALLE-X</h4>
<ul>
<li>时间：2023-03-07<br />
</li>
<li>出处：Microsoft<br />
</li>
<li>贡献：以源语言语音和目标语言文本为提示，预测目标语言语音的声学标记序列，可用于从语音到语音的翻译任务。它可以生成目标语言的高质量语音，同时保留看不见的说话者的声音、情感和声学环境。有效缓解了外国口音问题，可以通过语言ID来控制。<br />
</li>
<li>结构：与VALL-E基本一致，但使用多语言训练，并加入了语言ID。除了模型本身，结合使用
G2P Tool 将文本转换成音素，以及最后使用 Encodec 生成音频数据。<br />
<img
src="/attachments_2023/Pasted%20image%2020230505162221.png" /><br />
自回归和非自回归模型的输入不同；右侧显示了语音到语音翻译的过程。<br />
给定源语音 Xs，语音识别和翻译模型首先从语义编码器生成源音素
Ss，从语义解码器生成目标音素 St。此外，使用 EnCodec 编码器将 X
压缩为源声学标记 As。然后，将 Ss、St 和 As 连接起来，作为 VALL-E X
的输入，以生成目标语音的声学标记序列。使用 EnCodec
的解码器将生成的声学标记转换为最终的目标语音。<br />
<img src="/attachments_2023/Pasted%20image%2020230505164738.png" /></li>
</ul>
<h4 id="bark">3.3.5 BARK</h4>
<ul>
<li>时间：2023-04<br />
</li>
<li>出处：suno-ai<br />
</li>
<li>贡献：开包即用的多语言语音合成器，可在本地部署使用。<br />
</li>
<li>结构：<br />
<img
src="/attachments_2023/Pasted%20image%2020230507121038.png" /><br />
Bark通过三个Transformer模型，将文本转换为音频。<br />
</li>
<li>文本到语义Token<br />
输入：由Hugging Face的BERT标记器分词的文本<br />
输出：编码生成音频的语义Token<br />
</li>
<li>语义到粗略Token<br />
输入：语义Token<br />
输出：来自Facebook的EnCodec编解码器的前两个codebooks的Token<br />
</li>
<li>粗略到细节Token<br />
输入：EnCodec的前两个codebooks<br />
输出：EnCodec的8个codebooks</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>Django_1_入门</title>
    <url>/0_Inbox/1_%E6%AD%A3%E5%9C%A8%E5%81%9A/django/Django_1_%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h2 id="django">1 Django</h2>
<h3 id="简介">1.1 简介</h3>
<p>Django 是一个高级 Python Web 框架，致力于用更少的代码，构建更好的 Web
应用程序，总而言之，它是一个成熟的后端框架。</p>
<h3 id="为什么使用-django">1.2 为什么使用 Django</h3>
<p>后端 Django 配合前端 Vue
的组合确实用的太多了，可以算是一个必备技能。</p>
<h4 id="优点">1.2.1 优点</h4>
<ul>
<li>用户管理，数据库都不用自己处理，不用考虑具体细节实现<br />
</li>
<li>生态成熟，周边工具、资源、教程多</li>
</ul>
<h4 id="缺点">1.2.2 缺点</h4>
<ul>
<li>自成体系，有自己的框架，学习成本高<br />
</li>
<li>代码结构相对复杂，不像 flask 那么简捷</li>
</ul>
<h3 id="相关概念">1.3 相关概念</h3>
<h4 id="模型-model">1.3.1 模型 Model</h4>
<p>数据存取层，用于处理与数据相关的所有事务：
存取、验证有效性、行为以及数据之间的关系等。</p>
<h4 id="模板-template">1.3.2 模板 Template</h4>
<p>表现层，用于处理具体的显示，包括 HTML 页面和前端模板。</p>
<h4 id="视图-view">1.3.3 视图 View</h4>
<p>业务逻辑层，用于处理模型及模板的相关逻辑，是模型与模板间的桥梁。</p>
<h2 id="使用方法">2 使用方法</h2>
<h3 id="安装">2.1 安装</h3>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">pip3 install Django</span>  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">django-admin --version <span class="comment"># 查看版本</span></span>  </span><br><span class="line">```  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## 2.2 创建项目</span></span>  </span><br><span class="line">``` shell  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">django-admin startproject mytools <span class="comment"># 创建项目</span></span>  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> mytools</span>  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python manage.py startapp myapp <span class="comment"># 创建应用程序目录</span></span>  </span><br><span class="line">```  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## 2.3 写程序</span></span>  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">### 2.3.1 实现功能</span></span>  </span><br><span class="line">``` shell  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi myapp/views.py</span>  </span><br><span class="line">```   </span><br><span class="line">加入以下 Python 代码  </span><br><span class="line">``` python  </span><br><span class="line">from django.http import HttpResponse  </span><br><span class="line">  </span><br><span class="line">def hello(request):  </span><br><span class="line">    return HttpResponse(&quot;Hello, Django World!&quot;)  </span><br><span class="line">```  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">### 2.3.2 设定接口</span></span>  </span><br><span class="line">```  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi mytools/urls.py</span>  </span><br><span class="line">```  </span><br><span class="line">Python 程序改为：  </span><br><span class="line">``` python  </span><br><span class="line">from django.contrib import admin  </span><br><span class="line">from django.urls import path  </span><br><span class="line">from myapp.views import hello  </span><br><span class="line">  </span><br><span class="line">urlpatterns = [  </span><br><span class="line">    path(&#x27;admin/&#x27;, admin.site.urls),  </span><br><span class="line">    path(&#x27;hello/&#x27;, hello),  </span><br><span class="line">]  </span><br><span class="line">```  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## 2.4 运行服务</span></span>  </span><br><span class="line">``` python  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python manage.py runserver 0.0.0.0:8001</span>  </span><br><span class="line">```  </span><br><span class="line">此时，在本机8001端口打开访问新建的 hello。  </span><br><span class="line">http://localhost:8001/hello/  </span><br><span class="line">由于设定了 ip 为 0.0.0.0，则在docker外部通过 ip 也可以访问该网址，需要注意的是需要在 setting.py 中添加 ip 地址：  </span><br><span class="line">``` shell  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi mytools/settings.py</span>  </span><br><span class="line">```  </span><br><span class="line">修改形如：  </span><br><span class="line">``` python  </span><br><span class="line">ALLOWED_HOSTS = [&#x27;192.168.10.106&#x27;]  </span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>Django_2_进阶</title>
    <url>/0_Inbox/1_%E6%AD%A3%E5%9C%A8%E5%81%9A/django/Django_2_%E8%BF%9B%E9%98%B6/</url>
    <content><![CDATA[<p>本文将介绍一些 Django 的进阶用法</p>
<h2 id="用户管理">1 用户管理</h2>
<p>下面介绍最简单的用户管理方法：用 admin 管理员创建普通用户；仅实现
login.html 界面，使用 django 内部逻辑完成用户登录。</p>
<h3 id="建库">1.1 建库</h3>
<h4 id="建库-1">1.1.1 建库</h4>
<pre class="shell"><code>$ python manage.py migrate  
$ python manage.py createsuperuser # 创建管理员  </code></pre>
<h4 id="修改配置文件">1.1.2 修改配置文件</h4>
<pre class="shell"><code>$ vi mytools/settings.py  </code></pre>
<p>加入</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>AUTHENTICATION_BACKENDS <span class="op">=</span> [  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;django.contrib.auth.backends.ModelBackend&#39;</span>,  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>]  </span></code></pre></div>
<h3 id="添加新用户">1.2 添加新用户</h3>
<p>访问 admin 界面，用刚才创建的 superuser 登录<br />
http://localhost:8001/admin/<br />
按提示创建几个user用户</p>
<h3 id="在界面中调用登录界面">1.3 在界面中调用登录界面</h3>
<h4 id="在接口前加装饰器">1.3.1 在接口前加装饰器</h4>
<pre class="shell"><code>$ vi mytools/myapp/views.py  </code></pre>
<p>加入</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> django.contrib.auth.decorators <span class="im">import</span> login_required  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="at">@login_required</span>  </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 具体接口  </span></span></code></pre></div>
<h4 id="添加登录界面">1.3.2 添加登录界面</h4>
<pre class="shell"><code>$ vi mytools/myapp/urls.py  </code></pre>
<p>加入</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> django.contrib.auth <span class="im">import</span> views <span class="im">as</span> auth_views  </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>urlpatterns <span class="op">=</span> [  </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    path(<span class="st">&#39;accounts/login/&#39;</span>, admin.site.urls),  </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>]  </span></code></pre></div>
<h4 id="实现登录界面">1.3.3 实现登录界面</h4>
<p>添加 login.html 界面</p>
<pre class="shell"><code>$ mkdir templates/registration/  
$ vi templates/registration/login.html  </code></pre>
<p>添加以下内容，界面比较丑：</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;!DOCTYPE </span>html<span class="dt">&gt;</span>  </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;html</span> <span class="er">lang</span><span class="ot">=</span><span class="st">&quot;en&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;head&gt;</span>  </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;meta</span> <span class="er">charset</span><span class="ot">=</span><span class="st">&quot;UTF-8&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;title&gt;</span>Login<span class="kw">&lt;/title&gt;</span>  </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/head&gt;</span>  </span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;body&gt;</span>  </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;h1&gt;</span>Login<span class="kw">&lt;/h1&gt;</span>  </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;form</span> <span class="er">method</span><span class="ot">=</span><span class="st">&quot;post&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">&#123;% csrf_token %&#125;</span>  </span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        <span class="kw">&lt;label</span> <span class="er">for</span><span class="ot">=</span><span class="st">&quot;username&quot;</span><span class="kw">&gt;</span>Username:<span class="kw">&lt;/label&gt;</span>  </span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        <span class="kw">&lt;input</span> <span class="er">type</span><span class="ot">=</span><span class="st">&quot;text&quot;</span> <span class="er">id</span><span class="ot">=</span><span class="st">&quot;username&quot;</span> <span class="er">name</span><span class="ot">=</span><span class="st">&quot;username&quot;</span> <span class="er">required</span><span class="kw">&gt;&lt;br&gt;</span>  </span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>        <span class="kw">&lt;label</span> <span class="er">for</span><span class="ot">=</span><span class="st">&quot;password&quot;</span><span class="kw">&gt;</span>Password:<span class="kw">&lt;/label&gt;</span>  </span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>        <span class="kw">&lt;input</span> <span class="er">type</span><span class="ot">=</span><span class="st">&quot;password&quot;</span> <span class="er">id</span><span class="ot">=</span><span class="st">&quot;password&quot;</span> <span class="er">name</span><span class="ot">=</span><span class="st">&quot;password&quot;</span> <span class="er">required</span><span class="kw">&gt;&lt;br&gt;</span>  </span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        <span class="kw">&lt;button</span> <span class="er">type</span><span class="ot">=</span><span class="st">&quot;submit&quot;</span><span class="kw">&gt;</span>Login<span class="kw">&lt;/button&gt;</span>  </span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;/form&gt;</span>  </span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/body&gt;</span>  </span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/html&gt;</span>  </span></code></pre></div>
<h2 id="使用网页模板">2 使用网页模板</h2>
<p>实现简单的前后端界面</p>
<h3 id="设置模板目录">2.1 设置模板目录</h3>
<p>修改配置文件：</p>
<pre class="shell"><code>$ vi mytools/settings.py  </code></pre>
<p>修改模板目录，形如：</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>TEMPLATES <span class="op">=</span> [  </span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    &#123;  </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;BACKEND&#39;</span>: <span class="st">&#39;django.template.backends.django.DjangoTemplates&#39;</span>,  </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;DIRS&#39;</span>: [os.path.join(BASE_DIR, <span class="st">&#39;templates&#39;</span>),],   </span></code></pre></div>
<h3 id="创建模板">2.2 创建模板</h3>
<pre class="shell"><code>$ mkdir templates/myapp -p  
$ vi templates/myapp/translate.html  </code></pre>
<p>加入网页内容如下：</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;!DOCTYPE </span>html<span class="dt">&gt;</span>  </span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;html</span> <span class="er">lang</span><span class="ot">=</span><span class="st">&quot;en&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;head&gt;</span>  </span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;meta</span> <span class="er">charset</span><span class="ot">=</span><span class="st">&quot;UTF-8&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;title&gt;</span>英文翻译中文<span class="kw">&lt;/title&gt;</span>  </span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/head&gt;</span>  </span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;body&gt;</span>  </span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;h1&gt;</span>英文翻译中文<span class="kw">&lt;/h1&gt;</span>  </span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;form</span> <span class="er">method</span><span class="ot">=</span><span class="st">&quot;post&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">&#123;% csrf_token %&#125;</span>  </span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>        <span class="kw">&lt;label</span> <span class="er">for</span><span class="ot">=</span><span class="st">&quot;english_text&quot;</span><span class="kw">&gt;</span>请输入英文：<span class="kw">&lt;/label&gt;</span>  </span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>        <span class="kw">&lt;input</span> <span class="er">type</span><span class="ot">=</span><span class="st">&quot;text&quot;</span> <span class="er">id</span><span class="ot">=</span><span class="st">&quot;english_text&quot;</span> <span class="er">name</span><span class="ot">=</span><span class="st">&quot;english_text&quot;</span> <span class="er">required</span><span class="kw">&gt;</span>  </span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>        <span class="kw">&lt;button</span> <span class="er">type</span><span class="ot">=</span><span class="st">&quot;submit&quot;</span><span class="kw">&gt;</span>翻译<span class="kw">&lt;/button&gt;</span>  </span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;/form&gt;</span>  </span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">&#123;% if chinese_translation %&#125;  
    <p>中文翻译结果：&#123;&#123; chinese_translation &#125;&#125;</p>  
    &#123;% endif %&#125;</span>  </span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/body&gt;</span>  </span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/html&gt;</span>  </span></code></pre></div>
<h3 id="使用模板">2.3 使用模板</h3>
<pre><code>$ vi mytools/apps/views.py  </code></pre>
<p>加入</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> translate(request):  </span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> request.method <span class="op">==</span> <span class="st">&#39;POST&#39;</span>:  </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>        english_text <span class="op">=</span> request.POST.get(<span class="st">&#39;english_text&#39;</span>, <span class="st">&#39;&#39;</span>)  </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>        chinese_translation <span class="op">=</span> english_text.upper()  </span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> render(request, <span class="st">&#39;myapp/translate.html&#39;</span>, &#123;<span class="st">&#39;chinese_translation&#39;</span>: chinese_translation&#125;)      </span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> render(request, <span class="st">&#39;myapp/translate.html&#39;</span>)  </span></code></pre></div>
<h2 id="使用-css-样式">3 使用 css 样式</h2>
<h3 id="创建静态文件目录">3.1 创建静态文件目录</h3>
<pre class="shell"><code>$ mkdir myapp/static  
$ vi myapp/static/styles.css  </code></pre>
<p>内容大致如下：</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode css"><code class="sourceCode css"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">/* 设置全局字体和字号 */</span>  </span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>body &#123;  </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">font-family</span>: Arial<span class="op">,</span> <span class="dv">sans-serif</span><span class="op">;</span>  </span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">font-size</span>: <span class="dv">16</span><span class="dt">px</span><span class="op">;</span>  </span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">line-height</span>: <span class="dv">1.5</span><span class="op">;</span>  </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>&#125;  </span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co">/* 设置链接样式 */</span>  </span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>a &#123;  </span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">text-decoration</span>: <span class="dv">none</span><span class="op">;</span>  </span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">color</span>: <span class="cn">#007bff</span><span class="op">;</span>  </span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>&#125;  </span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co">/* 设置标题样式 */</span>  </span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>h1<span class="op">,</span> h2<span class="op">,</span> h3 &#123;  </span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">font-family</span>: <span class="st">&#39;Times New Roman&#39;</span><span class="op">,</span> <span class="dv">serif</span><span class="op">;</span>  </span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">font-weight</span>: <span class="dv">bold</span><span class="op">;</span>  </span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">color</span>: <span class="cn">#333</span><span class="op">;</span>  </span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>&#125;  </span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="co">/* 设置背景颜色 */</span>  </span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>body &#123;  </span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">background-color</span>: <span class="cn">#f0f0f0</span><span class="op">;</span>  </span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>&#125;  </span></code></pre></div>
<h3 id="修改配置文件-1">3.2 修改配置文件</h3>
<pre><code>$ vi mytools/settings.py  </code></pre>
<p>加入静态数据相关设置</p>
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>STATIC_URL <span class="op">=</span> <span class="st">&#39;/static/&#39;</span> <span class="co"># 指定在模板中引用静态文件时的基本 URL  </span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>STATIC_ROOT <span class="op">=</span> os.path.join(BASE_DIR, <span class="st">&#39;staticfiles&#39;</span>) <span class="co"># 用于收集静态文件的目标目录，主要用于构建生产环境  </span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>STATICFILES_DIRS <span class="op">=</span> [ <span class="co"># 列表包含静态文件目录  </span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    os.path.join(BASE_DIR, <span class="st">&#39;myapp/static&#39;</span>),  </span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>]  </span></code></pre></div>
<p>生成</p>
<pre class="shell"><code>$ python manage.py collectstatic # 主要用于构建生产环境  </code></pre>
<p>设置之后请重启 django 服务以确保生效</p>
<h3 id="设置-html-的格式">3.3 设置 html 的格式</h3>
<div class="sourceCode" id="cb21"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">&#123;% load static %&#125;</span>  </span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;html&gt;</span>  </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;head&gt;</span>  </span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;link</span> <span class="er">rel</span><span class="ot">=</span><span class="st">&quot;stylesheet&quot;</span> <span class="er">type</span><span class="ot">=</span><span class="st">&quot;text/css&quot;</span> <span class="er">href</span><span class="ot">=</span><span class="st">&quot;</span><span class="er">&lt;</span><span class="st">!--swig￼5--&gt;&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;script</span> <span class="er">src</span><span class="ot">=</span><span class="st">&quot;</span><span class="er">&lt;</span><span class="st">!--swig￼6--&gt;&quot;</span><span class="kw">&gt;&lt;/script&gt;</span>  </span></code></pre></div>
<h3 id="其它模板下载">4.3 其它模板下载</h3>
<p>https://bootswatch.com/</p>
<h2 id="参考">5 参考</h2>
<p><a
href="https://www.zhihu.com/tardis/bd/art/462232259?source_id=1001">使用django-bootstrap3创建网站</a></p>
]]></content>
  </entry>
  <entry>
    <title>ChatGPT API</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/ChatGPT/ChatGPT_API/</url>
    <content><![CDATA[<h2 id="用法">1 用法</h2>
<h3 id="申请api-key">1.1 申请API KEY</h3>
<p><a
href="https://platform.openai.com/">openai平台</a>，右上角-&gt;Personal-&gt;API
Key-&gt;Create secret key，然后将key加入代码。<br />
ChatGPT3.5收费的单位,是“$0.002 per 1k
tokens”,每1000个tokens需要花费0.002美元。</p>
<h3 id="代码">1.2 代码</h3>
<h4 id="命令行">1.2.1 命令行</h4>
<pre class="shell"><code>curl https://api.openai.com/v1/chat/completions \  
 -H &quot;Authorization: Bearer $OPENAI_API_KEY&quot; \  
 -H &quot;Content-Type: application/json&quot; \  
 -d &#39;&#123;  
 &quot;model&quot;: &quot;gpt-3.5-turbo&quot;,  
 &quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is the OpenAI mission?&quot;&#125;]   
 &#125;&#39;  </code></pre>
<h4 id="python">1.2.2 Python</h4>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> openai  </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>completion <span class="op">=</span> openai.ChatCompletion.create(  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  model<span class="op">=</span><span class="st">&quot;gpt-3.5-turbo&quot;</span>,   </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  messages<span class="op">=</span>[&#123;<span class="st">&quot;role&quot;</span>: <span class="st">&quot;user&quot;</span>, <span class="st">&quot;content&quot;</span>: <span class="st">&quot;Tell the world about the ChatGPT API in the style of a pirate.&quot;</span>&#125;]  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>)  </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(completion)  </span></code></pre></div>
<h4 id="完整代码">1.2.3 完整代码</h4>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> openai  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 只需要在python里设置代理即可  </span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">&#39;HTTP_PROXY&#39;</span>] <span class="op">=</span> <span class="st">&#39;http://ip:port&#39;</span>   </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">&#39;HTTPS_PROXY&#39;</span>] <span class="op">=</span> <span class="st">&#39;http://ip:port&#39;</span>   </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>openai.api_key <span class="op">=</span> <span class="st">&#39;自已申请一个key，目前好像还没开始收费&#39;</span>   </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_openai(string):  </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    completion <span class="op">=</span> openai.ChatCompletion.create(  </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">&quot;gpt-3.5-turbo&quot;</span>,   </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    messages<span class="op">=</span>[&#123;<span class="st">&quot;role&quot;</span>: <span class="st">&quot;user&quot;</span>, <span class="st">&quot;content&quot;</span>: string&#125;]  </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    )  </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> completion[<span class="st">&#39;choices&#39;</span>][<span class="dv">0</span>][<span class="st">&#39;message&#39;</span>][<span class="st">&#39;content&#39;</span>].strip()  </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>test_openai(<span class="st">&quot;REVSC OPN/PRQ ILIAC ART W/STNT &amp; ANGIOP IPSILATL 的ICD-CM-9手术编码是什么,用中文简单回答&quot;</span>)  </span></code></pre></div>
<p>目前能用，至于回答的对不对，那就是另一回事儿了。</p>
<p>使用效果如下：<br />
<img src="/attachments_2023/Pasted%20image%2020230310100505.png" /></p>
<h3 id="查看使用情况">1.3 查看使用情况</h3>
<p>chatgpt平台-&gt;右上角-&gt;Personal-&gt;在Usage中可以查看自己的使用情况，目前送18$，我的有效期致4月1日。<br />
<img src="/attachments_2023/Pasted%20image%2020230308181755.png" /></p>
<h2 id="技巧">2 技巧</h2>
<p>总结了一些简单的提升效率，节约资源的方法如下：<br />
* API 主要用于需要批量处理或者自动处理的场景中。<br />
* 将复杂问题拆分成几个步骤问题，更容易得到正常答案。<br />
* 提供一些上下文信息，以避免歧意。<br />
* 加一些提示：如 “请用中文简单回答”，以节约流量。</p>
<h2 id="充值">3 充值</h2>
<h3 id="流量评测">3.1 流量评测</h3>
<p>亲测，发了大约3000个请求，内容为中英文混杂，提问为普通长短，回答为简答；用Python的len统计字串长度约
465201，约 0.86$，差不多一个字一个token的样子（自己计算约 0.96 $）。</p>
<h3 id="虚拟信用卡充值">3.2 虚拟信用卡充值</h3>
<p>目前可以免费试用API，后期如果需要付费使用或者升Plus会员，则需要申请一张欧美信用卡（可用虚拟信用卡）向ChatGPT充值。以下方法230307前后亲测有效。<br />
<a href="https://juejin.cn/post/7206249233115643959">ChatGPT API
Key申请使用及充值教程</a><br />
<a href="https://chatgpt-plus.github.io/chatgpt-plus/">国内开通Chat GPT
Plus保姆级教程</a></p>
<h3 id="chatgpt充值">3.3 ChatGPT充值</h3>
<p>ChatGPT平台-&gt;右上角-&gt;Personal<br />
需要注意的是：目前使用API方式也需要外网。</p>
<h3 id="参见">3.4 参见</h3>
<p><a
href="https://openai.com/blog/introducing-chatgpt-and-whisper-apis">ChatGPT
API 使用方法</a></p>
<h2 id="其它">4 其它</h2>
<h3 id="美国五个免消费税的州是">4.1 美国五个免消费税的州是</h3>
<p>特拉华州 Delaware<br />
新罕布什尔州 New Hampshire<br />
蒙大拿州 Montana<br />
俄勒冈州 Oregon<br />
阿拉斯加州 Alaska</p>
<h3 id="浏览器开启无痕模式">4.2 浏览器开启无痕模式</h3>
<h3 id="查ip具体位置">4.3 查IP具体位置</h3>
<p>http://en.ipip.net/</p>
<h2 id="新实验">5 新实验</h2>
<ul>
<li>买了新号 20元<br />
</li>
<li>使用了俄勒冈的代理（IP）<br />
</li>
<li>信用卡设置了俄勒冈的地址，就在IP附近<br />
</li>
<li>还用了之前 Depay 的信用卡号，set up 卡片时，仍显示 Declined<br />
<img src="/attachments_2023/Pasted%20image%2020230521214745.png" /></li>
</ul>
]]></content>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>llamaindex_分享</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/ChatGPT/llamaindex_%E5%88%86%E4%BA%AB/</url>
    <content><![CDATA[<p><a
href="1_Note/0_工具/ChatGPT/llamaindex结构图.canvas">llamaindex结构图</a></p>
<h2 id="功能">1 功能</h2>
<p>大模型学习的主要是通用数据，而用户可能需要让ChatGPT在本地的知识库中寻找答案。<br />
普通用户不太可能训练大模型；由于本地数据格式丰富，内容烦多，且考虑到使用成本和token大小限制，也不可能在每次提问时都将所有数据传给ChatGPT。<br />
llamaindex提供了解决此问题的方法：通过ChatGPT把本地文本转成Embedding，然后在本地建立数据索引；询问时先在本地查询，再用ChatGPT将查询结果合成答案，llamaindex是用户数据和大模型之间的接口。</p>
<h2 id="原理">2 原理</h2>
<h3 id="模块">2.1 模块</h3>
<p><img
src="/attachments_2023/Pasted%20image%2020230511102545.png" /></p>
<p>llama_index由三个主要模块组成：<br />
* 数据模块：用于读取本地或网络数据，并将大块文本切分成Node块。<br />
*
索引和存储模块：将文本块通过ChatGPT转换成Embedding嵌入表示存储在本地，构建本地知识库。<br />
*
搜索模块：根据使用者提出的问题，在本地知识库中定位可能的答案，然后将问题和答案传给ChatGPT整合出最终答案。</p>
<h3 id="组织数据">2.2 组织数据</h3>
<p>当用户提出问题时，需要与本地知识库进行匹配，如果数据库中内容很多，会花费大量匹配时间。为节约时间，可以对文章中的章、节、文本文件整体内容、目录内容等生成总结，逐层构造树结构，图结构，或者关键字映射表，以节约搜索时间。<br />
llamaindex提供了各种结构支持，需要开发者自行调用。<br />
<img src="/attachments_2023/Pasted%20image%2020230514153950.png" /></p>
<h3 id="核心概念">2.3 核心概念</h3>
<ul>
<li><p>Node &amp; Index<br />
Node指切分后的文本块；Index索引可以理解为Node数据块通过ChatGPT转换后在本地的存储方式。索引结构支持List,
Tree,
Keyword方式；除了创建index以外，还提供对其中的子块进行增删的编辑操作，以节约token。另外，除了对纯文本进行索引，还提供图索引，表索引，SQL中数据索引。</p></li>
<li><p>Embedding &amp; Vector<br />
这里的Embedding和Vector指的都是通过ChatGPT转换后的数据；当前版本嵌入的维度是
1536（问题的和Node一样长）；假设将每个块设成最大600（Node: chunk
size），如果是18K大小的文本文件，存储了utf-8的中文文字，每字占3字节，6000多字，约使用10来个Node存储；每个Node被转换成1538个float值，存储在本地，即Vector
store。</p></li>
<li><p>Query &amp; Response Synthesis<br />
Query询问指的是用户提出的问题；Response
Synthesis指的是从索引中定位出可选答案后，组织答案的方法。</p></li>
</ul>
<h2 id="文档">3 文档</h2>
<h3 id="文档内容">3.1 文档内容</h3>
<p>代码中的docs目录数据用于生成网页版的说明文档，也可通过以下网址直接查看文档：<br />
https://gpt-index.readthedocs.io/en/latest/<br />
通过操作界面左上图标可调出帮助目录，操作左下角切换不同版本文档。</p>
<h3 id="学习路径">3.2 学习路径</h3>
<p>文档内容很多，包含文本和源码示例，推荐使用以下顺序阅读文档：<br />
* gallery: 看别人用该库实现的功能<br />
* getting_started: 最简单的安装方法和示例<br />
* guides: 一般用户使用方法<br />
* use_case: 使用案例（做了什么，怎么做，相对简单）<br />
* how_to (KEY COMPONENTS):
原理和用法的主索引，从上到下由浅入深（前三项最重要）<br />
* reference: 细节的详细信息, 大部分是源码自动生成的文档
（具体使用时查看）</p>
<h2 id="代码分析">4 代码分析</h2>
<ul>
<li>benchmarks: 用于评测<br />
</li>
<li>build/dist/scripts: 打包过程中产生的目录文件<br />
</li>
<li>tests: 测试用例<br />
</li>
<li>llama_index: 核心源码 (200多个源码文件)
<ul>
<li>readers: 从各种数据源读入数据的解析工具, 其file支持多种模式<br />
</li>
<li>index, storage, query等，建议以文档为入口开始学习<br />
</li>
</ul></li>
<li>examples: 分门别类的示例<br />
</li>
<li>experimental: 一些不重要的实验<br />
</li>
<li>README.md：示例了最简单的使用方法</li>
</ul>
<h3 id="安装">4.1 安装</h3>
<h4 id="pip安装">4.1.1 pip安装</h4>
<p>llamaindex 是个 python库，用pip安装即可（需要Python
3.8及以上版本）。</p>
<pre><code>pip install llama-index  </code></pre>
<h4 id="源码安装">4.1.2 源码安装</h4>
<p>由于版本更替太快，建议使用源码安装。<br />
源码地址：https://github.com/jerryjliu/llama_index</p>
<h2 id="注意事项">5 注意事项</h2>
<ul>
<li>使用ChatGPT需要设置代理和APIKEY<br />
</li>
<li>需要指定数据在本地存放的目录<br />
</li>
<li>如果需要可以做多个索引<br />
</li>
<li>注意安装的版本和源码一致，否则example将无法运行<br />
</li>
<li>推荐使用最新版本，目前最新版本0.6.x的数据模式以及log信息都优于之前版本</li>
</ul>
<h2 id="其它">6 其它</h2>
<h3 id="示例代码">6.1 示例代码</h3>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> llama_index <span class="im">import</span> SimpleDirectoryReader, PromptHelper, LLMPredictor, ServiceContext  </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain <span class="im">import</span> OpenAI  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gradio <span class="im">as</span> gr  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os  </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> llama_index <span class="im">import</span> GPTVectorStoreIndex, SimpleDirectoryReader, LLMPredictor, ServiceContext  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> llama_index <span class="im">import</span> StorageContext, load_index_from_storage  </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 环境变量  </span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">&#39;HTTP_PROXY&#39;</span>] <span class="op">=</span> <span class="st">&#39;http://localhost:7890&#39;</span>  </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">&#39;HTTPS_PROXY&#39;</span>] <span class="op">=</span> <span class="st">&#39;http://localhost:7890&#39;</span>  </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">&quot;OPENAI_API_KEY&quot;</span>] <span class="op">=</span> <span class="st">&quot;xxx&quot;</span>  </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 显示更多DEBUG信息  </span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging  </span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys  </span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>logging.basicConfig(stream<span class="op">=</span>sys.stdout, level<span class="op">=</span>logging.DEBUG)  </span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>logging.getLogger().addHandler(logging.StreamHandler(stream<span class="op">=</span>sys.stdout))  </span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="co">## 工具  </span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> construct_index(directory_path):  </span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    max_input_size <span class="op">=</span> <span class="dv">4096</span>  </span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    num_outputs <span class="op">=</span> <span class="dv">2000</span>  </span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    chunk_overlap_ratio <span class="op">=</span> <span class="fl">0.1</span>  </span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    chunk_size_limit <span class="op">=</span> <span class="dv">600</span>  </span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    prompt_helper <span class="op">=</span> PromptHelper(context_window <span class="op">=</span> max_input_size,   </span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>                                 num_output <span class="op">=</span> num_outputs,   </span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>                                 chunk_overlap_ratio<span class="op">=</span>chunk_overlap_ratio,   </span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>                                 chunk_size_limit<span class="op">=</span>chunk_size_limit)  </span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    llm_predictor <span class="op">=</span> LLMPredictor(llm<span class="op">=</span>OpenAI(temperature<span class="op">=</span><span class="fl">0.7</span>, model_name<span class="op">=</span><span class="st">&quot;gpt-3.5-turbo&quot;</span>,   </span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>                                            max_tokens<span class="op">=</span>num_outputs))  </span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    documents <span class="op">=</span> SimpleDirectoryReader(directory_path).load_data()  </span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>    service_context <span class="op">=</span> ServiceContext.from_defaults(llm_predictor<span class="op">=</span>llm_predictor,   </span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>                                                   prompt_helper<span class="op">=</span>prompt_helper)  </span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>    index <span class="op">=</span> GPTVectorStoreIndex.from_documents(documents,service_context<span class="op">=</span>service_context,  </span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>                                               prompt_helper<span class="op">=</span>prompt_helper)  </span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    index.storage_context.persist() <span class="co"># 保存  </span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> index  </span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a><span class="co">## 生成索引  </span></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> construct_index(<span class="st">&quot;docs&quot;</span>)  </span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a><span class="co">## 提问  </span></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>chatbot(<span class="st">&quot;MODS,中文回答&quot;</span>)  </span></code></pre></div>
<p>启动网页界面，默认启动7860端口：</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gradio <span class="im">as</span> gr  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>iface <span class="op">=</span> gr.Interface(fn<span class="op">=</span>chatbot,  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>                     inputs<span class="op">=</span>gr.inputs.Textbox(lines<span class="op">=</span><span class="dv">7</span>, label<span class="op">=</span><span class="st">&quot;输入您的文本&quot;</span>),  </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>                     outputs<span class="op">=</span><span class="st">&quot;text&quot;</span>,  </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>                     title<span class="op">=</span><span class="st">&quot;AI 知识库聊天机器人&quot;</span>)  </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>iface.launch(share<span class="op">=</span><span class="va">True</span>)   </span></code></pre></div>
<p><img
src="/attachments_2023/Pasted%20image%2020230512153206.png" /></p>
<h3 id="我的环境">6.2 我的环境</h3>
<ul>
<li>位置在：/exports/git/llama_index/mine/test.ipynb<br />
</li>
<li>运行镜像：docker run --rm -v /exports:/opt/xieyan --name
gpt-academic -d --net host -p 8866:8866 -p 7860:7860 -p 8823:22
gpt-academic:xy_04 bash</li>
</ul>
<h3 id="源码中的主要代码">6.3 源码中的主要代码</h3>
<ul>
<li>对于本地Embedding的检索一般在
<ul>
<li>llama_index/indices/query/embedding_utils.py
<ul>
<li>get_top_k_embeddings()<br />
</li>
</ul></li>
<li>llama_index/vector_stores/simple.py
<ul>
<li>SimpleVectorStore:query()<br />
</li>
</ul></li>
<li>根据根据以上函数内部Node遍历时间即可估算其效率<br />
</li>
</ul></li>
<li>核心示例
<ul>
<li>最上层README</li>
</ul></li>
</ul>
<h3 id="一些想法">6.4 一些想法</h3>
<ul>
<li>是不是按段转更合适<br />
</li>
<li>对不同类型文章有不同组织方式，比如知识型，情节推动型...</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>试用MetaGPT</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/ChatGPT/%E8%AF%95%E7%94%A8MetaGPT/</url>
    <content><![CDATA[<h2 id="简介">简介</h2>
<p>最近朋友和B站都给我推 MetaGPT，正好有空就下载亲测了一下。MetaGPT
是目前（230809）github热榜第一名，今天就加了3000多个星。</p>
<p>MetaGPT是一个多智能体框架，能够生成不同的角色：工程师、产品经理、架构师和项目经理。然后共同构建一个软件项目，使用的模型是GPT-4，与AutoGPT有些类似。</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230809161421.png" /><br />
中文帮助文档见：https://github.com/geekan/MetaGPT/blob/main/docs/README_CN.md</p>
<h2 id="实验">实验</h2>
<h3 id="搭建环境">搭建环境</h3>
<pre><code>$ git clone https://github.com/geekan/MetaGPT  # 约11M左右  
$ cd MetaGPT  
$ docker build . -t metagpt:baseline # 生成镜像  
$ mkdir -p /opt/metagpt/&#123;config,workspace&#125; # 请切换成root后执行  
$ docker run --rm metagpt/metagpt:v0.3 cat /app/metagpt/config/config.yaml &gt; /opt/metagpt/config/config.yaml  
$ cd /opt/metagpt/  
$ cp config/config.yaml config/key.yaml # 生成配置文件  
修改 key.yaml中的 OPENAI_API_KEY, OPENAI_API_BASE  
$ docker run --name metagpt -d     --privileged     -v /opt/metagpt/config:/app/metagpt/config     -v /opt/metagpt/workspace:/app/metagpt/workspace metagpt:baseline # 运行镜像  
$ docker exec -it metagpt /bin/bash # 进入镜像  </code></pre>
<h3 id="运行">运行</h3>
<pre><code>$ python startup.py &quot;写一个微信小程序，实现简单的文件阅读和翻译功能&quot;  </code></pre>
<p>运行之后，程序创建项目：<br />
workspace/wechat_mini_reader/</p>
<h3 id="实验结果">实验结果</h3>
<ul>
<li>最终花费：￥4.07（GPT-4 用的是一个国内的中转）<br />
</li>
<li>我的需求是：写一个微信小程序，实现简单的文件阅读和翻译功能，最终它生成了一组Python程序（不是微信小程序），是demo的感觉，离完整应用差得比较远。<br />
</li>
<li>生成5个代码文件，包含：Flask构架、sqlite3数据库，调用google
translate的翻译，文件读取等等，整体生成数据400行，其中含代码105行，其它为设计文档。</li>
</ul>
<h3 id="主观感受">主观感受</h3>
<ul>
<li>可以设置你想花多少钱调用GPT-4，默认3$<br />
</li>
<li>工具链做得很好，一小时之内可以上手<br />
</li>
<li>可以做demo，简化了项目开始的工作量<br />
</li>
<li>想用它做一个完整项目，个人觉得差距还比较大<br />
</li>
<li>它生成的竞品分析，API文档，mermaid图也都挺好的<br />
</li>
<li>可能存在大局观问题：每个小步做得都对，合一块不一定对</li>
</ul>
<h2 id="代码分析">代码分析</h2>
<p>目前metagpt的项目，核心代码量有80多个python文件，共6000多行（代码文件都不大），底层也使用了langchain</p>
<h3 id="主要代码">主要代码</h3>
<ul>
<li>startup.py：代码入口，可以设置想花多少钱，需要几个角色合作……<br />
</li>
<li>actions：使用 PROMPT 方式，通过调用 GPT 和其它 API
实现了具体的功能，比如：写代码、分析库依赖、文本转语音、运行代码、测试……<br />
</li>
<li>document_store：各种存储的支持，faiss, milvus,
chromadb向量数据库，本地存储，各种模式数据的读取，<br />
</li>
<li>management：管理所有技能<br />
</li>
<li>memory：管理存储<br />
</li>
<li>prompts：管理各种角色的提示<br />
</li>
<li>provider：调用大语言模型，目前支持Claude和OpenAI<br />
</li>
<li>roles：各角色的具体实现和相关工具，角色包含：工程师，架构师，产品，项目管理……<br />
</li>
<li>tools &amp; utils：辅助工具</li>
</ul>
<h3 id="底层逻辑">底层逻辑</h3>
<p>我觉得，该工具是将软件开发拆解成前后多个步骤，调用模型完成各个步骤，通过提示以及对返回结果的解析，最终结合成完整的项目。即：用大模型实现了软件开发的全链路。<br />
可能对于开发某种类型的应用效果比较好，对于所以类型软件而言，个人觉得目前尚处于初始阶段。有时候不如针对具体问题，直接提问；有时候
MetaGPT 过程也给我们一些启发。<br />
另外，真正应用过程可能遇到的问题是：开发简单的软件可能不需要这么多角色；开发复杂的软件，相互交错的工作，GPT是否能支撑非常复杂的设计？<br />
虽然我个人觉得离自动编程还挺远，不过还是有很多有意思和值得借鉴的内容～～</p>
]]></content>
  </entry>
  <entry>
    <title>试用文心一言</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/ChatGPT/%E8%AF%95%E7%94%A8%E6%96%87%E5%BF%83%E4%B8%80%E8%A8%80/</url>
    <content><![CDATA[<h2 id="入口">1 入口</h2>
<p>https://yiyan.baidu.com/</p>
<h2 id="界面">2 界面</h2>
<h3 id="整体界面">2.1 整体界面</h3>
<ul>
<li>目标：作为普通用户使用。<br />
</li>
<li>结果：整体设计很好，各种角色和提示词，界面也好看，细节到位。</li>
</ul>
<h2 id="模型效果">3 模型效果</h2>
<h3 id="写一段微信小程序">3.1 写一段微信小程序</h3>
<ul>
<li>目标：对于本土化的工具，国外文本生成支持不是很好。<br />
</li>
<li>结果：看着还不错，还没试运行。</li>
</ul>
<h3 id="当朋友聊天我会找谁">3.2 当朋友聊天我会找谁</h3>
<ul>
<li>目标：讨论一些人文问题，提出一些之前和 ChatGPT
聊到的问题，对比答案。<br />
</li>
<li>结果：答案也大差不差，呵呵…… 相对 ChatGPT，我觉得 ERNIE
比较教条，调性不太一样。</li>
</ul>
<h3 id="业务能力">3.3 业务能力</h3>
<ul>
<li>目标：具体业务的能力。<br />
</li>
<li>结果：测试了一下总结长文的能力，理解能力可用。</li>
</ul>
<h2 id="易用性">4 易用性</h2>
<h3 id="申请-api">4.1 申请 API</h3>
<ul>
<li>目标：真正解决问题，还是需要使用 API。<br />
</li>
<li>结果：230831 早上 3:00 申请，10:13 收到短信，通过审核。</li>
</ul>
<h3 id="费用">4.2 费用</h3>
<ul>
<li>目标：看看用哪个更划算<br />
</li>
<li>结果：差不多
<ul>
<li>文心一言：ERNIE-Bot-turbo 0.008元/千tokens<br />
</li>
<li>ChatGPT：0.002美元/千tokens<br />
</li>
</ul></li>
<li>评论：<br />
千帆支持多个模型，有ERNIE的，也有LAMMA，不同模型计费方式不同，可对比不同模型效果；这里更像是个集成平台，而非完全是百度的大语言模型。</li>
</ul>
<h3 id="反馈时间">4.3 反馈时间</h3>
<ul>
<li>目标：评测反馈时间<br />
</li>
<li>结果：
<ul>
<li>问了第一个问题（demo代码中的默认问题）反馈时间 1s<br />
</li>
<li>问第二个问题时，提示：Open api daily request limit reached<br />
</li>
<li>开通了 ERNIE-Bot-turbo 后可正常使用<br />
</li>
<li>客服说送了 20 代金券，但我没找到在哪儿<br />
</li>
<li>重复两次问了一个 800 字的问题，API 反馈时间
3-3.5s（同一问题，ChatGPT网页版回答4s左右）</li>
</ul></li>
</ul>
<h3 id="长度限制">4.4 长度限制</h3>
<ul>
<li>目标：评测其长度限制<br />
</li>
<li>结果：
<ul>
<li>我向它提问：“ERNIE-Bot-turbo 每次提问 token
的长度限制是多少”，回答：“ERNIE-Bot-turbo 每次提问的 token
的长度限制是64个字符”，这明显是不对的。<br />
</li>
<li>我在文档里也没找到，重要参数是不是应该写在比较显眼的地方。</li>
</ul></li>
</ul>
<h3 id="学习成本">4.5 学习成本</h3>
<ul>
<li>目标：评价学习成本<br />
</li>
<li>结果：
<ul>
<li>调用 http 请求，不需要额外安装 Python 包<br />
</li>
<li>可能是出于安全考虑，需要先获得 access_token<br />
</li>
<li>Python代码量不大，学习成本不高<br />
</li>
</ul></li>
<li>相关文档：https://cloud.baidu.com/doc/WENXINWORKSHOP/s/4lilb2lpf</li>
</ul>
<h2 id="整体感受">5 整体感受</h2>
<ul>
<li>至少不用 xx 上网<br />
</li>
<li>中文内容支持更好一些<br />
</li>
<li>客服打电话，加微信，问公司信息，又无法回答技术问题，推销感让人觉得有点……<br />
</li>
<li>我自已用，还是优先
ChatGPT；公司用的，需要正规的渠道，文心一言会比较合适。</li>
</ul>
<h2 id="关于评测">6 关于评测</h2>
<p>大家都不开源，偏重又不一样，普通用户仅仅问几个问题，也评测不出啥效果，只能收集一些大概的感觉。比如，单位用会考虑：是否可用，是否有明显问题；自己常用的领域，支持地好不好；提问和回答的限制价格；自己用可能会考虑：思维的广度，世界观。</p>
]]></content>
  </entry>
  <entry>
    <title>试用智能编程助手——用大模型提升编程效率</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/ChatGPT/%E8%AF%95%E7%94%A8%E6%99%BA%E8%83%BD%E7%BC%96%E7%A8%8B%E5%8A%A9%E6%89%8B%E2%80%94%E2%80%94%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E5%8D%87%E7%BC%96%E7%A8%8B%E6%95%88%E7%8E%87/</url>
    <content><![CDATA[<h2 id="简介">1 简介</h2>
<p>网传有了大模型之后，很多人都要失业了，其中也包括一部分程序员，确实大模型可以减轻开发者的工作量，但是具体到减轻了多少工作量，哪种类型的工作，学习成本，使用成本如何？不捧不踩,今天我们尽量客观地体验一下。</p>
<p>本文将介绍目前使用最多的三个智能编程助手，它们均可提供：代码解释、注释、生成、实时补全等功能。下面基于
VSCode 环境来介绍具体的使用方法。</p>
<h2 id="copilot">2 Copilot</h2>
<h3 id="介绍">2.1 介绍</h3>
<p>Copilot
由Github和OpenAI合作推出，底层基于的Codex模型，通过GPT-3继续训练得到。<br />
Copilot
可以先免费试用一个月。所以大家可以先试试，如果觉得必需，再购买或者在某宝以便宜的方式购买。</p>
<h3 id="vscode使用方法">2.2 VSCode使用方法</h3>
<ul>
<li>安装插件：github copilot, github copilot lab, github copilot
chat<br />
主要功能分成两部分：一部分是生成后续程序 (github
copilot)，另一部分通过与 copilot 对话实现更丰富的功能支持 (github
copilot chat)。<br />
</li>
<li>正常安装后，左侧边栏和界面右下会出现小机器人图标<br />
右下角提示 copilot需要 github
帐号登录，按提示操作即可一个月免费使用（或者申请个比较便宜的学生号）。<br />
<img src="/attachments_2023/Pasted%20image%2020230811112050.png"
alt="|600" /><br />
</li>
<li>生成后续程序<br />
例如：编写一行注释，回车后等几秒，自动生成的代码以灰色呈现；按Tab键接受推荐；Alt+左/右中括号可切换不同的推荐；Ctrl+Enter：打开一个Tab页，查看所有推荐。（其它环境快捷键可能不同，请查看具体帮助页）<br />
</li>
<li>点击左侧图标可调出 Chat 栏<br />
目前版本主要分成四大功能：程序解释、代码翻译、写测试用例、其它功能（BRUSHES）；其它功能又包括：加注释、fixbug，程序拆分、加强稳定性等，其中最后一项"自定义"可以用文本描述功能并执行，该功能非常实用，比如：新加一个函数，一个类，加头文件都可以通过文本描述实现。</li>
</ul>
<h4 id="问题及解决">2.2.1 问题及解决</h4>
<ul>
<li>一开始安装后我的左侧边栏没显示Copilot图标，我更新了vscode最新版，又尝试切换了插件的预发布版本后可正常使用，如果还不正常，也可尝试关闭vscode，再进入。<br />
</li>
<li>如果安装后，没直接出现github登录提示框，可尝试关闭vscode，再进入。</li>
</ul>
<h4 id="资源">2.2.2 资源</h4>
<ul>
<li>主页：https://github.com/features/copilot/<br />
</li>
<li>使用手册：https://docs.github.com/en/copilot/</li>
</ul>
<h3 id="总结">2.3 总结</h3>
<h4 id="优点">2.3.1 优点</h4>
<ul>
<li>稳定，功能全<br />
</li>
<li>生态成熟，支持IDE：JetBrains IDEs，Vim/Neovim，Visual Studio，Visual
Studio Code<br />
</li>
<li>可以根据程序的上下文补全代码</li>
</ul>
<h4 id="缺点">2.3.2 缺点</h4>
<ul>
<li>需要“科学”才能稳定使用，商业版可支持设置代理。<br />
</li>
<li>普通用户每10刀一个月，对认证师生或高质量开源贡献者免费开放。非专业选手不一定非得用
Copilot，而对于专业选手每月10刀也能接受。<br />
</li>
<li>需要配置比较多。</li>
</ul>
<h2 id="codegeex">3 CodeGeeX</h2>
<h3 id="介绍-1">3.1 介绍</h3>
<p>CodeGeeX是清华系列国产工具，底层基于 ChatGLM2模型，开源免费。</p>
<h3 id="vscode使用方法-1">3.2 VSCode使用方法</h3>
<ul>
<li>安装插件：codegeex<br />
安装之后，在右侧看到说明文档，内容比较全也比较长。<br />
</li>
<li>主要功能分成两部分，同copilot，都封装在一个插件中。<br />
</li>
<li>正常安装后，左侧边栏和界面右下会出现类似菱形的图标。<br />
按提示 login，微信登录即可用。<br />
</li>
<li>生成后续程序<br />
基本用法同 Copilot 一致，AI生成的代码浅灰色，按Tab链后变正常。<br />
</li>
<li>点击左侧图标可调出 Chat 栏<br />
Chat
栏支持提问和代码翻译等功能；智能问答含三个基本功能：/explain，/comment，/fixbug（在左下角输入框输入"/"可调出），在右边选代码，左边点功能即可。也可以在框中输入需要操作的文本描述。</li>
</ul>
<h3 id="总结-1">3.3 总结</h3>
<h4 id="优点-1">3.3.1 优点</h4>
<ul>
<li>开源免费<br />
</li>
<li>无需“科学”，直接使用<br />
</li>
<li>无需复杂配置</li>
</ul>
<h4 id="缺点-1">3.3.2 缺点</h4>
<ul>
<li>功能相对偏少，可看作低配版的 Copilot<br />
</li>
<li>在聊天中，输入自已描述的功能效果不太好，它不太能看懂需求<br />
</li>
<li>我测试了两个时段，其中有一次提问时不太稳定，一直 wait timeout
(也可能是巧合)</li>
</ul>
<h2 id="cursor">4 Cursor</h2>
<h3 id="介绍-2">4.1 介绍</h3>
<p>Cursor
是调用Chatgpt接口实现的AI编程工具，目前GPT-3.5可免费使用，GPT-4只对专业订购者开放。Cursor本身是一个IDE，可从其官网下载安装包。</p>
<h3 id="使用方法">4.2 使用方法</h3>
<ul>
<li>从其主页：https://www.cursor.so/ 直接下载对应平台的 IDE 安装。<br />
</li>
<li>IDE 和 VSCode很类似，可看作轻量化的
VSCode，使用习惯非常像，常用快捷键都一样。<br />
</li>
<li>第一次使用时，可以试用左侧的 demo
测试，融入操作的向导非常贴心。<br />
</li>
<li>点击右上角可以对它提问<br />
</li>
<li>主要快捷键有两个：
<ul>
<li>Ctrl+K在代码中操作<br />
</li>
<li>Ctrl+M以提问方式交互<br />
</li>
<li>其它的提示都显示在屏幕上，按提示操作很快就学会了，学习成本低。<br />
</li>
</ul></li>
<li>与代码续写相比，它可以根据需求，生成整个程序，整体更有章法。<br />
<img src="/attachments_2023/Pasted%20image%2020230810142846.png"
alt="|600" /></li>
</ul>
<h3 id="总结-2">4.3 总结</h3>
<h4 id="优点-2">4.3.1 优点</h4>
<ul>
<li>使用 ChatGPT 作为算法引擎，免费可用<br />
</li>
<li>无需“科学”，直接使用<br />
</li>
<li>IDE 和 GPT结合得非常好，几乎所有操作提示全在界面上<br />
</li>
<li>不只是补全，还可以生成整体代码<br />
</li>
<li>无需复杂配置，学习成本低</li>
</ul>
<h4 id="缺点-2">4.3.2 缺点</h4>
<ul>
<li>IDE比较简单，不能满足开发需求<br />
</li>
<li>使用时需要在 VSCode 与 Cursor IDE之间切换，打断思路。</li>
</ul>
<h2 id="讨论">5 讨论</h2>
<h3 id="使用场景">5.1 使用场景</h3>
<ul>
<li>对于新手，我们不用再花很多时间强调代码规范了，让大家直接用 AI
就可以润色出不错的代码和注释。<br />
</li>
<li>对于不熟悉的领域、代码、编程语言，可以快速地了解和梳理代码，解释代码和逻辑。<br />
</li>
<li>自动编写常用的代码片断<br />
</li>
<li>自动编写相对复杂的 正则 或 SQL 查询<br />
</li>
<li>解决一些简单的bug<br />
</li>
<li>帮助程序员快速入门一门语言或一种框架<br />
</li>
<li>快速程序写 demo 和代码框架，程序员只需要做少量修改即可使用</li>
</ul>
<h3 id="使用体验">5.2 使用体验</h3>
<h4 id="基于场景的设计">5.2.1 基于场景的设计</h4>
<p>最简单的使用大模型的方法是 ChatGPT
聊天界面提问代码相关问题，这种情况下，程序员需要描述环境，比如功能，编程语言，函数的输入输出，风格……
而返回也往往是包含描述和代码，一般需要人看完整段回答，然后选取部分代码，再与自己代码组合。而且在两个界面之间切来切去很打断思路。</p>
<p>而上述的几种工具都使用了基于场景的设计，把工具融入编码的工作流，自动识别上下文，直接修改代码，节省了很多脑力，和
Chat 差别非常大。</p>
<h4 id="清晰的注释">5.2.2 清晰的注释</h4>
<p>目前辅助工具更擅长写小模块，模板，常用功能；而对于业务理解，整体设计相对较差。从原理看，模型是用代码训练出来的，训练用的源码也有不同水平，难免不对，尤其对其未见过的复杂业务逻辑。</p>
<p>因此，整个开发过程需要人与工具不断沟通，比如：一开始它给我写的代码非常简单，后来我修改了几次注释提示，想要的内容就全都有了，自己再整理一下，或者让它整理一下，就很完美了。</p>
<p>另外，程序员可以先梳理业务逻辑，将其拆分成子任务，然后再用辅助工具其现子任务的具体功能。</p>
<h3 id="使用效果">5.3 使用效果</h3>
<p>《Google Research 2022年度盘点》发布：谷歌在内部为开发者提供 5
亿参数的语言模型 ML-Enhanced 用于 为 IDE
集成代码补齐功能，通过内部1W+员工的实验对比显示，该功能减少了6%的开发时间，3%
的新代码(以字符为单位)是通过接受机器学习生成的。由此可见，AI
的代码补全功能并不像我们想象中那么有效。至少目前离完全自动化还很远。</p>
<p>当然，这也与开发应用的类型有关。我个人感觉，对于前后端，数据分析，数据等常用工具而言，提升20%-30%的工作效率应该没问题，甚至有时候觉得，有些普通的功能，选择一下，等着按Tab就行了。对于不熟悉的领域，机器生成的常常比人写的好。</p>
<h3 id="如何选择工具">5.4 如何选择工具</h3>
<p>下图是计算机科学家 Matthias Plappert
在他的推文中对主流大模型代码效果的评测：<br />
<img src="/attachments_2023/Pasted%20image%2020230811150531.png"
alt="|400" /><br />
这样看来 openai-gpt4 还是首选，但比较贵，性价比最高的应属
openai-text-davinci-003；Openai 的 GPT 系列仍独占鳌头。</p>
<p>对于如何选择辅助工具，也列出了一些建议，仅供大家参考：<br />
*
如果有比较高的定制需求，或者大批量修改，可以自己做一些提示和后处理，调用
chatgpt-3.5/4 的api，直接优化代码。<br />
* 如果以编程为生，需要深度使用，自己又能“科学”的，推荐使用
Copilot。<br />
* 对于单位使用或者科研人员，建议先用 CodeGeeX 试试水，或者考虑购买
Copilot 商业版。<br />
* 如果使用
VSCode，建议使用可嵌入的工具，不用切来切去，不打断思路；如果没有非常依赖的
IDE 建议先试用 Cursor。</p>
<h2 id="用后感">6 用后感</h2>
<p>今天，启docker镜像时把tag弄错了，导致 copilot
没能正常运行。活儿又有点急，没来得及找原因，就切着用 ChatGPT
实现查相应的功能，这一整天就跟单腿蹦似的；晚上修好了，感觉松了一口气。<br />
有时候开着它，给你推荐得不对还打断思路，但是用习惯了，没它还真别扭。<br />
这一旦开始依赖……真是可怕。</p>
<h2 id="参考文献">7 参考文献</h2>
<p><a
href="https://www.bilibili.com/video/av616461964/?vd_source=eef058f284e51ad4598d556801a9fc84">【CodeGeeX2】很强的国产免费AI代码补全工具，基本使用教程</a><br />
<a
href="http://lihuaxi.xjx100.cn/news/1278193.html?action=onClick">VsCode
安装Copilot</a><br />
<a
href="https://zhuanlan.zhihu.com/p/615214243?utm_id=0">2023年AI编程工具总结</a><br />
<a
href="https://baijiahao.baidu.com/s?id=1768027730905599188&amp;wfr=spider&amp;for=pc">大模型代码生成排行榜出炉，70亿LLaMA拉跨，被2.5亿Codex吊打</a><br />
<a
href="https://baijiahao.baidu.com/s?id=1765386086960995037&amp;wfr=spider&amp;for=pc">当前业界最优秀的8个编程大模型简介</a><br />
<a
href="https://ai.googleblog.com/2022/07/ml-enhanced-code-completion-improves.html">ML-Enhanced
Code Completion Improves Developer Productivity</a></p>
]]></content>
  </entry>
  <entry>
    <title>DockerBuild</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/Docker/DockerBuild/</url>
    <content><![CDATA[<h1 id="docker-build">Docker Build</h1>
<p>#Docker #工具</p>
<h2 id="说明">1. 说明</h2>
<p> 之前介绍过用commit的方式生成新的Docker
Image，今天介绍用Build方式做image，Build方式需要写一个配置文件，然后利用当前是已存在的image，按照配置文件进行调整生成新的image。</p>
<p> 相对来说，commit方法更随意，我们用它将现场保存为image，而build
image生成的image更“干净”。</p>
<h2 id="基本操作">2. 基本操作</h2>
<p><strong>(1) 看当前环境</strong></p>
<pre><code>$ docker images  </code></pre>
<p> 看一下当前的image，确定新的image是基于哪个image，记下它的大版本号(REPOSITORY)和小版本号(TAG)。</p>
<p><strong>(2) 写配置文件Dockerfile</strong></p>
<pre><code>$ vi Dockerfile  </code></pre>
<p> 写入以下内容，我这里是安装了一个新python包pyecharts</p>
<pre><code>FROM 基础大版本号:基础小版本号  
RUN [&quot;pip&quot;, &quot;install&quot;, &quot;pyecharts&quot;]  </code></pre>
<p><strong>(3) BUILD新的Docker image</strong></p>
<pre><code>$ docker build -t 新的大版本号: 新的小版本号 .  </code></pre>
<p>此时docker会从当前目录”.”中读取Dockerfile，并按其设置建立新的image</p>
<p><strong>(4) 查看是否BUILD成功</strong></p>
<pre><code>$ docker images  </code></pre>
<h2 id="dockerfile常用命令">3. Dockerfile常用命令</h2>
<ol type="1">
<li>FROM: 制作image时依据的基本image<br />
</li>
<li>RUN：制作image时执行的命令，一般在Dockerfile中多次出现<br />
</li>
<li>CMD：启动docker时执行的命令，在Dockerfile中只出现一次<br />
</li>
<li>ENV：设置环境变量<br />
</li>
<li>COPY：制作image时，将文件系统中的文件复制到Docker镜像中<br />
</li>
<li>WORKDIR：设置工作目录<br />
</li>
<li>EXPOSE：设置向外暴露的端口<br />
</li>
<li>VOLUME：设置容器与外界映射的目录</li>
</ol>
<h2 id="参考">4. 参考</h2>
<p><strong>(1) Docker入门02——Dockerfile详解</strong><br />
http://www.cnblogs.com/sorex/p/6481407.html</p>
<p>看/sbin/init由谁提供：</p>
<p>dpkg -L systemd-sysv | grep /sbin/init<br />
此外，“初始化”仅仅是systemd一个符号链接：</p>
<p>$ ls -lthd /sbin/init<br />
lrwxrwxrwx 1 root root 20 May 12 05:39 /sbin/init -&gt;
/lib/systemd/systemd</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker进阶</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/Docker/Docker%E8%BF%9B%E9%98%B6/</url>
    <content><![CDATA[<h1 id="docker进阶">Docker进阶</h1>
<p>#Docker #工具</p>
<h2 id="说明">说明</h2>
<p> 之前，基本是在单机上用Docker，在不影响当前环境的前提下，创建和使用一些特殊环境。最近，涉及到多Docker的协作，比如：在同一服务器上启动和管理多个容器；在一台服务器上使用类似的镜像版本，在不同的机器之间复制镜像等等，积累了一些docker使用方法，和大家分享一下。</p>
<p>##环境搭建<br />
 要想了解整个流程，还是在自己机器上搭建环境，从头到尾过一遍，最为直接。</p>
<pre><code>$ sudo apt-get install docker.io  </code></pre>
<p> 安装好之后，就可以使用docker命令了。此时还只能用root身份，如果想让某个用户操作docker，则需要将其加入docker组。</p>
<pre><code>$ sudo usermod -aG docker $your-user # 将新成员加入docker组  
$ sudo service docker restart # 重启docker服务  
$ newgrp - docker # 刷新docker成员  
从官网拉下ubuntu镜像  
$ docker run -it ubuntu bash # 如果本地不存在ubuntu镜像，则会从官网下载(pull)该镜像，进入该镜像，并以交互方式运行bash（后面介绍run的具体参数）  </code></pre>
<p> 此时就进入了docker所启动系统命令行（后简称被DOCKER启动的系统为虚拟系统,运行DOCKER的计算机为本地系统，注意它和virtual
box虚拟机不同），它是一个只是几十兆的小系统，此时可以用apt-get安装一些软件，来构造你的环境。</p>
<h2 id="docker的cs模式">Docker的CS模式</h2>
<p> 从上面的service docker
restart可以看出，Docker是Client/Server方式的，Ｃ/S之间通过socker通讯。Service端启在后台，client端用docker命令与server通讯。</p>
<h4 id="显示-docker-系统信息">(1) 显示 Docker 系统信息</h4>
<pre><code>$ docker info  </code></pre>
<h2 id="容器相关操作">容器相关操作</h2>
<p> 我们先把Docker看成虚拟机，容器就是虚拟机的运行实例。</p>
<h4 id="创建和启动容器">(1) 创建和启动容器</h4>
<p> 上面简单介绍了用run启动容器，下面来看看run的具体参数和使用方法</p>
<pre><code>$ docker run [OPTIONS] IMAGE [COMMAND] [ARG...]  
常用参数如下：  
-d: 后台运行容器，并返回容器ID  
-i: 以交互模式运行容器，通常与 -t 同时使用  
-t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用  
-p: 将容器端口映射到主机端口（-p 8890:8888，是把容器的8888端口映射到主机8890端口）  
-v: 将主机目录映射到容器中（-v 主机目录:容器中目录，-v参数可以有多个）  
--ip：指定ip地址  
--rm：在停止运行（stop）后删除容器，这样关闭后就不再需要用docker rm删除容器了。  
IMAGE 镜像的名字  
COMMAND：需要启动的命令  </code></pre>
<h4 id="查看当前运行的容器">(2) 查看当前运行的容器</h4>
<p> 可以通过以下命令，查看正在运行的容器。</p>
<pre><code>$ docker ps  </code></pre>
<p> 此时，能看到正运行容器的一些信息，注意其中的CONTAINER
ID，之后我们会通过这个ID号操作指定的容器。<br />
 在搭建环境的最后一步，我们用docker
run启动了一个容器，此时再开一个终端，用docker
ps命令，就可以看到这个容器的存在。用exit退出后，再用docker
ps，则看不到该容器了。</p>
<h4 id="在已运行的容器中执行命令">(3) 在已运行的容器中执行命令</h4>
<p> 我们常使用-d参数后台启动容器，用exec可与正在运行的容器交互。</p>
<pre><code>$ docker exec -it CONTAINER_ID /bin/bash  </code></pre>
<p> 该命令可进入正在运行的docker，常用它进入docker安装一些软件。</p>
<h4 id="在虚拟系统与本地系统之间复制文件">(4)
在虚拟系统与本地系统之间复制文件</h4>
<pre><code>$ sudo docker cp HOST_PATH CONTAINER_ID:CONTAINER_PATH  </code></pre>
<p>本地复制到容器</p>
<pre><code>$ sudo docker cp CONTAINER_ID:CONTAINER_PATH HOST_PATH  </code></pre>
<p>容器复制到本地</p>
<h4 id="查看某一容器的log">(5) 查看某一容器的log</h4>
<pre><code>$ docker logs CONTAINER_ID  </code></pre>
<p> 查看docker中的log信息，比如我们用docker在后台启一个jupyter，后来忘了token导致无法登录，就可以从log中找到。</p>
<h4 id="停止运行中的容器">(6) 停止运行中的容器</h4>
<pre><code>$docker stop CONTAINER_ID  </code></pre>
<h4 id="删除容器">(7) 删除容器</h4>
<pre><code>$docker rm -f CONTAINER_ID  </code></pre>
<p> 删除之后，容器中的操作将不再保存。<br />
 run包含建立（create）容器和启动（start）容器两步。对应的关闭时，也会为stop关闭和rm删除两步。如果run运行时不使用-rm参数，则停止运行后该容器不会被删除。需要用rm命令手动删除。</p>
<h2 id="镜像image相关操作">镜像Image相关操作</h2>
<p> 镜像一般指的是只读的数据包。容器是动态的，镜像是静态的，容器退出后该镜像依然存在，请注意，在容器中对虚拟系统的所做的修改并不会自动被保存在镜像之中。比如说，我下了Ｎ个软件，退出后，下次再run该镜像时，这些包就不存在了。<br />
 为什么不能像使用virtual
box或者vmware虚拟机那样，一边运行一边保存呢？我觉得，是因为很多时候，在同一机器上可能基于同一个image启动多个container，如果即时保存，image里面倒底该保存哪个container呢？</p>
<h4 id="查看镜像">(1) 查看镜像</h4>
<p> 可以通过以下命令，查看当前可用的image。</p>
<pre><code>$ docker images  </code></pre>
<p> 注意IMAGE ID如果想要操作特定镜像，则需要使用该ID。</p>
<h4 id="以创建方式制作镜像">(2) 以创建方式制作镜像</h4>
<p> 有时候我们需要保存安装的包和一些数据，以备下次使用。有两种方法：一种是用build方式创建新的镜像，一种是用commit在原有镜像的基础上修改后，保存成新的镜像。</p>
<pre><code>$ docker build -t REPOSITORY:TAG  </code></pre>
<p> 用当前目录的Dockerfile创建镜像，Dockerfile文件可以指定基础镜像，安装包，环境变量等等。</p>
<h4 id="以修改方式制作镜像">(3) 以修改方式制作镜像</h4>
<p> 在一个容器中修改之后，可以通过commit把修改保存到镜像上。</p>
<pre><code>$ docker commit CONTAINER_ID REPOSITORY:TAG  </code></pre>
<p> 此时，用docker
images，就可以看到新的镜像了。新镜像只保存其基础版本的增补，并不会占太大空间，下次启动时，只需要指定REPOSITORY:TAG即可。<br />
 还可通过TAG命令修改其版本号</p>
<pre><code>$ docker tag 旧版本号 新版本号  </code></pre>
<p> 相对来说，build方法更加规范，能做出比较“干净”的镜像，我们知道这个镜像与基础版本有何不同，而commit相对比较随意，常用它来保存自己的工作现场。</p>
<h4 id="删除镜像">(4) 删除镜像</h4>
<p> 先停掉（stop）启动的容器，然后运行rmi命令：</p>
<pre><code>$ docker rmi IMAGE_ID  </code></pre>
<h4 id="把一个机器上的镜像复制到另一台机器上">(5)
把一个机器上的镜像复制到另一台机器上</h4>
<p> 在要导出的机器A上，执行</p>
<pre><code>$ docker save -o 文件名 IMAGE的TAG  </code></pre>
<p> 在要导入的机器B上，执行</p>
<pre><code>$ docker load -i 文件名  </code></pre>
<h2 id="layer层">Layer层</h2>
<p> 做到这一步，有点好奇，docker内部到底是如何管理基础版本和其上复杂分支的呢？先来看看元数据。<br />
 用以下命令，可获取容器或者镜像的元数据</p>
<pre><code>$ docker inspect CONTAINER_ID/IMAGE_ID  </code></pre>
<p> 此时，可以看到当前的信息，比如IMAGE_ID的ID及其Parent，从而可确定其继承关系。在Docker内部，只保存各个版本之间的差异。<br />
 Layer是Docker用来管理镜像层的中间概念，因为单个镜像层可能被多个镜像使用，所以docker把layer和image的概念分开，layer存放了镜像层的diff_id，size，parent_id等内容。在同一个Docker版本管理系统中，只要Layer一致，就只保存一份。<br />
 默认情况下，镜像的存储路径为/var/lib/docker/aufs/，其中的layers文件夹存储的就是layer信息。<br />
 在机器Ａ上，镜像的存储是增量的，如果用save/load方式复制到另一台机器B上，镜像会不会很大？答案是不会。镜像的存储是按Layers层层堆叠的，同一layer只存储一次，所以在向一台机器导入image时，会对比和保存新镜像和现存layer不同的部分。只是在复制过程中比较占空间。</p>
<h2 id="参考">参考</h2>
<h4 id="docker-命令大全">(1) Docker 命令大全</h4>
<p>http://www.runoob.com/docker/docker-command-manual.html</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>nvidia-docker无法正常启动</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/Docker/Docker%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</url>
    <content><![CDATA[<h1 id="nvidia-docker无法正常启动">nvidia-docker无法正常启动</h1>
<p>#深度学习 #Docker</p>
<p>上周更新了nv的驱动到450，然后发现nvidia-docker无法启动了，报错：</p>
<pre><code>docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused &quot;process_linux.go:449: container init caused \&quot;process_linux.go:432: running prestart hook 1 caused \\\&quot;error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: initialization error: driver error: failed to process request\\\\n\\\&quot;\&quot;&quot;: unknown.  </code></pre>
<p>使用命令：</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>$ nvidia<span class="op">-</span>container<span class="op">-</span>cli <span class="op">-</span>k <span class="op">-</span>d <span class="op">/</span>dev<span class="op">/</span>tty info  </span></code></pre></div>
<p>又出现报错：</p>
<pre><code>    -- WARNING, the following logs are for debugging purposes only --  
      
    I1001 02:01:39.488895 21811 nvc.c:281] initializing library context (version=1.0.7, build=b71f87c04b8eca8a16bf60995506c35c937347d9)  
    I1001 02:01:39.488944 21811 nvc.c:255] using root /  
    I1001 02:01:39.488952 21811 nvc.c:256] using ldcache /etc/ld.so.cache  
    I1001 02:01:39.488959 21811 nvc.c:257] using unprivileged user 1000:1000  
    W1001 02:01:39.490269 21812 nvc.c:186] failed to set inheritable capabilities  
    W1001 02:01:39.490334 21812 nvc.c:187] skipping kernel modules load due to failure  
    I1001 02:01:39.490648 21813 driver.c:133] starting driver service  
    E1001 02:01:39.490932 21813 driver.c:197] could not start driver service: load library failed: libcuda.so.1: cannot open shared object file: no such file or directory  
    I1001 02:01:39.491071 21811 driver.c:233] driver service terminated successfully  
    nvidia-container-cli: initialization error: driver error: failed to process request  </code></pre>
<p>于是升级了对应版本的cuda1</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>$ apt install libcuda1<span class="op">-</span><span class="dv">450</span>  </span></code></pre></div>
<p>之后恢复正常</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker集群</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/Docker/Docker%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<h1 id="docker集群">Docker集群</h1>
<p>#Docker #工具</p>
<h2 id="说明">1. 说明</h2>
<p> 一般情况下，我们用Docker
run命令将docker启成普通进程。有时候我们有多台运行docker的机器，希望Docker以集群方式运行。与手动启动不同Docker，集群涉及统一管理，各服务的状态监控，负载均衡，日志文件，重启，统一向外暴露端口等等。</p>
<p> 本篇介绍一些Docker集群相关的内容：包括集群管理工具Smarm，卷Volume，图形化管理工具Portainer。</p>
<h2 id="安装docker的最新版本">2. 安装Docker的最新版本</h2>
<p> 如果ubuntu版本较低，用apt-get只能安装docker的早期版本，像docker
service, docker
volume等工具都无法正常使用，需要下载docker较新的版本，方法如下：</p>
<pre><code>$ curl -fsSLO https://get.daocloud.io/docker/builds/Linux/x86_64/docker-17.05.0-ce.tgz  
$ sudo tar --strip-components=1 -xvzf docker-17.05.0-ce.tgz -C /usr/local/bin  #解压到bin目录  
$ sudo dockerd    </code></pre>
<p> 执行dockerd启动docker后台服务，就无需再使用系统方式启动（service
docker
start），用docker命令即可与后台服务交互了。该方法也比较适用于在嵌入式系统中安装docker。</p>
<h2 id="docker-portainer">3. Docker Portainer</h2>
<p> Portainer是Docker的可视化管理工具，用它可以查看和管理docker的映像，容器，卷，后台服务等等。</p>
<p> Docker的辅助工具，一般也是以Docker
image的方式提供，安装它们不需要用apt-get或者下载tgz包，只需要用docker
pull把镜像下载到本地即可使用。安装Portainer方法如下：</p>
<pre><code>$ docker search portainer  # 查看portainer相关的工具  
$ docker pull docker.io/portainer/portainer  #下载portainer镜像  
$ docker images  # 查看是否正常下载到本地  
$ docker run -d -p 9000:9000 \  
    --restart=always \  
    -v /var/run/docker.sock:/var/run/docker.sock \  
    --name prtainer-test \  
docker.io/portainer/portainer   # 运行portainer  </code></pre>
<p> 此时用浏览器访问http://127.0.0.1:9000，即可看到portainer界面，首次访问时需要设置密码(如：admin,
12345678)，登入后即可看到docker的各种状态。</p>
<h2 id="docker-volume">4. Docker Volume</h2>
<p> 上篇提到过，镜像是静态的，当容器关闭之后，对其中内容的修改不能保存，虽然可以用commit从容器生成镜像，但很麻烦，所以在手动运行容器时用-v参数，将容器外目录映射到容器内，以方便保存。</p>
<p> 在集群中以服务的方式启动docker时，不使用直接指定路径的映射方式，而使用volume，简单地说，就是把容器外目录映射成一个volume，再将该volume挂载成容器内目录，这样多个容器可使用同一volume。</p>
<p> 具体方法如下：</p>
<pre><code>$ docker volume create --name 名  # 创建volume, 默认位置在/var/lib/docker/volumes/名/_data  
$ docker volume ls  # 查看当前所有volume，也可使用portainer中的volume查看  
$ docker volume inspect VOLUME_NAME  # 查看volume的具体内容  
$ docker rm -v VOLUME_NAME  # 删除 volume  </code></pre>
<h2 id="docker-swarm">5. Docker Swarm</h2>
<p> Swarm是Docker官方提供的一款集群管理工具，其主要作用是把若干台Docker主机抽象为一个整体，并且通过一个入口统一管理这些Docker主机上的各种Docker资源。</p>
<p> Swarm自己不运行容器，它只是接受docker客户端发送过来的请求，调度适合的节点来运行容器，这意味着，即使Swarm由于某些原因挂掉了，集群中的节点也会照常运行，当Swarm重新恢复运行之后，它会收集重建集群信息。</p>
<p> 具体方法如下：</p>
<pre><code>$ docker pull swarm  # 下载swarm镜像  
$ docker run swarm create  
此时会显示集群号，要记住这个号，各台机器加入集群时，都需要指定这个号  
$ docker run swarm list token://集群号  # 查看集群中的所有节点  </code></pre>
<p> 在各个docker机器用以下方式加入集群</p>
<pre><code>$ docker run -d swarm join --addr=192.168.1.207:2375 token://集群号  </code></pre>
<p> 在管理节点上运行以下命令</p>
<pre><code>$ docker rn -d -p 2376:2375 swarm manage token:  </code></pre>
<p> 此时用docker ps就可以看到此管理容器了</p>
<h2 id="docker-stack">6. Docker Stack</h2>
<p> 一个stack就是一组有关联的服务的组合，可以编排在一起管理。具体方法是将各个服务的内容填写在一个yml文件中。docker
build时指定的CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在yml
中再次设置。</p>
<p> yml文件写法如下：</p>
<pre><code>version: &quot;3.0&quot;  
services:  
  example: # 服务名  
    image: xieyan:0.4  # 镜像名  
    command: sleep 5000  # 执行的程序  
    volumes:   
      - haha:/root/model_data  # 挂载的volume及容器中的对应目录  
    deploy:  
      mode: replicated  
      replicas: 1  
      placement:  
        constraints: [node.hostname!=node1]  # 限制不在nod1结点执行  
      resources:  
        limits:  
          cpus: &#39;2&#39;  # 限制CPU个数  
          memory: 2048M  # 限制内存大小  
  
volumes:  
  haha:  
external: true  </code></pre>
<p> 开启和关系stack方法如期下：</p>
<pre><code>$ docker stack deploy --compose-file tmp.yml testme # 开启stack, testme是stack名  
$ docker stack rm testme  #　关  </code></pre>
<p> 此时在portainer的stack/service中可以看到testme_example<br />
 如果启动服务出问题，可能会不停的重启，可用以下命令查看出错的具体原因。</p>
<pre><code>$ docker service logs testme_example  </code></pre>
<h2 id="参考">7. 参考</h2>
<p>Portainer -- Docker可视化管理工具的安装配置及使用<br />
https://blog.csdn.net/A632189007/article/details/78779920</p>
<p>Docker管理工具-Swarm部署记录<br />
https://www.cnblogs.com/liuyansheng/p/8178341.html</p>
<p>深入理解Docker(镜像、容器、服务、swarm、stack)<br />
https://blog.csdn.net/oChangWen/article/details/75758211</p>
<p>Docker存储volume<br />
https://www.cnblogs.com/elvi/p/8463673.html</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>搭建TensorFlow的GPUDocker环境</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/Docker/%E6%90%AD%E5%BB%BATensorFlow%E7%9A%84GPUDocker%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h1 id="搭建tensorflow的gpu-docker环境">搭建TensorFlow的GPU
Docker环境</h1>
<p>#深度学习 #Docker</p>
<p><strong>推荐的基础镜像列表</strong></p>
<p><a
href="https://tianchi.aliyun.com/forum/postDetail?postId=67720">https://tianchi.aliyun.com/forum/postDetail?postId=67720</a></p>
<p><strong>TensorFlow的GPU镜像</strong></p>
<pre><code>$ docker pull registry.cn-shanghai.aliyuncs.com/tcc-public/tensorflow:latest-cuda10.0-py3  
$ nvidia-docker run --shm-size 8G --rm -v /exports:/exports -it registry.cn-shanghai.aliyuncs.com/tcc-public/tensorflow:latest-cuda10.0-py3 bash  </code></pre>
<p><strong>在镜像中安装其它软件</strong></p>
<p>（最好先更新软件源/root/.pip/pip.conf,
/etc/apt/sources.list，以便更快下载）<br />
进入docker内部</p>
<pre><code>$ pip install pandas sklearn lightgbm catboost  </code></pre>
<p><strong>说明</strong></p>
<p>如需使用GPU的镜像，需要在宿主机安装nvidia-docker及CUDA相关工具，具体方法请见：<br />
《搭建深度学习的docker环境》https://www.jianshu.com/p/cc9e617d79c2</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>IE6和Firefox同时支持PNG透明图片的方法</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E5%85%B6%E5%AE%83/IE6%E5%92%8CFirefox%E5%90%8C%E6%97%B6%E6%94%AF%E6%8C%81PNG%E9%80%8F%E6%98%8E%E5%9B%BE%E7%89%87%E7%9A%84%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1
id="ie6和firefox同时支持png透明图片的方法">IE6和Firefox同时支持PNG透明图片的方法</h1>
<p>#网站</p>
<p>1. 原理</p>
<p>IE6默认不支持PNG图片的半透明效果,
但由于它是XP系统默认的浏览器,目前仍被广泛的使用.
解决此问题的方法是在Html中加入Javascript,<br />
其中判断当浏览器是低版本IE时对Html中的PNG做相应处理.</p>
<p>2. 代码</p>
<p>只需在Html开头加入以下Javascript脚本即可</p>
<p>&lt;scriptlanguage="JavaScript"&gt;</p>
<p>function correctPNG() // correctly handlePNG transparency in Win IE
5.5 &amp; 6.</p>
<p>{</p>
<p>var arVersion =navigator.appVersion.split("MSIE")</p>
<p>var version = parseFloat(arVersion[1])</p>
<p>if ((version &gt;= 5.5) &amp;&amp;(document.body.filters))</p>
<p>{</p>
<p>for(var i=0; i&lt;document.images.length;i++)</p>
<p>{</p>
<p>var img = document.images[i]</p>
<p>var imgName = img.src.toUpperCase()</p>
<p>if (imgName.substring(imgName.length-3,imgName.length) == "PNG")</p>
<p>{</p>
<p>var imgID = (img.id) ? "id='" +img.id + "' " : ""</p>
<p>var imgClass = (img.className) ?"class='" + img.className + "' " :
""</p>
<p>var imgTitle = (img.title) ?"title='" + img.title + "' " : "title='"
+img.alt<br />
+ "' "</p>
<p>var imgStyle ="display:inline-block;" + img.style.cssText</p>
<p>if (img.align == "left") imgStyle= "float:left;" + imgStyle</p>
<p>if (img.align == "right")imgStyle = "float:right;" + imgStyle</p>
<p>if (img.parentElement.href) imgStyle ="cursor:hand;" + imgStyle</p>
<p>var strNewHTML = "&lt;span " +imgID + imgClass + imgTitle</p>
<p>+ " style="" +"width:" + img.width + "px; height:" + img.height
+"px;" +<br />
imgStyle + ";"</p>
<p>+ "filter:progid:DXImageTransform.Microsoft.AlphaImageLoader"</p>
<p>+ "(src='" + img.src + "',sizingMethod='scale');"&gt;</span>"</p>
<p>img.outerHTML = strNewHTML</p>
<p>i = i-1</p>
<p>}</p>
<p>}</p>
<p>}</p>
<p>}</p>
<p>window.attachEvent("onload",correctPNG);</p>
</script>
<p>3. 示例<br />
具体效果见网页</p>
<p><a
href="http://oatmental123.sinaapp.com/slim/">http://oatmental123.sinaapp.com/slim/<br />
</a></p>
<p>通过在Firefox浏览器中点右键, 查看网页源代码, 可参考其具体代码.</p>
]]></content>
      <tags>
        <tag>网站</tag>
      </tags>
  </entry>
  <entry>
    <title>MSN博客搬家工具</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E5%85%B6%E5%AE%83/MSN%E5%8D%9A%E5%AE%A2%E6%90%AC%E5%AE%B6%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<h1 id="msn博客搬家工具">MSN博客搬家工具</h1>
<p>#工具 #Java</p>
<p>1. 说明<br />
最近 MSN 的博客即将关闭，而使用 MSN 上推荐的迁移到 workpress
，又总是不成功。在网上下了几个工具，都是各个 blog<br />
开发的，只能搬到特定的 blog 中去。让人十分郁闷。<br />
后来试写了一段代码，先把从 MSN 博客备份到本地，挑了些技术文档搬到了
CSDN<br />
，下面是程序的实现和说明，大家举一反三吧。用此方法也可以搬到其它的 blog
。<br />
编译好的程序可以下载，源码可以下载，大家可以直接使用或者修改加以完善。</p>
<p>2. 原理<br />
使用 XML-RPC 协议，一个 XML-RPC 消息就是一个请求体为 xml 的
http-post<br />
请求，被调用的方法在服务器端执行并将执行结果以 xml
格式编码后返回，可以通过此协议，读写 blog 上的文章，如 CSDN ，<br />
WORDPRESS ，新浪等都支持，利用它可以方便地开发 blog 的客户端。</p>
<p>3. 程序说明</p>
<ol type="1">
<li>MSN 网页解析<br />
</li>
</ol>
<pre><code>** public class Fetcher &#123;    
private String getPage(String file) &#123;  //  ** ** 读取日志文件  ** **    
BufferedReader reader = null;    
StringBuilder sb = new StringBuilder();    
** ** String line = null;    
try &#123;    
reader = new BufferedReader(new InputStreamReader(    
new FileInputStream((file)), Charset.forName(&quot;utf-8&quot;)));    
while ((line = reader.readLine()) != null) &#123;    
sb.append(line);    
&#125;    
reader.close();    
&#125; catch (MalformedURLException e) &#123;    
System.out.println(&quot;file:&quot; + file);    
System.out.println(&quot;error:&quot; + e);    
&#125; catch (IOException e) &#123;    
System.out.println(&quot;file:&quot; + file);    
System.out.println(&quot;error:&quot; + e);    
&#125;    
return sb.toString();    
&#125;    
    
//  ** ** 解析日志文件：标题，日期，正文  ** **    
public void getDoc(String file, String server, String user, String passwd) &#123;    
String html = getPage(file);    
String titleDivRegex = &quot; &lt;title&gt;.+?&lt;/title&gt;&quot;;    
Pattern titleDivPattern = Pattern.compile(titleDivRegex);    
Matcher titleDivMatcher = titleDivPattern.matcher(html);    
String title = null;    
if (titleDivMatcher.find()) &#123;  //  ** ** 标题  ** **    
title = titleDivMatcher.group().replaceAll(&quot; &lt;title&gt;&quot;, &quot;&quot;)    
.replaceAll(&quot;&lt;/title&gt;&quot;, &quot;&quot;);    
&#125;    
String dateDivRegex = &quot;&lt;h5 id=/&quot;.+?/&quot;&gt;.+?&lt;/h5&gt;&quot;;    
Pattern dateDivPattern = Pattern.compile(dateDivRegex);    
Matcher dateMatcher = dateDivPattern.matcher(html);    
String dateStr = null;    
Date postDate = null;    
if (dateMatcher.find()) &#123;  //  ** ** 日期  ** **    
dateStr = dateMatcher.group().replaceAll(&quot; &lt;h5 id=/&quot;.+?/&quot;&gt;&quot;, &quot;&quot;)    
.replaceAll(&quot;&lt;/h5&gt;&quot;, &quot;&quot;).trim();    
String tmp = dateStr.replace(&quot;&amp;#58;&quot;, &quot;:&quot;);    
postDate = new Date(tmp);    
&#125;    
String textDivRegex = &quot;&lt;div id=/&quot;.*/&quot; class=/&quot;blogpost/&quot;&gt;.+?&lt;/div&gt;&quot;;    
Pattern textDivPattern = Pattern.compile(textDivRegex);    
Matcher textMatcher = textDivPattern.matcher(html);    
String text = null;    
if (textMatcher.find()) &#123;  //  ** ** 正文  ** **    
text = textMatcher.group().replaceAll(    
&quot; &lt;div id=/&quot;.*/&quot; class=/&quot;blogpost/&quot;&gt;&quot;, &quot;&quot;).replaceAll(    
&quot;&lt;/div&gt;&quot;, &quot;&quot;).trim();    
&#125;    
String[] categories = &#123; &quot;android&quot;, &quot;linux&quot; &#125;;    
text = &quot;&lt;html&gt;&lt;meta http-equiv=/&quot;Content-Type/&quot; content=/&quot;text/html;  
charset=utf-8/&quot;&gt;&quot;    
\+ text + &quot;&lt;/html&gt;&quot;;    
    
Post post = new Post(title, text, categories, postDate);    
post.setServer(server, user, passwd);    
post.publish();    
    
System.out.println(&quot;title:&quot; + title);    
System.out.println(&quot;date&quot; + postDate);    
&#125;    
** ** &#125;  **  
  
2)  上转到其它博客    
** public class Post &#123;    
private Date dateCreated;    
private String description;    
private String title;    
private String[] categories;    
private String mServer;    
private String mUser;    
** ** private String mPasswd;    
static private XmlRpcClientConfigImpl config;    
static private XmlRpcClient client;    
    
public Post(String title, String description, String[] categories,    
Date dateCreated) &#123;    
this.dateCreated = dateCreated;    
this.description = description;    
this.title = title;    
this.categories = categories;    
&#125;    
    
static &#123;    
config = new XmlRpcClientConfigImpl();    
client = new XmlRpcClient();    
&#125;    
    
private void writelog(String log) &#123;    
UI.getInstance().showLog(log);    
&#125;    
    
public void setServer(String server, String user, String passwd) &#123;    
mServer = server;    
mUser = user;    
mPasswd = passwd;    
try &#123;    
config.setServerURL(new URL(mServer));    
client.setConfig(config);    
&#125; catch (MalformedURLException e) &#123;    
System.out.println(&quot;connect error&quot;);    
&#125;    
&#125;    
    
public void publish() &#123;    
Map &lt;String, Object&gt; struct = new HashMap&lt;String, Object&gt;();    
struct.put(&quot;dateCreated&quot;, dateCreated);    
struct.put(&quot;description&quot;, description);    
struct.put(&quot;title&quot;, title);    
struct.put(&quot;categories&quot;, categories);    
Object[] params = new Object[] &#123; mUser, mUser, mPasswd, struct, true &#125;;    
String blogid = null;    
try &#123;  //  ** ** 发布日志  ** **    
blogid = (String) client.execute(&quot;metaWeblog.newPost&quot;, params);    
writelog(&quot;OK:  title=&quot; + title + &quot; id=&quot; + blogid + &quot;/n&quot;);    
&#125; catch (XmlRpcException e) &#123;    
writelog(&quot;ERR: title=&quot; + title + &quot;/n&quot;);    
&#125;    
struct.clear();    
&#125;    
&#125;  </code></pre>
<p>4. 使用方法</p>
<ol type="1">
<li>下载代码</li>
</ol>
<ol type="a">
<li><p>从此处下载<br />
http://download.csdn.net/source/2773467<br />
（注意：本程序只测试过迁移到 CSDN ，迁移到其它 Blog
可能需要修改代码）</p></li>
<li><p>将下载的软件包解压缩</p></li>
</ol>
<ol start="2" type="1">
<li>运行程序</li>
</ol>
<ol type="a">
<li>改 msn blog 日期格式以便于程序识别</li>
</ol>
<ol type="i">
<li><p>打开 msn blog ，并登录</p></li>
<li><p>选项 - &gt; 常规<br />
将日期设置为 yyyy/mm/dd 格式<br />
将时间设置为 hh:mm:ss 格式</p></li>
</ol>
<ol start="2" type="a">
<li>将 msn blog 日志保存到本地</li>
</ol>
<ol type="i">
<li><p>msn 博客登录后，在迁移页面点击 ” 将日志下载到 PC”</p></li>
<li><p>解包，依据 index 把需要迁移的日志放入目录 X</p></li>
</ol>
<ol start="3" type="a">
<li>上传到其它 blog</li>
</ol>
<ol type="i">
<li><p>在其它 blog 注册用户</p></li>
<li><p>cd blogmover</p></li>
<li><p>java -jar blogmover.jar<br />
点击 Choose 选择迁移日志所存在的目录 X<br />
在 Server,UserID, Passwd 中填写新 blog 的信息，然后点击 Send</p></li>
</ol>
<ol start="3" type="1">
<li>编译源码</li>
</ol>
<ol type="a">
<li><p>用 eclipse 打开</p></li>
<li><p>File-&gt;New-&gt;JavaProject-&gt;Create project from existing
source 打开源码</p></li>
<li><p>项目名 -&gt; 右键 -&gt;Build Path-&gt;Configure Build
Path…-&gt;Add Extennal JARs<br />
加入软件包一级目录的三个库 (wsxxx, xmlxxx, xmlxxx)</p></li>
<li><p>编译运行即可</p></li>
</ol>
<p>5. 参考</p>
<ol type="1">
<li><p>从百度空间到 CSDN—— 博客搬家源码<br />
<a
href="http://blog.csdn.net/telnetor/archive/2010/05/04/5556539.aspx">http://blog.csdn.net/telnetor/archive/2010/05/04/5556539.aspx<br />
</a></p></li>
<li><p>各个 blog 的 xml-rpc 支持 ( MetaWeblog API )<br />
<a
href="http://www.discuz.net/thread-946562-1-1.html">http://www.discuz.net/thread-946562-1-1.html<br />
</a></p></li>
</ol>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>跨平台的UML工具——Jude（astah）</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E5%85%B6%E5%AE%83/UML%E5%B7%A5%E5%85%B7_Jude%EF%BC%88astah%EF%BC%89/</url>
    <content><![CDATA[<h1 id="section"></h1>
<p>#工具</p>
<h2 id="用途">1 用途</h2>
<p>跨平台的UML工具——Jude（astah），用JAVA实现的UML工具，可导出UML图片。</p>
<h2 id="软件">2 软件</h2>
<p>Jude现更名为astah</p>
<h2 id="安装">3 安装</h2>
<p>从 <a
href="http://jude.change-%20vision.com/jude-web/index.html">http://jude.change-vision.com/jude-web/index.html</a>
，可下载相应的Windows，Mac
OS，Linux版本，新版安装包，包含Java运行环境</p>
<h2 id="参考">4 参考</h2>
<p><a
href="http://blog.csdn.net/mimepp/article/details/2058170">一个不错的免费UML工具：JUDE
community</a></p>
]]></content>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>什么是积分墙？</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E5%85%B6%E5%AE%83/%E4%BB%80%E4%B9%88%E6%98%AF%E7%A7%AF%E5%88%86%E5%A2%99%EF%BC%9F/</url>
    <content><![CDATA[<h1 id="什么是积分墙">什么是积分墙？</h1>
<p>#移动开发</p>
<p>1. 当前市场</p>
<p>开发者总得生存，没有收入用什么维持开发呢？移动平台的应用程序赢利一般靠广告收入和销售程序取得，像Android软件在中国没什么销售平台，而普通广告一般用户看到100次，也不一定会点击一次，中国市场上又不算展示量，而只靠点击量计费。<br />
其实普通开发者想要的无非是，有人用了我的软件，无论从广告商，还是从普通用户手里得到相应的报酬，这并不过分。</p>
<p>2. 为什么出现积分墙？<br />
积分墙的“墙”是指集中展示的广告，而“积分”（有的也叫虚拟货币）就是用户通过点击广告，得到一定的积分，然后在应用中消费这些积分，比如：积了Ｎ分，就可以再玩一关。而开发者也通过用户对广告的点击，从广告商那儿得到广告费。<br />
不知道为什么有的应用市场会驳回带积分墙的应用？这也没有强买强卖的性质。而正常的开发者，一般也会让用户先体验到软件好用之后，才会让用户消费积分，根本上还是在卖软件。如果还没使过不知好坏，就开始要积分，估计用户直接就给删了。</p>
<p>3. 用户体验如何（举例说明）</p>
<ol type="1">
<li><p>用户使用某个游戏前五关过了，想玩第六关的时候，跳出对话框，告知用户需要积分才能玩下一关，点击广告或者下载其它应用可获得积分</p></li>
<li><p>用户点击了下载应用按钮，跳出一个界面，界面上是应用程序列表，上面显示着下载每个应用可获得的积分</p></li>
<li><p>用户下载并使用了某个应用就获得了积分</p></li>
<li><p>用户又可以通过消费积分玩游戏的后续几关。</p></li>
<li><p>用户过关过得快，也可能奖励积分（有的软件也提供用户赢得虚拟货币）</p></li>
</ol>
<p>4. 程序中加何加入积分墙？（以Android应用为例）</p>
<ol type="1">
<li><p>与正常广告一样，也需要加入网络访问等权限，和相应的界面的声明（AndroidManifest.xml），引入相应的积分墙jar包</p></li>
<li><p>调用一般分为三个部分（积分墙只能加在程序中），无法通过只修改资源实现</p></li>
</ol>
<ol type="a">
<li><p>调出积分墙界面（供用户通过下载应用等获得积分，如下载应用得到10分）</p></li>
<li><p>获取当前积分数（用于判断用户是否可以继续使用程序）</p></li>
<li><p>消费积分（在相应情况下扣除用户积分，如用10分换再玩两关）</p></li>
</ol>
<p>5. 积分墙和一般广告有什么差别？<br />
广告就像卖艺，捧场的就点一下，不点也没办法。积分墙就像卖票，只有积分才能使用。<br />
不同的广告适合不同的应用类型。广告条会一直循环显示，在用户不点击的情况下，不能增加开发者收入，还浪费用户流量。而积分墙来得直接，如果需要继续使用，那么请积分，如果不希望以任何方式付费，也就无法使用了。而积分墙也不适合总是显示出来。</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
      </tags>
  </entry>
  <entry>
    <title>将DVD视频转成IPAD支持的格式</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E5%85%B6%E5%AE%83/%E5%B0%86DVD%E8%A7%86%E9%A2%91%E8%BD%AC%E6%88%90IPAD%E6%94%AF%E6%8C%81%E7%9A%84%E6%A0%BC%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="将dvd视频转成ipad支持的格式">将DVD视频转成IPAD支持的格式</h1>
<p>#Linux #工具</p>
<p>买了一些幼儿教育的DVD盘，小朋友用IPAD自己就可以看了，不用开电视又开DVD机的。我觉得这种需求很多人都有，但却没找到可以转换的免费软件。不是需要注册就是只能免费转五分钟。最后只好用Linux解决，主要是用mencoder软件进行转码，通过参数设置输出视频格式。一般情况下通过apt-<br />
getinstall mencoder安装软件。</p>
<p>我的操作系统是ubuntu
10.04，比较旧，正常安装的mencoder不支持faac格式，转码时提示：ubuntu
10.04 do not<br />
supportfaac，因此下载了源码自己编译，mencoder包含在软件包mplayer之中。从
<a href="http://www.mplayerhq.hu/MPlayer/releases/"><br />
http://www.mplayerhq.hu/MPlayer/releases/<br />
</a> 处下载。具体方法如下：</p>
<p>1. 安装解码器：安装一些解码器，作为mplayer的必须的插件：<br />
$ apt-get install libtheora-dev<br />
$ apt-get install libfaad-dev<br />
$ apt-get install libxvidcore-dev<br />
$ apt-get install libfaac-dev<br />
$ apt-get install libx264-dev</p>
<p>2. 配置和编译mencoder<br />
$ ./configure --enable-faac --enable-faad --enable-fontconfig
--enable-xvid--<br />
enable-x264 --enable-theora<br />
$ make<br />
$ make install<br />
编译时，如果出现找不到faac等库的提示，可以在Makefile的EXTRALIBS部分加入"-lfaac
-lxvidcore<br />
-lx264-lfontconfig"</p>
<p>3. 视频转码：</p>
<p>$ mencoderdvd://1 -o xxx.mp4 -of lavf -lavfopts format=mp4 -vf<br />
pp=lb,crop=720:480:0:0-ovc x264 -ovc x264 -x264encopts<br />
crf=30:vbv_maxrate=2500:nocabac:global_header:frameref=3:threads=auto:bframes=0:subq=6:mixed-<br />
refs=0:weightb=0:8x8dct=1:me=umh:partitions=all:qp_step=4:qcomp=0.7:trellis=1:direct_pred=auto-<br />
oac faac -faacopts br=128:mpeg=4:object=2:raw -channels 2 -srate
48000</p>
<p>此时就生成了IPAD支持的mp4格式的视频，通过Itunes同步到IPAD后即可正常播放。</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>蓝思指数</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E5%85%B6%E5%AE%83/%E8%93%9D%E6%80%9D%E6%8C%87%E6%95%B0/</url>
    <content><![CDATA[<h2 id="蓝思指数">1 蓝思指数</h2>
<p>蓝思阅读指数,所谓的Lexile(蓝思指数),是美国科学基金会(National Science
Foundation,United States 简称
NSF)为提高学生的阅读能力,而研究出的一种衡量学生阅读水平和标识书籍难易程度的一套标准。</p>
<h2 id="地址">2 地址</h2>
<p>http://lexile.com</p>
<h2 id="分级表">3 分级表</h2>
<figure>
<img src="/attachments_2022/Pasted%20image%2020221207185918.png"
alt="Pasted%20image%2020221207185918.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020221207185918.png</figcaption>
</figure>
<h2 id="查书的难度">4 查书的难度</h2>
<p>https://hub.lexile.com/find-a-book/book-results</p>
<h2 id="计算段落的难度">5 计算段落的难度</h2>
<p>Analyzer工具，可以免费测试250个单词以内的段落的蓝思值。<br />
https://hub.lexile.com/analyzer</p>
<h2 id="问题">6 问题</h2>
<p>英语是拼读语言，大部分单词符合拼读规则。蓝思指数源自美国，对于英语是母语的人，看到拼写基本会读，会读就知道大概意思。而很多单词我们能大概拼出来也不知道是什么意思。<br />
找了几篇难度在700左右的文章，看了看觉得难度差异非常大，感觉用这个直接给娃找书……仅供参考吧。</p>
]]></content>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E5%85%B6%E5%AE%83/%E9%9B%86%E6%88%90%E5%B7%A5%E5%85%B7_Jenkins/</url>
    <content><![CDATA[<p>Jenkins是一个开源软件项目，是基于Java开发的一种持续集成工具，用于软件项目的持续集成。简单地说，你可以通过Jenkins服务，把github上的更新自动安装部署到指定位置。</p>
<h2 id="安装">1 安装</h2>
<p>最简单，又不影响系统的方式，还是以docker方式安装：</p>
<pre><code>$ docker run -p 8080:8080 -p 50000:50000 -v jenkins_home:/var/jenkins_home jenkins/jenkins:lts-jdk11  </code></pre>
<p>此时 jenkins 的镜像被自动下载，并启动。</p>
<h2 id="配置">2 配置</h2>
<ul>
<li>用浏览器打开8080端口。<br />
</li>
<li>然后按界面提示从docker中的passwd文件中找到密码，并登录。<br />
</li>
<li>如果是第一次使用，选“按推荐安装插件”，等进度条运行结束。<br />
</li>
<li>按提示设置管理员用户名和密码。<br />
</li>
<li>设置完成后即可开始使用。</li>
</ul>
<h2 id="开始使用">3 开始使用</h2>
<p>不同版本的界面大同小异：<br />
* 创建任务(也叫"新建Item"或"New任务" )<br />
* 先尝试一下最常用的流水线任务(也叫"Pipeline")<br />
* 点Github项目，然后输入github项目地址，SCM选择Git，在Repository
URL中输入其git地址，如：https://github.com/xxxx/xxxx.git<br />
* 注意项目中如果包含Jenkinsfile，则选择“Pipeline script from
SCM”，如果不包含，也可以直接在界面上输入脚本<br />
* 点击保存<br />
* 在左侧点立即构建(也叫Build)</p>
<h2 id="查看问题">4 查看问题</h2>
<ul>
<li>每一次的构造信息在该Pipeline页面的左下角显示。<br />
</li>
<li>如果出现错误，则显示红叉，点击红叉打开该构造过程，点左边的Console
Output，即可看到具体问题。</li>
</ul>
<h2 id="参考">5 参考</h2>
<p><a
href="https://blog.csdn.net/sexyluna/article/details/121892823">docker版Jinkens安装教程</a></p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>沉浸式翻译</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E6%B5%8F%E8%A7%88%E5%99%A8%E5%B7%A5%E5%85%B7/%E6%B2%89%E6%B5%B8%E5%BC%8F%E7%BF%BB%E8%AF%91/</url>
    <content><![CDATA[<h2 id="介绍">1 介绍</h2>
<ul>
<li>名称：沉浸式翻译（浏览器插件）<br />
</li>
<li>地址：https://immersivetranslate.com/docs/installation/<br />
</li>
<li>优势：
<ul>
<li>中英文翻译对照<br />
</li>
<li>支持pdf翻译<br />
<img src="/attachments_2023/Pasted%20image%2020230929112932.png" /></li>
</ul></li>
</ul>
<h2 id="使用方法">2 使用方法</h2>
<p>方法1：点击右上角翻译图标<br />
方法2：在网页右键选“沉浸式翻译”</p>
<h2 id="快捷键">3 快捷键</h2>
<p>Alt+W: 翻译整个页面。<br />
Alt+A: 翻译/切换原文（在arxiv上翻译论文非常好用）。<br />
<img src="/attachments_2023/Pasted%20image%2020230929113751.png" /></p>
]]></content>
  </entry>
  <entry>
    <title>CVS打标签</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/CVS_%E6%89%93%E6%A0%87%E7%AD%BE/</url>
    <content><![CDATA[<p>#工具 #版本管理</p>
<p>关键字：CVS，TAG，标签，查看，取出</p>
<p>1. TAG</p>
<ol type="a">
<li><p>TAG是什么<br />
TAG一般被译为标签，常见的用法是在软件发布到一定程度时（如发布阶段性版本时），对其所有文件打标签。</p></li>
<li><p>TAG如何命名<br />
标签名称必须以大写或者小写字母开始，可以包括大小写字母、数字、<code>-' 和</code>_'。两个标签名
<code>BASE</code> 和 HEAD 是保留为 cvs 使用</p></li>
</ol>
<p>2. 常用命令</p>
<ol type="a">
<li>对单个文件打标签<br />
</li>
</ol>
<pre><code>$ cvs tag 标签名 文件名  </code></pre>
<ol start="2" type="a">
<li>对当前目标下所有文件打标签（含子目录）<br />
</li>
</ol>
<pre><code>$ cvs tag 标签名  </code></pre>
<ol start="3" type="a">
<li>对某个目录打标签<br />
</li>
</ol>
<pre><code>$ cvs tag 标签名 目录名  </code></pre>
<ol start="4" type="a">
<li>查看单个文件的版本信息<br />
</li>
</ol>
<pre><code>$ cvs status –v 文件名  </code></pre>
<ol start="5" type="a">
<li>取出标签对应的版本<br />
</li>
</ol>
<pre><code>$ cvs checkout –r 标签名 模块名  </code></pre>
<p>3. 参考:<br />
<a
href="http://oss.org.cn/man/develop/cvsdoc_zh/Tags.html">http://oss.org.cn/man/develop/cvsdoc_zh/Tags.html<br />
</a></p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>版本管理</tag>
      </tags>
  </entry>
  <entry>
    <title>git下载太慢的改进方法</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/Git_%E4%B8%8B%E8%BD%BD%E5%A4%AA%E6%85%A2%E7%9A%84%E6%94%B9%E8%BF%9B%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>#版本管理</p>
<h3 id="配置git参数">1. 配置git参数</h3>
<pre><code>$ git config --global http.postBuffer 524288000 # 加大缓存  
$ git config --global core.compression -1 # 设置默认压缩方法  
$ export GIT_TRACE_PACKET=1 # 打开调示信息  
$ export GIT_TRACE=1  
$ export GIT_CURL_VERBOSE=1  
$ git config --global http.lowSpeedLimit 0 # 设置最低速度  
$ git config --global http.lowSpeedTime 999999 # 设置最低速度时间，单位秒  </code></pre>
<p>设置好之后重新下载</p>
<h3 id="只下载某一分支">2. 只下载某一分支</h3>
<pre><code>$ git clone --depth 1  --branch 分支名 https://github.com/xxx.git  </code></pre>
<h3 id="参考">3. 参考</h3>
<ol type="a">
<li>详细介绍git clone --depth=1的用法<br />
https://blog.csdn.net/qq_43827595/article/details/104833980<br />
</li>
<li>github使用时太卡完美解决<br />
https://www.pianshen.com/article/78851729185/</li>
</ol>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>版本管理</tag>
      </tags>
  </entry>
  <entry>
    <title>Git常用命令</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/Git_%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<p>#版本管理</p>
<h2 id="介绍">1 介绍</h2>
<p>Git
是一个开源的分布式版本控制系统，现在管理代码一般都用它，一方面是管理各种软件版本，同时也提供对多人并行开发支持。有的在公司内部搭建Git服务器，更多情况下是使用GitHub，GitHub是一个软件项目托管平台，可以在其上建立公开项目或者私有项目。</p>
<p>在对Git工具不太熟悉的情况下，进行复杂操作时，常怕误操作，不敢多做尝试，本篇我们将从零开始，在GitHub上建立一个自己的项目，并介绍一些最常用的命令和场景，比如合并代码。</p>
<h2 id="在github上建立自己的仓库">2 在github上建立自己的仓库</h2>
<p>https://github.com/, 登录，点new repository构建新项目</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-0c7c82171ef8e963.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>点击create repository后项目就新建成功了，这时点clone or
Download按钮，可看到下载地址。</p>
<h2 id="把远程代码的下载到本地">3 把远程代码的下载到本地</h2>
<pre><code>$ git clone 地址  
形如：  
$ git clone https://github.com/xieyan0811/xxx.git   </code></pre>
<p> 也可以用-b指定分支名</p>
<h2 id="分支操作">4 分支操作</h2>
<p><strong>(1) 列出当前分支：本地/远程</strong></p>
<pre><code>$ git branch -a  </code></pre>
<p><strong>(2) 列出本地分支</strong></p>
<pre><code>$ git branch  </code></pre>
<p>可以看到，不指定分支时，“拉”的是主分支maste</p>
<p><strong>(3) 切换分支</strong></p>
<pre><code>$ git checkout -b 本地名 远程名  </code></pre>
<p>形如：</p>
<pre><code>$ git checkout -b dev origin/dev  
# 从远程分支dev拉到本地分支dev  </code></pre>
<pre><code>$ git checkout -b test1  
# 以当前分支为基础，建立新的分支test1，并切换到该分支  </code></pre>
<pre><code>$ git checkout master   
# 切换回主分支  </code></pre>
<p><strong>(4). 删除分支</strong></p>
<pre><code>$ git branch -D test1  
# 删除名为test1的分支  </code></pre>
<h2 id="编辑代码">5 编辑代码</h2>
<p><strong>(1) 查看当前状态</strong></p>
<pre><code>$ touch a.txt  
$ touch b.txt  
$ git add a.txt  
$ git status  </code></pre>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-9163145c44faa82b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>git本地分三个区：工作区（已修改的）、暂存区（修改且add的）、版本区（修改,add且commit的）。从上图可以看到被add之后的数据a.txt进入了暂存区（绿色），当前修改但还未add的b.txt仍在工作区。</p>
<p><strong>(2) 从工作区到暂存区</strong></p>
<pre><code>$ git add b.txt # 把b.txt提到暂存区   
$ git add .  # 把当前目录下所有修改提交到暂存区  </code></pre>
<p><strong>(3) 从暂存区到版本库</strong></p>
<pre><code>$ git commit -m &quot;说明文字&quot;  </code></pre>
<h2 id="查看历史">6 查看历史</h2>
<p><strong>(1) 版本历史</strong></p>
<pre><code>$ git log   </code></pre>
<p>注意其中的长串数字即版本号，越在上面的时间越近。</p>
<p><strong>(2) 查看操作记录</strong></p>
<pre><code>$ git reflog  </code></pre>
<p><strong>(3) 回退版本</strong></p>
<pre><code>$ git reset --hard HEAD   </code></pre>
<p>上例是回上一个版本, 回其它版本使用： "git reset --hard $COMMIT号"</p>
<p><strong>(4) 查看远程仓库（默认名是origin）</strong></p>
<pre><code>$ git remote # 查看远程仓库名   
$ git remote -v # 查看远程仓库地址  </code></pre>
<h2 id="储藏操作">7 储藏操作</h2>
<p>有时需要切换分支，但又不想提交当前代码，可以使用stash保存当前的中间状态，以便之后再切换回来。</p>
<pre><code>$ touch xx.txt  
$ git add xx.txt  
$ git stash save &quot;log info&quot;   </code></pre>
<p>储藏当前的变更，运行之后，看到当前目录回到分支未修改过的状态。</p>
<pre><code>$ git stash log # 查看储藏，越在上面的时间越近  
$ git stash apply stash@&#123;0&#125;  # 恢复第0个储藏  
$ git stash pop # 恢复上一个储藏，并从堆栈中移除  </code></pre>
<h2 id="下拉代码">8 下拉代码</h2>
<p><strong>(1). 拉远程分支的最新代码到本地分支</strong></p>
<pre><code>$ git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;  </code></pre>
<p><strong>(2). 冲突解决</strong><br />
当本地和远程修改了同一文件时，可能提示：“您尚未结束您的合并（存在
MERGE_HEAD）”</p>
<pre><code>$ git checkout --ours 文件名 # 使用当前版本  
或  
$ git checkout --theirs 文件名 # 使用远程版本  </code></pre>
<p>然后再使用commit, pull, push即可</p>
<h2 id="查看前次commit">9 查看前次commit</h2>
<pre><code># 查看前次版本号  
git show --stat HEAD  
# 查看之前版本号  
git log  
# 查看改了什么  
git show --stat COMMIT_ID  </code></pre>
<h2 id="恢复代码">10 恢复代码</h2>
<ul>
<li>恢复单个文件<br />
丢弃自己之前的修改</li>
</ul>
<pre><code>$ git checkout -- 文件名  </code></pre>
<h2 id="提交代码">11 提交代码</h2>
<p><strong>(2). 上传本地代码到远程分支</strong></p>
<pre><code>#查看工作区代码相对于暂存区的差别  
$ git status   
#将当前目录下修改的所有代码从工作区添加到暂存区 . 代表当前目录  
$ git add .  
$ git commit -m  &#39;message&#39;  
$ git push &lt;远程主机名&gt; &lt;本地分支名&gt;: &lt;远程分支名&gt;  </code></pre>
<p>把本地master推到远程xieyan分支，形如：</p>
<pre><code>$ git push origin master:xieyan  </code></pre>
<p><strong>(3). pull request</strong></p>
<p>用于将一个分支的修改合并到另一分支（如主分支），在网页界面操作：先进入自己的分支，点右上角的
pull request，
选择要提交到的分支，在右侧选让谁review。他在那边同意之后，你和他都可以选择merge
pull request，就可以合并了。</p>
<p><strong>(4). pull request之后需要修改再提交</strong><br />
* 正常修改代码<br />
* 正常提交到待合并的分支上（add,commit,push...）<br />
* 此时再看pull request，有两个commit<br />
* 正常approve，然后merge即可<br />
* 总结：不需要特别的撤回处理，只要再正常提交一次，在pull
request里就可看到前后两次提交，然后正常处理合并即可。</p>
<h2 id="打标签">12 打标签</h2>
<ul>
<li>列出所有版本号<br />
</li>
</ul>
<pre><code>git tag　  </code></pre>
<ul>
<li>切换到标签<br />
</li>
</ul>
<pre><code>git checkout　版本号  </code></pre>
<h2 id="排除无需上传的文件">13 排除无需上传的文件</h2>
<pre><code>vi .gitignore  </code></pre>
<p>把文件或目录路径（从git根目录开始的相对路径）加入其中，一行一个</p>
<h2 id="综合示例">14 综合示例</h2>
<p><strong>(1) 新建分支并做修改</strong></p>
<p>在github网页上左侧点master钮，按提示新建一个分支test1，并切换到这个分支，并且在新分支中修改README.txt文件内容。</p>
<p><strong>(2) 在本地修改Readme.txt</strong></p>
<p><strong>(3) 储藏修改</strong></p>
<pre><code>$ git stash save &quot;log&quot; # 此时工作目录中的修改看不到了，恢复成了“干净的状态”。  </code></pre>
<p><strong>(4) 拉下远程仓库</strong></p>
<pre><code>$ git fetch origin   </code></pre>
<p>更新远程代码到本地仓库，可以认为它是针对于版本区的操作</p>
<pre><code>$ git checkout -b test1 origin/test1   </code></pre>
<p>如果本地有些修改，既没提交，也没储藏，那么checkout时会失败，因为git不能确定你是不是要丢弃当前修改。</p>
<p><strong>(5) 切回到本地修改的分支</strong></p>
<pre><code>$ git checkout master  </code></pre>
<p><strong>(6) 合并代码</strong></p>
<pre><code>$ git merge test1 # 其中test1是分支名  </code></pre>
<p><strong>(7) 恢复储藏</strong></p>
<pre><code>$ git stash pop  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5fe47a04ff5c4cdc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>此时就看到了冲突被特殊字符标出了，解决完冲突后重新提交代码即可。</p>
<h2 id="问题与解答">15 问题与解答</h2>
<p><strong>(1) Pull和Fetch区别是什么?</strong></p>
<p>Pull包含fetch和merge两个过程，如果可能代码有冲突，尽量不用pull，因为它会自动合并代码，可能出现一些奇怪的问题，推荐用上例中的方法手动合并代码。</p>
<p><strong>(2) Github在Ubuntu终端使用时中文显示乱码</strong></p>
<p>在Ubuntu终端使用github命令，如git status, git
add时中文显示成乱码，形如：</p>
<pre><code>&quot;\346\250\241\345\236\213\347\273\  </code></pre>
<p>解决方法</p>
<pre><code>git config --global core.quotepath false  </code></pre>
<p>[[Git_下载太慢的改进方法]]</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>版本管理</tag>
      </tags>
  </entry>
  <entry>
    <title>生成卡通头像</title>
    <url>/1_Note/11_%E5%BA%94%E7%94%A8/AI%E7%BB%98%E7%94%BB/%E7%94%9F%E6%88%90%E5%8D%A1%E9%80%9A%E5%A4%B4%E5%83%8F/</url>
    <content><![CDATA[<h3 id="使用场景">使用场景</h3>
<ul>
<li>有时候不愿意把自己相片直接贴到社交媒体作为头像。<br />
</li>
<li>但是每个人都会有想让别人看到的某一面。<br />
</li>
<li>弄清楚画中人想要让别人看到的是什么，可能偏服务类的艺术都是这样。<br />
<img src="/attachments_2023/Pasted%20image%2020230912122757.png" /></li>
</ul>
<h3 id="操作方法">操作方法</h3>
<ul>
<li>上传一张自己的相片，不要大头照，需要比较自然放松的姿式<br />
</li>
<li>使用 Segment Anything 把画面中的人抠出来<br />
</li>
<li>使用 ControlNet 的 Scribble，设置 Scibble xdog，提取清晰线图<br />
</li>
<li>选 img2img 使用原图作为底图<br />
</li>
<li>选择一个喜欢的基础模型，调大 denoising<br />
</li>
<li>提示词建议：a young woman, light smile, with glasses, warm colored
background, soft light. <lora:add_detail:1></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>算法之_欧拉公式</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/0_%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E7%AE%97%E6%B3%95%E4%B9%8B_%E6%AC%A7%E6%8B%89%E5%85%AC%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="算法之_欧拉公式">算法之_欧拉公式</h1>
<p>#数学</p>
<h2 id="引子">１. 引子</h2>
<p>看傅立叶变换的时候，一直奇怪，幂指数是怎么映射成三角函数的？学习了一下欧拉公式，果然很神奇，用到了自然常数e，圆周率π，虚数i，三角函数sin/cos，指数，还有泰勒展开．不是算法有多难，只是涉及基础太多，经常被卡住，总结如下．</p>
<h2 id="泰勒展开">２. 泰勒展开</h2>
<p>泰勒展开是用多项式逼近原函数，这么做是因为像sin(x)这样的函数，如果代入x=4很难算出结果，但是将x的值代入形如f(x)=a0+a1x+a2x<sup>2+a3x</sup>3…的多项式就很容易计算。具体是用原函数的导数实现的，把函数展开成多项式，公式如下：</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-815f604e101fc036.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>其中Rn(x)是余项</p>
<h2 id="自然常数e">３. 自然常数e</h2>
<p>e是自然常数(欧拉数)，它是一个约等于2.718的无理数，定义是</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-5fe7b7445bb0cf59.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>它的含义可以通过复利来理解，假设你有1块钱，年利息是1块钱（100%），一年后可拿到两块钱(1+1/1)<sup>1=2；按利滚利计算，如果半年付一次利息(1+1/2)</sup>2=2.25；一个月付一次息，(1+1/12)<sup>12=2.61；每天付一次息，(1+1/365)</sup>365=2.715，当x驱于无穷时e约为2.718．</p>
<h2 id="自然指数ex的泰勒级数展开">４. 自然指数e^x的泰勒级数展开</h2>
<p>把e<sup>x在x=0处展开，由于e</sup>0=1且e<sup>x的导数还是e</sup>x，展开后得到</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-421f3c3512614c62.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-c3531b1dc2993e33.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>上图是e^x，以及展开式前5项和前10项拟合的图像</p>
<h2 id="复数">５. 复数</h2>
<p>复数是形如a+b*i的数，其中a,b是实数，i^2=-1.（对应直角坐标系）<br />
在复变函数(复数作为自变量和因变量的函数)中，变量z可以写成z=r (cosθ+
isinθ) ．r是z的模，即r = |z|;
θ是z的辐角，复数记作点Z(a,b)或向量OZ（对应极坐标系）</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-9a119d5f2881c2ff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>把乘一次i看成相对0点逆时针转90度，乘两次，转180度，转成实轴的-1，转三次是-i，转四次又回到单位1。因此可以把其虚部看成定义如何旋转。</p>
<h2 id="把虚数i代入ex的展开式">６. 把虚数i代入e^x的展开式</h2>
<p>虚数i是-1开方，因此有i^1=i, i<sup>2=-1，i</sup>3=-i，i^4=1</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-10f40bd5a48cbab8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>此时可以看到其结果分为实部和虚部两部分</p>
<h2 id="把sinx做泰勒级数展开">７. 把sin(x)做泰勒级数展开</h2>
<p>在x=0处展开，由于sin(0)=0，cos(0)=1，sin’(x)=cos(x)，cos’(x)=-sin(x)</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-2baadb990b0fdabc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<h2 id="把cosx做泰勒级数展开">８. 把cos(x)做泰勒级数展开</h2>
<p>在x=0处展开</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-c35c418855b780f9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<h2 id="欧拉公式">９. 欧拉公式</h2>
<p>由以上几步，可以看到e^ix的实部和虚部正好对应sin(x)和cos(x)的展开，据此，得到欧拉公式：</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-8b30ac9bbec448f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>欧拉公式将指数函数的定义域扩大到了复数域，建立了三角函数和指数函数的关系，被誉为“数学中的天桥”。<br />
下图中，将上式右侧表示为二维坐标中的点，xy轴分别表示其实部虚部，θ为转角(即上式中的x)，转动半径为单位1（模不变）．它的几何意义就是随着虚部x的增加不断转圈．</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-cbc46fc18f4f2305.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>可以把 e<sup>(i<em>x)
看作通过单位圆的圆周运动来描述单位圆上的点，e^(i</em>x)表示在单位圆上转动了x弧度(即某个角度时)得到的向量，以此类推，e</sup>(πi)在单位圆上转了半圈。显然得到的是实轴上的-1，然后与1合并可抵消得到0
，由此得到 ：</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-bfa3fe8973e8f0ee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<h2 id="扩展成时间的函数">１０. 扩展成时间的函数</h2>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-b7d89e85393f7fa5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>上图中又加入了t，把e<sup>(ix)想成e</sup>(iwt)，t是时间，w是系数。把平面上的转圈扩展成了空间中的转圈，纵轴表示时间t，两个横轴分别为实部(cos(t))和虚部(sin(t))，蓝线经过的点是e<sup>ix，即，把时域上的e</sup>ix分别投射到了实轴cos(t)和虚轴sin(t)，它们都是时间t的函数．图中可看到正余和余弦的投射（红／绿），如果用python做3D图，拖动旋转角度效果更直观．这就傅立叶变换原理：将时域值拆分映射到频域，通过三角函数的叠加表示。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>医学异常检测综述</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/10_%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%8C%BB%E5%AD%A6%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<p>英文题目：Deep Learning for Medical Anomaly Detection - A
Survey<br />
中文题目：深度学习的医疗异常检测综述<br />
论文地址：https://arxiv.org/pdf/2012.02364.pdf<br />
领域：深度学习，异常检测<br />
发表时间：2021.04<br />
作者：Tharindu Fernando，澳大利亚昆士兰科技大学<br />
出处：ACM Computing Surveys<br />
被引量：1024（谷歌学术）<br />
代码和数据：<br />
阅读时间：22.11.09</p>
<h2 id="读后感">1 读后感</h2>
<p>主要讨论在医疗数据中使用深度学习方法，以处理影像数据，时间序列为主，同时讨论了医学数据一些特有的属性。</p>
<h2 id="介绍">2 介绍</h2>
<h3 id="什么是异常">2.1 什么是异常</h3>
<p>异常检测的主要任务是识别不符合总体数据分布的数据样本。在医疗领域，除了建模以外，对模型的解释也至关重要。在实际应用中，对异常的定义也比较复杂，比如行为的不一致性；区分噪声与异常；还需要考虑上下文对异常的影响。</p>
<h3 id="医疗异常的不同">2.2 医疗异常的不同</h3>
<p>模型在医疗领域的应用包括两部分：诊断（识别当前状态）和预测（未来的状态），这两部分都可能发生异常。<br />
<img src="/attachments_2022/Pasted%20image%2020221109161533.png"
alt="Pasted%20image%2020221109161533.png" /></p>
<p>它要求：当对正常样本建模时，模型应该能够表示正常数据分布的多样性；模型需要足够的灵敏度(正确识别异常样本的能力)，要求异常检测模型具有较高的准确性；另外，正常样本之间也可能存在差异，比如<strong>在成人和儿童静息状态脑电图数据的显著差异</strong>;
医学异常检测通常以监督学习任务为主。</p>
<h3 id="使用深度学习">2.3 使用深度学习</h3>
<p>深度学习可以更好地处理非线性数据；并有可以自动构造特征；支持一些自动识别功能，避免了一些手工标注异常；还可以针对时序了数据识别长距离的依赖关系（如LSTM）。</p>
<h3 id="本文贡献">2.4 本文贡献</h3>
<p>本文涉及多种医疗异常建模方法，读者可以比较和对比不同深度学习技术的优缺点，并将这些发现用于不同的医疗应用领域。涉及卷积神经网络，循环神经网络，生成对抗网络，自动编码器，神经记忆网络，支持无监督学习、监督学习和多任务学习。另外，还讨论了解释模型决策的方法。<br />
<img src="/attachments_2022/Pasted%20image%2020221109171541.png"
alt="Pasted%20image%2020221109171541.png" /></p>
<h3 id="本文组织方式">2.5 本文组织方式</h3>
<p>第II部分算法，其中II-A介绍医疗数据类型，II-B介绍算法，II-C介绍应用场景；第III部分是模型解释；第IV部分是挑战与限制；第V部分总结。</p>
<h2 id="ii.-使用深度学习检测医疗异常">3 II.
使用深度学习检测医疗异常</h2>
<h3 id="数据类型">3.1 数据类型</h3>
<h4 id="生物医学图像">3.1.1 1) 生物医学图像</h4>
<ul>
<li>X光片：原理是骨骼中的钙密度更大，会散射x射线。通常用于各种诊断目的，包括检测骨折、牙齿问题、肺炎和某些类型的肿瘤。<br />
</li>
<li>CT
计算机断层扫描：收集了多个横截面成像，常用于检测腹部肿瘤或病变，定位头部损伤、肿瘤和血块，诊断复杂的骨折和骨肿瘤。<br />
</li>
<li>MRI
核磁：原理是不同类型的组织释放的能量不同，这使得核磁共振扫描能够分离出不同的区域。通常用于人体非骨或软组织区域的成像，比如：显示大脑，脊髓，神经和肌肉，脑肿瘤的检测和组织损伤的识别。</li>
</ul>
<h4 id="电子生物医学信号">3.1.2 2) 电子生物医学信号</h4>
<ul>
<li>ECG
心电图：一种可视化的工具，可以观察产生心跳的流经心脏的电流。它通过测量心电图上的时间间隔，可以筛选出不规律的电活动；电活动的强度可以反映心脏的哪些区域工作过度或压力过大。<br />
</li>
<li>EEG
脑电图：检测大脑中的电活动，利用电脉冲进行交流。常用于研究睡眠模式、心理障碍、头部损伤造成的脑损伤和癫痫。<br />
</li>
<li>MEG脑磁图：主要检测由这些细胞外电流引起的磁场。</li>
</ul>
<h4 id="杂项数据类型">3.1.3 3）杂项数据类型</h4>
<p>如心音描记术(PCG)和其它可穿戴医疗设备。</p>
<h3 id="b.医疗异常检测算法方法">3.2 B.医疗异常检测算法方法</h3>
<h4 id="无监督异常检测">3.2.1 1）无监督异常检测</h4>
<p><strong>自编码器AEs</strong><br />
Auto
Encoders，可以自已学习特征。对它的改进包含离散自编码器，它通过惩罚对非0值的加和使特征足够稀疏。<br />
<img src="/attachments_2022/Pasted%20image%2020221109174955.png"
alt="Pasted%20image%2020221109174955.png" /><br />
另外，还有去噪自编码器，压缩自编码器；其中变分自编码器得到了很广泛的应用，它假设观测值x从概率分布中采样，并试图估计该分布的参数（引入了概率）。<br />
自编码器的弱点是，对于高维数据分布，编码能力受限，经常导致错误的重构和不准确的近似建模数据分布。<br />
<strong>生成对抗网络GANs</strong><br />
一个生成器，一个判别器，也有很多改进版本，其中条件GAN使用最为广泛，还有Cycle-GAN在图像翻译任务中比较流行，它的原始输入可以由生成的输出合成。<br />
判别器主要用于判别真伪，而非是否异常。具体使用的一种方法是：当生成图和目标图出现差异时，认为异常，并使用该过程识别异常。</p>
<h4 id="有监督的异常检测">3.2.2 2) 有监督的异常检测</h4>
<p>在监督异常检测中，提供一个监督信号，指示哪些示例来自正常类别，哪些是异常的。<br />
多任务学习是其中一个重要应用：它在多个相关任务之间共享相关信息，而不是单独学习它们。在学习异常分类的过程中，研究对象之间的异同，相对于主题的变化。</p>
<h4 id="循环神经网络">3.2.3 3) 循环神经网络</h4>
<p>由于时序信处在医疗数据中广泛使用，它主要使用历史数据来预测未来数据，因此，此处把它单独归成一类。深度学习方法包含：RNN，LSTM，GRU等。其中NMNs（Neural
Memory
Networks）神经记忆网络是RNN的另一种变体，它使用一个外部存储器堆栈来存储信息，LSTM遗忘门和写控制器相似。可用于如识别脑电图预测癫痫发作。</p>
<h3 id="背景和相关应用">3.3 背景和相关应用</h3>
<h4 id="检测mri异常">3.3.1 1）检测MRI异常</h4>
<p>概括起来大致分两种：一种是使用深度学习作为特征提取器，后面接随机森林、SVM等机器学习算法做异常检测；另一种是深度学习网络后面接Softmax直接预测异常和类别。<br />
具体的深度学习模型大多数使用CNN；也有使用自编码器作为特征提取器，后接机器学习模型的；还有分两步训练，第一步先训练无监督AE学习特征，第二步用有监督方法加一个Softmax层利用有标签数据优化。<strong>（结合有监督和无监督）</strong><br />
另外，还有多尺度多任务的框架，实现腰椎神经孔狭窄症的诊断，在不同的尺度上捕捉多个器官；多任务是在回归边界框定位器官和预测所定位器官的异常。<br />
<img src="/attachments_2022/Pasted%20image%2020221109182100.png"
alt="Pasted%20image%2020221109182100.png" /><br />
还有利用NMN方法，将内存堆栈存储作为区分正常和异常样本的重要特征。</p>
<h4 id="在内窥镜检查数据中发现异常">3.3.2 2)
在内窥镜检查数据中发现异常</h4>
<p>CNN是内镜图像异常检测的主要方法。多分类通常使用分类交叉熵损失训练，使模型可以检测正常和异常的例子，同时识别异常类别。</p>
<h4 id="心音异常检测">3.3.3 3) 心音异常检测</h4>
<p>主要处理音频信号，一般结合深度学习和手工提取特征，包含时域特征、高阶统计量、信号能量和频域特征，如梅尔谱图和梅尔频率倒谱；同时使用1D-CNN或者RNN建模。这些方法能有效地对
S1和S2心音位置周围的信息，以检测异常。该领域主要使用有监督数据建模。</p>
<h4 id="癫痫发作预测">3.3.4 4) 癫痫发作预测</h4>
<p>对于不均衡数据，首先使用平衡数据集训练模型，数据集包含等量的预测数据和间隔数据。当系统部署时，建议添加一个可调处理层，可以根据用户的需求进行优化。<strong>这种方法很实用</strong><br />
还有一种对抗学习的方法，修改了网络结构，添加两个全连接层来调整鉴别器网络，以便训练它执行正常/异常分类，而不是真/假分类。这种体系结构是半监督的，其中有标签和无标签的示例都用于模型训练。<br />
<img src="/attachments_2022/Pasted%20image%2020221109183902.png"
alt="Pasted%20image%2020221109183902.png" /></p>
<h2 id="iii-模型解释">4 III 模型解释</h2>
<p>图-14对模型解释进行了分类：<br />
<img src="/attachments_2022/Pasted%20image%2020221109184017.png"
alt="Pasted%20image%2020221109184017.png" /><br />
从模型角度看，分为可对所有模型解析的方法和针对特定类型模型解释的方法。<br />
从作用范围看，分为局部解释和整体解释，局部方法是对特定的预测进行推理，而全局方法探索整体模型行为。<br />
第三种方法：用其它模型解决现有模型，包括两种方法：一个是用简单的模型模拟复杂模型的行为，另一种是用可视化的方法解析模型。<br />
第四种方法：将医学领域的模型解释技术可以大致分为基于归因的方法和基于非归因的方法。</p>
<p><strong>可视化激活映射</strong><br />
这可以揭示输入的哪些区域/特征被高度激活，并将信息传递给分类器。<br />
<img src="/attachments_2022/Pasted%20image%2020221109184835.png"
alt="Pasted%20image%2020221109184835.png" /><br />
Grad-Cam方法可以解析每个像素对决策的影响。（<strong>可以看看NLP有没有类似的方法</strong>）</p>
<p><strong>用于各种模型的局部可解释模型(LIME)</strong><br />
输入被划分为一系列可解释的组件，其中部分输入被屏蔽。然后将每个扰动样本通过该模型得到特定类的概率，并返回权重最高的分量作为解释。<br />
它的问题是：由于解释偏向于数据点，生成的解释可能是不稳定的，因此当两个分量接近时，可能导致非常不同的解释。</p>
<p><strong>SHapley加法解释(SHAP)</strong><br />
目前存在，一个提供完整的解释的方法。</p>
<p><strong>医疗异常检测方法解释</strong><br />
DeepLEFT、DeepTaylor、引导反向传播(GBP)和集成梯度等也被用来解释黑盒深度学习模型。<br />
另外，可用注意力图可以<strong>解释模型特征的相互作用</strong>，比如在医疗图片和诊断信息之间建立联系；专家知识来解释模型决策。</p>
<p>综上，如何选择模型解析器主要取决于以下因素：<br />
* 使用全局解释还是局部解释<br />
* 用户对结果理解的专业水平<br />
* 应用领域是否有时间限制，解释是否需要实时生成</p>
<h2 id="iv-挑战和开放的研究问题">5 IV 挑战和开放的研究问题</h2>
<h3 id="缺乏可解释性">5.1 缺乏可解释性</h3>
<p>GradCAM, LIME,
GBP这些方法都不是为医学领域研发的，所以对临床可能不是很有效，需要更多地加入专家共识，比如Human-in-the-Loop技术，用于设计可解释的诊断模型，让临床专家可以改进深度模型的决策，以模仿他们自己的决策过程。<br />
另外，如果决策依赖于多个输入特征流，需要更复杂的策略来解释行为。<br />
强化学习，也是一个方法，它通过试图最大化奖励，在迭代中改进其检测过程。代理用来探测异常的探测过程可以说明其行为背后的直觉。</p>
<h3 id="因果关系和不确定性">5.2 因果关系和不确定性</h3>
<p>因果和相关往往被混淆，XY同时发生，并一定存在因果关系，只是相关，比如它们由于同样原因引起。<br />
普通模型只能找到关联关系，而无法找到其原因。如果想定位原因，还需要原因估计模型，比如：基于图结构，基于算法信息理论的方法，因果贝叶斯网络，但是这些方法很少在医学异常检测中应用。<br />
另外，数据中还存在不确定性，可能输入小的改变就能影响模型预测的结果，这与模型的置信度相关。<br />
有一种方法，利用计算出的不确定性措施，将困难的案例子集转为进一步检查。(<strong>值得借鉴</strong>)</p>
<h3 id="缺乏通用性">5.3 缺乏通用性</h3>
<p>模型可能缺乏对不同操作条件的概括，对于没见过的数据集，可能效果不好。尽管公开可用的数据集的数量持续增加，但可用的数据样本数量仍然有限；另外，对数据的筛选，也可能让模型不能捕捉真实数据分布。<br />
图-18展示了来自不同子集的样本分布在嵌入空间中。<br />
<img src="/attachments_2022/Pasted%20image%2020221109191717.png"
alt="Pasted%20image%2020221109191717.png" /><br />
如果一个诊断模型只在这个数据集的一个特定子集上进行训练，它就会在另一个子集上产生错误检测。因此，需要捕捉整个种群多样性的大规模数据集。</p>
<p>医学信息标注成本高，不太可能有像ImageNet那样的丰富标注的数据集。元学习可能起一定作用，它是迁移学习的一种，它可对领域进行适配，让特定领域训练的模型可应用到其它领域。</p>
<h3 id="处理数据不平衡和未标记数据">5.4 处理数据不平衡和未标记数据</h3>
<p>数据不均衡会引起预测偏向主导类别，医疗异常检测的不平衡一直是数据重采样(过采样或过采样)和成本敏感训练，其中损失的权重分配给少数类。<br />
另外，还可以使用GAN做数据增强，合成较为真实的少数类样本。<br />
对于大量无标注的数据可以使用半监督学习方法加以利用，上文中也示例了通过对无监督算法的修改，将模型适用于正常的异常分类任务，而不是真假验证。<br />
半监督学习的目标可被设计成自动生成标签。然后，学习到的知识被转移到不同的下游任务。<br />
自监督学习也可以应用于检测异常，但在医学领域应用比较少。</p>
<h2 id="总结">6 总结</h2>
<p>略...</p>
]]></content>
      <tags>
        <tag>生物医学</tag>
        <tag>异常检测</tag>
      </tags>
  </entry>
  <entry>
    <title>读文阅读_关系表征的在线学习DeepWalk</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/12_%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%85%B3%E7%B3%BB%E8%A1%A8%E5%BE%81%E7%9A%84%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0DeepWalk/</url>
    <content><![CDATA[<p>#论文阅读 #自然语言处理 #图神经网络</p>
<h1 id="读后感">读后感</h1>
<ul>
<li>针对问题：<strong>学习图中节点的表征</strong>，解决多分类、异常检测等问题。通过优化算法，可应用于<strong>大规模</strong>数据。<br />
</li>
<li>结果：当标签数据稀疏时，F1分数比之前方法提升10%；在一些实验中，使用60%训练数据，结果即可优于其它方法。<br />
</li>
<li>核心方法：借鉴自然语言处理方法，利用统计原理，使用<strong>无监督</strong>数据学习。<br />
</li>
<li>难点：优化部分较难理解。<br />
</li>
<li>泛读后理解程度：直接精读。<br />
（看完题目、摘要、结论、图表及小标题）</li>
</ul>
<h1 id="介绍">介绍</h1>
<p>英文题目：DeepWalk: Online Learning of Social Representations<br />
中文题目：DeepWalk：关系表征的在线学习<br />
论文地址：http://perozzi.net/publications/14_kdd_deepwalk.pdf<br />
领域：知识图谱<br />
发表时间：2014<br />
出处：KDD<br />
被引量：5094<br />
代码和数据：https://github.com/phanein/deepwalk/<br />
阅读时间：2022.3.28</p>
<h1 id="精读">精读</h1>
<h2 id="介绍-1">1. 介绍</h2>
<p><img src="/attachments_2022/Pasted%20image%2020220328211733.png"
alt="Pasted%20image%2020220328211733.png" /><br />
编码的目标是使用相对较低的维度表征数据，如图以2维为例，左图是输入，右图是输出，可以看到，输入中的连接关系，可表征成输出的特征的相似性，颜色表示它们的聚类结果。<br />
把稀疏的表示转换为低维稠密表示之后，可以使用统计学方法建模，比如使用简单的逻辑回归算法进一步处理。</p>
<p><strong>文章贡献如下</strong>：<br />
*
提出DEEPWALK算法，使用深度学习方法分析图，构建适用于统计建模的健壮表示，利用短程随机游走学习图结构中的规则。<br />
*
将文中方法应用于多标签的分类任务中，在稀疏问题上，有5%-10%的提升，在一些情况下可减少60%的训练数据。<br />
*
文中展示了算法的可扩展性，可利用并行计算，应用于网络规模的图（如YouTube），并通过较小的修改构建流式版本（online
learning）。</p>
<h2 id="问题定义">2. 问题定义</h2>
<p>设G=(V,E)，G是图，V是顶点，E是边，GL=(V,E,X,Y)是部分标注的图，其中X是节点的S维特征，Y是标签。<br />
传统方法是希望找到X与Y间的映射H，而文中方法的目标是利用嵌入在网络结构中的节点相关性信息，实现更好的表征。<br />
文中利用无监督方法，学习图中展示的结构特征，而非把标签作为特征的一部分，使得新表征与标签分布无关。<br />
本文的目标是学习低维的X表征，每个维度表达一些概念。这些表征是相对通用的，与具体算法无关，可用这些表征解决下游的决策问题。</p>
<h2 id="学习关系表示">3. 学习关系表示</h2>
<p>希望找到有以下特性的方法：<br />
*
适应性：可适应网络的<strong>不断进化</strong>，而无需每次都从头训练。<br />
* 社区意识：新表征的相似性应于网络中的相似性保持一致。<br />
* 低维度：低维度的新表征，有更好的泛化性，训练和预测速度更快。<br />
* 连续性：新表征中的特征是连续值，从而实现更强的健壮性。</p>
<h3 id="随机游走">3.1 随机游走</h3>
<p>从节点vi开始，随机访问<span
class="math inline">\(W_{v_i}^1,W_{v_i}^2...W_{v_i}^k\)</span>，<span
class="math inline">\(W_{v_i}^{k+1}\)</span>是随机从vk的邻居中选择的顶点，简单地说就是a到a的邻居b，b再到b的邻居c……随机游走已被用作内容推荐和社区检测等应用中，用于度量相似性。用它计算本地结构信息，时间上与输入图的大小呈次线性关系。</p>
<p>文中使用短程随机游走作为工具从网络中抽取信息，它提供了两种特性：可使用并行方法来探索图中的不同部分；小的改变<strong>不需要对全图重新训练</strong>。可以迭代更新模型，时间上是次线性的。</p>
<h3 id="连接幂律">3.2 连接：幂律</h3>
<p>如果连接图中度的分布满足幂律，短程随机行走中顶点出现的频率也将服从幂函数分布。<br />
幂律(Power Laws)指的是：节点具有的连线数和节点数目乘积是一个定值。</p>
<p><img src="/attachments_2022/Pasted%20image%2020220324094154.png"
alt="Pasted%20image%2020220324094154.png" /><br />
自然语言中的词频与图中节点的随机游走分布类似，如图-2所示，左图是YouTube网络中短程游走情况，横坐标是节点出现的次数，纵坐标是节点数量，也就是说只有少量节点游走的次数很多；它可类比成自然语言处理如右图，Wikipedia中常用词非常少。本文将一些自然语言建模技术用于图的建模。</p>
<h3 id="语言模型">3.3 语言模型</h3>
<p>自然语言模型的目标是估计由单词组成字符串的正确性。对于单词(w0,w1,...,wn)，利用训练集，最大化概率Pr(wn|w0,w1,...,wn-1)，具体方法是使用概率神经网络泛化成词表征。</p>
<p>解决图问题时，相应地使用短程随机游走，把游走视为语言中的短语或短句，根据之前节点关系，预测下一节点vi<br />
<img src="/attachments_2022/Pasted%20image%2020220324095554.png"
alt="Pasted%20image%2020220324095554.png" /><br />
文中目标是不仅学习节点共现的概率分布，同时生成一种映射关系Φ，将网络中的关系表征为节点d维向量，然后用它进行后续计算。<br />
<img src="/attachments_2022/Pasted%20image%2020220324100006.png"
alt="Pasted%20image%2020220324100006.png" /><br />
随着随机步数的增加，条件概率计算量则变得非常大。</p>
<p>在自然语言问题中，最近提出一些新的算法：将通过上下文预测缺失词，改为通过一个词预测上下文；上下文由其左右两侧词组成，改为不考虑上下文中词的顺序，只最大化上下文中词出现的概率。对节点表示问题，也可做相应优化：<br />
<img src="/attachments_2022/Pasted%20image%2020220324100538.png"
alt="Pasted%20image%2020220324100538.png" /><br />
（上式中斜线的意思是除vi以外）</p>
<p>顺序无关性能更好地捕捉到随机游走中“近距离”的节点，另外，一次给出一个顶点构造小模型，也加快了训练速度。</p>
<p>式-3中捕捉了本地图结构中共享了相似性，<strong>具有相似邻居的节点需要近似的编码表征</strong>，也可泛化到其它机器学习任务中。</p>
<h2 id="方法">4. 方法</h2>
<h3 id="概述">4.1 概述</h3>
<p>自然语言建模时需要语料库和词表V，DEEPWALK将截断的随机游走看作语料库，将图中节点看作词表。</p>
<h3 id="算法deepwalk">4.2 算法：DEEPWALK</h3>
<p>算法主要包括两部分：产生随机游走；更新程序。过程中以每个节点vi作为起点进行游走Wvi，游走从最后访问的顶点的邻域均匀采样，直到达到最大长度T。<br />
<img src="/attachments_2022/Pasted%20image%2020220324102059.png"
alt="Pasted%20image%2020220324102059.png" /><br />
外层循环游走整体的迭代遍数（一共试着走几次），在每次遍历开始时，第4行生成一个遍历顶点的随机顺序，这样做能加快随机梯度下降的收敛。</p>
<p>内层循环遍历图中所有节点，对每个节点产生t步的随机游走W（随机游走的路径和长度都是随机的），在第7行使用它代入SkipGram算法来更新表征，其目的是优化式-3中的目标函数。</p>
<h4 id="skipgram">4.2.1 SkipGram</h4>
<p>参见：[[几种词嵌入方法#Word2Vec的skip-gram模型]]<br />
SkipGram是一种语言模型，它在句子中设置窗口，然后计算窗口中词的最大共现概率。对于式-3，在假设词相互独立的情况下，概率可表示成乘法关系：<br />
<img src="/attachments_2022/Pasted%20image%2020220325095058.png"
alt="Pasted%20image%2020220325095058.png" /><br />
<img src="/attachments_2022/Pasted%20image%2020220325095300.png"
alt="Pasted%20image%2020220325095300.png" /><br />
算法2遍历了在窗口w中随机游走的所有可能性，将vj映射成新表征Φ(vj
)，最大化游走到它邻近节点的概率，J是目标函数，通过它来优化Φ。</p>
<h4 id="分层softmax">4.2.2 分层Softmax</h4>
<p>（这部分比较难理解，我试着扩展一下，可能不对）</p>
<p>算法2中第3行，当图中节点较多时，计算量非常大。因为Softmax归一化，要计算图中所有的节点。因此文中提出了分层Softmax，实际上是把多分类变成了二分类树，即把softmax变成了多次sigmoid。<br />
<img src="/attachments_2022/Pasted%20image%2020220325133248.png"
alt="Pasted%20image%2020220325133248.png" /><br />
如图-3(c)所示，用与v1相关的节点作为叶子，构造了一个二分类树，从而把预测问题变成最大化树中特定路径的概率问题。当从起点到uk的路径被认为是经过一系列树节点b（b0是根节点，<span
class="math inline">\(b_{[log|v|]}=u_k\)</span>），则有：<br />
<img src="/attachments_2022/Pasted%20image%2020220325134434.png"
alt="Pasted%20image%2020220325134434.png" /><br />
此时的Pr被构建成二分类器（sigmoid函数）：<br />
<img src="/attachments_2022/Pasted%20image%2020220325134627.png"
alt="Pasted%20image%2020220325134627.png" /><br />
其中Ψ(bl)
是bl父节点的表征，它把复杂度从O(|V|)降到了O(log|V|)，从而加速了训练。</p>
<p>为加快训练，在构造树的过程中，给随机游走中通向频繁顶点的过程分配较短路径，使用哈夫曼编码来减少树中频繁元素的访问时间。（简单地说，就是先判断可能性最高的，从而减少判断次数）</p>
<h4 id="优化">4.2.3 优化</h4>
<p>计算模型参数θ = {Φ,Ψ}
的时间复杂度是O(d|V|)，算法-2第四行使用SGD方法优化参数。学习率初值是2.5%，逐步减少。</p>
<h3 id="并行">4.3 并行</h3>
<p>图-2展示了随机游走的频率分布服从幂律，这导致了低频顶点的长尾分布，Φ的稀疏性使我们可以使用随机梯度下降的异步版本ASGD，并行计算，且不需要加锁。它可被扩展到大规模的机器学习中。图-4展示了并行计算的效果，可以看到随着线程数的增加，训练时间变短（左），且模型精度变化不大（右）。<br />
<img src="/attachments_2022/Pasted%20image%2020220329215227.png"
alt="Pasted%20image%2020220329215227.png" /></p>
<h3 id="算法变异">4.4 算法变异</h3>
<h4 id="流方法">4.4.1 流方法</h4>
<p>流式方法在不需要了解全图的情况下也能计算，变化是游走直接更新模型。具体修改是：不再使用学习率衰减，而是将其设定为一个小的常数，因此，需要更长的时间学习；另外，不再需要建立树的参数。</p>
<h4 id="非随机游走">4.4.2 非随机游走</h4>
<p>有一些图通过交互产生，比如用户在网页中导航。这种情况下就不需要随机游走，可以直接用路径建模。这样采样不仅与网络结构有关，还包含了路径的频率。<br />
结合上述方法，可以持续改进网络，而不需要确定所有信息后再构建整个网络。这种方法可以用于处理大规模网络。</p>
<h2 id="实验设计">5. 实验设计</h2>
<h3 id="数据集">5.1 数据集</h3>
<ul>
<li>BlogCatalog：由博客作者相互关系构建的网络，标签是作者的主题类别。<br />
</li>
<li>FLICKR：图片共享网站用户之间的联系人网络，标签是用户感兴趣的组。<br />
</li>
<li>YOUTUBE：视频用户关系网络，标签是喜欢同一视频风格的群体。</li>
</ul>
<h3 id="基线">5.2 基线</h3>
<ul>
<li>频谱聚类：使用拉普拉斯矩阵的前d维特征向量作为表征，然后对表征聚类。<br />
</li>
<li>模矩阵：使用图G的模矩阵B的前d个特征向量表征。<br />
</li>
<li>边聚类：对邻接矩阵使用K-means聚类。<br />
</li>
<li>wvRN：根据领居权重投票方法。<br />
</li>
<li>少数服从多数：简单地选择训练集中出现最多的标签作为类别。</li>
</ul>
<h2 id="实验">6. 实验</h2>
<h3 id="多标签分类">6.1 多标签分类</h3>
<h4 id="blogcatalog">6.1.1 BlogCatalog</h4>
<p>分别使用训练集的10%-90%进行训练，可以看到DEEPWALK优于频聚类以外的其它方法，当标注少时，DEEPWALK比频聚类更有优势，这是文中算法的特点。<br />
<img src="/attachments_2022/Pasted%20image%2020220329223340.png"
alt="Pasted%20image%2020220329223340.png" /></p>
<h4 id="flickr">6.1.2 Flickr</h4>
<p>实验分别标注了1%-10%的数据，可以看到DEEPWALK优于其它算法，它只需要60%甚至更少的数据，就能达到与其它算法相同的精度。<br />
<img src="/attachments_2022/Pasted%20image%2020220329223544.png"
alt="Pasted%20image%2020220329223544.png" /></p>
<h4 id="youtube">6.1.3 YouTube</h4>
<p>YOUTUBE网络比其它网络大得多，频聚类和模矩阵无法满足这样的计算量。这种网络也更接近现实世界。使用1%-10%比例标注。<br />
<img src="/attachments_2022/Pasted%20image%2020220329224103.png"
alt="Pasted%20image%2020220329224103.png" /><br />
可以看到它在少量标注时明显优于其它算法。<br />
综上，文中方法对于多分类任务，在网络大，稀疏，标注少的情况下效果都很好。</p>
<h3 id="灵敏度参数">6.2 灵敏度参数</h3>
<p>图-5展示了参数对分类任务模型的影响。<br />
<img src="/attachments_2022/Pasted%20image%2020220330085907.png"
alt="Pasted%20image%2020220330085907.png" /></p>
<h3 id="维度影响">6.2.1 维度影响</h3>
<p>其中左边展示了不同输出维度的影响，其中a1和a3用不同颜色展示不同的训练比率，在两个数据集中结果相似：模型的最优维度依赖于训练样本数。a2和a4不同颜色展示了不同游走次数γ，两图都在γ=30时性价比最高；虽然FLICKR比BLOGCATALOG边多一倍，但γ取值不同时，两张图很相似。<br />
这说明文中方法可适应不同大小的网络，且模型表现依赖于游走次数，维度取决于训练样本量。</p>
<h3 id="采样率影响">6.2.2 采样率影响</h3>
<p>右图展示了不同游走次数的影响，b1,b3展示了不同输出维度，b2,b4展示不同训练样本，情况基本一致，γ对结果有显著影响，而在γ&gt;10之后再增加次数，效果提升就不太明显了。这说明只需要少量游走，就可以学到节点的表征。</p>
]]></content>
      <tags>
        <tag>图神经网络</tag>
        <tag>知识表示</tag>
      </tags>
  </entry>
  <entry>
    <title>基于GCN的跨语言知识图对齐</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/12_%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_GCN%E7%9F%A5%E8%AF%86%E5%9B%BE%E5%AF%B9%E9%BD%90/</url>
    <content><![CDATA[<h1 id="介绍">介绍</h1>
<p>英文题目：Cross-lingual Knowledge Graph Alignment viaGraph
Convolutional Networks<br />
中文题目：基于GCN的跨语言知识图对齐<br />
论文地址：https://aclanthology.org/D18-1032.pdf<br />
领域：知识图谱，知识对齐<br />
发表时间：2018<br />
作者：Zhichun Wang 北京师范大学<br />
出处：EMNLP<br />
被引量：198<br />
代码和数据：https://github.com/1049451037/GCN-Align<br />
阅读时间：2022.04.15</p>
<h1 id="其它介绍">其它介绍</h1>
<p>文章亮点：<br />
* 复习了之前的对齐方法<br />
* 提出了邻接矩阵的计算以及属性的代入方法技巧<br />
* GCNAlign和同类文件相比，引用量大，速度快，效果好，常作为默认工具<br />
* 文章偏重真实场景中，多种关系，属性类别，属性值的应用。</p>
<h1 id="泛读">泛读</h1>
<ul>
<li>针对问题：不同语言知识图中的实体对齐<br />
</li>
<li>结果：使用比较简单的方法，超过或得到与之前的方法近似的效果<br />
</li>
<li>核心方法：调整GCN层计算方法，可同时对结构和属性编码<br />
</li>
<li>难点：无<br />
</li>
<li>泛读后理解程度：直接精读<br />
（看完题目、摘要、结论、图表及小标题）</li>
</ul>
<h1 id="精读">精读</h1>
<h2 id="摘要">摘要</h2>
<p>文中方法主要用于解决多语言知识图的实体对齐问题。文中提出GCNs（graph
convolutional
networks），利用预对齐实体，通过训练，将实体表征为低维向量。实体对齐基于实体和嵌入的距离计算。嵌入基于对图结构和实体属性的学习，结合二者得到更精确的结果。</p>
<h2 id="介绍-1">1. 介绍</h2>
<p>很多时候，需要知识在不同语言中具有相同编码，匹配，链接。手工难以实现，因此不断寻找自动方法。</p>
<p>传统对齐方法依赖机器翻译或者定义跨语言的特征来发现语言之间的关系。最近，常用基于嵌入的方法对齐，包含MTransE，JAPE等。两个图中有一些预对齐的实体，基于嵌入的方法通过训练将实体转换到低维空间，然后基于它们在低维空间的表示进行匹配，JE和ITransE也用于单语言中的知识融合和跨语言的知识对齐。上述方法无需依赖机器翻译或特征工程。</p>
<p>然而，上述方法都面临优化问题，比如 JE,
MTransE和ITransE都使用超参数均衡损失函数，JAPE使用预对齐的实体将两个图合二为一，并给负例加权。<strong>实体嵌入既要编码结构信息，又要编码等价关系</strong>。另外，属性信息也应该被更好地利用。MTransE和ITransE未利用属性信息，JAPE只利用了属性类型。</p>
<p>文中提出基于图卷积的方法GCNs直接对实体的等价关系建模。卷积网络抽取图结构，利用节点的邻居编码：两个对等实体的邻居也常常是对等的实体。另外，还对属性进行了简单有效的利用。</p>
<p>文中模型主要优势如下：<br />
*
使用图中的实体关系构建GCNs，只使用实体在图中的对等关系（没像JAPE使用词嵌入），模型复杂度低。<br />
* 只需要预测对齐的实体作为训练数据，不需要预对齐的关系或属性。<br />
* 结合关系结构和属性有效地提升了对齐效果。</p>
<h2 id="相关工作">2. 相关工作</h2>
<h3 id="图嵌入">2.1 图嵌入</h3>
<p>图嵌入：将图中实体和关系映射到低维空间。学习图嵌入一般通过最小化全局损失函数。常用于关系预测，信息抽取等任务。</p>
<h4 id="transe">TransE</h4>
<ul>
<li>简单而有效的方法<br />
</li>
<li>时间：2013年<br />
</li>
<li>原理：<span class="math inline">\(h+r \approx t\)</span>
编码后的头实体加关系约等尾实体<br />
</li>
<li>损失函数：最小化训练集上基于差值的排序标准<br />
</li>
<li>引申算法：TransH，TransR，TransD，后续的模型增加了复杂度，提升了效果</li>
</ul>
<h3 id="基于嵌入的实体对齐">2.2 基于嵌入的实体对齐</h3>
<h4 id="je">JE</h4>
<ul>
<li>时间：2016年<br />
</li>
<li>把两个图映射到同一嵌入空间<br />
</li>
<li>通过种子对齐多个图<br />
</li>
<li>图嵌入使用TransE改进算法<br />
</li>
<li>损失函数：TransE损失+全局对齐损失</li>
</ul>
<h4 id="mtranse">MTransE</h4>
<ul>
<li>时间：2017年<br />
</li>
<li>把两个图映射到不同嵌入空间<br />
</li>
<li>提供转换方法转换两组空间<br />
</li>
<li>图嵌入使用TransE改进算法<br />
</li>
<li>损失函数：知识图模型+对齐模型<br />
</li>
<li>训练时，需要两图中对齐的三元组</li>
</ul>
<h4 id="jape">JAPE</h4>
<ul>
<li>时间：2017年<br />
</li>
<li>结合了结构嵌入和属性嵌入<br />
</li>
<li>结构嵌入使用TransE<br />
</li>
<li>属性嵌入使用Skip-gram模型，捕捉属性的相关性<br />
</li>
<li>需要预先对关系和属性对齐</li>
</ul>
<h4 id="itranse">ITransE</h4>
<ul>
<li>时间：2017年<br />
</li>
<li>先使用TransE学习实体和边的嵌入<br />
</li>
<li>利用对齐种子学习不同语言库在联合空间的知识图映射<br />
</li>
<li>通过使用新发现的实体对齐来更新实体的联合嵌入，从而实现迭代实体对齐<br />
</li>
<li>要求在KG之间共享所有关系</li>
</ul>
<p>上述几个模型都使用类似框架：用TransE学习实体嵌入，再定义对齐实体嵌入之间的变换和对齐。</p>
<p>文中提出的方法使用了不同框架，它使用GCNS将实体嵌入到统一的向量空间中，其中对齐的实体被期望尽可能接近，并且只学习实体嵌入，不学习边嵌入，因而不需要边的相关先验知识。</p>
<h2 id="问题定义">3. 问题定义</h2>
<p>KGs使用三元组，三元组又分为关系三元组〈entity1,relation,entity2〉和属性三元组〈entity,attribute,value〉，文中方法使用了两种。</p>
<p>KG 定义为 G
=(E,R,A,TR,TA)，其中E为实体，R为关系，A为属性，TR为关系三元组，TA为属性三元组，用符号V定义属性的具体值。</p>
<p>用G1,G2分别代表不同语言的两个图 。<br />
<span class="math display">\[ S={ \{ (e_{i1},e_{i2})|e_{i1}\in
E_1,e_{i2} \in E_2} \} ^m_{i=1}\]</span><br />
S是G1与G2之间m个预先对齐的实体对，即种子。将任务定义为对齐不同语言的知识图，基于已知的对齐种子找到新的实体对齐。对于DBpedia和YAGO的这样数据集，可以利用多语言间链接来构建预测对齐的实体对。种子作为对齐过程中的训练数据。</p>
<h2 id="方法">4. 方法</h2>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-53a2c19471e3bd9c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>如图-1所示，KG1和KG2分别是不同语言的两个图，给出二者间的对齐种子S，基于GCN方法搜索图中更多的实体对齐。基本思想是利用GCN将不同语言的实体嵌入到同一个向量空间，相等的实体在空间中的距离越近越好。利用事先定义好的距离函数作为量度。</p>
<h3 id="基于gcn的实体嵌入">4.1 基于GCN的实体嵌入</h3>
<p>GCN是一种直接操作图数据的神经网络结构，它使用端到端的学习来预测，其输入是任意大小和形状的图，具体输入是节点和结构的特征向量，其目标是学习一种方法来表示输入的特征，并生成节点级的输出。GCN可以将邻居节点的信息编码成实际的值，作用于下游的分类回归任务。解决图对齐问题基于以下两个假设：（1）相对节点具有类似属性（2）相同节点的邻居相同。GCNs结合了属性信息和结构信息，文中方法使用GCN将信息转换到低维向量空间中，相似的节点在该空间中编码也想似。</p>
<p>一个GCN模型包含多个层，第l层的输入是一个nxd(l)的特征矩阵，其中n是图中节点个数，d(l)是第l层的特征数。第l层的输出是通过图卷种计算出的矩阵：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-0711f6abbc6529c3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中
σ是激活函数，A是nxn的邻接矩阵，用于描述图的连通性，A<sup>=A+I，它加入了单位矩阵I，I描述了节点自身的连通性；D</sup>是度矩阵，参数W(l)是d(l)xd(l+1)的参数矩阵，用于第l层输出向l+1层转换。</p>
<h4 id="结构和属性嵌入">结构和属性嵌入</h4>
<p>文中方法将不同图中的节点映射到同一向量空间，为了利用节点的结构和属性信息，在两个角度对齐了向量。h是每一层输出的特征向量，结构向量hs(0)被随机初始化，在训练过程中更新；属性向量ha(0)也在训练过程中更新。H是所有向量的表示。W是训练得到的参数。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-fa08c58d057db3ff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>公式中的[ ; ]
表示concat连接两个矩阵；激活函数使用ReLU(.)=max(0,.)。</p>
<h4 id="模型设置">模型设置</h4>
<p>文中方法使用了两层GCN，每层处理一个图产生它的实体嵌入，对两个图分别生成GCN1和GCN2，描述实体的结构向量均使用ds作为其维度，两个模型共享参数矩阵Ws。对于实体的属性特征，输出特征的维度为da，由于两个图的特征个数不同，两个模型的输入属性特征不同，维度也不同。因此，第一层将属性转换成同一维度da（矩阵W不同），第二层属性GCN输出为同一维度da。</p>
<p>表-1展示了各数据的维度：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-958d4cb23883557e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="计算邻接矩阵">计算邻接矩阵</h4>
<p>在GCN模型中，邻接矩阵A被用于卷积计算。与无向图不同的是，当前图包含多种关系。因此，重新定义了A：aij
∈A，aij是实体i传播到实体j的程度，通过不同的关系连接的实体，等价的概率也不同（比如关系：父母和朋友）。因此对每种关系计算了两种量度：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-8d779169fe5e95c1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中 <code>#Triples_of_r</code> 是包含关系r的三元组个数；
<code>#Head_Entities_of_r</code> 和 <code>#Tail_Entities_of_r</code>
是头/尾实体和关系r同时存在的个数。用它来描述第i个实体对第j个实体的影响，以计算邻接矩阵：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d3e0f54297190f34.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>它同时反应了正向和反向的强度。举例如下：</p>
<p>例一：父子关系</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-1ccc0e1485428d28.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>李大与李二：<br />
<span class="math display">\[  
\begin{aligned}  
&amp; fun=\frac{1}{4} \\  
&amp; ifun=\frac{1}{4} \\  
&amp; a_{ij}=\frac{1}{4}+\frac{1}{4}=0.5  
\end{aligned}  
\]</span><br />
张大与张三：<br />
<span class="math display">\[  
\begin{aligned}  
&amp; fun=\frac{3}{4} \\  
&amp; ifun=\frac{1}{4} \\  
&amp; a_{ij}=\frac{3}{4}+\frac{1}{4}=1  
\end{aligned}  
\]</span></p>
<p>例二：朋友关系<br />
（为简化对比，假设朋友关系是有向图，实际并不是）</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a588d3f261d34942.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><span class="math display">\[  
\begin{aligned}  
&amp; fun=\frac{2}{12} \\  
&amp; ifun=\frac{1}{12} \\  
&amp; a_{ij}=\frac{2}{12}+\frac{1}{12}=0.25  
\end{aligned}  
\]</span><br />
总之：某种关系出现越少，对它所连接的实体影响越大(类似TF/IDF)。比如父子关系出现少影响大，朋友关系出现多影响小。</p>
<h3 id="对齐预测">4.2 对齐预测</h3>
<p>实体对齐基于两个图GCN输出结果的距离。<strong>设图G1中实体为ei，G2中实体为vj</strong>。计算距离：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-b21f09341e79dddd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中f(x,y)是1范数（向量元素绝对值之和），hs和ha是实体的结构嵌入和属性嵌入，ds和da是输出维度，β是用于衡量结构和属性的超参数。</p>
<p>实体越相似，距离越近。计算G1中ei与G2中所有实体的距离，排序后返回相似度最高的实体作为对齐的候选项。G2向G1对齐也是同理（方向不同结果不同）。</p>
<h3 id="模型训练">4.3 模型训练</h3>
<p>使用种子S来训练GCN模型，最小化基于边际的排序损失函数：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-cacd581535bc077e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中[x]+=max{0,x}，S'是由e或v随机替换得到的负例，f用于计算距离，γs,γa
&gt;
0是超参数，用于提升对齐的效果，它是理想的正例和负例之间的距离（正例至少要比负例大γ，loss才能等于0）。<br />
Ls和La分别是结构和属性的损失函数，二者相互独立，也分开优化，具体方法使用随机梯度下降。</p>
<h2 id="实验">5. 实验</h2>
<h3 id="数据集">5.1 数据集</h3>
<p>DBP15K是由Sun等2017年构建的，基于DBpedia的多语言对齐数据集，包含：中文，英文，日文，法文。每组数据包含两种语言15K个实体的对齐，用于训练和测试。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-3b647dba1f8c9767.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="实验设置">5.2 实验设置</h3>
<p>使用JE，MTransE，JAPE，JAPE'(不预对齐关系和实体)作为对比基线，30%作为训练集，70%作为测试集。</p>
<p>Hits@k指的是正确对齐的实体排在前k个候选实体中的比例。</p>
<p>超参数设置成输出维度ds=1000，da=1000， γs = γa = 3， 计算距离时的 β
设为经验值0.9（关系占90%，属性占比10%）。</p>
<h3 id="结果">5.3 结果</h3>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-b381ad199e5bf397.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>（图太长，截了一部分）<br />
其中关键字：SE w/o
neg是无负例的结构三元组，SE是结构三元组，AE是属性三元组。</p>
<h4 id="gcnse与gcnseae">GCN(SE)与GCN(SE+AE)</h4>
<p>可以看到加入属性三元组后，效果提升范围在1%-10%之间。这说明对齐主要依赖结构信息，而属性信息也很有用，文中结合二者的方法也是有效的。</p>
<h4 id="gcnseae-与基线">GCN(SE+AE) 与基线</h4>
<p>在中英互译的评测中JAPE有明显优势，GCN结果与之很相近。需要注意的是JAPE使用了额外的信息（词嵌入），而文中模型未使用这些先验知识，JAPE'在未使用先验知识的情况下效果就差了很多。而另两个数据集中，文中模型效果更好。相对JE和MTransE效果明显提升。</p>
<h4
id="gcn与jape使用不同量的训练数据">GCN与JAPE使用不同量的训练数据</h4>
<p>用预对齐实体作为种子，直觉上训练样本越多，效果应该越好。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-e421d9b021e709f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>图二展示了取10%-50%作为训练集对比Hits@1，JAPE和GCN模型效果，除了图-2(a)中英文训练集超过40%的情况，其它GCN均优于JAPE。</p>
<h2 id="总结和未来工具">总结和未来工具</h2>
<p>GCN方法使用了结构和属性三元组，在各个数据集上表现都较好。<br />
未来将探索更多基于GCN的方法，比如 Relational GCNs， Graph Attention
Networks；以及在文中框架上迭代地发现新的实体对齐。</p>
]]></content>
      <tags>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>异常检测综述</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/10_%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<p>英文题目：Anomaly Detection : A Survey<br />
中文题目：异常检测综述<br />
论文地址：https://readpaper.com/paper/2122646361<br />
领域：异常检测<br />
发表时间：2009<br />
作者：VARUN CHANDOLA等，明尼苏达大学<br />
出处：ACM Computing Surveys<br />
被引量：11797（谷歌学术）</p>
<h2 id="读后感">1 读后感</h2>
<p>一篇典型的综述文章，快速了解异常检测的定义，用途，方法……发表时间比较早，是机器学习异常检测方法的总结。正文50多页，比较长。</p>
<h2 id="介绍">2 介绍</h2>
<p>文章根据方法对异常检测分类，对于每个类别，提供一个基本的异常检测技术，然后展示该类别中新技术与基本技术的差异，此类技术的优缺点及计算复杂度。</p>
<p>异常一般包含：异常(anomalies)、离群点(outliers)、不一致的观察结果(discordant
observations)、特例(exceptions)、畸变(aberrations)、意外(surprises)、特性(peculiarity)或污染(contaminants)。其中又以异常和离群点最为常见。</p>
<p>异常检测的应用领域包含：信用卡、医疗保险的欺诈检测，网络安全的入侵检测，关键系统的故障检测，监视敌人军事活动等。异常检测用于识别这些问题，并做出对应的行动。</p>
<h3 id="何为异常">2.1 何为异常</h3>
<p>异常检测是指在数据中发现不符合预期行为的模式。比如图-1中的o1,o2,o3不在正常的区域N1,N2内，它们都是异常点：<br />
<img src="/attachments_2022/Pasted%20image%2020221030152635.png"
alt="Pasted%20image%2020221030152635.png" /><br />
异常检测与去噪 (noise removal) 和噪声调和(noise accommodation)
关注的问题相似，但目标不同。去噪是想从数据中去掉异常数据，噪声调和是让模型更健壮，对异常免疫；而异常检测所感兴趣的是识别出异常数据。另外，与之相似的还有新颖点检测(novelty
detection)，它的目标是检测出之前数据中未被发现的模型。</p>
<h3 id="挑战">2.2 挑战</h3>
<p>异常检测的目标是检测不属于正常区域的数据，它面临如下挑战：<br />
*
正常范围包含每种正常行为，很难定义，且正常异常之间的边界也不好精确划分。<br />
* 恶意攻击时，异常行为常常将自己表现得像正常行为。<br />
* 在不断发现的领域，当前的正常行为，未必能满足未来的需要。<br />
* 由于数据分布不同，同一技术不一定能直接应用另一领域的异常检测。<br />
* 没有足够的打标签数据。<br />
* 数据中包含噪声常常与异常值相似，噪声难以识别和消除。</p>
<p>常用的异常检测方法包括：统计方法，机器学习，数据挖掘，信息理论，光谱理论等且需要将它们应用于不同领域，如图-2所示：<br />
<img src="/attachments_2022/Pasted%20image%2020221030154829.png"
alt="Pasted%20image%2020221030154829.png" /></p>
<h3 id="相关工作">2.3 相关工作</h3>
<p>此处对比了本文和另外一些综述性文章和书籍，如下表所示，其中序号1表示本文：<br />
<img src="/attachments_2022/Pasted%20image%2020221030155136.png"
alt="Pasted%20image%2020221030155136.png" /></p>
<h3 id="本文贡献">2.4 本文贡献</h3>
<p>之前文章大多讨论单个领域的异常检测，文章讨论了异常检测在各个领域的应用。文中主要讨论了常用的6种技术（在第4-9部分详述），针对每种技术提出了基本方法，改良方法，优缺点，计算复杂度等；列出了每个应用领域中所应用的技术列表；另外，还区分了简单异常和复杂的异常（与上下文相关或集体异常）。</p>
<h3 id="文章组织方式">2.5 文章组织方式</h3>
<p>文章组织方式如图-2所示分成三块：<br />
第2部分介绍了异常检测的输入输出分类等各个方面的丰富和复杂性；第3部分介绍了不同领域的异常检测；第4-9部分介绍了具体的几种建模技术；第10-11介绍了上下文异常和集体异常检测；第12-13部分是总结展望和结束语。</p>
<h2 id="异常检测的各个方面">3 异常检测的各个方面</h2>
<h3 id="输入数据">3.1 输入数据</h3>
<p>一般数据可能包括：对象，记录，点，向量，模式，事件，案例，样本，观察结果，实体等等。每个实例可能包含一个或多个特征，特征又分：布尔型，类别型及连续型。<br />
数据需要与检测方式匹配，比如假设检验对不同数据类型使用不同方法；最近邻方法需要特征间的距离是可以度量的；数据还可以根据相似度进行分类；数据实例之间还可能存在线性排序关系，比如时间，空间序列，基因组序列，蛋白质序列等。</p>
<h3 id="异常的类型">3.2 异常的类型</h3>
<p>异常一般分为以下三类：</p>
<h4 id="点异常">3.2.1 点异常</h4>
<p>这是最简单的情况，如果一个点与其它点不同，则为点异常，比如图-1中的o1,o2。</p>
<h4 id="上下文异常">3.2.2 上下文异常</h4>
<p>上下文异常也叫条件异常，实例一般包含两组特征：<br />
*
上下文特征：用于描述实例上下文（邻居）的情况，比如空间中经度纬度邻近的特征，时间序列中之前之后时间的特征等。<br />
* 行为特征：用于描述与上下文无关的主体本身的特征。<br />
由于上下文的差异，同样的行为有时被认定为正常，比如图-3中的t1点，而t2点被认为异常。<br />
<img src="/attachments_2022/Pasted%20image%2020221030165507.png"
alt="Pasted%20image%2020221030165507.png" /></p>
<h4 id="集体异常">3.2.3 集体异常</h4>
<p>数据是否异常取决于相关数据实例的集合，如图-4中的心电图数据：<br />
<img src="/attachments_2022/Pasted%20image%2020221030165759.png"
alt="Pasted%20image%2020221030165759.png" /><br />
这里的1000-1500中的多个实例组合被识别成了集体的异常。集体异常也常常出现在时间序列，空间序列，图片数据检测中。</p>
<h3 id="给数据打标签">3.3 给数据打标签</h3>
<p>给训练集中的每个实例打标签：是/否为异常数据，常需要专家进行标注，人工标注代价比较高；通常需要获得各种类型的异常实例，比获得正常实例困难得多；数据常常动态变化，新的异常不断出现；另外很多数据非常少，难以获取，比如空难数据。<br />
由于上述问题异常标注分为三种模式：</p>
<h4 id="有监督的异常检测">3.3.1 有监督的异常检测</h4>
<p>有监督异常检测需要对全部训练集进行标注，检测方法通常是建立预测模型，这与一般预测模型相似，文中不详细讨论。它有两个主要问题：第一个问题是异常数据相对正常数据一般很少，这造成了数据偏斜，增加了建模难度；第二个问题是获取准确和有代表性的异常标签常常具有挑战性，因此，也有人提出了一些技术向数据集中注入人工异常数据。</p>
<h4 id="半监督的异常检测">3.3.2 半监督的异常检测</h4>
<p>只标注训练数据中的正常实例，由于不需要异常类别的标签，因此它们比监督技术更适用，比如飞行器发生异常就是重大事故，也就是说训练数据中可能不包含各种类型的异常数据。常用方法是为正常行为建模，并使用该模型来识别测试数据中的异常。</p>
<h4 id="无监督的异常检测">3.3.3 无监督的异常检测</h4>
<p>不需要训练数据，用途更广泛。它背后的假设是正常实例比异常实例多很多，如果不满足这个假设，则会产生大量误报警。</p>
<h3 id="异常检测的输出">3.4 异常检测的输出</h3>
<p>典型的输出一般包含两种类型：</p>
<h4 id="打分">3.4.1 打分</h4>
<p>为测试集中每个实例计算异常评分，它取决于该实例的异常程度。有些模型输出异常度排序列表；分析人员通过设定阈值来判定是否为异常。</p>
<h4 id="打标签">3.4.2 打标签</h4>
<p>为每个测试集中实例打标签：是/否异常。</p>
<h2 id="异常检测的应用">4 异常检测的应用</h2>
<p>（本部分每小节都包含具体方法相关的论文列表，数据太多，请见原文）<br />
对于每种应用场景从四方面讨论：<br />
* 异常的概念<br />
* 数据的性质<br />
* 面对的挑战<br />
* 检测方法</p>
<h3 id="入侵检测">4.1 入侵检测</h3>
<p>入侵检测针对计算系统的恶意行为。<br />
面对的挑战是数据量大，需要高效的异常检测，常常需要处理数据流，另外还需要防止大量误报警。<br />
数据难以标注，主要使用半监督和无监督方法。<br />
入侵一般分为主机入侵和网络入侵。</p>
<h4 id="基于主机的入侵">4.1.1 基于主机的入侵</h4>
<p>针对基于主机的入侵，主要使用根据系统调用的方法；入侵包含未经授权的行为和违反规则，事件共发是检测异常的关键因素，另外可以在不同层级（程序级、用户级）分析数据。一般情况下，使用序列数据建模，对点建模也比较少。</p>
<h4 id="基于网络的入侵">4.1.2 基于网络的入侵</h4>
<p>常见的异常是点异常，也有集合异常的情况，攻击一般由黑客发起，通过获得未经授权的访问网络的权限，目的是窃取信息或破坏网络。检测系统针对不同粒度的数据检测。另外面临的挑战还包括黑客不断变换攻击行为，以逃避被识别。</p>
<h3 id="欺诈检测">4.2 欺诈检测</h3>
<p>欺诈检测是指对银行、信用卡公司、保险公司、手机公司、股票市场等商业组织中的犯罪活动进行侦查，以避免经济损失。下面介绍一些具体应用：</p>
<h4 id="信用卡欺诈">4.2.1 信用卡欺诈</h4>
<p>检测欺诈性信用卡申请或信用卡盗用，检测信用卡申请类似于检测保险欺诈。<br />
数据通常由多个维度定义的记录组成，如用户ID、消费金额、连续使用卡片的间隔时间等。欺诈通常反映在交易记录中(点异常)。<br />
信用公司有完整的数据，也有标记记录。<br />
基于概要分析和聚类的技术通常用于该领域。<br />
挑战是它需要即时在线检测，一种方法是使用当前数据与该用户的历史数据比较，该方法需要频繁访问数据库；另一种方法通过检测地理位置，都可归于检测上下文异常的方法。</p>
<h4 id="手机电话欺诈">4.2.2 手机电话欺诈</h4>
<p>手机欺诈检测是典型的活动监控问题。任务是扫描大量的帐户，检查每个帐户的呼叫行为，并在帐户似乎被滥用时发出警报。<br />
可以按时间聚合，或按用户或区域进行聚合。这些异常现象包含大量的呼叫或呼叫不可达的目的地。</p>
<h4 id="保险索赔欺诈">4.2.3 保险索赔欺诈</h4>
<p>该域中的可用数据为索赔人提交的文件，从这些文档中提取不同的特征。人工调查的案例被监督和半监督技术作为标记实例用于保险欺诈检测。保险索赔欺诈检测通常是作为一个通用的活动监控问题处理的，也使用基于神经网络的技术。</p>
<h4 id="内幕交易检测">4.2.4 内幕交易检测</h4>
<p>内幕交易发生在股票交易市场中，即信息公开前利用内部信息非法获利。常
通过识别异常的交易活动来识别，数据源包含：如期权交易数据，股票交易数据，新闻。数据有连续关联。挑战是需要以在线方式尽早发现欺诈行为。</p>
<h3 id="医学与公共卫生异常检测">4.3 医学与公共卫生异常检测</h3>
<p>医疗和公共卫生领域的异常，包含患者状况异常或仪器错误或记录错误，疾病爆发等。该领域检测对精度要求很高。数据通常由记录组成，这些记录可能包含几种不同类型的特征。主要针对异常记录（点异常）检测，可用的数据常属于健康患者，因此常用半监督学习；其中还包含一些时序数据如心/脑电图，使用集体异常检测。</p>
<h3 id="工业设备损伤检测">4.4 工业设备损伤检测</h3>
<p>主要指尽早发现工业设备的损坏。数据常常为各种不同传感器的记录数据，又细分为以下两个领域：</p>
<h4 id="机械设备故障">4.4.1 机械设备故障</h4>
<p>检测可能是由于磨损或其他不可预见的情况而发生的缺陷。数据常具有时间特征，有时使用时序方法或集体异常检测。相对而言，正常数据更容易获得，因此常用半监督方法。挑战是需要尽快发现异常以采取措施。</p>
<h4 id="结构缺陷">4.4.2 结构缺陷</h4>
<p>缺陷检测用于如梁的裂缝，机体的应变。数据也常具有时间性质，通过检测数据变化，时间空间相关性来计算。</p>
<h3 id="图像处理">4.5 图像处理</h3>
<p>处理图像的异常检测技术包含：对运动的检测，图像上的异常的区域检测，卫星图像，数字识别，光谱学，分析x线影像，和视频监控等。数据具有时空特征。像素点往往有连续的颜色，亮度，纹理等。主要挑战是输入的数据量大，有时需要对视频进行实时处理。</p>
<h3 id="文本数据异常检测">4.6 文本数据异常检测</h3>
<p>针对文档或新闻文章中的新主题、事件或新闻检测。异常是由新的事件或异常主题引起的。该领域的数据通常是高维且非常稀疏的。且有时效性，因为文档是随着时间收集的。主要面临的挑战是处理数据随时间大量变化。</p>
<h3 id="传感器网络">4.7 传感器网络</h3>
<p>传感器网络指从各种无线传感器收集数据。传感器检测包含故障检测和入侵检测。数据可能包含：二进制、离散、连续、音频、视频等。由于资源的限制，异常检测技术需要实现轻量级化，也可能分布式处理，另外，处理噪声和缺失值也是一个挑战，需要区分
噪声和异常。</p>
<h3 id="其它领域">4.8 其它领域</h3>
<p>异常检测还被用于，语音识别，机器人行为中，流量监控，点击通过保护，检测web应用程序中的故障，检测生物数据中的异常，检测人口普查数据中的异常，检测犯罪活动之间的关联，检测客户关系管理(CRM)数据中的异常，检测天文数据中的异常和检测生态系统干扰等。</p>
<h2 id="基于分类的异常检测">5 基于分类的异常检测</h2>
<p>分类方法用于有监督学习，需要有标注的训练集，一般分为训练模型和代入实例测试两个阶段。<br />
该方法基于以下假设：<br />
<em>基于给定特征，可以训练能够区分正常类和异常类的分类器。</em><br />
分类器进一步又可分为单分类（如图6-b，主要学习正常和异常的边界）和多分类（如图6-a，多个正常类别，加一个异常类别），有的模型可以给出置信度得分，如果属于哪一类的置信度都不高，则认为是异常类别。<br />
<img src="/attachments_2022/Pasted%20image%2020221101170434.png"
alt="Pasted%20image%2020221101170434.png" /></p>
<h4 id="神经网络分类器">5.1.1 神经网络分类器</h4>
<p>神经网络分类器可用于单分类和多分类。自编码器（Replicator Neural
Networks）是2002年提出的，它用于实现单分类，它是多层的前馈网络，其输入和输出层元素个数相同，训练阶段将数据通过隐藏层压缩再还原，测试时代入xi，输出oi，如果xi与oi足够相似，则认为正常，否则为异常：<br />
<img src="/attachments_2022/Pasted%20image%2020221101183059.png"
alt="Pasted%20image%2020221101183059.png" /><br />
其中n是特征个数，误差δi是用于判断x与o相似度的得分。</p>
<h4 id="贝叶斯网络">5.1.2 贝叶斯网络</h4>
<p>贝叶斯网络一般用于多分类任务，其基本方法是针对单个变量的朴素贝叶斯
，后验概率最大的作为类别标签。从训练集中计算类先验和测试数据属于各类的可能性，如果概率为0，则认为异常。该方法可推广到多元数据集。需要注意的是该方法变量之间是无关的，后来又发展出一些改进方法来解决变量依赖问题。</p>
<h4 id="支持向量机">5.1.3 支持向量机</h4>
<p>支持向量机用于单分类任务，用它学习一个包含正例的区域，它的核可以学到对复杂区域的表示。如果测试集实例落入区域则认为正常，否则为异常。其中一种变体是找到包含所有训练数据超球，然后判断测试数据在超球的内外。</p>
<h4 id="基于规则的方法">5.1.4 基于规则的方法</h4>
<p>基于规则的方法用于寻找正例的行为规则，如果测试集不符合任意一条规则，则认为异常。规则方法可用于单分类和多分类任务。<br />
在多分类时，先用训练数据学习规则，如使用决策树，RIPPE等方法，每个规则都有一个置信度；测试数据找到最匹配的规则，并将其置信度的倒数作为异常得分。<br />
关联规则是一个比较重要的方法，常用于单分类方法，通过无监督的方式从训练数据中挖掘规则，支持度的阈值用于对规则剪枝。He等2004年提出了一种方法，将规则的频繁项集个数作为测试集的异常得分。</p>
<p><strong>计算复杂度</strong><br />
分类方法的复杂度视具体方法不同，一般情况下，决策树方法比较快，包含二次优化的SVM相对慢（也有改进优化方法）。由于分类方法会训练出模型，在将测试数据代入模型，而非当场计算，所以预测较快。</p>
<p><strong>优点</strong><br />
* 多分类器可以区分实例所属类别。<br />
* 预测速度快。</p>
<p><strong>缺点</strong><br />
* 往往没那么多标注数据用于训练<br />
* 一般情况下结果为标签的值，不过也有一些算法输出概率。</p>
<h2 id="基于最近邻的异常检测">6 基于最近邻的异常检测</h2>
<p>该方法基于如下假设：<br />
<em>正常数据出现在密集的区域中，异常数据与正常数据间隔比较远。</em><br />
最近邻是基于距离的算法，如何衡量距离也比较重要。对于连续型数据，一般使用欧式距离，对于分类变量常使用匹配系数或更加复杂的方法。对于多维变量，会结合各个维度的结果。最近邻方法一般分为以下两类：</p>
<h3 id="基于距离的-knn">6.1 基于距离的 KNN</h3>
<p>实例的异常得分取决于距其最近K个实例的距离（或相似度）K根据情况设置，有时设置为1。然后使用一个阈值定义正常与否；也可以选择异常得分最高的前几个作为异常；还可以选择不同的方法计算距离以实现优化；另外，提升计算效率也是一个优化的方向。</p>
<p>最基本的方法是对与实例最近的K个邻居的距离加和，后来还发展出，计算与实例距离在d以内的邻居个数n，它相当于在实例附近做了一个半径为d的超球体，其密度可视
为n/πd^2，其密度的倒数可视为异常得分，即：它周围邻居越少，越可能异常。</p>
<p>一般数据都是连续型，之后也有一些针对于其它类型变量的优化，比如对类别变量使用超图方法计算；以及结合连续型和分类型的距离计算方法；对于分类属性，两个实例具有相同值的属性的数量定义了它们之间的距离，对于连续属性，维护协方差矩阵以捕获连续值之间的依赖关系。</p>
<p>提升效率的方法，有些方法通过忽略肯定异常或肯定非异常的数据消减搜索空间；基于分区和聚类的减枝方法；以及通过下采样提升效率。为了消减搜索空间，有些算法将搜索空间切分成固定大小的立方体组成的超网格，如果一个立方体中实例较多，则认为正常，否则为异常……</p>
<h3 id="基于密度的方法">6.2 基于密度的方法</h3>
<p>基于密度的方法主要计算实例邻居的密度，密度高则认为正常，否则为异常。一个实例的k个最近邻可构成一个超球体，球心为该实例，球里包含k个近邻。到第距离第k个实例的距离的倒数可被视为密度，即k个近邻离它越近，密度越大。</p>
<p>基于密度的基本方法也有些问题，比如图-7中，由于C1中密度低，因此其中很多点间的距离都大于p2到C2间的距离，如果以C1的密度为标准，则p2被视为正常，如果以C2为标准，位于C1中的实例认为异常。<br />
<img src="/attachments_2022/Pasted%20image%2020221102163010.png"
alt="Pasted%20image%2020221102163010.png" /></p>
<p>为解决数据集中密度不同的问题，使密度只与近邻相关，出现很多改进方法，其中使用最多的是LOF(Local
Outlier
Factor)及其变种。LOF的核心是找到局部密度，LOF分数等于实例的k个最近邻居的平均局部密度与数据实例本身的局部密度之比。之后还有一些方法，对本地密度(COF)，其它变量类型(PST)，及效率进行改进。</p>
<p><strong>计算复杂度</strong><br />
最近邻的基本方法需要为每个节点找近邻，O(N^2)的复杂度，上述方法很多着重提升效率，但各有不同的适用范围。如使用超网络在特征数量大时不适用；抽样技术在样本较少时不适用等。</p>
<p><strong>优点</strong><br />
* 这是一种无监督方法，不对分布进行假设，完全是数据驱动的<br />
* 半监督学习相对于无监督学习在遗漏检测中效果更好。<br />
* 可用于不同类型特征的检测，但需要定义好距离计算方法。</p>
<p><strong>缺点</strong><br />
*
算法基于距离，如果正常实例没有太多邻域，或者异常数据有很多邻居则会无效。<br />
* 如果测试集中的正常数据在训练集中没怎么见过，则假阳率很高。<br />
* 在数据量大的情况下，计算效率是一个严重问题。<br />
* 如何定义距离函数是一个挑战，尤其对于图片，序列等数据。</p>
<h2 id="基于聚类的异常检测">7 基于聚类的异常检测</h2>
<p>聚类是将类似的数据分成不同的簇。聚类是一种针对无监督数据的研究方法，基于聚类的方法一般分为三种<br />
* 第一种方法基于以下假设：<br />
<em>正常数据属于聚类中的某一个簇，异常数据不属于任何簇</em><br />
这种方法包含：DBSCAN，ROCK，SNN，FindOut等，这种方法
的问题是它没有对异常数据进行调优。<br />
* 第二种方法基于以下假设：<br />
<em>正常数据离簇心近，异常数据离簇心远</em><br />
该方法分两步，第一步对训练数据聚类，第二步根据每个实例距离质心的远近计算异常得分，从而在训练集中定位一些异常数据。这种方法包括：SOM，KMeans，EM等，其中SOM应用比较广。该方法也可以用于半监督数据，用<strong>标签改进聚类（判断同一类别中的标签的一致程度）</strong>。如果异常数据单独成簇，则上述方法不可用，于是提出第三种方法.<br />
* 第三种方法基于以下假设：<br />
<em>正常数据属于大而密集的入簇，异常数据属于小而稀疏的簇</em><br />
该方法包括：FindCBLOF，CBLOF获取实例所属的集群的大小，以及数据实例到其集群中心的距离作为得分。还有一些改进聚类效率的方法。</p>
<h3 id="聚类和k近邻的区别">7.1 聚类和K近邻的区别</h3>
<p>由于聚类大多也是基于计算距离的，所以K近邻的一些距离计算方法也可以在聚类中使用。不同的是聚类基于所在的簇进行分析，最近邻基于实例的邻居分析。</p>
<p><strong>计算复杂度</strong><br />
训练的复杂度取决于聚类算法。如果聚类需要计算所有数据实例的成对距离，具有二次复杂度；如果使用基于启发式的技术，如k-means或近似聚类技术，则具有线性复杂度。测试阶段速度快，它只涉及测试实例与少量集群进行比较。</p>
<p><strong>优点</strong><br />
* 可以在无监督数据中使用<br />
* 普通的聚类方法也可以处理复杂数据<br />
* 测试实例预测快。</p>
<p><strong>缺点</strong><br />
* 高度依赖聚类算法捕捉正常数据的有效性<br />
* 算法必须满足相应的假设（上述三种假设）<br />
* 计算复杂度高</p>
<h2 id="基于统计的异常检测">8 基于统计的异常检测</h2>
<p>基于统计的方法基于以下假设：<br />
<em>正常数据出现在随机模型的高概率区域，而异常发生在低概率区域。</em><br />
模型基于统计方法，判断之前没见过的数据是否属于该模型产生的数据，包含参数方法和非参数方法。</p>
<h3 id="参数方法">8.1 参数方法</h3>
<p>参数方法基于的假设是数据符合基于参数Θ的分布，f (x,
Θ)是概率密度函数，x是训练集中的观测值，Θ是通过x学到的，测试集中的异常分数是f的倒数。另外，也可以用假设检验的方法判断x是否为异常。基于分布的类型，参数方法又可细分如下：</p>
<h4 id="基于高斯分布">8.1.1 基于高斯分布</h4>
<p>假设数据服从高斯分布，参数通过最大似然估计计算，将x与估计均值的距离作为异常得分，然后用阈值判断是否异常。不同的技术使用不同的阈值和距离计算方法。常使用标准差的3倍作为阈值，如果服从高斯分布，μ
± 3σ 能包含
99.7%实例。另外，也常用箱图分位数的方法检测异常值（IQR）。常用分位数的1.5倍作为阈值，Q1
− 1.5IQR and Q3 + 1.5IQR 一般包含 99.3%的实例，QR=Q3-Q1。<br />
格拉布斯检验(Grubbs
Test)，也叫最大归一化残差检验，常用于检测单变量的异常值，对于测试集中的x计算其z得分：<br />
<img src="/attachments_2022/Pasted%20image%2020221103172812.png"
alt="Pasted%20image%2020221103172812.png" /><br />
其中上划线x是均值，s是标准差，当z大于以下值时，则认为异常。<img
src="/attachments_2022/Pasted%20image%2020221103173003.png"
alt="Pasted%20image%2020221103173003.png" /><br />
其中N是数据量，t是阈值。之后有人把它推广到多变量检测中。<br />
学生T-检验也是常用于高斯分布的检测方法（使用前需要先确定数据服从高斯分布），它用于判断训练集和测试集是否属于同一分布。扩展到多变量的t检验是t^2-test。</p>
<p>X<sup>2统计用于检测系统调用异常，训练阶段假设正态数据具有多元正态分布，X</sup>2定义如下：<br />
<img src="/attachments_2022/Pasted%20image%2020221103173640.png"
alt="Pasted%20image%2020221103173640.png" /><br />
其中Xi是观测值，E是期望值，n是变量个数，当X^2很大时，则认为包含异常数据。</p>
<h4 id="基于回归模型">8.1.2 基于回归模型</h4>
<p>在时间序列的异常检测中常使用回归方法。一般分为两步，第一步用训练数据训练模型参数，第二步计算测试集数据与模型的残差，通过差异大小判断是否异常。<br />
在回归过程中，异常数据可能影响回归参数，因此提出了稳健回归（Robust
regression），通过判断残差的大小，它不仅可以忽略异常，还能定位异常，ARIMA方法与之类似。基于回归的改进主要包括：对多元时间序列的检测。</p>
<h4 id="基于参数分布的混合">8.1.3 基于参数分布的混合</h4>
<p>基于参数分布的混合使用参数统计分布来对数据建模。又分为两类：<br />
第一类是分别对正常实例和异常实例建模，在测试阶段分别判断实例是属于正常模型还是异常模型，比如假设正常集和异常集都服从高斯分布，且均值一致，但异常集的标准差更大；还有一些迭代计算的方法。<br />
第二种方法把正常数据视为多种高斯分布的混合，如果测试数据不属于其中任何的高斯分布，则认为它是异常数据。</p>
<h3 id="非参数方法">8.2 非参数方法</h3>
<p>模型结构不是由先验定义的，而是由给定数据确定的。这种技术通常对数据做较少的假设。</p>
<h4 id="基于直方图">8.2.1 基于直方图</h4>
<p>使用直方图描述正常数据，这种方法也被称为基于计数或频率的技术。它能很好地统计识别入侵和诈骗行为。最简单的单变量检测方法分成两步，首先，使用训练集统计直方图，然后检测测试集中数据是否落入其中，以判别其是否为异常；也利用将其落入柱的高度来计算异常分值的；箱的个数是一个重要超参数。之后有一些改进，对异常值也用直方图描述。<br />
在多变量的情况下，可以对每个属性计算直方图，及异常分值，然后聚合各个分值。</p>
<h4 id="基于核函数">8.2.2 基于核函数</h4>
<p>概率密度估计的一种非参数技术，它使用核函数来近似实际密度，类似于前面描述的参数化方法，区别是使用的密度估计技术。另外，还可用半监督统计技术来检测异常，该技术使用核函数来估计正常实例的概率分布函数，位于低概率区域的一个实例被视为异常。</p>
<p><strong>计算复杂度</strong><br />
基于统计技术的复杂视具体方法不同，拟合单参数分布，计算高斯、泊松、多项式等，常在数据大小和属性数量上是线性的。使用期望最大化(EM)等迭代方法，每次迭代通常也是线性的，收敛可能较慢。基于内核的技术具有与数据大小相关的二次型时间复杂度。</p>
<p><strong>优点</strong><br />
* 当数据满足分布的假设时，统计技术是很好的方案。<br />
* 异常评分与置信区间相关，在进行决策时，可以将其作为附加信息。<br />
*
如果方法对数据中的异常是稳健（容错）的，则可使用无监督数据训练模型。</p>
<p><strong>缺点</strong><br />
*
使用上述方法前需要先验证数据是否满足对应假设，而现实中的数据大多是不满足的高维数据。<br />
* 为复杂分布构造假设检验，选择检验方法难度大。<br />
*
基于直方图的方法难以处理多维数据，数据可能在单个维度上是高频的，但组合后低频异常。</p>
<h2 id="基于信息理论异常检测">9 基于信息理论异常检测</h2>
<p>信息理论技术利用复杂度、熵、相对熵等来分析数据集的信息内容。<br />
该方法基于以下假设：<br />
<em>异常数据会导致数据集的信息内容不正常。</em><br />
设D是数据集，C(D)是它的复杂度，求取最小的子集I，使得C(D)-C(D-I)取得最大值，也就是说去掉混乱的数据I，它可能没有单一的最优解。主要的技术在于如何选用不同的C来衡量复杂性。</p>
<p>上述方法一方面需要考虑子集的大小，一方面需要考虑复杂性，它需要对每种子集运行指数时间，后续提出了一些技术对最反常子集进行搜索。如局部搜索算法(LSA)，以及使用信息瓶颈度量技术。</p>
<p>该技术常被用于序列，空间，图数据的异常检测，数据被切分成小块，此技术用于检测各个小块是否异常。</p>
<p><strong>计算复杂度</strong><br />
基本的信息论方法是指数时间复杂度，有的优化方法可以提供具有线性时间复杂度的近似技术。</p>
<p><strong>优点</strong><br />
* 可以处理无监督数据。<br />
* 不需要满足条件假设。</p>
<p><strong>缺点</strong><br />
*
高度依赖于计算复杂方法的选择。通常，只有当数据中存在大量异常时，这种方法才能检测到异常的存在。<br />
* 对序列或空间操作时，需要切分数据，而切分的大小很难确定。<br />
* 难以给异常值打分。</p>
<h2 id="基于频谱的异常检测">10 基于频谱的异常检测</h2>
<p>基于频谱的异常检测利用特征组合捕捉数据的规律。<br />
它基于以下假设：<br />
<em>数据降维后，正常和异常的实体表现出更明显的不同</em><br />
将数据通过嵌入或者投影方法转换后，异常数据更容易被识别，该技术可用于半监督或无监督学习。<br />
其中主成份分析PCA是一种典型方法，转换后满足规律的正常实例的投影值较低，而偏离规律的异常实例的投影值较大，从而实现异常检测。<br />
在时序图的异常检测中，提出通过邻接矩阵的矩阵分解(CMD)得到与原始图近似的矩阵，并重建时间序列，然后在序列中检测异常。<br />
另外还有稳健PCA（robust
PCA），主成份通过正常数据的协方差矩阵得到；在预测阶段，根据转换后点到主分量的距离来判断是否为异常值。对比映射后的y值与特征值的比λ值：<br />
<img src="/attachments_2022/Pasted%20image%2020221108180932.png"
alt="Pasted%20image%2020221108180932.png" /><br />
它类似于统计方法中计算实例与样本均值的马氏距离。</p>
<p><strong>计算复杂度</strong><br />
基于PCA的技术对数据量是线性的，但对于维度是二次数。奇异值分解的技术通常对数据量为二次的。</p>
<p><strong>优点</strong><br />
*
一种降维方法，因此适用于处理高维数据，另外，它可以作为数据预处理，然后再使用其它异常检测技术。<br />
* 可用于无监督数据。</p>
<p><strong>缺点</strong><br />
* 只在正常异常数据在低维可分的情况下使用<br />
* 计算复杂度高</p>
<h2 id="处理上下文异常">11 处理上下文异常</h2>
<p>之前讨论的都是基于单点的异常检测，本节讨论基于上下文的异常检测。它首先需要定义上下文，特征一般也分为上下文特征和行为特征两部分。上下文可以定义为：</p>
<ul>
<li>空间：一般定义实例位置，然后以从空间领域中提取特征。<br />
</li>
<li>图：这里指的是图结构，结点由边相连，可从邻居（有边相连的节点）提取特征。<br />
</li>
<li>序列：数据是顺序的，并已知实例在序列中的位置，其中时序数据得到广泛研究，另外，带时间戳的事件是一种连续时间不均匀的事件。<br />
</li>
<li>概况：通常情况下，数据可能没有显式的空间或顺序结构，但仍然可以使用一组上下文属性将数据分割或聚集到组中。然后分析用户在其组内的异常情况。</li>
</ul>
<p>处理方法分为以下两类：</p>
<h3 id="简化成点异常检测问题">11.1 简化成点异常检测问题</h3>
<p>上下文异常是指实例点在上下文的条件下异常，其根本也是对点的判断，也可将上下文视作为特征。检测一般分两步：第一步把上下文转换成特征，第二步使用点异常检测方法。<br />
假设特征文可拆分成上下文特征U 和
行为特征V（点本身的特征），因此学习在U条件下V：p(Vj|Ui)，异常得分计算如下：<br />
<img src="/attachments_2022/Pasted%20image%2020221108183831.png"
alt="Pasted%20image%2020221108183831.png" /><br />
具体使用时，比如欺诈检测，将用户和时间作为上下文特征，其它特征作为行为特征，利用规则比较，以检测异常。另外，<strong>可先用标签分割数据，然后再用聚类检测异常</strong>。<br />
对于空间数据，使用位置坐标可以直接检测出领域，然后使用统计方法检测领域内的异常（局部异常）。<br />
对于时间序列，将观测值与领域值的中位数相比较；还可将时间序列转换到特征空间中，然后使用单点的异常检测方法。</p>
<h3 id="利用数据中的结构">11.2 利用数据中的结构</h3>
<p>有些情况下，无法简单划分上下文和行为，比如对于时间序列和事件序列，常使用序列模型的扩展来识别异常。<br />
一般先用训练数据建模以预测上下文中的行为，如果行为和预期明显不符，则认为异常，回归是一种常用方法。</p>
<p>对于时序数据，很多基于回归的技术如：robust regression,
auto-regressive, ARMA, ARIMR, Support Vector Regression等。</p>
<p>一种检测字母序列中单个异常的技术。将序列分为两部分，分别计算其柯尔莫戈罗夫复杂度。复杂程度高的包含异常。序列被递归地分割，直到它们只剩下一个事件，该事件被声明为序列中的异常。</p>
<p>还有一种方法，用前前N个时点预测下一个时点的行为，如果预测不正确则视为异常。这种方法被扩展到：频繁项集挖掘，有限状态自动机，马尔可夫链蒙特卡罗，它们用历史数据预测后续事件发生的概率。</p>
<p>P2P网络中的二部图结构被用来首先识别图中任何节点的邻域，然后检测该节点在邻域内的相关性。相关性评分低的节点被视为异常节点。作者还提出了一种近似技术，首将图划分为不重叠的子图,然后在其分区内计算节点的邻域。</p>
<p><strong>计算复杂度</strong><br />
对于简化成点异常的方法，其训练阶段复杂度取决于具体检测技术，切分技术相对较快，聚类或混合模型估计的技术相对较慢。测试阶段计算相对昂贵。<br />
对于利用数据结构的方法，训练阶段相对较慢，但测试阶段较快。</p>
<p><strong>优点</strong><br />
认为数据实例在一个上下文中往往是相似的（自然定义）。这种技术能够检测到从全局角度检测异常（点异常检测技术不行）。</p>
<p><strong>缺点</strong><br />
只适用于可以定义上下文的情况。</p>
<h2 id="处理集体异常">12 处理集体异常</h2>
<p>但一组实例同时发生则为异常，而其中的单独发生时可能是正常的，它相对于前两种更复杂是因为它需要探索数据结构中的异常区域。主要是识别实例间的关系，关系又包含：</p>
<ul>
<li>序列异常检测技术：典型的数据集包括事件序列数据，或数值型时间序列数据。<br />
</li>
<li>空间异常检测技术：处理空间数据，识别数据中的连接子区域是否异常（如图片）。<br />
</li>
<li>图异常检测技术：处理图数据，识别数据中的连接子图是否异常。</li>
</ul>
<h3 id="序列异常检测">12.1 序列异常检测</h3>
<p>序列的异常检测与时间和位置相关，又可分成两类，一类是序列由信号组成，另一类是连续的，如时间序列。另外，序列可以是单变量，也可以是多变量的。</p>
<h4 id="在序列集中检测异常序列">12.1.1 在序列集中检测异常序列</h4>
<p>这种方法常用于无监督数据或半监督数据。其挑战是序列不定长，测试数据无法与训练数据对齐，比如事件队列中第一个事件，刚好是另一队列的第三个事件。解决方案有以下两种：<br />
* 把序列数据转换成点数据后再处理<br />
对于定长序列，将长度为10的序列转换成10个属性向量，然后使用点异常检测技术来检测异常（如神经网络或聚类）。<br />
对于不定长序列，则把不定长的数据转换成定长的记录，比如用分箱的方式，把序列元素放入箱，把每个箱作为一个特征，然后代入模型（计算欧式距离及RIPPER方法）。<br />
还有方法直接计算不等长串之间的距。例如：计算最长公共子序列的长度作为似度量，然后后再使用聚类等异常检测技术。<br />
* 给序列建模<br />
上面方法主要用于对齐的序列，但对于事件序列，生物序列，不能使用。序列建模主要用于半监督学习，因此，需要训练数据。序列建模的主旨是根据序列建立规则，比如基于时间的归纳学习，测试集数据与所有规则对比，当无法匹配任意规则时视为异常。其中有限状态自动机（FSA）和马尔可夫序列模型最为流行。进而发展出隐马尔可夫模型，概率后缀树(PST)PST是变阶马尔可夫链的紧表示，稀疏马尔可夫树(SMT)。再将HMM序列集进行聚类，并将不属于任何聚类的任何序列检测为异常。</p>
<h4 id="检测长序列中的异常子序列">12.1.2 检测长序列中的异常子序列</h4>
<p>将序列中与其余部分不一致的部分识别为异常子序列。它检测长序列中的区域异常，常用于无监督学习，它背后的假设是正常部分有可识别的模式，而异常数据不适合这一模式，主要面临的挑战是：不能确定异常串的长度；当输入数据包含异常时，难以对正常模式建模。<br />
有一种方法使用香农的经典信息定理，先切分长序列，然后对各段编码，其中编码需要最高比特数的段被视为异常。<br />
相似的方法还有：利用窗口比较的算法，使用滑动窗口从给定的连续观察序列中提取子序列。使用基于压缩的不相似度量将每个子序列与整个序列进行比较。每个子序列的异常值是它与整个序列的不相似度。<br />
还有方法，使用滑动窗口从给定序列中提取子序列，然后计算每个子序列到原始序列中最接近的非重叠子序列的距离。子序列的异常值与它与最近邻居的距离成正比。<br />
还有最大熵马尔可夫模型，即条件随机场，预测最可能的状态序列。观测序列中的任何异常段对于任何状态序列都具有较低的条件概率。</p>
<h4 id="期望频率异常">12.1.3 期望频率异常</h4>
<p>判断某一模式出现的频率是否异常，它检测的是在测试集中出现的频率是否与训练集中出现的频率一致。比如：使用滑动窗口从给定的字母字符串中提取子字符串，他们确定子字符串相对于正常数据集中是否异常，使用后缀树（或HMM）来估计它与正常数据中字符串的预期频率的差异。</p>
<h3 id="空间异常检测">12.2 空间异常检测</h3>
<p>目标是检测子图或子组件的异常。比如检测图片中的某一部分与其余部分的差异（上下文异常），使用多元高斯随机马尔可夫场来分割图片，与之前方法不同的是它使用了空间结构。<br />
具体方法如：自底向上的子图枚举技术，分析给定图中子图的频率，以确定它是否异常（子图的大小也要考虑在内，因为大的子图必然很少出现在图中）；也有些方法测量子图的规律性或熵，与上下文相比，以确定其异常值。</p>
<h2 id="异常检测技术的相对优缺点">13 异常检测技术的相对优缺点</h2>
<p>对于不同问题，需要使用不同的异常检测技术</p>
<p><img src="/attachments_2022/Pasted%20image%2020221110145541.png"
alt="Pasted%20image%2020221110145541.png" /><br />
图-10(a)中所示正常数据呈高斯分布，异常数据稀疏且远离正常分布，且是有监督数据。第4-9节的方法都可以使用。<br />
图-10(b)中数据由多个高斯分布组成，且方差很低，由于它们均匀地分布在一个圆上，如果使用单类建模，可能识别圆外是异常区域，从而无法识别圆中的异常，使用聚类方法识别不同的类，基于多类分类的技术可能能够了解每个聚类周围的边界，或者利用最近邻方法，都可能检测到中心的异常。<br />
如图-10(c)的情况，聚类或最近邻也难以识别。</p>
<p>聚类和最近邻，难以识别高维异常；频谱技术通过将数据映射到低维投影，可解决高维问题，前提是数据降维后仍有区别。<br />
最好的情况是正负例都有标签，但很难实现，即使有标签，又难以对不均衡数据建模。对于只有正例标签的半监督数据或无监督数据，聚类可能更为有效。<br />
统计技术只在数据的维数较低和统计假设成立的情况下才有效。<br />
信息理论技术需要一种足够灵敏的测量方法，否则只能在异常数量显著足够多的情况下才能检测到异常。<br />
聚类和最近邻是基于距离的算法，因此需要找到适合的距离度量方法。</p>
<p>时间复杂度也是个重要的问题，基于分类、基于聚类和统计技术的训练时间很长，但预测通常很快。相比之下，基于最近邻的技术、信息论和光谱技术没有训练阶段，预测时间长，实际使用中可能受到限制。</p>
<p>异常检测技术通常假设，与正常实例相比，数据中的异常非常罕见。但也有例外，比如蠕虫爆发。</p>
<h2 id="结束语和今后的工作">14 结束语和今后的工作</h2>
<p>当前的异常检测没有定义具体的异常是什么，主要是依赖结构判定。因此也无法使用统一的量度来对比不同的方法。未来上下文和集体异常检测技术在将发现越来越多的适用性；分布式位置的数据的存在促进了对分布式异常检测技术的需求；随着传感器网络的出现，也需要检测更具实时及在线检测技术，及增量地更新模型；在复杂的系统中异常检测涉及到建模不同组件之间的相互作用。</p>
<p><strong>核心：建立模型，把其中少量没法建模的视为和其它不同的”异常“。</strong></p>
]]></content>
      <tags>
        <tag>异常检测</tag>
      </tags>
  </entry>
  <entry>
    <title>使用卷积图神经网络实现半监督分类器</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/12_%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%8D%B7%E7%A7%AF%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91GCN/</url>
    <content><![CDATA[<h1 id="介绍">介绍</h1>
<p>英文题目：Semi-Supervised Classification with Graph Convolutional
Networks<br />
中文题目：使用卷积图神经网络实现半监督分类器<br />
论文地址：https://arxiv.org/abs/1609.02907<br />
领域：自然语言处理，知识图谱，图神经网络<br />
上传时间：2016<br />
出处：ICLR 2017<br />
被引量：10671<br />
代码和数据：</p>
<ul>
<li>https://github.com/tkipf/gcn<br />
</li>
<li>https://github.com/kaize0409/pygcn/</li>
</ul>
<p>阅读时间：22-03-11</p>
<p>#自然语言处理 #图神经网络</p>
<h1 id="泛读">泛读</h1>
<ul>
<li>针对问题：图节点多分类，半监督学习<br />
</li>
<li>结果：在知识图和引文图数据集中，有效提升了精度和效率<br />
</li>
<li>核心方法：基于频谱图，卷积神经网络，编码时考虑到图结构和节点的特征<br />
</li>
<li>难点：几乎全是公式推导，先验知识太多，单看公式看不懂<br />
</li>
<li>泛读后理解程度：30%<br />
（看完题目、摘要、结论、图表及小标题）</li>
</ul>
<h1 id="精读">精读</h1>
<h2 id="摘要">摘要</h2>
<p>论文提出了<strong>基于图</strong>的，使用<strong>类似卷积神经网络</strong>的<strong>半监督学习</strong>方法。选择卷积结构让我们在建模时更注重邻近的节点。模型隐藏层编码同时考虑了<strong>局部结构</strong>和<strong>节点特征</strong>。相较于之前模型效果明显提升。</p>
<h2 id="介绍-1">1. 介绍</h2>
<p>论文主要解决图中节点的分类问题，且只对图中部分节点打了标签，使用半监督学习方法，通过显式的基于图的规则的方式打标签。在损失函数中使用了拉普拉斯正则化项：<br />
<span class="math display">\[ L=L_0+\lambda L_{reg}\qquad
(1)\]</span><br />
其中：<br />
<span class="math display">\[  
L_{reg}=\sum_{i,j}A_{ij}||f(X_i)-f(X_j)||^2=f(X)^T\Delta f(X)  
\]</span><br />
其中L0是有标签部分的误差（分类的类别），λ是正则化项的权重Lreg通过所有数据（含有标签和无标签）计算得出；把神经网络编码作为函数f，X是节点的原始的特征矩阵。<span
class="math inline">\(\Delta=D-A\)</span>，其中A是领域矩阵（其值可以是0/1值，也可以是权重），D是度矩阵，∆
是拉普拉斯矩阵，有时也用符号L表示。</p>
<h3 id="预备知识">预备知识</h3>
<h4 id="邻接矩阵">邻接矩阵</h4>
<p>定义权重Aij为点vi和点vj之间的权重，所有点间线的权重Aij组成邻接矩阵A，第i行第j值表示为Aij。</p>
<h4 id="度矩阵">度矩阵</h4>
<p>定义di是与i点相连所有点的权重之和：<br />
<span class="math display">\[di = \sum_{j=1}^n A_{ij}\]</span><br />
度矩阵D是一个对角矩阵（主对角线上有值）：<br />
<span class="math display">\[D=\left(\begin{matrix}  
d1 &amp; ... &amp; ...\\  
... &amp; d2 &amp; ...\\  
... &amp; ... &amp; ... \\  
... &amp; ... &amp; dn\end{matrix} \right)\]</span></p>
<h4 id="拉普拉斯矩阵">拉普拉斯矩阵</h4>
<p><span class="math display">\[ L=D-A\]</span></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5fee376e2413ce42.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="拉普拉斯算子">拉普拉斯算子</h4>
<p>拉普拉斯矩阵就是图结构上的拉普拉斯算子，或者说是离散的拉普拉斯算子。</p>
<p>拉普拉斯算子对应的运算是：二阶导数，即散度。它用于衡量一个节点变化之后，对其他相邻结点（也可以说是整个图）的干扰总收益(总变化)：将所有相邻的点相加再减去该中心点x的相邻个数。<br />
<span class="math display">\[\Delta f= \sum \frac{\partial
f}{\partial^2x}\]</span><br />
离散函数的一阶导（含义是：一个节点与它邻近节点的差异）：<br />
<span class="math display">\[  
\frac{\partial f}{\partial x}=f&#39;(x)=f(x+1)-f(x)  
\]</span><br />
离散函数的二阶导（一个节点与它前后两个点组成的关系，是平滑还是尖峰）<br />
<span class="math display">\[ \begin{aligned}  
\frac{\partial f^2}{\partial x^2}&amp;=f&#39;&#39;(x) \approx
f&#39;(x+1)-f&#39;(x) \\  
&amp;=f(x+1)+f(x-1)-2f(x)  
\end{aligned}  
\]</span><br />
对于某一个点i，<br />
<span class="math display">\[\Delta f_i=\sum_{j\in
N_i}(f_i-f_j)\]</span><br />
如果边具有权重Aij，则有：<br />
<span class="math display">\[\Delta f_i=\sum_{j\in
N_i}A_{ij}(f_i-f_j)\]</span><br />
当i,j无边相连时，Aij=0，所以Ni就可以变成N。<br />
<span class="math display">\[ \begin{aligned}  
\Delta f_i &amp; =\sum_{j\in N}A_{ij}(f_i-f_j) \\  
&amp; =\sum_{j\in N}A_{ij}f_i -\sum_{j\in N}A_{ij}f_j  
\\  
&amp; = d_if_i-A_{i:}f  
\end{aligned}   
\]</span><br />
空间的二阶导：<br />
<span class="math display">\[\Delta f= \sum \frac{\partial
f}{\partial^2x}=(A-D)f=Lf\]</span></p>
<h3 id="正文">正文</h3>
<p>正则化项Lreg的目标是让有连接的点在编码后差异足够小，整个图更平滑。该公式一依赖假设：图中连通的节点共享相同标签，这限制了模型的表述能力，因为边不只用于编码节点的相似性。</p>
<p>使用<strong>神经网络对图结构编码</strong>，用节点特征X、邻接矩阵A和函数f编码：f(X,A)，利用有标签和无标签数据共同训练模型，使模型能够学习到对所有节点均适用的规则。</p>
<p><strong>本文贡献：</strong><br />
*
介绍了一种简单而有效的神经网络模型<strong>分层</strong>规则，它使用图谱卷积的一阶近似。<br />
*
示范了用半监督学习的，基于图的神经网络方法，解决图节点分类问题，模型的精度和效率方面相较于SOTA都有显著提升。</p>
<h2 id="图的快速近似卷积">2. 图的快速近似卷积</h2>
<p>对于图神经网络f(X,A)，文中提出了多层图卷积网络（GCN），下图展示了基于层的递推，每个隐藏层计算如下：<br />
<span class="math display">\[  
H^{(l+1)}=\sigma(\widetilde{D}^{-\frac{1}{2}}\widetilde{A}\widetilde{D}^{-\frac{1}{2}}H^{(l)}W^{(l)})
\qquad(2)  
\]</span><br />
其中 <span
class="math inline">\(\widetilde{A}=A+I_N\)</span>，A是邻接矩阵，它表示了节点与其邻居的相关信息，<span
class="math inline">\(I_N\)</span>是单位矩阵（对角线全1其它为0），它补充了该节点自身的信息。计算度矩阵<span
class="math inline">\(\widetilde{D}_{ii}=\sum_j\widetilde{A}_{ij}\)</span>，也考虑了节点自身的信息。<span
class="math inline">\(W^{(l)}\)</span>是对不同层分别训练的权重参数。
σ是激活函数。H为隐藏层，H(0)=X。</p>
<h3 id="谱图卷积">2.1 谱图卷积</h3>
<h4 id="预备知识-1">预备知识</h4>
<h5 id="卷积">卷积</h5>
<ul>
<li>卷积(Convolution)是通过两个函数f和g生成第三个函数的一种数学算子。<br />
</li>
<li>CNN中卷积是离散卷积，两个函数分别是卷积核和图片像素值，它实现了对图片的局部连接和参数共享。<br />
</li>
<li>图卷积：拓扑图中每个顶点的相邻顶点数目都可能不同，某个点可能与所有点都有连接，也可能部分连接，所以没办法用直接用卷积核过滤某一部分；因此，需要借助拉普拉斯矩阵实现卷积。</li>
</ul>
<h5 id="特征分解">特征分解</h5>
<p><a
href="https://blog.csdn.net/xieyan0811/article/details/78597889">机器学习_用PCA主成分分析给数据降维#1
特征值与特征向量</a></p>
<h5 id="傅里叶变换">傅里叶变换</h5>
<p>傅里叶变换是一种投影，比如将函数拆解成无数个不同频率正弦波之和。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d2d0fa569eee5a9f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>空间傅里叶变换：一个N
维空间，只要找到该空间的基，该空间的任意向量就都可以由正交基线性组合。<br />
函数傅里叶变换：将一个函数展开成正交函数基的线性组合。<br />
图的傅里叶变换：在图上找正交基，图上任意点可表示为正交基的线性组合。<br />
因此，只要找到图的<strong>正交基</strong>，就可以完成图的傅里叶变换，再由卷积定理，就可以实现对<strong>图的卷积</strong>。</p>
<h5 id="卷积定理">卷积定理</h5>
<p>函数<strong>卷积</strong>的<strong>傅里叶</strong>变换是函数傅立叶变换的乘积。<br />
<span class="math display">\[  
f\star g=F^{-1}\{F(f)\cdot F(g)\}  
\]</span><br />
求卷积就变成了，两个函数分别做傅里叶变换，相乘后，再反向傅里叶变换即可。</p>
<h5 id="图的频域变换步骤">图的频域变换步骤</h5>
<ul>
<li>创建图的表征矩阵<br />
</li>
<li>特征分解：计算矩阵的特征值和特征向量；通过特征向量将节点从空间映射到频域（拉普拉斯矩阵是对称的，所以可以进行对角化，也就是找到正交基）<br />
</li>
<li>进行下一步操作：基于新的表征，进行聚类或分类……<br />
<span class="math display">\[L=U\Lambda U^T=(u_1,u_2,...,u_n)\left(  
\begin{matrix}  
λ1 &amp; &amp; \\  
&amp; ⋱ &amp; \\  
&amp; &amp; λn  
\end{matrix}  
\right)   
\left(  
\begin{matrix}  
u_1\\  
u_2\\  
... \\  
u_n  
\end{matrix}  
\right)  
\]</span><br />
特征向量U，特征值 <span class="math inline">\(\Lambda=
\{\lambda_1,\lambda_1,\ldots,\lambda_n\}\)</span>，<span
class="math inline">\(u_l\)</span> 是对应于 <span
class="math inline">\(\lambda_l\)</span> 的基。设特征值从大到小是<span
class="math inline">\(\lambda_1\)</span>到<span
class="math inline">\(\lambda n\)</span>，其中<span
class="math inline">\(\lambda_1\)</span>影响最大，那么保留前k个<span
class="math inline">\(\lambda\)</span>就可以大致逼近原来L。</li>
</ul>
<p>图傅里叶变换是在将一个图信号分解到不同平滑程度的图信号上，就像传统傅里叶变换将函数分解到不同频率的函数上一样。</p>
<p>图傅里叶变换将图信号往拉普拉斯特征向量上投影，也是一种信号分解。如果将图看作信号的函数，把对图中节点的操作f(i)映射成了频域的<span
class="math inline">\(\hat{f}(\lambda_1)\)</span>，其中i是节点，<span
class="math inline">\(\lambda_1\)</span>是特征值，把对节点的变换变成了对特征值的变换。<span
class="math inline">\(\hat{f}\)</span>是对整体的变换。</p>
<h4 id="正文-1">正文</h4>
<p>由于无法直接在图上进行卷积操作，如果想实现卷积，需要借助拉普拉斯矩阵。经过变换，图中所有节点的特征都可以被图的拉普拉斯矩阵的特征向量的线性组合表示。</p>
<p>图卷积需要使用卷积核gθ缩放每个节点（公式3左边），公式右边的gθ是对特征值的卷积，θ为参数，其个数和图中节点个数相同：<br />
<span class="math display">\[  
g_\theta \star x=Ug_\theta U^Tx \qquad (3)  
\]</span><br />
这里 x 是图中节点的输入向量，左边的星指卷积，即对 x 的卷积，U
是拉普拉斯矩阵的特征向量（图的正交基）， Λ是特征值组成的对角矩阵，<span
class="math inline">\(U^Tx\)</span>是对x的傅里叶变换。可将右侧的gθ看成对拉普拉斯矩阵特征值的函数，即<span
class="math inline">\(g\theta(\Lambda)\)</span>。如果想使用式3，需要对L做特征分解得到U，计算量是<span
class="math inline">\(O(N^2)\)</span>，对大图来说计算量太大。此时：<br />
<span
class="math inline">\(g_\theta(\Lambda)\)</span>是一阶的情况，它只考虑节点的一跳之内的近邻，如果需要支持多跳，则还需考虑<span
class="math inline">\(\Lambda^k\)</span>：<br />
<span class="math display">\[  
g_\theta(\Lambda) \approx \sum_{k=0}^K \theta_k \Lambda^k  
\]</span><br />
然后，使用了切比雪夫多项式方法逼近<span
class="math inline">\(g\theta(\Lambda)\)</span>函数，它通过设置k值只关注k跳内的关系。<br />
<span class="math display">\[  
g_{\theta&#39;}(\Lambda) \approx \sum_{k=0}^K
\theta_k&#39;T_k(\widetilde{\Lambda}) \qquad (4)  
\]</span><br />
这里的<span
class="math inline">\(\widetilde{\Lambda}=\frac{2}{\lambda_{max}}\Lambda-I_N\)</span>，λmax是L矩阵的最大特征值，计算后相当于做了正则化，将特征值映射到[-1,1]之间；θ′
是切比雪夫系数向量，由切比雪夫不等式的定义可知：<br />
<span
class="math display">\[T_k(x)=2xT_{k-1}(x)-T_{k-2}(x)\]</span><br />
其中T0(x)=1，T1(x)=x。Tk可以迭代计算，从而降低了计算复杂度。</p>
<p>考虑到文中遇到的现实问题是对x的卷积，代入傅里叶变换，最后简化得到：<br />
<span class="math display">\[  
g_{\theta&#39;}\star x \approx
\sum_{k=0}^{K}\theta_k&#39;T_k(\widetilde{L})x\qquad(5)  
\]</span><br />
同样的<span
class="math inline">\(\widetilde{L}=\frac{2}{\lambda_{max}}L-I_N\)</span>，问题就变成求解K次多项式问题，它只依赖节点，及与节点最多在K跳内的邻居。其复杂度为O(|E|)，E为边数，与边的数据成线性关系。</p>
<p>切比雪夫多项式实现的目标是最佳逼近，它利用以<strong>递归方式</strong>定义的多项式序列，gθ(Λ)可以用切比雪夫多项式Tk(X)的截断展开式来很好地逼近K阶。</p>
<h3 id="基于层的线性模型">2.2 基于层的线性模型</h3>
<p>以下是此论文的优化重点。<br />
对于公式5，如果限制K=1，也就是每个节点只考虑它的一阶邻居，上述函数就变成了拉普拉斯谱频的线性函数（从而不再受切比雪夫多项式的规则限制），将其看作一层，通过堆叠多层，来实现丰富的表达能力。我们希望模型对于较宽的度分布，可以平衡图中局部领域的过拟合；另外，多层机制也可以构建更深的网络，来提升模型在多领域的建模能力。</p>
<p>当K=1时，最大特征向量λmax≈2<br />
<span class="math display">\[ \begin{aligned}  
g_{\theta&#39;}\star x &amp; \approx
\theta_0&#39;x+\theta_1&#39;(L-I_N)x\\  
&amp; =\theta_0&#39;x-\theta_1&#39;D^{-\frac{1}{2}}AD^{-\frac{1}{2}}x
\qquad (6)  
\end{aligned}  
\]</span><br />
这是由于：<br />
<span class="math display">\[  
L=D^{-\frac{1}{2}}(D-A)D^{-\frac{1}{2}}=I_n-D^{-\frac{1}{2}}AD^{-\frac{1}{2}}  
\]</span><br />
公式5被拆成了两部分，前一部分计算当前节点，后一部分计算领域节点，卷积核可被整个网络共享，连续应用卷积核有效地卷积节点的第k阶邻域，其中k可看作卷积层的数目。</p>
<p>实际应用时，通过限制参数数目，既可以避免过拟合，也可以减少运算量，进而得到以下公式：<br />
<span class="math display">\[g_\theta\star x \approx \theta(I_N +
D^{-\frac{1}{2}}AD^{-\frac{1}{2}})x \qquad (7)  
\]</span><br />
将参数定义为 <span
class="math inline">\(\theta=\theta_0&#39;=-\theta_1&#39;\)</span>，<span
class="math inline">\(I_N+D^{-\frac{1}{2}}AD^{-\frac{1}{2}}\)</span>
是[0,2]范围内的特征值，在神经网络上连续使用同一操作可能引起梯度爆炸或梯度消失，使用<span
class="math inline">\(I_N\)</span>，将A和D变成了<span
class="math inline">\(\widetilde{A}\)</span>和<span
class="math inline">\(\widetilde{D}\)</span>。</p>
<p>根据以上定义，<span class="math inline">\(X\in
R^{NxC}\)</span>，N是节点数，C是输入的特征维度，计算新的节点表征：<br />
<span
class="math display">\[Z=\widetilde{D}^{-\frac{1}{2}}\widetilde{A}\widetilde{D}^{-\frac{1}{2}}X\theta
\qquad(8) \]</span><br />
其中<span
class="math inline">\(\theta\)</span>是参数矩阵，Z输出的信号矩阵。计算复杂度是O(|E|FC)，其中F是输出维度，C是输入维度。</p>
<h2 id="半监督的节点分类问题">3. 半监督的节点分类问题</h2>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-aa3dd74d913acf2c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>通过有监督学习，左图：将输入为C维的特征（节点X以及节点间的关系A），编码成输出F维特征（向量表示Z），最终实现分类y。其中黑线表示图的边，它在多层之间共享。右图：用颜色标出结果。</p>
<h3 id="示例">3.1 示例</h3>
<p>接下来，以两层的GCN为例，前向传播过程如下式所式：<br />
<span class="math display">\[ \begin{aligned}  
Z &amp;=f(X,A) \\  
&amp; =softmax(\hat{A}ReLU(\hat{A}XW^{(0)})W^{(1)}) \qquad (9)  
\end{aligned}  
\]</span></p>
<p>w0是一个CxH的矩阵用于将输入数据转换到隐藏层；W1是HxF的矩阵，用于将隐藏层转换为输出；softmax用于处理最后的多分类，最后用交叉熵作为误差函数：</p>
<p><span class="math display">\[  
L=-\sum_{l\in y_L}\sum_{j=1}^F Y_{lf}\ lnZ_{lf} \qquad (10)  
\]</span></p>
<p>其中yL是有标签的节点集合。在学习过程中训练W0和W1。</p>
<h3 id="实现">3.2 实现</h3>
<p>代码由TensorFlow实现，训练基于GPU环境，计算复杂度是O(|E|CHF)。</p>
<h2 id="相关工作">4. 相关工作</h2>
<h3 id="基于图的半监督学习">4.1 基于图的半监督学习</h3>
<p>基于图的半监督学习有两大方向：图的拉普拉斯正则化；基于图嵌入的方法。<br />
最近，图嵌入方法进一步被关注，它源于skip-gram模型，DeepWalk通过随机游走学习邻近节点，LINE和node2vec又优化了随机游走（深度/广度优先），还有其它一些图嵌入的优化方法。</p>
<h3 id="图神经网络">4.2 图神经网络</h3>
<p>将神经网络应用到图结构，可以追溯到2005年，2009年提出了使用RNN框架，2015年将CNN引入图结构，然后引入度矩阵，本文也进一步利用不同节点的度来规范化邻接矩阵。</p>
<p>2016年提出的使用图神经网络解决节点分类问题，其复杂度较高，是<span
class="math inline">\(O(N^2)\)</span>。本文中方法基于2014年提出的谱图卷积神经网络，文中方法提高了大规模网络中的模型的可扩展性和分类性能。</p>
<h2 id="实验">5 实验</h2>
<h3 id="数据集">5.1 数据集</h3>
<p>实验数据包括引文网络和知识图，如表-1所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-43c056664cba523a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>引文网络的输入是用词袋方法提取的每篇文章的词向量，以及文章间的引用关系，用0/1二值表，即无向图，因此邻接矩阵A为对称矩阵。对各篇文章打了类别标签进行训练。NELL知识图是用一组边(关系)连接的实体，实体使用向量表示。</p>
<h2 id="结果">6 ## 结果</h2>
<h3 id="半监督的节点分类">6.1 半监督的节点分类</h3>
<p>与其它模型比较：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5a899caf2882d839.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="传播模型评价">6.2 传播模型评价</h3>
<p>使用不同传播模型的效果对比如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-81a2518a8206831c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="每次迭代的耗时">6.3 每次迭代的耗时</h3>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-2a39fab02b98723b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="讨论">7. 讨论</h2>
<h3 id="半监督模型">7.1 半监督模型</h3>
<p>文中提出的模型克服了之前模型的两种限制：边仅仅编码节点的相似性；多步pipeline难以被优化的问题。模型效率更高，且提升了分类性能。</p>
<p>实验证明，公式8提出的简化模型，不仅简化了复杂度和参数，还在很多数据集中表现更好。</p>
<h3 id="局限性和未来的工作">7.2 局限性和未来的工作</h3>
<h4 id="内存">内存</h4>
<p>实验中，当图太大时，无法使用GPU计算，只能使用CPU，其时间尚可接受。使用多batch的方法，会把某些领域切断，所以可能影响模型效果。</p>
<h4 id="有向边和边的特征">有向边和边的特征</h4>
<p>文中模型目前无法支持边的特征，且只能支持无向图，在实验中处理知识图时，通过对边的处理可以部分解决此问题。</p>
<h4 id="限制假设">限制假设</h4>
<p>论中假设自连接与相邻节点的边同等重要，但对于某些数据集，给其赋予不同权重效果可能更好<br />
<span class="math display">\[\widetilde{A}=A+\lambda I_N\]</span></p>
<h1 id="参考">参考</h1>
<p><a
href="https://zhuanlan.zhihu.com/p/85287578">拉普拉斯矩阵与拉普拉斯算子的关系</a><br />
<a href="https://www.cnblogs.com/pinard/p/6221564.html">谱聚类（spectral
clustering）原理总结</a><br />
<a
href="https://blog.csdn.net/qwezhaohaihong/article/details/105635966">谱图理论-拉普拉斯矩阵理解</a><br />
<a href="https://www.cnblogs.com/combfish/p/12271470.html">05-spectral
图机器学习之谱分解</a><br />
<a
href="https://blog.csdn.net/wsj998689aa/article/details/40303561">神奇的拉普拉斯平滑</a><br />
<a href="https://zhuanlan.zhihu.com/p/147687999">图傅里叶变换</a><br />
<a
href="https://www.cnblogs.com/KongHuZi/p/12669497.html">《SEMI-SUPERVISED
CLASSIFICATION WITH GRAPH CONVOLUTIONAL
NETWORKS》论文阅读（一）</a><br />
<a
href="https://blog.csdn.net/weixin_44413191/article/details/108902434">【图神经网络】图卷积网络
GCN</a></p>
]]></content>
      <tags>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>读文阅读_Node2Vec</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/12_%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%8F%AF%E6%89%A9%E5%B1%95%E7%89%B9%E5%BE%81%E5%AD%A6%E4%B9%A0Node2Vec/</url>
    <content><![CDATA[<p>#论文阅读 #自然语言处理 #图神经网络</p>
<h2 id="介绍">介绍</h2>
<p>英文题目：node2vec: Scalable Feature Learning for Networks<br />
中文题目：node2vec：面向网络的可扩展特征学习<br />
论文地址：https://arxiv.org/abs/1607.00653<br />
领域：图神经网络，知识表示<br />
发表时间：2016<br />
出处：KDD<br />
被引量：6181<br />
代码和数据：http://snap.stanford.edu/node2vec/<br />
参考其它翻译：<a
href="https://zhuanlan.zhihu.com/p/46344860">【论文笔记】node2vec</a></p>
<h2 id="说明">说明</h2>
<ul>
<li>一切皆可vector<br />
</li>
<li>图神经网络经典必读第一篇</li>
</ul>
<h2 id="读后感">读后感</h2>
<p>（看完题目、摘要、结论、图表及小标题看完，约30分钟）<br />
针对问题：自动学习图中<strong>结点和边</strong>的特征表示<br />
目标：更好地表征图中的节点：兼顾同质性和结构等价性。<br />
结果：在多领域与SOTA模型对比，展示算法有效性，可在复杂网络中生成任务无关的表征。<br />
方法：note2vec框架，<strong>优化随机游走</strong>算法，<strong>结合深度优先和广度优先两种游走方式</strong>，用参数设置游走方式的选择，从而提升效率。</p>
<h2 id="精读">精读</h2>
<p>（核心章节：读+整理 ：3小时）</p>
<h3 id="摘要">摘要</h3>
<p>如果想使用机器学习算法对图中节点和边建模，需要自动学习对图中元素的描述以替代手动对图的特征工程。</p>
<p>文中提出node2vec框架，学习对图中节点的连续性特征的表示。将节点映射到低维空间，使图中相邻节点相似性最高。文中设计了一种有偏随机游走过程，核心在于加入有弹性的领域探索方法来增强特征的表达能力。</p>
<p>在多分类和连接预测任务中对比了node2vec与SOTA模型，展示出文中方法在复杂网络情况下，可有效地学习任务无关的表示。</p>
<p>……</p>
<h3 id="特征学习框架">3. 特征学习框架</h3>
<p>设G=(V,E)，其中G为图，V是节点，E是边。设f为V-&gt;<span
class="math inline">\(R^d\)</span>
映射函数，将节点V映射成特征表示R，d是特征维度。对于每个节点u∈V，定义Ns(u)为使用采样策略S得到的节点u的邻居。</p>
<p>目标是找到映射f，以最大化节点u的邻居是Ns(u)的对数概率。[[Pasted image
20220220154359.png]]为了简化问题，做以下假设：<br />
* 条件独立假设：假设节点与其各个邻居之间的关系相互独立<br />
<img src="/attachments_2022/Pasted%20image%2020220220153258.png"
alt="Pasted%20image%2020220220153258.png" /><br />
* 特征空间中的对称性：节点与其邻居的关系是对称的。<br />
<img src="/attachments_2022/Pasted%20image%2020220220154241.png"
alt="Pasted%20image%2020220220154241.png" /><br />
基于上述两个假设，公式一可简化成：<br />
<img src="/attachments_2022/Pasted%20image%2020220220154334.png"
alt="Pasted%20image%2020220220154334.png" /><br />
<img src="/attachments_2022/Pasted%20image%2020220220154637.png"
alt="Pasted%20image%2020220220154637.png" /><br />
当网络很大时，使用<strong>负抽样来逼近它</strong>；并使用随机梯度上升法来优化模型参数。</p>
<p>特征学习方法使用自然语言处理中的Skip-gram方法。</p>
<h4 id="经典搜索策略">经典搜索策略</h4>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220220160807.png"
alt="Pasted%20image%2020220220160807.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220220160807.png</figcaption>
</figure>
<p><strong>常见两种采样策略：</strong><br />
* 广度优先(BFS）<br />
邻域由与它直接连通的节点组成，如上图所示，当邻居数据k=3时，BFS采样节点s1,s2,s3。<br />
* 深度优先(DFS）<br />
邻域由距离源节点越来越远的顺序采样的节点组成，如上图中的s4,s5,s6。</p>
<p><strong>同质性和相似结构：</strong><br />
* 同质性<br />
同质网络中各个节点往往是相互连通的，如上图中的u和s1就属于同质网络。<br />
* 结构相似<br />
当节点有类似的网络结构时，这些节点可能充当相似角色，比如上图中的u和s6具有结构相似性（看起来像节点中的hub）。需要注意的，结构相似的网络可能并不相连，它们可能出现在网络的不同位置。</p>
<p>另外，同质性和结构相似性往往在网络中并存。</p>
<p>不同的采样策略决定了节点的特征表示，基于BFS的嵌入方法与结构相似性相关，它可以找到微观局部的邻居，当目标节点起到桥接或hub作用时，通过直接邻域就可以发现。用BFS只能探索图中比较少的区域。相对来说，DFS可以探索更大区域，它反映了邻域的宏观情况，即同源性。它不但需要推断节点间依赖性，还要推断精确的关系，这相对困难，另外，深度优先涉及更远更复杂的依赖，且一般来说距离越远，相关性越小。</p>
<h4 id="node2vec">3.2 node2vec</h4>
<p>文中提出了一种弹性的邻域采样策略，兼顾深度和广度。</p>
<h5 id="随机游走">3.2.1 随机游走</h5>
<p>对于节点u，先设定游走的步数l，用ci表示第i步游走的分布，比如第0步时c0=u。<br />
<img src="/attachments_2022/Pasted%20image%2020220220164900.png"
alt="Pasted%20image%2020220220164900.png" /><br />
其中πvx是节点v和x之间的转移概率，而Z是归一化常数。</p>
<h5 id="有偏探索">3.2.2 有偏探索</h5>
<p>最简单的方法是根据<strong>边的权重采样</strong>下一个节点，但这样无法兼顾网络结构以及不同的邻居类型。另外，还需要结合BFS和DFS，而非二选一。</p>
<p>文中使用了p,q两个参数，如图所示：上一步从t到v，目前处于节点v，此时计算边的转移概率πvx：<br />
<img src="/attachments_2022/Pasted%20image%2020220220170011.png"
alt="Pasted%20image%2020220220170011.png" /><br />
<img src="/attachments_2022/Pasted%20image%2020220220170023.png"
alt="Pasted%20image%2020220220170023.png" /><br />
其中wvx是图中边的权重，dtx是从t到x的最短路径距离（注意这里指的是t和x的距离，不是v和x的距离）。</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220220165752.png"
alt="Pasted%20image%2020220220165752.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220220165752.png</figcaption>
</figure>
<p>如图所示，参数p和q控制着游走的距离以及近邻数。</p>
<p>返回参数p：p控制是否返回t节点，p较大时，不容易返回t节点，它鼓励了模型向外探索，并避免了两跳冗余；当p较小时，则使距离足够短，使表示具有微观性。</p>
<p>向内/向外参数q：q允许选择探索向内或向外的节点，当q&gt;1时，随机游走倾向回到t，使表示具有微观性；当q&lt;1时，则倾向广度优先。与完全的深度优先不同，这里只考虑了两步。</p>
<p>相对于单纯的深度或广度优先，随机游走在空间和时间上都更加高效。</p>
<h5 id="node2vec算法">3.2.3 node2vec算法</h5>
<p><img src="/attachments_2022/Pasted%20image%2020220220172409.png"
alt="Pasted%20image%2020220220172409.png" /><br />
PreprocessModifiedWeights根据参数p,q和图G生成转换概率；外循环表示生成r次随机游走；内循环对于每个节点u，用node2vecWork生成随机游走，最后使用随机梯度下降SGD优化模型参数。</p>
<p>函数note2vecWork用于生成每个节点的游走，遍历每种可能的游走长度l，将当前节点curr设为最后添加的节点，找到它所有的邻居节点，然后根据转移概率π进行有偏采样，得到邻居s并将其加入walk。</p>
<p>最终由三步构成：计算转移概率、模拟随机游走、使用SGD优化。</p>
<h4 id="学习边的特征表示">3.3 学习边的特征表示</h4>
<p>node2vec提供了半监督的节点特征学习方法，有时我们对于节点间的关系更感兴趣，比如链接预测：两个节点间是否存在连接，随机游走方法可将节点的表示扩展成边的表示。</p>
<p>假设两个节点u和v，其特征向量为f(u),f(v)，则两个节点的关系被表示为g(u,v)。无论u与v之间是否有边存在，都可以用这种方法表示（存在边为true，不存在为false）。还有一些方法也可以用于表示边，如下表所示。</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220220181535.png"
alt="Pasted%20image%2020220220181535.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220220181535.png</figcaption>
</figure>
<p>图3描述了节点的关系，上图为同质化，下图为结构一致性。</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220220181928.png"
alt="Pasted%20image%2020220220181928.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220220181928.png</figcaption>
</figure>
]]></content>
      <tags>
        <tag>图神经网络</tag>
        <tag>知识表示</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习异常检测</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/10_%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/</url>
    <content><![CDATA[<p>英文题目：Deep Learning for Anomaly Detection: A Review<br />
中文题目：基于深度学习的异常检测综述<br />
论文地址：https://arxiv.org/pdf/2007.02500.pdf<br />
领域：异常检测，深度学习<br />
发表时间：2020.01<br />
作者：Guansong Pang，阿德莱德大学<br />
出处：ACM Comput. Surv.<br />
被引量：697（谷歌学术）<br />
代码和数据：见论文附录A<br />
阅读时间：2022.11.05<br />
全文翻译：https://blog.csdn.net/pingguolou/article/details/117421638</p>
<h2 id="读后感">1 读后感</h2>
<p>本篇解读的论文发表于2020年，主要介绍基于深度学习的异常检测技术，可作为2009年发表的那篇高引的传统异常检测综述的互补。前三章主要是相关问题和挑战（1-3章）。从第四章开始总结了近年来深度异常检测的具体方法，共3大分类（4-6章），11个小分类。分别对关键直觉，目标函数，基本假设，优势劣势，及应对挑战方法进行讨论。最后讨论了未来的机会，还提供了大量文献列表和训练数据集，实用性强。本文旨在做一个二十分钟左右的简单的导读。</p>
<h2 id="介绍">2 介绍</h2>
<p>异常检测被定义为：检测明显偏离大多数数据的数据实例。早期技术涉及：数据挖掘、机器学习、计算机视觉和统计学，近年来深度学习在多维数据、时间数据、空间数据和图数据都表现出巨大提升，深度学习异常检测是使用神经网络学习特征表征和异常得分。</p>
<p>本篇主要贡献如下：<br />
* 问题和挑战：提出问题的复杂性和挑战。<br />
* 归类和方法：将目前深度学习异常检测分为3大类11小类，并逐一介绍。<br />
*
文献回顾：回顾了大量会议和期刊的文献，通过关键直觉，目标函数，基本假设，优势劣势，挑战几个方面进行分析。<br />
* 未来的机会：讨论了未来机会和挑战<br />
* 源码和数据集：收集了大量源代码和数据集。</p>
<h2 id="问题复杂性和挑战">3 问题复杂性和挑战</h2>
<h3 id="复杂性">3.1 复杂性</h3>
<p>异常检测问题的复杂性主要包含以下几方面：<br />
*
不可知性：异常在发生前常是未知的，且每种异常表现可能不同（异质性）。<br />
*
稀有性和类别不平衡：异常数据占比小，难以收集，标注；正常与异常分布不均衡。<br />
*
异常类型多样：点异常，上下文异常（只在特点背景下才是异常），集体数据异常（整体是异常的，但其中点可能正常）。</p>
<h3 id="主要挑战">3.2 主要挑战</h3>
<p>下面问题大多未被很好解决，而深度学习方法可能发挥作用。<br />
* CH1
异常检测召回率（查全率）低：分布不均衡引发召回率低，需要尽量减少误报，同时增加召回率。<br />
* CH2
高维和非独立数据的异常检测：对于高维空间，常先把特征映射到低维空间，再检测，如何在映射中保留足够信息供下游任务使用；另外还需要处理时间、空间、图等相互依赖的关系。<br />
* CH3
正常和异常数据的使用效率：异常数据很难标记，更多时间要处理无监督和半监督数据，无监督学习往往需要依赖对数据分布的假设。另外，弱监督是指只有部分不完整的异常标签（不包含所有异常类别），且可能是不精确的。<br />
* CH4
抗噪声异常检测：需要处理标注错误的实例（即噪声）与异常数据，更好地利用标注数据。<br />
* CH5
检测复杂的异常：上下文异常和集体异常需要进一步处理；另外，还需要对多个异质数据源的异常，如：多维数据、图像、文本、音频等数据（关联异常）。<br />
* CH6
异常的解释：在有些领域不能把模型作为黑盒使用，它可能带来对少数群体的偏见（比如种族偏见），需要利用解释算法提供决策的原因，以便纠正偏见。尤其对于复杂的模型。</p>
<p>相对来说深度方法能进行端到端的优化，且能学到专门的表征（隐藏层输出），提升数据利用率，能处理更复杂的数据（如文本，视频，图像等），目前已有成熟的多种框架，相对传统方法更有优势。</p>
<h2 id="使用深度学习异常检测">4 使用深度学习异常检测</h2>
<h3 id="预备工作">4.1 预备工作</h3>
<p>跳过一些神经网络的基本原理介绍。<br />
深度网络可学习更好地表征数据。设为X原始空间中的数据集，学习一个映射X-&gt;Z，将其映射到表示空间，在表示空间中更容易区分正常和异常数据。异常检测目标是学习映射函数或者学习异常得分函数（异常得分越高，越可能异常）。</p>
<h3 id="深度异常检测分类">4.2 深度异常检测分类</h3>
<p>文章将深度学习异常检测分为3大类11小类。<br />
<img
src="/attachments_2023/Pasted%20image%2020230906204244.png" /><br />
三大类分别是：提取特征的学习(一个子类），标准化的特征表示（两个小类，七个子类），端到端的学习（四个子类）。</p>
<h2 id="深度学习的特征提取">5 深度学习的特征提取</h2>
<p>该方法从高维提取低维数据表示z = 𝜙
(x;Θ)，再用于下游的异常检测，上下游相互独立。<br />
与传统的PCA和随机投影相比，深度学习在提取富含语义的特征和非线性特征关系方面表现出更强的能力。<br />
它基于假设：<br />
<em>深度学习模型提取的表征保留了有助于将区分异常的信息</em><br />
比如使用AlexNet, VGG,
ResNet图像处理框架提图片低维特征，然后进一步代入下游任务，比如把视频拆成多帧图像，检测其中的异常帧。它需要特征转换器足够强大，且在不同任务中尽量是通用的。</p>
<p><strong>优点</strong><br />
* 可使用现成的预训练模型和异常检测方法（SVM）。<br />
* 网络提供了比线性提取器更强的降维功能。<br />
* 容易实现。<br />
<strong>缺点</strong><br />
* 完全分离的特征提取和异常评分可能导致次优结果。<br />
* 预训练的深度学习模型往往只能针对特定类型数据。<br />
<strong>挑战</strong><br />
将高维投射到低维空间，使现有的异常检测方法能够在更简单的数据空间中工作，常有助于揭示隐藏的异常现象，并减少假阳性。而在映射过程中可能丢失异常相关的重要信息。另外，利用深度网络可以学习从更丰富的数据中提取特征。</p>
<h2 id="学习特征的通用表示">6 学习特征的通用表示</h2>
<p>结合特征学习和异常评分，一般分为以下两类：</p>
<h3 id="通用的标准化特征学习">6.1 通用的标准化特征学习</h3>
<p><strong><em>模型就可以直接给出异常得分，通常是其它算法的附产品，未针对异常检测优化</em></strong><br />
通过使用通用的目标来学习实例的表征，目标函数往往不是为检测设计，但可用于提升异常检测效果。它可以捕捉数据中的基本规律。<br />
<img src="/attachments_2022/Pasted%20image%2020221105175733.png"
alt="Pasted%20image%2020221105175733.png" /><br />
其中Θ和W是训练得到的模型参数，𝜙是特征空间的映射，𝜓用于处理具体任务，l是损失函数，s是异常评分，f是评分函数。具体又分为以下4个子类别：</p>
<h4 id="自编码器ae">6.1.1 自编码器AE</h4>
<p>一种广泛使用的数据压缩和降维技术，低维数据表征强制学习数据的规律，以最小化重建误差。异常数据很难从低维表征中重建，因此有很大的重建误差，以此区分正常和异常。<br />
它基于以下假设：<br />
<em>与异常情况相比，正常实例可以更好地从压缩的空间中进行重组。</em><br />
一个AE由一个编码网络和一个解码网络组成，编码器将原始数据映射到低维特征空间，解码器则试图从投影的低维空间恢复数据，这两个网络的参数是用一个重建损失函数来学习的。模型会尽量保留与主导实例（即正常数据）相关的信息，而异常数据由于偏离正常数据，所以损失更大，也可将损失作为异常得分。<br />
<img src="/attachments_2022/Pasted%20image%2020221105185846.png"
alt="Pasted%20image%2020221105185846.png" /><br />
其中e表示编码，d表示解码，z是压缩后的数据x^为重建数据，s为异常评分。<br />
之后还提出了AE的更多改进版本，如sparse AE, denoising AE, contractive
AE等。AE除了处理表格数据以外，也被用于序列数据图数据图像视频的异常检测，如CNN-AE，LSTM-AE，GCN-AE等，这些方法将编解码输入到处理流程中；也有先处理AE，再处理其它网络如RNN的方法。</p>
<p><strong>优点</strong><br />
* 方法直接，通用<br />
* 可使用不同类型AE变体<br />
<strong>缺点</strong><br />
* 可能由于训练集中不常见的规律和异常存在偏差。<br />
* 目标是数据压缩，而非异常检测，没有对异常检测进行优化。<br />
<strong>挑战</strong><br />
AE可以和不同网络结构结合，检测高维数据异常及复杂数据，学到的表征数据可能优于手工提取数据。AE容易受到训练中数据噪声的影响，导致过拟和及重建错误，RPCA（假设误差是稀疏的PCA）思想也被用于改进AE。</p>
<h4 id="生成对抗网络gan">6.1.2 生成对抗网络GAN</h4>
<p>基于生成对抗网络的异常检测也被广泛使用，这种方法主要通过生成网络G学习潜在的特征空间，从而捕捉数据的规则。真实实例和生成实例的残差被定义为异常得分。<br />
它基于的假设是：<br />
<em>正常数据比异常数据，通过生成网络生成数据的效果更好。</em><br />
AnoGAN是早期的方法，首先用常规目标训练GAN：<br />
<img src="/attachments_2022/Pasted%20image%2020221105215031.png"
alt="Pasted%20image%2020221105215031.png" /><br />
其中G是生成模型，D是判别模型，V是博弈的价值函数，其损失函数由两部分组成，一部分是残差损失，用于衡量生成数据的效果：<img
src="/attachments_2022/Pasted%20image%2020221105215617.png"
alt="Pasted%20image%2020221105215617.png" />另一部分是基于特征匹配的损失：<br />
<img src="/attachments_2022/Pasted%20image%2020221105215552.png"
alt="Pasted%20image%2020221105215552.png" /><br />
其中𝛾是迭代次数的索引号，h是隐藏层的输出。z从一个随机采样开始，随着迭代逐步优化。异常得分被定义为最后一步得出的z构造出的数据和x的相似性：<br />
<img src="/attachments_2022/Pasted%20image%2020221105220306.png"
alt="Pasted%20image%2020221105220306.png" /><br />
𝛼为超参数。<br />
AnoGAN的主要问题是Z的迭代搜索效率低，后来又提出了BEGAN，快速AnoGAN，ALAD，GANomaly
进一步优化，另外还有Wasserstein GAN，Cycle GAN等。</p>
<p><strong>优点</strong><br />
* GAN生成能力强，尤其在图像上能检测出从空间重构的异常实例。<br />
* 大量基于GAN的模型可用于特征检测。<br />
<strong>缺点</strong><br />
* 基于GAN的模型训练困难较大，可能无法收敛或模型崩溃。<br />
*
当训练数据包含意外的值或者真实分布很复杂时，模型可能产生异常的实例。<br />
* 模型目标是数据合成，不是目标检测，结果可能不是最优。<br />
<strong>挑战</strong><br />
GAN通过潜在空间重建高维空间，在潜在空间保留了重要信息，它可能提升精度以超过原始空间。</p>
<h4 id="可预测模型">6.1.3 可预测模型</h4>
<p>主要用于时序数据，使用时间窗口，将以前实例作为上下文，通过预测实例来学习特征表示。为了精准预测，需要表征学习窗口内的时间序列和复发性依赖。正常实例服从依赖关系，异常数据违反依赖关系，是不可预测的。预测误差可用于定义异常评分。<br />
基于以下假设：<br />
<em>正常实例在时序上比异常实例更可预测。</em><br />
该技术常用于视频异常检测，如已知x1,x2,..xt帧，任务是预测未来帧xt+1，使预测的t+1帧与实际帧更为相似。损失函数被定义为：<br />
<img src="/attachments_2022/Pasted%20image%2020221105222232.png"
alt="Pasted%20image%2020221105222232.png" /><br />
其中x^是预测的帧，x是实际帧，pred是MSE计算的帧预测损失，adv是对抗损失，它使用对抗性训练来增强图像生成。<br />
另一种研究方法是自回归模型，模型假设序列中的每个元素都线性地依赖于之前的元素。如给定x和它的潜在空间表示z
= 𝜙 (x; Θ)，自回归模型因子p(z)被定义为：<br />
<img src="/attachments_2022/Pasted%20image%2020221105223156.png"
alt="Pasted%20image%2020221105223156.png" /><br />
K是潜在空间的维度。<br />
<strong><em>可能加</em></strong><br />
<strong>优点</strong><br />
* 一些序列学习技术可用于异常检测<br />
* 可学习不同类型的时间和空间依赖<br />
<strong>缺点</strong><br />
* 只用于序列数据预测<br />
* 顺序预测计算量大<br />
* 其基本目标是序列预测，不是异常检测，异常检测结果可能不是最优。<br />
<strong>挑战</strong><br />
该方法用于学习与时间相关的低维表征，一般用于上下文异常检测。</p>
<h4 id="自监督分类器">6.1.4 自监督分类器</h4>
<p>通过建立自监督分类器来学习表征，它基于传统的交叉特征分析或特征模型，将与分类模型不一致的识别为异常。每个模型根据其他特征来预测一个特征。它评价的是特征内部的一致性。<br />
传统方法多用于表格数据，深度学习模型可用于图像数据，通过增强数据建立预测模型。<br />
它基于以下假设：<br />
<em>正常实例比异常实例对自监督分类器更一致。</em><br />
开始的方法通过对图片的水平翻转，平移和旋转，在增强数据的基础上训练多分类模型，将同一图片及变换后的图片作为一个类别。在推理时，也用转换组合进行增强，用所有增强后的实例做softmax再聚合来定义规范性得分。其损失函数定义为：<br />
<img src="/attachments_2022/Pasted%20image%2020221105224756.png"
alt="Pasted%20image%2020221105224756.png" /><br />
其中CE是交叉熵，其中 z𝑇𝑗 = 𝜙 (𝑇𝑗 (x);
Θ)，其中T是变换，z是低维空间的表示，𝜓是多分类器，yTj是转换后合成类的OneHot编码。这里使用了特征学习器𝜙和类别学习器𝜓。在这种自监督多分类训练过程中，正常实例引起的梯度变化比离群值大得多，网络更新也偏向正常值，正常值与分类器更为一致。评估异常使用三种策略：平均预测概率，最大预测概率，所有预测概率的负熵（此策略更好）。<br />
<strong>优点</strong><br />
* 在无监督半监督情况下都能很好地工作，评分以内在属性为基础。<br />
<strong>缺点</strong><br />
* 只适用于图像数据。<br />
* 异常分数是在分类基础上得出的，它可能不是最优的。<br />
<strong>挑战</strong><br />
学到的常态性的低维表征有助于比原始的高维空间更好地检测异常情况。由于自监督分类器中呈现的异常和正常实例之间的一些内在差异，这种方法也能够在无监督的环境下工作，对训练数据中的异常污染表现出良好的稳健性。</p>
<h3 id="依赖异常检测的特征学习">6.2 依赖异常检测的特征学习</h3>
<p><strong><em>深度学习和机器学习相结合</em></strong><br />
针对某一种异常优化特征表示，可表示为：<br />
<img src="/attachments_2022/Pasted%20image%2020221105230333.png"
alt="Pasted%20image%2020221105230333.png" /><br />
与式2-3不同，这里的f是一种现有的异常评分，专门针对当前目标 f
优化特征表征，一般对异常的量度分为以下三类：</p>
<h4 id="基于距离的度量">6.2.1 基于距离的度量</h4>
<p>针对距离优化特征表示。传统的基于距离异常度量的主要问题是，无法在高维数据中有效工作，而基于深度学习的方法可在度量前将高维转换到低维空间，很好地解决了这一问题。<br />
它基于以下假设：<br />
<em>异常现象分布在离其最近的邻居很远的地方，而正常实例位于密集的邻域。</em><br />
这种方法首先用于利用随机邻居距离优化从超高维数据中学习低维表示。让伪标签异常的近邻远大于正常的近邻。伪标签是由一些基本距离的异常检测器生成的。<br />
设S为X中的抽样的数据子集，A为异常集合，N为正常集合，计算损失函数如下：<br />
<img src="/attachments_2022/Pasted%20image%2020221105232207.png"
alt="Pasted%20image%2020221105232207.png" /><br />
m是预先定义好的常量，使用了铰链损失函数，其目的是让异常邻居的距离至少要比正常距离大m。距离函数f是随机距离，计算方法如下：<br />
<img src="/attachments_2022/Pasted%20image%2020221105232409.png"
alt="Pasted%20image%2020221105232409.png" /><br />
f用于表示实例的异常得分，也可以替换成其它距离计算方法。</p>
<p><strong>优点</strong><br />
* 基于距离的方法在以前的工作中建立了很好的基础。<br />
* 可解决传统基于距离方法无法解决的高维问题。<br />
* 可以学习专门为距离优化的表征。<br />
<strong>缺点</strong><br />
* 基于距离的方法计算量较大<br />
* 被基于距离方法的弱点限制<br />
<strong>挑战</strong><br />
可对针对距离优化表征，解决了高维问题，可利用少数标记的异常实例学习常态表征。</p>
<h4 id="基于分类的度量">6.2.2 基于分类的度量</h4>
<p>学习为后续基于单类分类的异常检测定制的特征表示。单分类是检测测试实例是否符合训练数据。大多数单分类模型受支持向量机启发，此处的方法一般是将SVM和深度网络相结合。<br />
它基于以下假设：<br />
<em>所有的正常实例都来自于一个类，并可用紧凑的模型来概括，异常情况并不符合这个模型。</em><br />
具体思想是先用神经网络降维，然后从低维数据中用SVM学习一个超平面实现分类。其通用表述是：<br />
<img src="/attachments_2022/Pasted%20image%2020221106093234.png"
alt="Pasted%20image%2020221106093234.png" /><br />
其中r是边界参数，Θ是从高维向低维映射的网络参数，z是转换后的低维向量，𝑣是一个超参数，它是训练集中异常分数的上限，任何𝑟
− w⊺z𝑖 &gt;
0的实例都可能报告为异常点。该方法有两个好处，可以用深度学习网络学习更有表现力的特征用于下游任务；另外有助于消除核函数中计算量大的配对距离计算。<br />
另一条研究线路是研究SVDD（建立一个最小的超球体，以尽可能地包含所有正常数据）的深度模型，其核心加数是中心c和半径r，深度SVDD旨在利用神经网络将数据实例映射到最小体积的球体中，然后采用铰链损失函数来保证球体中心和投影实例之间的余量，目标可通过最小化以列损失函数共同训练：<br />
<img src="/attachments_2022/Pasted%20image%2020221106094645.png"
alt="Pasted%20image%2020221106094645.png" /><br />
一些改进方法，可将SVDD应用于半监督学习，其关键思想是最小化正常实例到中心的距离，同时最大化异常实体到中心的距离。<br />
<strong>优点</strong><br />
* 基于单分类的方法已得到很好研究。<br />
* 表征学习和单分类相结合，可有目的的学到更好的表征。<br />
* 免于手工选择核函数。<br />
<strong>缺点</strong><br />
* 单模模型在正常类复杂分布的数据集上可能不起作用。<br />
* 检测性能取决于单分类的异常量度。<br />
<strong>挑战</strong><br />
该方法可以利用少量标记的正常和异常数据来学习更有效的模型描述，不仅可以检测已知的异常，还可以检测新的异常类别。</p>
<h4 id="基于聚类的度量">6.2.3 基于聚类的度量</h4>
<p><strong><em>这个挺好的</em></strong><br />
深度异常检测旨在学习表征，使异常数据偏离正常数据表征空间中的聚类。大量研究致力于使用聚类定义异常，如判断聚类的大小，与质心的距离，质心间的距离，以及成员间的距离，基于高斯混合模型的异常检测也被纳入该类别。<br />
它基于以下假设：<br />
<em>正常实例比异常实例对聚类有更强的依附性。</em><br />
深度聚类专门为聚类算法定制特征，基于以下关键直觉：<br />
* 好的表征能学到更好聚类，好的聚类能为表征学习提供有效的监督信号<br />
*
聚类算法基础假设不同，为一种聚类算法优化的表征不一定可用于其它算法<br />
深度聚类方法通常包括两个模块：在前向过程中进行聚类，在后向过程中使用聚类分配作为伪类标签学习表征。其损失函数一般是：<br />
<img src="/attachments_2022/Pasted%20image%2020221106102437.png"
alt="Pasted%20image%2020221106102437.png" /><br />
lclu是聚类的损失函数，y是伪标签，𝜙是特征映射，f是聚类分配函数，aux用于对表征施加额外的约束，比如基于自编码器的重建损失，以学习到稳健和保留局部结构的表征。<br />
由于聚类可能被损失污染，上述方法可应用于半监督环境，在无监督环境中使用时还需要加一些额外约束条件。算法的目标是聚类，在过程中可以产生基于聚类的表征，后续还有一些改进，以加强对异常的识别。<br />
<strong>优点</strong><br />
* 可利用现有的聚类的方法和理论<br />
* 针对聚类的目标专门优化表征<br />
* 深度学习方法在处理复杂数据时，更容易发现异常。<br />
<strong>缺点</strong><br />
* 异常检测的效果取决于聚类结果<br />
* 聚类可能被噪声带偏，反过来导致不太有效的表征。<br />
<strong>挑战</strong><br />
一些聚类算法对异常值很敏感，当训练数据被异常值污染时，深度聚类和随后的异常检测在很大程度上会被误导。使用来自自动编码器重建错误的手工特征的深度聚类可能有助于学习稳健模型。</p>
<h2 id="端到端学习">7 端到端学习</h2>
<p>以端到端方式学习标量异常评分，不依赖现有的异常度量（以免受该方法的缺陷影响），底层框架可表示为：<br />
<img src="/attachments_2022/Pasted%20image%2020221106104331.png"
alt="Pasted%20image%2020221106104331.png" /><br />
它同时学习异常表征和异常得分或排名。和5.2中方法的差异是，5.2偏重结合现有的度量和深度学习方法，而端到端的学习通过重新设计损失函数直接学习。分为下列四个主要方法：</p>
<h4 id="排序模型">7.1.1 排序模型</h4>
<p>这组方法直接学习异常排名，神经网络由序数变量驱动。<br />
它基于以下假设：<br />
<em>存在一个可观察的序数变量来捕捉某些数据的异常性。</em><br />
在无监督环境中，一个研究思路是设计基于序数回归的损失函数来驱动异常评分神经网络。设y为标签，y
= {𝑐1, 𝑐2 } 且 𝑐1 &gt; 𝑐2，其目标函数设置为：<br />
<img src="/attachments_2022/Pasted%20image%2020221106110623.png"
alt="Pasted%20image%2020221106110623.png" /><br />
此外l是MSE或MAE的损失函数，当x为异常时y是c1，当x是正常实例时y是c2，此处的y是标量，因此是一个标量序数回归问题。<br />
在端到端的网络中，是否正常(A/N，由一些现有的方法初始化，不断迭代更新)也作为网络的输入，学习优化异常分数，让异常的数据去拟合更大的值，比如使用ResNet-50抽取图像特征，然后在其后加入两个全连接层来构建异常评分。<br />
在弱监督环境中，假设有很少的有标签的异常，和大规模无监督数据，异常检测被设置成成对关系预测任务，以区分数据为以下哪种情况：两个异常，一个异常，没有异常。设A为标记异常集，U为无标签集，全部数据X由A和U组成。P为数据抽样实例对，y是序列变量，预定义有：𝑦x𝑎𝑖
x𝑎 𝑗 &gt; 𝑦x𝑎𝑖 x𝑢𝑖 &gt; 𝑦x𝑢𝑖 x𝑢 𝑗，方法定义如下：<br />
<img src="/attachments_2022/Pasted%20image%2020221106133143.png"
alt="Pasted%20image%2020221106133143.png" /><br />
其中𝜏是预测标签的方法，模型被优化为：两个异常点分数大于一个异常点，大于无异常点。在推理阶段，每个实例与A和U分别配对，以获得异常得分。<br />
另一种弱监督学习方法，用于视频监督，已知某个视频包含异常帧，但不知哪一帧异常，引入了基于多实例学习的排名模型，目标是保证异常视频（正袋）分数大于正常视频（负袋）分数。使用铰链损失：<br />
<img src="/attachments_2022/Pasted%20image%2020221106133946.png"
alt="Pasted%20image%2020221106133946.png" /><br />
其中x是抽样的视频片断，Bp是正袋，Bn是负袋，损失函数第一项保证异常得分大于正常得分，后两个是额外的优化约束，第二个保证得分平衡性，最后一个保证异常稀疏性（异常帧不会太多）。<br />
<strong>优点</strong><br />
* 异常得分可直接用损失函数优化<br />
* 通过对正常/异常的相对关系替代对异常的定义<br />
* 建立在成熟的排名技术和理论上<br />
<strong>缺点</strong><br />
* 无监督方法效果明显比半监督差。<br />
* 可能不适用于未被标记的异常情况。<br />
<strong>挑战</strong><br />
*
使用弱监督可能学习到更具表现力的低维表征，上述两种半监督方法提供了利用粗粒度的标签的方法，端到端的模型可定义造成异常大的特征，提供了直接的异常解释，另外，在有噪声的条件下也能很好工作。</p>
<h4 id="先验驱动模型">7.1.2 先验驱动模型</h4>
<p>基于概率的方法。<br />
利用先验分布对异常分数学习进行编码和驱动。可以对异常分数的内部模块或学习输出施加先验。<br />
基于的假设<br />
<em>强加的先验捕捉了数据集的基本（非）正态性。</em><br />
它的关键的直觉是，将一组序列数据作为输入的代理，代理的正常行为可以通过其潜在的奖励函数来理解，如果代理给一个测试序列分配了低奖励，那么该测试序列就会被识别为异常情况。可表述为如下的后验优化问题：<br />
<img src="/attachments_2022/Pasted%20image%2020221106145430.png"
alt="Pasted%20image%2020221106145430.png" /><br />
其中𝑝 (Θ)是基于Θ的先验分布，S是一系列的观测序列，𝑝
(s|Θ)是潜在回报函数，回报的倒数可作为异常评分，最大化上述公式就等于直接学习了异常评分。<br />
经验表明，各种真实数据集中的异常分数都非常符合高斯分布，即假设正常实例的异常分数聚在一起，而异常实例的异常分数远离该聚类。研究使用高斯先验对异常分数进行编码，并使分数能够直接优化。<br />
损失函数定义如下：<br />
<img src="/attachments_2022/Pasted%20image%2020221106150241.png"
alt="Pasted%20image%2020221106150241.png" /><br />
若夫中𝜇𝑏和𝜎𝑏分别是均值和方差，正常时y=0，异常时y=1，m是置信区间参数。该方法具有很好的可解释性。</p>
<p><strong>优点</strong><br />
* 异常得分可以在给定的先验中直接优化<br />
* 可纳入不同的先验，使用不同的贝叶斯深度学习技术<br />
* 和其它方法相比，能学到更可解析的异常分数<br />
<strong>缺点</strong><br />
* 为场景设置合理的先验比较困难<br />
* 如果先验不能拟合分布，则模型效果会降低。<br />
<strong>挑战</strong><br />
检测模型是由异常评分函数的先验分布驱动的，在训练数据中存在异常污染的数据中工作良好。</p>
<h4 id="softmax似然模型">7.1.3 Softmax似然模型</h4>
<p>通过最大化训练数据中事件的可能性来学习异常分数。由于正常实例更为常见，因此被认为是高概率事件，异常为低概率事件，从而定义异常得分。<br />
它基于以下假设：<br />
<em>异常和正常实例分别是低概率事件和高概率事件。</em><br />
使用直接对事件似然建模来学习异常分数的思想。问题被定义为：<br />
<img src="/attachments_2022/Pasted%20image%2020221106142734.png"
alt="Pasted%20image%2020221106142734.png" /><br />
学习参数Θ，p是x发生的概率，使用最大似然函数计算。<br />
<img src="/attachments_2022/Pasted%20image%2020221106143021.png"
alt="Pasted%20image%2020221106143021.png" /><br />
其中𝜏是异常评分函数，它通过特征间的关系计算：<br />
<img src="/attachments_2022/Pasted%20image%2020221106143352.png"
alt="Pasted%20image%2020221106143352.png" /><br />
其中z是x的低维表征，i,j是特征编号，w是交叉参数，通过训练获得。计算p时分母是正则化项，计算量大，因此，也有使用NCE方法对其进行优化的。</p>
<p><strong>优点</strong><br />
* 不同特征交互作用可被纳入异常得分的学习过程中。<br />
* 异常得分忠实于特定异常交互的优化（好像异常共性）。<br />
<strong>缺点</strong><br />
* 特征多时计算量大<br />
* 异常得分依赖于负样本的生成质量<br />
<strong>挑战</strong><br />
这是一种基于特征交互作用的方法，为异质数据源泉的数据集的低维表征提供了方法，能人不同数据源捕捉到更到正态/非正态信息，比传统方法更好地检测异常。</p>
<h4 id="端到端的单分类器">7.1.4 端到端的单分类器</h4>
<p>基于GAN的方法。<br />
训练单分类器以端到端方式学习实例是否正常，与5.2.2的区别在于它不依赖SVM等已有分类器。这种方法是GAN和单分类的结合，其核心是生成判别器，区分正常实例和生成的伪异常实例。<br />
它基于以下假设：<br />
<em>(i) 近似于异常的数据实例可以被有效地合成。<br />
(ii) 所有的正常实例都可以由一个判别性的单模型来总结。</em><br />
最初提出的方法ALOCC训练两个深度学习网络，一个用于判别正常/异常实例，另一个被训练成扭曲正常值以生成异常实例（基于去噪AE）。方法定义为：<br />
<img src="/attachments_2022/Pasted%20image%2020221106140703.png"
alt="Pasted%20image%2020221106140703.png" /><br />
Px^是被高斯噪声破坏的X的数据分布，它与AE的参数同时优化。除了用AE造数据，有的方法还从异常类中抽取数据，另外还有一些生成破坏实例的其它方法，比如生成与正常实例互补的实例，生成边界实例等。<br />
<strong>优点</strong><br />
* 以端到端方式进行对抗优化<br />
* 以对抗学习和单类技术作为理论基础<br />
<strong>缺点</strong><br />
* 很难保证生成的参考实例与未知的异常情况非常相似。<br />
*
GANs的不稳定性可能导致生成的实例具有不同的质量，从而导致异常分类性能不稳定。<br />
* 仅限于半监督的异常检测场景。<br />
<strong>挑战</strong><br />
单分类器学习生成现实的边缘/边界实例，使学习富有表现力的低维规范性表征成为可能。</p>
<h2 id="算法和数据集">8 算法和数据集</h2>
<p>7.1 代表性算法<br />
表-2列出了代表性的算法<br />
<img src="/attachments_2022/Pasted%20image%2020221106150928.png"
alt="Pasted%20image%2020221106150928.png" /><br />
对其总结如下：<br />
* 大多数方法在无监督或半监督模式下运行<br />
* 深度学习技巧，如数据增强、dropout和预训练等尚未得到充分研究<br />
* 所使用的网络架构并不深，大多数方法的网络层数不超过5层<br />
* (leaky) ReLU是最常用的激活函数<br />
* 不同的骨干网可以用来处理不同类型的输入数据。<br />
多数算法的源代码都是公开的，附录A1还列出的源码地址。</p>
<h3 id="真实异常的数据集">8.1 真实异常的数据集</h3>
<p>表-3列出了可用数据集，可从 https://git.io/JTs93 获取<br />
<img src="/attachments_2022/Pasted%20image%2020221106151329.png"
alt="Pasted%20image%2020221106151329.png" /></p>
<h2 id="总结和未来的机会">9 总结和未来的机会</h2>
<h3 id="探索异常监控信号">9.1 探索异常监控信号</h3>
<p>探索异常信号是深度异常检测的关键，以获取异常评分，及正常/异常。很多方法用以对探测无监督或自监督的数据。5.1中的方法并未针对异常检测优化；5.2中方法虽然包含优化，但对数据分布进行了假设；另外，还有使用领域知识，实现知识驱动的异常检测的方法。</p>
<h3 id="深度弱监督异常检测">9.2 深度弱监督异常检测</h3>
<p>弱监督数据一般指不完全，不精确，不准确（如粗粒度）标记的异常数据，它们往往在现实中是可得的，并可以提升模型效果。但由于异常可能是高度异质性的，可能存在未知，新异常：超出了给定异常示例，最近研究发现，深度学习往往能学到超出给定异常示例范围的异常。<br />
当然，检测已知异常也非常重要
，异常可能来自不同的异常类，因此表现出完全不同的特征。重要的是探索利用少量标记数据来学习更强大的具有更深体系结构的检测模型的可能性。</p>
<h3 id="大规模的正常学习">9.3 大规模的正常学习</h3>
<p>大规模无监督，自监督表示学习在实现下游学习任务方面取得了巨大成功。在很难获得足够的标记数据的情况下使用。首先在无监督/自监督模式下从大规模无标记数据中学习可转移的预训练表示模型，然后在半监督模式下微调检测模型。<br />
另外，数据可能包含噪声，因此，鲁棒性在预训练建模和微调阶段都很重要。此外，不同领域的异常和数据集差异很大，因此大规模的常态性学习可能在特定领域进行。</p>
<h3 id="复杂异常的深度检测">9.4 复杂异常的深度检测</h3>
<p>目前大多数深度异常检测方法都集中在点异常上，表现出比传统方法更好的性能。然而，对条件异常，集体异常的深度模型研究较少，而处理复杂依赖数据是深度模型的优势，也是未来重要的机会。</p>
<h3 id="可解释和可操作的深度异常检测">9.5
可解释和可操作的深度异常检测</h3>
<p>目前异常检测主要着重优化精度，对可解释性关注较少，导致解释性和可行动性较弱。可利用深度异常检测模型探索深度模型解释和可操作知识发现的方法。</p>
<h3 id="新颖的应用程序和设置">9.6 新颖的应用程序和设置</h3>
<p>已经有一些令人兴奋的新兴研究应用和问题设置，其中可能有一些扩展深度检测方法的重要机会。以及一些强相关的领域：比如OOD检测（分布外检测），好奇心学习，异常可能存在的依赖特征，检测对抗实例。</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>异常检测</tag>
      </tags>
  </entry>
  <entry>
    <title>图注意力网络</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/12_%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%9B%BE%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%BD%91%E7%BB%9CGAN/</url>
    <content><![CDATA[<h1 id="介绍">介绍</h1>
<p>英文题目：GRAPH ATTENTION NETWORKS<br />
中文题目：图注意力网络<br />
论文地址：https://export.arxiv.org/pdf/1710.10903.pdf<br />
领域：知识图谱，知识表示<br />
发表时间：2018年<br />
作者：Petar Veliˇckovi ́c，剑桥大学<br />
出处：深度学习顶会 ICLR<br />
被引量：1000<br />
代码和数据：https://github.com/PetarV-/GAT<br />
阅读时间：2022.04.25</p>
<h1 id="读后感">读后感</h1>
<p>简介部分复习了当时主流做法的演进过程，是很好的导读，其中GNN（基于RNN），GCN（基于CNN），GAN
（基于Attention）都比较重要，MoNet和GraphSAGE也可以读一下（GraphSAGE用于大规模数据）。</p>
<h1 id="泛读">泛读</h1>
<ul>
<li>针对问题：基于图结构的节点分类<br />
</li>
<li>结果：在小数据集传导测试中GAN与GCN效果不相上下，略好一点；在大数据集归纳测试中，无法使用GCN等方法，GAN更有优势。<br />
</li>
<li>核心方法：把注意力机制引入图神经网络。<br />
</li>
<li>难点：如果之前了解Attention和图的基本表示方法，本篇原理和代码都不复杂。<br />
</li>
<li>泛读后理解程度：直接精读<br />
（看完题目、摘要、结论、图表及小标题）</li>
</ul>
<h1 id="精读">精读</h1>
<h2 id="摘要">摘要</h2>
<p>提出图注意力网络 graph attention
networks（GATs），基于图结构，利用带MASK的自注意力机制。利用邻居节点的特征对不同邻居分配不同权重，无需高代价的矩阵运算，也不需要事先了解图结构。</p>
<h2 id="简介">简介</h2>
<p>不规则数据常常使用图来描述，用神经网络解决图问题：最早提出用RNN方法表征有向无环图；2005提出GNN将RNN用于更多的图结构，它通过迭代扩展节点状态直至均衡，对每个节点产生一个输出；后又被改进，加入门控单元。（<strong>建议延伸阅读GNN</strong>）</p>
<p>卷积思想也被引入图神经网络，包含基于谱和不基于谱的方法。</p>
<p>基于谱方法：Bruna等在2014年使用谱表征方法应用于上下文中的节点分类问题，在频域使用卷积计算拉普拉斯矩阵的特征分解，它使用了大量计算和非局部的滤波器。2015年Henaff提出使用光滑系数，使其在空间上局部化；2016年Defferrard使用切比雪夫逼近滤波器，不再需要计算拉普拉斯的特征向量。最终，在2017年Kipf和Welling简化了之前的方法提出GCN，每层使用一跳的邻居，建构多层模型（<strong>CNN的谱方法推荐阅读GCN，其中也介绍了切比雪夫方法</strong>）。上述谱方法学习的过滤器（取舍邻居节点）都依赖拉普拉斯向量，拉普拉斯又基于图的邻接矩阵和度矩阵，强依赖图结构，因此，训练好的模型不能用于其它结构的图（结构变化，模型就不能用了）。</p>
<p>不基于谱方法：2015-2017年相继提出了将卷积直接用于图，计算空间上相邻的组的方法。面临的问题是节点的近临数各不相同以及如何保证CNN共享权重，解决方法有：学习不同度的权重矩阵；使用转换矩阵的强度来定义近邻，然后学习不同通道和邻居度的权重；以及提取并归一化包含固定数量节点的邻域。2016年Monti在MoNet（mixture
model
CNNs）提出了统一CNN结构的空间方法（GAT可以作为MoNet的一个特殊实例）。Hamilton在2017年提出了GraphSAGE，以归纳方法计算节点的表征，它采样固定数目的邻近节点，使用特殊的聚合函数，这种方法在几个大型归纳基准测试中取得了令人印象深刻的表现。（<strong>建议延伸阅读GraphSAGE，该方法常被用于大图模型的效果对比</strong>）</p>
<p>注意力机制近年来在很多序列任务中效果很好，它的一个主要优势是支持不同大小的输入，专注最相关的部分做决策，常用的方法有自注意力和内部注意力，通过和CNN和RNN结合，注意力在机器阅读和学习句子表征方面效果很好。2017年Vaswani展示了注意力不仅可以和其它模型结合，其本身也能在机器翻译任务中构建强大的模型。</p>
<p>本文受其启发，将注意力应用于基于图结构的节点分类问题，其主要想法是利用自注意力方法，使用领域信息，计算图中每个节点的隐藏表征，具有以下特点：<br />
* 该操作是高效的，可以跨节点对并行操作<br />
* 通过为邻域指定任意权重，应用于具有不同度的图节点<br />
* 适用于归纳学习，可以推广到不完全可见的图</p>
<h2 id="gat架构">2. GAT架构</h2>
<h3 id="图注意力层">2.1 图注意力层</h3>
<p>层的输入是节点特征h={h1,h2,...hN}，其中N是节点数量，hi是向量hi ∈
RF，F是每个节点的特征个数。输出是新的节点特征：h'={h'1,h'2,...h'N}，h'i∈
RF ′，输入的特征个数F可能与输出的特征个数F'不同。</p>
<p>为了通过层学习到更有效的表征，至少需要一个可学习的线性转换，模型参数W
∈ RF ′ ×F ，它被应用于每个节点，利用自注意力矩阵a，a : RF ′× RF
′来计算注意力参数：<br />
<img src="/attachments_2022/Pasted%20image%2020220502150544.png"
alt="Pasted%20image%2020220502150544.png" /><br />
它用于表示节点j对节点i的重要性。在注意力的一般公式中，模型允许每个节点参与其它节点的计算，因而与图结构无关。文中方法则使用Mask来遮蔽无关的节点，只考虑j
∈
Ni，即i在图中的邻居节点，实验只考虑一阶邻居。再使用Softmax进行归一化：<br />
<img src="/attachments_2022/Pasted%20image%2020220502151126.png"
alt="Pasted%20image%2020220502151126.png" /><br />
注意力a是单层前馈网络，权重参数a ∈ R 2F
′，使用LeakyReLU作为激活函数，将(1)代入式(2)后，表示为：<br />
<img src="/attachments_2022/Pasted%20image%2020220502151536.png"
alt="Pasted%20image%2020220502151536.png" /><br />
其中T表示转置，||表示串联操作，如图-1中左图所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220502151714.png"
alt="Pasted%20image%2020220502151714.png" /><br />
之后，利用a来计算最终输出的特征h'：<br />
<img src="/attachments_2022/Pasted%20image%2020220502152416.png"
alt="Pasted%20image%2020220502152416.png" /><br />
其中σ是激活函数。</p>
<p>为了保证模型的稳定性，将单头注意力扩充成多头注意力模型，使用K个互不依赖的注意力机来实现式-4的转换，然后将输出特征串联作为最终输出的特征表示，最终的输出每个节点有KF'个特征。<br />
<img src="/attachments_2022/Pasted%20image%2020220502153904.png"
alt="Pasted%20image%2020220502153904.png" /><br />
其中||表示串联。</p>
<p>当使用多头注意力时，网络的最后一层不应输出太长特征，因此使用均值方法averaging来计算输出特征。<br />
<img src="/attachments_2022/Pasted%20image%2020220502154332.png"
alt="Pasted%20image%2020220502154332.png" /><br />
多头聚合方法如图-1右图所示（一个颜色代表一个头，hi代表邻近节点）。</p>
<h3 id="与之前方法对比">2.2 与之前方法对比</h3>
<p>上述方法解决了之前图神经网络遗留的问题：<br />
*
在计算方面，它非常高效，自注意力层可以并行计算边，输出特征可以在节点上并行。不需要特征分解或类似的复杂运算，单头的时间复杂度可表示为O(|V
|F F ′ + |E|F
′)，其中F是特征数，|V|和|E|是节点和边的个数，复杂度与GCN相当，多头注意力占用的空间和参数由头数K决定，且多头可以并行计算。<br />
*
与GCNs方法不同的是，文中模型允许对同一邻居节点使用不同的权重，从而实现了模型容量的飞跃，此外，学习到的注意力权重可能提升模型的可解释性。<br />
*
注意力机制以共享方式应用于图中所有边，它不依赖全局图结构f无需事先访问所有节点，因此：<br />
* 图不需要是无向的<br />
* 可用于归纳学习，支持在训练时不完全了解全图的任务<br />
*
2017年提出的GraphSAGE方法对节点采样固定数目的邻居，为了保证计算过程的一致性，它不能访问所有邻居，当使用LSTM作为聚合工具时，它得到了更好的效果。文中方法则不受这些因素影响，它使用所有邻居，且不假设其顺序。<br />
*
文中方法可视为MoNet的特例，与Monet相比，文中模型使用节点特征来计算相似性，而不是节点的结构属性。</p>
<h2 id="评价">3. 评价</h2>
<h3 id="数据集">3.1 数据集</h3>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220502160927.png"
alt="Pasted%20image%2020220502160927.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220502160927.png</figcaption>
</figure>
<p>文中共使用了四个数据集，前三个用于测试传导，第四用用于测试归纳，具体数据见表-1。<br />
*
传导数据集中的节点是文档，边是文档间的引用关系（无向），特征是使用词袋模型提取的文档表征，每个节点对应一个类别标签。<br />
*
归纳数据集是PPI（蛋白质相互作用），20张图训练数据，2个测试图，2个验证图，平均每图2372个节点，每个节点50个特征，共121个标签，一个节点可同时拥有多个标签。</p>
<h3 id="对比模型">3.2 对比模型</h3>
<ul>
<li>传导学习：使用多个模型对比，详见表-2，其中效果比较好的有图卷积网络GCN；使用切比雪夫过滤器的Chebyshev；以及MoNet模型。<br />
</li>
<li>归纳学习：主要与使用不同聚合方法的GraphSAGE模型对比，其它几种方法不能用于该数据集。<br />
请注意，用于对比的多层感知机MLP完全没有用到图结构信息。</li>
</ul>
<h3 id="实验设置">3.3 实验设置</h3>
<ul>
<li>传导学习：使用两层GAT模型，第一层多头K=8，每头输出特征数为F'=8，使用ELU激活函数，第二层用于分类，使用单头注意力计算C个特征，C是类别数，后接softmax激活函数。使用了dropout和正则化项，每个节点都可被领域随机采样。<br />
</li>
<li>归纳学习：使用三层GAT模型，前两层多头K=4，每头输出特征F'=256，使用ELU激活函数，最后一层为多标签的分类，使用6头注意力，每头121个特征，然后取均值，后接sigmoid激活函数。由于训练数据量大，因此不使用dropout和正则化项。还与注意力均为1（所有邻居权重相等）且架构相同的模型进行了对比。<br />
两个模型均使用 Glorot
初始化，最小化交叉熵损失函数，使用Adam优化器，early
stopping策略，最多迭代100次。</li>
</ul>
<h3 id="实验结果">3.4 实验结果</h3>
<ul>
<li>传导学习<br />
其中GCN-64*
表示使用64个隐藏层特征。GAT比GCN效果略好，这可能是由于对相同邻居分配不同权重带来的收益。<br />
<img src="/attachments_2022/Pasted%20image%2020220502162314.png"
alt="Pasted%20image%2020220502162314.png" /><br />
</li>
<li>归纳学习<br />
GAT相对之前方法明显提升20.5%，另外对比了相同架构下，与注意力衡定(Const-GAT)相比，分配给相同邻居不同权重使模型效果提升3.5%。<br />
<img src="/attachments_2022/Pasted%20image%2020220502162337.png"
alt="Pasted%20image%2020220502162337.png" /></li>
</ul>
<p>图-2在CORA数据集上，将GAT模型的第一层t-SNE变换将特征表示可视化。图上聚类对应7个标签，证明了模型输出对不同主题的区分能力。<br />
<img src="/attachments_2022/Pasted%20image%2020220502165922.png"
alt="Pasted%20image%2020220502165922.png" /></p>
]]></content>
      <tags>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>图神经网络有多强大GIN</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/12_%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CGIN/</url>
    <content><![CDATA[<h2 id="介绍">介绍</h2>
<p>英文题目：How Powerful are Graph Neural Networks？<br />
中文题目：图神经网络有多强大？<br />
论文地址：https://arxiv.org/pdf/1810.00826.pdf<br />
领域：图神经网络，知识表示<br />
发表时间：2018<br />
作者：Keyulu Xu等，MIT，斯坦福大学<br />
出处：ICLR<br />
被引量：1506<br />
阅读时间：22.06.11</p>
<h2 id="读后感">读后感</h2>
<p>这也是一篇引用量很大的图神经网络精典论文。之前研究方法着重于表示节点，引文着眼于表征图的结构。作者认为之前方法难以区分不同的图结构，并提出了一种基于GNN的方法GIN，它的区分效果与WL-Test效果相当。</p>
<h2 id="介绍-1">介绍</h2>
<p>一般情况下一个节点的表式通过聚合它k跳之内的邻近节点计算，而全图的表示则通过对所有节点的池化计算。</p>
<p>近年来新型GNN的设计主要基于经验直觉、启发式和实验试错法，而对神经网络的性质和局限性的理论较少。文中提出理论框架来分析GNN的能力，这里主要是评价模型是否能够区分网络结构。</p>
<p>文中使用了WL-test方法，即图同构测试，它是一个区分网络结构的强效方法，也是通过迭代聚合邻居的方法来更新节点，它的强大在于使用了injective（见后）聚合更新方法。而这里要评测GNN是否能达到类似WL-test的效果。</p>
<p>文中还使用了多合集multiset的概念，指可能包含重复元素的集合。</p>
<p>论文主要贡献如下：</p>
<ul>
<li>展示了GNN模型可达到与WL-test类似的图结构区分效果<br />
</li>
<li>设计了聚合函数和Readout函数，使GNN能达到更好的区分效果<br />
</li>
<li>发现GCN及GraphSAGE无法很好表达图结构，而GNN可以<br />
</li>
<li>开发了简单的网络结构GIN（图同构网络），它的区分和表示能力与WL-test类似。</li>
</ul>
<h2 id="预备知识">预备知识</h2>
<h3 id="图表征">图表征</h3>
<p>论文主要关注两种任务：一种是对图中节点的分类，通过学习节点表示，以预测节点的类别；另一种是根据图结构分类，通过学习对整个图的表示，预测整图的类别。</p>
<p>这里涉及节点的表示和整图的表示。各节点往往通过它的邻居节点聚合计算，通过k轮迭代后，节点的表示隐式的包含了图的结构信息。GNN第k层计算方法如下：</p>
<p><img src="/attachments_2022/Pasted%20image%2020220611171757.png"
alt="Pasted%20image%2020220611171757.png" /><br />
其中a表示聚合节点v邻近特征的方法，h是特征向量。简单说就是先聚合节点v邻居节点上一层的表示，再与节点v自身上一层的表示相结合。</p>
<p>算法重点在于AGGREGATE和COMBINE的具体算法。比如AGGREGATE常使用乘参数再做池化的方法，而COMBINE常使用串联方法。</p>
<p>对于整图分类任务，使用READOUT函数来聚合节点特征最后一次迭代的结果，生成向量来表征整个图，聚合方法也是可简可繁。<br />
<img src="/attachments_2022/Pasted%20image%2020220611173031.png"
alt="Pasted%20image%2020220611173031.png" /></p>
<h3 id="wl-test">WL-test</h3>
<p>WL-test用于比较两图的拓扑结构是否相同。<br />
<img src="/attachments_2022/Pasted%20image%2020220611205436.png"
alt="Pasted%20image%2020220611205436.png" /><br />
原理如图所示：(a)对于图G与G'，其中每个节点属于某种元素（标签）一共五种元素；(b)利用其邻近节点的标签组合表示当前节点；(c)生成新标签；(d)用新标签表示节点；依照此逻辑不断迭代。最终生成右图中的特征向量用于表征图G和G'。颜色表示标签，数值表示该标签在图中的出现次数。当两图表征不一致时，则认为两图异构。</p>
<h2 id="理论框架">理论框架</h2>
<p><img src="/attachments_2022/Pasted%20image%2020220611175421.png"
alt="Pasted%20image%2020220611175421.png" /><br />
如图-1所示，有一个图（左图），如果想表征其中的蓝色节点，且只考虑两跳；计算方法如中图所示（子树）;
通过迭代，变成了右图所示，每个节点只考虑其邻居，计算邻居时，再考虑邻居的邻居。</p>
<p>算法需要满足injective，injective可译为内射，即可把不同的元素映射成不同输出，在图结构中，不同的邻居结构需要生成不同的节点表征，而max，mean池化显然都不是injective的（后详述）。</p>
<h2 id="建立强大的图神经网络">建立强大的图神经网络</h2>
<p>任何基于聚合的GNN最多与WL-test一样强大，我们要让GNN尽量逼近它，证明请见附录。</p>
<p>GNN公式如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220611192834.png"
alt="Pasted%20image%2020220611192834.png" /><br />
其中f用于处理邻居节点，φ
用于内射。另外，readout也需要具有内射的性质。<br />
除了区分不同的图之外，GNN相对于WL-test还有一个优势是它能将相似的图结构映射到相似的嵌入，并捕获图结构之间的依赖关系。而WL-test只是one-hot编码。</p>
<h3 id="gin网络">GIN网络</h3>
<p>GIN网络，即图同构网络。为了在建模时实现内射，使用加和作为聚合函数，理论上多层感知机可以模拟函数的组合，用以下方法更新GIN的节点表示：<br />
<img src="/attachments_2022/Pasted%20image%2020220611194539.png"
alt="Pasted%20image%2020220611194539.png" /></p>
<h3 id="gin的整图表征">GIN的整图表征</h3>
<p>整图分类任务，需要使用readout根据节点嵌入计算整图嵌入。计算方法如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220611200652.png"
alt="Pasted%20image%2020220611200652.png" /><br />
用串联的方法连接了节点所有迭代步的表示，使用所有迭代是因为，随着迭代次数增加，节点能实现更加全局和精炼的表示，而早期迭代的结果则更容易泛化。</p>
<h2 id="功能较弱的gnn">功能较弱的GNN</h2>
<p>使用消融实验对比，展示上述公式的有效性。</p>
<h3 id="单层感知机与多层感知机">单层感知机与多层感知机</h3>
<p>单层感知机不能充分地捕获结构相似性，具体见实验结果。</p>
<h3
id="平均池化和最大池化不能区分结构">平均池化和最大池化不能区分结构</h3>
<p>平均池化和最大池化都不是内射的，如图-2，图-3 所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220611202410.png"
alt="Pasted%20image%2020220611202410.png" /><br />
图-2展示了在多合集情况下，sum的效果最好，mean次之，max最差。</p>
<p>图-3中不同颜色表示不同实体，其中图2-a中两图结构不同，但平均池化和最大池化不能加以区分，而求和可以区分；图-2b中平均池化可区分两图，但最大池化取红与绿中最大值不能区分两图；同理，使用平均池化和最大池化也不能区分图-3c中的两个图。</p>
<h3 id="平均池化学习分布">平均池化学习分布</h3>
<p>平均池化不能识别某一元素出现的次数，因此，它可以捕捉实体的特征分布，但不能精确描述多合集。平均池化比较适合只看有没有，不看有多少的任务，或者特征多，重复少的任务。</p>
<h3 id="最大池化学习不同元素的集合">最大池化学习不同元素的集合</h3>
<p>最大池化适合捕捉具有代表性的元素或“骨架”，而不是区分确切的结构或分布的任务。</p>
<h3 id="其它池化方法">其它池化方法</h3>
<p>还有其它池化方法，如：加权平均，LSTM池化等，而对判断同构问题来说文中使用的求和方法具有足够的表征能力。</p>
<h2 id="实验">实验</h2>
<h3 id="数据集">数据集</h3>
<p>实验使用了9个数据集，其中五个生物医疗，四个社会网络，主要以捕捉结构为主。</p>
<p>实验结果如图-4所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220611204535.png"
alt="Pasted%20image%2020220611204535.png" /><br />
<img src="/attachments_2022/Pasted%20image%2020220611204657.png"
alt="Pasted%20image%2020220611204657.png" /></p>
]]></content>
      <tags>
        <tag>图神经网络</tag>
        <tag>知识表示</tag>
      </tags>
  </entry>
  <entry>
    <title>基于动态辩论的知识图推理</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/12_%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%9F%BA%E4%BA%8E%E5%8A%A8%E6%80%81%E6%90%8F%E5%BC%88%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%8E%A8%E7%90%86/</url>
    <content><![CDATA[<h1 id="介绍">介绍</h1>
<p>英文题目：Reasoning on Knowledge Graphs with Debate
Dynamics（R2D2）<br />
中文题目：基于动态辩论的知识图推理<br />
论文地址：https://arxiv.org/pdf/2001.00461.pdf<br />
领域：图神经网络, 知识推理<br />
发表时间：2020<br />
出处：AAAI 2020<br />
被引量：6<br />
代码和数据：https://github.com/m-hildebrandt/R2D2</p>
<p>#自然语言处理 #知识推理 #论文阅读</p>
<h2 id="读后感">读后感</h2>
<ul>
<li>针对问题：基于图的自动知识推理<br />
</li>
<li>目标：提升对真命题和伪命题的识别，提升可解释性<br />
</li>
<li>结果：对于分类和链接预测任务均有良好表现，且实现了一些归因。<br />
</li>
<li>核心方法：
<ul>
<li>利用动态辩论的强化学习算法。<br />
</li>
<li>这是一个相对白盒的方法<br />
</li>
<li>采用两个agent的对抗，一个找真命题相关路径，一个找假命题相关路径，使用知识图中的路径作为参数生成特征，最终由判别器做出判断推理的真伪。<br />
</li>
</ul></li>
<li>具体模型：深度学习模型，两个Agent使用LSTM，判断使用MLP<br />
</li>
<li>难点：对抗学习应用于图论和知识推理。<br />
</li>
<li>泛读后理解程度：60%<br />
（看完题目、摘要、结论、图表及小标题）</li>
</ul>
<h2 id="精读">精读</h2>
<p>（只翻译了实现部分）</p>
<h3 id="方法">3. 方法</h3>
<p>文中方法由三部分组成：一个分类器judge和两个agent。agent用于在知识图（KG）中寻径，两个agent分别寻找支持各自论点的证据：基于逐渐训练的模型，决定在每一个node上如何选择下一跳；并将每一跳记入当前路径；所有路径都作为judge判断的依据，来训练和预测推理是否为真。</p>
<p>如图-1所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220222093729.png"
alt="Pasted%20image%2020220222093729.png" /><br />
图中各种颜色的线都是已存在的边edge，其中蓝色线是judge的推理：Jordan是不是专业的篮球运动员；绿色的边是agent1找到的认为该假设成立的证据；红边是agent2找到的认为该假设不成立的证据。</p>
<p>可以看到，模型通过训练（包括judge判断子模型、两个agent子模型寻径的方法，都学习成网络参数）。最终模型不仅能做出推理，且能展示推理相关的证据链。</p>
<p>其推理如下：</p>
<p><strong>States</strong><br />
将可观察的状态定义为S，每个agent在某个时点的状态定义为e，t为时间点，i指定是哪个agent，q=(s,p,o)是一个三元组，s,p,o分别指主谓宾。将状态定义为：<br />
<span class="math display">\[S_t^{(i)}=(e_t^{(i)},q)\]</span><br />
<strong>Actions</strong><br />
将在状态S时所有可能的动作定义为A（原地不动也是一种动作self-loops），它包含所有从e点出发的边和相关的目标结点，A定义为：<br />
<span class="math display">\[A_{S_t^{(i)}}=\{(r,e)\in
R\times\xi:S_t^{(i)}=(e_t^{(i)},q)\land(e_t^{i},r,e)\in
Kg\}\]</span></p>
<p><strong>Environments</strong><br />
将环境定义为：agent动作更新状态的过程</p>
<p><strong>Policies</strong><br />
将agent一系列的行为定义为策略。第一步仅是一个主谓宾三元组，而后每一步根据其动作和上一步的状态来决定，通常将每个agent的动作历史通过LSTM编码。<br />
<span
class="math display">\[h_t^{(i)}=LSTM^{(i)}([a_{t-1}^{(i)},q^{(i)}])\]</span><br />
其中的动作a也隐含了之前的状态，q是对三元组的编码。实体和关系嵌入是每个agent特有的，在训练和搏奕过程中学习。</p>
<p>将每一步每一个动作可能的概率分布定义为d：<br />
<span
class="math display">\[d_t^{(i)}=softmax(A_t^{(i)}(W_2^{(i)}ReLU(W_1^{(i)}h_t^{(i)})))\]</span><br />
其中A包含了S状态所有可能的潜在行为。</p>
<p>最终训练出的策略，就是上述公式中学习到的一系列模型参数。</p>
<p><strong>Debate Dynamics</strong><br />
动态辩论，φ(q) ∈
{0,1}是agent针对三元组q得出的结果，agent1尽量找到结构为true的三元组，agent2则相反。设共辩论T次（上例中辩论了两次），用τ
表示论据。</p>
<p><strong>The Judge</strong><br />
送别器由两部分组成，第一部分是二分类器，第二部分用于评价论据的质量，并将结果回传给agent，以供agent调参，使agent通过训练更好地寻找证据。</p>
<p>模型结构如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220222094124.png"
alt="Pasted%20image%2020220222094124.png" /></p>
<p>对于每一步(第n步）计算判别结果y。<br />
<span
class="math display">\[y_n^{(i)}=f([\tau_n^{(i)},q^J])\]</span><br />
需要注意的是，这里的判断不是根据q的主谓宾做出的，而是根据agent的行为做出的。</p>
<p>最终，对所有步的综合得分如下，它加入了每个agent每一步的y：<br />
<span
class="math display">\[t_\tau=\sigma(w^TReLU(W\sum_{i=1}^2\sum_{n=1}^Ny_n^{(i)}))
\]</span><br />
损失函数使用交叉熵：<br />
<span class="math display">\[L_q=\phi(q)log
t_{\tau}+(1-\phi(q)(1-logt_{\tau})\]</span><br />
在训练过程中，优化每一步的损失，并使用L2惩罚以避免过拟合。</p>
<p><strong>Reward</strong><br />
为了给每个agent更多反馈信息，judge可以分别计算两个agent的t。</p>
<p><strong>Reward Maximization and Training Scheme</strong><br />
反馈最大的训练方案：文中利用强化学习来最大化agent的累积反馈，信息增益是反馈R的累积。<br />
构建KG+，它包含在KG中未观察到的三元组，其基本原理如下：由于KG只包含真实事实，因此，创建负标签的数据集。对(s，p，o)∈KG，生成(s，p，!o)构造KGc。KG+
:=KG ∪ KGc。（我理解好像是以此方法构造反例）。<br />
另外，优化的方法还包括：在开始迭代时先冻结agent的权重，先训练judge的权重；用移动平均线减少误差；用正则化强化探索等。</p>
<h2 id="一些问题">一些问题</h2>
<p>看论文过程中一直没太明白，为什么可以根据图中的红色边+绿色边，就能推断蓝色边？我觉得可能是：传入模型的是node和edge的嵌入（比如：一开始可能是词嵌入或者图嵌入），如示例中所示：Jardan是专业的蓝球运动员（蓝色），可以通过公牛队，NBA（绿色）这些词嵌入得到职业的相关性；而明显与儿童电影，棒球（红色）相关的职业相反；黑色的性别、国籍则与之无关。</p>
]]></content>
      <tags>
        <tag>图神经网络</tag>
        <tag>知识推理</tag>
      </tags>
  </entry>
  <entry>
    <title>基于知识图谱的约束性问答</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/12_%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%9F%BA%E4%BA%8E%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E7%BA%A6%E6%9D%9F%E6%80%A7%E9%97%AE%E7%AD%94/</url>
    <content><![CDATA[<h2 id="读后感">读后感</h2>
<ul>
<li>针对问题：利用当前的知识库(KB)，回答用自然语言提出的问题。<br />
</li>
<li>目标：一方面开发用于评价约束性问答的数据集；另一方面开发针对约束性问答的解决方法。<br />
</li>
<li>结果：产出评测数据集；提出的多约束查询图算法提升了对复杂问题的解答能力。<br />
</li>
<li>核心方法：
<ul>
<li>复杂问题的分类和处理机制，抽象出六种约束类型，以及对应各类问题的解决方法。<br />
</li>
<li>方法
<ul>
<li>找到问题相关实体节点<br />
</li>
<li>找到满足约束的所有路径<br />
</li>
<li>将与问题语义相似度最高的作为答案<br />
</li>
</ul></li>
</ul></li>
<li>难点：整个过程中约束到底如何产生作用。<br />
</li>
<li>泛读后理解程度：直接精读<br />
（看完题目、摘要、结论、图表及小标题）</li>
</ul>
<h2 id="介绍">介绍</h2>
<p>英文题目：Constraint-Based Question Answering with Knowledge
Graph<br />
中文题目：基于知识图谱的约束性问答<br />
论文地址：https://readpaper.com/paper/2572289264<br />
领域：图神经网络、问答系统<br />
发表时间：2016<br />
出处：acl<br />
被引量：142<br />
代码和数据：https://github.com/JunweiBao/MulCQA/tree/ComplexQuestions<br />
阅读时间：2022.03.20</p>
<p>#自然语言处理 #图神经网络 #论文阅读</p>
<h2 id="摘要">摘要</h2>
<p>WebQuestions和SimpleQuestions是近年来常用的基于知识的问答系统（KBQA）数据集，它们之中大多是简单问题，即在现成的数据三元组中就能找到答案，它们缺乏对复杂问题的评价能力。为此，文中提出建构新的数据集，用于评价需要多种知识相关性才能得到答案的复杂问题。另外，文中提出KBQA方法来解决多约束问题。相对于现有方法，文中方法在现有的两个基准数据集上获得了与之前模型差不多的结果，并在复杂问题上取得了显著的改进。</p>
<h2 id="引言">1. 引言</h2>
<p>基于知识库的问答任务（KBQA）是：利用当前的知识库(KB)，回答用自然语言提出的问题。Freebase是个类似wikipedia的网站，在本文中被用做待查的知识库。WebQuestions和SimpleQuestion两个数据集常被用于评测KBQA问题。</p>
<p>WebQuestion是85%的问题，以及SimpleQuestion中的所有问题都是“简单”问题。所谓简单问题是使用单个关系链接就可以回答的问题（主谓宾三元组），如图一上图中所示的问题。<br />
<img src="/attachments_2022/Pasted%20image%2020220306210333.png"
alt="Pasted%20image%2020220306210333.png" /><br />
图一中的下图则是复杂问题，它用两个条件得出一个结果。其中的“多约束”是指包含用不同表达式表示的多个语义约束，以限制答案集。回答此类问题需要结合多种关系。</p>
<p>论文的两个主要贡献是：<br />
*
系统地提出了解决多约束问题的方法：将多约束问题（MulCQ）转换成多约束查询图MulCG。<br />
*
建立新的QA数据集ComplexQuestions，用于评测多约束问题。且文中模型在复杂数据集上有显著提升。</p>
<h2 id="多约束问题">2. 多约束问题</h2>
<h3 id="约束的分类">2.1 约束的分类</h3>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220314133044.png"
alt="Pasted%20image%2020220314133044.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220314133044.png</figcaption>
</figure>
<p>多约束问题被定义为需要多个连接或者需要特殊转换才能找到答案的问题，将其分为六大类：</p>
<ol type="1">
<li>多实体约束：一个问题涉及多个实体，比如表-1中问题1的"Forest
Whitaker", "Mark Rydell"共同限制了答案。<br />
</li>
<li>类型约束：问题中指定了答案的类型，比如表-1中问题2限制了回答的类型为City。<br />
</li>
<li>显性时间约束：显示地约束了时间，如表-1中问题3限制了2012年，这种问题很常见。<br />
</li>
<li>隐性时间约束：隐性地约束了时间，如表-1中问题4限制时间在南北战争开始时，处理时需要先将期变换为显性时间，这类约束常出现在从句中。<br />
</li>
<li>顺序约束：问题答案通常需要通过排序才能得到，一般在问题中用最高级短语描述排序规则，如表-1中问题5，回答时需要先对中国河的长度进行排序。<br />
</li>
<li>聚合约束：这类问题通常需要通过统计求出，比如表-1中问题6问个数。</li>
</ol>
<h3 id="选择问题构建复杂问题数据集">2.2 选择问题构建复杂问题数据集</h3>
<p>使用以下步骤筛选基于FreeBase能找到答案，且为多约束的问题，然后进行人工标注。<br />
首先，取2015.1.1-2015-4.1搜索引擎三个月的问题，它们满足以下两个条件：不包含代词；问题长度在7-20个单词之间，这是因为问题太短一般不包含约束条件，问题太常又难以回答。进一步采样其中的10%，使用实体链接方法来检测实体，去掉不包含实体的问题；去掉除了实体和停用词不包含其它词的问题；最后将问题分类如下：</p>
<ol type="1">
<li>问题至少包含两个不重叠的实体<br />
</li>
<li>问题包含FreeBase中的类型短语<br />
</li>
<li>问题包含NER可识别出的时间日期<br />
</li>
<li>问题中包含关键字，如“when”,"before","after","during"<br />
</li>
<li>问题中包含WordNet中的最高级短语或序号<br />
</li>
<li>问题中包含对个数的提问。</li>
</ol>
<p>问题可以包含一个或多个约束，满足条件的有上万条问题，根据其分布筛选问题，然后根据FreeBase中的知识进行手动标注，最终获取了878个问答对。</p>
<h3 id="问题说明">2.3 问题说明</h3>
<p>最终发布的复杂问题数据集，包括2100个多约束问题答案对，包括下面三种来源：<br />
(1) 596个从WebQuestions训练集中选择，326从其测试集中选择。<br />
(2) 300个在2015年由 Yin et al... 发布<br />
(3) 878个基于上一节的方法标注<br />
将其分成训练集1300和测试集800两部分。</p>
<h2 id="定义">3. 定义</h2>
<h3 id="知识库">3.1 知识库</h3>
<p>用K表示知识库，以三元组triple(t)的方式组织数据，比如主语subject(s)是BarackObama，谓语predicate(p)是
birthday，宾语object(o)是1961。主语和宾语一般是实体或者数值，谓语常用于描述关系。</p>
<h3 id="多约束查询图">3.2 多约束查询图</h3>
<p>首先定义四种元素：<br />
<strong>节点</strong>：<br />
文中定义了两种类型的节点，已知的恒定节点（方）和未知的可变节点（圆）。<br />
<strong>边</strong>：<br />
文中定义了两种类型的边，关系边和功能边，上例中的动词birthday是关系边，功能边用于表示大于小于等函数关系，如表-2所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220317104759.png"
alt="Pasted%20image%2020220317104759.png" /><br />
<strong>基本查询图</strong>：<br />
基本查询图定义为(vs,p,vo)，vs表示问题中给出的恒定的节点，vo是可变节点，它隐藏在答案之中，p是连接两者的路径，它可能由一条边或多条边构成。<br />
<strong>约束</strong>：<br />
约束定义为三元组(vs,r,vo)，vs是恒定节点，vo是可变节点，r是功能边，实例化后，vo与实体vs需满足关系r。<br />
<strong>MulCG</strong>：<br />
Multi-constraint query graph多约束查询图
，MulCG基于基本查询图B，它包含一个问题和一系列的约束C={C1,...CN}，最终输出符合条件的图gN，它满足所有约束。<br />
从基本查询图的恒定节点开始，根据约束，遍历所有的可变节点，整个过程中所有被连接的实体关系都应满足相关性关系以及常识。<br />
<img src="/attachments_2022/Pasted%20image%2020220317110230.png"
alt="Pasted%20image%2020220317110230.png" /></p>
<p>图-2展示了MulCG的一个示例，文中的恒定实体是United
States，可变实体是x和y，两条边为officals,
holder，三个约束分别为C1=(President,Equal,y1),C2=(2000,&lt;,y2)，C3=(1,MaxAtN,y2)。注意，不同的约束顺序可能造成不同结果。</p>
<h2 id="方法">4. 方法</h2>
<p>问题定义如下：将多约束定义为Q，知识定义为K，将问题解析成一系列约束H(Q），对于每一个g
∈ H(Q)，得到节点的特征F(Q,g)，通过排序，得分最高分结果作为答案。</p>
<h3 id="生成基本查询图">4.1 生成基本查询图</h3>
<p>搜索问题中提到的实体，将每个实体s作为恒定节点，基于知识图，搜索s相关的路径（限定跳数），建立基本查询图一跳(s,p0,x)或两跳&lt;s,p1-yout-p2,x&gt;，yout和x都是可变节点，x为最终答案。</p>
<p>使用基于卷积网络CNN的模型计算问题与基本查询经过路径的相似度，此部分将在4.4详述。</p>
<h3 id="约束检测和绑定">4.2 约束检测和绑定</h3>
<p>一个基本查询图只对应一种关系，对于多约束，需要将所有约束逐条加入，每一条约束具体又包含约束搜索和约束绑定。<br />
<img src="/attachments_2022/Pasted%20image%2020220317115201.png"
alt="Pasted%20image%2020220317115201.png" /></p>
<p><strong>(1) 实体约束</strong><br />
对实体的约束常作为恒节点，比如图-3(a)是一个多实体问题，Forest Whitaker和
Mark
Rydell指向不同实体，最初生成的基本查询图是g0=B，然后，<strong>搜索</strong>到了约束1：C1=(Mark
Rydell, Equal,
y1)，然后将边director<strong>绑定</strong>到g0，从而，将变量节点Ci与gi-1通过路径相连。<br />
约束可以让任何节点与基本查询图连接；对实体的约束绑定，常常用于解决消歧问题。</p>
<p><strong>(2) 类型约束</strong><br />
对答案的类型约束常常由名词给出，比如图3-a中的“film”就是类型约束。<strong>搜索</strong>时，对于知识的类型，构建了形如C2=(film,Equal,y2)的类型约束；<strong>绑定</strong>时，类型限制加在可变节点上，该节点具有边类型的答案。</p>
<p><strong>(3) 显性时间约束</strong><br />
时间约束常常描述为介词短语或从句中的数字，如"after
2000"，图-2中，from连接了y0和y2，函数约束C2=(2000,&lt;,y2)，它筛选了y0相关实体中大于2000的子集。先<strong>搜索</strong>时间短语，比如2000，小于号通过表2中字典建立约束Ci=(t,r,y1)；搜索到时间约束后，如果知识图中有路径p连接的实节满足条件，则将约束<strong>绑定</strong>关系。</p>
<p><strong>(4) 隐性时间约束</strong><br />
图-3(b)
中描述的"南北战争之后"触发了隐性时间约束，它使用了时间状语从句。由于命名实体识别不能识别隐性时间约束，因此使用预定义词的方式<strong>搜索</strong>，然后将其转换成显式时间约束；<strong>绑定</strong>方法与显性时间约束一样。</p>
<p><strong>(5) 顺序约束</strong><br />
顺序约束通常通过形容词或副词的数字和最高级形式表示，比如图-2中的first，通过对答案中节点的排序的MaxAtN函数，得到最终结果。<strong>搜索</strong>使用WordNet中提取的序列数表和最高级表来检测关键词，再用数学函数来计算约束Ci=(n,op,yi)；如果与边相连的可变节点满足条件，使用词嵌入与最高级词最相关的词<strong>绑定</strong>路径，如此例中使用from绑定。</p>
<p><strong>(6) 聚合约束</strong><br />
当问题以"how many"开头，或者包含"number of", "count
of"等关键字时，实现时需要统计答案节点中的实体个数。</p>
<h3 id="生成搜索空间">4.3 生成搜索空间</h3>
<p>算法1描述了生成搜索空间H(Q)的过程：<br />
<img src="/attachments_2022/Pasted%20image%2020220306215958.png"
alt="Pasted%20image%2020220306215958.png" /><br />
E是将Q作为输入检测到的与之链接的实体集合。<br />
用s遍历E中实体，将s和知识库K作为输入，得到所有基本查询图gb，然后将它们中的每一条都加入H(Q)和T，T表示临时数据集。<br />
用gb遍历临时数据集T，基于gb,E,Q,K，找到相关的所有约束C，Permutation(C)返回所有可能的约束的索引号，对于每个索引号，试图找到临时数据集中能与之绑定的查询图gc，将其插入候选集H(Q)。</p>
<h3 id="特征和排序">4.4 特征和排序</h3>
<p><img src="/attachments_2022/Pasted%20image%2020220306214810.png"
alt="Pasted%20image%2020220306214810.png" /><br />
使用孪生卷积网络来计算两个字符序列的相似度，输入是两个字符序列，将它们映射成k维的字符向量，与词汇匹配方法相比，连续空间表示方法显示出更好的结果。</p>
<p>对于两个序列Sl和Sr，分别加入了S和E来标记开始和结束，首先把输入词转换成one-hot
vector，然后查表找到其词嵌入，再通过卷积加入3个词的上下文信息得到上下文向量特征，用最大池化来提取最显著的局部特征，生成定长的全局特征，最后用一个多层感知机将池化层转换到语义层，两边分别得到Hl和Hr，然后用cosine(Hl,Hr)来计算二者的距离，得到两个序列的相似度。</p>
<p>基于上术CNN模型，为基本序列图（Basic Query
Graph）设计了表-3中的四个特征，为约束也提供四类特征，分别是指示特征I，计数特征N，约束搜索特征V和约束绑定特征P。<br />
<img src="/attachments_2022/Pasted%20image%2020220319211606.png"
alt="Pasted%20image%2020220319211606.png" /></p>
<h2 id="实验">5. 实验</h2>
<h3 id="设置">5.1 设置</h3>
<p>使用三个数据集测试，ComplexQuestions（CompQ）是上文中提到的新生成包含2100问答的数据集；WebQuestion（WebQ）包含3778训练集，2032测试集，由人基于Freebase知识库手工标注；SimpleQuestion（SimpleQ）中每个问题都是人工编辑的知识库三元组。</p>
<h3 id="结果和分析">5.2 结果和分析</h3>
<p>实验结果如图-4所示，将STAGG作为Baseline：<br />
<img src="/attachments_2022/Pasted%20image%2020220319214004.png"
alt="Pasted%20image%2020220319214004.png" /><br />
对于简单问题与STAGG效果类似，对于复杂的约束问题明显优于STAGG，尤其是使用了Constraint约束训练的模型效果有明显提升，另外，加入了更多的WebQ和SimpleQ训练数据后，模型效果也有所提升。</p>
<h2 id="相关工作和讨论">6. 相关工作和讨论</h2>
<p>2015年在基于知识的问答(KBQA)中，使用字典特征或CNN的方法对于简单关系问题就得到了较好的效果。<br />
WebQuestions和SimpleQuestion是两个用于评测KBAQ任务的数据集，其中大多数是简单问题。之前的研究也大多针对简单问题展开，近几年也提出一些针对多实体和约束的方法，但并没有具体评估它们的KBQA系统，也没有系统地给出多约束问题的解决方案。</p>
<h2 id="总结">7. 总结</h2>
<p>发布了ComplexQuestions数据集用于评价多约束问题，并提出了KBQA方法解决多约束的图问题，且得到了良好的实验效果。</p>
]]></content>
      <tags>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_多类型实体的图对齐_CGMuAlign</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/12_%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%A4%9A%E7%B1%BB%E5%9E%8B%E5%AE%9E%E4%BD%93%E7%9A%84%E5%9B%BE%E5%AF%B9%E9%BD%90_CGMuAlign/</url>
    <content><![CDATA[<h2 id="读后感">读后感</h2>
<p>文中的一个重要思想是：认为被对齐的图中的知识都是不完备的，所以在图间对齐时，主要对齐对些能齐上的，忽略那些对不上的；同时结构了自注意力模型，对不同关系分配不同权重。</p>
<h2 id="多类型实体的图对齐_cgmualign">多类型实体的图对齐_CGMuAlign</h2>
<p>英文题目：Collective Multi-type Entity Alignment Between Knowledge
Graphs<br />
中文题目：基于知识图的集合多类型实体对齐<br />
论文地址：https://assets.amazon.science/ff/7a/b96282984a0fbe5e31a8fcf68d17/scipub-1202.pdf<br />
领域：知识图谱，实体对齐<br />
发表时间：2020年<br />
作者：Qi Zhu，伊利诺伊大学，亚马逊<br />
出处：the web conference<br />
被引量：17<br />
代码和数据：https://github.com/GentleZhu/CG-MuAlign<br />
阅读时间：2022.04.25</p>
<h3 id="介绍">介绍</h3>
<p>实体对齐的目标是识别不同图中的同一实体。不同的图在建构的时候由于目标不同，各有偏重。比如图-1中的左右两张图：<br />
<img src="/attachments_2022/Pasted%20image%2020220508162326.png"
alt="Pasted%20image%2020220508162326.png" /></p>
<p>图中的Aditya
Raj是同一实体，在左图中他即是作者也是编辑，而右图中它是作者和制作人，即：在不同图中实体有不同的类别。使用不同策略，对齐结果也不同。</p>
<p>实体对齐中常见的问题包括：使用图嵌入做对齐，忽略了丰富的属性信息，在传导模型中，加入新实体需要重新训练模型；模型常常在训练数据丰富时效果较好，而在稀疏和缺少的类型中效果较差（如有些数据没有标签）。</p>
<p>作者希望用GNN方法解决上述问题，GNN方法通过逐步整合邻域，来实现归纳模型并计算之前没出现过的实体。测试后发现效果并不好，原因是之前方法认为节点完全一致的情况下才算对齐，两图的偏重不同就可能对不齐。比如图-1中IMBD包含编辑、导演、演员信息，而Freebase中包含导演和制作人信息。</p>
<p>所以文中提出了集成决策，设计了注意力机制在图间更关注实体的共同邻居作为正向证据。比如图-1中左图出现四部电影，右图出现两部电影，用之前的方法，不同邻居将产生不同节点嵌入，而文中方法给共同的邻居电影以更大权重。对于负例，使用自注意力机制，如两个同系列的电影可能有相同的作家、导演和演员，但年份和长度不同，对不同边给予不同权重。</p>
<h3 id="主要贡献">主要贡献</h3>
<ul>
<li>提出基于GNN的CG-MuAlign框架，支持对齐不同类型。<br />
</li>
<li>结合了自注意力和图交叉注意力方法。<br />
</li>
<li>优化算法，使模型能在大规模数据集上使用。<br />
</li>
<li>在数据量大，标注量小的情况下，模型效果好。</li>
</ul>
<h3 id="算法">算法</h3>
<h4 id="整体结构">整体结构</h4>
<p>定义图为： G = (V, E, T , R) ，求节点映射 φ : V → T和边映射 ψ : E →
R。注意这里的T指的不是三元组，而是节点类型。用S表示对齐种子（标注数据），只有少量数据被标注。</p>
<p>模型包含两个GNN编码器和一个对齐层。编码器从节点v得到k跳子图用于收集邻居信息：<br />
<img src="/attachments_2022/Pasted%20image%2020220508174726.png"
alt="Pasted%20image%2020220508174726.png" /><br />
对于节点i，利用它的邻居们j在前一层的表示，计算它的表示z，再利用z和i节点本身在上一层的表示求它在本层的表示：<br />
<img src="/attachments_2022/Pasted%20image%2020220508174912.png"
alt="Pasted%20image%2020220508174912.png" /><br />
两个图的GNN结构和参数都相同，经过多层最终输出为两个GNN的隐藏层h，计算距离损失函数：<br />
<img src="/attachments_2022/Pasted%20image%2020220508175310.png"
alt="Pasted%20image%2020220508175310.png" /><br />
这个公式之前文章中讲过，γ为加大正例和负例间的距离。d是二范数的距离函数。模型结构如图-3所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220508175434.png"
alt="Pasted%20image%2020220508175434.png" /></p>
<h4 id="集成gnn">集成GNN</h4>
<p>首先，根据边的类型对i的邻居编组Ni,r，使用不同转换函数（参数矩阵W），比如图-1左图作为作者有三个邻居，作为编辑有一个邻居，对每种邻居计算z：<br />
<img src="/attachments_2022/Pasted%20image%2020220508180151.png"
alt="Pasted%20image%2020220508180151.png" /><br />
当图-2中一个人同时是作者和制作人时，上述方法可描述不同角色。</p>
<p>设节点级的注意力参数为a，边级的注意力参数为b，使用以下聚合方法，计算整体的z：<br />
<img src="/attachments_2022/Pasted%20image%2020220508185058.png"
alt="Pasted%20image%2020220508185058.png" /><br />
然后计算第k层的隐藏层<br />
<img src="/attachments_2022/Pasted%20image%2020220508185143.png"
alt="Pasted%20image%2020220508185143.png" /><br />
其中||指串联，上述方法命名为COLLECTIVEAGG。<br />
每个encoder堆叠了多个层，k-1层的输出作为k层的输入，第0层的输入是节点特征，允许不同类型特征有不同长度，所以第一层的W大小可能不同，后面层长度都一样。</p>
<h4 id="节点级的交叉图注意力">节点级的交叉图注意力</h4>
<p>图结构差异主要是由知识图中的不完备性引起的。在CG-MuAlign中，对于在两图中都有的邻居给予更高的权重。设p与q是节点的邻居对
(p, q) ∈ Ni × Ni′ ，式-4中的a计算如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220508190423.png"
alt="Pasted%20image%2020220508190423.png" /><br />
上式对ap和aq进行了归一化处理。a越大说明p和q越像。如图-2a所示，算法给作为writer两项更高权重（红框），所以说图间注意力更偏重正例。<br />
<img src="/attachments_2022/Pasted%20image%2020220508191325.png"
alt="Pasted%20image%2020220508191325.png" /></p>
<h4 id="边级别的关系感知自注意力">边级别的关系感知自注意力</h4>
<p>如果邻居只依赖交叉注意力聚合，则难以利用负面证据。比如在亚马逊音乐和维基百科中都有歌曲《Radioactive》，交叉注意力发现它们在图中的作者制作人等多数信息都相同，但演唱者不比，所以不是同一个实体，这说明对于歌曲，演唱者比作者制作人更重要。用GAN类似方法，计算边的注意力：<br />
<img src="/attachments_2022/Pasted%20image%2020220508193147.png"
alt="Pasted%20image%2020220508193147.png" /><br />
注意这里的a向量是注意力权重，而不是上面的a(alpha)。<br />
<img src="/attachments_2022/Pasted%20image%2020220508192138.png"
alt="Pasted%20image%2020220508192138.png" /></p>
<h4 id="扩展">扩展</h4>
<p>上述方法训练和应用运算量大，利用下面三种方法优化。</p>
<p><strong>简化计算</strong><br />
基于开放世界假设，设Gu为完全知识图，而需要对齐的G和G'各有包含Gu的部分知识，设K为跳数。经过一系列推理（此处略过），说明随着K的增长，集合能力（上面公式中的集合方法）的期望呈几何衰减，服从长尾分布，所以只需要在最后一层使用集合方法以节约算力，其它均使用平均聚合方法：<br />
<img src="/attachments_2022/Pasted%20image%2020220508194849.png"
alt="Pasted%20image%2020220508194849.png" /></p>
<p><strong>小批量训练和对邻居采样</strong><br />
传统图模型使用全局训练，在大数据集上无法应用。文中方法在训练数据的正样本对中采样，并构建K跳的子图，以节约算力。<br />
另一个技巧是尽量对关系重要的邻居采样，以提升集合能力。比如一部电影一般是一个导演多个演员，所以导演携带更多信息。对不同关系的采样概率设置如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220508195707.png"
alt="Pasted%20image%2020220508195707.png" /></p>
<p><strong>生成候选集</strong><br />
上述方法解析了训练算力问题，而预测时，可能需要面对数以百万计的实体。在生成候选集时，对于每个测试节点，使用几个强关键字(如人名和出生日期)来收集可能的匹配实体，并使用CG-MuAlign来预测候选对中的比对得分。</p>
<h3 id="实验">实验</h3>
<p>实验使用两个大数据集：电影数据和音乐数据集。<br />
<img src="/attachments_2022/Pasted%20image%2020220508200504.png"
alt="Pasted%20image%2020220508200504.png" /><br />
对比基线也都是非常流行的模型<br />
<img src="/attachments_2022/Pasted%20image%2020220508201136.png"
alt="Pasted%20image%2020220508201136.png" /><br />
还对比了只使用Self或Cross的效果<br />
<img src="/attachments_2022/Pasted%20image%2020220508200921.png"
alt="Pasted%20image%2020220508200921.png" /><br />
与之前深度学习模型相比运行时间短。<br />
<img src="/attachments_2022/Pasted%20image%2020220508201244.png"
alt="Pasted%20image%2020220508201244.png" /></p>
]]></content>
      <tags>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>基于大图的归纳表示学习</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/12_%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%A4%A7%E5%9B%BE%E7%9A%84%E8%8A%82%E7%82%B9%E8%A1%A8%E5%BE%81GraphSAGE/</url>
    <content><![CDATA[<h1 id="介绍">介绍</h1>
<p>英文题目：Inductive Representation Learning on Large Graphs<br />
中文题目：基于大图的归纳表示学习<br />
论文地址：https://arxiv.org/abs/1706.02216<br />
领域：知识图谱，知识表征<br />
发表时间：2017<br />
作者：William L. Hamilton，斯坦福大学<br />
出处：NIPS<br />
被引量：2398<br />
代码和数据：https://github.com/williamleif/GraphSAGE，pyg和dgl均有对该方法的支持<br />
阅读时间：2022.05.03</p>
<h1 id="读后感">读后感</h1>
<p>学习大图、不断扩展的图，未见过节点的表征，是一个很常见的应用场景。GraphSAGE通过训练聚合函数，实现优化未知节点的表示方法。之后提出的GAN（图注意力网络）也针对此问题优化。<br />
文中提出了：传导性问题和归纳性问题，传导性问题是已知全图情况，计算节点表征向量；归纳性问题是在不完全了解全图的情况下，训练节点的表征函数（不是直接计算向量表示）。<br />
图工具的处理过程每轮迭代（
一次propagation）一般都包含：收集信息、聚合、更新，从本文也可以更好地理解，其中聚合的重要性，及优化方法。</p>
<h1 id="泛读">泛读</h1>
<ul>
<li>针对问题：大图的节点表征<br />
</li>
<li>结果：训练出的模型可应用于表征没见过的节点<br />
</li>
<li>核心方法：改进图卷积方法；从邻居节点中采样；考虑了节点特征，加入更复杂的特征聚合方法<br />
</li>
<li>难点：需要预先了解图卷积网络<br />
</li>
<li>泛读后理解程度：直接精读<br />
（看完题目、摘要、结论、图表及小标题）</li>
</ul>
<h1 id="精读">精读</h1>
<h2 id="摘要">摘要</h2>
<p>使用低维向量表示大图中的节点对下游的预测任务非常有用，但目前方法大多依赖训练集中所有节点；这些方法具有传导性，但不能用于没见过的节点。文中提出了<strong>GraphSAGE</strong>方法，这是一个通用的归纳框架，它均衡节点的特征信息，并可为未见过的节点构建有效的词嵌入方法。与之前为每个节点训练单独的嵌入向量不同，文中方法学习一个函数利用从节点近邻中采样和聚合特征来构建新的节点嵌入。</p>
<h2 id="介绍-1">1. 介绍</h2>
<p>使用低维向量表示大图中节点的基本思路是把稀疏数据压缩到稠密的低维度，然后应用于下游的分类、聚类、链接预测等任务中。</p>
<p>之前方法大多应用于单一固定图，而实际应用中需要快速嵌入之前没见过的节点，或者将模型应用于全新的图，即需要归纳能力：操作不断演进的图和未见过的节点。</p>
<p>相对于传导，归纳方法更为复杂，因为它需要将未见过的节点或图与之前的学习“对齐”。因此，归纳框架必须能学到节点邻居的结构，用于描述局部和全局的情况。</p>
<p>如果想将之前的传导方法应用于未见的节点，在预测之前，还需要额外的训练。之前提出的GCNs将卷积方法应用于传导的图嵌入，效果很好。本文将GCNs扩展到无监督的归纳学习中，又加入了可学习的聚合方法。</p>
<p>GraphSAGE（SAmple and
aggreGatE）用于归纳地学习图中节点的嵌入。与之前基于矩阵分解的方法不同，它的目标是嵌入未见过的节点（事先没矩阵没法分解），因此，它需要更好利用节点特征，同时学习拓补结构和邻居特征的分布，因此，着重处理特征较多的图；同时利用图的结构，也能处理无节点特征的图。</p>
<p>与之前直接生成节点编码不同，文中方法训练聚合函数来优化聚合邻居特征的方法。在预测和测试时，使用训练好的模型计算词嵌入。通过定义损失函数，在无监督任务中也能学习（将结构作为学习目标），也可以学习有监督任务。</p>
<h2 id="相关工作">2. 相关工作</h2>
<p><strong>基于因式分解的嵌入方法</strong><br />
最近常见学习图嵌入的方法是基于随机游走的统计方法和基于矩阵分解的方法。这些方法直接学习各节点的嵌入，如想应用于新节点，则需要额外训练。与之前方法不同：文中方法使用<strong>节点特征</strong>训练模型，来预测未知节点。</p>
<p><strong>图上的有监督学习</strong><br />
之前常用基于核的方法，有监督地学习图中结构，根据各种各样的核提取节点向量。后来出现基于神经网络的有监督学习，它们通过学习图结构实现具体功能，比如用于整图的分类。而文中提出的方法主要用于表征图中的节点，可使用无监督数据训练。</p>
<p><strong>图卷积网络</strong><br />
近年来卷积神经网络被用应于图学习，已提出的一些方法都不太适用于大图，Kipf提出GCNs算法是一个用于传导的半监督算法，它在训练时需要全图的拉普拉斯矩阵，文中方法可视为GCNs的变体，具体在3.3中讨论。</p>
<h2 id="建议的方法graphsage">3. 建议的方法：GraphSAGE</h2>
<p>简单地说：为了得到中间红色节点的表征，先从邻域中采样（左图），利用邻居蓝色节点聚合出红色节点；而蓝色节点又是根据其邻居绿色节点聚合出来的；通过迭代计算邻居信息，最终生成红色点的表征，它聚合了与它距离较近（直接）和较远（间接）的节点信息（中图），最终在下游任务中使用学到的节点表征。<br />
<img src="/attachments_2022/Pasted%20image%2020220503132608.png"
alt="Pasted%20image%2020220503132608.png" /></p>
<h3 id="生成嵌入算法">3.1 生成嵌入算法</h3>
<p>假设模型参数已经训练好，学习了K个聚合函数，AGGREGATEk, ∀k ∈ {1, ...,
K})，它从邻居节点聚合信息，训练K个权重矩阵Wk（训练方法见3.2）。</p>
<p>算法-1展示了如何利用模型生成新的节点嵌入：<br />
<img src="/attachments_2022/Pasted%20image%2020220503111452.png"
alt="Pasted%20image%2020220503111452.png" /><br />
其中v是目标节点，u是v的邻居节点，输入特征用x表示，hk是节点在第k层的表征；第4行，节点v聚合它邻居在上一层表征作为HK(v)k，第0次表征为输入x；第5行，串联v点在上层的表征和HK(v)k，通过矩阵W和激活函数转换后生成该点在本层的表征；第7行对表征做规范化；第9行将最后一层表征作为输出。其中聚合函数可以有多种。</p>
<p>算法背后的逻辑是：每一次迭代，节点都从它的近邻聚合数据，经过多次迭代，节点逐渐从离它更远的部分获得越来越多的信息。</p>
<p>对于minibatch的操作方法，详见附件A。</p>
<p><strong>与Weisfeiler-Lehman同构实验的关系</strong></p>
<p>GraphSAGE算法的概念灵感来自于测试图同构的经典算法（GCN也可看作是WL的变形）。WL算法详见：<a
href="https://zhuanlan.zhihu.com/p/90645716">什么是Weisfeiler-Lehman(WL)算法和WL
Test？</a><br />
GraphSAGE是WL测试的近似，用GraphSAGE生成节点表示而不是用WL-test测试同构，所以，使用训练的神经网络聚合器替换hash函数。GraphSAGE和经典的WL测试之间的联系为文中的算法设计学习节点邻域的拓扑结构提供了理论背景。</p>
<p><strong>定义邻域</strong><br />
文中方法统一抽样一组固定大小的邻居，而非使用算法1中所有的邻居，这是为了保持每个batch的一致性，将N(v)定义为取固定大小的邻居。在不同的迭代中使不同的均匀样本。</p>
<p>如果不采样，那么内存和运行时间将不可预测，在最坏的情况下可能达到O(|V|)；固定后的复杂度是：[[Pasted
image 20220503115736.png]]<br />
其中S和K是用户定义的常量，当K=2，S1.S2&lt;=500时可实现高性能。</p>
<h3 id="学习graphsage参数">3.2 学习GraphSAGE参数</h3>
<p>设计的损失函数，鼓励相近的节点具有相似表征，不同的节点有较大差异。使用随机梯度下降调参权重矩阵Wk。<br />
<img src="/attachments_2022/Pasted%20image%2020220503125300.png"
alt="Pasted%20image%2020220503125300.png" /><br />
其中zu是输出的表征，v是u在指定随机步以内u的共现节点， σ
是sigmoid激活函数，Pn是负例分布，Q是负例个数。与之前方法不同的是，zu是从局部领域中包含的特征生成的，而不是为每个节点训练的嵌入。</p>
<p>上面描述了无监督任务中利用节点特征计算损失函数优化模型的方法，其结果可以作为服务或者存储供下游任务使用，对于特定的有监督学习下游任务，也可以替换或添加损失函数来训练模型。</p>
<h3 id="聚合器架构">3.3 聚合器架构</h3>
<p>节点的邻居没有顺序，因此，算法-1中的聚合方法需要操作无序向量，聚集器需要是对称的（不随其输入的排列而变化），同时是可训练的并保持较高的表示能力。文中研究了三种聚合器：</p>
<p><strong>Mean aggregator</strong><br />
均值聚合，即简单地对近邻取均值，它类似于传导GCN框架中使用的卷积传播规则，将算法-1中4,5行替换成以下方法：<br />
<img src="/attachments_2022/Pasted%20image%2020220503130853.png"
alt="Pasted%20image%2020220503130853.png" /><br />
该方法类似于GCN方法，它是局部谱卷积粗略的线性近似，它与我们提出的其它几种方法的差别是不使用concat串联操作。而串联可视为在不同层间的“跳级”，能够提升性能。</p>
<p><strong>LSTM aggregator</strong><br />
LSTM方法相对复杂，与均值聚合相比，它有更强的表达能力，需要注意的是LSTM是非对称的，通过简单地将LSTM应用于节点邻居的随机排列，使LSTM适应用无序集合。</p>
<p><strong>Pooling aggregator</strong><br />
池化聚合，使用最大池化方法从领域聚合特征，加入一个全连接层变换，然后进行最大池化。<br />
<img src="/attachments_2022/Pasted%20image%2020220503131805.png"
alt="Pasted%20image%2020220503131805.png" /><br />
max方法以元素为单位取最大值，σ是非线性激活函数，多层感知机（这里只用了一层）被视为利用邻居集中的节点计算特征的函数，通过最大池化又捕捉了不同方面的特征。原则上可以用平均池化代替最大池化，测试中发现没有显著差异，故实验使用了最大池化。</p>
<h2 id="实验">4. 实验</h2>
<p><strong>实验设置</strong><br />
实验对比了四个基线：随机分类，基于特征的逻辑回归（忽略图结构），DeepWalk算法，DeepWork+特征；同时还对比了四种GraphSAGE，其中三种在3.3节中已经说明，GraphSAGE-GCN是GCNs的归纳版本。具体超参数为：K=2，s1=25，s2=10。程序使用TensorFlow编写，Adam优化器。<br />
<img src="/attachments_2022/Pasted%20image%2020220503135139.png"
alt="Pasted%20image%2020220503135139.png" /></p>
<h3 id="演进图中的归纳学习">4.1 演进图中的归纳学习</h3>
<p><strong>Citation数据集</strong><br />
使用科学网引文数据集，将学术论文分类为不同的主题。数据集共包含302424个节点，平均度9.15，使用2000-2004年数据作为训练集，2005年数据作为测试集。使用节点的度以及论文摘要的句嵌入作为特征。</p>
<p><strong>Reddit数据集</strong><br />
将Reddit帖子归类为属于不同社区。数据集包含232965个帖子，平均度为492。使用现成的300维GloVe
Common Crawl单词向量；对于每个帖子，使用特征包含：(1) 帖子标题的平均嵌入
(2) 帖子所有评论的平均嵌入 (3) 帖子的分数 (4)帖子的评论数量。</p>
<p>从表-1实验结果可以看到，GraphSAGE方式相对于基线方法有明显提升，经过训练的聚合函数优于GCN方法。另外，无监督学习和有监督学习效果差不多。</p>
<h3 id="跨图泛化">4.2 跨图泛化</h3>
<p>对于跨图泛化的任务，需要学习节点角色而不是训练图的结构。使用跨各种生物蛋白质-蛋白质相互作用(PPI)图，对蛋白质功能进行分类。在20个图表上训练算法，2个图用于测试，2个图用于验证，平均每图包含2373个节点，平均度为28.8。</p>
<p>从实验结果可以看出LSTM和池化方法比Mean和GCN效果更好。</p>
<h3 id="运行时间和参数敏感度">4.3 运行时间和参数敏感度</h3>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220503135200.png"
alt="Pasted%20image%2020220503135200.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220503135200.png</figcaption>
</figure>
<h3 id="对比不同聚合函数">4.4 对比不同聚合函数</h3>
<p>如表-1所示，LSTM和POOL方法效果最好，与其它方法相比有显著差异，LSTM和POOL之间无显著差异，但LSTM比POOL慢得多(≈2x)，使POOL聚合器在总体上略有优势。</p>
]]></content>
      <tags>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_知识图对齐PRASE</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/12_%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E7%9F%A5%E8%AF%86%E5%9B%BE%E5%AF%B9%E9%BD%90PRASE/</url>
    <content><![CDATA[<h1 id="介绍">介绍</h1>
<p>英文题目：Unsupervised Knowledge Graph Alignment by Probabilistic
Reasoning and Semantic Embedding<br />
中文题目：基于概率推理和语义嵌入的无监督知识图对齐<br />
论文地址：https://arxiv.org/abs/2105.05596v1<br />
领域：自然语言处理，知识图谱<br />
发表时间：2021<br />
作者：腾讯天衍实验室<br />
出处：IJCAI（国际人工智能联合会议）<br />
被引量：1<br />
代码和数据：<br />
https://github.com/qizhyuan/PRASE-Python<br />
https://github.com/dig-team/PARIS<br />
阅读时间：22.04.08</p>
<h1 id="泛读">泛读</h1>
<ul>
<li>针对问题：实体对齐（不是本体对齐）<br />
</li>
<li>结果：效果优于之前模型<br />
</li>
<li>核心方法：提出PRASE，基于<strong>概率推理</strong>和<strong>语义嵌入</strong>，使用不断更新种子的方法迭代训练上述两个子模型。<br />
</li>
<li>难点：先需要了解一下PARIS模型<br />
</li>
<li>泛读后理解程度：70%<br />
（看完题目、摘要、结论、图表及小标题）</li>
</ul>
<h1 id="精读">精读</h1>
<h2 id="摘要">摘要</h2>
<p>目前常用的实体对齐方法包括：基于词嵌入的对齐、常识推理和字典匹配。前者的模型常常依赖有监督学习，缺乏恰当的推理，难以避免逻辑错误的映射；后者解决了推理问题，但较少使用图结构和实体上下文。本文致力于结合二者。</p>
<h2 id="介绍-1">1. 介绍</h2>
<p>实体对齐可用于把局部的知识图结合成更大的知识图，具体的工作是需要找到不同图中<strong>含义相同的实体</strong>、关系等。</p>
<p><strong>图嵌入</strong>将图中实体关系等信息编码到低维空间，使其包含的语义信息作为进一步探索的工具。对齐问题的解决方法常常是：先将待对齐的知识图嵌入到一个向量空间中，然后通过计算向量距离或相似性来发现映射。</p>
<p>这些基于嵌入的模型常常需要一定数量的知识映射（对齐种子）来进行训练，而种子标注需要大量人力。种子的数量和抽样分布对对准性能有很大影响。而且先编码后映射的方法可能忽略整体性，从而导致映射错误。</p>
<p>使用<strong>逻辑推理或者字典映射</strong>，本体对齐方法是相对传统的技术，比如2012年的PARIS利用概率归因和字典映射方法，通过名字匹配一些初始特征之后，通过迭代概率推理来推断实体、关系的等价性。因此无需训练，不依赖种子，更高效和可扩展。但它在开发和利用图形结构和其他上下文信息方面较弱。</p>
<p>本文致力于结合上述两种模型，提出了无监督的迭代框架PRASE。其中的PR是概率推理模块（probablistic
reasoning），SE是词嵌入（semantic
embedding）模块。PR基于之前PARIS模型，SE用于捕捉图结构和实体的上下文，PR从SE处得到映射和实体嵌入。</p>
<p>本文主要贡献如下：<br />
* 提出无监督的对齐框架PRASE，用迭代方法结合了两种模型<br />
* 使用PARIS和不同的词嵌入模块实现模型<br />
* 在多个数据集上达到比之前更好的效果</p>
<h2 id="预备知识">2. 预备知识</h2>
<p>背景和相关工作</p>
<h3 id="问题表述">2.1 问题表述</h3>
<p>设符号：E是实体，R是关系，A是属性，V是属性值。将图定义为G=(E,R,A,V,TR,TA)，其中TR指关系三元组，TA指属性三元组：<br />
<img src="/attachments_2022/Pasted%20image%2020220408093940.png"
alt="Pasted%20image%2020220408093940.png" /><br />
问题定义成对两个图G和G'中实体的对齐方法：<br />
<img src="/attachments_2022/Pasted%20image%2020220408094046.png"
alt="Pasted%20image%2020220408094046.png" /><br />
"≡"指的是两个实体指向现实世界中的同一对象。</p>
<h3 id="paris方法">2.2 PARIS方法</h3>
<p>属性三元组和关系三元组类似，因此定义：<br />
<img src="/attachments_2022/Pasted%20image%2020220408094258.png"
alt="Pasted%20image%2020220408094258.png" /><br />
并且定义了关系的度量函数及其反向函数：<br />
<img src="/attachments_2022/Pasted%20image%2020220408094529.png"
alt="Pasted%20image%2020220408094529.png" /><br />
其中|.|表示集合的基数（集合中的元素数量），上述函数用于计算头实体和尾实体的唯一性。当F(r)=1时，说明其头实体是唯一的，请注意：F和F-1具有不变性，因此，可提前计算。</p>
<p>PARIS（2012年论文，用于对齐实例、关系、类，适用于大型图）可以交替计算实体映射和包含关系，不同图中的两个实体h和h'相等的概率P(h
≡h′)，计算如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220408095328.png"
alt="Pasted%20image%2020220408095328.png" /><br />
其中(h,r,t)是图中的三元组，式-2的大概意思是：在确定了尾实体相等的概率、关系r的逆函数F-1，以及r与r'包含关系的概率后，即可计算头实体h与h'是同一实体的概率。<br />
其中P(r ⊆ r′)表示r是r'子集的概率：<br />
<img src="/attachments_2022/Pasted%20image%2020220408095418.png"
alt="Pasted%20image%2020220408095418.png" /><br />
式-3假设已知头实体和尾实体分别指向同一实体的概率，分母计算所有h,t，分子计算包含h,r,t的三元组。</p>
<p>可以看到计算P(r ⊆ r′)需要P(h ≡h′)，而P(h ≡h′)又需要P(r ⊆
r′)，二者相互依赖，因此需要迭代优化。一开始，P(r ⊆
r′)可被设置为一个很小的值，比如0.1；或者，当实体是属性时，如果文字描述相同则设为1，否则为0；更高级的方法是用实体间的编辑距离作为其评分。</p>
<p>在每次迭代时，式-2计算出了实体相等的概率，式-3又计算了关系的包含关系，迭代直至收敛。最终PARIS输出的是实体映射表记作
̃YP，Po(e≡e‘)，(e，e’)∈Yp，上标o表示输出。</p>
<h3 id="基于嵌入的知识图对齐">2.3 基于嵌入的知识图对齐</h3>
<p>基于嵌入的知识图对齐一般分两步：先学习词嵌入（如使用TransE或图神经网络），在不同图中使用同一向量空间编码，通过参数共享、参数互换、嵌入变换、嵌入校准等策略实现；然后，基于度量实体嵌入的相似性来预测实体映射。</p>
<p>MTransE是比较典型的嵌入方法，通过以下损失函数优化：<br />
<img src="/attachments_2022/Pasted%20image%2020220409114521.png"
alt="Pasted%20image%2020220409114521.png" /><br />
其中||.||计算欧几里得范数，h,r,t都是编码后的低维向量，处于同一向量空间。一般情况下需要种子训练模型：<br />
<img src="/attachments_2022/Pasted%20image%2020220409171156.png"
alt="Pasted%20image%2020220409171156.png" /><br />
最小化损失：<br />
<img src="/attachments_2022/Pasted%20image%2020220409171303.png"
alt="Pasted%20image%2020220409171303.png" /><br />
其中e和e'是实体嵌入，维度为m，M是大小mxm的转移矩阵。通过学习M，G可被转换到G'所在的空间。最终实现实体映射记作
̃YE，其相似度在[0,1]之间。记作: S(e ≡ e′),(e,e′) ∈
̃YE。通过该方法可以进行近邻搜索。</p>
<h2 id="框架">3. 框架</h2>
<h3 id="prase-概览">3.1 PRASE 概览</h3>
<p><img src="/attachments_2022/Pasted%20image%2020220409115343.png"
alt="Pasted%20image%2020220409115343.png" /><br />
模型框架如图-1所示，主要由概率模型PR和嵌入模型SE组成。PR用于计算实体映射
̃YP
及其概率Po。然后将高置信度的映射作为种子，传入嵌入模型SE，SE通过这些种子来训练模型，然后SE模型对于PR模型输出的未对齐的实体
̃UP进行预测；之后，将SE预测结果实体映射表 ̃YE和相似度得分S(e ≡
e′)，以及实体嵌入结果：<br />
<img src="/attachments_2022/Pasted%20image%2020220409171543.png"
alt="Pasted%20image%2020220409171543.png" /><br />
作为PR模块的输入，再进行下一次迭代。以上过程迭代K次，PR模型最终输出实体映射表
̃YP。</p>
<h3 id="概率推理模型">3.2 概率推理模型</h3>
<p>PR模块首先利用式-1计算出关系的函数F及其反向函数，然后利用式2式3计算两个实体的相似概率。PR与SE交替调用，在k次迭代时（k&gt;0），将前次输出作为本次的输入<br />
<img src="/attachments_2022/Pasted%20image%2020220409151718.png"
alt="Pasted%20image%2020220409151718.png" /><br />
i指输入，o指输出，每次迭代时PR的输入如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220409151155.png"
alt="Pasted%20image%2020220409151155.png" /><br />
P指的是PR模块的映射概率。当前一个PR模型认为两实体对齐时，将其为同一实体的概率以权重a1代入；当SE模型认为二者对齐且相似度大于阈值δ1（δ1,a1,a2均为超参数，取值范围在0-1之间），将其相似度以权重a2代入；否则设其概率初值为0。</p>
<p>为了更直接地利用SE输出的嵌入信息，在迭代过程中，将PARIS中的式-2变为式-5：<br />
<img src="/attachments_2022/Pasted%20image%2020220409152456.png"
alt="Pasted%20image%2020220409152456.png" /><br />
利用超参数β（取值(0,1)）来平衡词向量相似度和PARIS计算的概率。sim()计算cosine距离，其取值在[0,1]。</p>
<h3 id="语义嵌入模块">3.3 语义嵌入模块</h3>
<p>在第k次迭代时，利用上一次PR产生的对齐数据集Yk-1，从中提取出置信度高（超参数δ2作为阈值）的对齐数据作为种子Sk来训练SE，尽管很多时候种子中包含不正确的数据，但是它也能带来大量的有用信息。用训练好的SE代入未对齐的实体U，它将输出与U最相似的实体，以及词嵌入。任何词嵌入方法都可以用作SE。</p>
<p>PRASE流程如算法-1所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220409144900.png"
alt="Pasted%20image%2020220409144900.png" /><br />
对于两个图G和G'，设置迭代次数K。<br />
line 1： 用式-1初始化PR模块（通过两图中三元组计算关系函数F）<br />
line 2：PR处理：用式-2和式-3依次计算实体相似概率和关系的包含<br />
line 3：产生了初始的对齐数据集Y0和未对齐数据集U0。<br />
line 4：开始迭代<br />
line 5：基于前次对齐数据集Yk-1产生种子<br />
line 6：使用种子训练SE模型<br />
line 7：用SE模型对前次未对齐数据Uk-1预测<br />
line 8：产生了本次预测结果YE和嵌入结果EEk<br />
line 9：使用式-4初始化PR模型<br />
line 10：PR处理，计算式-5和式-3<br />
line 11：产生了本次的对齐数据集Yk和未对齐数据集Uk。<br />
line 12：继续迭代<br />
line 13：最终输出Y</p>
<h2 id="评价">4. 评价</h2>
<h3 id="数据集">4.1 数据集</h3>
<p>OpenEA 数据集： 常用的用于评测图对齐的数据集。由DBpedia, YAGO, and
Wikidata组成，文中评测使用其V2版本，包含跨语言数据集和跨知识图谱数据集，另外，还使用了相对困难的数据集D-W-15K-V2。<br />
下载地址：https://github.com/nju-websoft/OpenEA</p>
<p>工业数据集：MED-BBK-9K是Zhang在2020年提出的数据集，包含专业医学数据集和百度百科医学数据（中文），约几十万个三元组。形如：<br />
<img src="/attachments_2022/Pasted%20image%2020220410114407.png"
alt="Pasted%20image%2020220410114407.png" /><br />
下载地址：https://github.com/ZihengZZH/industry-eval-EA<br />
解压后即可看到三元组数据（<strong><em>又解锁一个中文的医学图谱数据及其对齐算法，开心</em></strong>）。</p>
<h3 id="实验设置">4.2 实验设置</h3>
<p><img src="/attachments_2022/Pasted%20image%2020220409162248.png"
alt="Pasted%20image%2020220409162248.png" /><br />
最上边部分是嵌入模型，第二部分是推理模型，STR-Match和
EMB-Match计算实体间的相似度，最后一部分是PRASE模型分别使用BootEA和MultiKE模型作为SE。</p>
<p>实验环境是： NVIDIATesla M40 GPU, and CentOS 7.2，128G内存，2.4GHz
CPU。对于4个100K的数据集的训练速度是平均1697秒，BootEA和MultiKE分别是24727和3198。</p>
<p>表-3和表-4分别展示了消融实验和不同嵌入模型的对比效果。<br />
<img src="/attachments_2022/Pasted%20image%2020220409163238.png"
alt="Pasted%20image%2020220409163238.png" /><br />
图-5展示了不同迭代次数对模型的影响，更多的迭代可以提升模型效果，但K也不用设得太大。<br />
<img src="/attachments_2022/Pasted%20image%2020220409164853.png"
alt="Pasted%20image%2020220409164853.png" /></p>
<h1 id="prase-python代码解析">PRASE-Python代码解析</h1>
<h3 id="下载">下载</h3>
<p>$ git clone git@github.com:qizhyuan/PRASE-Python.git</p>
<h3 id="运行">运行</h3>
<p>$ PRASE-Python/<br />
$ python test.py<br />
（程序在我笔记本CPU环境下运行时间约2分钟）</p>
<h3 id="代码">代码</h3>
<ul>
<li>test.py 测试程序<br />
</li>
<li>objects/KGs.py 最核心代码<br />
</li>
<li>objects/KG.py 图数据结构支持<br />
</li>
<li>objects/Entity.py 实体数据结构支持<br />
</li>
<li>objects/Relation.py 关系数据结构支持<br />
</li>
<li>model/PARIS.py 概率推理模型</li>
</ul>
<p>代码没有用什么特殊的库，在任何Python环境里都可以运行。</p>
<h3 id="数据集-1">数据集</h3>
<h4 id="介绍-2">介绍</h4>
<p>论文中测试了多个数据集，代码中包含了对Wikidata和dbpedia两个知识图的对齐，以便跑通测试程序。具体使用的是D_W_15K_V2，包含15K个实体的版本2。</p>
<h4 id="所需数据">所需数据</h4>
<p>data/*<br />
* 三元组：<br />
* 二个图的属性三元组attr_triples_1, attr_triples_1<br />
* 二个图的关系三元组rel_triples_1, rel_triples_1<br />
* 实体关系：ent_links<br />
* 嵌入模型结果：其中包含对齐结果，实体嵌入，关系嵌入等<br />
* BootEA/* 实体嵌入训练结果<br />
* MultiKE/* 实体嵌入训练结果</p>
<h3 id="分析">分析</h3>
<p>结合论文再看数据集就非常真观，嵌入模型，比如MultiEA输出由两部分组成：实体对齐结果&amp;实体嵌入。</p>
<h3 id="代码细节">代码细节</h3>
<p>针对KGs.py分析，代码包含两上类KGs和KGsUtil，前者保存图对齐过程中的数据和逻辑；后者为辅助工具，一方面用于存取数据，</p>
<p>sub_, sup_分别是论文中提到的两个包容关系。<br />
ent_match, ent_prob分别是实体匹配关系及其概率</p>
<h3 id="注意">注意</h3>
<p>代码中没有更新SE模块的部分，主要以实现PARIS的Python版本为主，github的README最后也提到（截至目前2022.04.14），如果想更新SE，需要和其它工具配合，比如OpenEA。</p>
<h3 id="如何代入自己的数据">如何代入自己的数据</h3>
<ul>
<li>先用自已的数据训练词嵌入<br />
</li>
<li>然后参考data下的数据格式做数据后，即可训练</li>
</ul>
<h3 id="收获">收获</h3>
<p>这是一个非常好的示例，之前我们拿到各种格式的异构图都可以照葫芦画瓢地训练一波。<br />
目前为止，对图的认识是：<br />
* 无论原理还是算法都没那么复杂；<br />
* 能把支持各种无法统一的数据，转换成嵌入的数值；</p>
]]></content>
      <tags>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_自然语言模型加知识图谱_DKPLM</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/12_%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%8A%A0%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1_DKPLM/</url>
    <content><![CDATA[<p>英文题目：DKPLM: Decomposable Knowledge-enhanced Pre-trained Language
Model for Natural Language Understanding<br />
中文题目：DKPLM:可分解的利用知识增强的预训练语言模型<br />
论文地址：https://arxiv.org/abs/2112.01047<br />
领域：自然语言处理, 知识图谱<br />
发表时间：2021.12<br />
作者：Taolin Zhang等，华东师范大学，阿里团队<br />
出处：AAAI-2022<br />
代码和数据：https://github.com/alibaba/EasyNLP（集成于EasyNLP）<br />
阅读时间：2022.09.11</p>
<h2 id="读后感">读后感</h2>
<p>自然语言和知识图结合的一种新尝试，几种优化方法比较有意思。尤其是他对长尾信息的分析，很有启发性：即使在无监督学习的情况下，也要尽量使用重要的数据训练模型。另外，还给出了具体方法，比如实体出现频率高于均值，则忽略它…</p>
<h2 id="介绍">介绍</h2>
<p>加入知识增强的自然语言模型简称KEPLM，它将知识图中的三元组注入NLP模型，以提升模型对语言的理解能力。在模型使用时需要知识搜索和编码，运算量大。</p>
<p>本文提出可分解的知识增强名为DKPLM，具体方法是使用长尾实体作为知识注入的目标，还在训练时设计了重建知识三元组的知识解码任务。它只在预测训练时注入了知识，在精调模型和预测时用法与BERT一致，相对节省资源。如图-1所示：</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220911114024.png"
alt="Pasted%20image%2020220911114024.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220911114024.png</figcaption>
</figure>
<p>在预训练时使用以下主要技术：</p>
<ul>
<li>基于知识的长尾实体探测<br />
</li>
<li>利用知识图中三元组做成伪实体替换长尾实体训练模型，模型无需增加参数。<br />
</li>
<li>利用三元组中的关系，通过对实体及其谓词来解码对应实体中的每个token。</li>
</ul>
<p>实验证明对于zero_shot任务，以及预测速度都有明显提升。</p>
<h2 id="方法">方法</h2>
<p>整体架构如图-2所示：</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220911114950.png"
alt="Pasted%20image%2020220911114950.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220911114950.png</figcaption>
</figure>
<h3 id="长尾实体检测">长尾实体检测</h3>
<p>通过对wiki数据分析可以看到实体出现的频率服从幂律分布，如图-3所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220911132256.png"
alt="Pasted%20image%2020220911132256.png" /><br />
只有很少的实体高频出现，多数实体出现次数少，这使用自然语言模型难以从上下文中有效学习。之前论文提到注入高频三元组不总是有利于对下游任务，反而更容易注入负面知识。因此更好的方法是注入长尾实体，同时还需要考虑实体在知识图中和句中的重要性。具体考虑以下三点（图-2第二层右侧）：<br />
* 实体频率：实体在预训练数据集中出现的频率，记作：Freq(e)。<br />
*
语义重要性：实体在句中的重要性，记作：SI(e)。计算SI可以使用语义相似度，通过去掉句中的实体e后的编码hrep与原句编码ho比较，识别该实体的重要性。<br />
<img src="/attachments_2022/Pasted%20image%2020220911133935.png"
alt="Pasted%20image%2020220911133935.png" /><br />
*
知识连接：实体在知识图中多跳邻居的个数，记作：KC(e)。如下式所示，其中Rmax，Rmin是预定义的阈值，|N|表示邻居个数，Hop指跳数。<br />
<img src="/attachments_2022/Pasted%20image%2020220911134055.png"
alt="Pasted%20image%2020220911134055.png" /><br />
最终基于知识的长尾系数KLT计算如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220911134556.png"
alt="Pasted%20image%2020220911134556.png" /><br />
其I{x}为布尔性的指示函数，当实体出现频率高于均值时，则忽略该实体。<br />
（我理解是：在训练集中出现次数太多的去掉，在知识图中邻居太多的去掉，在句子里有它没它都一样的去掉）</p>
<h3 id="伪token嵌入的注入">伪Token嵌入的注入</h3>
<p>为了提升模型对长尾实体的理解，将知识图中的关系代入模型训练。如果预测训练数据中出现了头实体eh，则用它相关的关系谓词和尾实体替换它的嵌入：<br />
<img src="/attachments_2022/Pasted%20image%2020220911135659.png"
alt="Pasted%20image%2020220911135659.png" /><br />
同理，如果出现尾实体，则用谓词加头实体来表示。<br />
以替换头实体为例，对关系和尾实体编码：<br />
<img src="/attachments_2022/Pasted%20image%2020220911140706.png"
alt="Pasted%20image%2020220911140706.png" /><br />
其中F(e)是预训练模型PLM的输出，fsp是自注意力池化，LN是标准化层，W是模型参数。<br />
由于尾实体和关系谓词通常都比较短，生成的表示可能是无效的，因此还加入了对头实体的描述文本记作e_h^des，使用预训练模型对其编码，最终的伪实体表示如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220911141118.png"
alt="Pasted%20image%2020220911141118.png" /><br />
这里的⊕表示串联。通过上述方法，促进模型学习知识图中的三元组。</p>
<h3 id="相关知识解码">相关知识解码</h3>
<p>为了更确定地让模型学习注入信息，又调整了解码层逻辑。在最后一层，利用自注意力池化获取跨实体的实体掩码表示。<br />
<img src="/attachments_2022/Pasted%20image%2020220911151343.png"
alt="Pasted%20image%2020220911151343.png" /><br />
用头实体本身通过上述方式生成表示h_eh<sup>o，再加入hr，目标是解码尾实体，用h_d</sup>i表示预测尾实体的第i个token。<br />
<img src="/attachments_2022/Pasted%20image%2020220911151730.png"
alt="Pasted%20image%2020220911151730.png" /><br />
上式中δ是缩放因子，h_d^0等于h_eh_o作为初始的启发。</p>
<p>由于词表较大，使用采样的SoftMax来对比预测值与实际值。损差函数计算方法如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220911152100.png"
alt="Pasted%20image%2020220911152100.png" /><br />
这里yi是实际token，yn是采样的负token，Q是负采样函数，N为负例个数。</p>
<p>训练目标包含两项任务：相关的知识解码和BERT自带掩码模型任务，最终损失函数计算如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220911152411.png"
alt="Pasted%20image%2020220911152411.png" /></p>
<h2 id="实验">实验</h2>
<p>模型底层框架基于RoBERTa，使用英文Wikipedia作训练数据，知识图包含3085345个实体，822种关系。由于实体太多，使用PEPR算法选择负实体，并将N设为20，λ1最终取值为0.5。主实验结果如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220911153208.png"
alt="Pasted%20image%2020220911153208.png" /><br />
从表-4可以看到，DKPLM速度明显优于其它知识注入模型：<br />
<img src="/attachments_2022/Pasted%20image%2020220911153609.png"
alt="Pasted%20image%2020220911153609.png" /><br />
从图-5的消融实验可以看到，三种优化方法各自的贡献：<br />
<img src="/attachments_2022/Pasted%20image%2020220911153712.png"
alt="Pasted%20image%2020220911153712.png" /></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>SHAP解释模型</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/14_%E6%A8%A1%E5%9E%8B%E8%A7%A3%E9%87%8A/SHAP%E8%A7%A3%E9%87%8A%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>#Python #机器学习 #模型解释</p>
<h2 id="简介">1 简介</h2>
<p>近年来，模型的可解释性越来越受到重视，SHAP是一个Python工具包，它可以解析任何模型的输出。本文除了介绍SHAP的基本用法之外，还示例了新版本提供的一些高级用法，进一步提升了预测的归因效果以及分组分析。</p>
<h2 id="环境配置">2 环境配置：</h2>
<p>以下实验使用当前最新版本shap：0.39.0</p>
<pre class="shell"><code>$ pip install shap  </code></pre>
<p>注意xgboost也需要使用对应的较新版本，如：</p>
<pre class="shell"><code>$ pip install xgboost==0.82  </code></pre>
<p>为使用交互界面，notebook环境下，加载用于可视化的JS代码</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shap  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>shap.initjs()  </span></code></pre></div>
<h2 id="实验数据">3 实验数据</h2>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shap  </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>shap.initjs()  </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>X,y <span class="op">=</span> shap.datasets.boston()  </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> xgboost.train(&#123;<span class="st">&quot;learning_rate&quot;</span>: <span class="fl">0.01</span>&#125;, xgboost.DMatrix(X, label<span class="op">=</span>y), <span class="dv">100</span>)  </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>explainer <span class="op">=</span> shap.TreeExplainer(model)  </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>shap_values <span class="op">=</span> explainer.shap_values(X)   </span></code></pre></div>
<h2 id="实验">4 实验</h2>
<h4 id="实验一">4.1.1 实验一</h4>
<p>SHAP的可解释性，基于对每一个训练数据的解析。比如：解析第一个实例每个特征对最终预测结果的贡献。</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>shap.plots.force(shap_values[<span class="dv">0</span>])    </span></code></pre></div>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-caad6880f59c0fe9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="（图一）" />
<figcaption aria-hidden="true">（图一）</figcaption>
</figure>
<p>图中，红色特征使预测值更大（类似正相关），蓝色使预测值变小，而颜色区域宽度越大，说明该特征的影响越大。（此处图中数字是特征的具体数值）<br />
其中base_value是所有样本的平均预测值，output_value即f(x)是本实例的预测值。本例分析了回归问题，对于分类问题，可以看到base_value和output_value并不在0-1之间，这是由于对数转换造成的。</p>
<h4 id="实验二">4.1.2 实验二</h4>
<p>进而可以画出每个特征对结果影响程度的具体大小（此处图中数字是特征权重）</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>shap.plots.waterfall(shap_values[<span class="dv">0</span>])    </span></code></pre></div>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-c6c5ac73907e672f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="（图二）" />
<figcaption aria-hidden="true">（图二）</figcaption>
</figure>
<h4 id="实验三">4.1.3 实验三</h4>
<p>以上都是对于单个实例的解释，更多的时候我们看到的是这种图：</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>shap.plots.beeswarm(shap_values)<span class="op">!</span>[]  </span></code></pre></div>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-2a423df57a895e32.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="（图三）" />
<figcaption aria-hidden="true">（图三）</figcaption>
</figure>
<p>它对所有实例作图，相当于把图一上的每个特征旋转90度画成点图。这样可以看到特征对预测影响的大小，需要注意的是：这里的横坐标是shap-value，即影响的权重，而非特征的具体值，特征值大小对结果的影响通过颜色表示（红色为值大，蓝色为值小，紫色邻近均值）。因此，区域分布越宽说明它的影响力越大，这个图一般是上宽下窄（影响大的放在上面）。<br />
图中最后一行显示了Sum of other
features，如果不需要显示这一行，可使用函数做图 ：</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>shap.summary_plot(shap_values, test, max_display<span class="op">=</span><span class="dv">5</span>)  </span></code></pre></div>
<h4 id="实验四">4.1.4 实验四</h4>
<p>以上只是罗列结果，并未进行统计处理，而对模型产生最大影响的前N的特征，一般是通过各个特征绝对值的均值（abs()-&gt;mean()）得到的，使用绝对值解决了正负抵消的问题，更关注相关性的大小。<br />
从这个图中就没办法看出是正相关还是负相关了，但使用shap工具可以得到具体的shap
value，可以自行处理。</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>shap.plots.bar(shap_values)    </span></code></pre></div>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-3f6009832fbd3309.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="（图四）" />
<figcaption aria-hidden="true">（图四）</figcaption>
</figure>
<h4 id="实验五">4.1.5 实验五</h4>
<p>此处可引申出SHAP更多的用法，尤其对于研究和归因，比如研究模型对“老年男性”或者“入院第五天”人群的特征重要性。做柱图的bar函数支持cohort参数，通过传入list（与实例个数相等），来划分人群（当前版本
0.39.0 支持cohort分群逻辑）。</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np    </span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> [<span class="st">&#39;aa&#39;</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">506</span>)] <span class="co"># 定义群及对应标签    </span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>idx[<span class="dv">5</span>]<span class="op">=</span><span class="st">&#39;bb&#39;</span>    </span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>idx[<span class="dv">8</span>]<span class="op">=</span><span class="st">&#39;bb&#39;</span>    </span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>shap.plots.bar(shap_values.cohorts(idx))    </span></code></pre></div>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-919a2af1f6db5e2a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="（图五）" />
<figcaption aria-hidden="true">（图五）</figcaption>
</figure>
<h4 id="实验六">4.1.6 实验六</h4>
<p>上述bar画出的是统计图，有时还是想在图中看出特征是正相关还是负相关，使用force函数可将多个实例的特征贡献度画在一张图上。</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>shap.plots.force(explainer.expected_value, shap_values.values[:<span class="dv">10</span>])    </span></code></pre></div>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-29436ec0ba270d82.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="（图六）" />
<figcaption aria-hidden="true">（图六）</figcaption>
</figure>
<p>force()工具非常灵活，横纵坐标都可以选择，每个横坐标对应一个实例，可选择：按输出排序，按实例顺序排序，按近似实例排序；纵向可以选择查看哪些特征，默认是查看所有特征。通过转入不同的shap
value数组，可以研究部分或全部实例。</p>
<h2 id="保存图片">5 保存图片</h2>
<p>静态图可通过plt.savefig保存(只支持单实例)，注意设置matplot和show参数：</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>shap.force_plot(explainer.expected_value[<span class="dv">0</span>], shap_values[<span class="dv">0</span>], data_arry, matplotlib<span class="op">=</span><span class="va">True</span>,show<span class="op">=</span><span class="va">False</span>)  </span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="va">None</span>)  </span></code></pre></div>
<p>动态图只能保存成html，具体使用:</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>xx <span class="op">=</span> shap.force_plot(....)  </span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>shap.save_html(<span class="st">&#39;xx.html&#39;</span>, xx)  </span></code></pre></div>
<h2 id="参考">6 参考</h2>
<p><a
href="https://zhuanlan.zhihu.com/p/106320452">不再黑盒，机器学习解释利器：SHAP原理及实战</a><br />
<a
href="https://zhuanlan.zhihu.com/p/83412330">SHAP：Python的可解释机器学习库</a></p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>机器学习</tag>
        <tag>模型解释</tag>
      </tags>
  </entry>
  <entry>
    <title>SHAP解释模型二</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/14_%E6%A8%A1%E5%9E%8B%E8%A7%A3%E9%87%8A/SHAP%E8%A7%A3%E9%87%8A%E6%A8%A1%E5%9E%8B%E4%BA%8C/</url>
    <content><![CDATA[<p>SHAP解释模型（二）</p>
<p>本文在<a
href="https://blog.csdn.net/xieyan0811/article/details/120393090">SHAP解析模型</a>之后，又尝试了一些SHAP新版本的进阶用法，整理并与大家分享．</p>
<h2 id="环境配置">1 环境配置</h2>
<p>以下实验使用当前最新版本shap：0.41.0，同时安装xgboost作为预测模型，并使用较高版本的matplotlib（低版本有时画图报错）．</p>
<pre><code>$ pip install shap==0.41.0  
$ pip install xgboost==0.82  
$ pip install matplotlib==3.5.2  </code></pre>
<h2 id="实验数据">2 实验数据</h2>
<p>仍延用波士顿房价数据集，由于有些方法需要explainer对象，因此构造了shap_value_obj</p>
<pre><code>import shap  
import xgboost  
X,y = shap.datasets.boston()  
  
model = xgboost.train(&#123;&quot;learning_rate&quot;: 0.01&#125;, xgboost.DMatrix(X, label=y), 100)  
explainer = shap.TreeExplainer(model)   
shap_values = explainer.shap_values(X)   
shap_values_obj = explainer(X)   </code></pre>
<h2 id="单特征实验">3 单特征实验</h2>
<p>首先，尝试一些单特征分析方法．</p>
<h3 id="分析单个实例">3.1 分析单个实例</h3>
<p>在图中主要关注base_value，它是预测的均值，而f(x)展示了该实例的具体预测值，红色和蓝色区域的颜色和宽度展示了主要特征的影响和方向．</p>
<pre><code>shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:])  </code></pre>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220821100923.png"
alt="Pasted%20image%2020220821100923.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220821100923.png</figcaption>
</figure>
<h3 id="决策图">3.2 决策图</h3>
<p>决策图可在一张图上展示多个实例的特征对结果的影响，一般情况下，位置越靠上的特征影响越大．本例中设定feature_order='hclust'，则是按shap
value进行聚类，再按特征的相关度排序，因此线条看起来比较直；其x轴描述的是各个特征对最终预测值拉扯的方向和力度．<br />
使用该方法也可以用于异常值检测，如果有一条线明显与其它线的方向不同，则可能是异常值．</p>
<pre><code>features = X[:20] # 只分析前20个样本  
shap_values = explainer.shap_values(features)  
shap.decision_plot(explainer.expected_value, shap_values,   
                   features, feature_order=&#39;hclust&#39;)  </code></pre>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220821101551.png"
alt="Pasted%20image%2020220821101551.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220821101551.png</figcaption>
</figure>
<h3 id="热力图">3.3 热力图</h3>
<p>热力图的横轴是每个实例，纵轴是每个特征对该实例的影响，用颜色描述该特征对该实例的影响方向和力度，比如x轴在300附近的实例，其预测值f(x)在0.5附近，原因是LSTAT对它起到正向作用，而RM对它起负向作用，其它特征影响比较小（浅色）．</p>
<pre><code>shap.plots.heatmap(shap_values_obj)  </code></pre>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220821101642.png"
alt="Pasted%20image%2020220821101642.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220821101642.png</figcaption>
</figure>
<h2 id="特征组合实验">4 特征组合实验</h2>
<p>特征组合是数据分析的重要因素，下面实验对特征组合的挖掘方法．</p>
<h3 id="带聚类的特征图">4.1 带聚类的特征图</h3>
<p>先对shap
value做聚类，此时shap_value值类似的实例被分成一组，相关性强的特征就能显现出来，再画条形图时，展示了特征的相关性．</p>
<pre><code>clustering = shap.utils.hclust(X, y)   
shap.plots.bar(shap_values_obj,   
               clustering=clustering,  
               clustering_cutoff=0.5)  </code></pre>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220821101740.png"
alt="Pasted%20image%2020220821101740.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220821101740.png</figcaption>
</figure>
<h3 id="依赖图">4.2 依赖图</h3>
<p>依赖图分析一个特征对另一个特征的影响，示图类似shap散点图，横坐标为特征"RM"的取值范围，纵坐标为其取值对应的shap
value，颜色分析的是另一特征"RAD"在"RM"变化过程中的分布．</p>
<pre><code>shap.dependence_plot(&quot;RM&quot;, shap_values_obj.values, X, interaction_index=&#39;RAD&#39;)  </code></pre>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220821101052.png"
alt="Pasted%20image%2020220821101052.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220821101052.png</figcaption>
</figure>
<h3 id="交互图">4.3 交互图</h3>
<p>交互图对角线上展示的是该特征与预测值的关系，它与最普通的shap
plot相一致，对角线以外其它位置是特征两两组合对预测的影响．每个子图的横坐标为shap
value，也就是说，子图越宽，该特征组合对结果影响越大．</p>
<pre><code>shap_interaction_values = explainer.shap_interaction_values(X)  
shap.summary_plot(shap_interaction_values, X)  </code></pre>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220821101147.png"
alt="Pasted%20image%2020220821101147.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220821101147.png</figcaption>
</figure>
<h3 id="特征组合的影响">4.4 特征组合的影响</h3>
<p>将交互图按特征重要性排序后绘图．个人认为下图非常有用，它将单特征与特征组合画在一张图中，可以从中分析出哪些特征组合更为重要．</p>
<pre><code>shap_interaction_values = explainer.shap_interaction_values(X)  
shap.summary_plot(shap_interaction_values, X, max_display=10, plot_type=&quot;compact_dot&quot;)  </code></pre>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220821102503.png"
alt="Pasted%20image%2020220821102503.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220821102503.png</figcaption>
</figure>
<h2 id="参考">5 参考</h2>
<p><a href="https://www.modb.pro/db/129193">用 SHAP
可视化解释机器学习模型实用指南(下)</a><br />
<a
href="https://zhuanlan.zhihu.com/p/456843338">数据科学家必备｜可解释模型SHAP可视化全解析</a></p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>机器学习</tag>
        <tag>模型解释</tag>
      </tags>
  </entry>
  <entry>
    <title>分类模型的可解释性</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/14_%E6%A8%A1%E5%9E%8B%E8%A7%A3%E9%87%8A/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/</url>
    <content><![CDATA[<h1 id="分类模型的可解释性">分类模型的可解释性</h1>
<p>#机器学习</p>
<p>论文题目：《Why Should I Trust You? Explaining the Predictions of Any
Classifier》<br />
论文地址： <a
href="https://links.jianshu.com/go?to=https%3A%2F%2Fchu-data-%20lab.github.io%2FCS8803Fall2018%2FCS8803-Fall2018-DML-Papers%2Flime.pdf">https://chu-data-lab.github.io/CS8803Fall2018/CS8803-Fall2018-DML-<br />
Papers/lime.pdf</a><br />
模型可解释性论文列表： <a
href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2FoneTaken%2Fawesome_deep_learning_interpretability"><br />
https://github.com/oneTaken/awesome_deep_learning_interpretability<br />
</a></p>
<p>《Why Should I Trust You? Explaining the Predictions of Any<br />
Classifier》是2016年发表在KDD上的论文，至今被引用2984次。文中介绍了可以应用于任何分类模型的模型解释方法。</p>
<p>很多复杂的机器学习模型和深度学习模型，都被外界视为黑盒，如何对用户解释它的结果、评价其效果，让用户放心地使用，尤其是在医疗这种性命攸关的领域，对于模型推广至关重要。文中提出了用于解释分类模型的LIME方法。</p>
<p>在机器学习领域，一般在训练集上训练模型，用测试集（或验证集）评价模型，然后统计整体模型的准确性。但是测试集与实际场景中使用的数据往往存在一定差异。</p>
<p>对于单条实例，它的表现又如何？是否可以信任模型该次预测？例如对于准确率是80%的模型，如何确定本次的预测到底属于正确的80%，还是错误的20%。文中提出了解释和评价单次预测的方法LIME，并通过对多个典型的实例的评价，将该方法延伸到评价整个模型SP-<br />
LIME，并讨论了在什么情况下应该信任模型（模型的适用范围）。</p>
<p>人做决策时往往依赖其先验知识，以及知识背后的原因。评价模型有效性的重要方法是找到影响决策的关键特征，比如一段话中的重点单词，图片中的某些小块，如下图所示，LIME方法找出了影响某一次决策的重要特征，其中绿色为相关特征，红色为重要特征。</p>
<p><img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81MzU3ODkzLWZjOWFhYjYyZjFkZWIxOGYucG5n?x-oss-%20process=image/format,png" /></p>
<h3 id="评价单个实例lime">评价单个实例LIME</h3>
<p>如果在建模的过程中出现一些泄露，比如X（假设是x1）里掺入了y的部分内容，或者数据集引起的偏差（如：男女不平等）。在实际应用中，这些x1又无法得到，那么在测试集中计算得出的模型准确度并不能说明模型的好坏。使用LIME方法寻找关键因素，如果发现x1是决定性因素，就很容易发现泄露问题。</p>
<p>另外，精确度并不是模型的唯一量度，有时需要从多个模型中选择出最佳模型，一般会选择整体正确率最高的模型，或者根据各个模型的准确率加权，最终方法对于单个实例未必是最优选择。对于单个实例，计算出决策的依据，并与人的先验知识印证，有利于选择对该实例效果最好的模型。在这样的交互过程中，开发者也能了解究竟哪些因素更能影响人的决策，从而优化模型。</p>
<p>开发者都希望在输入数据和输出数据间建立可解释的联系。但是复杂的机器学习模型或者深度学习建模中，相对比较困难，模型预测过程是成千上万参数共同作用的结果。希望最终呈现出来的是人能理解的，而非特征实际上怎么计算的细节，也不一定是输入的具体特征（如图片输入各像素点的颜色）。</p>
<p>实现LIME的具体方法是：在实例x附近加干扰，得到一些与它近似的实例z，用训练出的模型f对这些z进行预测f(z)，作为解释模型g的label。代入模型，优化下面公式中定义的目标函数。对于邻近x的z给予较高的权重π，对于较远的z给予较低的权重π。</p>
<p><img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81MzU3ODkzLWEyZThlOGU5NjA5YWJkNjQucG5n?x-oss-%20process=image/format,png" /></p>
<p>在分类问题中，f可看作是实例x属于某分类的概率，即f是预测模型；g是用于解释的模型；πx(z)通过衡量实例z与x的近似度赋予实例权重；L用于度量在局部范围π条件下，g用于解释f的不可信度（越小越好）；Ω(g)是模型g的复杂度。简单地讲：LIME的目标是从众多的解释模型G中选择最合适的模型g，该模型对于人类的理解足够简单（Ω(g)小），且不可信度L也比较小（复杂模型f和简单模型g在x附近效果差不多）。</p>
<p>在直觉上看，下图示例是一个比较复杂的二分类，整体并不是线性可分的，通过训练得出了复杂的二分类模型f，不同分类分别使用蓝色和肉色表示；对局部实例x（粗红十字），通过在它附近模拟一些实例z（十字和圆点），并且根据它们与x的距离赋予不同权重，用z和x训练简单的线性模型g，用于在局部范围内拟合x。再从简单模型g中提取可描述的特征。</p>
<p><img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81MzU3ODkzLWFhYmVjZTA5ZWI4NjM1YzgucG5n?x-oss-%20process=image/format,png" /></p>
<p>L的具体计算方法如下：</p>
<p><img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81MzU3ODkzLWE1MDhmMmExY2Y2OTNlNzMucG5n?x-oss-%20process=image/format,png" /></p>
<p>其中π根据距离赋予不同实例z权重，f(z)是模型对z的预测值
，z’是根据z计算的可解释的特征，g(z’)是简单模型。</p>
<p>举个现实中的例子：假设最终训练出来了无比复杂强大的模型f，它可以识别各种动物。各种动物有其各自的特征，各不相同，但是对于单个实例“猪”，必定有一些与它相关的重要特征（它是全部重要特征的子集）。生成猪和其类似动物作为数据，训练简单模型g，用于学习与“猪”相关的重要特征。虽然g代表不了整个模型f，但它能很好地描述“猪”。</p>
<p>文中方法把基础模型f当作黑盒，因此LIME方法可应用于任何分类模型。该方法可能出现的问题是：简单模型g，即使在实例x附近也未必能完美地模拟f。但是可以评价g在x附近对f的拟合程度，同样也可据此选择更适合的g。</p>
<p>有些分类器虽然统计上看效果不错，但对于某类实例x可能效果并不好，如果通过上述方法提取的特征看起来并不合理，也可从而评价f对x实例预测的可信度，以便后期优化模型f。</p>
<h3 id="评价整个模型-sp-lime">评价整个模型 SP-LIME</h3>
<p>上述方法用于评价对单个实例预测的可信程度，如果需要评价整个模型，则需要评价多个实例。SP（submodular<br />
pick）方法用于在大量数据中选择适当的实例。</p>
<p>开发者希望被选择的实例能覆盖各种label类型，覆盖尽可能多的情况，且不冗余（不重复）。如下例所示：</p>
<p><img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81MzU3ODkzLWZlMDExOGU3ZmJjOTI2MDEucG5n?x-oss-%20process=image/format,png" /></p>
<p>图中的行代表各个文档（实例），列代表文档中出现的关键词（特征），图中通过各个特征在各个实例的重要性构造了矩阵W。可以看到第二列特征对于每个文档都很重要（蓝色）；第二行和第五行涵盖了除f1特征之外的所有特征。</p>
<p>在构造实例集的过程中，尽量使用对各种情况都重要的特征f2，也尽量减少纳入类似实例，如第二行和第三行就非常相似。这样，不会因为训练集中“猫”多，使猫相关的特征显得非常重要，而是相对均匀地选择重要特征。</p>
<p>另一次看的笔记：<a
href="/1_Note/2_算法/14_模型解释/论文阅读_分类模型的可解释性">论文阅读_分类模型的可解释性</a></p>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_分类模型的可解释性</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/14_%E6%A8%A1%E5%9E%8B%E8%A7%A3%E9%87%8A/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/</url>
    <content><![CDATA[<p>#论文阅读 #模型解释</p>
<p>论文题目：《Why Should I Trust You? Explaining the Predictions of Any
Classifier》<br />
论文地址：<a
href="https://chu-data-lab.github.io/CS8803Fall2018/CS8803-Fall2018-DML-Papers/lime.pdf">https://chu-data-lab.github.io/CS8803Fall2018/CS8803-Fall2018-DML-Papers/lime.pdf</a><br />
模型可解释性论文列表：<a
href="https://github.com/oneTaken/awesome_deep_learning_interpretability">https://github.com/oneTaken/awesome_deep_learning_interpretability</a></p>
<p>《Why Should I Trust You? Explaining the Predictions of Any
Classifier》是2016年发表在KDD上的论文，至今被引用2984次。文中介绍了可以应用于任何分类模型的模型解释方法。</p>
<p>很多复杂的机器学习模型和深度学习模型，都被外界视为黑盒，如何对用户解释它的结果、评价其效果，让用户放心地使用，尤其是在医疗这种性命攸关的领域，对于模型推广至关重要。文中提出了用于解释分类模型的LIME方法。</p>
<p>在机器学习领域，一般在训练集上训练模型，用测试集（或验证集）评价模型，然后统计整体模型的准确性。但是测试集与实际场景中使用的数据往往存在一定差异。</p>
<p>对于单条实例，它的表现又如何？是否可以信任模型该次预测？例如对于准确率是80%的模型，如何确定本次的预测到底属于正确的80%，还是错误的20%。文中提出了解释和评价单次预测的方法LIME，并通过对多个典型的实例的评价，将该方法延伸到评价整个模型SP-LIME，并讨论了在什么情况下应该信任模型（模型的适用范围）。</p>
<p>人做决策时往往依赖其先验知识，以及知识背后的原因。评价模型有效性的重要方法是找到影响决策的关键特征，比如一段话中的重点单词，图片中的某些小块，如下图所示，LIME方法找出了影响某一次决策的重要特征，其中绿色为相关特征，红色为重要特征。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-fc9aab62f1deb18f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="评价单个实例lime">评价单个实例LIME</h4>
<p>如果在建模的过程中出现一些泄露，比如X（假设是x1）里掺入了y的部分内容，或者数据集引起的偏差（如：男女不平等）。在实际应用中，这些x1又无法得到，那么在测试集中计算得出的模型准确度并不能说明模型的好坏。使用LIME方法寻找关键因素，如果发现x1是决定性因素，就很容易发现泄露问题。</p>
<p>另外，精确度并不是模型的唯一量度，有时需要从多个模型中选择出最佳模型，一般会选择整体正确率最高的模型，或者根据各个模型的准确率加权，最终方法对于单个实例未必是最优选择。对于单个实例，计算出决策的依据，并与人的先验知识印证，有利于选择对该实例效果最好的模型。在这样的交互过程中，开发者也能了解究竟哪些因素更能影响人的决策，从而优化模型。</p>
<p>开发者都希望在输入数据和输出数据间建立可解释的联系。但是复杂的机器学习模型或者深度学习建模中，相对比较困难，模型预测过程是成千上万参数共同作用的结果。希望最终呈现出来的是人能理解的，而非特征实际上怎么计算的细节，也不一定是输入的具体特征（如图片输入各像素点的颜色）。</p>
<p>实现LIME的具体方法是：在实例x附近加干扰，得到一些与它近似的实例z，用训练出的模型f对这些z进行预测f(z)，作为解释模型g的label。代入模型，优化下面公式中定义的目标函数。对于邻近x的z给予较高的权重π，对于较远的z给予较低的权重π。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a2e8e8e9609abd64.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>在分类问题中，f可看作是实例x属于某分类的概率，即f是预测模型；g是用于解释的模型；π<sub>x</sub>(z)通过衡量实例z与x的近似度赋予实例权重；L用于度量在局部范围π条件下，g用于解释f的不可信度（越小越好）；Ω(g)是模型g的复杂度。简单地讲：LIME的目标是从众多的解释模型G中选择最合适的模型g，该模型对于人类的理解足够简单（Ω(g)小），且不可信度L也比较小（复杂模型f和简单模型g在x附近效果差不多）。</p>
<p>在直觉上看，下图示例是一个比较复杂的二分类，整体并不是线性可分的，通过训练得出了复杂的二分类模型f，不同分类分别使用蓝色和肉色表示；对局部实例x（粗红十字），通过在它附近模拟一些实例z（十字和圆点），并且根据它们与x的距离赋予不同权重，用z和x训练简单的线性模型g，用于在局部范围内拟合x。再从简单模型g中提取可描述的特征。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-aabece09eb8635c8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>L的具体计算方法如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a508f2a1cf693e73.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中π根据距离赋予不同实例z权重，f(z)是模型对z的预测值
，z’是根据z计算的可解释的特征，g(z’)是简单模型。</p>
<p>举个现实中的例子：假设最终训练出来了无比复杂强大的模型f，它可以识别各种动物。各种动物有其各自的特征，各不相同，但是对于单个实例“猪”，必定有一些与它相关的重要特征（它是全部重要特征的子集）。生成猪和其类似动物作为数据，训练简单模型g，用于学习与“猪”相关的重要特征。虽然g代表不了整个模型f，但它能很好地描述“猪”。</p>
<p>文中方法把基础模型f当作黑盒，因此LIME方法可应用于任何分类模型。该方法可能出现的问题是：简单模型g，即使在实例x附近也未必能完美地模拟f。但是可以评价g在x附近对f的拟合程度，同样也可据此选择更适合的g。</p>
<p>有些分类器虽然统计上看效果不错，但对于某类实例x可能效果并不好，如果通过上述方法提取的特征看起来并不合理，也可从而评价f对x实例预测的可信度，以便后期优化模型f。</p>
<h4 id="评价整个模型-sp-lime">评价整个模型 SP-LIME</h4>
<p>上述方法用于评价对单个实例预测的可信程度，如果需要评价整个模型，则需要评价多个实例。SP（submodular
pick）方法用于在大量数据中选择适当的实例。</p>
<p>开发者希望被选择的实例能覆盖各种label类型，覆盖尽可能多的情况，且不冗余（不重复）。如下例所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-fe0118e7fbc92601.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>图中的行代表各个文档（实例），列代表文档中出现的关键词（特征），图中通过各个特征在各个实例的重要性构造了矩阵W。可以看到第二列特征对于每个文档都很重要（蓝色）；第二行和第五行涵盖了除f1特征之外的所有特征。</p>
<p>在构造实例集的过程中，尽量使用对各种情况都重要的特征f2，也尽量减少纳入类似实例，如第二行和第三行就非常相似。这样，不会因为训练集中“猫”多，使猫相关的特征显得非常重要，而是相对均匀地选择重要特征。</p>
<p><a
href="/1_Note/2_算法/14_模型解释/分类模型的可解释性">分类模型的可解释性</a></p>
]]></content>
  </entry>
  <entry>
    <title>论文阅读_广义加性模型</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/14_%E6%A8%A1%E5%9E%8B%E8%A7%A3%E9%87%8A/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%B9%BF%E4%B9%89%E5%8A%A0%E6%80%A7%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>英文题目：Intelligible Models for Classification and Regression<br />
中文题目：可理解的分类和回归模型<br />
论文地址：https://www.doc88.com/p-41099846725043.html<br />
领域：模型可解释性，广义加性模型，机器学习<br />
发表时间：2012<br />
作者：Yin Lou，Rich Caruana（模型可解释性大佬），康耐尔大学，微软<br />
出处：KDD<br />
被引量：256<br />
代码和数据：https://github.com/interpretml/interpret<br />
阅读时间：220819</p>
<h2 id="读后感">读后感</h2>
<p>加性模型的准确性优于线性模型，差于梯度决策树和深度学习模型．它在模型精度和可解释性间取平衡．其核心原理是针对单个特征建立模型（可以是非线性模型），然后把这些复杂模型加在一起形成最终模型．本文描述了具体实现方法．</p>
<h2 id="介绍">介绍</h2>
<p>复杂模型虽然预测精度高，但可解释性较差，因为很难判断单个特征在复杂模型中的贡献度．本文目标是建立尽量准确且可解释的模型，让用户可以理解每个特征的贡献度．使用广义加性模型（GAMs）方法，其核心算法如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220819153525.png"
alt="Pasted%20image%2020220819153525.png" /><br />
将 g 称为 link 函数，f 称为 shape 函数，g 和 f
可以是任何函数，比如非线性函数，对于单个特征建模 f，f
可以有很高的复杂度，但特征之间组合比较简单，只能是叠加关系．</p>
<p>比如下式就是一个加性模型的示例：<br />
<span
class="math display">\[y=x_1+x^2_2+\sqrt{x^3}+log(x_4)+exp(x_5)+2sin(x_6)+\epsilon\]</span><br />
对应的每个特征影响如图-1所示，可以分别看到每个特征对y的影响．<br />
<img src="/attachments_2022/Pasted%20image%2020220820144739.png"
alt="Pasted%20image%2020220820144739.png" /></p>
<p>每个shape函数都可以是非线性的，这也是加性模型效果优于线性模型的原因．表-1展示了各种模型的基本公式：<br />
<img src="/attachments_2022/Pasted%20image%2020220819154738.png"
alt="Pasted%20image%2020220819154738.png" /></p>
<h2 id="方法">方法</h2>
<p>设数据集中有N个实例，每个实例有n个特征{xi1...xin}，标签为yi．目标是构建函数F(x)，最小化损失函数L(y,F(x))．</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220820154911.png"
alt="Pasted%20image%2020220820154911.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220820154911.png</figcaption>
</figure>
<p>具体实现方法涉及两个维度，对于单特征训练的shape模型，一般使用样条函数或者树模型（图-4中的纵向）；对于shape模型的组合训练方法（图-4中的横向），即如何训练整体模型，则可选用最小二乘法，梯度提升和回修法．</p>
<h3 id="shape函数">shape函数</h3>
<p>文中提到的shape函数有样条函数和集成树函数，所有shape函数只涉及单个特征作为输入．</p>
<h4 id="样条函数">样条函数</h4>
<p>样条是一种特殊的函数，由多项式分段定义．比如三次样条中的每一段都由三次多项式表示，且整体是一条光滑的曲线，三次多项式形如：<br />
<span class="math display">\[  
y=a_i+b_ix+c_ix^2+d_ix^3  
\]</span><br />
文中使用了设置维度为d的回归样条函数：<br />
<img src="/attachments_2022/Pasted%20image%2020220820150922.png"
alt="Pasted%20image%2020220820150922.png" /></p>
<h4 id="树和集成树模型">树和集成树模型</h4>
<p>使用二叉树和集成二叉树方法，用叶节点个数可描述树的复杂度．树模型的每个分叉是对同一特征的不同值范围进行切分．支持的树包括：Single
Tree，Bagged Trees，Boosted Trees，Boosted Baaged
Trees．后面的实验中将首字体作为其方法的缩写．</p>
<h3 id="训练整体模型">训练整体模型</h3>
<p>用以下方法训练整体模型，用最小二乘训练样条函数，用梯度提升和回修训练树模型．</p>
<h4 id="最小二乘法">最小二乘法</h4>
<p>最小二乘法可以很好的训练线性模型，这里将bk(x)看成特征，训练拟合参数Bk．另外，还加入了平滑系数
λ．实验中将该方法称为惩罚最小二乘，记作P-LS．对于逻辑回归问题，将样条被简化为用不同的基拟合逻辑回归，方法称为惩罚迭代重加权最小二乘，记作
P-IRLS。</p>
<h4 id="boosting梯度提升法">Boosting梯度提升法</h4>
<p>在每一次迭代中，循环地依次训练所有特征，具体方法如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220819175637.png"
alt="Pasted%20image%2020220819175637.png" /><br />
* line 1: 将每个shape函数初值设为 0<br />
* line 2: 一共10次迭代：M=10<br />
* line 3: 遍历所有特征：假设一共三个特征n=3<br />
* <strong>line 4</strong>: 这里构造了一个数据集合R，对于所有实例
i=1...N，其自变量是实例中是第j个特征xij，因变量是将每个实例i代入当前所有
f
后（有几个特征就有几个f，这里用k表示特征数）计算预测值，然后计算预测与真值y的残差．<br />
* line
5：学习Shape函数S，利用第j个特征x，训练S(x)用于拟合R，之所以是Boosting，是因为它拟合的不是y本身，而是拟合残差<br />
* line 6：利用拟合的残差函数S调整更新第 j 个特征的拟合函数 fj</p>
<h4 id="backfitting回修法">Backfitting回修法</h4>
<p>回修法是之前拟合加性模型的主流方法，它与梯度提升方法非常类似，差别在伪代码的第4行和第6行，在第4行，回修法的fk不包含其本身对应的第fj；而第6行，直接用S替换fj．对比可以看出梯度提升拟合的是残差，而回修法拟合的是fj本身，因此，随着数据不同，回修的波动可能相对较大，最终可能难以收敛．</p>
<h2 id="实验">实验</h2>
<p>图-3对比了梯度提升和回修方法对回归(a,b,c)和分类(d,e,f)的建模效果，可以看到，当叶节点过多时，在训练集中效果好，但在测试集上效果差，回修法效果相对不稳定．<br />
<img src="/attachments_2022/Pasted%20image%2020220820160348.png"
alt="Pasted%20image%2020220820160348.png" /></p>
<p>图-5对比了使用不同Shape函数的效果，第一行样条函数由于追求拟合曲线的平滑，在数据较少的位置拟合效果较差，这可能是由于样条过于平滑，学不出细节．相对来说第二行的树模型效果更好．<br />
<img src="/attachments_2022/Pasted%20image%2020220820160329.png"
alt="Pasted%20image%2020220820160329.png" /></p>
<p>表-5展示了主实验结果，这里使用了6个回归数据集，从实验结果的均值可以看到，复杂模型效果最好，加性模型中，BST-bagTRX效果最好，它是梯度提升的Bagging树，X表示随机设置叶节点数．</p>
<p><img src="/attachments_2022/Pasted%20image%2020220820155313.png"
alt="Pasted%20image%2020220820155313.png" /><br />
比较有意思的是，在BST-bagTR类中，叶节点2-4，效果最好，这可能是由于叶节点太多可能造成过拟合．</p>
<p>图-6展示了回归中各个模型的偏差和方差，偏差描述了模型预测结果和实际 y
之间的差异，方差用于评价子学习器学出结果的一致性，以评价稳定性（常用交叉验证的方法测量方差）．可以看到对于所有数据集，位于中间偏左的梯度提升+树模型效果都最好．</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220820160648.png"
alt="Pasted%20image%2020220820160648.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220820160648.png</figcaption>
</figure>
<h2 id="扩展阅读">扩展阅读</h2>
<h3 id="ga2m">GA2M</h3>
<p>Accurate Intelligible Models with Pairwise Interactions<br />
是同一作者写的另一篇基于GAM的优化，将基于单个特征的加性模型扩展为基于特征组合的加性模型．核心公式如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220819165923.png"
alt="Pasted%20image%2020220819165923.png" /><br />
其核心方法在于如何选择和优化特征组合，实验证明在有些情况下比lightgbm更好．</p>
<h2 id="实际使用">实际使用</h2>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pygam <span class="im">import</span> LinearGAM, s, f  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 生成样本数据  </span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.sort(<span class="dv">5</span> <span class="op">*</span> np.random.rand(<span class="dv">40</span>, <span class="dv">1</span>), axis<span class="op">=</span><span class="dv">0</span>)  </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.sin(X).ravel() <span class="op">+</span> np.random.normal(<span class="dv">0</span>, <span class="fl">0.3</span>, size<span class="op">=</span><span class="dv">40</span>)  </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 使用 LinearGAM 拟合模型  </span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>gam <span class="op">=</span> LinearGAM(s(<span class="dv">0</span>) <span class="op">+</span> f(<span class="dv">0</span>))  </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>gam.fit(X, y)  </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 使用线性回归模型拟合数据  </span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>reg <span class="op">=</span> LinearRegression().fit(X, y)  </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 生成预测数据  </span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>XX <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">1000</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)  </span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>y_pred_gam <span class="op">=</span> gam.predict(XX)  </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>y_pred_reg <span class="op">=</span> reg.predict(XX)  </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># 画出数据图像  </span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>plt.plot(X, y, <span class="st">&#39;o&#39;</span>, label<span class="op">=</span><span class="st">&#39;Observations&#39;</span>)  </span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>plt.plot(XX, y_pred_gam, <span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;GAMLinear&#39;</span>)  </span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>plt.plot(XX, y_pred_reg, <span class="st">&#39;g&#39;</span>, label<span class="op">=</span><span class="st">&#39;Linear Regression&#39;</span>)  </span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;best&#39;</span>)  </span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>plt.show()  </span></code></pre></div>
<p>注意："f" 和 "s" 是两个重要的概念，"f"
指的是预测变量与响应变量之间的非线性关系。"s"
指的是预测变量与响应变量之间的线性关系。其中的参数指对哪一个变量操作，这里x只有一个变量，所以都是针对0操作。</p>
]]></content>
      <tags>
        <tag>模型解释</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_解释黑盒模型方法综述</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/14_%E6%A8%A1%E5%9E%8B%E8%A7%A3%E9%87%8A/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E8%A7%A3%E9%87%8A%E9%BB%91%E7%9B%92%E6%A8%A1%E5%9E%8B%E6%96%B9%E6%B3%95%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<h1
id="论文阅读_解释黑盒模型方法综述">论文阅读_解释黑盒模型方法综述</h1>
<p>#机器学习 #论文阅读</p>
<p>论文：《A Survey of Methods for Explaining Black Box Models》<br />
论文地址：https://arxiv.org/abs/1802.01933v3<br />
(本文为论文核心内容提炼，并非逐段翻译)</p>
<p>《A Survey of Methods for Explaining Black Box
Models》是2018年发表在ACM Computing
Surveys上的一篇综述性论文，正文37页，介绍了七十多种模型解释相关论文，参数文献144篇。它列出了每种方法的相关论文，作者，发表时间，解释模型，被解释模型，解释何种类型数据，是否提供代码，数据等信息，如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-816b54b29e711a73.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>论文的前五章介绍了为什么需要使用可解释模型，第六到九章分类别介绍了各种解释方法及相关论文，并对每一种方法进行了简要介绍。</p>
<h2 id="如何评价模型">如何评价模型</h2>
<p>无论是写论文，还是和客户沟通，描述下列几点都是必不可少的。</p>
<p>• 模型评价指标<br />
一般数据分析时都会使用：敏感性、特异性、F1 score、AUC曲线等方法。</p>
<p>• 被多少数据支持<br />
训练数据和测试数据的数据量也是重要量度，10000个实例训练出的模型相对于100个实例训练的模型更加可靠。</p>
<p>• 泛化能力<br />
在某些比较敏感的领域，数据往往不被公开，使用A机构数据构建的模型，不一定能在B机构正常工作，此时需要考虑训练数据是单中心还是多中心，单中心数据可能包含的一些本地因素，导致难以泛化，有时需要对比数据运行在不同场景中的测试效果，以展示其泛化性能。</p>
<p>• 健壮性<br />
健壮性主要指当数据缺失时，模型能否正常工作。</p>
<p>• 一致性<br />
如果使用多模型预测，对比各个模型结果是否一致，也是一种对模型准确性的量度。</p>
<p>• 可解释性<br />
可解释性在下文详述。</p>
<h4 id="为什么解释模型">为什么解释模型</h4>
<p>• 安全性、可靠性
精确度都是自己说的，数据处理方法不同，纳入训练集和测试集的数据不同，定义的因变量不同，算出的精确度也不同，因此不能作为模型的唯一量度和对比模型效果。
对于医疗、自动驾驶，这些生死攸关的领域，除了提供准确率和最终预测结果，还需要提供做出判断的依据，使模型具有可解释性才能被接受。</p>
<h4 id="隐藏的问题">隐藏的问题</h4>
<p>• 建模数据和实际数据不一致<br />
有些数据和类别在训练时无法获取，但实际应用中又必须使用；另外，有时test与train分布一致，但与实际场景中数据不一致。这些都使得评价模型和评价实际效果之间存在差异。</p>
<p>• 结果正确，但依据不对<br />
在狼与狗的分类器中，分类的依据可能是图片的背景，而不是动物本身，尽管模型准确率很高，但当狗出现在野外时，很可能被识别为狼。</p>
<p>• 无法察觉的攻击<br />
在深度学习领域，有时对抗攻击仅通过人眼不可查觉的微小调整即可骗过模型，这使得模型变得不可靠。</p>
<p>• 获取数据与现实不一致<br />
有些数据处理时，在训练集和测试集中都去掉了缺失数据和脏数据。但实际情况下，这些数据可能无法被识别，或者也需要被预测，这使得模型计算得出的准确率比实际应用高很多。</p>
<h4 id="科研中的回归和解释">科研中的回归和解释</h4>
<p>科研项目中有时需要提取出可以简单地识别和表达的规律。</p>
<h4 id="模型选型">模型选型</h4>
<p>在一些重要领域，模型的可解释性也是选型的重要考虑因素，有时为了可解释性也可以牺牲一些精确度。</p>
<h4 id="偏差">偏差</h4>
<p>• 错误数据引起<br />
训练数据中可能包含错误数据，且清洗时并未发现，这些数据造成了建模的偏差。</p>
<p>• 模型引起<br />
有些偏差是模型本身的特性造成的，比如使用线性模型拟合非线性数据，结果误差很大。</p>
<p>• 人类偏见<br />
有些数据虽然客观存在，但也蕴含了偏见，如果某一招聘网站计算出女程序员数量少，则可能认为女性不适合从事该工作，从而使模型失去了公平性。伦理和隐私问题目前也是模型正在面对的问题。</p>
<h4 id="寻找错误原因">寻找错误原因</h4>
<p>通过分析模型错误预测的原因改进模型。</p>
<h4 id="哪些模型需要解释">哪些模型需要解释</h4>
<p>一般情况下复杂的模型都需要解释，比如组合树模型、深度学习模型、非线性模型等等。</p>
<h2 id="怎么解释模型">怎么解释模型</h2>
<p>解释是阐明自变量X和因变量Y之间的关系，一般包括解释模型的内部逻辑和决策的原因。常用的方法是统计和归因。同时需要遵循以下原则：</p>
<p>• 可认知的特征<br />
需要概念层的解释：易于理解。比如深度学习网络的隐藏层虽然也是一种权重但很难向用户解释其含义。</p>
<p>• 符合常识<br />
解释必须符合专家背景知识，否则即使结果正确，也常被认为是“蒙的”。</p>
<p>• 只解释起决定作用的因素<br />
代入模型的数据很多，解释应力求简约，一般只解释最重要的前N个特征，以及对重要类别进行解释。</p>
<p>• 易于理解，便于决策<br />
规则不能太多，树不能太深，线性的非零参数不能太多；特征之间不能过度组合；对于不同背景知识用户，可使用不同解释方法。</p>
<h2 id="常用解释方法">常用解释方法</h2>
<p>• 规则模型（用于纯数据）<br />
规则是最终提炼出的一组或多组类似if-else的逻辑，某一实例可能符合多条规则得出不同结论、或者不符合任何规则。此时，可使用多条规则的优先级，如top-k
rules投票方法。</p>
<p>• 简单决策树（用于纯数据）<br />
不同于规则模型，树模型中单个实例只可能落入一个分支。</p>
<p>• 特征重要性（用于纯数据）<br />
很多模型自带特征重要性输出。</p>
<p>• 划出重点区域（用于图片，文字）<br />
常使用Attention方法，画出图中的重要区域，或者文本中的关键词，以解释决策原因。</p>
<p>• 可视化方法（用于纯数据）<br />
分析某一特征与结局变量的关系，类似单因素分析。</p>
<p>• 结局与特征组合的关系（用于纯数据）<br />
目的往往是去掉不重要的特征</p>
<p>• 使用元数据解释（所有）<br />
使用某个类别的典型数据，寻找某一类别的共性，相近实例分析。</p>
<p>• 最大激活（用于神经网络）<br />
分析单层最大激活，倒推哪部分特征更重要。</p>
<p>• 注意事项<br />
注意限制复杂度，并在精确和解释间取得平衡。</p>
<h2 id="不同模型方法不同">不同模型方法不同</h2>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ef54e80f414bb2f8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>不同模型使用不同的解释方法，当模型本身就具有可解释性，如树模型或线性模型能解释自身逻辑，但需要考虑如何展示这些规则（TRANSPARENT
BOX DESIGN）；反之，如果是黑盒模型，则需要考虑如何解释模型整体（MODEL
EXPLANATION），解释单个实例预测结果（OUTCOME
EXPLANATION），以及模型检测问题（MODEL
INSPECTION），下面将一一介绍。</p>
<h2 id="解释整体模型">解释整体模型</h2>
<p>论文的第六部分主要介绍了解释整体模型的方法，一般情况下，从解释具体实例开始，再具体实例到各个类别，各个类别又组成了对整体模型的解释。具体方法如下：</p>
<p>• 决策树<br />
早在1996年，就已使用决策树模型解释深度网络。<br />
举例一：使用自上而下的解释方法，先根据各个类别选择元型数据，选取每个元型其及附近数据构造针对每一类别的简单模型并提取特征，用简单模型构造复杂模型。比如一个复杂模型可以识别汽车、行人、长颈鹿等多种物体，而针对其中类型长颈鹿的模型比整体模型简单很多。<br />
举例二：从森林模型提取主要树模型，可以使用聚类方法，也可以选择其中误差最小的树，或者最重要的树。</p>
<p>• 规则<br />
举例一：可为每一类别分别建立一组或多组规则，当规则重叠时，使用支持率更高的规则，或者复杂度较使的规则。<br />
举例二：可以使用自下而上的解释方法：先对数据聚类，找到元型，再产生规则。</p>
<p>• 简单模型解释复杂模型<br />
人们希望找到一种对所有模型都适用的解释方法：用一个简单模型c解释复杂模型b。具体方法如下：</p>
<ol type="1">
<li>设黑盒模型为b，解释模型为c。<br />
</li>
<li>用迭代方法模拟实例x附近实例代入模型b得到标签y’（遗传、蒙特卡罗、增化学习，倒推）<br />
</li>
<li>代入模拟的数据和y’训练模型c。<br />
</li>
<li>计算可信度：尽量减少b与c的差异（match比例）。<br />
</li>
<li>提取模型c的重要特征，分析路径，分析错误实例。</li>
</ol>
<h2 id="解释预测结果">解释预测结果</h2>
<p>解释单个实例，是一种局部解释，它只涉及输入的单个实例和模型b。且只与模型b的部分实例有关。具体方法如：</p>
<p>• 寻找重要特征子集<br />
• 计算特征变化对结局变量影响<br />
• 神经网络越往后层包含的无关信息越少，以此倒推重要特征。<br />
• 使用线性解释非线性（但并非所有情况都能使用线性拟合）。</p>
<p>下例展示了图像识别中影响最终判断的重点区域，方法是计算对用最后一层（线性层），具有最大影响的图像区域（最大平均池化）。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-cae8c810761a9363.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="模型检查">模型检查</h2>
<p>模型检查使用了一些做图方法来解释模型，例如：</p>
<p>• 改变一些属性，对照预测结果变化，并用图片展示分析结果。<br />
下图展示了一些作图方法，左图使用PDP（Partial Dependence
Plot）图，其横轴是酒的PH值的高低，纵轴是酒的价值，它解释了部分特征对结局的影响。右图是年龄对风险的影响。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a1aeb970b5db1d2e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>• 基于树可视化<br />
可用决策树解释RNN，并将特征分组。</p>
<p>• 基于最大激活<br />
根据某个实例激活的神经元，展示各层激活的位置和区域。</p>
<p>• 其它做图方法<br />
单因素分析（连接、离散）、多因素分析、组合特征分析等。</p>
<h2 id="透明模型">透明模型</h2>
<p>有些模型自带可解释性，比如树模型，规则模型，线性模型等，但具体解释时也需要一些技巧。</p>
<h4 id="简单树模型">简单树模型</h4>
<p>树模型本身就是对模型的全局解释，而解释具体实例则使用树中的某一路径，注意限制树的复杂度（深度）。</p>
<h4 id="规则模型">规则模型</h4>
<p>使用规则时，可使用贪婪算法、贝叶斯算法简化规则，缩小特征空间；通过规则分析错误原因，规则最好相互独立。</p>
<h4 id="元型选择">元型选择</h4>
<p>• 典型数据<br />
对于每一类别，可使用均值、聚类中心等方法选取元型数据。</p>
<p>• 每一类别可能不止一个元型<br />
比如手写数字识别时，数据7的典型写法可能不止一种，此时需要使用聚类方法选择多个元型。</p>
<p>• 人机交互调整<br />
生成元型数据时，往往模型选择和专家纠正相互迭代进行，以便尽快达到最佳效果。</p>
<p>• 元型反例<br />
有时也可使用元型反例，描述与典型规则不一致的特殊情况，比如“鲸鱼不是鱼”。</p>
<p>• 图像重建<br />
通过对某一类型数据的学习，如对“狗”图片的学习，用生成对抗的方法生成更为典型的狗图片（忽略背景）。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_语音合成_Spear-TTS</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/1_%E8%AF%AD%E9%9F%B3/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90_Spear-TTS/</url>
    <content><![CDATA[<p>name_ch: 说话、阅读和提示：少量监督实现高保真文本转语音<br />
name_en: Speak, Read and Prompt：High-Fidelity Text-to-Speech with
Minimal Supervision<br />
paper_addr: http://arxiv.org/abs/2302.03540<br />
code: https://google-research.github.io/seanet/speartts/examples/<br />
date_publish: 2023-02-07</p>
<h2 id="读后感">1 读后感</h2>
<p>这是一个完整的TTS系统，可视为AudioLM的延展。</p>
<h2 id="摘要">2 摘要</h2>
<p>多语言的语音合成系统，使用大量无监督数据，少量有监督数据训练，结合了两种类型的离散语音表示，解耦了：从文本生成语义标记（读），由语义标记再生成声音标记（说）两部分，用大量纯音频数据训练“说模块”，减少“读模块”对并行数据（并行数据指：文本语音数据对）的需求。<br />
为控制说话人，使用提示方法，只需要3秒音频即可合成在训练集中未见过的说话人的语音。<br />
实验表明，<strong>SPEAR-TTS 仅使用 15
分钟的并行数据</strong>即可与最先进的方法的字符错误率相比较，主观测试证明其可在自然度和声学质量方面与真实语音相媲美。</p>
<h2 id="离散的语音表示">3 离散的语音表示</h2>
<p>详见AudioLM</p>
<h3 id="语义token">3.1 语义token</h3>
<p>语义标记的作用是提供一个粗略的、高层级的条件来生成随后的声学标记。因此，应该提供一种表示，其中语言内容（从语音到语义）是显著的，同时不考虑说话人身份和声学细节等副语言信息。<br />
为了获得这样的表示，训练了一个基于 <a
href="/1_Note/2_算法/2_大模型/论文阅读_音频表示_w2v-BERT">w2v-BERT</a>
的自监督语音表示模型。该模型结合了<strong>Mask语言建模</strong>和<strong>对比学习</strong>以获得语音表示。训练结束后，对特定层的均值方差归一化输出<strong>运行
k 均值聚类。使用质心索引作为离散标记</strong>。</p>
<h3 id="声学token">3.2 声学token</h3>
<p>声学标记是离散的音频表示，可提供声学细节的高保真重建。训练了一个 <a
href="/1_Note/2_算法/1_语音/论文阅读_音频压缩_SoundStream">SoundStream</a>
神经编解码器来<strong>重建语音</strong>，同时将其<strong>压缩成一些离散单元</strong>。
SoundStream
通过在<strong>卷积自编码器</strong>的瓶颈中添加一个<strong>残差量化器</strong>来实现这一目标。</p>
<h2 id="spear-tts-概述">4 SPEAR-TTS 概述</h2>
<p>SPEAR-TTS 通过将<strong>文本作为生成条件来扩展
AudioLM</strong>。如图-1所示，主要分为两个场景：<strong>S1文本转成离散的语义标记，S2将语义转声学标记，再利用SoundStream转成音频</strong>。<br />
其中需要两步转换，原因是：语义信息在逻辑上介于文本和声学信息之间；且<strong>语义转声学只需要无标注的音频数据训练</strong>。另外，还可以再加入与
AudioLM类似的第三种场景，通过预测与精细残差矢量量化级别对应的声学标记，来提高合成语音的质量。</p>
<h2 id="s1提升监督效率">5 S1:提升监督效率</h2>
<p>通过有监督学习从文本到语义标记的映射，使用语音合成数据集提取语义标记，将S1变为序列到序列seq2seq的任务，具体使用Transformer结构。<br />
<img
src="/attachments_2023/Pasted%20image%2020230502151534.png" /><br />
有监督学习需要大量标注数据，对于<strong>小语种</strong>比较困难，文中使用了两种改进策略：</p>
<h3 id="预训练">5.1 预训练</h3>
<p>在一个去噪预训练任务上对Encoder-Decoder的Transformer进行预训练。给模型提供了一个原始语义token序列的<strong>损坏版本</strong>，目标是产生相应的<strong>未损坏token</strong>序列。<br />
典型的损坏方法包括随机替换、删除和遮蔽单个token或整个token范围。在初步研究中观察到独立地以<strong>恒定概率删除单个token</strong>的方法比其他替代方案更有效。<br />
在对模型进行去噪任务的预训练之后，对S1任务进行微调。微调时冻结编码器的上层和解码器的参数。</p>
<h3 id="回译backtranslation">5.2 回译：Backtranslation</h3>
<p>相同的文本序列可以对应多种音频，比如不同的声音、口音、韵律、情感内容和录音条件。这使得文本和音频高度不对称。回译方法是：<strong>使用可用的并行数据对来训练语音到文本模型，并使用它和来自纯音频的语料来生成并行数据</strong>，增加模型的训练数据。<br />
<img
src="/attachments_2023/Pasted%20image%2020230502151507.png" /><br />
从左下开始看图-2，首先，利用有限数据的损坏方法（加噪再去噪）来预训练模型P，生成语义token表征音频数据；然后训练回译模块，利用少量的并行数据微调解码器，训练模型B；利用模型B的回译方法以及大量无标签数据生成大量可用于训练的并行数据（右上）；最后用所有并行数据精调模型（右下）只精调编码器的下面几层。</p>
<h2 id="s2控制生成过程">6 S2:控制生成过程</h2>
<p>第二个场景是将语义标记映射到声学标记，此处，可从<strong>只有音频</strong>的数据集的句子中提取语义声学标记，然后训练Transformer模型实现seq2seq的翻译功能。第二阶段生成<strong>语音、节奏和录音条件随机变化</strong>的话语，再现训练数据中观察到的特征分布。<br />
由于 S1 和 S2 的训练是<strong>解耦</strong>的，因此当 <strong>S1
在单说话人数据集上训练时，S2 可保留生成语音的多样性</strong>。</p>
<p>为了控制说话者声音的特征，在<strong>训练的时候就考虑</strong>了有音频提示和无音频提示两种情况。如图-3所示：<br />
<img
src="/attachments_2023/Pasted%20image%2020230502151109.png" /><br />
这里的红色块是语义token，黄色块是声学token，灰色为提示分隔符。在按音频提示生成语音的场景中（下图），用以下训练连接序列：来自提示的语义token，来自目标的语义token，来自提示的声学token。该模型生成与来自目标的语义标记相对应的声学token（Output），同时保留来自提示的声学标记中的语音和说话条件。<br />
在训练时，从每个训练集中随机选择两个不重叠的语音窗口，从中计算语义和声学标记的序列。将其中<strong>一个窗口视为提示，将另一个视为目标输出</strong>。<br />
在推理时，输入也是前三块，使用自回归方式生成Output。</p>
]]></content>
      <tags>
        <tag>语音</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_语音合成_VALL-E</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/1_%E8%AF%AD%E9%9F%B3/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90_VALL-E/</url>
    <content><![CDATA[<p>name_ch: 神经网络编解码器语言模型实现零样本TTS<br />
name_en: Neural Codec Language Models are Zero-Shot Text to Speech
Synthesizers<br />
date_publish: 2023-01-05<br />
paper_addr: http://arxiv.org/abs/2301.02111<br />
code: https://github.com/microsoft/unilm/tree/master/valle</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230505151400.png" /></p>
<h2 id="读后感">1 读后感</h2>
<p>语音合成模型，输入是待合成的文本，3秒的录音，输出为与录音一致的合成后的语音内容。</p>
<h2 id="与传统tts的差异">2 与传统TTS的差异</h2>
<p>之前的语音模型是：音素-&gt;梅尔倒谱-&gt;音频；VALL-E是：音素-&gt;离散编码-&gt;音频。<br />
<img src="/attachments_2023/Pasted%20image%2020230505151746.png" /></p>
<h2 id="主要贡献">3 主要贡献</h2>
<p>• 我们提出了VALL-E，有效使用上下文学习能力的TTS
框架，音频编解码器代码作为中间表示，以取代<strong>传统的梅尔声谱图</strong>。<br />
• 通过利用大量的<strong>半监督数据</strong>在说话者维度构建了一个通用的
TTS 系统。<br />
• VALL-E
能够以相同的输入文本提供不同的输出，并保持声音提示的<strong>声学环境和说话者的情绪</strong>。<br />
•
在零样本场景中提示来合成具有高说话人相似度的<strong>自然语音</strong>。</p>
<h2 id="背景">4 背景</h2>
<p>合成音频数据的<strong>挑战</strong>，包括每个时间步骤需要生成的概率数量多和序列长度长的问题。为了解决这些问题，使用语音量化技术来压缩数据和提高推理速度。矢量量化广泛应用于自监督语音模型中进行<strong>特征提取</strong>，如vq-wav2vec和HuBERT。<br />
最近的研究表明，<strong>自监督模型</strong>中的编码也可以重构内容，并且推理速度比WaveNet快。但是，说话人身份已被丢弃，重构质量很差。而AudioLM模型有效解决了以上问题。深度学习在音频编码方面也取得了显著提升，这里使用了Encodec作为音频编码器。</p>
<h2 id="方法">5 方法</h2>
<h3 id="问题表述">5.1 问题表述</h3>
<p>其中 y 是音频样本，x = {x0, x1, . . . , xL}
是其对应的音素转录，我们使用预训练的神经编解码器模型将每个音频样本编码成离散的声学代码，表示为Encodec(y)
= C， T是下采样的话语长度。重建波形 Decodec(C) ≈ y^。<br />
推理过程中，给定音素序列和未见过的说话人的 3
秒登记录音，首先通过训练的语言模型估计具有相应内容和说话人语音的声学代码矩阵，模型推理，然后用解码器合成高质量的语音。</p>
<h3 id="训练">5.2 训练</h3>
<p><img
src="/attachments_2023/Pasted%20image%2020230505154108.png" /><br />
以分层的方式设计了两个条件语言模型，一个用于生成声音c1（自回归AR），一个用于精调声音c2-8（NAR非自回归）。AR
模型和 NAR 模型的结合在语音质量和推理速度之间提供了良好的折衷。<br />
自回归为了生成具有特定内容的语音，使用音素序列作为语言模型的音素提示。使用非自回归
(NAR) 模型生成其他七个量化器的代码。与 AR 不同的是，NAR 模型允许每个
token 参与 self-attention 层中的所有输入 token。</p>
<h3 id="推理">5.3 推理</h3>
<p>如果该模型无需微调即可为看不见的说话人合成高质量的语音，则该模型被认为具有上下文学习能力。<br />
首先将文本转换为音素序列，并将录音编码为声学矩阵，形成音素提示和声学提示。对于
AR
模型，使用以提示为条件的基于采样的方法，可以显着增加输出的多样性。对于
NAR
模型，使用贪心解码来选择概率最高的标记。最后，使用解码器生成以八个代码序列为条件的波形。</p>
]]></content>
      <tags>
        <tag>语音</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_语音合成_VALLE-X</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/1_%E8%AF%AD%E9%9F%B3/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90_VALLE-X/</url>
    <content><![CDATA[<p>name_ch: 用你自己的声音说外语：跨语言神经编解码器语言建模<br />
name_en: Speak Foreign Languages with Your Own Voice：Cross-Lingual
Neural Codec Language Modeling<br />
paper_addr: http://arxiv.org/abs/2303.03926<br />
date_publish: 2023-03-07</p>
<h2 id="读后感">1 读后感</h2>
<p>对 VALL-E
的扩展，以源语言语音和目标语言文本为提示，预测目标语言语音的声学标记序列，可用于从语音到语音的翻译任务。它可以生成目标语言的高质量语音，同时保留看不见的说话者的声音、情感和声学环境。有效缓解了外国口音问题，可以通过语言ID来控制。</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230505162221.png" /><br />
以从源文本和目标文本中导出的音素序列，以及从音频编解码器模型中导出的源声学标记作为提示，生成目标语音。<br />
<img src="/attachments_2023/Pasted%20image%2020230505162409.png" /></p>
<h2 id="介绍">2 介绍</h2>
<p><strong>主要贡献</strong><br />
• 提出 VALL-E X
条件跨语言语言模型，以源语言语音和目标语言文本为提示，预测目标语言声学标记。<br />
•
多语言上下文学习框架，能保持看不见的说话者的声音、情感和语音背景，仅依赖源语言中的一个句子提示。<br />
• 显著减少外国口音问题，这是一个众所周知的跨语言问题。<br />
• 将VALL-E X
应用于零样本跨语言文本到语音合成和零样本语音到语音翻译任务。在说话人相似度、语音质量、翻译质量、语音自然度和人类评估方面击败强基线。</p>
<h2 id="方法">3 方法</h2>
<p>除了模型本身，结合使用 G2P Tool 将文本转换成音素，以及最后使用
Encodec 生成音频数据。</p>
<h3 id="模型构架">3.1 模型构架</h3>
<p><img
src="/attachments_2023/Pasted%20image%2020230505163144.png" /><br />
由一个自回归的多语音编码器和一个非自回归的编码器组成。<br />
多语言声学标记 (A) 和音素序列 (S) 分别使用编码器和 G2P
工具从语音和转录中转换而来。在训练期间，使用来自不同语言的配对 S 和 A
来优化这两个模型。本文中语义标记指音素序列。</p>
<h3 id="多语言训练">3.2 多语言训练</h3>
<p>利用了双语语音转录 (ASR) 语料库，成对的 (Ss, As) 和 (St, At)
来训练多语言模型。<br />
另外，利用语言 ID 来指导 VALL-E X
中特定语言的语音生成。因为是用多语言数据训练的，如果不指定ID，可能会混淆为特定语言选择合适的声学标记。例如汉语是声调语言，而英语是非声调语言。这在引导正确的说话风格和缓解口音问题方面出奇地有效，具体来说，将语言
ID 嵌入到密集向量中，并将它们添加到声学标记的嵌入中。</p>
<h3 id="多语言推理">3.3 多语言推理</h3>
<p><img
src="/attachments_2023/Pasted%20image%2020230505164738.png" /><br />
自回归和非自回归模型的输入不同；右侧显示了语音到语音翻译的过程。<br />
给定源语音 Xs，语音识别和翻译模型首先从语义编码器生成源音素
Ss，从语义解码器生成目标音素 St。此外，使用 EnCodec 编码器将 X
压缩为源声学标记 As。然后，将 Ss、St 和 As 连接起来，作为 VALL-E X
的输入，以生成目标语音的声学标记序列。使用 EnCodec
的解码器将生成的声学标记转换为最终的目标语音。</p>
<h2 id="相关知识">4 相关知识</h2>
<ul>
<li>SpeechUT:
SpeechUT是一种跨模态预训练模型，用于将语音和文本连接起来。它使用隐藏单元作为接口来对齐语音和文本，并将语音编码器和文本解码器的表示与共享单元编码器连接起来。<br />
</li>
<li>G2P Tool 把是 Grapheme-to-Phoneme
工具的缩写，是一种将单词的字素转换为音素的工具。它使用循环神经网络实现。</li>
</ul>
]]></content>
      <tags>
        <tag>语音</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_音频压缩_Encodec</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/1_%E8%AF%AD%E9%9F%B3/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E9%9F%B3%E9%A2%91%E5%8E%8B%E7%BC%A9_Encodec/</url>
    <content><![CDATA[<p>name_ch: 高保真神经音频压缩<br />
name_en: High Fidelity Neural Audio Compression<br />
date_publish: 2022-10-24<br />
paper_addr: http://arxiv.org/abs/2210.13438<br />
code: github.com/facebookresearch/encodec</p>
<h2 id="读后感">1 读后感</h2>
<p>方法与SoundStream相似，模型主要使用了卷积，LSTM，还加入Transformer优化量化单元，以减少带宽。</p>
<h2 id="摘要">2 摘要</h2>
<p>Encodec也是一个音频编码器 audio
codec，包括编码器-解码器架构、量化方法和感知损失等要素。EnCodec在多个音频压缩比和采样率条件下，在语音和音乐的压缩中均达到了最先进的质量水平。<br />
文章还讨论了神经网络压缩模型的两个问题：如何<strong>表示噪音</strong>和如何<strong>高效地压缩</strong>，作者通过构建大而多元化的训练集和引入辨别器网络，解决了第一个问题，而通过引入熵编码和实时模式流的控制来解决第二个问题。<br />
检验了EnCodec的运算速度、实时和压缩效果，得到了较好的实验效果。</p>
<h2 id="方法">3 方法</h2>
<p><img
src="/attachments_2023/Pasted%20image%2020230502102037.png" /><br />
模型由编码器，量化器，解码器三部分组成。</p>
<h3 id="编解码器结构">3.1 编解码器结构</h3>
<p>如图所示，主要使用卷积结构。另外，同时提供针对流式数据和非流式数据的处理方法。</p>
<h3 id="残差向量量化">3.2 残差向量量化</h3>
<p>同StreamSound类似，通过在训练时选择不同数量的残差步骤，可以使用单个模型支持<strong>多个带宽目标</strong>。</p>
<h3 id="语言建模和熵编码">3.3 语言建模和熵编码</h3>
<p>另外训练了一个小型基于Transformer的语言模型，旨在通过单个CPU核心保持快于实时的端到端压缩/解压缩速度。<br />
该模型包括5层、8个头、200个通道、每个前馈块的维度为800，没有dropout。<br />
在训练时，选择一个带宽和相应的codebook数量Nq。对于时间步t，从时间t-1得到的离散表示使用学习的嵌入表之一变换成连续表示，然后相加。<br />
Transformer的输出被馈送到Nq个线性层，并且每个线性层输出通道的数量与每个codebook的基数（例如1024）相同，这样可以给在时间t上估计占用每个codebook的分布的对数。<br />
因此，在单个时间步骤上忽略了潜在的码书之间的互信息。这样就可以<strong>加速推理，并且对最终交叉熵的影响有限</strong>。</p>
<h3 id="训练目标">3.4 训练目标</h3>
<p>目标函数结合了重建损失，判别损失，以及量化损失。<br />
<img
src="/attachments_2023/Pasted%20image%2020230502102412.png" /><br />
其中x是原始音频，x^是生成音频；<br />
* 重建损失包含时域损失lt和频域损失lf<br />
* lt：评价了音频帧的差异<br />
* lf：评价了多个时间尺度在梅尔频谱的差异<br />
* 对抗损失 <img
src="/attachments_2023/Pasted%20image%2020230502111429.png" /><br />
*
lg：对抗中的判断器，评价了判别器的损失，引入了基于多尺度短时傅里叶变换(MS-STFT)
鉴别器的感知损失项<br />
*
lfeat：对抗中的生成器，评价了音频之间特征的差异，为生成器添加了相对特征匹配损失，<br />
lw：VQ承诺损失，用于计算 zc 当前残差和 qc(zc)
相应码本中最近的条目的差异。<br />
lr：另外，还训练一个小型 Transformer
语言模型（可选），用于使用在量化单元上进行熵编码，以进一步减少带宽。</p>
<h3 id="损失函数的参数">3.5 损失函数的参数</h3>
<p>引入了一个损失平衡器，平衡器可以更容易地推断出不同的损失权重，每个权重都可以解释为来自相应损失的模型梯度的分数。</p>
]]></content>
      <tags>
        <tag>语音</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_音频压缩_SoundStream</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/1_%E8%AF%AD%E9%9F%B3/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E9%9F%B3%E9%A2%91%E5%8E%8B%E7%BC%A9_SoundStream/</url>
    <content><![CDATA[<p>name_ch: SoundStream：一种端到端的神经音频编解码器<br />
name_en: SoundStream：An End-to-End Neural Audio Codec<br />
paper_addr: http://arxiv.org/abs/2107.03312<br />
date_publish: 2021-07-07</p>
<h2 id="读后感">1 读后感</h2>
<p>高效压缩语音、音乐和一般音频。模型由编码器，量化器，解码器组成，主要使用了卷积技术。</p>
<h2 id="摘要">2 摘要</h2>
<p>基于<strong>神经网络</strong>的音频编码器，可高效生成文本，音乐。模型结构由<strong>全卷积编码器/解码器网络和残差矢量量化器组成</strong>。它结合了<strong>对抗和重建损失技术</strong>，可将量化的嵌入作为输入，生成高质量音频。<br />
单模型生成3kbps~18kpbs的音频。该模型适用于低延迟实现，<strong>支持流式</strong>推理，并可在<strong>智能手机
CPU</strong>
上实时运行。通过主观质量证明，SoundStream输出音频高于之前模型。<br />
<img src="/attachments_2023/Pasted%20image%2020230502083500.png" /></p>
<h2 id="介绍">3 介绍</h2>
<p><strong>主要贡献</strong>：<br />
*
提出音频编码器SoundStream，由编码、解码、量化器组成；通过重建和对抗损失训练模型，实现高品质音频生成。<br />
* 提出新的残差量化器，平衡速率/失真/复杂度；提出quantizer
dropout，使单个模型能处理不同比特率。<br />
*
对于采用梅尔图谱特征的解决方案，编码器带来了非常显著的编码效率提升。<br />
*
主观评测中证明，其输出音质高于之前模型，其3kbps的效果在主观评估中优于12kbps的Opus和9.6kbps的EVS。<br />
* 模型可在低延迟下运行，部署在智能手机上时，可在单个 CPU
线程上实时运行。<br />
* 提出了一种 SoundStream
编解码器的变体，可以联合音频压缩和增强，而不引入额外的延迟。</p>
<h2 id="方法">4 方法</h2>
<p><img
src="/attachments_2023/Pasted%20image%2020230502083544.png" /><br />
模型由三部分组成：<br />
* 编码器：卷积Encoder将采样率为fs的输入音频x转换为嵌入序列。<br />
*
残差向量量化（RVQ）：将嵌入通过codebooks，压缩成少量字节（目标位数）的表示，生成量化嵌入。<br />
* 解码器：从量化的嵌入中产生有损重建x^。<br />
其训练过程中还用了一个<strong>判别器Discrminator</strong>，它结合了<strong>对抗和重建损失</strong>，并使用可选的条件输入，用于指示是否从音频中去除<strong>背景噪声</strong>（Denosing）。</p>
<p>部署模型时，Transmiter的编码器和量化器将压缩，由Receiver解码音频信号。</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230502090255.png" /></p>
<h3 id="编码器结构">4.1 编码器结构</h3>
<p>其输出维度是SxD，D是Embedding的维度，S = T
/M，其中T是时间M是不同层（跨度）的输出如图中的：M = 2 · 4 · 5 · 8 =
320；如图每个Encoder由多个EncoderBlock组成，而EncoderBlock又由ResidualUnit组成。</p>
<h3 id="解码器结构">4.2 解码器结构</h3>
<p>解码器类似于编码器的逆过程，把降采样变成了升采样。</p>
<h3 id="残差向量量化">4.3 残差向量量化</h3>
<p>量化器的目标是压缩编码器产生的嵌入，转换到指定的字节长度。它学习一个
N 个矢量的码本来编码 enc(x) 的每个 D 维帧。然后将编码后的音频 S×D
映射到形状为 S × N 的onehot向量序列。</p>
<h3 id="判别器结构">4.4 判别器结构</h3>
<p>定义了两个不同的鉴别器：<br />
* 基于<strong>波型</strong>的鉴别器，它接收单个波形作为输入；<br />
* 基于 <strong>STFT</strong>
（快速傅里叶变换）的鉴别器，它接收输入波形的复值 STFT
作为输入，以实部和虚部表示。<br />
两个鉴别器都是完全卷积的，因此输出中的逻辑数与输入音频的长度成正比。</p>
<h3 id="训练目标">4.5 训练目标</h3>
<p><span class="math display">\[g(x) = dec(Q(enc(x))\]</span><br />
输入音频是x，最终输出音频x^=g(x)。保证生成的保真度和质量。<br />
鉴别器用于判断语音为<strong>原始语音还是生成语音</strong>：<br />
<img
src="/attachments_2023/Pasted%20image%2020230502093553.png" /><br />
生成器的对抗损失是：<br />
<img src="/attachments_2023/Pasted%20image%2020230502093608.png" /></p>
<p>为了提高信号保真度，还采用了两个额外的损失：<strong>特征损失
Lfeat</strong>
，在鉴别器定义的特征空间中计算；<strong>多尺度光谱重建损失
Lrec</strong>：<br />
<img
src="/attachments_2023/Pasted%20image%2020230502093746.png" /><br />
其中L是模型内部的层数，用于对比每一层的原始数据与生成数据的差别，计算其平均绝对误差。</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230502093759.png" /><br />
这里的S(x)用于计算梅尔倒谱。</p>
<p><strong>从损失函数中可以看到，除了深度学习对抗学习的方法，这里还引入了描述音频的梅尔倒谱，傅里利变换提取特征的方法，用于衡量生成音频与原始音频的差异</strong>。</p>
<p>最终的误差结合了上述三种误差：<br />
<img src="/attachments_2023/Pasted%20image%2020230502093820.png" /></p>
<h3 id="结合压缩和增强">4.6 结合压缩和增强</h3>
<p>SoundStream
设计为压缩和增强可以由同一模型联合进行，而不会增加整体延迟。<br />
提供代表两种模式（去噪启用或禁用）的调节信号，使模型可同时支持生成带背景声的音频和去噪的音频。具体方法是引入了特征线性调制
(FiLM) 层。</p>
]]></content>
      <tags>
        <tag>语音</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_音频生成_AudioLM</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/1_%E8%AF%AD%E9%9F%B3/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E9%9F%B3%E9%A2%91%E7%94%9F%E6%88%90_AudioLM/</url>
    <content><![CDATA[<p>name_ch: AudioLM：一种音频生成的语言建模方法<br />
name_en: AudioLM：a Language Modeling Approach to Audio Generation<br />
date_publish: 2022-09-07<br />
paper_addr: http://arxiv.org/abs/2209.03143</p>
<h2 id="读后感">1 读后感</h2>
<p>主要解决生成语音的两个问题：<strong>一致性和高质量</strong>。</p>
<h2 id="摘要">2 摘要</h2>
<p>这是一个利用长期一致性生成高质量音频的框架，它先将音频输入转成一系列离散的token，然后将生成音频作为<strong>表示空间的语言建模</strong>。提出了一种混合的分词方案来平衡<strong>重建质量</strong>和<strong>长依赖</strong>的结构。</p>
<p>使用<strong>Mask方法捕获长距离的关系</strong>，最终使用离散编码生成高品质的合成效果。它可以通过简短的提示，来生成自然连贯延续语音。利用大量无监督数据训练，在<strong>没有任何文字标注或注释的情况下</strong>，AudioLM
会生成<strong>句法和语义上合理的语音延续</strong>，同时还保持说话人身份和不可见的说话人的韵律。另外，还可以生成钢琴音乐。</p>
<h2 id="介绍">3 介绍</h2>
<p>在数据都是无监督的情况下，基于Transformer架构。具体使用的技术包括：对抗性神经音频压缩，自监督表示学习，语言建模。学习不同尺度的相互作用，保证语音的一致性。</p>
<p><strong>贡献</strong><br />
*
提出AudioLM框架，<strong>分层方式结合语义和声学标记</strong>，以实现生成长期一致性和高质量的音频。<br />
*
通过与w2v-BERT以及SoundStream的对比，证明了模型的可辨别性和重建质量优势的互补性。<br />
*
模型可以<strong>不依赖文本标注</strong>，生成语音，句法和语义。只需要3s语音作为提示，即可生成训练期间未见过的语音，并保持说话人的声音，韵律，录音条件（混响、噪音）。<br />
*
除合成人声外，还可以合成音乐声，其旋律、和声、音调和节奏都与提示一致。<br />
*
为防御生成语音带来的潜在风险，还提出了一个分类器，用于识别合成音频和真实音频。</p>
<h2 id="模型">4 模型</h2>
<p><img
src="/attachments_2023/Pasted%20image%2020230504170205.png" /></p>
<p>声学token由 SoundStream处理，语义token由 w2v-BERT 的中间层产生。</p>
<h3 id="组件">4.1 组件</h3>
<ul>
<li>将输入音频x映射到离散的词表y：y=end(x)。<br />
</li>
<li>使用仅有decoder的Transformer模型，操作y，用时间t-1的预测t对应的词（预测阶段使用自回归）。<br />
</li>
<li>解码模型 ，将预测出的y^映射回音频格式。 x<sup>=dec(y</sup>)</li>
</ul>
<h3 id="权衡离散音频表示">4.2 权衡离散音频表示</h3>
<p>使用<strong>尽量少的数据</strong>同时需要保证生成的音质，这涉及<strong>比特率的下限和序列长度</strong>。这里引入了<strong>语义token和声学token</strong>。如图-1所示。它们的产生被<strong>解耦</strong>；语义token需要时序依赖，声学token需要保证高音质，且使用语义作为条件。</p>
<p>使用 <a
href="/1_Note/2_算法/1_语音/论文阅读_音频压缩_SoundStream">SoundStream</a>
计算声学token，它使用了RQV（残差向量量化）技术将嵌入降维和离散化，并映射到码表。</p>
<p>使用 <a
href="/1_Note/2_算法/2_大模型/论文阅读_音频表示_w2v-BERT">w2v-BERT</a>
计算语义标记。该模型可以自主学习音频表示，将输入的音频波形映射到一个富有语言特征的向量空间。通过使用两个自监督目标：掩码语言建模（MLM）损失和对比损失训练模型实现。选择w2v-BERT模型的MLM模块中的一个中间层并计算该层的嵌入，<strong>可以提取出语义标记。将这些标记进行聚类，并使用聚类中心索引作为语义标记</strong>。</p>
<p>实验证明，将二项解耦效果更好。</p>
<h3 id="语义和声学标记的分层建模">4.3 语义和声学标记的分层建模</h3>
<p>先使用模型产生语义，然后再语义条件下生成高质量音频，有两个好处：<br />
* <strong>语义结果独立于音频结果</strong>。<br />
* 减少了每个阶段的标记序列，训练和推理效率更高。</p>
<p>具体实现如图-2所示，包含三个场景：<br />
<img
src="/attachments_2023/Pasted%20image%2020230504182454.png" /><br />
* 长期结构一致性的语义建模：利用上文，使用自回归方法预测语义z。<br />
*
以语义标记为条件的粗略声学建模：利用上文和语义，预测粗糙声的声学标记y。<br />
*
精细声学建模：用粗糙声学标记y以及上文生成精细声学信息，生成高质量标记。<br />
SoundStream 嵌入的采样率是 w2v-BERT
嵌入的两倍。另外拆分两的场景的原因是可以限制序列长度。</p>
<h3 id="预测">4.4 预测</h3>
<p>训练后，可以使用 AudioLM 生成音频，测试了以下三种情况：</p>
<h4 id="无条件生成">4.4.1 无条件生成</h4>
<p>无条件地对所有语义标记 ^z
进行采样，然后将其用作声学建模的条件。此实验证明了：模型可生成多种多样、句法和语义一致的语言内容，验证了语义与声学的无关性。</p>
<h4 id="声学生成">4.4.2 声学生成</h4>
<p>使用从测试集 x 中提取的真实语义标记 z
作为条件来生成声学标记。生成的音频序列在说话人身份方面有所不同，但语义内容与
x 的真实内容匹配。这表明语义标记捕获了语义内容。</p>
<h4 id="生成语音延续">4.4.3 生成语音延续</h4>
<p>从短提示 x 生成延续。首先将提示映射到相应的语义标记 z
和粗糙的声学标记
y。第一阶段生成语义标记的延续；第二阶段，将生成的语义与提示粗声学标记y连接起来，并将其作为条件提供给粗声学模型；在第三阶段，用精细的声学模型处理粗略的声学标记；最后，将提示和采样的声学标记都提供给
SoundStream 解码器以重建波形 x^。</p>
]]></content>
      <tags>
        <tag>语音</tag>
      </tags>
  </entry>
  <entry>
    <title>Survey on Neural Speech Syntheis</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/1_%E8%AF%AD%E9%9F%B3/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<p>#论文阅读 #语音</p>
<h2 id="基本信息">基本信息</h2>
<p>题目： Survey on Neural Speech Syntheis<br />
论文地址：https://arxiv.org/abs/2106.15561<br />
上传时间：2021年1月<br />
全文翻译：<a
href="https://blog.csdn.net/weixin_42721167/article/details/118684294">论文学习：A
Survey on Neural Speech Synthesis</a></p>
<h2 id="阅读体会">阅读体会</h2>
<p>比较全面介绍用<strong>深度学习</strong>实现<strong>语音合成</strong>的<strong>综述性</strong>论文。论文整体63页，其中正文37页，参考TTS相关论文400多篇。本文并不打算对论文逐句翻译，只列出重点，作为个人阅读笔记，同时加入笔者的一些注释。</p>
<h2 id="摘要">摘要</h2>
<p>近年来基于神经网络的深度学习算法大大提升了语音合成的质量，这篇文章集学术研究和工业应用于一体，是一篇综述性的文档，它包含语音合成的几个重要组成部分：<strong>文本分析、声学模型和声码器</strong>；涉及热门主题，比如：快速TTS，使用更少资源训练等等；还总结了TTS相关资料（工具和数据），最后讨论了TTS未来的发展方向。</p>
<h2 id="介绍">1. 介绍</h2>
<p>TTS主要指的是把文本转换成语音输出，它是一个由来已久的课题，涉及：<strong>语言学、声学、数据信号处理、机器学习</strong>等领域。这几年深度学习使TTS效果有了显著提升，
这篇论文是对深度学习TTS的综述。</p>
<h3 id="tts-历史">1.1 TTS 历史</h3>
<p>（从12世纪开始……此处省略）早期的计算机语音合成包括：频谱参数合成、音素合成、连接合成等方法；之后基于统计的机器学习算法，来预测<strong>频谱、基频、长度</strong>等合成参数；从<strong>2010年之后，基于神经网络的语音合成占据主导地位</strong>，实现了更好的合成效果。</p>
<ul>
<li><p>频谱参数合成<br />
算法模拟嘴唇、舌头、声门和声道的动作产生语音。理论上，它模拟了人类发音方法，是最有效的合成法，而实际上很难采集各个参数的数据，因此该方法效果往往比后面几种方法效果差（笔者注：发音像“机器人”一样的“金属音”）。</p></li>
<li><p>共振峰合成<br />
基于一系列规则控制录波器模型产生语音，规则用于模拟共振峰及其谐波的特征，它由合成模型和声学模型组成，通过一系列参数控制，如基频、音色、噪音等。它合成出的音质较高，占用资源较低，使用于嵌入式系统，且不依赖大量的语料库，但相对来说合成效果不够自然，这是由于很难针对自然度描述规则。</p></li>
<li><p>基于连接的合成<br />
基于连接的方法依赖存储在数据中大量的语音片断，它包括从整句到音节的播音员录音，在合成过程中，算法搜索最值语音片断，通过连接这些片断产生合成语音，它产生的语音具有较高的读性，更接近播音员的音色，但需要录制大时音频，且在情绪、自然度、韵律、流畅度方面较差。</p></li>
<li><p>基于统计的合成<br />
基于统计的合成简称SPSS（statistical parametric speech
synthesis），与基于连接合成不同的是，它生成声数参数，然后通过利过算法利用这些参数复原语音，它通常由文本分析、声学模型（参数预测）、声码器三部分组成，如图1所示（三部分后面详述）。该类模型的优点是：合成效果更自然、灵活性更高（可调节参数）；较低的资源占用。它的缺点的：合成的声音可能带有噪音，听起来有些像机器人，而非自然的人声。</p></li>
</ul>
<p><img src="None" /></p>
<ul>
<li>基于神经网络的合成<br />
随着神经网络技术发展，神经网络被引入了SPSS，作为其中的声学模型替代HMM统计模型预测参数，后来又发展出了直接用音素生成音频的模型，WaveNet被视为首例神经网络TTS模型，后来又发现出了end-to-end模型，将文字直接转换成音频。相对于之前的模型，它在自然度和智能性都有更高水平，并且更少依赖人工预处理和特征工程
。</li>
</ul>
<h3 id="文章组织方式">1.2 文章组织方式</h3>
<p><img src="/attachments_2022/Pasted%20image%2020211202114451.png"
alt="Pasted%20image%2020211202114451.png" /><br />
论文主要包含两大主题：TTS的主要组成、TTS高级主题。</p>
<ul>
<li><p>第一部分简单介绍</p></li>
<li><p>第二部分介绍了TTS主组由上图的三部分组成：文本分析（Text
Analysis）模块将文本序列转换为语言特征，声学模型（Acoustic
Model）从语言特征生成声学特征，声码器（Vocoder）从声学特征合成波形。及其模型的实现。</p></li>
<li><p>第三部分介绍一些前沿问题，如：提升模型速度，减少资源占用，用少量数据更训练效果更好的模型，提升鲁邦性解决丢音、重复等问题，加强情感表达，通过不量训练模拟某人语音等。</p></li>
<li><p>第四部分列出了开源的代码和语料库资源。</p></li>
<li><p>第五部分总结展望。</p></li>
</ul>
<h2 id="主要组成部分">2. 主要组成部分</h2>
<p>主要介绍上图中三部分的神经网络实现，</p>
<h3 id="主要分类">2.1 主要分类</h3>
<p>一般将语言合成分成文本分析、声学模型、声码器三部分，以及end-to-end模型。文本分析把文本转换成语言学特征，声学模型把语言学特征转换成声学特征，声码器将声学特征转换成音频。而end-to-end模型直接将文本转换成音频。也可将其中的几个步骤放在一个模型中，如图
所示：</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020211204145259.png"
alt="Pasted%20image%2020211204145259.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020211204145259.png</figcaption>
</figure>
<h3 id="文本分析">2.2 文本分析</h3>
<p>文本分析将文本转换成包含语音和韵律的特征。在统计参数合成中，文本分析用于提取语言特征向量序列，并且包含诸如文本规范、短语切分、标注成份，韵律预测，字符到音素转换等功能。尽管end-to-end模型，大幅简化了文本分析功能
，但一般情况下还是需要做一些规范化和字符到音素映射的工具。文本分析一般包含以下步骤：</p>
<ul>
<li>文本规范化：将"1989", "Jan
24"转换成对应文本，规范化一般基于规则；也有一些神经网络模型利用序列处理解决这一问题；之前有人研究结合规则和神经网络来提升效果。<br />
</li>
<li>短语切分：像中文需要将字分成词再进行下一步处理。<br />
</li>
<li>标注成分：标句子成份，如：名词、动词……<br />
</li>
<li>韵律预测：韵律包含节奏、重音和语调，它们与时长、音量和音高相对应，这些因素在言语交际中起着重要作用，对于不同语言也有不同处理，对于中文，韵律词、韵律短语和语调短语构成了韵律树三层结构，利用RNN,
CRF, Self-Attention等方法来解决该问题。<br />
</li>
<li>字符到音素转换：将字符转换成音标（拼音），主要通过查表方法实现，对于英文这种字母单音，字典不能涵盖所有单词，因此需要模型或规则辅助转换，对于中文，除字典以外，也需要根据上下文处理多音字，这也需要用模型消歧。</li>
</ul>
<p>综上，文本分析需要从音素、音节、词、短语和句子等不同层面来构建语言特征。文本分析与神经网络有很多结合，比如用一个神经网络实现文本分析的任务。韵律对语音的自然度有很大影响，在神经网络模型简化模型的基础上，也将音高、时长、断句、呼吸、停顿等因素加入了编码器的上层。另外，还有一些方法来支持韵律特征：(1)
从语音中学习韵律规则; (2) 利用无监督数据学习韵律生成预测训练模型 (3)
使用图网络来结合语法信息。</p>
<h3 id="声学模型">2.3 声学模型</h3>
<p>声学模型将语言学特征转换成声学特征，具体实包括在SPSS中使用HMM或DNN实现的静态参数模型；基于
encoder-attention-decoder框架的序列模型；以及最新的用于并行生成器的前馈网络
。可以将声学模型分为两种：SPSS中的声学模型，根据语言特征预测MGC、BAP和F0等声学特征；以及基于神经的end-to-end模型，其根据音素或字符来预测声学特征。</p>
<h4 id="spss中的声学模型">2.3.1 SPSS中的声学模型</h4>
<p>这类模型的研发由以下几个因素驱动：1)
可采用更多的上下文信息作为输入；2) 可以考虑到输出帧之间的相关性；3)
处理语言特征到声学特征的映射是一对多的情况。</p>
<ul>
<li><p>HMM隐马尔模型可用于生成语音参数，与之前的拼接方法相对，HMM在改变说话人、情感、风格等方面比较灵活，它的主要缺点是音质较少，原因是：1)声学模型精度不高，过于平滑缺乏细节；2)
HMM模型能力的不足使声音编码技术受限。</p></li>
<li><p>DNN深度神经网络模型提升的合成的质量；LSTM类模型又考虑了远距离上下文的影响；后续还有使用CBHG，
GAN，基于Attention的循环神经网络来进一步改善声学模型的品质。</p></li>
</ul>
<h4 id="end-to-end的声数模型">2.3.2 End-to-end的声数模型</h4>
<p>end-to-end的声学模型对于传统的SPSS模型，有以下有事：1)
不需要对齐语言特征和声学特征，简化了预处理；2)为了提高性能，输入的语言特征被简化为字符或音素序列，输出声学特征从低维的MGC向高维的Mel谱图甚至更高维线性谱图转变。</p>
<ul>
<li><p>基于RNN的模型（Tracotron系列）<br />
Tacotron利用注意力框架，输入作为字符线性谱输出，并使用Griffin-Lim算法来生成波形。Tacotron2使用附加的WaveNet模型来生成梅尔谱图并生成波形。Tacotron
2比以往的拼接TTS、参数TTS、神经TTS的语音质量有了很大的提高。<br />
后来有很多工作从不同方面对Tacotron进行了改进：1)采用参考编码器和风格符号来增强语音合成的表现力，2)去掉注意机制，用时间长预测实现自回归，3)将自回归生成改为非自回归，4)建立端到端的文本生成波形模型。</p></li>
<li><p>基于CNN的模型（DeepVoice系列）<br />
DeepVoice用卷积神经网络优化了SPSS系统。通过神经网络获取语言特征后，基于WaveNet的声码器生成波形。DeepVoice
2通过改进的网络结构和支持多说话人来增强DeepVoice。它还采用了Tacotron+WaveNet的pipeline，首用Taco
tron生成线谱图，然后使用WaveNet生成波形。DeepVoice
3利用全卷积网络结构进行语音合成，它可以从字符生成梅尔谱图，并可扩展到多说话人数据集。并使用了更紧凑的序列到序列模型，跳过了生成语言特征的步骤。<br />
之后，ParanNet是完全基于卷积的非自回归模型，可以加快梅尔谱图的生成速度，并获得较好的语音质量。DCTTS与Tacotron共享类似的pipeline，并利用基于完全卷积的attention网络从字符序列生成梅尔谱图。它们使用超分辨率网络获得线性谱图，并使用Griffin-Lim合成波形。</p></li>
<li><p>基于Transformer的模型（FastSpeech系列）<br />
TransformerTTS利用attention框架从音素产生梅尔图谱。之前基于RNN的attention网络主要存在两个问题：1)
编码器和解码器不能并行训练，编码器不能并行预测，影响了使用效率；2)
RNN对于长序列的依赖关系建模效果较差。TransformerTTS采用了Transformer的基本模型结构，并吸收了Tacotron2中解码器、前网/后网和预测停止符号的设计。它的音质与Taco
tron2相当，但训练时间更短。Transformer由于并行计算而并不很稳定，又出现了MultiSpeech通过编码器归一化、解码器瓶颈和对角注意约束等方式，提高了注意机制的健壮性，而RobuTrans利用持续时间预测来增强自回归的健壮性。<br />
前面所述模型都使用自回归的生成器有以下问题：1) 预测速度慢，2)
健壮性问题：由于文本与梅尔谱图之间的对齐不准确造成的跳词、重复问题。FastSpeech提取了以下解决办法：1)
用前馈的Transformer网络提升预测速度，2)
移除了注意力机制，以避免重复和跳词，以解决健壮性问题。解决方案是使用长度调节器来解决音素和梅尔语谱图序列之间的长度不匹配（具体方法在3.4.2节中介绍），便于并行生成。FastSpeech的
音质与之前的自回归模型差不多。<br />
FastSpeech2主要从两个方面提升了FastSpeech：1)
使用真实的梅尔谱图作为训练目标，以替代自回归教师模型中提取出的梅尔谱图作为训练目标。这简化了流程，也避免了蒸馏导致的信息丢失。2)
提供更多的信息，例如音调、时长和能量作为解码器输入，这简化了文本到语音的一对多映射问题。FastSpeech
2获得了更好的音质，并保持了FastSpeech快速、健壮且可控的语音合成优势。FastPitch
通过使用音调信息作为解码器输入来改进FastSpeech。</p></li>
<li><p>其它声学模型<br />
除了上述模型，还有一些基于 Flow, GAN, VAE,
Diffusion的声学模型，具体见下表（最下面）<br />
<img src="/attachments_2022/Pasted%20image%2020211205111232.png"
alt="Pasted%20image%2020211205111232.png" /></p></li>
</ul>
<h3 id="声码器">2.4 声码器</h3>
<p>声码器可分为两类，一类用于组成SPSS；一类是基于神经网络的声码器。第一类一般包含两部分：声码分析和声码合成，声码分析从声音中提取梅尔倒谱、非周期频谱和基频等声学特征，合成阶段将声学特征合成为音频。</p>
<p>早期的神经网络直接把语言特征作为输入产生音频，后来把梅尔倒谱作为输入。生成较长的音频时，自回归需要很长时间计算，引入Flow、GAN、VAE、DDPM模型又改进了这些问题。</p>
<ul>
<li>自回归声码器<br />
自回归模型是统计上一种处理时间序列的方法，即使用x1至xt-1来预测xt，并假设它们为x在时序上呈线性关系，由于它使用x预测自已，所以叫自回归。<br />
WaveNet
使用扩展卷积实现自回归来生成音频，与传统的分为分析和合成两步的SPSS不同，WaveNet在声码器部分使用End-to-end模型，因为不需要额外的先验知识，WaveNet的输入是语音学特征，输出是线性谱或梅尔图谱。它虽达到了较好的音质，但用时较长。后续模型对此进行了改进，如SampleRNN使用多层RNN网络实现无条件生成音频，进而
Char2Wav实现在声学特征的基本上有条件生成音频。WaveRNN使用RNN、双Softmax层、权重修剪和缩放等技术减少了计算量。LPC-NET将传统的数字信号处理引入神经网络，使用线性预测系数计算下一个波形点，以及用轻量级RNN计算残差。LPCNet根据BFCC特征产生语音波形……<br />
</li>
<li>基于流的声码器<br />
基于流的模型是一种生成模型。生成模型是给定训练数据，要生成与该数据分布相同的新样本，即用一个概率模型来拟合给定的训练样本。基于流的神经网络分为以下两种类型：
<ul>
<li>自回归变换<br />
如逆自回归流IAF可以看作是自回归流(AF)的对偶公式。AF的训练是平行的，而生成采样是顺序的。相反，IAF中的生成采样是并行的，而似然估计的推理是顺序的。并行WaveNet利用概率密度蒸馏将IAF的有效采样与AR建模的有效训练结合起来，但它依赖于复杂的师生训练，并且计算量大。<br />
</li>
<li>二部变换<br />
保证变换是可逆的，二部变换利用仿射耦合层，确保可以从输入可以计算输出，输出也能计算输入。它可达到高音质和更快的速度。<br />
</li>
<li>上述两种变换各有优缺点<br />
自回归变换对数据分布x和标准概率分布z之间的相关性建模，因而具有更好的表现力，但相对复杂；二部变换相对简单，但需要大量参数；综合二项，WaveFlow提供了基于似然的模型的统一视图来实现并行预测。<br />
</li>
</ul></li>
<li>基于GAN的声码器<br />
生成对抗网络GAN常用作生成器，如生成文本、生成声音、生成图片等，它一般包括生成器和鉴别器两部分。一般名字里带GAN的TTS都使用了生成对对抗网络。
<ul>
<li><p>生成器<br />
大多数GAN的声码器使用扩展卷积来增加接受场来模拟波形序列中的长相关性，并用上采样条件信息匹配波形序列的长度。如：选择对条件信息进行一次上采样，然后进行膨胀卷积以保证模型容量。上采样过早地增加了序列长度，导致较大的计算量。因此，一些编码器选择迭代上采样并进行扩展卷积，以避免较低层的过长序列。vocGan提出了一种多尺度生成器，输出不同尺度的波形序列。HiFi-GaN通过多感受场融合模块并行处理不同长度的不同图案，在合成效率和样品质量之间进行折衷。</p></li>
<li><p>鉴别器<br />
鉴别器。鉴别器的目的是捕捉波形特征，从而引导生成器更好地生成音频。1)
随机窗口鉴别器（InGaN-TTS）使用多个鉴别器来鉴别波形的不同随机窗口，它以不同的互补方式评估音频，简化全音频的真假判断；2)
多尺度鉴别器（Melgan）使用多个鉴别器来判断不同尺度(音频下采样)的音频，每个尺度上的鉴别器可以聚焦于不同频段的特征；3)
多周期鉴别器（HiFi-GaN）利用多个鉴别器鉴别等间距样本，通过观察输入信号在不同周期的不同部分，捕捉到不同的隐含结构。4)
分级鉴别器（vocGAN）对产生的波形从粗粒度到细粒度进行不同分辨率的判别，引导生成器学习低频和高频声学特征与波形的映射关系。</p></li>
<li><p>损失函数<br />
新模型也对损失函数对行了改进，用于提高对抗训练的稳定性和效率，并改善感知音频质量。</p></li>
</ul></li>
<li>基于扩散的声码器<br />
DDPM去噪扩散概率模型的基本思想是用扩散过程和逆过程来表征数据与潜在分布之间的映射关系：在扩散过程中，波形数据样本逐渐加入一些随机噪声，最后变成高斯噪声；在反向过程中，随机高斯噪声逐步去噪为波形数据样本。基于扩散的声码器可以产生非常高音质的语音，但迭代过程时间长，推理速度慢。很多模型都致力于解决这一问题。<br />
</li>
<li>其它声码器<br />
还有其它一些工作，如：在保持语音生成可控的同时实现高语音质量。通过综合实验对几种常见声码器进行评估，研究声码器的鲁棒性等。<br />
</li>
<li>讨论<br />
总结如下：
<ul>
<li>基于自回归(AR)相比于其它模型在数学上更简单 。<br />
</li>
<li>除AR之外，所有的生成模型都可以支持并行语音生成。<br />
</li>
<li>除AR之外，所有的生成模型都能在一定程度上支持潜在的调控。<br />
</li>
<li>基于GAN的模型不能估计数据样本的似然。</li>
</ul></li>
</ul>
<h3 id="走向完全的-end-to-end-模型">2.5 走向完全的 End-to-end 模型</h3>
<p>End-to-end端到端的模型输入是字符或音素，输出是音频，它的优点是：需要较人的人工标注和特征提取；2)
避免了流式模型向后传递错误的问题；3) 减小了训练，开发和部署的成本。</p>
<p>它面临的最大挑战是由于模态不同，输入字符和输出音频之间长度无法匹配。比如20个单词，对应100个音素，生成80k长度的音频序列，由于内存限制，难于全部训练，切块训练又难以取得上下文的表征。</p>
<p>为解决这一问题，神经网络TTS发展经历了一个从SPSS走向End-to-end的渐进发展过程，如下图
所示。1)简化文本分析模块和语言功能，只保留文本归一化和字音素转换，将字符转换成音素，或者直接将字符作为输入去掉整个文本分析模块。2)简化声学特征，将复杂的声学特征简化为Mel谱图。3)将两个或三个模块替换为单个端到端模型。<br />
<img src="/attachments_2022/Pasted%20image%2020211209094239.png"
alt="Pasted%20image%2020211209094239.png" /><br />
* 场景0：最基本的SPSS模型结构，使用了三个基本模块。<br />
*
场景1：将文本分析和声学模型合并成一个端到端的模型，从音素生成声学模型生，转给声码器产生音频。<br />
*
场景2：WaveNet第一次从语言学特征直接生成音频输出，可将它看作合并了声学模型和声码器，但它仍需要文本分析模型来生成语言学特征。<br />
*
场景3：Tacotron提出了简化语言特征和声学特征的方案，使用编码器-注意力模型-解码器模型直接从字符/音素预测线性谱图或梅尔图谱。<br />
*
场景4：输入为字符或音素，输出为音频的端到端模型。Char2Wav从字符生成声学特征，SampleRNN生成波形，结合这两个模型可用于直接语音合成。类似地，ClariNet联合直接产生波形的自回归声学模型和非自回归声码器；FastSpeech
2s直接使用并行结构的文本生成语音，可以极大地提高预测速度；EATS的并行模型直接从字符/音素生成波形，它利用持续时间内插和软动态时间回绕损耗进行端到端对齐学习。Wave-Taco
tron在Taco tron上构建了一个基于流的解码器，直接产生波形。</p>
<h3 id="其它分类方法">2.6 其它分类方法</h3>
<p>除了以上的分类方法，还可以把模型分为：1) 自回归模型和非自回归模型；2)
根据生成模型的方式，可分为：
普通生成模型，流模型，GAN，VAE以及diffusion传播模型；3)
按网络结构可分为CNN，RNN，自注意力模型和混合模型。</p>
<h2 id="tts高级主题">3 TTS高级主题</h2>
<h3 id="背景和分类">3.1 背景和分类</h3>
<p>本章的内容主要讨论一些前沿研究和应用。3.2部分将讨论对自回归模型的加速以及缩减模型大小；3.3讨论如何提升合成效果的自然度和易懂，例如：在训练数据较少的情况下，如何有效地训练模型；3.4讨论加强模型的鲁棒性，如改进丢词重复等问题，以提升模型的易懂性。3.5讨论如何通过控制模型的风格和韵律以提升模型的表现力；3.6讨论使用少量数据训练，适配参数，来训练转换目标说话人，以实现高质量的语音适配的应用。</p>
<h3 id="tts加速">3.2 TTS加速</h3>
<p>TTS服务经常部署在云端或者在嵌入式系统中支行，需要较快的合成速度。早期的模型对于长文本合成速度较慢，为解决这一问题，出现的技术方案包含：1)
使用非自回归模型产生梅尔图谱以及并行化生成音频；2)
轻量和有效的模型结构；3) 利用领域知识加快语音合成，具体方法如下：</p>
<p><strong>并行生成器</strong><br />
各个模型的时间复杂度如下表所示<br />
<img src="/attachments_2022/Pasted%20image%2020211213095348.png"
alt="Pasted%20image%2020211213095348.png" /></p>
<p><strong>模型减重</strong><br />
非自回归模型虽然加快了训练和预测的速度，但并没有简化模型参数和训练量，对于嵌入设备模型减重也非常重要，与此相关的工作主要集中在：修剪、量化、知识提炼和神经结构搜索。</p>
<p><strong>使用领域知识加速</strong><br />
加入领域知识可加速预测，具体方法如：<br />
线性预测：将数字信号处理与神经网络相结合，采用线性预测系数计算下一个波形，采用轻量级模型预测残差值，加快了自回归波形生成的推理速度。<br />
多频带/子频带建模：把音频拆成多个子频带，用于加快声码器的速度。<br />
除此以外，还有利用充分聚束和比特聚束减少计算复杂度；流合成即不等待全句只对现在token合成加快预测速度；用简单结构模拟快速傅里叶变换；用帧分割和交叉递减，并行合成波形的某些部分，然后将合成的波形串联在一起，以确保低端设备上的快速合成等方法。</p>
<h3 id="使用少量资源训练模型">3.3 使用少量资源训练模型</h3>
<p>一般情况下，训练模型都需要大量高品质的文本和音频数据，但世界上的很多语言没有足量数据，所以商业软件一般只支持十几种常用语言。对于小语种合成商业产值不大，但很有社会意义。为实现这一目标，产生了以下技术。</p>
<p><strong>自监督训练</strong><br />
文本和音频对很难收集，但收集未配对的相对容易。自监督训练被用于提升语音的可懂度和语音的生成能力。比如使用预训练的BERT模型作为编码器，使用预训练的自回归梅尔图谱生成器作为解码器，建立语音转换任务联合训练，此外，可以将语音量化为离散的token序列，以与音素或字符序列相似。以此方式预训练TTS模型，然后在少数真正配对的文本和语音数据上微调该TTS模型。</p>
<p><strong>跨语言转换</strong><br />
由于人类的语音使用类似的发声器官，读音和语义结构，丰富的语言训练出的模型，可以映射到小语种模型中。由于音素略有差异，所以需要对Embedding层进行一些处理；采用国际音标(IPA)或字节表示法可以支持多语言的任意文本。此外，在进行跨语言迁移时也可以考虑到了语言的相似性。</p>
<p><strong>转换发音者</strong><br />
当某个说话人的语音数据有限时，可以利用来自其他说话人的数据来提高该说话人的合成质量。具本方法是通过语音转换将其他说话者的语音转换为该目标语音以增加训练数据，或者通过语音适配或语音克隆使针对其他语音训练的TTS模型适应该目标语音，此问题将在在3.6节进一步讨论。</p>
<p><strong>语音链反向转换</strong><br />
语音合成和语音识别是对偶的两组应用，可以利用它们之前的关系互相改善。</p>
<p><strong>利用低品质数据</strong><br />
在网络上存在一些低质量的文本音频对，从中可以挖掘并改进TTS模型质量，比如利用它们来降噪、去纠缠等。</p>
<h3 id="tts鲁棒性">3.4 TTS鲁棒性</h3>
<p>影响TTS鲁棒性的通常是声学模型中经常会出现跳词、重复、注意力崩溃等等问题。有以下两个原因：<br />
*
难以对齐梅尔图图谱和字符音素。有两种解决方法，一种是改善注意力模型；另一种是使用时长预测代替注意力模型。<br />
*
自回归生成中的偏差爆炸和误差传播。有两种解决方法，一种是改进自回归模型，另一种是用非自回归取代自回归模型。<br />
声码器不会面临上述问题，因为声学特征和波形已经按帧对齐。</p>
<h4 id="提升注意力机制">3.4.1 提升注意力机制</h4>
<p>自回归的声码器的问题常常是由于编码器-注意力-解码器结构中注意力对齐（文本和音频特征对齐）问题引起的，下面是核心问题：<br />
*
Local：一个字符可对应多个音频帧，而每帧只对应一个字符；可用于解决注意力崩溃问题问题。<br />
*
Monotonic（单调性）：字符有先后顺序，如果字符A在B前，则输出音频A也在B前，可用于解决重复问题。<br />
* Complete（完备性）：每个字符至少对应一帧，可用于解决丢音问题。</p>
<p><img src="/attachments_2022/Pasted%20image%2020211215100544.png"
alt="Pasted%20image%2020211215100544.png" /><br />
具体方案如下：<br />
* Content-based attention（基于内容的注意力）<br />
早期的注意模型是基于内容的，注意力的分布取决于编码器和解码器之间隐藏层的匹配度。Attention模型一开始用于解决翻译等问题，翻译中源和目标中的词可按含义来对义，但对于语音合成和语音识别问题的对齐则比较困难，需要注意上述的三个核心问题。<br />
* Location-based attention（基于位置的注意力）<br />
根据位置对齐文本和音频特征，使用它可以保证单调性。<br />
* Content/Location-based hybrid
attention（基于内容和位置的混合注意力）<br />
结合了上下文和位置对齐两种方法，使用前一个注意力对齐来计算当前注意力对齐，也用于解决单调性问题。<br />
* Monotonic attention（单高性注意力）<br />
在对齐时参考了位置单调增加的原理，从而解决了丢音和重复的问题，为保证完备性，He
et al.又提出了步进单调注意力，保证对齐注意力位置每次只前进一步
，从而保证不跳过任何一个单元。<br />
* Windowing or off-diagonal penalty（加窗和非对角线处罚）<br />
由于单调可知，输入和输出呈对角线关系，因此，提取了将注意力限定在子窗口中，从而降低了学习灵活性和难度；另外，通过构造掩码，使用损失函数惩罚的方式，鼓励注意力分布在对角线附近区域内（band），<br />
* Enhancing encoder-decoder connection（提升编解码器的连接）<br />
输出帧之间有很强的相关性，解码器常常更多的考虑前其之前帧的数据，从而忽略了编码器的输入。因此很多工作在编解码器之间建立更强的链接，从而改进注意力的对齐能力。比如：在每个时间步产生多帧预测；丢弃之前的信息，以减少对后面预测的影响；提高编解码之间位置的关联性；鼓励输出的梅尔图谱包含更多文本信息。<br />
* Positional attention（位置注意力）<br />
有一些非自回归模型，使用位置作为query，加入key,value的计算（详见attention模型）。</p>
<h4 id="用长度预测取代注意力">3.4.2 用长度预测取代注意力</h4>
<p>上述的注意力模型改进无法解决所有问题，一些人试图用预测各字符输出音频的长度来解决问题，以替代注意力模型，这有点像之前SPSS中的长度预测。一般有两种做法：第一种是使用扩展工具联合训练，给长度打标签；第二种是使用真实时长代入训练End-to-end模型，在预测时预测出长度。</p>
<ul>
<li><p>外部对齐<br />
引用外部工具实现对齐，主要包括以下几种：1)
从编解码注意力模型中获取持续时间标签；2)
基于语音识别的CTC对齐音素和梅尔图谱输出；3)
隐马尔可夫对齐基于蒙特利尔强制对齐提取时间长度。</p></li>
<li><p>内部对齐<br />
Align使用动态规划法通过多阶段训练学习文本和梅尔图谱之前的关系；JDI-T借鉴FastSpeech从自回归教师模型中提取时长，但不需要两阶段训练；Glow-TTS单调对齐搜索来提取持续时间；EATS利用插值和DTW优化端到端时间预测。</p></li>
<li><p>对End-to-end优化<br />
典型的时间预测方法用内部或外部的对齐工具提取时间用于训练；用预测的时长用于整个模型的预测。利用梅尔图谱的损失函数来优化模型。</p></li>
<li><p>End-to-end优化<br />
EATS使用内部模块预测时长，并借助时长插值和软DTW损失对时长进行端到端的优化。非注意模型Tacotron提出了半监督学习方法，如果没有持续时间标签可用，则预测的时长可以用于上采样。</p></li>
</ul>
<h4 id="提升自回归模型效果">3.4.3 提升自回归模型效果</h4>
<p>自回归模型常常遇到偏差爆炸误差传播问题，偏差爆炸是由于在训练过程中，使用上一步的输出作为下一步的输入，而预测时上一步的输出也是预测出来的。训练和预测的差异导致错误在预测时错误不断向后传播，偏差在短时间内很快积累起来。</p>
<p>目前研究了不同的方法来缓解上述问题。Guo等利用教授强迫来缓解实际数据和预测数据的不同分布的差异。刘等进行师生蒸馏方法，教师接受教师强迫模式的训练，学生之先前预测的值作为输入，优化以减小教师和学生模型之间隐藏状态的距离。生成的梅尔谱图序列的右侧通常比左侧差，因此利用从左到右和从右到左的生成来进行数据扩充和规范化；Vainer
and
Dušek提出了数据扩充的方法，将高斯噪声加入图谱来模拟预测误差，并通过随机替换几个帧来降低输入谱的质量，以鼓励模型依赖使用更远的帧生成。</p>
<h4 id="用非自回归替换自回归">3.4.4 用非自回归替换自回归</h4>
<p>非自回归模型可划分为两类：ParaNet和Flow-TTS
使用上文中提到的位置注意力（positional attention）对齐文本的语音;
FastSpeech和EATS
[69]使用时长预测解决文本和语音序列之间错位的问题。AR和Attention有以下组合：</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020211216080508.png"
alt="Pasted%20image%2020211216080508.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020211216080508.png</figcaption>
</figure>
<h3 id="tts表现力">3.5 TTS表现力</h3>
<p>语音的自然度很大程度上依赖表现力，与此相关的研究包括：内容、音色、韵律、风格、情感等方面的建模、解缠、控制和传递等。</p>
<p>语音表现力中一个关键问题是一对多映射，单一文本对应多个语音参数，如时长，音高，音量，风格，情感等。如果只使用L1损失函数且没有丰富的输入信息，将导致过于平滑的梅尔图谱预测，比如只对数据库里的单音素建模，将导致低音质和低表现力。因此，需要提供更多样的信息做为建模的输入。另外，使用更多多信息作为输入后，可实现：1)
通过控制参数控制合成效果；2) 转换语音风格；3)
为实现细力度的控制，需要分解内容、韵律、音色和噪音等各个因素。</p>
<h4 id="参数信息分类">3.5.1 参数信息分类</h4>
<ul>
<li><p>文本信息<br />
需要表达的内容，如文本或者音素，一些方法可以通过词嵌入或文本预训练的方式来提高合成质量和表现力。</p></li>
<li><p>发音人音色<br />
发音人相关特征，支持多发声者的TTS系统需要对声音人的特征建模。</p></li>
<li><p>韵律、风格和情感<br />
韵律、风格和情感是提升表现力的主要方法，包含了包含语调、重音和节奏以及如何说出文本。</p></li>
<li><p>录音设备和环境噪声<br />
设备和环境是语音的通道，它与上述三点不相关，但也影响了音质，这方面的研究围绕合成中的分解，控制，降噪。</p></li>
</ul>
<h4 id="参数信息建模">3.5.2 参数信息建模</h4>
<p>与表现力相关的参数包括：</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020211216083342.png"
alt="Pasted%20image%2020211216083342.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020211216083342.png</figcaption>
</figure>
<p><strong>信息类型</strong></p>
<p>信息类型可分为外显和内隐两种，外显型可以明确打标签；内隐型只能通过计算获取其参数。</p>
<p>对于外显型，我们可以直接使用它作为模型输入，获取它的渠道包含：1)
获取语言ID，声音者ID，韵律的标签数据，比如韵律数据的标注方法如ToBI，AutoBI，Tilt，SLAM等；2)
从音频中提取音高、能量，时长等。</p>
<p>除了外显型数据还包含一些更细粒度的参数，可通过模型从数据中提取，典型的建模方法包括：</p>
<ul>
<li>参考编码<br />
Kerry-Ryan等人将韵律定义为去除由于文本内容后语音信号中剩余的变化，音色、通道效果和模型韵律不需要编码器来标注。它从参考音频中提取韵律，作为解码器的输入。在训练过程中，使用真实参考音频，在推理过程中，使用另一参考音频来合成具有相似韵律的语音。Wang从参考音频中提取嵌入内容，并将其用作查询来参与(通过基于Q/K/V的注意力)风格标记库，并且将关注结果用作用于模型的韵律条件。从而增加TTS模型学习不同类型样式的能力和变化性，使数据集中不同数据样本之间的知识共享成为可能。风格符号库中的每个符号可以学习不同的韵律表征，例如不同的语速和情绪。在推理过程中，利用参照音和提取的韵律，简单地选择风格符号来合成语音。<br />
</li>
<li>变量自动编码<br />
张等人利用VAE对潜在空间中的更多信息进行建模，利用高斯先验作为正则化，实现对合成风格的表现力建模和控制。一些研究还利用VAE框架更好地对表达合成的更多信息进行建模。<br />
</li>
<li>对抗生成模型<br />
利用生成对抗模型对隐变量建模，学习更多信息，可优化一对多的映射问题，对抗预测过于平滑的问题，能够更好地模拟多模态分布。<br />
</li>
<li>文本预训练<br />
使用预测训练的模型利用词嵌入和参数提升模型的表现力。</li>
</ul>
<p><strong>信息粒度</strong><br />
从粗到细分成六个粒度等级：1) 语音和发音者等级；2)
段落等级（由短语和句子构成）；3)
短语等级，提取单个隐藏向量来表示该发音的音质/风格/韵律；4)
词/音节等别，它针对发音级别，但无法覆盖的细粒度风格/韵律信息；5)
字符/音素等级，包含持续时间、音高或韵律信息；6) 帧等级。</p>
<p>此外，还有使用多个不同粒度的层次结构建模，以提升表现力。Suni等人论证了韵律层次结构在口语中的内在存在。Kenter等人从框架和音素级别到音节级别预测韵律特征，并与单词和句子级别的特征串联。Hono等人利用多粒度的VAE来获得不同的时间分辨率潜变量，并从较粗级别的潜变量采样较细级别的潜在变量。Sun等人使用VAE对音素和单词级别的差异信息进行建模，并将它们组合在一起输入解码器。Chien和Lee对韵律预测进行了研究，提出了从词到音级的层次结构来改进韵律预测。</p>
<h4 id="分解控制和转换">3.5.3 分解、控制和转换</h4>
<ul>
<li><p>使用对抗训练分解<br />
当风格和韵律信息纠缠在一起时，需要通过训练将它们分离，以加强合成模型的表现力，以及控制这些参数。Ma等人利用对抗性、协作的方法，增强内容的解缠能力和可控性。Hu等人通过对抗训练利用VAE框架，将噪音从说话人信息中分离出来。钱等人使用三个瓶颈重构来解开节奏、音高、内容和音色。Zhang等人提出通过帧级噪声建模和对抗性训练来分离说话人的噪声。</p></li>
<li><p>使用循环一致性/反馈损失来控制风格</p></li>
</ul>
<p>当提供风格标签等信息作为输入时，TTS模型可合成具有相应风格的语音。为了增强TTS模型的可控性，一些工作提出使用周期一致性或反馈损失来鼓励合成语音在输入中包含差异信息。</p>
<ul>
<li>利用半监督学习提升可控性</li>
</ul>
<p>如果对音高、长度、能量、韵律、情感、发音人、噪音等属性都有标注，那到通过设置这些属性，很容易控制合成。但在没有这些标注，或只有部分标注的情况下，使用半监督学习方法，也可以实现分离这些特征。</p>
<ul>
<li>通过控制差异信息实现变换</li>
</ul>
<p>通过差异信息改变风格，如果有对差异的标注，对语音数据训练，从而根据标签在合成时转换风格。在没有标注的情况下，还能从训练中提取差异信息。像音高、长度、能量都可以从数据中提取，另外，还能提取一些不易描述的潜在信息。</p>
<h3 id="适配tts">3.6 适配TTS</h3>
<p>使用适配TTS技术，可以为任何发音人合成语音，常被用于配音、声音克隆、自定义声音，是非常热门的研究领域。包含之前统计参数合成、以及最近的一些语音克隆挑战比赛。通常源模型是支持多发音人的TTS模型，通过少量数据适配，训练出针对新发音人的模型。</p>
<p>通常将其分成通用适配（提升通用模型）和有效适配（），如下图所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220115143234.png"
alt="Pasted%20image%2020220115143234.png" /></p>
<h4 id="通用适配">3.6.1 通用适配</h4>
<p><strong>通用的源模型</strong><br />
目标是为了提升源模型。一般情况下在训练过程中，没有包含韵律、单色、录音环境的标注，因此训练出的模型容易对训练集过拟合，缺乏泛化能力。于是使用在训练时将必要的声学特征作为输入，将记忆力变为泛化力；以及使用多样性的数据训练的方法。</p>
<p><strong>交叉领域适配</strong><br />
实现了在不同语言之间转换，如使用英文发音者实现中文普通语的语音合成。AdaSpeech设计了对不同录设备、环境噪声、噪音、语速、音色等声学条件的建模方法。</p>
<h4 id="有效适配">3.6.2 有效适配</h4>
<p>一般情况下，更多的数据使用模型达到更好的语音效果，但也造成更大的花费。利用适参数，通过对整个模型或部分模型的精调（fine-tune），有效适配的目标是尽可能少的数据和参数达到较高的适配效果。基本分为以下四类：</p>
<ul>
<li><p>更少数据适配<br />
只使用少量文字语音数据精调模型，从几钟到几秒钟不等，甚至是小于二十个句子。</p></li>
<li><p>更小参数适配<br />
在需要适配多个发音者的情况，需要让语音占内存较小的情况下达到较高音质。例如AdaSpeech提出了对条件层归一化生成参数，只需要精调该层参数就可以达到较好的适配效果。</p></li>
<li><p>未转录的数据适配<br />
在很多场景之中，只有语音数据，比如在线会议，AdaSpeech2利用这些语音数据实现重建和潜在的对齐，Inoue等人提出使用ASR方式识别语音数据，然后使用转录的数据对进行语音适配。</p></li>
<li><p>zero-shot适配<br />
对没有目标发音人语音数据的情况下，利用参数来实现适配，这种方式在目标发音人和源数据发音人差异较大时效果不好。</p></li>
</ul>
<h2 id="资源">4. 资源</h2>
<p>此处总结了一些TTS资源，包含开源项目、教程、比赛和语料库。</p>
<h2 id="未来方向">5. 未来方向</h2>
<p><strong>高质量的语音合成</strong><br />
高质量的语音是语音合成的目标，它涉及清晰度、自然度、表现力、韵律、风络、情况、健壮性、可控等方面。</p>
<ul>
<li>能力更强的语音生成模型<br />
</li>
<li>学习更好的表征，以提升模型效果<br />
</li>
<li>合成的健壮性，解决重音、跳音、长语音，提升泛化性以适应不同领域<br />
</li>
<li>表现力/控制/转移，让模型捕捉更多内在信息，以实现控制和转移<br />
</li>
<li>与人更相似，在情绪化、风格、自然度方面仍有待提升</li>
</ul>
<p><strong>有效的语音全成</strong><br />
减少资源占用包含减少收集和标注数据，训练模型和模型服务。<br />
*
精减数据，利用无监督或半监督学习和转移方法，对缺少数据的语音建模。<br />
*
精减参数，神经网络针对高质量的合成常常有数以千万计的模型参数，但在移动端，则需要限制内存和功耗，设计轻量级的模型是重要的应用场景。<br />
* 节能，训练和提供高品质的服务，提升资源利用效率。</p>
<h2 id="参考">参考</h2>
<ul>
<li><p>语音合成（TTS)论文优选：Cross-lingual<br />
<a
href="https://zhuanlan.zhihu.com/p/280705416">https://zhuanlan.zhihu.com/p/280705416</a></p></li>
<li><p>AI语音：语音合成，语音识别等语音技术（知乎专栏）<br />
<a
href="https://www.zhihu.com/column/c_1306669801105391616">https://www.zhihu.com/column/c_1306669801105391616</a></p></li>
<li><p>语音合成论文优选：语音合成综述（2021）<br />
<a
href="https://zhuanlan.zhihu.com/p/395767716">https://zhuanlan.zhihu.com/p/395767716</a></p></li>
<li><p>【论文学习】《A Survey on Neural Speech Synthesis》<br />
<a
href="https://blog.csdn.net/weixin_42721167/article/details/118684294">https://blog.csdn.net/weixin_42721167/article/details/118684294</a></p></li>
<li><p>《A Survey on Neural Speech Synthesis》（63页，References
400多篇）<br />
<a
href="https://arxiv.org/pdf/2106.15561v1.pdf">https://arxiv.org/pdf/2106.15561v1.pdf</a></p></li>
</ul>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>语音</tag>
      </tags>
  </entry>
  <entry>
    <title>语音合成工具_bark</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/1_%E8%AF%AD%E9%9F%B3/%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90%E5%B7%A5%E5%85%B7_bark/</url>
    <content><![CDATA[<h2 id="介绍">1 介绍</h2>
<p>多语言的文字转语音模型。<br />
地址: https://github.com/suno-ai/bark</p>
<h2 id="模型原理">2 模型原理</h2>
<p>Bark通过三个Transformer模型，将文本转换为音频。</p>
<h3 id="文本到语义token">2.1 文本到语义Token</h3>
<p>输入：由Hugging Face的BERT标记器分词的文本<br />
输出：编码生成音频的语义Token</p>
<h3 id="语义到粗略token">2.2 语义到粗略Token</h3>
<p>输入：语义Token<br />
输出：来自Facebook的EnCodec编解码器的前两个codebooks的Token</p>
<h3 id="粗略到细节token">2.3 粗略到细节Token</h3>
<p>输入：EnCodec的前两个codebooks<br />
输出：EnCodec的8个codebooks</p>
<h2 id="使用方法">3 使用方法</h2>
<h3 id="环境配置">3.1 环境配置</h3>
<pre><code>docker pull pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime  </code></pre>
<p>运行docker</p>
<pre><code>nvidia-docker run -e NVIDIA_DRIVER_CAPABILITIES=compute,utility -e NVIDIA_VISIBLE_DEVICES=all -p 8893:8888 -v /raid/:/opt/raid --gpus all --rm -it pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime bash  </code></pre>
<h3 id="安装-bark">3.2 安装 bark</h3>
<p>进入docker后：</p>
<pre><code># 安装 bark  
git clone https://github.com/suno-ai/bark  
cp /xxx/pip.conf /root/.pip/  
export http_proxy=http://192.168.1.22:xxxx  
export https_proxy=http://192.168.1.22:xxxx  
cd bark  
python setup.py install  
  
# 安装 jupyter  
pip install jupyter_nbextensions_configurator jupyter_contrib_nbextensions  
jupyter notebook --allow-root -y --no-browser --ip=0.0.0.0  </code></pre>
<h3 id="测试">3.3 测试</h3>
<p>设置环境变量：</p>
<pre><code>import os  
os.environ[&#39;SUNO_USE_SMALL_MODELS&#39;] = &#39;True&#39;  
os.environ[&#39;XDG_CACHE_HOME&#39;] = &#39;set local path to save models&#39;   
# default path: /USER_DIR/.cache/suno/bark_v0  </code></pre>
<p>合成语音：</p>
<pre><code>from bark import SAMPLE_RATE, generate_audio, preload_models  
from IPython.display import Audio  
  
# download and load all models  
preload_models()  
  
# generate audio from text  
text_prompt = &quot;&quot;&quot;  
    我要试试能不能合成中文  
&quot;&quot;&quot;  
audio_array = generate_audio(text_prompt)  
  
# play text in notebook  
Audio(audio_array, rate=SAMPLE_RATE)  </code></pre>
<h2 id="用后感">4 用后感</h2>
<ul>
<li>试用SMALL版本，一共下载三个模型，大小分别是1.1G，1.2G，2.5G，不是很大。<br />
</li>
<li>试用普通版本，一共下载三个模型，大小分别是3.5G, 3.7G,
5.5G，运行时占GPU 6G左右。<br />
</li>
<li>小模型中英文都能合成人声，但听起来比较粗糙，普通模型比较清晰。
流畅度还可以，对于中文的语调感觉不太好，无论模型大小均有此问题，有丢字，错误问题。<br />
</li>
<li>可以用提示指定男声或女声。<br />
</li>
<li>没看到论文，基本是现有技术的组合，结构类似AudioLM。</li>
</ul>
<h2 id="参考资料">5 参考资料</h2>
<p>[语音合成最新技术分享]https://zhuanlan.zhihu.com/p/622980527</p>
]]></content>
  </entry>
  <entry>
    <title>大语言模型带来的一些启发</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B_%E5%B8%A6%E6%9D%A5%E7%9A%84%E4%B8%80%E4%BA%9B%E5%90%AF%E5%8F%91/</url>
    <content><![CDATA[<p>仅代表个人看法，不喜勿喷。</p>
<blockquote>
<p>The limits of my language means the limits of my world. (Ludwig
Wittgenstein)</p>
<p>我的语言的极限意味着我的世界的极限。——维特根斯坦</p>
</blockquote>
<p>大语言模型解决的不仅是处理文本相关问题，它带来的是人对世界的理解，或者说让机器可以直接理解人的意图，而不再需要翻译成指邻、代码，而语言本身又隐含了人对世界的理解。从这个角度看，自然语言模型引领AI时代的进步也就不足为奇了。</p>
<p>十年前说这个，可能觉得很科幻吧；三年前，当看到GPT-3生成的驴唇不对马嘴的文章和回答，也只当是个炒作的噱头，一笑了之；最近两个月发布的AI进展真称得上是日新月异了，在这一刻，当ChatGPT仅两个月就月活过亿，那只能说，你可以不变，但阻止不了世界改变。</p>
<h2
id="过分拟合人的想法是对真实世界的扭曲">过分拟合人的想法是对真实世界的扭曲</h2>
<p>图片来自 GPT-4
论文[1]，对比了预训练模型和使用强化学习调优后模型预测的分布。可以看到，没调前（左图）和真实分布基本是一致的：世界是什么样，模型就学成了什么样；学习调优反而不一致了。强化学习的目标是让AI的回答更符合人的提问意图，以及去除毒性（数据中的偏见、攻击性）。<br />
数据也是人生成的，也有鸡汤，也有漫骂，所以……
当有一天，我们看到世界的全貌，会怎么样？<br />
<img src="/attachments_2023/Pasted%20image%2020230329182704.png" /></p>
<h2 id="你想要的答案到底是什么">你想要的答案到底是什么</h2>
<p>探讨来自谷歌2022年初探讨聊天机器人的论文LaMDA[2]，论文从三方面评估聊天机器人的回答质量：<br />
* sensibleness：文本是否合理，跟历史对话是否有冲突（靠谱）<br />
瞎编乱造，前后矛盾肯定是不行的，回答最好还能有理有据。<br />
* Specificity：对于提问是否有针对性，避免笼统回复（有用）<br />
比如你问AI，这电影怎么样？它回答“不错”，这就等于没说，你需要告诉好在哪。<br />
*
Interestingness：文本是否能引起人的注意或者好奇，是否是超出期待的巧妙回复（有趣）<br />
最好还能带来启发，满足情绪上的一些需求。<br />
（三者权重不同）<br />
从某个角度上讲，这也是我们对人的期许，逐层渐进。是不是觉得有点像：找男朋友的筛选标准？</p>
<h2 id="多闻和推理需要不同的训练途径">多闻和推理需要不同的训练途径</h2>
<p>实验来自DeepMind（发明AlphaGo的公司）在2021年12月发布的一篇论文：Gopher[3]<br />
任何学术科目，连同一般知识，通过改进模型规模都能提升其效果，但规模对逻辑推理、常识和数学任务的好处较少。<br />
最近一两年，出现的一些针对逻辑推理的训练方法，比如
CoT：Chain-of-Thought思想链，主要指模型的多步推理能力，以解决更为复杂的问题。</p>
<p>Google的PaLM论文[4]里，有很多推理示例，比如下面这个推理示例：</p>
<blockquote>
<p>用户输入：迈克尔在法国那个非常有名的博物馆里看它最著名的画作。然而，创作这幅画的艺术家恰恰让迈克尔想起了他小时候最喜欢的卡通人物。卡通人物平时手里拿的东西是哪个国家的？</p>
<p>模型输出：卢浮宫最著名的画作是蒙娜丽莎。制作蒙娜丽莎的艺术家是达芬奇。
Leonardo da Vinci
也是卡通忍者神龟中主角的名字。列奥纳多·达·芬奇来自意大利。列奥纳多·达·芬奇平时手里拿着的东西是武士刀。武士刀的原产国是日本。答案是“日本”。</p>
</blockquote>
<h2 id="读万卷书">读万卷书</h2>
<p>来自DeepMind在2022年3月发布的论文Chinchillla[5]，它针对训练数据量，模型参数量，以及数据训练量进行实验，得出一些结论：<br />
* 更长的训练时间，更多token，能提升模型效果<br />
学习更多的知识和更多训练更为重要<br />
* 大模型的参数量和性能之间存在幂律分布<br />
学到一定程度之后，进步就越来越慢了<br />
* 训练时token越多，模型效果越好<br />
作者认为模型的大小与训练token量应等比增加。<br />
从这个角度出发，作者将模型从280B参数降到了70G，用更多token训练模型，模型效果没有下降，反而还有些提升。<br />
从人的角度看，不需要太过纠结于拟合当前的知识和存储量，更重要的是扩展知识面，另外应该多“思考”。</p>
<h2 id="行万里路">行万里路</h2>
<p>众所周知，GPT-3.5没有相关论文，而GPT-4的论文[1]主要介绍了模型效果，而没有具体实验的技术和模型细节。<br />
从实验来看在MMLU测试中，之前模型通过种种优化，一般都在70分左右，最好也只有75分，而GPT-4达到了86.4分，其中强化学习功不可没。<br />
<img src="/attachments_2023/Pasted%20image%2020230329181459.png"
alt="|500" /><br />
GPT-3.5说它的结构与InstructGPT(2022-03)[6]一致，而InstructGPT主要的进步就是：RLHF（基于人类反馈的强化学习），它与之前的有监督学习和无监督学习不同的是通过模拟环境下试错，拥有了更长远的“眼光”。<br />
当然，这个阶段的AI也不可能一家独大，最近发布的基于Meta的LLaMA[7]模型优化的经济型模型
ColossalChat[8] 也使用了
RLHF（基于人类反馈的强化学习）已经开源并且开放了几乎是即下即用的github下载，听说前两天发布的
Dolly[9] 单机模型效果也很好。</p>
<h2 id="知识的互通性">知识的互通性</h2>
<p>当机器听得懂人话，不再用程序员翻译，更进一步还能听得懂声音，看得懂图片，视频，智力题……
输出也不限于文字回答，还可能是图片，代码，拆解的方案，推理的步骤。从LLM（大语言模型）到MLLMs（多模态大语言模型）的概念提出之后，又扩展了LLM的用途。所有可说，不可说，无法用语言描述的规律……<br />
23年3月发布了很多ChatGPT周边的应用，比如微软的Visual
ChatGPT[10]，自身没有训练大模型，只调用现有的图像处理和自然语言模型就实现了很好的带图像的聊天功能，微软的Kosmos-1[11]
结合图像和语言的大模型在智力题，直接识图方面能力也很强。</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230312071054.png" /><br />
<img src="/attachments_2023/Pasted%20image%2020230312091451.png" /></p>
<h2 id="关于版权">关于版权</h2>
<p>很多训练数据和评测都是公开的，而训练大模型时一般多数数据来自互联网，因此其产出的回答版权归谁，还真不好说。巨头可以不公开模型结构，训练细节，这都是公司的产权，可以不对外开放，但是从互联网上学到的知识训练出的模型，生成的答案，这个版权就不好说了，不止是语言模型，大多数生成模型可能都会遇到这个问题。</p>
<h2 id="一些想法">一些想法</h2>
<p>如果说前两次工业革命解放了人的体力，那么信息和AI就可能解放人的脑力，生产力的变化也会引起社会形态的变化。有点迷茫，忽然想到《双城记》：</p>
<blockquote>
<p>这是最好的时代，这是最坏的时代，这是智慧的年代，这是愚蠢的年代；这是信仰的时期，这是怀疑的时期；这是光明的季节，这是黑暗的季节；这是希望之春，这是失望之冬；人们面前应有尽有，人们面前一无所有；人们正踏上天堂之路，人们正走向地狱之门。</p>
</blockquote>
<h2 id="参考引用">参考引用</h2>
<p>1 <a href="https://arxiv.org/abs/2303.08774">GPT-4 Technical
Report</a><br />
2 <a href="http://arxiv.org/abs/2201.08239">LaMDA: Language Models for
Dialog Applications</a><br />
3 <a href="https://arxiv.org/abs/2112.11446">Scaling Language Models:
Methods, Analysis &amp; Insights from Training Gopher</a><br />
4 <a href="http://arxiv.org/abs/2204.02311">PaLM: Scaling Language
Modeling with Pathways</a><br />
5 <a href="http://arxiv.org/abs/2203.15556">Training Compute-Optimal
Large Language Models</a><br />
6 <a href="http://arxiv.org/abs/2203.02155">Training language models to
follow instructions with human feedback</a><br />
7 <a href="https://arxiv.org/abs/2302.13971">LLaMA: Open and Efficient
Foundation Language Models</a><br />
8 <a href="https://github.com/hpcaitech/ColossalAI">ColossalChat
github</a><br />
9 <a href="https://www.oschina.net/p/dolly">Dolly download
addr</a><br />
10 <a href="http://arxiv.org/abs/2303.04671">Visual ChatGPT: Talking,
Drawing and Editing with Visual Foundation Models</a><br />
11 <a href="http://arxiv.org/abs/2302.14045">Language Is Not All You
Need: Aligning Perception with Language Models</a></p>
]]></content>
  </entry>
  <entry>
    <title>论文阅读_ChatGLM</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_ChatGLM/</url>
    <content><![CDATA[<p>name_ch: Glm-130B：开放双语预训练模型<br />
name_en: GLM-130B：AN OPEN BILINGUAL PRE-TRAINED<br />
paper_addr: https://arxiv.org/abs/2210.02414<br />
code: https://github.com/THUDM/GLM-130B/<br />
date_publish: 2023-01-01</p>
<h2 id="读后感">1 读后感</h2>
<p>2022年11月，斯坦福大学大模型中心对全球30个主流大模型进行了全方位的评测2，GLM-130B
是亚洲唯一入选的大模型。 GLM-130B 在准确性和恶意性指标上与 GPT-3 175B
(davinci) 接近或持平。<br />
ChatGLM最大的优点是开源，并针对中文进行了优化，尤其是可以在自己的机器上搭建其简版的int4服务，实测回答一般性问题效果还不错，文后附环境搭建方法。</p>
<h2 id="摘要">2 摘要</h2>
<p>ChatGLM是使用中英双语预训练的大语言模型，具有130B参数（1300亿），使用400B
token训练。<br />
在模型结构上结合了GPT和BERT。在英文方面，效果优于GPT-3；在中文方面，优于260B参数的ERNIE
TITAN 3.0。可在4×RTX 3090 (24G) 或 8×RTX 2080 Ti (11G) GPUs
环境下运行。</p>
<h2 id="介绍">3 介绍</h2>
<p>论文提出：通用语言模型General Language Model (GLM)
，主要使用的技术是：双向注意力和自回归空白填充目标。嵌入梯度收缩策略可以显著提升GLM
- 130B的训练稳定性。<br />
<img src="/attachments_2023/Pasted%20image%2020230323174928.png" /></p>
<h2 id="方法">4 方法</h2>
<h3 id="结构">4.1 结构</h3>
<h4 id="glm架构">4.1.1 GLM架构</h4>
<p>与GPT，PaLM等模型使用Transformer的解码器方式不同，GLM-130B使用了一种双向通用语言模型（GLM）作为其Backbone。模型结构详见论文：<a
href="/1_Note/2_算法/2_大模型/论文阅读_GLM">论文阅读_GLM</a></p>
<p>GLM是一种基于Transformer的语言模型，它以自回归空白填充为训练目标。简而言之，对于一个文本序列<code>x=[x1, · · · ,xn]</code>，从其中采样文本<code>span&#123;s1，· · ·，sm&#125;</code>，其中每个si表示连续令牌的跨度，并用单个掩码替换si，要求模型对它们进行自回归恢复。与GPT类模型不同的是，它在不Mask的位置使用双向注意力，因此它混合了两种Mask，以支持理解和生成：</p>
<p>[MASK]：句子中的短空白，长度加总到输入的某一部分<br />
[gMASK]：随机长度的长空白，加在提供前缀上下文的句子末尾</p>
<p>理论上，双向注意力的空白填充目标<strong>比GPT风格的模型能够更有效地理解语境</strong>：当使用
MASK 时，GLM- 130B表现类似BERT和T5；当使用 gMASK 时，GLM - 130B表现出与
PrefixLM 相似的性质。</p>
<p>GLM - 130B在零样本LAMBDA上取得了80.2 %的高准确率，优于图2中的GPT -
3和PaLM 540B。<br />
<img src="/attachments_2023/Pasted%20image%2020230323181746.png" /></p>
<h4 id="归一化方法">4.1.2 归一化方法</h4>
<p>归一化有助于提升模型训练的稳定性，文中使用了2022年提出的DeepNorm方法（详见论文
：Deepnet: Scaling transformers to 1,000 layers），其公式为：<br />
<span class="math display">\[  
DeepNorm(x) = LayerNorm(α · x + Network(x))  
\]</span><br />
<span class="math display">\[α = (2N )^{\frac{1}{2}}\]</span><br />
其中N为层数。此方法有效地提升了训练稳定性。<br />
<img src="/attachments_2023/Pasted%20image%2020230323182219.png" /></p>
<h4 id="位置编码和前馈网络">4.1.3 位置编码和前馈网络</h4>
<p>对于GLM -
130B中的位置编码采用旋转位置编码(RoPE)，并选择GeLU激活函数以优化FFN。</p>
<h3 id="训练设置">4.2 训练设置</h3>
<p>GLM -
130B预训练目标不仅包括自监督的GLM自回归空白填充，还包括对小部分token的多任务学习，以提升其下游zero-shot任务的性能。</p>
<h4 id="自监督空白填充95">4.2.1 自监督空白填充（95%）</h4>
<p>同时使用了 MASK 和
gMASK，每个序列使用其中一种。具体来说，MASK用于在30
%的训练序列中掩盖连续的Token以进行空白填充。对于其他70%的序列，保留每个序列的前缀作为上下文，并使用gMASK来掩盖其余序列训练。<br />
预训练数据包括1.2 T英语、1.0
T的中文悟道语料库，以及从网络爬取的250G中文语料库(包括在线论坛、百科全书和QA)，形成了平衡的英汉内容构成。</p>
<h4 id="多任务指导预训练-mip5">4.2.2 多任务指导预训练 (MIP，5%)</h4>
<p>预训练中加入包括语言理解、生成和信息提取在内的多种指令提示数据集训练模型。</p>
<h3 id="并行训练和模型配置">4.3 并行训练和模型配置</h3>
<p>在96个DGX - A100 GPU ( 8 × 40G
)服务器集群上进行了60天的训练。将pipline模型并行与其他两种策略结合形成了3D并行策略。</p>
<h2 id="模型训练的稳定性">5 模型训练的稳定性</h2>
<p>需要在精度和稳定间保持平衡，低精度的FP格式提高了计算效率，但容易出现溢出错误，导致训练崩溃。</p>
<h3 id="混合精度">5.1 混合精度</h3>
<p>FP16用于前向和后向，FP32用于优化器状态和主权重，以减少GPU内存使用，提高训练效率。</p>
<h3 id="嵌入层梯度收缩">5.2 嵌入层梯度收缩</h3>
<p>实验表明，梯度范数可以作为训练崩溃的信息指标。具体来说，训练崩溃通常滞后于梯度范数中的"尖峰"几个训练步。发现嵌入层的梯度收缩可以克服损失尖峰，从而稳定GLM
- 130B的训练。</p>
<h2 id="在-rtx-2080-ti-上使用模型推理">6 在 Rtx 2080 TI
上使用模型推理</h2>
<p>在保持FP16激活精度的同时，重点关注模型权重的量化。量化后的模型在运行时动态转换为FP16精度，引入了较小的计算开销，大大降低了存储模型权重的GPU内存使用量。文中成功地实现了GLM
- 130B的INT4权重量化，目前模型已发布，可下载使用。<br />
<img src="/attachments_2023/Pasted%20image%2020230323190102.png" /></p>
<h2 id="实验">7 实验</h2>
<p>与英文模型比较：<br />
<img
src="/attachments_2023/Pasted%20image%2020230323185137.png" /><br />
与中文模型比较：<br />
<img src="/attachments_2023/Pasted%20image%2020230323185038.png" /></p>
<h2 id="实战环境搭建">8 实战——环境搭建</h2>
<p>ChatGLM-6B
是一个具有62亿参数的中英双语语言模型，由大模型量化后得到，代码+模型一共只有几个G大小。</p>
<h3 id="下载代码和模型">8.1 下载代码和模型</h3>
<p>由于我家机器性能有限，就下载了int4模型，约占空间5G左右，运行时占GPU内存5G左右。</p>
<pre><code>$ git clone https://github.com/THUDM/ChatGLM-6B  
$ git clone https://huggingface.co/THUDM/chatglm-6b-int4/  </code></pre>
<p>在网站 https://huggingface.co/THUDM/chatglm-6b-int4/tree/main
中下载：<br />
ice_text.model 和 pytorch_model.bin 两个大文件，替换git中的文件。</p>
<h3 id="下载运行环境镜像">8.2 下载运行环境镜像</h3>
<p>如果使用docker启动，推荐镜像：</p>
<pre><code>$ docker pull pytorch/pytorch:1.13.1-cuda11.6-cudnn8-runtime  </code></pre>
<p>启动镜像</p>
<pre><code>$ nvidia-docker run -e &quot;LC_ALL=zh_CN.UTF-8&quot; -e &quot;LANGUAGE=zh_CN.UTF-8&quot; -e &quot;LANG=zh_CN.UTF-8&quot; -p 7860:7860 --rm -v /exports:/workspace/exports -it pytorch/pytorch:1.13.1-cuda11.6-cudnn8-runtime bash  </code></pre>
<h3 id="调整代码">8.3 调整代码</h3>
<p>修改web_demo.py<br />
* 修改模型名为指定目录：</p>
<pre><code>tokenizer = AutoTokenizer.from_pretrained(&quot;../chatglm-6b-int4/&quot;, trust_remote_code=True)  
model = AutoModel.from_pretrained(&quot;../chatglm-6b-int4/&quot;, trust_remote_code=True).half().cuda()  </code></pre>
<ul>
<li>设置server_name为0.0.0.0，以便服务在docker外部调用<br />
</li>
</ul>
<pre><code>demo.queue().launch(share=False, inbrowser=True, server_name=&quot;0.0.0.0&quot;)  </code></pre>
<h3 id="运行服务">8.4 运行服务</h3>
<p>在镜像内部运行</p>
<pre><code>$ cd ChatGLM-6B/  
$ pip install -r requirements.txt  
$ python web_demo.py  </code></pre>
<p>启动服务后，就可以在宿主机浏览器中通过端口7860访问，效果如下：<br />
<img
src="/attachments_2023/Pasted%20image%2020230322224537.png" /><br />
个人觉得速度还挺快的，回答效果也还行。</p>
<h3 id="相关链接">8.5 相关链接</h3>
<p><a
href="https://github.com/THUDM/ChatGLM-6B">ChatGLM项目地址</a><br />
<a href="https://chatglm.cn/blog">ChatGLM模型介绍</a><br />
<a
href="https://huggingface.co/THUDM/chatglm-6b/tree/main">模型下载</a></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_Chinchilla</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_Chinchilla/</url>
    <content><![CDATA[<p>name_ch: 训练计算优化的大型语言模型<br />
name_en: Training Compute-Optimal Large Language Models<br />
paper_addr: http://arxiv.org/abs/2203.15556<br />
date_publish: 2022-03-29</p>
<h2 id="读后感">读后感</h2>
<p>针对训练数据量，模型参数量，以及数据训练量，通过实验，得出一些结论：更长的训练时间，更多token，能提升模型效果；大模型的参数量和性能之间存在幂律分布；训练时token越多，模型效果越好，作者认为模型的大小与训练token量应等比增加。<br />
换言之：不应该太过纠结于拟合当前的知识和存储量，更重要的是扩展知识面，另外应该多“思考”。</p>
<h2 id="摘要">摘要</h2>
<p>现在大模型严重训练不足。通过大量实验发现对于模型的每加倍size
训练令牌的数量也应该加倍。Chinchilla
使用更少的计算来进行微调和推理，极大地促进了下游应用。</p>
<h2 id="介绍">介绍</h2>
<p>可以看到，相对当时其它模型，Chinchilla使用了更多的token和更少的模型参数。</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230326080340.png" /><br />
文中主要讨论了，<strong>在运算量固定的情况下，如何选择参数和token量的配比，使损失函数最小</strong>。</p>
<p>通过在 5 到 5000 亿个标记上训练 400 多个语言模型，范围从 7000
万到超过 160 亿个参数。如图-1所示：<br />
<img src="/attachments_2023/Pasted%20image%2020230326081512.png" /></p>
<p>文中介绍Chinchilla模型是对Gopher的调整，将模型大小变为其1/4，token变为其4倍，与Gopher计算量基本一致。它不仅效果更好，还减少了模型规模，使其能在更低成本的硬件上运行。</p>
<h2 id="方法">方法</h2>
<p>从图-2中可以看到token量，参数量和运算量的相互关系：<br />
<img
src="/attachments_2023/Pasted%20image%2020230326085125.png" /><br />
实验尝试了使用不同大小的训练数据，不同参数量，以及把参数量和数据规模加入Loss的惩罚，经过大量实验（论文第三部分），得出以下结论：<br />
<strong>随着计算预算的增加，模型大小和训练数据量应该以大致相等的比例增加</strong>。<br />
图-3展示了不同参数对应的估计训练数据量（后面的模型可以参考这个量）：<br />
<img src="/attachments_2023/Pasted%20image%2020230326091050.png" /></p>
<h2 id="chinchilla模型">Chinchilla模型</h2>
<h3 id="训练数据">训练数据</h3>
<p><img
src="/attachments_2023/Pasted%20image%2020230326092519.png" /></p>
<h3 id="模型结构">模型结构</h3>
<p><img
src="/attachments_2023/Pasted%20image%2020230326092554.png" /></p>
<h3 id="实验">实验</h3>
<p>实验在阅读理解，问答，常识，MMLU等多个测试集中评测，效果是Chinchilla在绝大多数情况都优于其基础模型Gopher，其中<strong>MMLU</strong>对比效果如下（其它详见正文），对于其中几个子项（高中政治，国际法，社会学，美国外交政策）评测效果高于其它所有模型：<br />
<img src="/attachments_2023/Pasted%20image%2020230326093116.png" /></p>
<h2 id="收获">收获</h2>
<ul>
<li>延伸阅读：Scaling laws for neural language
models，被本篇引用了23次。<br />
</li>
<li>FLOP是一种衡量模型计算量的指标，全称为Floating Point
Operations，即浮点运算次数。在NLP中，FLOP
budgets是指模型的计算量预算。</li>
</ul>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_GLM</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_GLM/</url>
    <content><![CDATA[<p>中文名称: GLM：使用自回归空白填充的通用语言模型预训练<br />
英文名称: GLM：General Language Model Pretraining with Autoregressive
Blank Infilling<br />
论文地址: https://aclanthology.org/2022.acl-long.26<br />
出处: Proceedings of the 60th Annual Meeting of the Association for
Computational<br />
Linguistics (Volume 1：Long Papers)<br />
时间: 2022-01-01</p>
<h2 id="读后感">读后感</h2>
<p>通过在结构上的调整，结合了GPT和BERT类模型的优点，且模型规模和复杂度没有提升。将NLU任务转换成生成任务训练模型，使上下游任务训练方式保持一致。</p>
<h2 id="摘要">摘要</h2>
<p>没有一个预训练框架对自然语言理解
(NLU)、无条件生成和条件生成这三个主要类别的所有任务表现都好。文中提出了通用语言模型：General
Language Model (GLM)，它基于自回归空白填充来解决这一挑战。<br />
在 NLU 任务上的性能优于 BERT 和
T5。可以通过改变空白的数量（屏蔽几块）和长度（每块有几个token）来针对不同类型的任务对
GLM 进行预训练。且它只有BERT large的 1.25倍参数量。</p>
<h2 id="介绍">介绍</h2>
<p>GLM基于自回归的空白填充。从输入文本中随机删除连续的token(自编码)，并训练模型以顺序重建删除的token(自回归)。使用了二维的位置编码，相对于T5模型有更少的参数，差不多的效果。<br />
在处理 NLU
任务时，将其转换成完形填空问题；通过改变缺失跨度的数量和长度，自回归空白填充目标可以为有条件和无条件生成预训练语言模型。</p>
<h2 id="方法">方法</h2>
<h3 id="预测训练目标">预测训练目标</h3>
<h4 id="自回归的目标填充">自回归的目标填充</h4>
<p>输入x由多个 token 组成，采样一些 span（绿色和黄色的块）用 s
表示，每个 span 包含一个或多个 token，用 Mask 遮蔽每个
span，模型以自回归的方式预测损坏文本中缺失的
token，预测时可以使用其它span以及当前span中，当前位置之前的token。<br />
用z表示每个span中的具体位置，假设一共m个token，将目标定义为：<br />
<span class="math display">\[  
\max _{\theta} \mathbb{E}_{\boldsymbol{z} \sim
Z_{m}}\left[\sum_{i=1}^{m} \log p_{\theta}\left(\boldsymbol{s}_{z_{i}}
\mid \boldsymbol{x}_{\text {corrupt }},
\boldsymbol{s}_{\boldsymbol{z}_{&lt;i}}\right)\right]  
\]</span><br />
也就是说，使用被损坏的文本x，以及之前预测的Sz&lt;i来预测Szi处的token。<br />
<img src="/attachments_2023/Pasted%20image%2020230324164415.png" /></p>
<p>如图2(a)(b)，输入的x分为两部分，Part A是遮蔽后的文本，Part
B只包含遮蔽的文本，Part A中的数据不能使用Part B中的内容；Part
B可以使用Part
A中的内容和当前位置之前的内容。另外，在遮蔽文本的前后加START和END标记。从而使模型从Part
A中学习双向上下文，以Part B中学习单向上下文。具体训练时保证至少 15%
的原始标记被屏蔽。</p>
<p>图(c)中展示了两维的位置编码分别标记了token在整体中的位置和在span中的位置，且由S标记开头，生成的结果以E结束。</p>
<p>图(d)中把Part A与Part B连在一起，其中蓝色表示Part
A中可用的数据只包含被遮蔽后的x串，黄色和绿色分别表示了Part
B中两个span在不同时点可使用的数据范围。</p>
<h4 id="多任务预训练">多任务预训练</h4>
<p>由于需要用一个模型同时支持NLU和文本生成，所以是多任务的训练，有以下两个目标：<br />
* 文档级别：为了有效地生成长文本，长度是从原始长度的 50%–100%
的均匀分布中采样的。<br />
*
句子级别：为了预测seq2seq任务中完整句子和段落，限制屏蔽的跨度是完整的句子，屏蔽的token为原始文本长度的15%。<br />
两种方式都使用上述公式，只是屏蔽的span数量和长度不同。</p>
<h3 id="模型结构">模型结构</h3>
<ul>
<li>重新排列了层归一化和残差连接的顺序<br />
</li>
<li>使用单个线性层进行输出标记预测<br />
</li>
<li>用 GeLU 替换 ReLU 激活函数<br />
</li>
<li>两维的位置嵌入：如图-2(c)所示，这样的位置编码在预测Part
B时不会泄漏需要预测的长度，以保证适用于文本生成的下游任务。</li>
</ul>
<h3 id="精调模型">精调模型</h3>
<p>为了保证预训练和精调任务的一致性，将NLU中的分类任务改成了生成中的空白填充任务，具体类似完型填空，把答案当成文本中的一个token进行屏蔽，形如：<code>&#123;SENTENCE&#125;. It’s really [MASK]</code>，候选标签
y ∈ Y 也映射到完形填空的答案，称为 v(y)。<br />
<span class="math display">\[  
p(y \mid \boldsymbol{x})=\frac{p(v(y) \mid
c(\boldsymbol{x}))}{\sum_{y^{\prime} \in \mathcal{Y}}
p\left(v\left(y^{\prime}\right) \mid c(\boldsymbol{x})\right)}  
\]</span><br />
<img src="/attachments_2023/Pasted%20image%2020230328185234.png" /></p>
<p>相对于GLM，BERT和XLNet的问题在于它不能预测未知长度的序列。</p>
<h2 id="实验">实验</h2>
<p>为与 BERT进行公平比较，使用
BooksCorpus和英语维基百科作为预训练数据。并使用 BERT 的 30k 词汇量。与
BERTBase 和 BERTLarge 相同的架构训练 GLM_Base 和 GLM_Large，分别包含
110M 和 340M 参数；并训练GLM_RoBERTa对标RoBERT。</p>
<p>用GLM_Doc表示文档层次的训练，GLM_Sent表示句子层次的训练。GLM_410M和GLM_515M分别代表大模型的参数数量。T5的参数量分别是T5_Base（220M
参数）和 T5_Large（770M 参数）的结果。</p>
<p>主实验结果如下：<br />
<img src="/attachments_2023/Pasted%20image%2020230328190827.png" /></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>自然语言大模型介绍</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h2 id="简介">1 简介</h2>
<p>最近一直被大语言模型刷屏。本文是周末技术分享会的提纲，总结了一些自然语言模型相关的重要技术，以及各个主流公司的研究方向和进展，和大家共同学习。</p>
<h2 id="transformer">2 Transformer</h2>
<p>目前的大模型基本都是Transformer及其变种。本部分将介绍Transformer基础模型及其主要变种。</p>
<h3 id="transformer模型">2.1 Transformer模型</h3>
<p>Transformer是一种基于自注意力机制的模型，由Encoder和Decoder两部分组成。<br />
下图是精典论文《Attention is all you
need》中展示的模型结构图，左边是Encoder，右边是Decoder，</p>
<p><img src="/attachments_2023/Pasted%20image%2020230330110902.png"
alt="|500" /><br />
在Transformer中，Encoder将输入序列映射到一个高维空间中，Decoder则将这个高维空间中的向量映射回输出序列。<br />
在Encoder中，所有的词一起输入一起计算；在Decoder中像RNN一样一个一个词输入，将已经出现的词计算得到的Q与Encoder计算得到的K,V进行计算，经过了全部Decoder层再经过FC+Softmax得到结果之后再把结果当做Decoder的输入再走一遍整个流程直到得到END标签。<br />
Transformer既有Encoder又有Decoder，主要因为一开始处理的是翻译任务，需要先理解整句的意思，再逐字生成翻译结果。</p>
<p>Encoder和Decoder的主要区别包括：<br />
*
Decoder多包含了一个处理层（编码器-解码器注意力），其接入的是Encoder的输出。<br />
* Decoder下面的是 <strong>Masked
Attention</strong>，它屏蔽了下文，只考虑上文对下文的影响。<br />
简单讲：主要差别就是单向/双向注意力的差别。<br />
详见：<a
href="/1_Note/3_编程/Pytorch/Transformer框架">Transformer框架</a><br />
论文地址：<a
href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">Attention
is All you Need</a></p>
<h3 id="自编码">2.2 自编码</h3>
<ul>
<li>常见模型：BERT类模型<br />
</li>
<li>结构：只有Encoder<br />
</li>
<li>方法：双向上下文，Mask语言模型<br />
</li>
<li>场景：编码器产生适合自然语言理解任务的上下文表示，常用于解决阅读理解，完型填空等问题。<br />
</li>
<li>缺点：不能支持不确定长度文本的生成，而且依赖前后上下文，这样就非常限制下游任务的类型；一般只能在fine-tune后才能在下游任务中使用，这也将涉及大量人工操作和模型调参，模型也不能做得太大。<br />
</li>
<li>详见：<a
href="/1_Note/2_算法/6_自然语言/NLP模型应用之二：BERT">NLP模型应用之二：BERT</a><br />
</li>
<li>论文地址：<a href="https://arxiv.org/pdf/1810.04805.pdf">BERT:
Pre-training of Deep Bidirectional Transformers for<br />
Language Understanding</a></li>
</ul>
<h3 id="自回归">2.3 自回归</h3>
<ul>
<li>常见模型：GPT-3等模型<br />
</li>
<li>结构：只有Decoder<br />
</li>
<li>方法：单向上下文本：从左-&gt;右，“一个接一个”生成文本。将解码器自己当前步的输出加入下一步的输入，因此可以生成后续不定长的序列。<br />
</li>
<li>场景：适用于生成长数据，实现大模型，few-shot任务效果好<br />
</li>
<li>缺点：单向注意力，使之无法完全捕获 NLU
任务中上下文词之间的依赖关系。可以将其它任务转换成自回归任务，比如："XXXX电影很好看，这是对/错的"，完型填空题"xxx_yyy，横线上应该填zzz"。这基本就是提示的原理，它让Decoder类模型可以在不fine-tune的情况适应各种类型的下游任务，同时也拥有了BERT的一些优势——虽然不是双向的，但应学习的知识都在前文里。<br />
</li>
<li>详见：<a
href="/1_Note/2_算法/6_自然语言/论文阅读_自然语言模型GPT-3">论文阅读_自然语言模型GPT-3</a><br />
</li>
<li>论文地址：<a href="https://arxiv.org/abs/2005.14165">Language Models
are Few-Shot Learners</a></li>
</ul>
<h3 id="结合encoder和decoder">2.4 结合Encoder和Decoder</h3>
<ul>
<li>常见模型：T5，GLM<br />
</li>
<li>结构：结合Encoder和Decoder<br />
</li>
<li>方法：在Encoder中使用双向上下文，Docoder使用单向，在E和D间使用交叉注意力。<br />
</li>
<li>场景：主要用于<strong>有条件的文本生成</strong>，比如生成摘要，回答问题<br />
</li>
<li>缺点：需要更多参数。</li>
</ul>
<h4 id="t5">2.4.1 T5</h4>
<p><img
src="/attachments_2023/Pasted%20image%2020230330132454.png" /><br />
* 第一种方式实现上面提到的翻译功能，只使用其Encoder部分，如BERT。<br />
* 第二种方式是根据上文生成下文，如GPT<br />
*
第三种方式在序列的前缀部分使用完全可见的掩码，如在上面提到的英语到德语的翻译示例中，完全可见的掩码将应用于前缀“translate
English to German: That is good.target：”使用因果掩蔽来预测目标“Das ist
gut”。（对条件使用双向，对结果使用单向）。</p>
<h4 id="glm">2.4.2 GLM</h4>
<ul>
<li><a href="None">方法</a> 自回归的空白填充<br />
<img src="/attachments_2023/Pasted%20image%2020230324164415.png" /></li>
</ul>
<h2 id="模型变迁">3 模型变迁</h2>
<ul>
<li>BERT（Devlin et al.，2018）<br />
</li>
<li>GPT-2（Radford et al.，2019）<br />
</li>
<li>MegatronLM（Shoeybi et al.，2019）<br />
</li>
<li>T5（Raffel et al，2019）。<br />
</li>
<li>GPT-3（Brown et al.，2020 年）取得了重大突破<br />
</li>
<li><hr /></li>
<li>开始大模型<br />
</li>
<li>Jurassic-1（Lieber et al.，2021）<br />
</li>
<li>Megatron-Turing NLG 2022)<br />
</li>
<li>Gopher (Rae et al., 2021)<br />
</li>
<li>Chinchilla (Hoffmann et al., 2022)<br />
</li>
<li>PaLM (Chowdhery et al., 2022)<br />
</li>
<li>OPT (Zhang et al., 2022)<br />
</li>
<li>GLM (Zeng et al., 2022)<br />
<img src="/attachments_2023/Pasted%20image%2020230329105210.png" /></li>
</ul>
<h2 id="主流大模型">4 主流大模型</h2>
<ul>
<li>思想 &amp; 结构 &amp; 应用（道 术 技）<br />
</li>
<li>一般称参数大于100B的语言模型为大语言模型。<br />
</li>
<li>大模型主要用于解决few shot, zero shot问题。</li>
</ul>
<h3 id="google">4.1 Google</h3>
<p>Google
的几篇文章从模型架构，算法优化，模型规模，应用场景，以及大语言模型指导机器人同步推理；对话场景中的其它应用（搜索、翻译、计算器）结合等方面进行了广泛探索，且基本都是开源的。</p>
<h4 id="t5模型">4.1.1 T5模型</h4>
<ul>
<li>发布时间：2019-06-11<br />
</li>
<li>解决问题：T5是Transfer Text-to-Text Transformer的简写，它是一种NLP
Text-to-Text预训练模型。它的输入是文本，输出也是文本，模型使用迁移学习的技术，使用Transformer架构。其目标是给整个
NLP 预训练模型领域提供了一个通用框架，把所有任务都转化成一种形式。<br />
</li>
<li>方法：提出了Encoder加Decoder的新结构，结合了BERT和GPT结构的优势。将任务转换成合适的文本输入输出。<br />
</li>
<li>模型结构：Encoder+Decoder<br />
</li>
<li>模型和数据规模：包含
3B（Billion）和11B版本，处理后最终生成了750GB的数据集C4，并且在TensorFlow
Datasets开放了数据。<br />
</li>
<li>亮点：模型结构，整体框架<br />
</li>
<li>详见：<a href="https://www.zhihu.com/question/352227934">如何评价
Google 提出的预训练模型 T5？</a><br />
</li>
<li>论文地址：<a
href="https://jmlr.org/papers/v21/20-074.html">Exploring the Limits of
Transfer Learning with a Unified Text-to-Text Transformer</a></li>
</ul>
<h4 id="lamda">4.1.2 LaMDA</h4>
<ul>
<li>发布时间：2022-02-10<br />
</li>
<li>解决问题：调优对话机器人。提升模型的<strong>安全性和事实性</strong>，同时可利用<strong>外部知识来源</strong>，如：信息检索系统、语言翻译器和计算器——<strong>结合了自然语言模型与其它工具</strong>。<br />
</li>
<li>方法：利用众包方式，选择人类偏好的回答，利用标注数据finetune模型。<br />
</li>
<li>模型结构：Decoder结构。<br />
</li>
<li>数据和模型规模：1.56T 词进行预训练，137B 参数。<br />
</li>
<li>亮点：结合了自然语言模型和其它工具，功能有点像newbing<br />
</li>
<li>详见：<a
href="/1_Note/2_算法/2_大模型/论文阅读_LaMDA">论文阅读_LaMDA</a><br />
</li>
<li>论文地址：<a href="http://arxiv.org/abs/2201.08239">LaMDA: Language
Models for Dialog Applications</a></li>
</ul>
<h4 id="引导调优">4.1.3 引导调优</h4>
<ul>
<li>发布时间：2022-02-08<br />
</li>
<li>解决问题：在通过指令描述的一组数据集上微调语言模型，它显著提高了未见任务的
zero-shot 性能。FLAN 的性能相对于LaMDA每个任务平均值提升了10左右。<br />
</li>
<li>方法：将此类模型称为FLAN（Finetuned Language Net），用 Tensorflow
Datasets 上公开可用的 62
个文本数据集，划分为十二种任务，针对每种任务编写模板，用于调优模型。指令调优管道混合了所有数据集并从每个数据集中随机抽样。为了平衡不同大小的数据集，将每个数据集的训练示例数量限制为
30k，并遵循示例比例混合方案。<br />
</li>
<li>数据结构：同 LaMDA<br />
</li>
<li>数据和模型规模：预训练同LaMDA，精调使用62个数据集数据。<br />
</li>
<li>亮点：指令调优，见原理图<br />
</li>
<li>详见：<a
href="/1_Note/2_算法/6_自然语言/论文阅读_用引导调优模型">论文阅读_用引导调优模型</a><br />
</li>
<li>论文地址：<a href="http://arxiv.org/abs/2109.01652">Finetuned
Language Models Are Zero-Shot Learners</a></li>
</ul>
<h4 id="glam">4.1.4 GLaM</h4>
<ul>
<li>发布时间：2022-08-01<br />
</li>
<li>解决问题：针对节约计算资源的研究，推进了针对细分专家领域的发展。<br />
</li>
<li>方法：一种<strong>混合专家</strong>（MoE）模型，可以将其视为具有不同子模型（或专家）的模型，每个子模型都专门针对不同的输入。每层中的专家由门控网络控制，该网络根据输入数据激活专家。每次只激活8%的子网络。<br />
</li>
<li>模型结构：MoE，Decoder结构。<br />
</li>
<li>数据和模型规模：最大的 GLaM 有 1200B 参数，大约是 GPT-3 的 7
倍，却仅消耗用于训练 GPT-3 的 1/3
的能量，并且需要一半的计算触发器来进行推理；质量筛选数据对模型训练的影响。过滤后的网页包含
143B 个token，而未过滤的网页包含大约 7T
个token，实验说明有些任务需要高质量数据训练。<br />
</li>
<li>亮点：模型结构，见模型结构图<br />
</li>
<li>详见：<a
href="/1_Note/2_算法/2_大模型/论文阅读_GLaM">论文阅读_GLaM</a><br />
</li>
<li>论文地址：<a href="http://arxiv.org/abs/2112.06905">GLaM：Efficient
Scaling of Language Models with Mixture-of-Experts</a></li>
</ul>
<h4 id="palm">4.1.5 PaLM</h4>
<ul>
<li>发布时间：2022-10-05<br />
</li>
<li>解决问题：作者认为当模型大到一定程度后，其性能也能飞跃，而PathWay技术是其大规模训练的基础。PaLM更关注逻辑推理相关的任务，这也为后面的PaLM-E机器人行为规划奠定了基础。<br />
</li>
<li>方法：推理链提示和大模型都明显提升了模型的推理能力。<br />
</li>
<li>模型结构：Decoder结构。<br />
</li>
<li>数据和模型规模：使用6144 个芯片训练，模型8B/62B/540B参数，780
B高质量token，密集激活。数据基于训练
LaMDA和GLaM的数据，除了自然语言，还包含多种编程语言的源代码。根据文件之间的
Levenshtein 距离删除重复项。<br />
</li>
<li>亮点：大模型&amp;推理部分&amp;模型解释（6.3 推理，9.
探索解释）<br />
</li>
<li>详见：<a
href="/1_Note/2_算法/2_大模型/论文阅读_PaLM">论文阅读_PaLM</a><br />
</li>
<li>论文地址：<a href="http://arxiv.org/abs/2204.02311">PaLM: Scaling
Language Modeling with Pathways</a></li>
</ul>
<h4 id="palm-e">4.1.6 PaLM-E</h4>
<ul>
<li>发布时间：2023-03-06<br />
</li>
<li>解决问题：通过多模态接入了视频，传感器，将大模型学到的知识应用于机器人领域，进一步解决世界中的交互问题。PaLM-E直接产生动作的计划，从而让机器人自己规划过程。<br />
</li>
<li>方法：将图像和状态等输入嵌入到与语言标记相同的隐空间中，并由基于Transformer的LLM的自注意力层以与文本相同的方式进行处理，输出可以是问题的答案，或者文本形式生成的、由机器人执行的决策序列。<br />
</li>
<li>模型结构：Decoder解码器；提出神经网络结构，支持多模态token。模型包含三部分：观测数据编码器，映射器和自然语言模型。<br />
</li>
<li>数据和模型规模：训练的最大模型有 562B
参数，包含540B语言参数和22B视觉参数。<br />
</li>
<li>亮点：论文实验部分<br />
</li>
<li>详见：<a
href="/1_Note/2_算法/2_大模型/论文阅读_PaLM-E">论文阅读_PaLM-E</a><br />
</li>
<li>论文地址：<a href="http://arxiv.org/abs/2303.03378">PaLM-E: An
Embodied Multimodal Language Model</a></li>
</ul>
<h3 id="metafacebook">4.2 Meta（Facebook）</h3>
<p>Meta
更偏重于模型的应用场景，在模型规模，减少标注开销，提升质量等方面进行了研究，尤其是其发布的
LLaMA
目前已经成为各个经济适用模型的基础模型，可能很快成为DIY的主流框架。本部分除了
Meta公司的研究，还介绍了两个 LLaMA 的衍生产品。</p>
<h4 id="opt-175b">4.2.1 OPT-175B</h4>
<ul>
<li>发布时间：2022-05-03<br />
</li>
<li>解决问题：超大规模语言模型，该模型是当时第一个模型参数超过千亿级别的开放模型，该模型与GPT-3相比，更加开放及便于访问。<br />
</li>
<li>方法：训练 125M - 175B
各种大小的模型，经过一系列优化，只使用了GPT-3的1/7的训练资源。这是通过结合Meta的开源完全分片数据并行(FSDP)
API和NVIDIA的张量并行抽象在Megetron-LM中实现的。<br />
</li>
<li>模型结构：Decoder结构。<br />
</li>
<li>数据和模型规模：175B参数<br />
</li>
<li>详见：<a
href="https://www.cnblogs.com/mengrennwpu/p/16223272.html">Meta
AI新发布的超大规模语言模型-OPT-175B</a><br />
</li>
<li>论文地址：<a href="https://arxiv.org/pdf/2205.01068.pdf">OPT: Open
Pre-trained Transformer Language Models</a></li>
</ul>
<h4 id="self-instruct">4.2.2 Self instruct</h4>
<ul>
<li>发布时间：2022-12-20<br />
</li>
<li>解决问题：对引导精调的优化，之前引导精调主要使用人工处理的数据，数据量和范围都有限，本文通过示范少量引导示例，让模型自己生成引导数据对模型进行优化。经过自引导可使基础模型的GPT-3提升33%，与InstructGPT001差不多的效果。<br />
</li>
<li>方法：自引导过程是一个迭代自举算法。在第一阶段，模型被提示为新任务生成指令。此步骤利用现有的指令集合来创建更广泛的指令定义任务；然后，在将低质量和重复的指令添加到任务池之前，使用各种措施对其进行修剪；针对许多交互重复此过程，直到生成大量任务。<br />
</li>
<li>模型结构：Decoder结构。<br />
</li>
<li>数据和模型规模：以GPT-3作为基础，产生大约 52k 条指令，与大约 82k
实例输入和目标输出配对。<br />
</li>
<li>亮点：需要更少的人工标注数据<br />
</li>
<li>详见：<a
href="/1_Note/2_算法/2_大模型/论文阅读_Self_instruct">论文阅读_Self_instruct</a><br />
</li>
<li>论文地址：<a href="http://arxiv.org/abs/2212.10560">Self-Instruct:
Aligning Language Model with Self Generated Instructions</a></li>
</ul>
<h4 id="llama">4.2.3 LLaMA</h4>
<ul>
<li>发布时间：2023-02-27（论文发布时间）<br />
</li>
<li>解决问题：开源项目，以小取胜。使用更多token训练，更少的模型参数。其小模型可以运行在单GPU环境下，65B大模型可与<strong>PaLM模型</strong>效果竞争。<br />
</li>
<li>方法：大模型在Few
Shot上表现好，主要归功于大模型的参数量。本文至力于找到合适的数据量和参数量，以实现快速推理。调整模型结构，提升训练和预测速度。<br />
</li>
<li>模型结构：Decoder结构。<br />
</li>
<li>数据和模型规模：模型从7B-65B参数，使用T级别token训练。在训练 65B
参数模型时，代码在具有 80GB RAM 的 2048 A100 GPU。对包含 1.4T
令牌的数据集进行训练大约需要 21 天。<br />
</li>
<li>详见：<a
href="/1_Note/2_算法/2_大模型/论文阅读_LLaMA">论文阅读_LLaMA</a><br />
</li>
<li>论文地址：<a href="https://arxiv.org/abs/2302.13971">LLaMA: Open and
Efficient Foundation Language Models</a></li>
</ul>
<h4 id="colossalchat">4.2.4 ColossalChat</h4>
<ul>
<li>发布时间：2023-02-15<br />
</li>
<li>解决问题：开源完整 <strong>RLHF</strong>
训练代码，已开源含7B、13B两种模型。体验最小 demo 训练流程最低仅需 1.62GB
显存，任意单张消费级 GPU 即可满足。<br />
</li>
<li>方法：以Meta最新开源的LLaMA为基础预训练模型。用于通过完整的RLHF管道克隆ChatGPT。该管道包括监督数据收集、监督微调、奖励模型训练和强化学习微调，基于LLaMA预训练模型。它只需要不到10B个参数，就可以通过RLHF微调在中英文双语能力方面达到与ChatGPT和GPT-3.5相似的效果。<br />
</li>
<li>模型结构：同 LLaMA<br />
</li>
<li>数据和模型规模：英双语数据集，训练的英文一共 24M tokens，中文大约
30M tokens，总共约 54M
tokens。4bit量化推理70亿参数模型仅需4GB显存。<br />
</li>
<li>详见：<a href="https://github.com/hpcaitech/ColossalAI">源码地址</a>
24.3K star</li>
</ul>
<h4 id="dolly">4.2.5 Dolly</h4>
<ul>
<li>发布时间：2023-03-24（韩国公司）<br />
</li>
<li>解决问题：Dolly是一个低成本的LLM，它采用LLaMA为基础，是具有60亿参数的开源模型。通过指令精调，使其具有了类似于ChatGPT的交互性。可以自己下载训练，开发成本仅需30美元，且开源。<br />
</li>
<li>方法：对模型进行细微的修改，以激发服从指令的能力。斯坦福大学基于LLaMA构建了Alpaca，但不同之处在于，它利用一个包含50,000个问题和答案的小数据集进行了微调。即便对一个开源大型语言模型
GPT-J，也能通过30分钟的训练，赋予它神奇的类似ChatGPT的指令跟随能力。<br />
</li>
<li>模型结构：同 LLaMA<br />
</li>
<li>数据和模型规模：使用包含50,000个问题和答案的小数据集进行了微调。<br />
</li>
<li>详见：<a href="https://www.oschina.net/p/dolly">Dolly 低成本生成式
AI</a></li>
</ul>
<h3 id="openai">4.3 OpenAI</h3>
<p>OpenAI 的 GPT-4
无疑是目前最好的大语言模型，从GPT到GPT-4一路走来，ChatGPT爆发，可能是我们这个时代最重要的事件之一。可能是为了保持领先，OpenAI
逐渐转换策略，不再公开具体技术，常被讽 CloseAI。<br />
最初坚持使用单向Transformer构造大模型，现在看的确很有眼光，ChatGPT比GPT-3便宜10倍的价值，抢先占领市场，这个策略可能也是合理的。<br />
而AI、语言模型发展到今天，也是互联网数据，软硬件，深度学习，强化学习各个领域近年高速发展和开源的结果。个人认为：无论谁都不太可能一家独大。</p>
<h4 id="gpt-gpt3.5">4.3.1 GPT-GPT3.5</h4>
<ul>
<li>详见：<a href="https://zhuanlan.zhihu.com/p/609716668">GPT / GPT-2 /
GPT-3 / InstructGPT 进化之路</a></li>
</ul>
<h4 id="gpt-4">4.3.2 GPT-4</h4>
<ul>
<li>发布时间：2023-03-14<br />
</li>
<li>解决问题：评测了GPT-4：一个大规模的多模态模型，可以接受图像和文本输入并产生文本输出。提升了<strong>利用知识去解决具体问题</strong>的能力。对于非常复杂的指令，GPT-4的理解能力和创造力远超3.5。<br />
</li>
<li>方法：模型训练具体使用了互联网数据和一些三方版权数据。然后使用<strong>人类反馈强化学习
(RLHF)</strong> 对模型进行微调。<br />
</li>
<li>模型结构：延续了GPT-3的结构<br />
</li>
<li>数据和模型规模：报告不包含关于架构(包括模型尺寸)、硬件、训练计算、数据集构建、训练方法或类似的更多细节。<br />
</li>
<li>亮点：实验结果<br />
</li>
<li>详见：<a
href="/1_Note/2_算法/2_大模型/论文阅读_GPT-4">论文阅读_GPT-4</a><br />
</li>
<li>论文地址：<a href="https://arxiv.org/abs/2303.08774">GPT-4 Technical
Report</a></li>
</ul>
<h3 id="清华">4.4 清华</h3>
<p>2022年11月，斯坦福大学大模型中心对全球30个主流大模型进行了全方位的评测，GLM-130B
是亚洲唯一入选的大模型。 它准确性和恶意性指标上与 GPT-3 175B (davinci)
接近或持平。<br />
ChatGLM是GLM公开的单机版本，基本是开包即用，又是中英文双语训练的模型，对中文用户比较友好。</p>
<h4 id="glm-1">4.4.1 GLM</h4>
<ul>
<li>发布时间：2022-01-01<br />
</li>
<li>解决问题：通过在结构上的调整，结合了GPT和BERT类模型的优点，且模型规模和复杂度没有提升。将NLU任务转换成生成任务训练模型，使上下游任务训练方式保持一致。<br />
</li>
<li>方法：没有一个预训练框架对自然语言理解
(NLU)、无条件生成和条件生成这三个主要类别的所有任务表现都好。GLM
基于自回归空白填充来解决这一挑战。使用了二维的位置编码，相对于T5模型有更少的参数，差不多的效果。一个模型同时支持NLU和文本生成，所以是多任务的训练。<br />
</li>
<li>模型结构：GLM基于自回归的空白填充。从输入文本中随机删除连续的token(自编码)，并训练模型以顺序重建删除的token(自回归)。<br />
</li>
<li>数据和模型规模：使用BERT/RoBERT
几种模型大小相同的数据训练模型，以保证对比的公平性。<br />
</li>
<li>详见：<a
href="/1_Note/2_算法/2_大模型/论文阅读_GLM">论文阅读_GLM</a><br />
</li>
<li>论文地址：<a href="https://aclanthology.org/2022.acl-long.26">GLM:
General Language Model Pretraining with Autoregressive Blank
Infilling</a></li>
</ul>
<h4 id="chatglm">4.4.2 ChatGLM</h4>
<ul>
<li>发布时间：2023-01-01<br />
</li>
<li>解决问题：开源，并针对中文进行了优化，尤其是可以在自己的机器上搭建其简版的int4服务，实测回答一般性问题效果还不错。<br />
</li>
<li>方法：ChatGLM是使用中英双语预训练的大语言模型，在稳定性和性能方面进行了调优。在模型结构上结合了GPT和BERT。在英文方面，效果优于GPT-3；在中文方面，优于260B参数的ERNIE
TITAN 3.0。可在4×RTX 3090 (24G) 或 8×RTX 2080 Ti (11G) GPUs
环境下运行。<br />
不仅包括自监督的GLM自回归空白填充，还包括对小部分token的多任务学习，以提升其下游zero-shot任务的性能。<br />
</li>
<li>模型结构：同GLM。<br />
</li>
<li>数据和模型规模：具有130B参数（1300亿），包括1.2 T英语、1.0
T的中文悟道语料库，以及从网络爬取的250G中文语料库(包括在线论坛、百科全书和QA)，形成了平衡的英汉内容构成。<br />
</li>
<li>亮点：搭建方法<br />
</li>
<li>详见：<a
href="/1_Note/2_算法/2_大模型/论文阅读_ChatGLM">论文阅读_ChatGLM</a><br />
</li>
<li>论文地址：<a href="https://arxiv.org/abs/2210.02414">GLM-130B: AN
OPEN BILINGUAL PRE-TRAINED</a></li>
</ul>
<h3 id="deepmind">4.5 DeepMind</h3>
<p>DeepMind
围绕提升模型性能展开研究，其研究为后继的模型精减和优化，和更广阔的使用场景奠定了基础。</p>
<h4 id="gopher">4.5.1 Gopher</h4>
<ul>
<li>发布时间：2021-12-08<br />
</li>
<li>解决问题：经过实验得出结论：任何学术科目，连同一般知识，通过模型改进模型规模都能提升其效果，但规模对逻辑推理、常识和数学任务的好处较少。<br />
</li>
<li>方法：DeepMind 训练了 6 个不同大小的模型，从 44M 参数到 280B 参数的
Gopher 模型，进行比较，他们在一组 152 个任务上评估了模型，Gopher 打破了
100 项记录。<br />
</li>
<li>模型结构：Decoder结构。<br />
</li>
<li>数据和模型规模：10.5TB语料库上进行训练，280 B参数。<br />
</li>
<li>详见： <a
href="https://www.zhihu.com/question/504961275">如何评价DeepMind全新的语言模型
Gopher 及其 Gopher 家族？</a><br />
</li>
<li>论文地址：<a href="https://arxiv.org/abs/2112.11446">Scaling
Language Models: Methods, Analysis &amp; Insights from Training
Gopher</a></li>
</ul>
<h4 id="chinchillla">4.5.2 Chinchillla</h4>
<ul>
<li>发布时间：2022-03-29<br />
</li>
<li>解决问题：针对训练数据量，模型参数量，以及数据训练量，得出结论：更长的训练时间，更多token，能提升模型效果；大模型的参数量和性能之间存在幂律分布。<br />
</li>
<li>方法：在 5 到 5000 亿个标记上训练 400 多个语言模型，范围从 7000
万到超过 160
亿个参数，把参数量和数据规模加入Loss的惩罚。<strong>在运算量固定的情况下，如何选择参数和token量的配比，使损失函数最小</strong>；它对Gopher的进行调整，将模型大小变为其1/4，token变为其4倍，与Gopher计算量基本一致。<br />
</li>
<li>模型结构：同Gopher<br />
</li>
<li>数据和模型规模：10.5TB语料库上进行训练，70B模型参数。<br />
</li>
<li>详见：<a
href="/1_Note/2_算法/2_大模型/论文阅读_Chinchilla">论文阅读_Chinchilla</a><br />
</li>
<li>论文地址：<a href="http://arxiv.org/abs/2203.15556">Training
Compute-Optimal Large Language Models</a></li>
</ul>
<h3 id="microsoft">4.6 MicroSoft</h3>
<p>本月微软发布的两篇文章（2023年03月），相对偏具体的应用场景，以及语言模型和其它（如图片）数据相结合实现的应用效果，尽管把文本和图本映射到同一嵌入空间；通过调整提示调用ChatGPT和图像修改工具，并不是首次提出，但是实现的效果还是很炫酷有趣的。</p>
<h4 id="visual-chatgpt">4.6.1 Visual ChatGPT</h4>
<ul>
<li>发布时间：2023-03-08<br />
</li>
<li>解决问题：在ChatGPT和图像构建方法间做了桥接，和其它模型相比，除了利用大语言模型中的知识，还利用了ChatGPT强化学习带来的能力，<br />
</li>
<li>方法：主要对聊天的场景进行优化，在提示上作文章。即：在ChatGPT外边包了一层，这也是当前最常见的用法，文章偏工程化的具体实现。将CoT的潜力扩展到大规模任务，包括但不限于文本生成高清图像、图像到图像的翻译、图像到文本的生成等。<br />
</li>
<li>模型结构：主要组合调用现有模型，设计了一个Prompt
Manager，其中涉及22个不同的虚拟功能矩阵，并定义了它们之间的内部关联，以便更好地交互和组合。<br />
</li>
<li>数据和模型规模：(OpenAI “text-davinci-003” version)<br />
</li>
<li>详见：<a
href="/1_Note/2_算法/2_大模型/论文阅读_Visual_ChatGPT">论文阅读_Visual_ChatGPT</a><br />
</li>
<li>论文地址：<a href="http://arxiv.org/abs/2303.04671">Visual ChatGPT:
Talking, Drawing and Editing with Visual Foundation Models</a></li>
</ul>
<h4 id="kosmos-1">4.6.2 Kosmos-1</h4>
<ul>
<li>发布时间：2023-03-01<br />
</li>
<li>解决问题：主要研究视觉和文本领域的对齐，具体应用是看图回答问题。KOSMOS
-
1是一种多模态语言模型，能够感知通用模态、遵循指令、在语境中学习并产生输出。<br />
</li>
<li>方法：也没太说具体是怎么做的，主要是提出概念，展示能力。<br />
</li>
<li>模型结构：包含单模态数据和多模态数据。使用单模态数据进行表示学习。例如，利用文本数据进行语言建模预训练指令跟随、语境学习、各种语言任务等。此外，用跨模态对和交错数据学习将一般模态的感知与语言模型对齐。<br />
</li>
<li>数据和模型规模：1.3 B的参数。<br />
</li>
<li>亮点：应用场景：回答图片智力题，直接OCR <a
href="/1_Note/2_算法/2_大模型/论文阅读_Kosmos-1">论文阅读_Kosmos-1</a><br />
</li>
<li>详见：<a
href="/1_Note/2_算法/2_大模型/论文阅读_Kosmos-1">论文阅读_Kosmos-1</a><br />
</li>
<li>论文地址：<a href="http://arxiv.org/abs/2302.14045">Language Is Not
All You Need: Aligning Perception with Language Models</a></li>
</ul>
<h3 id="其它大模型">4.7 其它大模型</h3>
<p>还有一些大语言模型也有着里程碑的意义，比如：MT-NLG
530B，当时首次把模型扩展到
500+B的量级，示范了训练单体超大模型的方法；又如 BLOOM
是一个开放的模型，任何人都可以从Hugging
Face网站免费下载它进行研究。它们也常常在其它文章中用作模型对比的基线。</p>
<h4 id="megatronturing-nlg威震天-图灵mt-nlg-530b">4.7.1 Megatron–Turing
NLG（威震天-图灵，MT-NLG 530B）</h4>
<ul>
<li>发布时间：2021年10月<br />
</li>
<li>解决问题：英伟达和微软合作训练模型，示范了训练单体超大模型的方法，<br />
</li>
<li>方法：4480块A100训练，DeepSpeed &amp; Megatron
三维并行训练技术。DeepSpeed
是一个深度学习优化库，让分布式训练变得简单、高效且有效，Megatron-LM 是由
NVIDIA 的应用深度学习研究团队开发的大型、强大的 transformer
模型框架。<br />
</li>
<li>模型结构：Decoder结构。<br />
</li>
<li>数据和模型规模：530 B 参数<br />
</li>
<li>论文地址：<a href="https://arxiv.org/pdf/2201.11990v2.pdf">Using
DeepSpeed and Megatron to Train Megatron-Turing NLG<br />
530B, A Large-Scale Generative Language Model</a></li>
</ul>
<h4 id="bloom">4.7.2 BLOOM</h4>
<ul>
<li>发布时间：模型的训练于 2022 年 3 月至 7 月期间，耗时约 3.5
个月完成，在2022年11月上传arxiv。<br />
</li>
<li>解决问题：Hugging Face 联合创始人发起，多方联合，BigScience
的研究人员发布的开源模型。BLOOM最大的特点在于可访问性，任何人都可以从Hugging
Face网站免费下载它进行研究。<br />
</li>
<li>方法：Megatron &amp; DeepSpeed 训练。<br />
</li>
<li>模型结构：Decoder结构。<br />
</li>
<li>数据和模型规模： 176 B参数，1.5TB
经过大量去重和清洗的文本，<strong>包含 46 种语言</strong>，最终转换为
350B token。<br />
</li>
<li>详见：<a
href="https://zhuanlan.zhihu.com/p/603518061">【自然语言处理】【大模型】BLOOM：一个176B参数且可开放获取的多语言模型</a><br />
</li>
<li>论文地址：<a href="https://arxiv.org/pdf/2211.05100.pdf">BLOOM: A
176B-Parameter Open-Access Multilingual<br />
Language Model</a></li>
</ul>
<h2 id="收获总结">5 收获总结</h2>
<ul>
<li>GPT-3不再需要精调，解决few-shot问题效果好，只使用decoder<br />
</li>
<li>chain-of-thought(CoT) prompting
链式思维提示学习，用于提升模型推理能力<br />
思维链提示（2022年提出的一种方法）。<br />
</li>
<li>个人觉得对问题公式化的能力（数学推理），以及对世界的认知（常识推理），相对生成模型（生成一段文字/图片)，更为重要。<br />
</li>
<li>Self-Instruction可以被看作是一种知识蒸馏。<br />
</li>
<li>LM
的最大收益对应于语言的频繁使用（语言使用分布的头部），而在低频上下文中的收益最小。在不常见和创造性的指令方面表现出脆弱性。<br />
</li>
<li>为什么基于树的模型在表格数据上的性能仍然优于基于深度学习的模型？<br />
<a href="https://arxiv.org/abs/2207.08815">Why do tree-based models
still outperform deep learning on tabular data?</a><br />
</li>
<li>在大型语言模型中，token数指的是训练数据中的token总数。如果训练数据包含100万个单词和标点符号，则token数为100万。和GPT-3按token收钱的token是一个意思。<br />
</li>
<li>混合专家模型：mixture-of-expert (MoE)
models：使用多个专家网络（学习器）将问题空间划分为同质区域。<strong>后期的模型可能是这个思路</strong></li>
</ul>
<h2 id="其它想法">6 其它想法</h2>
<ul>
<li>以大语言模型为核心的多模态模型可能是下一个热点。从LLM到MLLMs，估计这个概念提出之后，又扩展了LLM的用武之地，除了理解语言作为“全知”，还能理解图片，视频，语音，行为，传感器从各个角度描述的真实世界……</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">读这篇的时候还有个小乌龙：没注意那Question，只看到了图片和回答，感觉不止是回答出正确答案，还能知道你想问什么？一瞬间引起了我&quot;极大的不适&quot;感，感觉内心被窥探了。但是往深了想，用大量 text/image pair 训练模型，是可以实现这个目标的，不是吗？  </span><br><span class="line">再想想，那些通讯软件平台，里面有大量的聊天，文本，图片记录，那可不止是只个亿的数据了，如果用这些去训练模型，又会怎么样？  </span><br><span class="line">当我们其中的一部分人插上了AI的翅膀，会怎么样？的确是又一次被震撼了。  </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_GLaM</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_GLaM/</url>
    <content><![CDATA[<p>name_ch: GLaM：使用混合专家有效扩展语言模型<br />
name_en: GLaM：Efficient Scaling of Language Models with
Mixture-of-Experts<br />
paper_addr: http://arxiv.org/abs/2112.06905<br />
journal: ICML 2022（会议）<br />
date_publish: 2022-08-01</p>
<h2 id="读后感">读后感</h2>
<p>针对节约计算资源的研究，推进了针对细分专家领域。<br />
一种混合专家（MoE）模型，可以将其视为具有不同子模型（或专家）的模型，每个子模型都专门针对不同的输入。每层中的专家由门控网络控制，该网络根据输入数据激活专家。</p>
<h2 id="摘要">摘要</h2>
<p>文中提出 GLaM (Generalist Language Model)
通用语言模型，它使用稀疏激活的专家混合架构来扩展模型容量，同时与密集变体相比，训练成本也大大降低，其中输入批次中的每个标记仅激活
96.6B（1.2T 的 8%）参数的子网络。<br />
最大的 GLaM 有 1.2 万亿个参数，大约是 GPT-3 的 7 倍。它仅消耗用于训练
GPT-3 的 1/3 的能量，并且只需要一半的计算触发器来进行推理。</p>
<h2 id="介绍">介绍</h2>
<p><strong>算力和效果</strong></p>
<figure>
<img src="/attachments_2023/Pasted%20image%2020230326095636.png"
alt="|400" />
<figcaption aria-hidden="true">|400</figcaption>
</figure>
<p><strong>模型结构对比</strong><br />
<img src="/attachments_2023/Pasted%20image%2020230326103438.png"
alt="|400" /></p>
<h2 id="训练数据">训练数据</h2>
<p>使用1.6T
token，开发了自己的文本质量分类器，以从大型原始语料库中生成高质量的网络语料库。通过使用
Pareto 分布根据网页的分数对网页进行抽样来应用此分类器。<br />
数据如下图所示：<br />
<img src="/attachments_2023/Pasted%20image%2020230326104707.png"
alt="|400" /></p>
<h2 id="模型结构">模型结构</h2>
<p><img
src="/attachments_2023/Pasted%20image%2020230326104945.png" /><br />
每个 MoE 层（底部灰块）与 Transformer
层（上部块）交错。对于每个输入token，例如“玫瑰”，门控模块从 64
个专家中动态选择两个最相关的专家，由 MoE
层中的蓝色网格表示。这两个专家的输出的加权平均值将被传递到上层的
Transformer
层。专家是被稀疏激活的，从而节约了计算资源。在推理阶段，同样是针对每个token选择两个专家。</p>
<h2 id="实验">实验</h2>
<p>作者训练规模不同的多个GLaM模型，并在Zero/Few Shot,
自然语言生成(NLG)，自然语言理解(NLU)等任务中评测了模型。</p>
<p>模型效果对比：<br />
<img
src="/attachments_2023/Pasted%20image%2020230326101518.png" /><br />
没有注入知识图，仅是从当前信息里直接学习。</p>
<p>实验还对比了根据质量筛选数据对模型训练的影响。过滤后的网页包含 143B
个token，而未过滤的网页包含大约 7T
个token。图-3(c)(d)展示了过滤前后的对比，说明有些任务需要高质量的数据训练。</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230326112533.png" /></p>
<p>图-3的(a)(b)展示了，在各种计算量条件下，MoE都表现出相对稠密模型更好的效果。</p>
<p>模型名称定义如下表所示，E表示专家个数。<br />
<img src="/attachments_2023/Pasted%20image%2020230326113657.png" /></p>
<p>图-4展示了模型效果和效率：<br />
<img
src="/attachments_2023/Pasted%20image%2020230326113837.png" /><br />
从左边三个图可以看出，达到相同效果稀疏模型需要的token更少，且稀疏模型优于稠密模型。从右边的图也可以看到稀疏模型有效节约了资源。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_GPT-4</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_GPT-4/</url>
    <content><![CDATA[<p>name_ch: GPT-4技术报告<br />
name_en: GPT-4 Technical Report<br />
paper_addr: https://arxiv.org/abs/2303.08774<br />
date_publish: 2023-03-14</p>
<h2 id="摘要">摘要</h2>
<p>评测了GPT-4：一个大规模的多模态模型，可以接受图像和文本输入并产生文本输出。<br />
GPT-4 是一种基于 Transformer
的模型，它延续了GPT-3的结构，经过预训练可以预测文档中的下一个token。训练后的<strong>对齐过程</strong>可提高<strong>真实性和遵守</strong>所需行为的措施的性能。</p>
<h2 id="介绍">介绍</h2>
<p>当前大语言模型的主要目标是提高模型<strong>理解和生成</strong>自然语言文本的能力，尤其是在<strong>更复杂和微妙</strong>的场景中。<br />
模型在评估中多数<strong>超过绝大多数</strong>人类测试者，在这方面明显优于GPT-3.5。尽管GPT-4生成的文本仍然不太可靠（提升了<strong>利用知识去解决具体问题</strong>的能力）。<br />
模型训练具体使用了互联网数据和一些三方版权数据。然后使用<strong>人类反馈强化学习
(RLHF)</strong>
对模型进行微调。本报告不包含关于架构(包括模型尺寸)、硬件、训练计算、数据集构建、训练方法或类似的更多细节。</p>
<h2 id="方法">方法</h2>
<h3 id="预测可扩展性">预测可扩展性</h3>
<p>GPT-4
项目的一大重点是构建<strong>可预测扩展的深度学习堆栈</strong>。开发了基础设施和优化方法，这些方法在多个尺度上具有可预测的行为，使计算量缩小了1000-10000倍。<br />
用小模型来预测某些参数组合下对应大模型的某种能力，如果预测足够精准，能够极大缩短炼丹周期，同时极大减少试错成本。</p>
<h4 id="预测损失">预测损失</h4>
<p>计算量和模型的最终损失之间存在幂律关系。用此方法可以高精度地预测
GPT-4 的最终损失。<br />
<img
src="/attachments_2023/Pasted%20image%2020230329174400.png" /><br />
图中X轴用GPT-4做了归一化，p、n、μ是计量单位的前缀，表示10的负12次方、负9次方和负6次方。</p>
<h4 id="预测-humaneval-上的能力扩展">预测 HumanEval 上的能力扩展</h4>
<p>除了预测模型的损失，还想在训练前评估模型的其它能力。GPT-4提出了HumanEval数据集，由164个编码问题组成，测试了编程逻辑和熟练程度的各个方面，将它作为另一个性能指标，并在训练之前对模型在HumanEval上的水平进行预测。同样也发现了类似幂律分布的情况。<br />
<img src="/attachments_2023/Pasted%20image%2020230329180539.png" /></p>
<h2 id="模型能力">模型能力</h2>
<p>对于非常复杂的指令，GPT-4的理解能力和创造力远超3.5。</p>
<p>GPT-3.5与GPT-4在各种考试中得分比较<br />
<img
src="/attachments_2023/Pasted%20image%2020230329181311.png" /><br />
详见表-1。</p>
<p>表-2列出了一些常用的自然语言评测方法，其中MMLU几乎是最常用的一个，GPT-4在其上的得分，是其它模型无法比拟的。<br />
<img
src="/attachments_2023/Pasted%20image%2020230329181459.png" /><br />
在MMLU测试英语以外的其它语种分数也非常高：<br />
<img src="/attachments_2023/Pasted%20image%2020230329181740.png" /></p>
<p>图-3还示例了将图片和文本作为输入，通过解释图中的幽默之处，展示了GPT-4对图的解释和推理能力。</p>
<p>图-6展示了GPT-4生成的文本真实性的测试，明显高于最新版本的chatGPT。<br />
<img src="/attachments_2023/Pasted%20image%2020230329182318.png" /></p>
<p>图-8还展示了预训练和强化学习后的校准曲线，可以看到强化学习后的分布与原始分布不再一致。<br />
<img src="/attachments_2023/Pasted%20image%2020230329182704.png" /></p>
<h2 id="个人总结">个人总结</h2>
<h3 id="gpt-4-优势">GPT-4 优势</h3>
<ul>
<li>支持多模态<br />
</li>
<li>更擅长解决问题<br />
</li>
<li>更高的“事实性、可控性”<br />
</li>
<li>可使用更小计算量精调模型</li>
</ul>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_Kosmos-1</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_Kosmos-1/</url>
    <content><![CDATA[<p>name_ch: 语言并非你所需要的全部：让感知与语言模型保持一致<br />
name_en: Language Is Not All You Need：Aligning Perception with Language
Models<br />
paper_addr: http://arxiv.org/abs/2302.14045<br />
code: https://github.com/microsoft/unilm<br />
date_publish: 2023-03-01</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230312063638.png" /></p>
<h2 id="读后感">读后感</h2>
<p>文章主要研究视觉和文本领域的对齐，具体应用是看图回答问题。<br />
文中做了大量工具，在评测部分可以看到它在多领域多个数据集上对模型进行了评测，很多领域做了尝试。文中也没太说具体是怎么做的，主要是提出概念，展示能力。<br />
<img src="/attachments_2023/Pasted%20image%2020230312071054.png" /></p>
<h2 id="摘要">摘要</h2>
<p><strong>KOSMOS -
1是一种多模态语言模型，能够感知通用模态、遵循指令、在语境中学习并产生输出。</strong></p>
<blockquote>
<p>The limits of my language means the limits of my world.<br />
Ludwig Wittgenstein</p>
</blockquote>
<p>作者还引用了一句话：我的语言的极限意味着我的世界的极限。</p>
<p>KOSMOS-1的优势：<br />
* 语言理解，生成，甚至OCR - free NLP (直接以文档图像为输入)<br />
* 感知语言任务，包括多模态对话，图像描述，视觉问答<br />
*
视觉任务，如(通过文本指令指定分类)描述的图像识别上取得了令人印象深刻的性能。</p>
<h2 id="介绍">介绍</h2>
<p>文中提出了三种新的拓展：<br />
* 从LLM到MLLMs：更自然的交互方式<br />
* 将语言作为通用接口<br />
* MLLMs提供的新能力</p>
<h2 id="kosmos-1-多模态自然语言模型">KOSMOS-1 多模态自然语言模型</h2>
<h3 id="输入表示">输入表示</h3>
<p>数据描述：<br />
<img
src="/attachments_2023/Pasted%20image%2020230312083622.png" /><br />
将嵌入信息送入解码器。对于输入令牌，使用查找表将其映射为嵌入。<br />
使用重采样器作为注意力池化机制，减少图像嵌入次数。</p>
<h3 id="多模态大语言模型">多模态大语言模型</h3>
<p>使用TorchScale底层库，MAGNETO和xPOS技术。</p>
<h3 id="训练对象">训练对象</h3>
<p>包含单模态数据和多模态数据。使用单模态数据进行表示学习。例如，利用文本数据进行语言建模预训练指令跟随、语境学习、各种语言任务等。此外，用跨模态对和交错数据学习将一般模态的感知与语言模型对齐。</p>
<h2 id="训练">训练</h2>
<h3 id="多模态训练数据">多模态训练数据</h3>
<h4 id="文本">文本</h4>
<p>见附录B.1.1</p>
<h4 id="文本数据对">文本数据对</h4>
<p>见附录B.1.2</p>
<h4 id="交错的图文数据">交错的图文数据</h4>
<p>见附录B.1.3</p>
<h3 id="训练设计">训练设计</h3>
<p>MLLM组件有24层，隐藏维度为2048，FFN中间尺寸为8192，注意力头为32，产生约1.3
B的参数。<br />
图像表示从一个预训练的CLIP
ViT-L/14模型中获得，该模型具有1024个特征维度。</p>
<h3 id="纯语言指令调优">纯语言指令调优</h3>
<p>使用Unnatural
Instructions和FLANv2数据进行指令调优，以使模型更好拟合人的指令（instructions）。<br />
具体见附录A.2。</p>
<h2 id="评测">评测</h2>
<p>分别在自然语言任务，交叉模态转换，非言语推理，语言感知和视觉任务中对模型进行评测。</p>
<h3 id="语言感知任务">语言感知任务</h3>
<p>主要针对图像描述和看图回答问题。</p>
<h3 id="智力测试非语言推理">智力测试（非语言推理）</h3>
<p><img
src="/attachments_2023/Pasted%20image%2020230312091451.png" /><br />
虽然分不高，但是明显比随机回答（瞎蒙）要好。</p>
<h3 id="不使用ocr的自然语言理解">不使用OCR的自然语言理解</h3>
<p>不使用OCR技术，直接理解图片中的文本。</p>
<h3 id="根据网页回答问题">根据网页回答问题</h3>
<p>略……</p>
<h3 id="多模态思维链提示">多模态思维链提示</h3>
<p>生成一系列推理步骤，并将多步问题分解成中间步骤，可以显著提高问题的求解效率。</p>
<h3 id="zero-shot-图像分类">Zero-Shot 图像分类</h3>
<h3 id="带描述的-zero-shot图像分类">带描述的 Zero-Shot图像分类</h3>
<p>提供上下文描述可以显著提高图像分类的准确率。<br />
<img src="/attachments_2023/Pasted%20image%2020230312092650.png" /></p>
<h3 id="自然语言任务">自然语言任务</h3>
<p>与LLM水平差不多</p>
<h3 id="模态转换任务">模态转换任务</h3>
<h4 id="语言到多模态">语言到多模态</h4>
<p>利用语言指令调优，提升其它模态的认识水平。</p>
<h4 id="多模态到语言">多模态到语言</h4>
<p>利用视觉常识推理，将视觉知识迁移到语言任务中。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_LLaMA</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_LLaMA/</url>
    <content><![CDATA[<p>name_ch: LLaMA：开放高效的基础语言模型<br />
name_en: LLaMA：Open and Efficient Foundation Language Models<br />
paper_addr: https://arxiv.org/abs/2302.13971<br />
code: https://github.com/facebookresearch/llama<br />
date_publish: 2023-02-27</p>
<h2 id="读后感">1 读后感</h2>
<p>开源项目，以小取胜。使用更多token训练，更少的模型参数。其小模型可以运行在单GPU环境下，65B大模型可与<strong>PaLM模型</strong>效果竞争；主要技术包含：调整了模型结构，加速了训练和推理。</p>
<h2 id="摘要">2 摘要</h2>
<p>论文展示了仅使用公开可用的数据集来训练最先进的模型，而无需诉诸专有和不可访问的数据集。模型从7B-65B参数，使用T级别token训练。LLaMA-13B模型效果超越了GPT-3(175B)模型。LLaMA-65B模型可与当前最好模型竞争。</p>
<h2 id="介绍">3 介绍</h2>
<p>大模型在Few
Shot上表现好，主要归功于大模型的参数量。本文至力于找到合适的数据量和参数量，以实现快速推理。</p>
<h2 id="方法">4 方法</h2>
<h3 id="预测训练数据">4.1 预测训练数据</h3>
<figure>
<img src="/attachments_2023/Pasted%20image%2020230325094818.png"
alt="|400" />
<figcaption aria-hidden="true">|400</figcaption>
</figure>
<h3 id="模型结构">4.2 模型结构</h3>
<p>模型基于Transformer结构，与其它框架主要有以下差别（基本都是2019-2021年，其它模型用过的技术）：<br />
* 预归一化：<br />
使用RMSNorm对每个 transformer
子层的输入进行归一化，而不是对输出进行归一化，以提升稳定性。<br />
* SwiGLU激活函数：<br />
使用SwiGLU代替ReLU激活函数。<br />
* 位置嵌入：<br />
在网络的每一层，删除了绝对位置嵌入，添加旋转位置嵌入。</p>
<h3 id="优化">4.3 优化</h3>
<p>模型规模如下：<br />
<img src="/attachments_2023/Pasted%20image%2020230325100715.png"
alt="|500" /></p>
<h3 id="高效实施">4.4 高效实施</h3>
<p>使用因果多头注意力算子的高效实现，减少了内存使用和计算。为进一步提高训练效率，减少了在带有检查点的反向传播过程中重新计算的激活量（替代了Pytorch
autograd）。通过使用模型和序列并行性减少模型的内存使用。此外，还尽可能多地重叠激活计算和
GPU 之间的网络通信。<br />
在训练 65B 参数模型时，代码在具有 80GB RAM 的 2048 A100 GPU。对包含 1.4T
令牌的数据集进行训练大约需要 21 天。</p>
<h2 id="主实验">5 主实验</h2>
<p>针对Zero-shot和Few-shot任务评测，以下是对阅读理解的评测，可以看到大模型和小模型对这类问题处理差别不大：<br />
<img src="/attachments_2023/Pasted%20image%2020230325102708.png"
alt="|400" /><br />
对下述功能进行了评测，不在此抓图说明，结果就是其65B模型和PalM540模型效果差不多，很多评测效果还更好。<br />
* 标准常识推理 (8个)<br />
* 闭卷答疑（2个）<br />
* 阅读理解（1个）<br />
* 数学推理（2个）谷歌的Minerva模型针对数学训练，效果更好<br />
* 代码生成（2个）<br />
*
大规模多任务语言理解。由​​多项选择题组成，涵盖各个知识领域，包括人文、STEM
和社会科学。在此评测中PaLM明显更好，可能因为训练它的语料更多。</p>
<p>可以看到token越多，训练效果越好：<br />
<img src="/attachments_2023/Pasted%20image%2020230325104034.png"
alt="|400" /></p>
<h2 id="指令微调">6 指令微调</h2>
<p>通过精调训练了一个引导模型
LLaMA-I，对于<strong>MMLU</strong>(57种主题的多选题)评测数据对比结果如下：<br />
<img src="/attachments_2023/Pasted%20image%2020230325104905.png"
alt="|400" /><br />
(据说GPT-4能达到86.4%)</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_MAE</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_MAE/</url>
    <content><![CDATA[<p>name_ch: 带遮蔽的自编码器是大规模的视觉学习者<br />
name_en: Masked Autoencoders Are Scalable Vision Learners<br />
others: MAE 论文逐段精读
https://www.bilibili.com/video/BV1sq4y1q77t/?spm_id_from=333.337.search-card.all.click&amp;vd_source=eef058f284e51ad4598d556801a9fc84<br />
paper_addr: https://ieeexplore.ieee.org/document/9879206/<br />
journal: 2022 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)<br />
date_publish: 2022-06-01</p>
<h2 id="读后感">读后感</h2>
<p>图像领域的<strong>无监督学习</strong>，延续ViT使用Transformer结构<a
href="/1_Note/2_算法/8_图形图像/论文阅读_ViT">论文阅读_ViT</a>，学习BERT遮蔽图片块，然后预测被遮蔽的块实现自我学习autoencoder。<br />
ViT论文最后也做过类似实验，但效果并不好，MAE对此做了一些修改：<strong>遮住更多的图片块</strong>，这是由于相对于文本，图像中存在更多冗余信息；编码时只处理没遮住的部分，从而节约了算力；另外，使用与Encoder不对称的<strong>轻量级</strong>Decoder来预测遮住的块。</p>
<h2 id="介绍">介绍</h2>
<p>MAE是Masked
Autoencoders的缩写，是一种用于计算机视觉的<strong>自监督学习方法</strong>。在MAE方法中，会随机mask输入图片的部分patches，然后重构这些缺失的像素。其主要技术基于ViT和BERT。</p>
<p>和ViT一样，先将图片切分成大小一致（一般是16x16）的Patch，遮住其中75%（图中灰色部分）；然后对没遮住的块进行编码，生成隐空间表示（蓝色列，下游应用使用的就是这一步的结果），然后用隐空间预测被遮住的块，以还原图像，逐步调优使模型更好地预测遮住的块，以实现不需要标注的自我学习。</p>
<h3 id="模型结构">模型结构</h3>
<p><img
src="/attachments_2023/Pasted%20image%2020230408163531.png" /></p>
<h3 id="效果展示">效果展示</h3>
<p>第一列是被部分遮蔽的图，第二列是MAE恢复的图，第三列是原图（人都脑补不成这样）。<br />
<img src="/attachments_2023/Pasted%20image%2020230408165523.png" /></p>
<h3 id="面临问题">面临问题</h3>
<p>之前BERT方法应用到视觉所面临的问题如下：<br />
* 之前一直使用卷积神经网络处理图像，直至最近ViT解决了这一问题。<br />
*
图像数据中存在大量冗余，不像文本信息一样密集，图像中mask掉一部分可通过邻近信息插补，因此无法学习到复杂关系，文中提出mask掉高比例数据，以解决这一问题。<br />
* 去掉图像区域再还原像素比较困难，文中提出设计解码器解决这个问题。</p>
<h3 id="核心设计">核心设计</h3>
<p>MAE基于两个核心设计：<br />
*
不对称的编码解码结构，编码器仅仅对可见的patches进行编码，而解码器则对所有patches进行解码，但结构更简单；<br />
*
使用随机掩码来遮盖输入图像的部分区域，以此来训练模型。出人意料的是，图像的大部分都遮住了，还能还原出来。<br />
MAE方法简单且可扩展性强（scalable），因此在计算机视觉领域得到了广泛应用。只使用ImageNet-1K来精调ViT-Huge模型，就能达到87.8%的准确率，且在其它下游任务中也表现良好。</p>
<h2 id="方法">方法</h2>
<p>MAE使用autoencoder自编码器，由不对称的编码和解码器构造。</p>
<h3 id="mask">Mask</h3>
<p>在不放回的情况下按照均匀分布对随机Patch抽样。简称为“随机抽样”。<br />
*
高掩蔽率（一般遮住75%）很大程度上消除了冗余，创建了无法通过从可见的相邻插补轻松解决的任务。<br />
* 均匀分布可防止潜在的中心偏差。<br />
* 高度稀疏的输入为设计接下来介绍的高效编码器提供可能。<br />
Mask具体实现同Vit，详见：<a
href="/1_Note/2_算法/8_图形图像/论文阅读_ViT">论文阅读_ViT</a></p>
<h3 id="编码器">编码器</h3>
<p>编码器是 ViT，通过添加位置嵌入的线性投影嵌入Patch，然后通过一系列
Transformer 块处理结果集。<br />
与ViT不同的是：MAE只对整个集合的一小部分（例如
25%）进行操作，不考虑Mask掉的Patch，从而节约了计算量和内存。</p>
<h3 id="解码器">解码器</h3>
<p>如架构图所示，解码器的输入是所有Patch，并对所有块加入了位置信息，与编码器相比，默认解码器更窄而浅，每个token的计算量仅编码器的
10%，通过这种不对称设计，显著减少了预训练时间。<br />
解码器只在预训练时使用，其下游任务只使用图-1中全蓝色的隐空间表示。</p>
<h3 id="重构目标">重构目标</h3>
<p>解码器输出中的每个元素代表一个Patch的像素值向量。解码器的最后一层是线性投影，其输出通道数等于补丁中的像素值数，另外，还使用归一化方法提升重构质量。损失函数计算像素空间中重建图像和原始图像之间的均方误差
(MSE)。</p>
<h3 id="简单实现">简单实现</h3>
<p>先随机打乱token顺序，删除token列表的后面一部分（相当于采样），然后送入编码器，后进行随机打乱的逆操作对齐对原来顺序加入位置信息后再送入解码器。这样简单操作开销可以忽略不计，且不用使用稀疏操作。</p>
<h2 id="我的收获">我的收获</h2>
<ul>
<li>标题中的Auto指的是学习编码的数据来自图片本身<br />
</li>
<li>标题：把自己的工作总结成一句话，如：XXX是XXX（相对客观，从读者角度看问题）<br />
</li>
<li>沐神视频看论文，先看摘要，然后看结论，再看中段<br />
</li>
<li>从原理上讲，mask也是一种噪声和使用去噪的方法</li>
</ul>
]]></content>
      <tags>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_PaLM-E</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_PaLM-E/</url>
    <content><![CDATA[<p>name_ch: Palm-E：具身多模态语言模型实现<br />
name_en: PaLM-E：An Embodied Multimodal Language Model<br />
paper_addr: http://arxiv.org/abs/2303.03378<br />
date_publish: 2023-03-06<br />
code: https://palm-e.github.io</p>
<h2 id="读后感">读后感</h2>
<p>Embodied一般译作“具身”，是一种基于身体经验和感知的认知学科，旨在研究人类知觉、思想和行动的相互作用。<br />
自然语言模型包含了大量关于世界的内化知识，但是不“落地”，本文通过多模态接入了视频，传感器，将大模型学到的知识应用于机器人领域，进一步解决世界中的交互问题。PaLM-E直接产生动作的计划，从而让机器人以规划过程。<br />
将字，图，传感器的结果等都Embedding映射到同一空间，在对模型结构改动小的情况下，同时使用了多模态数据。<br />
文中还测试了将训练不同任务的训练数据放一起训练后三个模型效果都有提升，即举一返三的效果。</p>
<h2 id="介绍">介绍</h2>
<p>提出了多模态语言模型，将现实世界中连续的传感器数据接入语言模型，从而建立了词语和感知之间的联系。对将其运用到序列机器人操作规划、视觉问答和字幕等任务中。联合训练互联网中的语言，视觉和视觉语言领域，跨领域的多样化联合训练，提升了模型效果。训练的最大模型有
562B 参数，包含540B语言参数和22B视觉参数。</p>
<p>将从语言数据中学到的表征与现实世界的视觉和物理传感器模态联系起来，对于解决计算机视觉和机器人的现实问题至关重要。其具体方法是：将图像和状态等输入嵌入到与语言标记相同的隐空间中，并由基于Transformer的LLM的自注意力层以与文本相同的方式进行处理。</p>
<p>文章主要贡献如下：<br />
*
提出并证明了一个通用的、可迁移学习的、多具身决策智能体，可以通过将具身数据混合到多模态大数据中进行训练。<br />
* 使用视觉-语言模型解决具身推理问题。<br />
* 提出神经网络结构，支持多模态token。<br />
* 除了具身相关功能，PaLM-E在视觉和语言领域效果也不错。<br />
* 展示了缩放语言模型大小可以在较少灾难性遗忘的情况下实现多模态微调。</p>
<h2 id="palm-e具身多模态语言模型">Palm-E：具身多模态语言模型</h2>
<p>PaLM-E的主要架构思想是在预训练语言模型的语言嵌入空间中注入<strong>连续的、具身的观测，如图像、状态估计或其他传感器模态</strong>。<br />
PaLM-E是一个仅有解码器的LLM，在给定前缀或提示的情况下，自动生成文本补充。<br />
具体方法如下，其输入形式如下：</p>
<pre><code>sentence is Q: What happened between &lt;img 1&gt; and &lt;img 2&gt;?  </code></pre>
<p>其中img1/img2是图片嵌入。输出可以是问题的答案，或者文本形式生成的、由机器人执行的决策序列。</p>
<h3 id="只有解码器的-llms">只有解码器的 LLMs</h3>
<p>和GPT一样，这里的生成模型也只使用了<strong>Transformer的解码层</strong>，它根据前文中的词生成后面的词：<br />
<span class="math display">\[p(w_{1:L}) = \prod\limits_{l=1}^{L}
p_{\mathrm{LM}}(w_{l} \mid w_{1:l-1})\]</span><br />
由于LLM是自回归的，因此预训练的模型可以用前缀w1:n作为条件，而不需要改变架构：<br />
<span class="math display">\[p(w_{n+1:L}|w_{1:n}) =
\prod\limits_{l=n+1}^{L} p_{\mathrm{LM}}(w_{l} \mid
w_{1:l-1})\]</span><br />
其中的前缀或提示w1:n提供了上下文，提示符可以包含LLM应该解决的任务的描述或者示例。</p>
<h3 id="token嵌入空间">Token嵌入空间</h3>
<p>上式中的w指自然语言中的离散的单词，一般通过γ将其映射到嵌入空间。<br />
<span class="math display">\[x_i = γ(w_i) ∈ R^k\]</span></p>
<h3 id="多模态句子连续观察的注入">多模态句子：连续观察的注入</h3>
<p>图片被注入嵌入空间时，跳过了离散token层，直接映射到嵌入空间X，训练编码器φ，用于实现具体的转换：<br />
<img
src="/attachments_2023/Pasted%20image%2020230313184358.png" /><br />
需要注意的是，单个观测Oj通常被编码为多个嵌入向量；另外，不同传感器可能使用不同编码器φ。</p>
<h3 id="具身输出机器人控制回路">具身输出：机器人控制回路</h3>
<p>为了将模型的文本输出和机器人的动作联系起来，文中区分了两种情况：<br />
*
如果任务只能通过输出文本来完成，例如在具身问答或场景描述任务中，模型的输出直接是任务的解。<br />
*
如果需要输出计划或者控制任务，PaLM-E会生成低级命令的文本。需要注意的是，它必须根据训练数据和提示自行确定哪些技能可用，并且不使用其他机制来约束或过滤其输出。它们不能解决长时任务或复杂指令，因此，PaLM-E被集成到一个控制回路中，其预测的决策由机器人通过低级策略执行，从而产生新的观测值，根据这些观测值，PaLM-E可以在必要时重新规划（一步一步预测）。</p>
<h2
id="不同传感器模态的输入和场景表示">不同传感器模态的输入和场景表示</h2>
<p>不同类型数据使用不同的方法映射到嵌入空间，数据包含：ViTs来转换2D图像，OSRT转换3D场景的表征；除了全局表征，还设计了以物体为中心的tokens来表征场景中的物体（将图片映射到不同物体）。<br />
另外，PaLM-E需要在其生成的计划中引用对象，也就是场景中的物体，它们常常可以用自然语言中的属性来描述；有时更为复杂，比如场景中很多同一颜色的块；因此，设计了对象相关的提示：<br />
<code>Object j is &lt;obj-j&gt;</code>，
使得PaLM-E中可使用obj-j来引用对象。</p>
<h3 id="训练方法">训练方法</h3>
<p>训练数据包含连续的观测数据I，文本w，以及索引信息n；文本包含前缀ni以构成多模态句子，预测结果只包含文本。使用交叉熵作为损失函数，<strong>在每个非前缀token上计算损失</strong>。</p>
<p>模型包含三部分：观测数据编码器，映射器和自然语言模型，考虑到LLM存在大量推理信息，尽量冻结LLM，只对其它模型调参。</p>
<h2 id="实验">实验</h2>
<p>图-1展示了具身模型的功能：<br />
<img
src="/attachments_2023/Pasted%20image%2020230314185451.png" /><br />
主要实验了三种机器人场景：Task and Motion Planning, Tabletop
Manipulation, Mobile Manipulation，同时它还具体之前模型的视觉问答能力
Visual Q&amp;A，以及自然语言处理能力 Language Only Tasks。</p>
<p>文中 6.1-6.4 介绍了机器人任务（略...）</p>
<h3 id="通用型vs专用型迁移">通用型vs专用型（迁移）</h3>
<p>实验了使用多种任务“全混合”共同训练模型。可以看到通过多任务训练，模型在各个任务中都得到了显著提升。<br />
<img src="/attachments_2023/Pasted%20image%2020230314182414.png" /></p>
<h3 id="数据效率">数据效率</h3>
<p>与现有的大规模语言或视觉语言数据集相比，机器人数据的丰富程度明显较低。上述迁移机制有助于PaLM
- E从机器人领域极少的训练样本中求解机器人任务。</p>
<h3 id="保留语言能力">保留语言能力</h3>
<p>用两种方法：<br />
*
一种是冻结LLM，只对其它模型调参，可以看到，冻结后效果不如调参好，但效果也可达到74.3%。<br />
<img src="/attachments_2023/Pasted%20image%2020230314185751.png" /></p>
<ul>
<li>另一种是训练端到端的模型，两种方法都可用。端到端训练时，随着<strong>模型规模的增加</strong>，模型保留了更多的原始语言性能。可以看到，在562B模型的自然语言处理性能损失只有3.9%。<br />
<img
src="/attachments_2023/Pasted%20image%2020230314183613.png" /><br />
实验还证明：在普通的视觉和自然语言任务中，加入了具身能力的模型的能力也没有太大损失。</li>
</ul>
<p>自然语言模型给机器人带来了具身推理能力，在结合了之前其它能力的情况下（如场景表示能力），使PaLM-E成为了通才。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>大模型</tag>
        <tag>多模态</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_PaLM</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_PaLM/</url>
    <content><![CDATA[<p>name_ch: PaLM：使用Pathways的扩展语言建模<br />
name_en: PaLM：Scaling Language Modeling with Pathways<br />
paper_addr: http://arxiv.org/abs/2204.02311<br />
date_publish: 2022-10-05</p>
<h2 id="读后感">读后感</h2>
<p>论文主要介绍了Google的超大模型PaLM，它在多数任务上都超过了SOTA，其主因是使用模型使用了大量参数和数据训练，作者认为当模型大到一定程度后，其性能也能飞跃，而PathWay技术是其大规模训练的基础。<br />
和其它模型相比，PaLM更关注逻辑推理相关的任务，这也为后面的PaLM-E机器人行为规划奠定了基础。<br />
动态路由层选择具体的路怎么走。</p>
<h2 id="摘要">摘要</h2>
<p>文中提出了 Pathways Language Model (PaLM)，使用6144 个TPU
v4芯片训练，模型540 B参数，780 B高质量token，密集激活，Transformer
语言模型。在推理任务上表现很好，文中提出：扩展到巨大模型后，性能急剧提高（Pathways是Jeff
Dean与2021年提出的一种谷歌通用AI架构，可高效利用硬件）。</p>
<h2 id="介绍">1. 介绍</h2>
<p>一般大模型的优势主要来自以下：<br />
(1) 缩放模型的深度和宽度；<br />
(2) 增加训练模型的token数量；<br />
(3) 对来自更多不同来源的更干净的数据集进行训练；<br />
(4) 通过稀疏激活模块在不增加计算成本的情况下增加模型容量。</p>
<p>本文的主要工作包括：<br />
* 使用Pathway有效地训练大模型，高效利用硬件<br />
* 随着更大的模型规范，模型效果不断改善<br />
* 在理解、推理等困难任务上展示了突破性能力<br />
* 模型从62B变成540B后，模型效果出现跨越式（非连续）地进步<br />
* 测试了英文及其它语言（其它语言语料的&lt;22%）<br />
* 在偏见和毒性测试中发现大模型相对毒性更高，且毒性与提示文本设计有关</p>
<h2 id="模型结构">2. 模型结构</h2>
<p>PaLM与GPT-3模型一样，只使用Decoder结构。优化技术如下：<br />
* SwiGLU激活函数<br />
组合了Swish和GeLU两种激活函数。<br />
* 平行层<br />
将串行变为平行操作（由于MLP
和注意力输入矩阵乘法可以融合），提速15%，且实验证明不影响模型效果。<br />
<span class="math display">\[   
y = x + MLP(LayerNorm(x + Attention(LayerNorm(x)))  
\]</span><br />
变为：<br />
<span class="math display">\[  
y = x + MLP(LayerNorm(x)) + Attention(LayerNorm(x))  
\]</span><br />
* 多Query注意力<br />
标准的多头注意力在自回归解码期间在加速器硬件上的效率很低，因为键/值张量在示例之间不共享。文中模型让key/value映射被每个头共享，而Query相互独立，该方法提升了解码器的自回归时间。<br />
* RoPE嵌入<br />
RoPE：rotary position
embedding旋转位置嵌入，是一种相对位置嵌入，它不同于绝对位置嵌入和一般的相对位置嵌入，它对长序列效果更好。<br />
* 共享输入输出嵌入<br />
输入和输出共享同一个嵌入矩阵，从而减少了模型的参数数量，提高了模型的效率。<br />
* 无Biases<br />
网络层不使用biases，可以增加大模型的训练稳定性。<br />
* 词表<br />
使用SentencePiece（通过统计方法，将频繁出现的字符串作为词，然后形成词库进行切分），使切分的粒度会更大一些。使用256K的token表，词表以外的文本被切分成utf-8字符。</p>
<h3 id="模型规模超参数">模型规模超参数</h3>
<p><img
src="/attachments_2023/Pasted%20image%2020230327160759.png" /></p>
<h2 id="训练数据">3. 训练数据</h2>
<p>780 B 高质量的 token 。数据基于训练
LaMDA和GLaM的数据，除了自然语言，还包含多种编程语言的源代码。根据文件之间的
Levenshtein 距离删除重复项。</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230327161308.png" /></p>
<h2 id="训练基础设施">4. 训练基础设施</h2>
<p>使用 PathWay 方法训练模型，在两个TPU v4
Pods上训练，在每个Pod中包含由3072个TPU
v4芯片链接的768个主机。允许在不使用任何pipeline并行的情况下高效的在6144个芯片上训练。<br />
pipeline方式有更多的相互等待时间，而pathway复杂度更高。每个TPU v4
Pod都包含模型参数的完全拷贝。<br />
详见：Pathway原理。<br />
<img src="/attachments_2023/Pasted%20image%2020230327163639.png" /></p>
<p><img
src="/attachments_2023/Pasted%20image%2020230327205314.png" /><br />
相比之前模型，PaLM在由于对模型、编译器和并行策略进行了多项优化，实现了非常高的
MFU，对应的硬件FLOPs利用率也更高。</p>
<h2 id="训练设置">5. 训练设置</h2>
<p>此节介绍了权重初始值，优化器，超参数，损失函数，序列长度，Batch大小，Dropout比例等细节。</p>
<h2 id="评测">6. 评测</h2>
<p>论文在：英文NLP任务，BIG_bench，推理，代码任务，翻译，多语言生成方面对PaLM进行了评测。</p>
<h3 id="英文nlp任务">6.1 英文NLP任务</h3>
<p>PaLM在1-shot设置下，在29个任务中的24取得了SOTA；在few-shot设置下，在29个任务中的28个取得了SOTA。分为自然语言理解和自然语言推理，平均分如下：<br />
<img src="/attachments_2023/Pasted%20image%2020230327191603.png" /></p>
<p>MMLU评测结果如下：<br />
<img src="/attachments_2023/Pasted%20image%2020230327191708.png" /></p>
<h3 id="big-bench任务">6.2 BIG-bench任务</h3>
<p>BIG-bench包括 150
多个任务，涵盖各种语言建模任务，包括逻辑推理、翻译、问答、数学等。除了模型之间的对比，还对比了人类的平均水平和最佳水平。<br />
PaLM 540B 5-shot 在 58 项常见任务中的 44 项上优于之前的 SOTA，<br />
<img
src="/attachments_2023/Pasted%20image%2020230327192232.png" /><br />
需要注意的是其中有一些推理相关的项目，效果如图-5所示：<br />
<img
src="/attachments_2023/Pasted%20image%2020230327193224.png" /><br />
可以看到，有几项接近了人类的最佳水平，也可以看到，当模型从62B变为540B时，模型效果有了跨越式的提升。<br />
另外，PaLM540B在多数评测中高于人类的平均水平，有35%低于人类平均。</p>
<h3 id="推理">6.3 推理</h3>
<p>推理任务分为两类：<br />
*
算术推理：通常涉及小学水平的自然语言数学问题，需要多步逻辑推理。其难点是将自然语言转化为数学方程式。<br />
* 常识推理：需要很强的世界知识的问答任务，而不是简单的事实问答。<br />
这种问题一般需要输出答案和推理过程。具体调优方法是使用<strong>思维链提示学习</strong>，提示学习时只使用了8-shot样本。从表-10中可以看到不同方式对结果的影响。<br />
<img
src="/attachments_2023/Pasted%20image%2020230327195119.png" /><br />
还进行了其它的推理评测，结果是<strong>推理链提示和大模型都明显提升了模型的推理能力</strong>。</p>
<h3 id="代码任务">6.4 代码任务</h3>
<p>代码任务一般包括：根据文本描述写代码，把一种语言的代码翻译成另一种，以及代码修复。训练和精调时都包含一些代码数据，使得模型具有编码能力。PaLM
540B
有一定的代码能力，PaLM-Coder则是在代码上微调的模型。微调能够显著的改善PaLM在代码任务上的效果。</p>
<h3 id="翻译">6.5 翻译</h3>
<p>评测主要关注三类问题：<br />
* 以英语为中心的语言对：PaLM优于所有基线，有些甚至优于监督基线。<br />
*
直接语言对（在不涉及英语的情况下直接翻译），PaLM仅在法语-德语上匹配监督表现。<br />
*
资源极少的语言对（如哈萨克-英语翻译），能够在德语-法语和哈萨克语-英语上给出很强的表现。</p>
<h3 id="多语言生成">6.6 多语言生成</h3>
<p>实验分别测试了1-shot和Finetuning的结果，第一组评测是将数据转换成文本，第二组评测以总结文本为主，可以看到，PaLM在1-shot中表现优于其它模型，PaLM模型越大，提升效果越明显；finetuning使各模型效果都有提升。<br />
<img src="/attachments_2023/Pasted%20image%2020230327202641.png" /></p>
<h3 id="多语言问答">6.7 多语言问答</h3>
<p>可以看到PaLM精调后效果有明显提升，效果不如T5，可能是由于mT5 和 ByT5
接受的非英语文本训练分别是 PaLM 的 6 倍和 1.5 倍。<br />
<img src="/attachments_2023/Pasted%20image%2020230327203357.png" /></p>
<h3 id="分析">6.8 分析</h3>
<p>随着给模型提供更多示例，性能会提高。<br />
<img src="/attachments_2023/Pasted%20image%2020230327203741.png" /></p>
<p><strong><em>7,8略</em></strong></p>
<h2 id="探索解释">9. 探索解释</h2>
<p>使用思维链提示调优模型，提高多步推理任务中的预测准确性，可以用于模型解释。</p>
<p>解释包含以下场景：<br />
*
了解模型是否出于“正确的原因”而产生正确的答案，而不是仅仅进行表面层面的统计推断，具有重大的科学意义。<br />
*
解释可能会显示给系统的最终用户，以增加或减少他们对给定预测的信心。<br />
* 在许多情况下（例如，解释一个笑话），解释本身就是期望的输出。</p>
<p>此部分列举了解释的两种场景：解释笑话，逻辑推理。对于每项任务，都编写了
2-shot 示例来演示所需的输出样式，作为例子提示模型。具体见图-19。</p>
<h4 id="笑话示例">笑话示例：</h4>
<p>输入：我打算在 4 月 6
日飞去探望我的家人。我妈妈说：“太好了，那天晚上你继父的诗歌朗诵会！”所以现在我要在
4 月 7 日飞来。<br />
模型输出：这个笑话是说话者的母亲试图让他们去他们继父的诗歌朗诵会，但说话者不想去，所以他们将航班改到诗歌朗读后的第二天。</p>
<h4 id="推理示例">推理示例：</h4>
<p>输入：迈克尔在法国那个非常有名的博物馆里看它最著名的画作。然而，创作这幅画的艺术家恰恰让迈克尔想起了他小时候最喜欢的卡通人物。卡通人物平时手里拿的东西是哪个国家的？<br />
模型输出：卢浮宫最著名的画作是蒙娜丽莎。制作蒙娜丽莎的艺术家是达芬奇。
Leonardo da Vinci
也是卡通忍者神龟中主角的名字。列奥纳多·达·芬奇来自意大利。列奥纳多·达·芬奇平时手里拿着的东西是武士刀。武士刀的原产国是日本。答案是“日本”。</p>
<h2 id="参考">参考</h2>
<p>https://zhuanlan.zhihu.com/p/602060627</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_Segment_Anything</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_Segment_Anything/</url>
    <content><![CDATA[<p>name_ch: 切分任何东西<br />
name_en: Segment Anything<br />
paper_addr: http://arxiv.org/abs/2304.02643<br />
date_publish: 2023-04-05<br />
demo: https://segment-anything.com</p>
<h2 id="读后感">读后感</h2>
<p>论文提出 Segment Anything
(SA)模型，无需精调，即可通过<strong>文本提示</strong>进行<strong>图像分割</strong>(抠图)。<br />
SA 基于将 Transformer 模型应用到图像处理领域 ViT <a
href="/1_Note/2_算法/8_图形图像/论文阅读_ViT">论文阅读_ViT</a>，对图像的无监督学习
MAE <a
href="/1_Note/2_算法/2_大模型/论文阅读_MAE">论文阅读_MAE</a>，以及文本图像相互映射的CLIP
<a
href="/1_Note/2_算法/6_自然语言/论文阅读_图像生成文本_CLIP">论文阅读_图像生成文本_CLIP</a>
，可以说它是图像领域大模型落地的一个精典范例。<br />
之前的图像分割模型，比如要识别图中的猫，先需要做一些标注数据，用工具把图中的猫标注出来，然后用这些标注数据在pretrain模型的基础上fine-tune。<br />
SA
论文解决了两个问题：把文字描述和图中形象联系起来；在不fine-tune的情况下解决zero-shot问题。另外，本文的一大亮点是：用先交互后自动的方式标注了数以十亿记的图片，实现了标注功能的自我提升。</p>
<h2 id="摘要">摘要</h2>
<p>Segment Anything
(SA)即分割一切，论文的成果是最终发布了模型<strong>SAM</strong>，它无需fine-tune即可对图中任何物体进行分割，且能通过文本提示分割图像，效果可与有监督学习媲美。论文同时发布了<strong>超过1B图片</strong>，<strong>11M的mask标注的数据集SA-1B</strong>。</p>
<h2 id="介绍">介绍</h2>
<p>提示学习帮助大语言模型提升了处理zero-shot问题的能力；CLIP和ALIGN模型又提供了文本和图像对齐的方法，以供下游任务使用，比如DALL-E的生成图片。本文主要研究图像分割：通过文本提示抠图。<br />
<img
src="/attachments_2023/Pasted%20image%2020230407221839.png" /><br />
具体通过三个相互关联的组件来构建模型：任务、模型、数据。</p>
<h2 id="任务">任务</h2>
<p>提示工程近年在自然语言和视觉建模方面产生巨大影响，文中提出了可提示的图像分割。如图1-(a)所示，通过提供图片，及各种各样的提示来分割出所需区域。提示可包含：描述文本、空间中的点（星）、区域（方块）等。在提示不明确的情况下，可能存在多个对象（如：衣服和穿衣服的人），至少能合理地分割其中一个对象。</p>
<p>在预训练阶段，构造了可能与具体使用方法相似的任务以训练模型，生成了具有泛化能力的图像分割器，以解决zero-shot问题。后期可通过提示和下游任务组合，桷建更大系统中的组件来执行新的、不同的任务。</p>
<h2 id="模型">模型</h2>
<p>设计模型结构SAM，需要支持：灵活的提示，实时计算，歧意识别。<br />
具体实现如图-1(b)所示，一个图像编码器生成图像嵌入，一个指令编码器生成提示嵌入，然后用一个轻量的mask解码器将二者结合用于分割任务。<br />
<img src="/attachments_2023/Pasted%20image%2020230409110629.png" /></p>
<h3 id="图像编码器">图像编码器</h3>
<p>基于ViT的图像编码器，只在图像输入时生成一次图像嵌入，嵌入生成后，可与多个提示结合，以节约算力，每次只需要
50ms，以满足web交互的需要。针对歧义问题，设计了一个提示多个mask的方案。<br />
本文中把图像先缩放成1024x1024，短边补齐，然后分成64x64块个16x16的块。</p>
<h3 id="指令编码器">指令编码器</h3>
<p>考虑两组提示：稀疏（点、框、文本）和密集（mask）。稀疏提示通过位置编码关联每个提示类型的学习嵌入和来自
CLIP（文本与图像映射）的嵌入。密集提示（mask）使用卷积嵌入，可与图像嵌入逐元素求和。</p>
<h3 id="解码器">解码器</h3>
<p>mask解码器将图像嵌入、提示嵌入和输出token映射到mask。该模型对
Transformer
解码器块进行了修改，后跟动态mask预测头。使用提示自注意力和交叉注意力来更新所有嵌入；然后对图像嵌入进行上采样；MLP
将输出token映射到动态线性分类器，再计算每个图像位置的蒙版是前​​景的概率。<br />
<img src="/attachments_2023/Pasted%20image%2020230414172806.png" /></p>
<h3 id="歧义问题">歧义问题</h3>
<p>如果给出的提示不明确，模型将生成多个有效mask。因此，修改模型以预测单个提示的多个输出mask，发现
3
个mask输出足以支持大多数常见情况（嵌套mask通常最多三个深度：整体、部分和子部分）。</p>
<h2 id="数据引擎">数据引擎</h2>
<p>大模型需要大量不同分布的图片及mask训练，而现有的数据集并不丰富。<br />
文中提出建立一个数据引擎 data
engine，模型标注数据，数据又反过来训练模型，循环往复。具体包含三个阶段：<br />
* 辅助手动：SAM 协助标注者注释mask。<br />
标注者被要求按照突出的顺序标记对象，并被鼓励在标注超过 30
秒后处理下一张图像。使用常见的公共分割数据集进行训练，然后开始交互标注，总共对模型进行了
6 次再训练，每个mask的平均注释时间从 34 秒减少到 14
秒，每张图像的平均mask数量从 20 个增加到 44 个。<br />
* 半自动：SAM
自动生成mask，使用上一个阶段训练的结果训练一个边界识别器。自动标注图片，让标注者专注于注释剩余的对象，以提升mask的多样性。<br />
根据新收集的数据重新训练模型 5
次。对象的标记更具挑战性，平均注释时间回到 34
秒，每张图像的平均mask数量从 44 个增加到 72
个mask，其中包括自动mask。<br />
* 全自动：SAM 自动标注，为每张图像平均产生约 100 个高质量mask。<br />
在此阶段，开发了歧义感知模型，即使在模棱两可的情况下也能预测有效的mask。最终生成的数据集有99.1%来自于全自动标注。</p>
<p>最终产生SA-1B数据集，超过 10
亿个带mask的数据集，图片全部由SAM自动标注，平均每个图像100个mask。</p>
<h2 id="模型效果">模型效果</h2>
<p>建立自己去meta网站试一试，不用梯子即可使用。<br />
https://segment-anything.com/demo<br />
自己上传图片试了一下，把头发和脸分开，两只手可以分开，肉色的衣服和皮肤，边缘还比较完美，mask后效果就很像动画效果。不知道修图师和插画师作何感想，娃们还会不会再去学插画和素描？是不是应该先去研究一下AlphaGo出来之后，围棋班有没有受影响？</p>
<h2 id="本地搭建环境">本地搭建环境</h2>
<p>源码基于Pytorch，从predictor_example来看，接口非常简单，只要稍微做过一些图像模型的人都能看懂，mask区域被直接返回，我没找到调用CLIP的图文对齐部分，只试用了切割部分。</p>
<p>下载源码</p>
<pre><code>git clone https://github.com/facebookresearch/segment-anything.git  
按README.txt中提示安装即可  </code></pre>
<p>基于docker运行</p>
<pre><code>docker pull pytorch/pytorch:1.13.1-cuda11.6-cudnn8-runtime  </code></pre>
<p>进入docker后，安装jupyter</p>
<pre><code>pip install jupyter_nbextensions_configurator jupyter_contrib_nbextensions  
jupyter notebook --allow-root -y --no-browser --ip=0.0.0.0  </code></pre>
<p>我的环境还安装了以下工具</p>
<pre><code>apt-get update  
apt-get install build-essential libgl1-mesa-glx libglib2.0-0  
pip install matplotlib torchvision pycocotools onnx black isort opencv-python  </code></pre>
<p>测试一下不同参数量的模型：<br />
<img
src="/attachments_2023/Pasted%20image%2020230408095236.png" /><br />
ViT-B(base), ViT-L(Large), ViT-H(Huge)。<br />
目前最大的模型是谷歌团队的 ViT-22B 模型，其参数 22B。</p>
<p>默认使用ViT-H，下载约2.4G，GPU内存用满11G。<br />
wget
https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth<br />
效果如下：<br />
<img src="/attachments_2023/Pasted%20image%2020230408100637.png"
alt="|400" /></p>
<p>下载ViT-B，下载约358M，GPU内存用到8G左右，<br />
wget
https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth<br />
比较后可以看到，大模型的mask效果明显更好一些：<br />
<img src="/attachments_2023/Pasted%20image%2020230408100418.png"
alt="|400" /><br />
不是特别大的模型，如果有GPU，在家用速度也能接受，从此拥有了自己的抠图小助手。</p>
<h2 id="参考文章">参考文章</h2>
<p>ViT模型：<a
href="/1_Note/2_算法/8_图形图像/论文阅读_ViT">论文阅读_ViT</a><br />
MAE模型：<a
href="/1_Note/2_算法/2_大模型/论文阅读_MAE">论文阅读_MAE</a></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>大模型</tag>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_Self_instruct</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_Self_instruct/</url>
    <content><![CDATA[<p>name_ch: 自引导：用自我生成的指令调整语言模型<br />
name_en: Self-Instruct：Aligning Language Model with Self Generated
Instructions<br />
paper_addr: http://arxiv.org/abs/2212.10560<br />
code: https://github. com/yizhongw/self-instruct<br />
date_publish: 2022-12-20</p>
<h2 id="读后感">读后感</h2>
<p>文中提出了自引导框架，之前引导精调主要使用人工处理的数据，数据量和范围都有限，本文通过示范少量引导示例，让模型自己生成引导数据对模型进行优化。</p>
<h2 id="摘要">摘要</h2>
<p>用引导数据精调模型提升了模型适应新任务的能力，它依赖于人工的引导数据，在数量、多样性和创造力方面受到限制，因此阻碍了精调模型的通用性。文中提出了自引导框架，通过自引导来提高预训练语言模型的指令遵循能力。经过自引导可使基础模型的GPT-3提升33%，与InstructGPT001差不多的效果。</p>
<h2 id="介绍">介绍</h2>
<p>2022年以后的大模型一般都使用了预训练和引导使用人工标注引导的技术。PROMPT
SOURCE, SUPER NATURAL INSTRUCTIONS是两个著名的引导数据集。<br />
自引导过程是一个迭代自举算法。在第一阶段，模型被提示为新任务生成指令。此步骤利用现有的指令集合来创建更广泛的指令定义任务；然后，在将低质量和重复的指令添加到任务池之前，使用各种措施对其进行修剪。可以针对许多交互重复此过程，直到生成大量任务。</p>
<p>该模型的迭代 SELF INSTRUCT 过程产生大约 52k 条指令，与大约 82k
实例输入和目标输出配对。</p>
<p>文章贡献：<br />
*
提出SELF-INSTRUCT，一种用<strong>最少的人工标记数据诱导</strong>指令能力的方法；<br />
* 通过广泛的指令调整实验证明了它的有效性；<br />
* 发布了一个包含<strong>52K
指令</strong>的大型综合数据集和一组手动编写的新任务，用于构建和评估未来的指令优化模型。</p>
<h2 id="方法">方法</h2>
<p>图-1中展示了其核心技术。<br />
<img src="/attachments_2023/Pasted%20image%2020230325151706.png" /></p>
<h3 id="定义引导数据">定义引导数据</h3>
<p>首先，（图左上）定义了175个种子任务，目标是生成一个引导数据集{I}，其中每条定义一个自然语言任务t，每个任务都有一个或多个输入输出实例
(Xt,
Yt)，预计模型M产生输出y。为了鼓励数据格式的多样性，允许不需要额外输入的指令（即，x为空）。</p>
<h3 id="生成自引导数据">生成自引导数据</h3>
<ul>
<li>生成自引导：<br />
将 175 个任务（每个任务 1 个指令和 1
个实例）作为初始任务池。每一步，从池中抽取 8
个任务指令作为上下文示例。其中6 条来自人工编写的任务，2
条来自前面步骤中模型生成的任务，以促进多样性。<br />
</li>
<li>判断自引导是否为分类<br />
示例见图<br />
</li>
<li>按不同方式生成数据<br />
为每条引导生成实例，针对于分类与非分类任务使用不同方法，<strong>对于分类任务一般先生成类别标签，然后生成问题；而非分类问题先生成问题，再生成答案</strong>。<br />
</li>
<li>过滤掉低质量数据<br />
为了鼓励多样性，只有当一条新指令与任何现有指令的 ROUGE-L 重叠小于 0.7
时，它才会被添加到任务池中。还排除了包含一些通常无法被语言模型处理的特定关键字的指令；另外，过滤掉完全相同或输入相同但输出不同的实例。<br />
</li>
<li>使用生成的指令精调模型<br />
连接指令和实例输入作为提示，训练模型产生实例输出。</li>
</ul>
<h2 id="来自-gpt3-的自引导数据">来自 GPT3 的自引导数据</h2>
<p>生成的数据包含52K引导，82K实例。<br />
<img
src="/attachments_2023/Pasted%20image%2020230325154653.png" /><br />
图-2展示了生成的最常见的动词及其直接宾语：<br />
<img src="/attachments_2023/Pasted%20image%2020230325160414.png" /></p>
<h2 id="实验">实验</h2>
<p>使用GPT-3生成的引导，利用GPT-3提供的fine-tune API 对GPT-3调优。</p>
<h3 id="实验一zero-shot任务">实验一：Zero-shot任务</h3>
<p>SUPERN1评测包含119项任务，每个任务100个实例。<br />
<img
src="/attachments_2023/Pasted%20image%2020230325161859.png" /><br />
可以看到Instruct-GPT相对于GPT-3基本版有较大提升，与InstructGPT001效果差不多。</p>
<h3 id="推广到面向用户的新任务">推广到面向用户的新任务</h3>
<p>创建了 252 条指令，每条指令 1
个实例。用它可以作为一个测试平台，用于评估基于指令的模型如何处理多样化和不熟悉的指令。人为评估分为从A-D四个等级，效果如下：<br />
<img
src="/attachments_2023/Pasted%20image%2020230325162209.png" /><br />
可以看到Self-instruct与instructGPT001差不多，相对于002,003差距较大。<br />
instructGPT001、002、003：001是比较早期的版本，002深度融合了代码训练和指令微调，003加入了PPO强化学习。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_Visual_ChatGPT</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_Visual_ChatGPT/</url>
    <content><![CDATA[<p>name_ch: Visual Chatgpt：使用可视化基础模型进行交谈、绘图和编辑<br />
name_en: Visual ChatGPT：Talking, Drawing and Editing with Visual
Foundation Models<br />
paper_addr: http://arxiv.org/abs/2303.04671<br />
code: https://github.com/microsoft/visual-chatgpt<br />
date_publish: 2023-03-08</p>
<h2 id="读后感">读后感</h2>
<p>在ChatGPT和图像构建方法间做了桥接，和其它模型相比，除了利用大语言模型中的知识，还利用了ChatGPT强化学习带来的能力，是一个结合已有技术的一个优雅示例。<br />
本文将CoT的潜力扩展到大规模任务，包括但不限于文本生成高清图像、图像到图像的翻译、图像到文本的生成等。CoT指的是Chain-of-Thought思想链，主要指模型的多步推理能力，以解决更为复杂的问题。<br />
主要对聊天的场景进行优化，在提示上作文章。即：在ChatGPT外边包了一层，这也是当前最常见的用法。文章偏工程化的具体实现。</p>
<h2 id="介绍">介绍</h2>
<p>主要实现：<br />
* 不仅发送和接收语言，还发送和接收图像。<br />
*
提供复杂的视觉问题或视觉编辑指令，提供多个AI模型的多步骤互动协作。<br />
* 提供反馈并询问对修正结果评价。</p>
<p>提供了如下功能：<br />
* 明确告诉ChatGPT和VFM，并指定输入输出格式；<br />
*
将不同的视觉信息，如png图像、深度图像和掩码矩阵转换为语言格式，帮助ChatGPT理解；<br />
* 处理不同视觉基础模型的历史、优先级和冲突。<br />
<img
src="/attachments_2023/Pasted%20image%2020230312095758.png" /><br />
文章贡献：<br />
* 提出了Visual
ChatGPT，打开了ChatGPT与视觉基础模型结合的大门，使ChatGPT能够处理复杂的视觉任务；<br />
* 设计了一个Prompt
Manager，其中涉及22个不同的虚拟功能矩阵，并定义了它们之间的内部关联，以便更好地交互和组合；<br />
* 进行了大量的零样本实验，展示了丰富的案例来验证Visual
ChatGPT的理解和生成能力。</p>
<h2 id="visual-chatgpt">Visual ChatGPT</h2>
<p>全文唯一公式：<br />
<img
src="/attachments_2023/Pasted%20image%2020230312101419.png" /><br />
i：i轮对话<br />
j：解决复杂问题时，回答可能拆解成多步，j表示每一步<br />
P：系统性提示<br />
F：虚拟函数模块，F={f1,f2,...fN}，它包含一组各有输入输出的决策函数。<br />
H：前几轮的对话s历史<br />
Q：表示人机对话中第i轮对话中的问题，它可以包含图片和文本<br />
R：解决复杂问题时，前j个步骤的结果<br />
A：人机对话中第i轮对话中的答案，回答支持多种格式混合<br />
M：提示管理器（核心功能），将图像等信息转换成ChatGPT能识别的文本；</p>
<p>其核心过程主要分为以下四步：<br />
<img src="/attachments_2023/Pasted%20image%2020230312102640.png" /></p>
<h3 id="处理系统性提示-mp">处理系统性提示 M(P)</h3>
<p>生成ChatGPT能明白的语义</p>
<h3 id="基础模块-mf">基础模块 M(F)</h3>
<p>更好地与图像工具结合，常见的两种应用是：生成/编辑图片，根据图片回答问题。</p>
<h3 id="处理用户输入-mqi">处理用户输入 M(Qi)</h3>
<p>用户输入可能是文本或者图片。</p>
<h3 id="处理输出-mfai">处理输出 M(F(Ai))</h3>
<p>处理VFM产生的图像，并在VFM和ChatGPT间交互，最终生成可以反馈给用户的数据。</p>
<h2 id="实验">实验</h2>
<p>实验使用ChatGPT (OpenAI “text-davinci-003” version)。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>大模型</tag>
        <tag>图形图像</tag>
        <tag>多模态</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_增强语言模型综述</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%A2%9E%E5%BC%BA%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<p>name_ch: 增强语言模型综述<br />
name_en: Augmented Language Models：a Survey<br />
paper_addr: http://arxiv.org/abs/2302.07842<br />
date_publish: 2023-02-15</p>
<h1 id="读后感">读后感</h1>
<p>文章是一篇增强语言模型（Augmented Language
Models，ALMs）综述，这里的增强主要指让大语言模型（LM）通过<strong>参数/非参数的方法</strong>与<strong>外部扩展模块</strong>相结合，从而获得<strong>超越单纯的自然语言建模</strong>的能力。具体能力包含：<strong>推理、使用工具、行动</strong>。它不仅能解决<strong>更多类型的问题</strong>，在连接外部模块后，其<strong>处理自然语言处理能力</strong>也得到突破性进展。</p>
<p>文章从<strong>方法论</strong>的角论进入阐释。内容分为六部分：介绍，推理，使用工具和行动，学习方法，讨论，结论，正文22页。</p>
<p>对于比较关注 LM
领域的读者，这篇文章中并没有提到让人意外的特殊方法。然而，文章对现有方法进行了全面细致的整理，提供了全景视角的概览，详细引用了相关文献和软件示例。是对知识很好的概览和梳理。</p>
<p>下文括号内均为个人观点，不喜勿喷。</p>
<h2 id="介绍">1 介绍</h2>
<h3 id="动机">1.1 动机</h3>
<p>近年来，大型语言模型（LLM）的发展非常迅速，随着模型规模的增加，模型涌现
emergence 出其突破性能力（各种能力之间相互促进）。然而，LLM
经常会产生一些幻觉
hallucinations（一本正经的胡说八道），导致其回答有时不太可信。特别是在解决数学问题、推理等复杂问题时，LLM
的表现往往不如人意。<br />
在解决具体问题时，我们需要提供必要的大规模知识给模型。然而，目前存在两大限制：(i)
参数模型是固定的（通常人们无法使用自己的数据训练大型模型）；(ii)
上下文受到限制（把知识转给大模型时受到限制）。</p>
<h3 id="定义">1.2 定义</h3>
<p>Reasoning：通常被翻译为推理或规划，指将复杂的任务分解为简单的子任务，从而使用现有的工具来解决这些子任务。<br />
Tool：LLM与外部模块相结合，例如结合文档检索器，通过工作与大型模型的交互操作，提升模型解决复杂问题的能力。<br />
Act：调用对虚拟或物理世界产生影响的工具并观察其结果，例如机械臂。</p>
<h2 id="推理">2 推理</h2>
<p>推理一般包括：常识推理、数学推理和符号推理等，其中推理链较长的被称为多步推理。LLM的在解决简单问题时效果较好，但在复杂问题中表现不佳，往往需要扩展其推理能力。</p>
<h3 id="通过提示引发推理elicitive-prompts">2.1
通过提示引发推理（Elicitive prompts）</h3>
<p>提示主要用于Zero-shot和Few-shot任务。启发式提示 (Elicitive prompts)
鼓励LM通过在输出答案之前遵循中间步骤来解决任务。<br />
对于Few-shot任务，Chain-of-thought (CoT)
可以有效提升其推理能力，此外，还可以通过对比答案一致性来提高效果。<br />
对于 Zero-shot 任务，可以使用提示语，例如 "Let’s think step by step"
来帮助解决问题。</p>
<h3 id="递归提示">2.2 递归提示</h3>
<p>为解决复杂问题，常使用递归的方法将大问题拆解成子问题。这种方法包括两种具体的方式：一种是分别解决各个子问题，再综合其结果得到最终答案（并行）；另一种是一步一步解决子问题（串行）。文中列举了相关的工作成果和引用文献。</p>
<h3 id="教语言模型进行推理">2.3 教语言模型进行推理</h3>
<p>当一个任务需要多个步骤才能正确解决时，人类通常依靠工作记忆来完成。可以通过预训练和微调的方式，将
step-by-step
数据加入到模型训练中，让模型能够预测推理步骤。例如，可以使用 work
标签来包含类似于内部工作记忆的信息。<br />
<img src="/attachments_2023/Pasted%20image%2020230527082944.png" /></p>
<h3 id="推理的局限性">2.4 推理的局限性</h3>
<p>无论是迭代推理还是递归推理，探索所有可行的推理路径都是困难的，并且不能保证每个推理步骤的正确性，失之毫厘，谬以千里。</p>
<h2 id="工具和行为">3 工具和行为</h2>
<p>回答问题所需的知识并不全都需要存在模型的权重中，还可以通过调用外部知识来扩展模型的功能。这需要将LLM与扩展模块相结合。</p>
<h3 id="调用其它模型">3.1 调用其它模型</h3>
<h4 id="迭代-lm-调用">3.1.1 迭代 LM 调用</h4>
<p>迭代式调用模型可以逐步改进输出，允许语言模型对自身进行迭代调用，直到输出满足特定标准。例如，Re3能够自动生成长度超过2000字的故事。在此过程中，模型使用先前提供的提示调用GPT3，生成计划、环境设置和角色；然后逐步注入计划和当前故事状态的信息，生成新的故事片段。此外，还可将大纲逐步扩展到任何需求的粒度。</p>
<h4 id="结合多模态">3.1.2 结合多模态</h4>
<p>LM
也可以作为通用接口，与在不同模态上预训练的模型一起使用。例如，处理文本和图像等多个模态的数据，并且可以适应不同的任务。例如，Flamingo是一种视觉语言模型（VLM），可以处理任何交错的文本和图像数据序列。通过训练大规模的多模态网络语料库，并通过少量样本的学习，使其可以轻松适应生成任务或分类任务。另外，Socratic
Models
是一种模块化的框架，可以组合不同模态的预训练模型，让模型之间进行信息交换，支持新的应用，例如机器人感知和计划，自由形式的视频问答等。</p>
<h3 id="信息检索">3.2 信息检索</h3>
<p>LM
可以通过增加记忆单元提升推理能力，或通过从外部知识源检索避免产生非事实和过时信息，从而实现与大型
LM 相当的性能，并减少所需的参数数量。</p>
<h4 id="检索增强语言模型">3.2.1 检索增强语言模型</h4>
<p><strong>密集和稀疏表示</strong><br />
外部知识的文本通常转换成向量表示，表示方法分为密集型和稀疏型。稀疏型指的是使用词袋类方法，生成对每个词的表示；密集型则使用深度学习模型通过嵌入方式表示。在具体使用过程中，先对外部知识进行检索，然后将问题和检索结果一起传递给
LLM。检索时，对于稀疏型数据，通常使用检查精确的术语重叠方式；对于密集数据，则常使用计算相关概念之间的语义相似性。</p>
<p><strong>用检索的文档调节 LM</strong><br />
该方法在知识密集型任务中表现突出，具体方法包括：使用预训练的大模型进行微调；训练端到端的模型；结合已经训练好的BERT预训练模型而无需调整参数等方法。<br />
<img src="/attachments_2023/Pasted%20image%2020230527094610.png" /></p>
<p><strong>思维链提示和检索器</strong><br />
将推理链 CoT 与检索器相结合，这种方法不需要精调模型。只需使用 CoT
推理来指导检索步骤，将意图分解在查询中。</p>
<h4 id="搜索引擎查询">3.2.2 搜索引擎查询</h4>
<p>当模型具备根据提示生成查询的能力时，LM
可以扩大其行动空间并变得更加主动。LaMDA 和 BlenderBot 是两个用于对话的
LM
模型。它们通过引入检索、计算和翻译等机制进行增强，从而进一步提升对话的能力。</p>
<h4 id="搜索和浏览网页">3.2.3 搜索和浏览网页</h4>
<p>训练代理在开放式互联网上导航以实现特定目标，例如搜索信息或购买商品。WebGPT
是一种基于 LM 的代理，它可以与 Web
浏览环境进行交互，以进一步细化初始查询或根据其与工具的交互执行其他操作，以提高问答能力。当前最好的模型是在人类演示中微调
GPT3，然后执行拒绝采样来训练以预测人类偏好的奖励模型。WebShops
可以根据提供的指令找到、定制和购买产品。这两个系统都是基于<strong>自然语言理解和推理</strong>的，因此非常适合语言模型。</p>
<h3 id="通过符号模块和代码解释器进行计算">3.3
通过符号模块和代码解释器进行计算</h3>
<p>LM
主要在自然语言处理方面表现出色，而对于需要处理大量数字或进行复杂算数运算的问题，即使加强了预训练的推理能力，也并不完美。更进一步的做法是将
LM 与专业引擎或工具结合使用，例如物理引擎或 Python 程序。例如，CoT
提供大型
LM，可以将符号推理、数学推理或算法任务分解为中间步骤以及每个步骤对应的
python 代码。</p>
<h3 id="作用于虚拟或物理世界">3.4 作用于虚拟或物理世界</h3>
<p>除了信息交互，LM也可以与真实世界交互。</p>
<h4 id="控制虚拟智能体">3.4.1 控制虚拟智能体</h4>
<p>与现实世界交互的第一步是在模拟的二维和三维环境中执行任务。例如，通过将嵌入序列作为输入来预测下一个动作。这涉及跨不同领域的组合泛化，其中
LM 可用作多步骤计划器，将高级任务分解为子目标。</p>
<h4 id="控制机器人">3.4.2 控制机器人</h4>
<p>一些研究者通过提供示例，使得LM能够编写与自然语言命令相应的机器人策略代码，并结合经典逻辑和外部库以生成利用空间几何推理的策略代码。<br />
然而，由于缺乏情境培训，语言模型在进行实际决策时存在问题。为了克服这个问题，一些研究者建议引入机器人的低层技能，以便将复杂的高级指令分解为简单的子目标，并根据情境选择最有价值的低层技能来完成任务。<br />
另外，还通过将环境中的语境信息与图像和文本对齐的方式融入机器人的决策中，提高了机器人在实现控制任务时的性能。</p>
<h2 id="学习方法">4 学习方法</h2>
<p>本部分介绍了提升模型效果的具体方法。</p>
<h3 id="有监督学习">4.1 有监督学习</h3>
<h4 id="few-shot提示">4.1.1 Few-shot提示</h4>
<p>人工编写示例是教导LM推理和使用工具以及行动的常用方法之一。该方法不需要调节模型参数，同时可以进行快速实验，且同一模型可供不同场景使用。另外，LM的规模大小、上下文窗口的大小、小样本示例的选择以及它们呈现的顺序也很重要。这个方法也有其缺点：(1)
一种新的行为非常难以学习，需要的不仅仅是少数几个例子 (2)
对于动作空间具有很多可能性的情况下，模型学习也会非常困难。</p>
<h4 id="精调模型">4.1.2 精调模型</h4>
<p>为提高预训练语言模型的推理和操作能力，可通过标准的监督学习来更新其参数，该方法已被应用于很多工具和系统，如搜索引擎、网页浏览器、计算器和翻译系统等。此外，还可以通过人工标注数据以进行精调，从而提高模型遵循指令的能力。</p>
<h4 id="预训练提示">4.1.3 预训练提示</h4>
<p>为了避免精调模型对于预测训练模型基本能力的扭曲，可以采用将预训练数据与带标签的推理示例混合的方法（改进Prompt）。这种方法将预训练数据与来自各种下游任务的示例混合。</p>
<h4 id="bootstrap自举">4.1.4 bootstrap（自举）</h4>
<p>自举是一种间接监督的方法，它可以作为精调的替代方案。在多个步骤中，使用这种方法进行探索。丢弃执行的动作或推理步骤没有导致正确预测的示例。最后，使用原始LM或另一个（通常较小的）模型在所有正确的示例上进行微调（通过训练出的模型来筛选实例，这种方法可能更准确）。</p>
<h3 id="强化学习">4.2 强化学习</h3>
<p>有监督学习需要大量标注，因为比较复杂且昂贵。相比之下，强化学习则可以利用用户喜好、排序结果等现成数据，更为便捷、快速和廉价。强化学习的核心是奖励函数机制。<br />
强化学习常应用于机器人、游戏等场景建模，其目标是通过为一系列问题提供策略，从而获得最大化的整体奖励值。在这个过程中，涉及到模型和使用者或其他工具的交互。</p>
<h4 id="硬编码奖励函数">4.2.1 硬编码奖励函数</h4>
<p>训练语言模型时，通常使用硬编码的奖励函数来使用外部工具更新模型的权重。该奖励基于工具的输出计算。具体来说，可以输入一段文本到模型中，然后根据模型当前状态生成一系列标记或动作。基于奖励的学习在赋予LM与外部工具交互的能力方面拥有显著的潜力。例如，WebGPT就使用了该技术。</p>
<h4 id="人类反馈">4.2.2 人类反馈</h4>
<p>在很多情况下，回答是否合适还取决于提问人的意图。由于人的偏好和价值观很难用硬编码的方式去评价，因此引入了人类反馈的强化学习（RLHF：Reinforcement
Learning from Human
Feedback）。这种方法是通过人对机器产生的多个回答进行打分，然后进一步训练模型。例如，GPT-3.5就使用了该方法，改进了模型的有用性、无害性和准确性。</p>
<h3 id="限制和未来方向">4.3 限制和未来方向</h3>
<p>当前的 RL
方法仍存在不稳定的问题，尤其是在没有现成可用数据的情况下需要进行推理和行动的任务中更为如此，此外还有数据质量问题。解决这些问题的方案可能来自于引导方法和离线
RL，同时还有一些自监督的方法。研究如何将这些方法，将模型扩展到更复杂的场景中，将是基于
LM 的通用模型的一个有前途的研究方向。</p>
<h2 id="讨论">5 讨论</h2>
<p><strong>远离传统语言建模</strong>：ALMs与传统语言建模不同。它可以执行中间的推理步骤，或者拥有访问互联网的能力。此外，它可以通过任务导向的监督数据，将答案与中间步骤明确地联系起来。在做决策时，它还会考虑当前状态和工具因素。</p>
<p><strong>权衡工具和记忆</strong>：对于某些情况，比如计算213443^344，使用外部工具可能是更好的选择；但是，像“埃菲尔铁塔位于巴黎”这样的信息就不应该移交给外部工具。可以通过调整模型，决定何时使用工具。此外，还可以将每个工具的计算预算整合到损失函数中,
以让模型学会使用工具。</p>
<p><strong>非参数框架</strong>：ALM
是非参数化框架的一种泛化。除信息检索外，LMs
可以委托给相应的外部工具处理其他问题，比如计算，以避免将很少访问的知识存储在它们的权重中。工具增强
LM
可能具有更好的可扩展性，能够产生更小的模型，同时保留较大模型的能力。这对于
ALMs
的非参数化泛化具有巨大的益处，能够从外部世界获取最新信息，并避免频繁更新。</p>
<p><strong>通往自主机器智能的道路</strong>：LeCun（2022）提出了自主智能代理（Agent）的概念。尽管
ALMs
的权重基本上包含了世界模型、感知和行动者模块，但作为预测单词级别的模型，它们无法像
LeCun 的 Agent 那样进行计划和推理。虽然 ALMs 可以作为人类交互的
Agent，但目前仍有很多开放的研究问题需要解决。</p>
<p><strong>ALM的优势</strong><br />
* 更可靠：可以通过与其他工具的印证来增加其可靠性。<br />
*
减少不确定性：通过使用外部工具来帮助模型确定其所知道和不知道的内容，ALM可以直接利用此不确定性，更好地了解何时应依赖自身权重，何时应查询外部工具。<br />
*
可解释性：ALM提供了中间推理步骤并依赖工具来增强可解释性。引用用于答案撰写的来源是至关重要的，思路链也可以导致正确的预测。<br />
*
增强功能：具有改进推理能力和工具的ALM可以成为更有帮助的工具，并解决比标准LM更广泛的任务。推理和操作之间形成一个反馈回路，每种能力都能进一步提高另一种能力。与外部工具、实体和环境交互可以改进推理。同样，推理可以提高ALM的决策能力。</p>
<p><strong>道德伦理问题</strong>：ALM引发了新的潜在伦理问题。实际上，其中许多预测仍然是不正确的，这使得检测错误变得更加困难。尤其是当它在虚拟或物理世界上采取行动时，如果不进行人工验证，可能会扩大LM造成的有害后果。</p>
<h2 id="结论">6 结论</h2>
<p>文章主要讨论归因和工具，以及对于非调参LM的增强能力。这种增强的语言模型通常需要人工标注和反馈的交互支持。此外，还可以将归因和工具结合起来进一步研究，以解决更为复杂的问题。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_大模型_ToolLLM</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%A4%A7%E6%A8%A1%E5%9E%8B_ToolLLM/</url>
    <content><![CDATA[<pre class="ad-info"><code>英文名称: ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs  
中文名称: TOOLLLM：帮助大语言模型掌握16000多个真实世界的API  
文章: http://arxiv.org/abs/2307.16789  
代码: https://github.com/OpenBMB/ToolBench  
作者: Yujia Qin  
日期: 2023-07-31  </code></pre>
<h2 id="读后感">1 读后感</h2>
<p>论文致力于让<strong>大模型学习使用工具，以实现复杂的任务</strong>。目前使用工具能力最强的还是
ChatGPT，但不清楚它是如何实现的。文中提出的 ToolLLM
<strong>主要用于构建针对 引导调优（instruction-tuning）的训练数据集
ToolBench</strong>
，最终通过数据对开源的LLaMA调优，训练的模型ToolLLaMA，对工具的使用能力与
ChatGPT 相当。</p>
<p>为了使路径搜索过程更加高效，提出了基于深度优先搜索的决策树（depth-first
search-based decision tree：<strong>DFSDT</strong>）；训练了 API
检索器来为每条指令推荐适当的 API。</p>
<p>最终发布了用于评价的工具 ToolEval，以及使用 ToolBench 调优的模型
ToolLLaMA，可支持复杂的引导和没见过的 API。优化了通过大模型与调用 API
的协作，生成最终答案的功能。</p>
<h2 id="介绍">2 介绍</h2>
<p>对于大模型和工具协作问题，之前工具有以下的局限性：<br />
* 使用有限的非真实或少量的 API 训练<br />
* 受限的场景：只涉及单个工具，未考虑到工具交互关系<br />
* 计划和归因效果差，只使用提示方式，难以处理复杂的指令<br />
* 开源的大模型效果不好<br />
表-1对比了 ToolBench 和之前的数据集：<br />
<img src="/attachments_2023/Pasted%20image%2020230904134752.png" /></p>
<p>图-1
展示了整体架构设计，左侧为训练，右侧为推理（使用模型预测）。<br />
在训练阶段，首先从 RapidAPI 收集
API，然后利用ChatGPT，一方面生成引导数据，用于训练神经网络的 <strong>API
Retriever</strong>（API
检索器），另一方面实现路径标注，生成引导学习的数据 ToolBench，将数据代入
LLaMA 精调模型生成 <strong>ToolLLaMA</strong>。<br />
在推理阶段，用户输入指令 Instruction，利用 API Retriever 检索可能调用的
API，然后将这些 API 输入ToolLLaMA模型，ToolLLaMA 执行多轮 API
调用以得出最终答案，最后再由 ToolEval 对结果进行评价。<br />
<img
src="/attachments_2023/Pasted%20image%2020230904135123.png" /><br />
通过评测，得到以下结论：<br />
* ToolLLaMA
具有处理<strong>单工具和复杂多工具</strong>指令的能力。它对以前未见过的
API 具有<strong>泛化能力</strong>，只需要 API 文档即可有效地适应新的
API。ToolLLaMA 在工具使用方面与 <strong>ChatGPT
性能相当</strong>。<br />
* DFSDT 方法<strong>考虑多条路径</strong>，可作为<strong>增强 LLM
推理能力的通用决策</strong>策略。比 ReACT 性能更好。<br />
* 训练 <strong>API 检索器</strong>神经网络表现出卓越的检索精度，返回的
API 与真实情况密切相关。</p>
<h2 id="构造数据">3 构造数据</h2>
<p>构造 ToolBench 分为以下三个阶段：</p>
<h3 id="收集api">3.1 收集API</h3>
<p>RapidAPI Hub 是一个 API 市场，提供数千个现实世界的 API，涵盖 49
个不同的类别 categories，如体育、金融和天气等；每个类别又含子类
collections，如中文API、人工智能API、数据库API；总共上万个API。对于每个API，收集其描述、所需参数、API调用的代码片段等。训练
LLM 理解API与文本描述的关系​​，以便泛化到未见过的API。</p>
<p>在实现过程中需要对 API 进行筛选，丢弃无法实现功能及返回延时过长的
API，最终保留了 3451 个高质量工具，共 16464 个 API。</p>
<p>另外，描述信息可能过长，包含一些冗余信息，这里使用 ChatGPT
对其进行精减，通过输入为工具的文档描述以及所需输出格式的示例，以此将文档压缩在
2048 tokens 之内。</p>
<h3 id="指令生成">3.2 指令生成</h3>
<p>生成高质量的指令需要关注两个关键点：支持<strong>工具多样性</strong>和<strong>多工具协同</strong>解决复杂任务。具体方法是从整个集合中采样
API，然后提示 ChatGPT 为这些 API 生成不同的指令。</p>
<p>具体方法是：<br />
为所有 API 及其组合生成指令，将 API 的总集定义为 SAPI，每次从 SAPI
中采样一些 API：Ssub N = {API1, · · ·, APIN}；通过提示让 ChatGPT
了解这些 API 的功能及其相互作用，然后生成涉及 Ssub N 中 API 的可能指令
<code>(Inst*)</code>，以及每个指令的相关
<code>API (Srel * ⊂ Ssub N ) (Inst*)</code>，即<code>&#123;[Srel 1 , Inst1],···,[Srel N′ , InstN′ ]&#125;</code>，其中N′表示每次生成实例的数量。用这些指令和相关
API 对<strong>训练 API 检索器</strong>。</p>
<p>与 ChatGPT 对话时，提示由以下部分组成：<br />
* 指令对应的任务的描述链链<br />
* Ssub N 中每个 API 的综合文档，<br />
* 三个种子示例，每个种子示例都是由人类专家编写的理想指令。以规范 ChatGPT
的行为。为单工具/多工具分别编写了 12 / 36
个不同的种子示例，每次随机采样三个示例。<br />
<img
src="/attachments_2023/Pasted%20image%2020230904163740.png" /><br />
简言之，就是通过 API 描述和种子，生成可能的 API集合S/指令Inst 对。</p>
<p>API组合非常多，由常识可知，多数工具不会组合在一起使用，对于这种稀疏问题，通过
RapidAPI 中的层次过滤出更有效的组合，具体方法是：从同一类别/集合中选择
2-5 个工具，并从每个工具中采样最多 3 个 API
以生成指令。最后又去掉了一些幻觉产生的API，生成数据对：单个工具相关87413个、同类别工具84815个
，同子类别工具25251个。</p>
<h3 id="路径标注">3.3 路径标注</h3>
<p>路径指的是工具和模型交互的过程，这里涉及多轮与 ChatGPT
的对话。给定指令 Inst<em>，提示 ChatGPT 搜索有效的操作序列：{a1, ···,
aN}。在每个时间步 t，模型根据之前的交互生成一个动作 at，即
ChatGPT(at|{a1, r1, · · · , at−1, rt−1}, Inst</em>)，其中 r* 表示真实的
API 响应。at 的格式链如下：“想法：···，API 名称：···，参数：····”。</p>
<p>对于每条指令，将所有采样的 API Ssub N 作为可用函数提供给
ChatGPT，而不是仅将其相关的 API Srel* 提供给 ChatGPT。以访问更广泛的 API
并扩展操作空间。另外，还定义了两个附加函数，即“完成最终答案”和“完成放弃”。</p>
<p><strong>DFSDT</strong><br />
传统的CoT 或 ReACT
对于决策有固有的局限性：（1）错误传播：一步错步步错；（2）有限的探索：CoT或ReACT只探索一种可能的方向，导致对整个动作空间的探索有限，如图所示。因此，即使是
GPT-4 也常常无法找到有效的解决方案路径。</p>
<p>本文提出：基于深度优先搜索的决策树 DFSDT，具体如：图-4所示。<br />
<img
src="/attachments_2023/Pasted%20image%2020230904164642.png" /><br />
当对于某一条路径搜索失败时，退回上一个节点的其它路径继续搜索。</p>
<p>具体方法使用深度优先搜索（DFS）而不是广度优先搜索（BFS），因为只要找到一条有效路径就可以完成注释，这样花费更少的
token 调用成本。最终，生成 12657 个指令-解决方案对，用于训练
ToolLLaMA。实验证明这个量集的实例已实现了满意的泛化的需要。</p>
<h2 id="实验">4 实验</h2>
<h3 id="tooleval">4.1 TOOLEVAL</h3>
<p>评测工具 TOOLEVAL 涉及两个评测标准。<br />
* 通过率（能否找到答案）：<strong>有限数量的操作</strong>（本文中为 200
个）内<strong>成功完成</strong>指令的比例。计算其百分比视为通过率。另外，还处理了答案是“未找到答案”的"假正例"。<br />
*
优胜率（答案好不好）：通过<strong>比较两个解决方案路径</strong>来测量答案质量。具体方法是：先让人注释人类偏好；对比
ChatGPT 评估器与人类注释者的相关性高达
75.8%，因此可将其作为可信评估器。且当对同一指令进行多次注释时，该评估结果比人类更加一致。</p>
<h3 id="初步实验">4.2 初步实验</h3>
<h4 id="api-检索器">4.2.1 API 检索器</h4>
<p>API 检索器通过 Sentence-BERT 实现，模型将<strong>指令</strong>和
<strong>API
文档</strong>分别编码为两个嵌入，然后计算两个嵌入的相关性，以训练模型。<br />
对比文中方法与 BM25，以及ChatGPT
提供的文本Embedding，文中方法明显更好（毕竟它是通过有监督数据训练过的模型），当然应用时效果也会更好。<br />
<img src="/attachments_2023/Pasted%20image%2020230905145615.png" /></p>
<h4 id="对比-dfsdt-和-react">4.2.2 对比 DFSDT 和 ReACT</h4>
<p>对比 DFSDT 和 ReACT 的通过率，其中还加入了比较多次 ReACT@N
的操作。几个实验都证明 DFSDT 更好，尤其在相对复杂的场景中，DFSDT
对性能改进更明显。<br />
<img src="/attachments_2023/Pasted%20image%2020230905150048.png" /></p>
<h3 id="主实验">4.3 主实验</h3>
<p>使用指令-解决方案对 LLaMA 7B 模型进行调优，得到模型
ToolLLaMA。对比其它模型结果如下：<br />
<img
src="/attachments_2023/Pasted%20image%2020230905151258.png" /><br />
* 这里表现最好的是
ChatGPT-DFSDT，也就是训练本文中模型的老师模型，这很正常，而且证明了
DFSDT 的有效性；<br />
*
文中模型明显优于其它方法，通过率略低于其老师模型，优胜率相似，这证明了可以通过调优本地模型替代
ChatGPT 的可行性。<br />
* Vicuna 和 Alpaca 是 LLaMA
的自然语言精调版本，实验证明它无法支持工具预测。</p>
<p><strong>消融实验</strong><br />
<img
src="/attachments_2023/Pasted%20image%2020230905152316.png" /><br />
这里对比文中几种方法各自对模型的影响：<br />
* 用 API 检索器推荐的 API 替换真实 API，模型效果略有降低，说明重要的 API
基本都被检索器识别到了。<br />
* 将推理方法从 DFSDT 降级为 ReACT，效果明显降低；主实验也证明了 DFSDT
的重要性。这也说明，使用一些外部的方法也能提升模型性能。<br />
* 使用 LoRA 作为增补模型以替代全模型调参，效果略有降低。<a
href="/1_Note/2_算法/8_图形图像/AI绘画/论文阅读_模型结构_LoRA">论文阅读_模型结构_LoRA</a></p>
<h2 id="启发">5 启发</h2>
<h3 id="大模型">5.1 大模型</h3>
<ul>
<li>大模型分成：理解力，知识力<br />
</li>
<li>在调优模型之外，可有很多方法提升模型效果<br />
</li>
<li>利用工具调优的网络 ToolLLM，可实现更复杂的功能<br />
</li>
<li>目前多数网络学习决策能力，外接网络，实现分类回归；文中学习生成能力，推荐一系列操作，通过多步交互，实现更复杂功能，并积累数据。<br />
</li>
<li>证明了本地模型替代 ChatGPT
的解决方案，可以泛化到其它定制功能。<br />
</li>
<li>用 ChatGPT构造各种训练数据，多步交互数据，精减内容，评测……</li>
</ul>
<h3 id="具体工作">5.2 具体工作</h3>
<ul>
<li>先用工具自动给Code写说明文档<br />
</li>
<li>学习本地 API（不是开放域）：Android的，自己的程序，用 ChatGPT
建立相关引导<br />
</li>
<li>不一定每次都调模型，2/8原则中的大部分功能有稳定的路径，用
Sentence-BERT可能又快又好地解决大部分问题。<br />
</li>
<li>ToolBench 开源了训练数据集，可以直接用。<br />
</li>
<li>至少可以把文中功能作为代码生成器使用，选择 API 用。<br />
</li>
<li>使用工具也有多个层级：使用什么API/组合完成任务，代码具体怎么写。<br />
</li>
<li>有效利用了数据中的层级，一步一步定位这个方法很好，不是把所有数据喂进去。<br />
</li>
<li>API 检索器 可以做，（机器看有什么工具可以使用），应该比普通的 code
生成器好用。<br />
</li>
<li>DFSDT 有效解决了一步错步步错的问题。<br />
</li>
<li>也是一大模型加一小模型的结构，用的是 Sentence-BERT。</li>
</ul>
<h3 id="其它想法">5.3 其它想法</h3>
<ul>
<li>我们要做的是工具/平台，不是具体代码，支持后面更多功能插进来。<br />
</li>
<li>在指令生成部分，反向用 ChatGPT，这个挺有意思的</li>
</ul>
<h3 id="具体实现">具体实现</h3>
<p>(仅供内部链)<br />
* <a
href="/4_Project/汽车/鸿蒙系统与AI_读后感">鸿蒙系统与AI_读后感</a><br />
* <a
href="/4_Project/汽车/系统_软件和底层的智能化">系统_软件和底层的智能化</a></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_音频表示_w2v-BERT</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E9%9F%B3%E9%A2%91%E8%A1%A8%E7%A4%BA_w2v-BERT/</url>
    <content><![CDATA[<p>name_ch:
W2V-BERT：结合对比学习和Mask语言建模进行自监督语音预训练<br />
name_en: w2v-BERT：Combining Contrastive Learning and Masked Language
Modeling for<br />
Self-Supervised Speech Pre-Training<br />
paper_addr: https://ieeexplore.ieee.org/document/9688253/<br />
date_publish: 2021-12-13</p>
<h2 id="读后感">1 读后感</h2>
<p>w2v-BERT是音频的表示学习。模型可用于优化语音识别。可以看作对w2v 2.0
的延展。</p>
<h2 id="摘要">2 摘要</h2>
<p>文中提出自监督的语音表示学习w2v-BERT，它结合了对比学习和Mask语言模型，前者使用模型将输入的连续语音信号离散化为一组有限的可辨别的语音标记；后面通过Mask方法生成结合上下文的语音表示。<br />
相对于之前模型，w2v-BERT结合了两个不同模型，实现了end-to-end
训练。w2v-BERT 优于 wav2vec 2.0 30% 以上。</p>
<h2 id="介绍">3 介绍</h2>
<p><strong>主要贡献</strong><br />
* 提出
w2v-BERT，可以同时直接优化对比损失和掩码预测损失，用于端到端的自监督语音表示学习。<br />
* 展示了 w2v-BERT 在 LibriSpeech 任务上产生了最先进的性能。<br />
* 展示了 w2v-BERT 在真实世界识别任务（语音搜索）任务中，对于wav2vec 2.0
的明显优势。<br />
* 经验上证实了对比学习和Mask预测的必要性。</p>
<h2 id="方法">4 方法</h2>
<p><img
src="/attachments_2023/Pasted%20image%2020230502145724.png" /></p>
<h3 id="模型结构">4.1 模型结构</h3>
<h4 id="特征编码器">4.1.1 特征编码器</h4>
<p>由两个 2D 卷积层组成，使声学输入序列长度减少到1/4。例如：给定一个
log-mel
声谱图作为输入，特征编码器提取潜在的语音表示，这些表示将被后续的对比学习模块作为输入。</p>
<h4 id="对比学习模块">4.1.2 对比学习模块</h4>
<p>包含一个线性映射层，及多个Conformer层，<strong>每个块都是一系列多头自注意力、深度卷积和前馈层</strong>。<br />
对比模块的目标是将特征编码器输出离散化为一组有限的代表性语音单元。对比模块涉及量化机制。另外，在没有Mask的情况下被传递到量化器以产生量化向量和分配token。量化向量结合mask位置对应的context
vector来解决 wav2vec 2.0 中定义的对比任务优化；分配的 token ID
稍后将被后续的掩码预测模块用作预测目标。</p>
<h4 id="mask预测模块">4.1.3 Mask预测模块</h4>
<p>使用BERT中的Mask方式，利用对比学习的输出，学习语音中高层级的上下文之间的关系。</p>
<h3 id="预训练">4.2 预训练</h3>
<h4 id="对比学习损失">4.2.1 对比学习损失</h4>
<p>（简单地说：Mask掉小段，并给出一些随机产生小段，用对比学习，通过上下文猜那个小段是对的）<br />
对比损失用于与量化器一起训练对比模块，其具体方法使用与wav2vec
2.0一样的量化机制。<br />
<strong>随机选择一些时间步长进行掩蔽</strong>。用随机向量替换它们。屏蔽特征编码器的输出被馈送到对比模块以生成上下文向量。同时，特征编码器的输出也被传递给量化器而不进行Mask以产生其<strong>量化向量</strong>。对于对应于Mask时间步长
t 的上下文向量 ct，要求模型从一组 K <strong>干扰项</strong> { ̃ q1, ̃
q2, ..., ̃ qK } 中识别其真实的量化向量 qt，将损失表示为
Lw，并用码本多样性损失 Ld
进一步扩大它，以鼓励统一的代码。对比损失定义为：<br />
<img src="/attachments_2023/Pasted%20image%2020230504194130.png" /></p>
<h4 id="mask预测损失">4.2.2 Mask预测损失</h4>
<p>对比模块产生的上下文向量直接传递给掩码预测模块，用于生成最终的上下文向量，以完成掩码预测任务。一个
softmax 层附加在模块的最后一个 conformer
块之上。如果最后一层的上下文向量对应于掩码位置，则 softmax
层会将上下文向量作为输入并尝试<strong>预测其对应的标记
ID</strong>，该标记 ID
是先前由量化器在对比模块中分配的。将此屏蔽预测任务的交叉熵损失表示为
Lm。<br />
w2v-BERT
经过训练可以同时解决两个自监督任务，最终要最小化的训练损失为：<br />
<img src="/attachments_2023/Pasted%20image%2020230504194629.png" /></p>
<h3 id="精调">4.3 精调</h3>
<p>使用有标签数据 LibriSpeech和voice search。训练语音识别ASR任务，ASR
网络由预训练的 w2v-BERT 模型和 LSTM 解码器组成。在二者之间插入一个带有
Swish 激活 和批量归一化的线性层作为投影块。</p>
<h2 id="相关知识">5 相关知识</h2>
<ul>
<li>Conformer 模型：一种混合了卷积神经网络和 Transformer 的模型<br />
</li>
<li>log-mel
声谱：其过程包括将语音信号进行短时傅里叶变换（STFT）得到频谱，再将频谱转换为Mel频率尺度，最后再对Mel频率尺度取对数（log）得到log-mel声谱。</li>
</ul>
]]></content>
      <tags>
        <tag>语音</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_音频表示_wav2vec_2</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/2_%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E9%9F%B3%E9%A2%91%E8%A1%A8%E7%A4%BA_wav2vec_2.0/</url>
    <content><![CDATA[<p>name_ch: wav2vec 2.0：语音表示自监督学习框架<br />
name_en: wav2vec 2.0：A Framework for Self-Supervised Learning of Speech
Representations<br />
paper_addr: http://arxiv.org/abs/2006.11477<br />
code: https://github.com/pytorch/fairseq<br />
date_publish: 2020-10-22</p>
<h2 id="读后感">1 读后感</h2>
<p>模型用于语音识别，模型结构结合了CNN和Transformer。文章言简意赅，结构非常舒服。</p>
<h2 id="摘要">2 摘要</h2>
<p>先从未标注语音中学习音频的表示，然后通过少量标注数据精调，得到模型优于用大量标注数据训练的模型，且其原理非常简单。<br />
仅使用<strong>十分钟的标记数据和 53k
小时的未标记数据</strong>的预训练，可达到 4.8/8.2
WER。这证明了使用有限数量的标记数据进行语音识别的可行性。</p>
<h2 id="介绍">3 介绍</h2>
<p>语音识别系统一般需要<strong>成千上万小时</strong>的转录语音（语音+对应文本）才能达到可接受的性能，而对于全球近7,000种语言中的大多数来说，并没有这么多标注数据。<br />
神经网络受益于大量无标记训练数据。<strong>自监督</strong>学习的方法，可从<strong>未标注</strong>的数据示例中学习<strong>通用的数据表示</strong>，再在标注数据上微调模型。这在自然语言处理，和计算机视觉中都取得了重要进步。<br />
文中提出的一个自监督学习框架，旨在从原始音频数据中学习到通用的数据表示。该方法使用了多层卷积神经网络对语音音频进行编码，使用类似于NLP中mask的方法，通过Transformer网络来构建情境化的表示，并通过对比任务来训练模型。</p>
<h2 id="模型">4 模型</h2>
<p><img
src="/attachments_2023/Pasted%20image%2020230502115141.png" /><br />
模型先使用卷积网络将输入音频X映射到隐空间Z，然后将Z送入Transformer网络构建表示C以便从上下文中提取相关信息；另外特征编码Z还被送入量化工具，以生成量化后的表示Q（离散）。从而学习了音频的表示。</p>
<h3 id="特征编码器">4.1 特征编码器</h3>
<p>编码器由多个块组成，其中包含时间卷积，然后是层归一化 和 GELU
激活函数。输入到编码器的原始波形被归一化为零均值和单位方差。编码器输出到
Transformer 。</p>
<h3 id="通过transformer结合上下文-表示">4.2 通过Transformer结合上下文
表示</h3>
<p>特征编码器的输出被送到Transformer
架构的上下文网络。使用卷积层作为相对位置嵌入。我们将卷积的输出和 GELU
添加到输入中，然后应用层归一化。</p>
<h3 id="量化模型">4.3 量化模型</h3>
<p>在自监督训练阶段，通过乘法量化将<strong>特征编码器 z
的输出离散化为有限的语音表示集</strong>。乘积量化相当于从多个码本中选择量化表示并将它们连接起来。给定
G 个码本或组，从每个码本中选择一个条目并连接生成向量 e1, ..., eG
并应用线性变换。Gumbel softmax
支持以完全可微分的方式选择离散码本条目。</p>
<h2 id="训练实验">5 训练&amp;实验</h2>
<h3 id="masking">5.1 Masking</h3>
<p>类似BERT的Mask方法，Mask掉部分Encoder后的特征，随机无重复地选择一定比例的时间步作为起始点，并<strong>屏蔽每个起始点连续M个时间步</strong>，屏蔽区间可能会重叠。</p>
<h3 id="目标">5.2 目标</h3>
<p>预训练时，通过对比学习优化损失函数Lm，同时使用损失Ld以鼓励模型使用codebook。<br />
<img
src="/attachments_2023/Pasted%20image%2020230502135811.png" /><br />
其中a为超参数。</p>
<h4 id="对比学习的损失">5.2.1 对比学习的损失</h4>
<p>上下文网络输出的c，q为量化隐空间的表示：<br />
<img
src="/attachments_2023/Pasted%20image%2020230502140239.png" /><br />
sim用于计算上下文表式与量化隐空间的距离。</p>
<h4 id="多样性损失">5.2.2 多样性损失</h4>
<p><img
src="/attachments_2023/Pasted%20image%2020230502140328.png" /></p>
<h3 id="精调">5.3 精调</h3>
<p>预训练模型针对语音识别进行了微调：使用Librispeech数据集，通过在上下文网络顶部<strong>添加一个线性投影</strong>，将音频表示映射到分类任务中，通过最小化
CTC 损失来优化模型。<br />
LibriSpeech是一个包含大约1000小时16kHz英语读音的语料库，数据源自LibriVox项目的有声读物，并经过仔细的分段和对齐。</p>
]]></content>
      <tags>
        <tag>语音</tag>
      </tags>
  </entry>
  <entry>
    <title>在机器学习中应用数学方法</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%BA%94%E7%94%A8%E6%95%B0%E5%AD%A6%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="在机器学习中应用数学方法">在机器学习中应用数学方法</h1>
<p>#深度学习</p>
<p>我们从初中就开始学习指数和对数，但即使是程序员平时也很少用到这些方法。本篇就来看看如何使用它们解决具体问题。</p>
<p><strong>指数</strong></p>
<p>在多分类问题中，一般在最后一步使用Softmax，将数值转换成属于各个类别的概率，比如根据输入物品图片，通过一系列处理，判别它是衣服、鞋子、帽子各类别的概率。具体公式如下：</p>
<p><img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81MzU3ODkzLTE4NTdlMDI0ZDEyOTU5MDAucG5n?x-oss-%20process=image/format,png" /></p>
<p>其中i为某一类别，j用于遍历所有可能的类别，Si计算的是某一类别的概率，即某一类别在所有类别中的占比。其中用到了自然指数e。e的图型如下：</p>
<p><img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81MzU3ODkzLWZkNzExMGU4ZjlmMjkwMDcucG5n?x-oss-%20process=image/format,png" /></p>
<p>首先，e指数是单调上升的，也就是说x越大y越大，变换之后的大小关系不会改变；且当x为负数时，y也是正数，这点非常重要。仍以物品分类为例，假设深度网络输出的最后一层是[1,-1,2]，其中包含负数，而概率在[0,1]之间，又不可能是负数。通过Softmax公式计算出每一分类的概率为：[0.25949646<br />
0.03511903 0.70538451]，完美地解决了这一问题。</p>
<p><strong>对数</strong></p>
<p>条件概率常被用于序列预测问题，比如使用模型写作时，使用前N个字预测第N+1字，实际也是概率问题，比如给出前两个字“白日”预测第三个字，第三个字备选项是包含10000个字的字库，计算其中每一字的概率。假设其中“依”字概率最大为0.3，再使用“日依”预测下一个字，其中概率最大的是“山”概率为0.15，以此类推，预测最后一个字为“尽”的概率为0.2。</p>
<p>能预测出“白日依山尽”的概率，即给定条件“白日”，“依山尽”三个字同时出现的概率为0.3
<em>0.15</em><br />
0.2=0.009。如果预测一个很长的序列，小数连乘的结果很可能趋近于0，这里常使用对数方法。自然对数做图如下：</p>
<p><img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81MzU3ODkzLWU0YTYyZWY3MDk3MjJjNTEucG5n?x-oss-%20process=image/format,png" /></p>
<p>由于负数没有对数，图像中只有x
&gt;0的部分。自然对数也是单调上升的；使用log后连乘变为连加，上例变成：</p>
<p>log(0.3 <em>0.15</em> 0.2)=log(0.3)+log(0.15)+log(0.2)=-4.71</p>
<p>如果使用log计算概率，概率取值在[0,1]之间，那么只需要关注图中红色线条部分。对概率x取对数，y最大值为0，最小值为负无穷，在前面加一个负号，将值转换到0到正无穷，并将其作为误差函数Loss=-log(p)，当p值较小时（可能性小）Loss为一个较大的误差；当p值接近1时误差Loss趋近于0，这就是用负对数似然计算误差。</p>
<p><strong>cosine距离</strong></p>
<p>cosine距离常用于计算两个向量的距离，如用于图片搜索，对比文字描述的相似度，计算距离等等。设想二维情况下，两个向量的夹角，如下图所示：</p>
<p><img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81MzU3ODkzLTFlMzQ2ZmU0NWU1NzQ4NmEucG5n?x-oss-%20process=image/format,png" /></p>
<p>当夹角θ接近0时，cos(θ)=1，向量距离很近，当夹角接近90度时，两向量正交二者无关cos(θ)=0；当夹角为180度时，方向相反cos(θ)=-1。</p>
<p>cosine距离公式如下：</p>
<p><img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81MzU3ODkzLWNmZDEzMzQwY2I5NzMwYmQucG5n?x-oss-%20process=image/format,png" /></p>
<p>其中u和v都是n维向量，分子为点积操作，分母可看作对各个维度的归一化。从直觉上看，它们每一维度上的值越接近，整体距离越近。因此也说：向量之间夹角的余弦也是单位向量均之间的点积。程序中很多向量相似度都通过点积计算，速度也非常快。</p>
<p>在选择距离计算方法时，cosine距离可看作是计算向量间的相似程度，而欧式距离计算的是两向量间的差异程度。</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>EasyNLP</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%B8%B8%E7%94%A8%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h2 id="常用线性回归模型">常用线性回归模型</h2>
<h3 id="多元线性回归">多元线性回归</h3>
<p>多元线性回归是最常用的预测数值型目标的建模方法，也常用于数据分析中的多因素分析。<br />
<span class="math display">\[  
\min_w||Xw-y||_2^2  
\]</span><br />
后面几种回归都是在它基础上稍做修改。当特征数多于实例数，某些数据有问题，或者某些特征相关性高时，线性回归得到的参数常常数值很大，常用Lasso回归和Ridge回归解决这一问题，防止模型过拟合。</p>
<h3 id="lasso回归套索回归">lasso回归（套索回归）</h3>
<p>lasso回归倾向于减少有效参数，使模型更加简单。具体方法是修改损失函数，将L1范数（各个元素绝对值之和）加入惩罚项，它可生成稀疏的模型参数。常用于特征存在共线性的情况，实现模型特征选择。<br />
<span class="math display">\[  
\min_w\frac{1}{2n_{samples}}||Xw-y||_2^2+\alpha||w||_1  
\]</span></p>
<h3 id="ridge回归岭回归">Ridge回归（岭回归）</h3>
<p>和Lasso回归类似，将L2范数（向量所有元素的平方和的开平方）加入惩罚项。常用于数据个数小于数据维度的情况，它限制参数大小，使之逼近0。<br />
<span class="math display">\[  
\min_w||Xw-y||_2^2+\alpha||w||_2^2  
\]</span></p>
<h3 id="huber回归">Huber回归</h3>
<p>Huber的损失函数结合了mse和mae，当模型的预测结果和真实值的差异较小时使用mse，较大时则使用mae，具体阈值通过人工设定。</p>
<h3 id="示例">示例</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston  </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split   </span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression <span class="keyword">as</span> LR,Ridge,HuberRegressor,LassoCV  </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error  </span><br><span class="line">  </span><br><span class="line">lb = load_boston()  </span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(lb.data, lb.target, test_size=<span class="number">0.25</span>,  random_state=<span class="number">666</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#model = HuberRegressor().fit(x_train, y_train)  </span></span><br><span class="line"><span class="comment">#model = Ridge().fit(x_train, y_train)  </span></span><br><span class="line"><span class="comment">#model = LR().fit(x_train, y_train)  </span></span><br><span class="line">model = LassoCV().fit(x_train, y_train)  </span><br><span class="line">preds = model.predict(x_test)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(model.coef_) <span class="comment"># 打印回归参数  </span></span><br><span class="line"><span class="built_in">print</span>(mean_squared_error(y_test, preds))  </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习_SVM支持向量机</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_SVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
    <content><![CDATA[<h1 id="机器学习_svm支持向量机">机器学习_SVM支持向量机</h1>
<p>#机器学习</p>
<h2 id="介绍">1. 介绍</h2>
<p>SVM支持向量机属于广义的线性模型，先回忆一下线性模型：可依据平面（多维）或直线（一维/二维）来理解模型。简单地说，可用一条线将两类分开，如下图所示。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-201f7d2e95459039.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>能将两类分开的直线不止一条（左图），我们希望找到离两组数据都最远的那条线（正中间那条线），以便更好地泛化。这就是右图中所示的极大边距分类器，一般把中间的直线称为决策面，把离决策面最近的那些点（训练实例）称为支持向量，也就是右图中紫圈中的点。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-36d71b718b27a649.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>有时会遇到无法用直线分类的情况，如左图所示，但可以用圆环划分，右图展示了同样的数据，各个特征值取原始值的平方，变换到新的特征空间后，数据变成了线性可分。将数据从线性不可分转成线性可分的函数称为核函数，转换的方法称为核技巧（这里是取平方的操作，核函数一般将低维数据映射到高维）。由于需要把原始模型转换成线性模型，再进一步操作，我们叫它“广义线性模型”。</p>
<p>这就是一般意义上的支持向量机SVM，它有两个重点：一个是考虑分类时的最大边距，另一个是使用核函数把线性不可分的变成线性可分的。</p>
<p>原理并不难，但具体实现涉及数学较多，如果嫌麻烦，请跳过“求解线性方程”部分。</p>
<h2 id="求解线性方程">2. 求解线性方程</h2>
<p>用线性模型分类，就是求取能把数据正确分类的直线（或平面），使得界两边的各个点离界都最远。有很多点，我们只需要考虑离分割线最近的那些数据点（支持向量）。这是一个求点到直线距离的问题。</p>
<p>初中学过，点(x0,y0)到直线Ax+By+C=0的距离公式是：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-7fc4601ff353e752.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>在多维的情况下，我们一般使用wx+b描述决策面。其中w是权向量，它决定了决策面的方向，b是偏置，它决定了决策面的位置。</p>
<p>求某点x0到决策面wx+b的距离，代入距离公式得到d=|wx0+b|/||w||。</p>
<p>现在求什么样的w和b值能使距离d最小。可以看成在(wx+b)的条件下，求||w||的最小值。即求带条件的最小值，这用到拉格朗日乘子的方法。</p>
<p>拉格朗日乘子用于寻找多元变量在一个或者多个限制条件下的极值点（柱点）。比如求函数f(x1,x2,...)在g(x1,x2,...)=0的约束条件下的极值。其主要思想是将约束条件函数与原函数联系到一起，生成等式方程：<span
class="math inline">\(L(x,λ)=f(x)+λ*g(x)\)</span>，λ为拉格朗日乘子，该公式把带条件的求极值化简成了不带条件的求极值。</p>
<p>在极值点处分别对x和λ求导。这里引入了λ，把求解w变成了求解λ。从而求出距离为最小值的情况下λ应该取什么值，知道了λ又能求w，在不断迭代之后，最终确定了直线的参数。而其中λ不为0的点又正好是支持向量（只有不为0的点是该直线的限定条件）。这样同时把支持向量和分割线都求出来了。</p>
<h2 id="松弛变量">3. 松弛变量</h2>
<p>因为数据不是100%线性可分，因此引入了松弛变量，它是允许变量处于分隔面的错误一测的比例。</p>
<p>松弛变量一般用惩罚系数C设置，C越大对误分类的惩罚越大（越不允许松弛），趋向于对训练集全分对的情况，这样对训练集测试时准确率很高，但泛化能力弱。C值小，对误分类的惩罚减小，允许容错，将他们当成噪声点，泛化能力较强。</p>
<h2 id="维度变化与核函数">4. 维度变化与核函数</h2>
<p>为什么低维不可分的数据变成高维就可分了呢？N个点在N-1维一定是可分的，就好像决策树，只要叶子够多，一定能分开。我们之前看到的PCA降维和此处的核函数升维，都是对数据的映射，就像是换了一个视角，但数据内部的关系不变。<br />
核函数的用途很广泛，SVM只是其中的一种用法，SVM中常用的核函数有：线性，多项式，径向基，S型曲线等。</p>
<h2 id="用途">5. 用途</h2>
<p>SVM是空间几何属性的模型（靠距离远近判断相似性），一般处理数值型数据，常用作分类器。是一种有监督的学习。<br />
从保留数据的角度看，有的算法要保留全部数据比如KNN，有的完全不保留数据比如决策树，SVM是保存一部分数据——支持向量（边界附近的点比其它点更重要），这样即能减少数据，又有明确的意义。<br />
它的泛化错误率低，开销不大，易解释，综合了参数化和非参数化模型的优点。不过它对参数和核函数选择比较敏感。<br />
在神经网络大规模应用之前，它是一种非常流行的算法，尤其在没有领域相关的先验知识的情况下，差不多是最好的不用修改就能很好工作的分类器了。</p>
<h2 id="例程">6. 例程</h2>
<p>调用sklearn中的svm分类器示例<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">clf = svm.SVC(C=1.0, kernel=&#x27;rbf&#x27;) # 指定惩罚系数C，核函数rbf  </span><br><span class="line">clf.fit(X_train,y_train) # 训练  </span><br><span class="line">accuracy = clf.score(X_test,y_test) # 准确度  </span><br><span class="line">print(&quot;accuracy:&quot;,accuracy)   </span><br><span class="line">print(clf.support_vectors_) #支持向量列表，从中看到切分边界  </span><br><span class="line">print(clf.support_) # 支持向量索引  </span><br><span class="line">print(clf.n_support_) # 持持向量个数  </span><br><span class="line">print(&quot;predict &quot;,clf.predict(np.array(item))) # 预测  </span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习_决策树与信息熵</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E4%BF%A1%E6%81%AF%E7%86%B5/</url>
    <content><![CDATA[<h1 id="机器学习_决策树与信息熵">机器学习_决策树与信息熵</h1>
<p>#机器学习 #数学</p>
<h2 id="决策树">1. 决策树</h2>
<p> 决策树(Decision
Tree）是一种预测模型；它是通过一系列的判断达到决策的方法。下面是一个判断是否买房的例子，一共15个实例，有Age,
Has_job, Own_house,
Credit_rating四个属性，树的各个分叉是对属性的判断，叶子是各分枝的实例个数。<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-454746a05a7f520b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="决策树" /><br />
 这是个很简单的例子，只用了两层，每个叶子节点就得到了一致的结果（如2/2），如果不一致，则会使用其它属性递归地划分，直到属性用完，或分支下得到一致的结果，或者满足一定停止条件。对于有歧义的叶子节点，一般用多数表决法。<br />
 决策树的优点是复杂度低，输出结果直观，对中间值缺失不敏感；缺点是可能过拟合，有时用到剪枝的方法避免过拟合。<br />
 决策树的原理看起来非常简单，但在属性值非常多，实例也非常多的情况下，计算量是庞大的，我们需要采用一些优化算法：先判断哪些属性会带来明显的差异，于是引出了信息量的问题。</p>
<h2 id="信息量">2. 信息量</h2>
<p>意外越大，越不可能发生，概率就越小，信息量也就越大，也就是信息越多。比如说“今天肯定会天黑”，实现概率100%，说了和没说差不多，信息量就是0。</p>
<p>信息量=
log2(1/概率)=log2(概率^-1)=-log2(概率)，log2是以2为底的对数。</p>
<p>举个例子：掷色子每个数有1/6的可能性，即log2(6)=2.6，1-6的全部可能性，二进制需要3位描述（3&gt;2.6）；抛硬币正反面各1/2可能性，log(2)=1，二进制用一位即可描述，相比之下，掷色子信息量更大。</p>
<h2 id="熵">3. 熵</h2>
<p><span
class="math display">\[熵=H=-sum(概率*log2(概率))\]</span>可以看到它是信息量的期望值，描述的也是意外程度，即不确定性。0&lt;H&lt;log2(m)，m是分类个数，log2(m)是均匀分布时的熵。二分类熵的取值范围是[0,1]，0是非常确定，1是非常不确定。</p>
<h2 id="信息量与熵">4. 信息量与熵</h2>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-139102cb1ac8e500.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /><br />
分类越多-&gt;信息量越大-&gt;熵越大，如图所示：图Ｃ将点平均分成5类（熵为2.32），图B将点平均分成两类（熵为1），则看起来Ｃ更复杂，更不容易被分类，熵也更大。</p>
<p>分类越平均-&gt;熵越大。图Ｂ（熵为1）比Ａ（熵为0.72）更复杂，更不容易被分类，熵也更大。</p>
<h2 id="信息增益">5. 信息增益</h2>
<p>信息增益(Information
Gain)：熵A-条件熵B，是信息量的差值。也就是说，一开始是Ａ，用了条件后变成了Ｂ，则条件引起的变化是A-B，即信息增益（它描述的是变化Delta）。好的条件就是信息增益越大越好，即变化完后熵越小越好（熵代表混乱程度，最大程度地减小了混乱）。因此我们在树分叉的时候，应优先使用信息增益最大的属性，这样降低了复杂度，也简化了后边的逻辑。</p>
<h2 id="举例">6. 举例</h2>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-613ccb2ed85e301e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /><br />
假设使用8天股票数据实例，以次日涨/跌作为目标分类，红为涨，蓝为跌，如上图所示涨跌概率各50%:50%（2分类整体熵为1），有D,E,F三个属性描述当日状态，它们分别将样本分为两类：方和圆，每类四个。D中方和圆中涨跌比例各自为50%:50%（条件熵为1，信息增益0）。E中方的涨跌比例为25%:75%，圆的涨跌比例为75%:25%（条件熵为0.81，信息增益0.19），F中方的涨跌比例为0:%:100%，圆的涨跌比例为100%:0%（条件熵为0，信息增益1）。</p>
<p>我们想要寻找的属性是可直接将样本分成正例和反例的属性，像属性F为圆一旦出现，第二天必大涨，而最没用的是D，分类后与原始集合正反比例相同。E虽然不能完全确定，也使我们知道当E为圆出现后，比较可能涨，它也带有一定的信息。</p>
<p>使用奥卡姆剃刀原则：如无必要，勿增实体。不确定有用的就先不加，以建立最小的树。比如，如个属性X（代表当日涨幅），明显影响第二天，则优先加入，属性Y（代表当天的成交量），单独考虑Y，可能无法预测第二天的涨跌，但如果考虑当日涨幅X等因素之后，成交量Y就可能变为一个重要的条件，则后加Y。属性Z（隔壁张三是否买了股票），单独考虑Z，无法预测，考虑所有因素之后，Z仍然没什么作用。因此属性Z最终被丢弃。策略就是先把有用的挑出来，不知道是不是有用的往后放。</p>
<h2 id="熵的作用">7. 熵的作用</h2>
<p>熵是个很重要的属性，它不只是在决策树里用到，各个分类器都会用到这个量度。比如说，正例和反例为99:1时，全选正例的正确率也有99%，这并不能说明算法优秀。就像在牛市里能挣钱并不能说明水平高。另外分成两类，随机选的正确率是50%；分而三类，则为33%，并不是算法效果变差了。在看一个算法的准确率时，这些因类都要考虑在内。在多个算法做组合时，也应选择信息增益大的放在前面。</p>
<p>在决策树中利用熵，可以有效地减小树的深度。计算每种分类的熵，然后优先熵小的，依层次划分数据集。熵的算法，一般作为决策树的一部分，把它单拿出来，也可以用它筛选哪个属性是最直接影响分类结果的。</p>
<h2 id="计算熵的程序">8. 计算熵的程序</h2>
<pre><code># -*- coding: utf-8 -*-  
import math  
  
def entropy(*c):  
    if(len(c)&lt;=0):  
        return -1  
    result = 0  
    for x in c:  
        result+=(-x)*math.log(x,2)  
    return result;  
      
if (__name__==&quot;__main__&quot;):  
print(entropy(0.99,0.01));  </code></pre>
<h2 id="决策树的核心程序">9. 决策树的核心程序</h2>
<h4 id="软件安装">(1) 软件安装</h4>
<p>ubuntu系统</p>
<pre><code>$ sudo pip install sklearn  
$ sudo pip install pydotplus  
$ sudo apt-get install graphviz  </code></pre>
<h4 id="代码">(1) 代码</h4>
<pre><code>    # 训练决策树  
    X_train, X_test, y_train ,y_test = cross_validation.train_test_split(X,y,test_size=0.2)  
    clf = tree.DecisionTreeClassifier(max_depth=5)  
    clf.fit(X_train,y_train)  
    accuracy = clf.score(X_test,y_test)  
    print(&quot;accuracy:&quot;,accuracy)  
    # 生成决策树图片  
    dot_data = StringIO()  
    tree.export_graphviz(clf,out_file=dot_data,   
                         feature_names=[&quot;open&quot;,&quot;high&quot;,&quot;low&quot;,&quot;close&quot;,&quot;turnover&quot;],  
                         filled=True,rounded=True,  
                         impurity=False)  
    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
    open(None).write(graph.create_jpg())  </code></pre>
<h2 id="如何看待决策树的结果">10. 如何看待决策树的结果</h2>
<p> 使用sklearn的tree训练数据后，可得到准确度评分。如果数据集中包含大量无意义的数据，评分结果可能不是很高。但是从图的角度看，如果某一个叶子节点，它的实例足够多，且分类一致，有的情况下，我们可以把这个判断条件单独拿出来使用。<br />
 使用一个模型，不是丢进一堆数据，训练个模型，看个正确率，预测一下就完了。要需要仔细去看树中的规则。树本身就是一个无序到有序的变化过程。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习_基于距离的算法KNN与K-Means</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E5%9F%BA%E4%BA%8E%E8%B7%9D%E7%A6%BB%E7%9A%84%E7%AE%97%E6%B3%95KNN%E4%B8%8EK-Means/</url>
    <content><![CDATA[<h1
id="机器学习_基于距离的算法knn与k-means">机器学习_基于距离的算法KNN与K-Means</h1>
<p>#机器学习</p>
<h2 id="距离的量度">1. 距离的量度</h2>
<h4 id="距离">1) 距离</h4>
<p>距离的定义是一个宽泛的概念：只要满足非负、自反、三角不等式就可以称之为距离。其中非负是指任意两个相异点的距离为正；自反是Dis(y,x)=Dis(x,y)；三角不等式是Dis(x,z)&lt;=Dis(x,y)+Dis(y,z)</p>
<h4 id="马氏距离闵可夫斯基距离">2) 马氏距离（闵可夫斯基距离）</h4>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-ffec9a9c0587590e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中d是维数，p是阶数，也称为p范数。<br />
当p=1时，是曼哈顿距离<br />
当p=2时，是欧氏距离<br />
当p→∞时，是切比雪夫距离<br />
当p=0时，是海明距离</p>
<h4 id="欧氏距离">3) 欧氏距离</h4>
<p>两点间的直线距离（一般用两条竖线||w||代表w的2范数）代入公式：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-5d70ae8960a3cd2e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="曼哈顿距离城市街区距离">4) 曼哈顿距离（城市街区距离）</h4>
<p>各坐标数值差的和，就像汽车只能行驶在横平竖直的街道上，代入公式：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-020009595d7d55d0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="切比雪夫距离">5) 切比雪夫距离</h4>
<p>各坐标数值差的最大值，当马氏距离的p→∞时，最终的结果取决于距离最大的维度上的距离：<br />
Dis∞=maxj|xj-yj|<br />
在二维的情况下：c=max(a,b)</p>
<h4 id="海明距离">6) 海明距离</h4>
<p>L0范数并不是一个真正的范数，它主要被用来度量向量中非零元素的个数。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-c867f06e46f931ff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="总结">7) 总结</h4>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-c1e397c097aa589b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 图片从上到下依次显示a与b点的三种距离：欧氏距离（蓝色），切比雪夫距离（红色），曼哈顿距离（绿色）</p>
<h2 id="范数">2. 范数</h2>
<p> 范数是一种强化了的距离概念，根据马氏距离的公式，把x,y两点间的距离看作一个向量z</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-ec9a7447c07052ed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>||z||p是向量z的p范数，也记作Lp范数。<br />
范数包括向量范数和矩阵范数，向量范数表征向量空间中向量的大小，矩阵范数表征矩阵引起变化的大小。上面我们看到的就是L0,
L1, L2, L∞范数的计算方法。<br />
机器学习中常使用范数防止过拟合，它可以计量模型的大小（复杂度），作为惩罚项加入公式，通过迭代计算，在误差和复杂度之间制衡，如公式：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-80ecfeb5ee865f2b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中x是自变量，y是结果，w是参数，通过f(x;w)预测y’，L(y,y’)求真实值与预测值的误差，Ω是惩罚项，λ是惩罚项的系数。目标是求误差最小时参数w的取值。<br />
和上一次SVM篇中讲到的一样，这也是在条件Ω下求误差L极小值的问题，还是拉格朗日乘子法，用系数λ把两式连在一起，变为简单的求极值问题。</p>
<h2 id="knnk近邻算法">3. KNN（K近邻）算法</h2>
<h4 id="k近邻">1) K近邻</h4>
<p>存在一个样本数据集合（训练集），并且样本集中每个数据都存在标签，输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征相比较，然后提取样本集中特征最相似的前K个数据的分类标签。<br />
算法参考Ｋ个距离最近的训练样例，并整合多个目标值，对于分类问题，最简单的方法是投票法，也可以预测各个类别的概率分布，对于回归问题，可取均值，或按距离加权等。<br />
简言之，K近邻就是根据距离实例最近的范例来判定新实例的类别或估值。<br />
K近邻可处理分类和回归问题。它需要记忆全部训练样本，空间复杂度高，计算复杂度高，优点是对异常值不敏感，精度高，但当样本少噪声大时也会过拟合。<br />
对于Ｋ值的选择，一般情况下，起初随着Ｋ增加，分类器的性能会快速提升，但K大到某一点时，性能又会下降，因此需要谨慎选择的Ｋ值，也有一些自动计算K值的方法，后面说。</p>
<h4 id="步骤">2) 步骤</h4>
<ol type="i">
<li>计算欧氏距离<br />
</li>
<li>按距离排序<br />
</li>
<li>选取距离最小的k个点<br />
</li>
<li>确定k点中各分类的出现概率<br />
</li>
<li>返回出现概率最高的分类</li>
</ol>
<h4 id="例程">3) 例程</h4>
<ol type="i">
<li>功能<br />
根据训练集中的四个实例，对新数据[1.2, 1.3]分类<br />
</li>
<li>代码<br />
</li>
</ol>
<pre><code># -*- coding: utf-8 -*-  
  
from numpy import *  
import operator  
  
def classify(inX, dataSet, labels, k):  
    dataSetSize = dataSet.shape[0]  
    diffMat = tile(inX, (dataSetSize, 1)) - dataSet #求inX与训练集各个实例的差  
    sqDiffMat = diffMat**2  
    sqDistances = sqDiffMat.sum(axis=1)  
    distances = sqDistances ** 0.5 # 求欧式距离  
    sortedDistIndicies = distances.argsort() # 取排序的索引，用于排label  
    classCount=&#123;&#125;  
    for i in range(k):  
        voteILabel = labels[sortedDistIndicies[i]]  
        classCount[voteILabel]=classCount.get(voteILabel,0)+1  
    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True)  
    return sortedClassCount[0][0] # 取最多的分类  
  
group = array([[1,1.1],[1,1],[0,0],[0,0.1]]) # 训练集  
labels = [&#39;A&#39;,&#39;A&#39;,&#39;B&#39;,&#39;B&#39;] #　训练集分类  
print classify([1.2,1.3], group, labels, 3) # 对数据点[0,0]分类  </code></pre>
<ol start="3" type="i">
<li>分析<br />
例程中没有调库，直接用python实现了KNN，主要为了解原理，实际操作中一般使用sklearn库中的sklearn.neighbors.NearestNeighbors类。</li>
</ol>
<h2 id="k-means聚类算法">4. K-means聚类算法</h2>
<h4 id="k-means">1) K-means：</h4>
<p>K-means（K均值）聚类，其中k是用户指定的要创建的簇的数目，算法以k个随机质心开始，计算每个点到质心的距离，每个点会被分配到距其最近的簇质心，然后基于新分配到的簇的点更新质心，以上过程重复数次，直到质心不再改变。<br />
该算法能保证收敛到一个驻点，但不能保证能得到全局最优解，受初始质心影响大。可采用一些优化方法，比如先将所有点作为一个簇，然后使用k-均值(k=2)进行划分，下一次迭代时，选择有最大误差的簇进行划分，重复到划分为k个簇为止。<br />
该算法在数据多的时候，计算量大，需要采取一些优化方法，比如一开始计算时只取部分数据。<br />
聚类方法常用于无监督学习，给无标签的数据分类；根据质心的原理也可实现有监督学习中的分类和回归。</p>
<h4 id="评价聚类">2) 评价聚类</h4>
<p>聚类常用于无监督学习，那么如何评价聚类的好坏呢？这里使用了散度。<br />
散度（divergence）可用于表征空间各点矢量场发散的强弱程度，给定数据矩阵X，散度矩阵定义为：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-5de58608cfac0045.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中μ是均值，散度可以理解为各点相对于均值的发散程度。<br />
当数据集D被划分为多个簇D1,D2…Dk时，μj为簇Dj的均值，Sj为簇Dj的散度矩阵，B为将D中各点替换为相应簇均值uj后的散度矩阵。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-2fac4a4926ba3262.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>无论是否划分，整体的散度S不变，它由各个簇内部的散度Sj和各均值相对于整体的散度B组成的。<br />
我们聚簇的目标是增大B，减少各个Sj，就是让簇内部的点离均值更近，各簇间的距离更远。该公式（求散度矩阵的迹）可以作为评价聚类质量的量度。</p>
<h4 id="例程-1">3) 例程：</h4>
<ol type="i">
<li>功能<br />
用sklearn提供的KMeans类实现聚类功能，并画图<br />
</li>
<li>代码<br />
</li>
</ol>
<pre><code># -*- coding: utf-8 -*-    
  
import numpy as np    
import matplotlib.pyplot as plt    
    
from sklearn.cluster import KMeans    
from sklearn.datasets import make_blobs    
    
plt.figure()    
random_state = 170    
X,y = make_blobs(n_samples=200,random_state=random_state)  # 使用sklearn提供的数据  
y_pred = KMeans(n_clusters=3,random_state=random_state).fit_predict(X)    
plt.scatter(X[:,0],X[:,1],c=y_pred)    
plt.show()  </code></pre>
<h2 id="使用注意事项">5. 使用注意事项</h2>
<p>基于距离的算法实际应用中，需要做一些预处理，以便达到更好的效果：<br />
属性多时，最好先降维，以免无意义数据淹没有意义数据。<br />
使用之前最好做直方图分析，查看样本的密集区域。<br />
使用之前需要对各个属性做标准化，以免值大的属性有更大权重。<br />
使用之前最好根据经验对各属性分配不同的权重。<br />
对于无法直接分开的数据，可以考虑使用核函数转换后再计算距离。</p>
<h2 id="算法之间的关系">6. 算法之间的关系</h2>
<p>线性回归，logistic回归，支持向量机，KNN，K-Means都属于基于距离的模型。下面以分类问题为例，看看它们之间的关系。</p>
<p>假设我们有一个训练数据集(xi,yi)，需要预测数据a属于哪个分类，在对数据毫无先验知识的情况下：<br />
我们可能会找一个和a最相近的x，然后把a预测成x对应的分类y，这就是最近邻；</p>
<p>如果觉得一个x不保险（万一它是噪声数据呢），找离它最近的k个点x，看看它们对应的y属性大多数属于哪个分类y，这就是k近邻；</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-fb3d8976093916f2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>如果我们估计这些数据可以被分成一簇一簇（左图），而不是混在一起的，那我们可以用K-Means先把它分成几簇，看a属性哪一簇，然后按簇预测，这样只保存簇心点及该簇对应的分类即可，可以简化数据存储和计算量；</p>
<p>如果不同的簇刚好对应不同的分类，也就是说不同分类在空间上是分离的，那么计算两个簇的质心（中图），连接两个质心（灰线），在连线中间做垂线（黑色），把两类分开，就是logistic回归/线性回归，这样就不需要保存实例，而保存直线参数即可分类；</p>
<p>如果计算直线的时候，考虑到直线到两类的边界（右图），就是SVM支持向量机，它保存边界上的实例和直线的参数，以提供更多的信息。</p>
<p>簇还可以和决策树结合，按照距离把相近的簇合二为一；如果考虑到数据在欧氏空间中的概率分布，还可以在概率模型和几何模型之建立联系……</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习_总结篇_十大经典算法与算法选择</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E6%80%BB%E7%BB%93%E7%AF%87_%E5%8D%81%E5%A4%A7%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E4%B8%8E%E7%AE%97%E6%B3%95%E9%80%89%E6%8B%A9/</url>
    <content><![CDATA[<h1
id="机器学习_总结篇_十大经典算法与算法选择">机器学习_总结篇_十大经典算法与算法选择</h1>
<p>#机器学习</p>
<h2 id="一-数据挖掘十大经典算法">一、 数据挖掘十大经典算法</h2>
<p>最近写了一些机器学习的文档，对应数据挖掘经典算法，列表如下：</p>
<p>####1. 聚类K-Means<br />
<a
href="http://www.jianshu.com/p/95a4bcff2198">《机器学习_基于距离的算法KNN与K-Means》</a></p>
<p>####2. 关联Apriori<br />
<a
href="http://www.jianshu.com/p/0b0d0c3de90d">《机器学习_规则与关联规则模型Apriori、FP-Growth》</a></p>
<p>####3. 最大期望EM<br />
<a
href="http://www.jianshu.com/p/a3572391a42d">《机器学习_隐马尔可夫模型HMM》</a></p>
<p>####4. 决策树DTree<br />
<a
href="http://www.jianshu.com/p/57899140dd14">《机器学习_决策树与信息熵》</a></p>
<p>####5. CART: 分类与回归树<br />
<a
href="http://www.jianshu.com/p/f2a4cbe388a9">《机器学习_用树回归方法画股票趋势线》</a></p>
<p>####6. 贝叶斯Bayes<br />
<a
href="http://www.jianshu.com/p/0a9e5af8a82a">《机器学习_统计模型之（一）贝叶斯公式》</a><br />
<a
href="http://www.jianshu.com/p/83288566f834">《机器学习_统计模型之（二）贝叶斯网络》</a><br />
<a
href="http://www.jianshu.com/p/266898337b82">《机器学习_统计模型之（三）朴素贝叶斯》</a></p>
<p>####7. 线性回归logistic<br />
<a
href="http://www.jianshu.com/p/7e77374e5b33">《机器学习_最小二乘法，线性回归与逻辑回归》</a></p>
<p>####8. 集成算法adaBoost<br />
<a
href="http://www.jianshu.com/p/3c8cca3e1ca2">《机器学习_集成算法》</a></p>
<p>####9. 支持向量机SVM<br />
<a
href="http://www.jianshu.com/p/f40535d08f43">《机器学习_SVM支持向量机》</a></p>
<p>####10. PageRank<br />
（没写）</p>
<p>####11. 其它（特征工程）<br />
<a
href="http://www.jianshu.com/p/9846fc1c4cac">《机器学习_用SVD奇异值分解给数据降维》</a><br />
<a
href="http://www.jianshu.com/p/9a2b5279a021">《机器学习_用PCA主成分分析给数据降维》</a></p>
<p>####12. 总结<br />
 数据挖掘是人工智能的一个分枝，基本覆盖了大部分机器学习算法。<br />
 有了深度学习之后，这些算法大多被归入浅层学习。至于是选择深度学习还是浅层学习，主要还是要看具体问题。两种学习也是强相关的，像在CNN和RNN的算法中其实也容入了浅层学习的很多想法。而HMM和GBDT看起来和深度学习也很相似。我觉得深度模型更值得借鉴的是它可以在多个层次同时调整。在集成浅层算法时，也可以参考。</p>
<h2 id="二-浅谈算法选型">二、 浅谈算法选型</h2>
<p> 以下是一些个人看法，希望在算法选型时给大家一些启发。</p>
<h4 id="算法的分类">1. 算法的分类</h4>
<p> 从开始看第一本讲算法书起，就希望能把算法归类，或者能让算法和问题类型对应起来。但好像并不这么简单。<br />
 《机器学习》（Peter
Flach著）把有学习模型分成三类：几何模型，统计模型，逻辑模型。简单地说，几何模型就是计算实例间的距离；统计模型是对已知变量X与未知变量Y之间的依赖关系统计建模；逻辑模型更偏重规则，每一种算法都被可被划入其中一种至几种分类。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-6976a16c0ac305a6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 虽然不能完全分开，但是遇到具体问题的时候，三选一总比十选一要容易得多。</p>
<h4 id="微调与重构">2. 微调与重构</h4>
<p> 罗曼罗兰说：“大半的人在二十岁或三十岁上就死了。一过这个年龄，他们只变了自己的影子”。这其实挺合理的。当一个基础系统，很多上层都依赖于它时，任何修改都可能导致上层多个系统的崩溃，所以一般系统达到一定规模之后，修改都以查缺补漏为主。一个系统停止更新了，基本也就看到天花板了。<br />
 微调总比重构来得容易，但效果也有限。以ImageNet比赛为例，每一次重大的进步都是因为加入了新结构，而微调和增加算力，效果都不特别特著。<br />
 我们使用现成算法也有这个问题，比如用sklearn库中的算法时，主要是调参，对调用者来说库就是黑盒，没法针对数据的特征做内部的修改，或者在内部嫁接多个算法。用库，你能轻松地赶上大家的水平，但是很难突破。所以有时候，看一个数据挖掘比赛，前十名用的都是同一个算法，大家主要在比调参和特征工程。</p>
<h4 id="有监督无监督与半监督">3. 有监督、无监督与半监督</h4>
<p> 确定有监督、无监督，是选择算法的第一步。这两种情况对应的算法完全不同，不过现在也常把聚类（无监督）放在有监督学习中使用（比如CNN）。<br />
 强化学习是一种半监督学习，一般是根据规则模拟一些场景，用于训练，比如利用左右互博的方式训练下棋，自动驾驶，机器人等等，它可以作为一种有效的数据补充。</p>
<h4 id="精确与启发">4. 精确与启发</h4>
<p> 精确模型对所有数据有效，往往用于预测（比如决策树），而启发模型对部分数据有效，往往用于筛选（比如规则模型）。<br />
 具体选择哪种模型，取决于已知数据带有信息量的多少。如果用属性和结果做图，发现大多数数据都是有规律的，就使精确模型。如果大多数都是噪音，只有少量有价值的点（或者是稀疏的），最好能选用启发模型，至少也要先把有序数据和无序数据分开。</p>
<h4 id="单模式与多模式">5. 单模式与多模式</h4>
<p>取得正确结果的路径往往不止一条，就如同决策树中的分枝，从这个角度看，处理复杂问题的时候，逻辑模型是必不可少的。<br />
 对于多模式，像朴素贝叶斯，线性回归这种简单算法就不太适用了，有时候我们会使用集成算法，把几种算法结合在一起。<br />
 处理具体问题的时候，也需要先判断这是单模式问题，还是多模式问题？单模式，可能倾向用几何距离类的算法，多模式可能要考虑逻辑和统计类，集成算法，或者先看看能不能把数据拆分后再做进一步处理。</p>
<h4 id="总结与推理">6. 总结与推理</h4>
<p> 模型有时被划分成判别式和生成式，判别式的训练过程一般以总结为主，比如决策树，线性拟合；而生成式中加入了一些推理，比如说关联规则，一阶规则，贝叶斯网络等等。选算法时也要注意，是否需要机器推导。</p>
<h4 id="表面与隐藏">7. 表面与隐藏</h4>
<p> 隐马尔可夫模型和神经网络模型中都有隐藏层的概念，它阐释出内在的关系，这类算法常对应一些比较复杂的问题。</p>
<h4 id="线性与非线性">8. 线性与非线性</h4>
<p> 线性指量与量之间按比例、成直线的关系，在数学上可以理解为一阶导数为常数的函数；非线性则指不按比例、不成直线的关系，一阶导数不为常数。<br />
 线性模型指一般线性模型，线性混合模型和广义线性模型（先映射成线性模型，再做处理），比如线性拟合，logistic回归，局部加权线性回归，SVM都属于线性类的模型。有的也能拟合曲线，但作用范围有限。<br />
 神经网络的主要优点之一就是能解决非线性问题。<br />
 线性模型和线性变换都是非常基本元素，算法中几乎无处不在。一般线性模型用只能处理简单的问题，主要是和其它算法组合使用。</p>
<h4 id="相关性组合与分解">9. 相关性、组合与分解</h4>
<p> 分析属性间的关系对选择算法也很重要，有时能看到属性间有明显的关系，比如图像中每个像素与它上下左右的相邻像素都相关，这时候我们使用神经网络中的卷积来替代全连接。<br />
 实例间也可能存在联系，比如股票中涨跌幅就是两日收盘价计算出来的，相比于收盘价，涨跌幅更具意义。<br />
 另外，还有一些不太明显的关系，可以通过分析特征的相关系数得到，并使用降维减小相关性和减少数据。</p>
<h4 id="连续与离散">10. 连续与离散</h4>
<p> 我们拿到的原始数据可能是连续的或是离散的，因为可以相互转换，数据的类型倒不是大问题，不过转换时，也需要注意一些细节。<br />
 比如说连续数据离散化时，需要去考虑切分的方法，像等深、等宽分箱，切分窗口重叠等等，最好能先用直方图分析一下数据的分布。<br />
 离散值转成连续值时也有一些问题，比如把：”男人”，“女人”与“孩子”，映射成0,1,2，那“男人”与“孩子”间的距离更大，这是明显是不合理的，这时候可能需要把一个属性拆成三个。</p>
<h4 id="数据保存">11. 数据保存</h4>
<p> 我们的思维中有多少是真正的思考，有多少是套路呢？如何把习得的套路保存下来，以及重用呢？<br />
 套路可能是决策树规则，可能是神经网络参数，可能是规则列表，又或是典型实例；还有一些学习得来的知识，怎么把它们容入连接成更大的模型？<br />
 对于人来讲，最终得以保存的可能是不可描述的经验和可描述的规则，规则可以是经验总结的，也可以是习得的，可以实例化，又可以加入进一步推导。它所涵盖的可能是全部（树模型），也可能是部分（规则模型），或者是一条主干（线性拟合）加上一些例外（离群点）。</p>
<h4 id="问题类型">12. 问题类型</h4>
<p> 下面看看常见的数据挖掘问题</p>
<ol type="i">
<li><p>纯数据的预测问题：<br />
 通过各个特征值预测结果，比较流行使用GDBT和CNN算法。</p></li>
<li><p>关联问题：<br />
 如根据用户的浏览，收藏，购物，给用户推荐，可能用到聚类，关联规则。</p></li>
<li><p>复杂问题<br />
 涉及一些组合问题，比如自动驾驶，机器人，需要处理一些冲突，均衡，常使用神经网络，博弈算法，有时也用到增强学习。</p></li>
<li><p>专业领域的问题<br />
 如图像处理，音频，自然语言处理，地图数据，涉及专业领域的知识，需要分析数据的具体特点以选择算法。</p></li>
</ol>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习_最小二乘法，线性回归与逻辑回归</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%EF%BC%8C%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%8E%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</url>
    <content><![CDATA[<h1
id="机器学习_最小二乘法线性回归与逻辑回归">机器学习_最小二乘法，线性回归与逻辑回归</h1>
<p>#机器学习 #数学</p>
<h2 id="线性回归">1. 线性回归</h2>
<p> 线性回归是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法。<br />
 直观地说，在二维情况下，已知一些点的X,Y坐标，统计条件X与结果Y的关系，画一条直线，让直线离所有点都尽量地近（距离之和最小），用直线抽象地表达这些点，然后对新的X预测新的Ｙ。具体实现一般使用最小二乘法。</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-439dac3a9810ac63.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="线性回归" />
<figcaption aria-hidden="true">线性回归</figcaption>
</figure>
<p> 线性回归的优点是理解和计算都相对简单，缺点是无法解决非线性问题。</p>
<h2 id="最小二乘法">2. 最小二乘法</h2>
<h4 id="原理">1) 原理</h4>
<p> 最小二乘法（ordinary least
squares，简称OLS）的核心就是保证所有数据偏差的平方和最小（“平方”的在古时侯的称谓为“二乘”）。<br />
 我们用直线拟合一些点，直线方程是 y’=ax+b
，每点偏差是y-y’，其中y是实际值，y’是估计值。sum((y-y’)^2)
最小时，直线拟合最好。上试代入y’，可得 M=sum((y-(ax+b))^2)
，对它求导取极值。此时，x,y是已知的，未知的是a和b，所以分别求M对a和b的偏导，解出的a,b即回归系数，记作W。线性回归就是计算参数W的过程。有了Ｗ，就能将Ｙ表示成多属性的加权线性组合。<br />
 假设有两个变量(多元回归)y’=w0+w1x1+w2x2，就变成了一个三维的问题，同样也用误差平方最小的方法M=sum((y’-(w0+w1x1+w2x2))^2)，Ｍ对w0,w1,w2的偏导为0处是极值，然后解出w0,w1,w2。更多元的情况见下面的公式推导。<br />
 预测时，用回归系数乘以输入值，再将结果加在一起就得到了预测值，一般用矩阵乘法实现。</p>
<h4 id="公式推导">2) 公式推导</h4>
<p> 通过矩阵运算求解回归系数的W={w0,w1,w2…}<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-84b4daf414097a0b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="线性回归代码实现">3. 线性回归代码实现</h2>
<pre><code># -*- coding: utf-8 -*-  
  
import numpy as np  
import matplotlib.pyplot as plt  
  
# 训练  
def standRegres(xArr,yArr):    
    m,n = np.shape(xArr)  
    xMat = np.mat(np.ones((m, n+1))) # 加第一列设为1，为计算截距  
    x = np.mat(xArr)  
    xMat[:,1:n+1] = x[:,0:n];  
    yMat = np.mat(yArr).T    
    xTx = xMat.T*xMat    
    if np.linalg.det(xTx) == 0.0:    
        print(&quot;This matrix is sigular, cannot do inverse&quot;) #行列式的值为0，无逆矩阵  
        return    
    ws = xTx.I*(xMat.T*yMat)    
    return ws    
  
# 预测  
def predict(xArr, ws):  
    m,n = np.shape(xArr)  
    xMat = np.mat(np.ones((m, n+1))) # 加第一列设为1, 为计算截距  
    x = np.mat(xArr)  
    xMat[:,1:n+1] = x[:,0:n];  
    return xMat*ws  
  
if __name__ == &#39;__main__&#39;:  
    x = [[1], [2], [3], [4]]  
    y = [4.1, 5.9, 8.1, 10.1]  
    ws = standRegres(x,y)  
    print(ws)  
    print(predict([[5]], ws))  
  
    # 画图  
    plt.scatter(x, y, s=20)  
    yHat = predict(x, ws)  
    plt.plot(x, yHat, linewidth=2.0, color=&#39;red&#39;)   
    plt.show()  </code></pre>
<p> 注意：回归系数的个数应该比属性多一个，用于表示截距，在sklearn中也是这样，只不过截距相关的放在intercept_中，其它放在coef_中。</p>
<h2 id="逻辑回归">4. 逻辑回归</h2>
<p> 逻辑回归，也叫逻辑斯蒂回归，logistic regression。<br />
 有监督学习常分成：分类和回归，不要一听xx回归，以为就是预测具体值了，这里的“逻辑回归”其实是个分类的方法。之所以叫逻辑回归，是因为最常见用它处理二分类问题，即分类为0或1（逻辑值）。如图所示，它是用一条直线，将实例分类。</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-e41b3bdcdfaee6ea.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="逻辑回归" />
<figcaption aria-hidden="true">逻辑回归</figcaption>
</figure>
<p> 与线性回归不同的只是这里的Ｙ是分类0或１，而不是具体数值。所以它叫广义线性模型。<br />
 把具体数据对应成0,1的方法是sigmoid，sigmoid函数只能分两类，而softmax能分多类，softmax是sigmoid的扩展。</p>
<h2 id="sigmoid函数">5. Sigmoid函数</h2>
<p> Sigmoid函数，就是Ｓ型函数，这就是一个数值和逻辑值间转换的工具，如下图示，它把Ｘ从负无穷到正无穷映射到Ｙ的0-1之间。很多时候需要求极值，而0,1分类不是连续的，不可导，所以用一个平滑的函数拟合逻辑值，因为用了它，所以这叫逻辑回归。<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-66669e10c7214d1f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="Sigmoid" /></p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习_条件随机场CRF</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BACRF/</url>
    <content><![CDATA[<p>#机器学习 #CRF</p>
<h1 id="条件随机场crf">条件随机场CRF</h1>
<h2 id="简介">简介</h2>
<p>在命名实体识别（后简称NER）中，迄今绝大多数模型都使用神经网络和条件随机场结合的方法实现。所以，需要稍微了解一下CRF的原理。</p>
<p>NER是自然语言处理中一个非常基础的任务，简单的说，就是识别句中的成份。比如"小明去学校"，其中“小明”是人名，“去”是动词，“学校”是地点。如果把字当作处理单元，“学”字是动词还是地点，不仅取决于该字的意思，还取决于它的上下文。</p>
<p>CRF可用于解决序列问题（前后状态存在相关性），比如根据第i-1个字来判断第i个字所充当的成份。当CRF与神经网络共同工作时，神经网络负责提取词义，CRF将词义与上下文结合，以实现更准确地判断。</p>
<h2 id="原理">原理</h2>
<p>这里涉及很多概念，比如最大团、马尔可夫性、马尔可夫链等等，本文不做展开，以免过长、过于复杂。</p>
<p>直奔主题，CRF最大的特点是它使用了特征函数。可以把特征函数想象成对输入x提取多个特征，每个特征函数提取一个特征。<br />
<span
class="math display">\[\sum_i^T\sum_k^M\lambda_kf_k(x,y_{i-1},y_i,i)\]</span><br />
序列中共有T个时间步（NER句中有T个字），用i遍历每一时间步（每个字），共有M个特征函数（提取M个特征），用k遍历每个特征函数，特征函数用f表示，其权重用λ表示，不同特征函数的权重各不相同。特征函数是事先定义好的，权重是训练中学出来的。</p>
<p>特征函数的输入包含观测序列x（NER里的句子），状态序列y（成份）的第i-1和第i个位置，以及具体位置的索引i。</p>
<p>上面公式也常常表示成：<br />
<span
class="math display">\[\sum_{i,k}\lambda_kt_k(y_{i-1},y_i,x,i)+\sum_{i,l}\mu_ls_l(y_i,x,i)\]</span><br />
它把前式中的特征函数f拆成了两部分，第一部分是当前项与上下文的关系，第二部分是具体词x与词的成份y之间的关系。两部分有各自的特征函数及权重。</p>
<p>我们看到CRF写成啥样的都有，但无论用什么字符表示，拆成一部分或两部分，其原理都是一样的。</p>
<p>最常见的CRF公式如下，它用于计算：文本序列x的条件下出现成份序列y的概率。<br />
<span
class="math display">\[P(y|x)=\frac{1}{Z(x)}exp\left(\sum_{i,k}\lambda_kt_k(y_{i-1},y_i,x,i)+\sum_{i,l}\mu_ls_l(y_i,x,i)\right)\]</span><br />
其中，Z(x)用于归一化：<br />
<span
class="math display">\[Z(x)=\sum_yexp\left(\sum_{i,k}\lambda_kt_k(y_{i-1},y_i,x,i)+\sum_{i,l}\mu_ls_l(y_i,x,i)\right)\]</span><br />
公式也被简化成：<br />
<span class="math display">\[P_w(y|x)=\frac{exp(w \cdot
F(y,x))}{Z_w(x)}\]</span><br />
其中的w是训练求得的模型参数。这么看，就像是一个求参数w的回归问题。</p>
<h2 id="隐马尔可夫模型与条件随机场">隐马尔可夫模型与条件随机场</h2>
<p>隐马尔可夫模型（HMM）与条件随机场模型（CRF）常放在一起比较，这是由于它们实现的功能基本一致。</p>
<p>HMM 公式如下：<br />
<span class="math display">\[ p(y,x) =
\prod_{t=1}^Tp(y_t|y_{t-1})p(x_t|y_t)\]</span><br />
对比公式可以看出：<br />
* 相同：二项者考虑了前项y-1对后项y的影响，以及x对y的影响。<br />
* 差异：HMM求联合概率p(y,x)，CRF求条件概率p(y|x)。<br />
* 差异：HMM仅考虑x-&gt;y，yi-1-&gt;yi的转移关系。<br />
*
差异：CRF引入了事先设定好的特征函数，计算特征函数时还加入了整个x，考虑到了整句上下文对该点成份的影响。</p>
<h2 id="参考">参考</h2>
<p><a
href="https://www.zhihu.com/question/35866596">如何用简单易懂的例子解释条件随机场（CRF）模型？它和HMM有什么区别？</a><br />
<a
href="https://blog.csdn.net/weixin_42398658/article/details/85222113">NLP
--- 条件随机场CRF（预测算法详解）</a></p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>CRF</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习_用PCA主成分分析给数据降维</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E7%94%A8PCA%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%E7%BB%99%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4/</url>
    <content><![CDATA[<h1
id="机器学习_用pca主成分分析给数据降维">机器学习_用PCA主成分分析给数据降维</h1>
<p>#机器学习 #特征工程</p>
<p>有时我们的数据中包括很多属性，有些是没意义的，有些是重复的，有些组合后意义更明显。此时，我们需要简化属性节约算力，去噪，去冗余，求取更典型的属性，同时又希望不损失数据本身的意义。</p>
<p>主成分分析（Principal Component
Analysis，PCA），是一种统计方法。通过正交变换将一组可能存在相关性的变量转换为一组线性不相关的变量，转换后的这组变量叫主成分。数据分析中常使用PCA给数据降维，它能在指定的损失范围内最大的简化属性。本篇将介绍PCA的原理，Python实现及应用场景。</p>
<h2 id="特征值与特征向量">1 1. 特征值与特征向量</h2>
<p>PCA的核心算法是：协方差矩阵和特征值分解，先来看看特征值分解相关的知识点。</p>
<h3 id="基">1.1 基</h3>
<p>我们无时无刻不用到基，十进制就是以10为基底的描述，一个小时60分钟，60就是基底，再说复杂一点，傅里叶变换中，余弦(或正弦)波是基底，小波变换中小波是基底，可以把它理解成一种基本的参照，比如1公斤，1海里，1升…</p>
<p>一个点在宇宙中本没有坐标，但只要定义了基，它就能被描述。任何的东西都可以借助基来描述。但不管使用什么样的基，上层的实体（逻辑关系）是不变的。比如，珠峰的高度=8848米=8.848千米，实体（高度）并没有改变，只是换了一种表述的方式。这里单位千米对应的就是基底，而数值对应的是坐标，描述的是向线段。</p>
<h3 id="坐标系">1.2 坐标系</h3>
<p>我们可以把不同坐标理解成不同的视角，比如两人看同一场电影，A坐在第一排最左边，B坐在最后一排的正中间。他们看到的是同一个等腰直角三角形（人脑会自动对三维空间做一些校正，所以真实世界中我们感觉变形并不明显）。但如果脱离了屏幕，单看左边的三角形，会难以描述它。而B的视角是直角坐标系，且三角形的两边与坐标轴垂直。同样是把它拉长的操作，在B视角延坐标轴的缩放即可，它比A视角描述和计算都更容易。不过无论坐在哪儿看到的都是同一部电影。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-610888f745ebf191.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>为了简化问题，也可以A移到B的视角，也就是转换的是它的基，具体方法是线性变换，也就是乘矩阵。下图是在坐标系中的视角变换。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-16544e69781782da.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="矩阵相乘的意义">1.3 矩阵相乘的意义</h3>
<p>两个矩阵相乘的意义是将右边矩阵中的每一列列向量变换到左边矩阵中每一行行向量为基所表示的空间中去。图形还是同一个图形，只是变了视角。将结果乘它的逆矩阵又变回了原来的坐标，于是，可以把复杂的变换拆分成：变视角-&gt;简单变换-&gt;视角变回去。</p>
<h3 id="特征值分解">1.4 特征值分解</h3>
<p>先来看看特征值，特征向量到底长什么样？</p>
<h4 id="代码">1.4.1 代码</h4>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> np.array([[<span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>], [<span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>]]) <span class="co"># 矩阵  </span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> np.linalg.eig(a) <span class="co"># 特征值分解  </span></span></code></pre></div>
<h4 id="运行结果">1.4.2 运行结果</h4>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>(array([ <span class="fl">3.</span>,  <span class="fl">1.</span>]),   </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>array([[ <span class="fl">0.70710678</span>,  <span class="fl">0.70710678</span>],  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">0.70710678</span>,  <span class="fl">0.70710678</span>]]))  </span></code></pre></div>
<h4 id="分析">1.4.3 分析</h4>
<p>运行结果的第一个数组是特征值，它是一个对角阵，所以只给出了对角线上的数据，第二个数组是特征向量矩阵。</p>
<p>它将矩阵A的变换拆分成了：旋转-&gt;拉伸-&gt;再转回去。<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-32a04a113b6eff67.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中P是负责旋转到正交的坐标系（各轴相互垂直）的“特征向量”，而
则是负责拉伸的“特征值”，它在一个方向上拉伸了3倍，另一个方向拉伸了1倍。拉抻值大的，就是它的主方向。</p>
<p>也可以把乘以特征向量当成正交分解。从物理角度上讲，是将一个力分解为Fx和Fy两个相互垂直的分力的方法，叫作力的正交分解。在这里是把矩阵分解成由特征向量指定的垂直（正交）的坐标系中的分量。</p>
<h2 id="协方差矩阵">2 协方差矩阵</h2>
<p> 协方差表达的是属性与属性间的相关程度，就是一个值变时，另一个值发生多大变化。<br />
 公式是Cov[X,y]=E((X-E(X))(Y-E(Y)))，E是期望值(重心)，这里先简单看作均值(即每种可能出现概率一样)，每个X,Y都会多少偏离均值，当X和Y偏离方向总是一致是它们正相关，总是相反时负相关，不一定时无关。<br />
协方差的值也会由于具体属性值的大小而受影响，相关系数更进一步，它是用X、Y的协方差除以X的标准差和Y的标准差，因此我们也常用相关系数来判断特征之间的关系。<br />
 协方差矩阵也有它解决不了的问题，它能判断两两属性间的关系，但遇到A,B共同决定C时就无能为力了，而且它只能表述线性关系，对于非线性也视为不相关（这就是为什么不线性相关的属性却不一定相互独立）<br />
 PCA就是对协方差矩阵做特征值分解。</p>
<h2 id="pca步骤">3 PCA步骤</h2>
<ul>
<li>去除平均值<br />
先求每个属性的均值，然后将整个矩阵减去均值，为计算协方差做准备。<br />
</li>
<li>计算协方差矩阵<br />
协方差矩阵是度量维度间的差异，而非样本间差异。协方差矩阵的主对角线上的元素是各个维度上的方差<br />
</li>
<li>计算协方差矩阵的特征值和特征向量<br />
对角化，使得除对角线外，其它元素为０，将能量归于主要方向。<br />
</li>
<li>将特征值排序<br />
</li>
<li>保留最大的N个特征值<br />
</li>
<li>将数据转换到特征向量构建的新空间中</li>
</ul>
<h2 id="程序">4 程序</h2>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> <span class="op">*</span>  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pca(dataMat, topNfeat<span class="op">=</span><span class="dv">9999999</span>): <span class="co"># 只何留特征值最大的前topNfeat个特征  </span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    meanVals <span class="op">=</span> mean(dataMat, axis<span class="op">=</span><span class="dv">0</span>) <span class="co"># 均值  </span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    meanRemoved <span class="op">=</span> dataMat <span class="op">-</span> meanVals  </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    covMat <span class="op">=</span> cov(meanRemoved, rowvar<span class="op">=</span><span class="dv">0</span>) <span class="co"># 协方差  </span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    eigVals,eigVects<span class="op">=</span>linalg.eig(mat(covMat)) <span class="co"># 计算特征值、特征向量  </span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    eigValInd <span class="op">=</span> argsort(eigVals) <span class="co"># 从小到大排序，返回索引值数组  </span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    eigValInd <span class="op">=</span> eigValInd[:<span class="op">-</span>(topNfeat<span class="op">+</span><span class="dv">1</span>):<span class="op">-</span><span class="dv">1</span>] <span class="co"># 保留后topNfeat个,然后调转先后  </span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(<span class="dv">0</span>)  </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    plt.plot(eigVals) <span class="co"># 特征值绘图，看看前几个最重要  </span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    redEigVects <span class="op">=</span> eigVects[:,eigValInd] <span class="co"># 按eigValInd排序和去掉列  </span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(redEigVects)  </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    lowDDataMat <span class="op">=</span> meanRemoved <span class="op">*</span> redEigVects <span class="co"># 转向新空间,行数不变，列按参数减少  </span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    reconMat <span class="op">=</span> (lowDDataMat <span class="op">*</span> redEigVects.T) <span class="op">+</span> meanVals <span class="co"># 再转回旧空间  </span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> lowDDataMat, reconMat  </span></code></pre></div>
<h2 id="程序分析">5 程序分析</h2>
<h3 id="特征值">5.1 特征值</h3>
<p>特征值分解之后，特征值越大说明该方向上的变化越大，越重要，反之不重要，则可以去掉，此方法可用于降维。如果对50维数据求特征值，发现只有5个值较大，其它都非常小，则说明只需要考虑这5个综合因素即可。</p>
<p>分解将向量拆分成正交的线性组合，正交也保证了“综合因素”的相互独立。</p>
<h3 id="方差">5.2 方差</h3>
<p>协方差矩阵的对角线就是各个特征的方差，方差阐释了数据的发散程度，在几个维度中，某一维方差最大，说明数据在该轴上分布得越广，该轴就是覆盖差异最大的坐标轴。具体应用比如：在聚类问题中，我们更希望最后汇聚成发散的几块，而不是团在一起。因此可以考虑以方差最大的方向分成几块，作为聚类的初始点。</p>
<h3 id="协方差">5.3 协方差</h3>
<p>协方差Cov(X,Y)=E((X-E(X)(Y-E(Y)))，其中E为期望值,
E(XY),就是XY乘积的均值，是两个变量总体误差的期望。如果把均值作为0，而上下波动的误差作为能量，则协方差就是能量的期望，协方差矩阵就是能量矩阵。它呈现的不是值的关系，而是变化的关系。具体应用比如：配置资产时，相关性高可能带来更高风险，选择独立的资产配置，或负相关的，可以对冲风险。</p>
<h2 id="使用">6 使用</h2>
<ul>
<li>PCA一般用于多维数据，它可以把N维数据转到M维空间，比如50维变5维，运算量就少了很多。<br />
</li>
<li>PCA只是分析特征间的关系，与结果无关，可视为一种无监督学习。<br />
</li>
<li>虽然转换后意义不够直观，但低维向量再乘特征向量的逆矩阵，还可以转回来。<br />
</li>
<li>从协方差矩阵看各属性的相互关系, 启发得到一些重要属性。<br />
</li>
<li>可取到特征值，通过其大小，判断信息量的多少。<br />
</li>
<li>用PCA去噪的原理是，认为被去掉的那些小的特征值是噪差干扰导致。<br />
</li>
<li>上例只为说明原理，实际应用中，一般直接调用sklearn库提供的PCA类</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习_统计模型之（一）贝叶斯公式</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%9E%8B%E4%B9%8B%EF%BC%88%E4%B8%80%EF%BC%89%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F/</url>
    <content><![CDATA[<h1
id="机器学习_统计模型之一贝叶斯公式">机器学习_统计模型之（一）贝叶斯公式</h1>
<p>#机器学习 #数据分析 #数学</p>
<h2 id="贝叶斯法则">1. 贝叶斯法则</h2>
<p> 先举个例子：比如事件X是努力，事件Y是成功，能成功的基本都努力了（条件Ｙ成立时，Ｘ必然成立）；但是努力不一定都能成功（条件X成立时，Y不是一定成立）。也就是说，X与Y之间的关系不对等，但X和Y又确实有关系。贝叶斯法则就是用来描述这种关系的。<br />
 所有要是有人说“成功源于努力，所以努力必能成功”，那是心灵鸡汤。正确的说法是努力能把成功的可能性提高一点。</p>
<h2 id="贝叶斯公式">2. 贝叶斯公式</h2>
<p> 事件Ｘ发生的概率，称为边缘概率，记作P(X) 。<br />
 事件Y在事件X已经发生条件下的发生概率，称为条件概率，记为P(Y|X) 。<br />
 事件X,Y共同发生的概率称为联合概率，记为P(XY) 或者P(X,Y)。</p>
<p>有公式：<br />
 P(XY) = P(Y)P(X|Y)=P(X)P(Y|X)<br />
 P(Y|X)=P(XY)/P(X)=P(Y) P(X|Y)/P(X)</p>
<p> 还用上面的例子，稍作调整：假设有50%的人努力了，即P(X)=50%；有20%的人成功了P(Y)=20%；且知道成功的人75%都努力了P(X|Y)=75%；求如果努力有多大成功率？</p>
<p> 努力且成功的人：P(X,Y)=P(X|Y)P(Y)=75%*20%=15%<br />
 努力的人有多大成功率：P(Y|X)=P(X,Y)/P(X)=15%/50%=30%</p>
<p>完整的贝叶斯公式:</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-c42722b6b378b3b1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 完整公式中，分母是所有努力者，即“努力&amp;成功”和“努力&amp;不成功”之和，上例中直接给出这两部分之和：有50%的人努力了。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-6e604f3e69b5f8ca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 有时候我们需要自己计算分母，比如将题目改为：有20%的人成功了P(Y1)=20%，成功的人有75%是努力的P(X1|Y1)=75%，不成功的人有43.75%是努力的P(X1|Y0)=43.75%，如上图所示。这里用Y1表示成功Y0表示不成功，X1表示努力X0示不努力。<br />
 此时，代入完整公式得到：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-ae55e382aec1e73f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="相关概念">3. 相关概念</h2>
<h4 id="先验后验">(1) 先验/后验</h4>
<p> 先验概率+样本信息=&gt;后验概率<br />
 先验概率是在进行一系列具体的观测和实验之前就知道的量P(Y)，一般来源于经验和历史资料。而后验概率一般认为是在给定样本的情况下的条件分布P(Y|X)。先验与样本的结合也是：规则和实践的结合。<br />
 将学习视为一个减少不确定性的过程，即用X带来的信息不断修改Y判断标准的过程，每一次训练之后，后验变为下一次的先验，不断重复。</p>
<h4 id="判别模型与生成模型">(2) 判别模型与生成模型</h4>
<p> 判别式模型是直接计算条件概率P(Y|X)建模，简单的说就是用正例反例直接做除法算出概率，常见的有线性回归，SVM等。<br />
 生成式模型是通过联合概率P(X,Y)，和贝叶斯公式求出P(Y|X)，其中包括推理的过程，常见的有朴素贝叶斯，HMM等。</p>
<h4 id="拉普拉斯平滑修正">(3) 拉普拉斯平滑（修正）</h4>
<p> 拉普拉斯平滑（Laplace Smoothing）又被称为加 1
平滑，它主要解决的是在概率相乘的过程中，如果有一个值为0，会导致结果为0的问题。<br />
 具体的方法是：分子加1，分母加K，K代表类别数目。<br />
 比如：p(X1| C1)是指的在垃圾邮件C1这个类别中，单词X1出现的概率。<br />
 p(X1|C1)= n1 /
n，n1为X1出现的次数，n为总单词数。当X1不出现时P(X1|C1)=0，修正后p(X1|C1)=(n1+1)/(n+N)，其中N是词库中所有单词的数目。</p>
<h4 id="似然函数">(4) 似然函数</h4>
<p> 概率描述了已知参数时的随机变量的输出结果；似然则用来描述已知随机变量输出结果时，未知参数的可能取值。<br />
 假设条件是X，结果是Y，条件能推出结果X-&gt;Y，但结果推不出条件，现在手里有一些对结果Y的观测值，想求X，那么我们举出X的所有可能性，再使用X-&gt;Y的公式求Y，看哪个X计算出的Y和当前观测最契合，就选哪个X。这就是求取最大似然的原理。<br />
 计算似然函数时，常使用似然函数的对数形式，即“对数似然函数”。它简化了操作（取对数后乘法变为加法），同时也避免了连乘之后值太小的问题。</p>
<h2 id="总结">4. 总结</h2>
<p> 统计模型的优势在于，用概率代替硬规则，如果两种可能性：0.51:0.49和0.99:0.01，如果用于预测，都会选前面的那种可能性，但是概率能展示出更多的信息。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>数学</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习_用SVD奇异值分解给数据降维</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E7%94%A8SVD%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3%E7%BB%99%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4/</url>
    <content><![CDATA[<h1
id="机器学习_用svd奇异值分解给数据降维">机器学习_用SVD奇异值分解给数据降维</h1>
<p>#机器学习 #数学</p>
<p> 本想把PCA和SVD写在一起，可上篇PCA还没写清楚就已经4页word了。再把SVD和特征工程的内容加上，实在是太长了，一下说太多也记不住，于是重开一篇。<br />
 SVD用到的原理和
PCA非常相似，就不再此赘述了，如果对特征值、特征向量相关问题不清楚请参见前篇<a
href="http://www.jianshu.com/p/9a2b5279a021">《机器学习_用PCA主成分分析给数据降维》</a></p>
<h2 id="原理">1. 原理</h2>
<p> 先回忆一下特征值分解：把向量x往特征向量方向上分解，然后每个方向上做伸缩，最后再把结果加起来即可。也可以理解为将向量x转到正交坐标系，在各个坐标轴的方向上缩放后，再转换回原来的坐标系。只有方阵才能做特征值分解，因此我们在PCA中不是直接对数据做分解，而是对参数的协方差矩阵做分解。<br />
 我们知道，任何矩阵都可以分解为三个矩阵的乘积 A=U * Sigma *
VT，也就是奇异值分解．其中 U 和VT 均是酉阵(正交阵在复数域的推广)，而
Sigma 为增广对角阵。从直观上讲，U 和 VT 可视为旋转操作，Sigma
可视为缩放操作。因此奇异值分解的含义就是说，若将矩阵看做一个变换，那么任何这样的变换可以看做是两个旋转和一个缩放变换的复合，这点和特征值分解基本一样。它也可以通过对Sigma的调整实现降维，通过U和VT在高维和低维间转换。相比特征值分解，奇异值分解可处理的不只是协方差矩阵（方阵），还可以直接处理数据。<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-31453450a952f1f2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片引自百度百科" /></p>
<p> 但SVD也有一些问题，比如数据多的时候，奇异值分解的计算量会很大，不像PCA做特征值分解时，矩阵的大小只和属性个数相关。</p>
<h2 id="例程">2. 例程</h2>
<h4 id="功能">(1) 功能</h4>
<p>对矩阵A做SVD分解；降维；原始数据转到低维度；降维后的数据恢复到原来维度，看数据损失。</p>
<h4 id="代码">(2) 代码</h4>
<pre><code>from numpy import linalg  
import array  
import numpy as np  
  
A=np.mat([[1,2,3],[4,5,6]])    
U,Sigma,VT=linalg.svd(A)    
print(&quot;U&quot;,U)  
print(&quot;Sigma&quot;,Sigma)  
print(&quot;VT&quot;,VT)  
Sigma[1]=0 # 降维  
print(&quot;Sigma&quot;,Sigma)  
  
S = np.zeros((2,3))  
S[:2, :2] = np.diag(Sigma)  
print(&quot;A conv:&quot;, np.dot(np.dot(A.T, U), S)) # 原始数据转到低维  
print(&quot;A&#39;:&quot;, np.dot(np.dot(U, S), VT)) # 恢复原始维度  </code></pre>
<h4 id="运行结果">(3) 运行结果</h4>
<pre><code>(&#39;U&#39;, matrix([[-0.3863177 , -0.92236578],  
        [-0.92236578,  0.3863177 ]]))  
(&#39;Sigma&#39;, array([ 9.508032  ,  0.77286964]))  
(&#39;VT&#39;, matrix([[-0.42866713, -0.56630692, -0.7039467 ],  
        [ 0.80596391,  0.11238241, -0.58119908],  
        [ 0.40824829, -0.81649658,  0.40824829]]))  
(&#39;Sigma&#39;, array([ 9.508032,  0.      ]))  
(&#39;A conv:&#39;, matrix([[-38.7526545 ,   0.        ,   0.        ],  
        [-51.19565893,   0.        ,   0.        ],  
        [-63.63866337,   0.        ,   0.        ]]))  
(&quot;A&#39;:&quot;, matrix([[ 1.57454629,  2.08011388,  2.58568148],  
        [ 3.75936076,  4.96644562,  6.17353048]]))  </code></pre>
<h4 id="分析">(4) 分析</h4>
<p> SVD分解矩阵A，A是一个2x3（m<em>n，其中m是行数）的矩阵，把它分解成三个矩阵的乘积：A=U
</em> Sigma *
VT，其中U的大小是2x2（m<em>m），VT为3</em>3（n<em>n），Sigma为min(m,n)，从矩阵乘法的角度上看，Sigma的大小应该是m</em>n，由于它是对角阵，为了简化，这里只取了对角线上元素。<br />
 Sigma奇异值为（9.508032，0.77286964），两值差异很大，说明转换后特征主要集中在一个维度上，于是降维，Sigma调整
为（9.508032，0）。将原始矩阵A转置后乘U和调整后的Sigma，实现了对A的降维。最后，将调整后的Sigma与U,VT相乘，映射回原始维度，变为矩阵A’，对比之下，A’与A的也差不太多。不过把两维降成一维还是挺夸张的，在此只为举例，大家领会精神吧。<br />
 这里比较重的是：观察Sigma，决定保留前几项？svd()函数对求出的奇异值和奇异向量按大小做了排序，其中值明显大的前N项，说明有N个“综合参数”最重要，因此，可以将数据降成N维。可降维度的多少，主要还是看数据的相关性，相关性越大，越适合降维。</p>
<h2 id="具体应用">3. 具体应用</h2>
<h4 id="图片压缩">(1) 图片压缩</h4>
<p> 把图片的像素放一个矩阵里，做SVD分解，只保留Sigma中值大的前N项。则存储时只需保存三个矩阵，假设原图大小100x100，N为5，则原图要10000点存储，而拆分后100x5+100x5+5=1005，图像大小变为原来的1/10。</p>
<h4 id="数据降维">(2) 数据降维</h4>
<p> 矩阵中记20人试吃这5种套餐的评价（5x20），先对整体数据做SVD分解，假设保留Sigma的前3项，把原矩阵转置并和U,Sigma相乘，矩阵就从5<em>20维变成了3</em>5维。再套用各种学习算法时，数据就大大缩减了（从高维到低维投影）。不过20个维度变为3个维度后，属性意义也不像之前那么直观了，我们可以使用VT矩阵把数据恢复到原来的维度。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习_统计模型之（三）朴素贝叶斯</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%9E%8B%E4%B9%8B%EF%BC%88%E4%B8%89%EF%BC%89%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</url>
    <content><![CDATA[<h1
id="机器学习_统计模型之三朴素贝叶斯">机器学习_统计模型之（三）朴素贝叶斯</h1>
<p>#机器学习 #数学</p>
<h2 id="条件独立假设">1. 条件独立假设</h2>
<p>条件独立假设简单的说就是特征x1和x2没有关系，比如说兔子的特征中，尾巴短和爱吃萝卜这两个特征它们分别和兔子相关，但两特征彼此之间无关，不是说尾巴短的都爱吃萝卜。所以有p(x2|x1)=p(x2)，即无论x1是什么，x2的概率都不变。朴素贝叶斯就是以条件独立假设为基础的。</p>
<h2 id="概率的乘法">2. 概率的乘法</h2>
<p>两个独立事件都发生的联合概率等于两个事件发生概率的乘积。<br />
当P(A)与P(B)无关时，P(B)=P(B|A)，所以P(A,B)=P(A)|P(B|A)=P(A)P(B)<br />
比如：目标是判断该动物是不是兔子，有三个属性：长耳朵P(A)=70%，短尾巴P(B)=50%，爱吃萝卜P(C)=60%，当三个条件都为真时:<br />
P(A,B,C)=P(A) * P(B) * P(C)=70% * 50% * 60% = 21%，<br />
奇怪，三个条件都为真，结果概率却小了？概率小不小主要看跟谁比，再看看三个条件都不成立时：<br />
(1-P(A)) * (1-P(B)) * (1-P(C))=30% * 50% * 40%=6%，<br />
对比这两个值21:6，就能判断它是一只兔子了。</p>
<h2 id="朴素贝叶斯">3. 朴素贝叶斯</h2>
<p>朴素贝叶斯（Naive Bayesian) 是贝叶斯分类器中应用最为广泛的算法之一,
之所以称为”朴素”是因为它有两个假设：特征之间相互独立，每个特征同等重要。<br />
完整公式是：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-f840d1953dd6f9eb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>前文说过它是贝叶斯网络的特殊情况：即网络中无边，各个节点都是独立的。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-59fd73fde6da679b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>它的优点是：对缺失数据不太敏感，算法也比较简单，结果比较直观。而缺点是：基于假设属性之间相互独立，这个假设在实际应用中往往是不成立的，容易产生高度相关特征的双重计数．赋于更高的比重。所以我们尽量在数据降维（去相关性）之后，再使用它。</p>
<h2 id="例程">4. 例程</h2>
<h4 id="功能">(1) 功能</h4>
<p>通过训练判断句子的感情色彩</p>
<h4 id="代码">(2) 代码</h4>
<pre><code># -*- coding: utf-8 -*-  
  
from numpy import *  
  
# 训练数据  
def loadDataSet():  
    postingList=[[&#39;my&#39;, &#39;dog&#39;, &#39;has&#39;, &#39;flea&#39;, &#39;problems&#39;, &#39;help&#39;, &#39;please&#39;],  
                 [&#39;maybe&#39;, &#39;not&#39;, &#39;take&#39;, &#39;him&#39;, &#39;to&#39;, &#39;dog&#39;, &#39;park&#39;, &#39;stupid&#39;],  
                 [&#39;my&#39;, &#39;dalmation&#39;, &#39;is&#39;, &#39;so&#39;, &#39;cute&#39;, &#39;I&#39;, &#39;love&#39;, &#39;him&#39;],  
                 [&#39;stop&#39;, &#39;posting&#39;, &#39;stupid&#39;, &#39;worthless&#39;, &#39;garbage&#39;],  
                 [&#39;mr&#39;, &#39;licks&#39;, &#39;ate&#39;, &#39;my&#39;, &#39;steak&#39;, &#39;how&#39;, &#39;to&#39;, &#39;stop&#39;, &#39;him&#39;],  
                 [&#39;quit&#39;, &#39;buying&#39;, &#39;worthless&#39;, &#39;dog&#39;, &#39;food&#39;, &#39;stupid&#39;]]  
    classVec = [0,1,0,1,0,1]    #分类：1 is abusive, 0 not  
    return postingList,classVec  
      
# 建立所有词汇列表  
def createVocabList(dataSet):  
    vocabSet = set([])  
    for document in dataSet:  
        vocabSet = vocabSet | set(document)  
    return list(vocabSet)  
  
# 用词汇列表将训练集中的词转换成：句中存在为1，不存在为0  
def setOfWords2Vec(vocabList, inputSet):  
    returnVec = [0]*len(vocabList)  
    for word in inputSet:  
        if word in vocabList:  
            returnVec[vocabList.index(word)] = 1   
        else:   
            print(&quot;the word: %s is not in my Vocabulary!&quot; % word)  
    return returnVec  
  
# 训练  
def trainNB0(trainMatrix, trainCategory):  
    numTrainDocs = len(trainMatrix) #　矩阵的行数  
    numWords = len(trainMatrix[0]) # 矩阵的列数  
    pAbusive = sum(trainCategory)/float(numTrainDocs) # 正例在总数中占比  
    p0Num = ones(numWords); p1Num = ones(numWords) # p0Num是一个数组，大小是所有不重词数  
    p0Denom = 2.0; p1Denom = 2.0  
    for i in range(numTrainDocs): # 按每句遍历  
        if trainCategory[i] == 1:  
            p1Num += trainMatrix[i] # 数组按每个值相加  
            p1Denom += sum(trainMatrix[i]) # 句子所有词个数相加  
        else:  
            p0Num += trainMatrix[i]  
            p0Denom += sum(trainMatrix[i])  
    p1Vect = log(p1Num/p1Denom) # 数组除以数，正例时，每个词出现概率  
    p0Vect = log(p0Num/p0Denom)  
    return p0Vect, p1Vect, pAbusive # 条件概率  
  
# 分类  
def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):  
    p1 = sum(vec2Classify * p1Vec) + log(pClass1)    #element-wise mult  
    p0 = sum(vec2Classify * p0Vec) + log(1.0 - pClass1)  
    if p1 &gt; p0:  
        return 1  
    else:  
        return 0  
  
if __name__ == &#39;__main__&#39;:  
    listOPosts,listClasses = loadDataSet()  
    myVocabList = createVocabList(listOPosts)  
    trainMat=[]  
    for postinDoc in listOPosts:  
        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))  
    p0V,p1V,pAb = trainNB0(array(trainMat),array(listClasses))  
    testEntry = [&#39;love&#39;, &#39;my&#39;, &#39;dalmation&#39;]  
    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))  
    print(testEntry,&#39;classified as: &#39;,classifyNB(thisDoc,p0V,p1V,pAb))  
    testEntry = [&#39;stupid&#39;, &#39;garbage&#39;]  
    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))  
    print(testEntry,&#39;classified as: &#39;,classifyNB(thisDoc,p0V,p1V,pAb))  </code></pre>
<h4 id="运行结果">(3) 运行结果</h4>
<pre><code>([&#39;love&#39;, &#39;my&#39;, &#39;dalmation&#39;], &#39;classified as: &#39;, 0)  
([&#39;stupid&#39;, &#39;garbage&#39;], &#39;classified as: &#39;, 1)  </code></pre>
<h2 id="sklearn中的工具">3. sklearn中的工具</h2>
<p>上例只为说明原理，一般使用朴素贝叶斯的时候都是调库，sklearn中提供以下常用工具：<br />
GaussianNB：先验为高斯分布的朴素贝叶斯，用于连续型变量。<br />
MultinomialNB：先验为多项式分布的朴素贝叶斯，多用于文本分类，统计出现次数。partial_fit()方法可以进行多次训练。<br />
BernoulliNB：先验为伯努利分布（二值分布）的朴素贝叶斯，变量是布尔型的。</p>
<h2 id="用途">4. 用途</h2>
<p>朴素贝叶斯常用于信息检索，文本分类，识别垃圾邮件等领域。</p>
<h2 id="一些想法">5. 一些想法</h2>
<p>说一些自己的想法，也不一定对。<br />
简单地说朴素贝叶斯就是按概率求合，然后比一下是正例的概率大还是反例的概率大。<br />
从贝叶斯网络的角度看，条件独立性去掉了网络中所有的依赖连接，把网络结构简化成了单层，是一个非常简单的模型，就像线性拟合似的，所以外理不了一个场景里的多种模式，如需处理，只能用集成模型组合多个简单模型。直觉上，朴素贝叶斯更适合数据多，属性多，分层少的应用。说它经典不是因为它功能强，而是因为其它足够简单和基础，可以作为组合的基本单元。<br />
它有一种用法是处理稀疏的特征，比如说用它处理文本，需要先去掉停用词（有点像减掉均值），否则有意义的信息会被巨量的无意义信息吞没。<br />
朴素贝叶斯也并不一定用于分类或回归，也可用于分析导致结果的重要条件，比如分别给正反例中的出现的属性按频率排序。间接地提炼有意义的特征，有点像从常识中把反常的点挑出来。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习_统计模型之（二）贝叶斯网络</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%9E%8B%E4%B9%8B%EF%BC%88%E4%BA%8C%EF%BC%89%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h1
id="机器学习_统计模型之二贝叶斯网络">机器学习_统计模型之（二）贝叶斯网络</h1>
<p>#机器学习 #数据分析 #数学</p>
<h2 id="贝叶斯网络">1. 贝叶斯网络</h2>
<p> 贝叶斯网络(Bayesian network)，又称信念网络(Belief
Network)，或有向无环图模型。它用网络结构代表领域的基本因果知识。<br />
 贝叶斯网络中的节点表示命题（或随机变量），认为有依赖关系（或非条件独立）的命题用箭头来连接。<br />
 令G =
(I,E)表示一个有向无环图(DAG)，其中I代表图形中所有的节点的集合，而E代表有向连接线段的集合，且令X
= (Xi)， i ∈
I为其有向无环图中的某一节点i所代表的命题，则节点X的联合概率可以表示成：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-f59a5515b4e55a87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 其中Pa(i)是i的父结点，是i的因。联合概率可由各自的局部条件概率分布相乘得出：<br />
 p(x1,…,xk)=p(xk|x1,….,xk-1)…p(x2|x1)p(x1)<br />
 这里顺便说一下朴素贝叶斯，由于其中各个变量x相互独立p(x2|x1)=p(x2)，得出：<br />
 p(x1,…,xk)=p(xk)…p(x2)p(x1)<br />
 因此说朴素贝叶斯是贝叶斯网络的一种特殊情况。</p>
<h2 id="例程">2. 例程</h2>
<h4 id="功能">(1) 功能</h4>
<p> eBay的Bayesian-belief-networks是一个贝叶斯网络的python工具包，此例为使用该库解决蒙提霍尔三门问题。</p>
<h4 id="问题描述">(2) 问题描述</h4>
<p> 蒙提霍尔是概率中的经典问题，出自美国的电视游戏节目。问题的名字来自该节目的主持人蒙提•霍尔（Monty
Hall）。参赛者会看见三扇关闭了的门，其中一扇的后面有一辆汽车，选中后面有车的那扇门可赢得该汽车，另外两扇门后面则各藏有一只山羊。当参赛者选定了一扇门，但未去开启它的时候，节目主持人开启剩下两扇门的其中一扇，露出其中一只山羊（主持人不会打开有车的那扇门）。主持人其后会问参赛者要不要换另一扇仍然关上的门。问题是：换另一扇门会否增加参赛者赢得汽车的机率？答案是：不换门的话，赢得汽车的几率是1/3。换门的话，赢得汽车的几率是2/3。<br />
 这是为什么呢？接着往下看。</p>
<h4 id="下载安装">(3) 下载安装</h4>
<pre><code>$ git clone https://github.com/eBay/bayesian-belief-networks  </code></pre>
<h4 id="代码">(4) 代码</h4>
<pre><code>from bayesian.bbn import build_bbn  
  
def f_prize_door(prize_door):  
    return 0.33333333  
def f_guest_door(guest_door):  
    return 0.33333333  
def f_monty_door(prize_door, guest_door, monty_door):  
    if prize_door == guest_door:  # 参赛者猜对了  
        if prize_door == monty_door:  
            return 0     # Monty不会打开有车的那扇门，不可能发生  
        else:  
            return 0.5   # Monty会打开其它两扇门，二选一  
    elif prize_door == monty_door:  
        return 0         #  Monty不会打开有车的那扇门，不可能发生  
    elif guest_door == monty_door:  
        return 0         # 门已经由参赛者选定，不可能发生  
    else:  
        return 1    # Monty打开另一扇有羊的门  
  
if __name__ == &#39;__main__&#39;:  
    g = build_bbn(  
        f_prize_door,  
        f_guest_door,  
        f_monty_door,  
        domains=dict(  
            prize_door=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;],  
            guest_door=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;],  
            monty_door=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;]))  
  
    g.q()  
    g.q(guest_door=&#39;A&#39;)  
g.q(guest_door=&#39;A&#39;, monty_door=&#39;B&#39;)  </code></pre>
<h4 id="运行结果">(5) 运行结果</h4>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-1739687c3c74bb2b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="分析">(6) 分析</h4>
<p> 程序中构建的贝叶斯网络如下图所示。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-b8222f72529190d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 先看看库是如何使用的，首先通过三个判别函数（节点对应的是判别函数，并不对应三个门）以及它们之间的依赖关系定义了网络g的结构，节点和连线关系是程序员根据业务逻辑定义的。而机器用来优化和计算在给定的条件下产生结果的概率。<br />
 prize_door和guest_door都是随机的，所以概率都是0.333；而主持人知道哪扇门后是奖，所以monty_door由另外两个结点（父结点）决定的，当参赛者猜对时，Monty会打开另两门之一，没猜对时Monty只能打开另一扇有羊的门。<br />
 从运行结果可以看到：先验是随机抽取的0.333，随着限制条件依次加入，不确定性逐渐变小，最终，参赛者如果选择换门（C）的赢率变为不换门（A）的两倍。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>数学</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习_规则与关联规则模型Apriori、FP-Growth</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E8%A7%84%E5%88%99%E4%B8%8E%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%A8%A1%E5%9E%8BApriori%E3%80%81FP-Growth/</url>
    <content><![CDATA[<h1
id="机器学习_规则与关联规则模型apriorifp-growth">机器学习_规则与关联规则模型Apriori、FP-Growth</h1>
<p>#机器学习 #关系规则</p>
<h2 id="何时使用规则模型">1. 何时使用规则模型</h2>
<p> 机器学习时常遇到一个问题：当数据并不完全可分时，分类器得分不高。真实世界中的数据经常是这样：各种无意义数据和少量有意义数据混在一起，无意义数据又没什么规律，无法统一去除。比如说，对股票外汇市场受各种因素影响，预测次日涨跌一般各算法效果都不好。虽然找不到通用的规则，却能在数据中探索到一些模式，比如十字星，孕线，三只乌鸦等组合还是具有一定的预测性。<br />
 之前使用决策树时，就遇到过这种情况，虽然整体得分不高，但某些叶节点上纯度高（全是正例或全是反例）并且实例多，可以把该分枝拿出来当规则使用。虽然不能用它预测任意数据，但可以作为一个过滤器使用。</p>
<h2 id="规则模型是什么">2. 规则模型是什么</h2>
<p> 规则模型和决策树同属逻辑模型，不同的是决策树对正例反例同样重视，而规则只重视正例/反例其中一项。因此决策树呈现的是互斥关系，而规则模型允许重叠，结果也相对零散的规则列表。规则更像是在大量数据中挑选有意义的数据。<br />
 如果说树是精确模型，规则模型则是启发式策略（虽然经过修改也能覆盖所有实例，但一般不这么用）。它可以找到数据集中的一个子集，相对于全部数据，该子集有明显的意义。<br />
规则模型多用于处理离散数据，如文本中查找频繁单词，提取摘要，分析购物信息等等。</p>
<h2 id="具体实现">3. 具体实现</h2>
<p> 在实现上，我们可以把规则当成树的变种，稍加修改，便是规则模型。具体有两种做法：一种是找规则，使其覆盖同质（全真或全假）的样本集（和树类似）；另一种是选定类别，找覆盖该类别实例样本的规则集。</p>
<h2 id="关联规则">4. 关联规则</h2>
<p> 规则是一个用途很多的算法，关于规则模型的文章不多，有的书把它归入逻辑推理中，而非机器学习。我们最常见的是关联规则，比如用Apriori实现的频繁项集挖掘算法。<br />
 最经典的是购物篮分析中啤酒、尿布的故事，即通过对购物清单的分析，发现看似毫无关系的啤酒和尿布经常在用户的购物篮中一起出现，通过挖掘出啤酒、尿布这个频繁项集，则当一个用户买了啤酒的时候可以为他推荐尿布，从而达到组合营销的目的。<br />
 下面将介绍两种基于关联规则的无监督学习算算法Apriori和FP-growth</p>
<h2 id="apriori">5. Apriori</h2>
<h4 id="介绍">(1) 介绍</h4>
<p> Apriori这个单词在拉丁语中的意思是“来自以前”，也可拆开为a
priori，即一次先验。算法的目标是找到出现频率高的简单规则。</p>
<h4 id="原理">(2) 原理</h4>
<p> 如果某个项是频繁的，那么它的所有子集也是频繁的。反之，如果一个项集是非频繁的，那么它的超集也是非频的。比如啤酒和尿布常常同时出现，则啤酒单独出现的机率也很高；如果这个地区的人极少喝啤酒，啤酒和尿布的组合也不会常常出现。</p>
<h4 id="算法">(3) 算法</h4>
<p> 生成单个物品列表，去掉频率低于支持度的，再组合两个物品，去掉低于支持度的，以此类推，求出频繁项集，在频繁项集中抽取关联规则。<br />
 算法的输入是大量可能相关的数据组合，支持度，置信度。输出是频率项集或关联规则。</p>
<h4 id="优缺点">(4) 优缺点</h4>
<p> Apriori的优点是易于理解，缺点是算得慢，如果共有N件物品，计算量是2^N-1。在属性过多，或属性的状态过多时都会导致大量计算。</p>
<h4 id="相关概念">(5) 相关概念</h4>
<p> 支持度：数据集中包含该项集的记录所占的比例<br />
 置信度：同时支持度/部分支持度（纯度）<br />
 频繁项集：经常同时出现的物品的集合<br />
 关联规则：两种物品间可能存在很强的关系，比如A,B同时出现，如果A-&gt;B，则A称为前件，B称为后件。如果A发生概率50%，而AB概率25%，则A不一定引发B，但如果AB发生概率为49%，则说明A-&gt;B。</p>
<h4 id="例程">(6) 例程</h4>
<ol type="i">
<li><p>功能<br />
从多次购物数据中取频率项集，并显示各组合的支持度</p></li>
<li><p>代码<br />
</p></li>
</ol>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -*- coding: utf-8 -*-  </span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> <span class="op">*</span>  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> loadDataSet():  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [[<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">4</span>], [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>], [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>], [<span class="dv">2</span>, <span class="dv">5</span>]]  </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 建立所有单项的集合，如购物中的物品集合  </span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> createC1(dataSet):  </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    C1 <span class="op">=</span> []  </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> transaction <span class="kw">in</span> dataSet:  </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> item <span class="kw">in</span> transaction:  </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> [item] <span class="kw">in</span> C1:  </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>                C1.append([item])                  </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    C1.sort()  </span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="bu">frozenset</span>, C1))  </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># D是数据，Ck是各个组的集合，返回满足支持率的组  </span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> scanD(D, Ck, minSupport):  </span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    ssCnt <span class="op">=</span> &#123;&#125; <span class="co"># 字典  </span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> tid <span class="kw">in</span> D: <span class="co"># 每条记录  </span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> can <span class="kw">in</span> Ck: <span class="co"># 每个组  </span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> can.issubset(tid):  </span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="kw">not</span> can <span class="kw">in</span> ssCnt: <span class="co"># 把组放入字典  </span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>                    ssCnt[can]<span class="op">=</span><span class="dv">1</span>  </span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:   </span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>                    ssCnt[can] <span class="op">+=</span> <span class="dv">1</span>  </span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    numItems <span class="op">=</span> <span class="bu">float</span>(<span class="bu">len</span>(D))  </span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    retList <span class="op">=</span> []  </span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    supportData <span class="op">=</span> &#123;&#125;  </span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> key <span class="kw">in</span> ssCnt:  </span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        support <span class="op">=</span> ssCnt[key]<span class="op">/</span>numItems  </span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> support <span class="op">&gt;=</span> minSupport:  </span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>            retList.insert(<span class="dv">0</span>,key) <span class="co"># 把字典中的该项加入list  </span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>        supportData[key] <span class="op">=</span> support  </span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> retList, supportData  </span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="co"># 建立各个层次的组, 只建立不判断, k是组里元素的个数  </span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> aprioriGen(Lk, k):   </span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    retList <span class="op">=</span> []  </span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    lenLk <span class="op">=</span> <span class="bu">len</span>(Lk)  </span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(lenLk):  </span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i<span class="op">+</span><span class="dv">1</span>, lenLk):   </span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>            L1 <span class="op">=</span> <span class="bu">list</span>(Lk[i])[:k<span class="op">-</span><span class="dv">2</span>]<span class="op">;</span> L2 <span class="op">=</span> <span class="bu">list</span>(Lk[j])[:k<span class="op">-</span><span class="dv">2</span>]  </span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>            L1.sort()<span class="op">;</span> L2.sort()  </span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> L1<span class="op">==</span>L2: <span class="co">#if first k-2 elements are equal  </span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>                retList.append(Lk[i] <span class="op">|</span> Lk[j]) <span class="co">#set union  </span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> retList  </span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> apriori(dataSet, minSupport <span class="op">=</span> <span class="fl">0.5</span>):  </span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>    C1 <span class="op">=</span> createC1(dataSet)  </span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="bu">set</span>, dataSet))  </span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>    L1, supportData <span class="op">=</span> scanD(D, C1, minSupport)  </span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>    L <span class="op">=</span> [L1]  </span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>    k <span class="op">=</span> <span class="dv">2</span>  </span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> (<span class="bu">len</span>(L[k<span class="op">-</span><span class="dv">2</span>]) <span class="op">&gt;</span> <span class="dv">0</span>):  </span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>        Ck <span class="op">=</span> aprioriGen(L[k<span class="op">-</span><span class="dv">2</span>], k) <span class="co"># 建立组  </span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>        Lk, supK <span class="op">=</span> scanD(D, Ck, minSupport) <span class="co"># 判断新组是否适合支持率  </span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>        supportData.update(supK)  </span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>        L.append(Lk) <span class="co"># 将本次结果加入整体  </span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>        k <span class="op">+=</span> <span class="dv">1</span>  </span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> L, supportData  </span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&#39;__main__&#39;</span>:  </span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>    dataSet <span class="op">=</span> loadDataSet() <span class="co"># 数据是二维数组，每项可看作如一次购物  </span></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>    L,suppData <span class="op">=</span> apriori(dataSet, minSupport <span class="op">=</span> <span class="fl">0.7</span>)  </span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(L)  </span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(suppData)  </span></code></pre></div>
<ol start="3" type="i">
<li>结果<br />
</li>
</ol>
<pre><code>[[frozenset([3]), frozenset([2]), frozenset([5])], [frozenset([2, 5])], []]  
&#123;frozenset([5]): 0.75, frozenset([3]): 0.75, frozenset([3, 5]): 0.5, frozenset([4]): 0.25, frozenset([2, 3]): 0.5, frozenset([2, 5]): 0.75, frozenset([1]): 0.5, frozenset([2]): 0.75&#125;  </code></pre>
<h2 id="fp-growth">6. FP-growth</h2>
<h4 id="介绍-1">(1) 介绍</h4>
<p> FP是Frequent
Pattern的缩写，代表频繁模式。FP-growth比Apriori快，性能提高在两个数量级以上，在大数据集上表现更佳。<br />
 和Apriori多次扫描原始数据相比，FP-Growth算法则只需扫描原始数据两遍，把数据存储在FP-Tree结构中。</p>
<h4 id="fp-tree">(2) FP-Tree</h4>
<p> 与搜索树不同的是，一个元素项可以在FP树中出现多次，FP树会存储项集的出现频率。每个项集会以路径的方式存储在树中，存在相似元素的集合会共享树的一部分，只当集合之间完全不同时，树才会分叉。<br />
 除了树，还有个索引表（Header table），把所有含相同元素的组织起来(link
list)，以便查找。</p>
<h4 id="算法-1">(3) 算法</h4>
<p>先构建FP树，然后从FP树中挖掘频繁项集</p>
<ol type="i">
<li>收集数据<br />
数据是五次购物的清单（记录），a,b,c,d…分别代表物品（item）</li>
</ol>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-4a5da898aae5957e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<ol start="2" type="i">
<li>去除非频繁项l, i, o等，并排序</li>
</ol>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-232efc00fd5c89a3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<ol start="3" type="i">
<li>将记录依次加入树，并建立索引表（左侧框），粉色为添加第一次购物数据。</li>
</ol>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-2ba74cfe09df3b39.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<ol start="4" type="i">
<li>从下往上构造每个item的条件模式基CPB（conditional pattern
base）<br />
 顺着header
table中item的链表，找出所有包含该item的前缀路径，这些前缀路径就是该item的条件模式基（CPB）<br />
 所有这些CPB的频繁度（计数）为该路径上item的频繁度（计数）</li>
</ol>
<p> 如包含p的其中一条路径是fcamp，该路径中p的频繁度为2，则该CPB
fcam的频繁度为2</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-6b5735746632bbc3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<ol start="22" type="a">
<li>构造条件FP-tree（conditional FP-tree）<br />
 累加每个CPB上的item的频繁度（计数），过滤低于阈值的item，构建FP-tree</li>
</ol>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-8e67106db7c81a79.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 如m的CPB{<fca:2>, <fcab:1>}，f:3, c:3, a:3, b:1,
阈值假设为3，则过滤掉b。<br />
 递归的挖掘每个条件FP-tree，累加后缀频繁项集，直到找到FP-tree为空或者FP-tree只有一条路径。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>关系规则</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习_集成算法</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h1 id="机器学习_集成算法">机器学习_集成算法</h1>
<p>#机器学习</p>
<h2 id="为什么使用集成算法">为什么使用集成算法</h2>
<p> 简单算法一般复杂度低，速度快，易展示结果，但预测效果往往不是特别好。每种算法好像一种专家，集成就是把简单的算法（后文称基算法/基模型）组织起来，即多个专家共同决定结果。</p>
<h2 id="如何组织算法和数据">如何组织算法和数据</h2>
<p> 这里我们的着眼点不是某个算法，某个函数，而是对数据和算法整体的规划。<br />
 从数据拆分的角度看：可以按行拆分数据，也可以按列给属性分组。<br />
 从算法组合的成份看：可以集成不同算法，也可以集成同一算法不同参数，还可以集成同一算法使用不同数据集（结合数据拆分）。<br />
 从组合的方式看：可以选择少数服从多数，或加权求合（可根据正确率分配权重）。<br />
 从组合的结构看：可以是并行，串行，树型或者更复杂。<br />
 综上，我们看到了各种构造集成的方法，这里面可选的组合太多，不可能一一尝试，目前拼的还是人的经验：对数据的理解，对算法的组织，以及对工具的驾驶能力。在使用集成算法的过程中，除了调库，调参，更重要的是领会精神。也可以自己编写一些集成算法。</p>
<h2 id="三个臭皮匠顶个诸葛亮">三个臭皮匠顶个诸葛亮</h2>
<p> 三个臭皮匠是否能顶诸葛亮，这还得具体问题，具体分析。如果基算法选错了，即使再怎么组合，再怎么调参也没用。但有些问题确实可以拆开看，达到1+1&gt;2的效果，比如说，用线性函数去拟合曲线，效果不好，但是如果用分段线性函数，效果还不错。分段线性函数就可看作线性函数的集成（把数据横着拆开了），只不过这种集成要比直接调集成函数复杂一些。</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-975764bf4c980af6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="分段线性拟合" />
<figcaption aria-hidden="true">分段线性拟合</figcaption>
</figure>
<p> 一般来说集成的会比不集成效果好，但集成的过程也会增加复杂度。</p>
<h2 id="常用的集成算法">常用的集成算法</h2>
<p> 集成算法一般分为三类：Bagging，Boosting，Stacking（我们可以把它简单地看成并行，串行和树型）。Bagging是把各个基模型的结果组织起来，取一个折中的结果；Boosting是根据旧模型中的错误来训练新模型，层层改进；Stacking是把基模型组织起来，注意不是组织结果，而是组织基模型本身，该方法看起来更灵活，也更复杂。</p>
<p>１. Bagging（自举汇聚法）<br />
 Bagging的全称是bootstrap
averaging，它把各个基模型的结果组织起来，具体实现也有很多种类型，以sklearn中提供的Bagging集成算法为例：<br />
 BaggingClassifier/BaggingRegressor是从原始数据集抽选Ｓ次（抽取实例，抽取属性），得到S个新数据集（有的值可能重复，有的值可能不出现）。使用同一模型，训练得到S个分类器，预测时使用投票结果最多的分类。<br />
 RandomForestClassifier随机森林，它是对决策树的集成，用随机的方式建立一个决策树的森林。当有一个新的输入样本进入的时候，就让森林中的每一棵决策树分别进行判断，预测时使用投票结果最多的分类，也是少数服从多数的算法。<br />
 VotingClassifier，可选择多个不同的基模型，分别进行预测，以投票方式决定最终结果。<br />
 Bagging中各个基算法之间没有依赖，可以并行计算，它的结果参考了各种情况，实现的是在欠拟合和过拟合之间取折中。</p>
<p>２. Boosting（提升法）<br />
 Boosting不断的建立新模型，而新模型更重视上一个模型中被错误分类的样本，最终根据按成功度加权组合得到结果。<br />
 由于引入了逐步改进的思想，重要属性会被加权，这也符合人的直觉。一般来说，它的效果会比Bagging好一些。由于新模型是在旧模型的基本上建立的，因此不能使用并行方法训练，并且由于对错误样本的关注，也可能造成过拟合。常见的Boosting算法有：<br />
 AdaBoost自适应提升算法，它对分类错误属性的给予更大权重，再做下次迭代，直到收敛。AdaBoost是一个相对简单的Boosting算法，可以自己写代码实现，常见的做法是基模型用单层分类器实现（树桩），桩对应当前最适合划分的属性值位置。<br />
 Gradient Boosting
Machine（简称GBM）梯度提升算法，它通过求损失函数在梯度方向下降的方法，层层改进，sklearn中也实现了该算法：GradientBoostingClassifier/GradientBoostingRegressor。GBM是目前非常流行的一类算法，在后面详细说明。</p>
<p>３. Stacking<br />
 Stacking训练一个模型用于组合(combine)其他各个基模型。具体方法是把数据分成两部分，用其中一部分训练几个基模型A1,A2,A3，用另一部分数据测试这几个基模型，把A1,A2,A3的输出作为输入，训练组合模型B。注意，它不是把模型的结果组织起来，而把模型组织起来。理论上，Stacking可以组织任何模型，实际中常使用单层logistic回归作为模型。Sklearn中也实现了stacking模型：StackingClassifier</p>
<h2 id="梯度提升算法gb">梯度提升算法（GB**）</h2>
<p> Gradient Boosting
Machine（GBM）梯度提升算法是目前比较流行的数据挖掘模型，它是泛化能力较强的算法，常用于各种数据挖掘比赛之中。常用的工具有XGBoost，LightGBM，sklearn提供的GradientBoostingClassifier等等。GBM常把决策树作为基模型，我们常看到的GBDT梯度提升决策树，一般也是指该算法。<br />
 通常我们使用GBM都是直接调库，所以我们关注的是：什么时候用它，选用哪个GBM库，给它什么样的数据，以及具体调参。<br />
GBM的原理是希望通过集成基模型使得模型总体的损失函数在梯度方向上下降（梯度下降具体见《深度学习——BP神经网络》篇），模型不断改进。<br />
在调参方面，作为梯度下降算法，我们也需要在参数中指定学习率（每次迭代改进多少），误差函数（在回归问题中判断预测值与实际值的差异）；是与决策树结合时，还需要指定树的大小；另外还要设置迭代的次数，每次抽取样本的比例等等。<br />
 在选库方面，sklearn中提供的GradientBoostingClassifier是GBM最基本的实现，同时还提供了图形化工具，让开发者对GBM中的各属性有直观理解。不过Sklearn是一个算法集，不是专门做GBM的。</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-1d8806d5dae2871c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="Feature" />
<figcaption aria-hidden="true">Feature</figcaption>
</figure>
<p> XGBoost（eXtreme Gradient
Boosting）是一个单独的工具包，对GBDT做了一些改进：比如加入线性分类器的支持，正则化，对代价函数进行了二阶泰勒展开，缺失值处理，提高了效率，支持分布式计算等等。<br />
 LightGBM（Light Gradient Boosting
Machine）同样是一款基于决策树算法的分布式梯度提升框架。相对于XGBoost，速度又有提高，并且占用内存更少。<br />
几个工具的比较详见《关于树的几个ensemble模型的比较（GBDT、xgBoost、lightGBM、RF）》</p>
<h2 id="实例">实例：</h2>
<ol type="1">
<li><p>说明：<br />
实例摘自sklearn官网上GBM的例程，实现的是波士顿房价预测，它使用4层决策树，经过500次迭代之后预测房价，从图中可看到，预测结果的均方误差在迭代的过程中是如何下降的，以及从模型中提取的变量与结果的相关性。</p></li>
<li><p>核心代码<br />
</p></li>
</ol>
<pre><code>params = &#123;&#39;n_estimators&#39;: 500, &#39;max_depth&#39;: 4, &#39;min_samples_split&#39;: 2,  
          &#39;learning_rate&#39;: 0.01, &#39;loss&#39;: &#39;ls&#39;&#125;  
clf = ensemble.GradientBoostingRegressor(**params)  
clf.fit(X_train, y_train)  
mse = mean_squared_error(y_test, clf.predict(X_test))  
print(&quot;MSE: %.4f&quot; % mse)  </code></pre>
<ol start="3" type="1">
<li>完整代码下载<br />
http://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regression.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py<br />
</li>
<li>运行结果<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-b41e26b68a0f2fbd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="房价预测" /></li>
</ol>
<h2 id="参考">参考</h2>
<ol type="1">
<li>GBDT源码分析之一 ：总览<br />
http://www.jianshu.com/p/02cfaae3fd01<br />
</li>
<li>机器学习算法中GBDT和XGBOOST的区别有哪些？<br />
https://www.zhihu.com/question/41354392<br />
</li>
<li>GBDT：梯度提升决策树<br />
http://www.jianshu.com/p/005a4e6ac775<br />
</li>
<li>Ensemble methods<br />
http://scikit-learn.org/stable/modules/ensemble.html<br />
</li>
<li>机器学习系列(12)_XGBoost参数调优完全指南<br />
http://blog.csdn.net/han_xiaoyang/article/details/52665396<br />
</li>
<li>关于树的几个ensemble模型的比较（GBDT、xgBoost、lightGBM、RF）<br />
http://m.blog.csdn.net/xwd18280820053/article/details/68927422</li>
</ol>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习之_逻辑回归</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</url>
    <content><![CDATA[<h1 id="机器学习之_逻辑回归">机器学习之_逻辑回归</h1>
<p>#机器学习</p>
<p>逻辑回归又称logistic回归，逻辑斯谛回归，是一种广义的线性回归分析模型。</p>
<h3 id="sigmod函数">1. Sigmod函数</h3>
<p> Sigmoid函数也是神经网络中常用的函数，用于把x从负无穷到正无穷压缩到y从0到1之间。画出来就是一条S型曲线，如下图中的蓝色曲线：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ce0c9652e3c9fc24.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 它以0点为中心对称，公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-b4aacfd397f8c6d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 当x值接近负无穷时，分母很大，S(x)接近0，当x接近正无穷时，分母接近1，S(x)接近1，当x为0时，S(x)为1/2在正中间。S曲线的弯曲程度由e决定。
它的导数是上图中的橙色曲线：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ed7df98eb04ecb88.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 导数的意义是变化率，当x很大时或很小时，S’(x)接近0，而在x接近0时，S’(x)值最大，即S曲线在0点处变化剧烈，它勾勒出了y在0与1之间模棱两可的区域。</p>
<h3 id="逻辑斯谛分布">2. 逻辑斯谛分布</h3>
<p> 必须满足逻辑斯谛分布，才能用逻辑回归。那么什么是逻辑斯谛分布？<br />
逻辑斯谛分布即增长分布，增长分布的分布函数是“增长函数”，公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-8759b0443fd27c62.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 可以看到，它把(x-μ)/γ代入Sigmoid函数。其中μ是位置参数，也可解释为数学期望（大多数情况下是均值），散布中心，而γ是形状参数，它描述了散布程度（集中还是分散）。逻辑斯谛分布记为L(μ,γ)，当时μ=0，γ=1，称为标准的逻辑斯谛分布，就是Sigmoid函数。</p>
<p> 我们形象地看一下μ和γ的功能：假设μ=3, γ=2，绘出的曲线如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-1678f7bd5e3f35d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 相比，它的中心点在μ=3（横坐标3，纵坐标1/2），且曲线也比较平缓γ=2，γ值越小，中心附近变化越剧烈。
增长函数是sigmoid的扩展，它将以0为中心以1为单位的S曲线，扩展为以μ为中心，以γ为单位的S曲线。
换言之，只要分布符合S曲线，就能用逻辑回归。</p>
<h3 id="分布函数和密度函数">3. 分布函数和密度函数</h3>
<p> 从概率的角度上讲，蓝色曲线它是分布函数，分布函数也叫累计分布函数（积分），它的函数值是概率P(X&lt;=x)，x越靠右，概率X发生的概率越大。</p>
<p> 常用的说明例子是：植物群体中发病的普遍率，横轴为时间，纵轴为发病率，一开始发病的植物少，增长缓慢，在中段出现爆发式增长，最终增长变慢，饱合达到100%。可以说分布函数中的Y是一个随时间积累得到的量（单调上升），即到时刻x为止，发病植物占所有植物的比例。而它的导数橙色线，即x时刻新发病的植物占整体的比例，即密度函数。</p>
<h3 id="逻辑回归">4. 逻辑回归</h3>
<p> 逻辑回归又称logistic回归，逻辑斯谛回归，是一种广义的线性回归分析模型。线性模型是通过一组值X0…Xn预测Y的具体值（从特征预测结果），而逻辑回归是将用X0…Xn预测Y属于哪个分类（A/B分类），基本的逻辑是先预测具体值，然后再用Sigmoid函数将具体值映射到0-1之间。如果这个概率大于0.5，则认为是A类。而决定0.5的因素是各个特征的权重。</p>
<h4 id="疑问一直线和s曲线有什么关系">(1)
疑问一：直线和S曲线有什么关系？</h4>
<p> y1=w *
x+b想像它的图像是x为横轴，y1为纵轴的一条直线，纵轴范围很大。而Sigmoid是0-1间的曲线，先把w
* x+b计算出y1，再将y1代入sigmoid函数，计算y2： y1=w * x+b (公式1)</p>
<p> y2=sigmoid(y1) (公式2)
这是个函数嵌套，所以结果并不直观；它相当于把x轴映射到y轴（蓝色），再把y轴按S曲线从正无穷到负无穷压缩到了0-1之间（橙色）。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-f28c17f7e015d6b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="疑问二sigmoid函数和概率有什么关系">(2)
疑问二：Sigmoid函数和概率有什么关系？</h4>
<p> 把直线方程代入Sigmoid函数（公式1代入公式2），公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-922883444534fd43.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 如果看成二分类问题，当sigmoid函数值大于0.5时认为是A类，否则认为是B类。通过直线方程，我们用特征x预测目标值y1，而通过sigmoid的变换，计算出该值属于哪个分类的概率y2。容易看出：上式的两个概率之和为1（两种可能性加起来是100%）。逻辑斯谛回归比较两个条件概率值的大小，将实例x分到概率值较大的一类中。</p>
<p> 把x和w推广到高维多特征的情况下，w=(w1,w2,w3…b),
x=(x1,x2,x3,…1)则公式变换如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-7a418e7d3d8097f6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 可以说，逻辑回归基本上就是线性回归的扩展。</p>
<h3 id="模型参数的估计">5 模型参数的估计</h3>
<p> 具体应用时，我们知道实例有多个特征x(x1,x2,x3…)，求各个特征对应的权重w(w1,w2,w3…b)，使得各个实例都能正确分类，求取w一般使用梯度上升法或牛顿法，这里讲讲梯度上升法。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-1fd8cf9ea9b4b962.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="应用">6. 应用</h3>
<p> 需要注意的是w *
x是线性函数，每个x与y之间，需要服从单调上升或者调下降的关系，如果不服从这种关系，就不能用逻辑回归。比如目标分类y是强壮与否，而特征x是年龄，我们知道并不是年龄越大越强壮（老年人），二者间并不存在同增同减的关系，年龄因素就没法直接使用逻辑回归，除非先对年龄做变换，例如abs(年龄-35)。</p>
<h3 id="参考">7. 参考</h3>
<ol type="1">
<li>概率论中常见分布总结以及python的scipy库使用：两点分布、二项分布、几何分布、泊松分布、均匀分布、指数分布、正态分布<br />
https://www.cnblogs.com/pinking/p/7898313.html</li>
</ol>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>自动机器学习框架之一_Auto-Sklearn</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%87%AA%E5%8A%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E4%B9%8B%E4%B8%80_Auto-Sklearn/</url>
    <content><![CDATA[<h1
id="自动机器学习框架之一_auto-sklearn">自动机器学习框架之一_Auto-Sklearn</h1>
<p>#Python #机器学习</p>
<p> 当我们做完了特征工程之后，就可以代入模型训练和预测，对于模型的选择及调参，主要根据分析者的经验。在具体使用时，经常遇到同一批数据，同一种模型，不同的分析者得出的结果相差很多。</p>
<p> 前面学习了几种常用的机器学习方法原理以及适用场景，对于完全没有经验的开发者，只要有足够时间，尝试足够多的算法和参数组合，理论上也能达到最优的训练结果，同理程序也能实现该功能，并通过算法优化该过程，自动寻找最优的模型解决方案，即自动机器学习框架。</p>
<p> 我们将在未来的三周里分别为大家介绍三个常用的机器学习框架：auto-sklearn、auto-ml
和 auto-keras。</p>
<p> Auto-Sklearn主要基于sklearn机器学习库，使用方法也与之类似，这让熟悉sklearn的开发者很容易切换到Auto-Sklearn。在模型方面，除了sklearn提供的机器学习模型，还加入了xgboost算法支持；在框架整体调优方面，使用了贝叶斯优化。</p>
<p>（转载请注明出处：https://www.jianshu.com/p/cd775730a1ec）</p>
<h3 id="安装">1. 安装</h3>
<p> Auto-sklearn需要基于python3.5以上版本，且依赖swig，因此需要先安装该库，具体方法如下：</p>
<pre><code>$ sudo apt-get install build-essential swig  
$ pip install auto-sklearn  </code></pre>
<p> 由于关于auto-sklearn的文档和例程不多，推荐下载auto-sklearn的源码，并阅读其中的example和doc，以便更多地了解auto-sklearn的功能和用法。</p>
<pre><code>$ git clone https://github.com/automl/auto-sklearn.git  </code></pre>
<h3 id="auto-sklearn-的优缺点">2. Auto-Sklearn 的优缺点</h3>
<p> 通常情况下，我们只能依据个人的经验，基于机器性能、特征多少、数据量大小、算法以及迭代次数来估计模型训练时间，而Auto-Sklearn支持设置单次训练时间和总体训练时间，使得工具既能限制训练时间，又能充分利用时间和算力。</p>
<p> Auto-Sklearn支持切分训练/测试集的方式，也支持使用交叉验证。从而减少了训练模型的代码量和程序的复杂程度。另外，Auto-Sklearn支持加入扩展模型以及扩展预测处理方法，具体用法可参见其源码example中的示例。</p>
<p> 其缺点是Auto-Sklearn输出携带的信息较少，如果想进一步训练只能重写代码。</p>
<h3 id="举例">3. 举例</h3>
<p> 本例使用96年美国大选数据，将”投票vote”作为因变量，它有只0/1两种取值，因此使用分类方法AutoSklearnClassifier，例程中将训练时间指定为两分钟，模型指定为只选择随机森机random_forest，训练后输出其在训练集上的打分score。</p>
<pre><code>import autosklearn.classification  
import statsmodels.api as sm  
  
data = sm.datasets.anes96.load_pandas().data  
label = &#39;vote&#39;  
features = [i for i in data.columns if i != label]  
X_train = data[features]  
y_train = data[label]  
automl = autosklearn.classification.AutoSklearnClassifier(  
time_left_for_this_task=120, per_run_time_limit=120, # 两分钟  
    include_estimators=[&quot;random_forest&quot;])  
automl.fit(X_train, y_train)  
print(automl.score(X_train, y_train))  
# 返回结果: 0.94173728813559321  
# 谢彦技术博客  </code></pre>
<h3 id="关键参数">4.关键参数</h3>
<p> Auto-sklearn支持的参数较多，以分类器为例，参数及其默认值如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-c8ebd9545a77390a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 下面介绍其常用参数，分为四个部分：</p>
<p><strong>(1) 控制训练时间和内存使用量</strong></p>
<p> 参数默认训练总时长为一小时（3600），一般使用以下参数按需重置，单位是秒。<br />
* time_left_for_this_task：设置所有模型训练时间总和<br />
* per_run_time_limit：设置单个模型训练最长时间<br />
* ml_memory_limit：设置最大内存用量</p>
<p><strong>(2) 模型存储</strong></p>
<p> 参数默认为训练完成后删除训练的暂存目录和输出目录，使用以下参数，可指定其暂存目录及是否删除。<br />
* tmp_folder：暂存目录<br />
* output_folder：输出目录<br />
* delete_tmp_folder_after_terminate：训练完成后是否删除暂存目录<br />
* delete_output_folder_after_terminate：训练完成后是否删除输出目录<br />
* shared_mode：是否共享模型</p>
<p><strong>(3) 数据切分</strong></p>
<p> 使用resampling_strategy参数可设置训练集与测试集的切分方法，以防止过拟合，用以下方法设置五折交叉验证：<br />
* resampling_strategy='cv'<br />
* resampling_strategy_arguments={'folds': 5}</p>
<p> 用以下方法设置将数据切分为训练集和测集，其中训练集数据占2/3。<br />
* resampling_strategy='holdout',<br />
* resampling_strategy_arguments={'train_size': 0.67}</p>
<p><strong>(4) 模型选择</strong></p>
<p> 参数支持指定备选的机器学习模型，或者从所有模型中去掉一些机器学习模型，这两个参数只需要设置其中之一。<br />
* include_estimators：指定可选模型<br />
* exclude_estimators：从所有模型中去掉指定模型</p>
<p> auto-sklearn除了支持sklearn中的模型以外，还支持xgboost模型。具体模型及其在auto-sklearn中对应的名称可通过查看源码中具体实现方法获取，通过以下目录内容查看支持的分类模型：autosklearn/pipeline/components/classification/，可看到其中包含：adaboost、extra_trees、random_forest、libsvm_svc、xgradient_boosting等方法。</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>自动机器学习框架之三_Auto-Keras</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%87%AA%E5%8A%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E4%B9%8B%E4%B8%89_Auto-Keras/</url>
    <content><![CDATA[<h1
id="自动机器学习框架之三_auto-keras">自动机器学习框架之三_Auto-Keras</h1>
<p>#机器学习</p>
<p> 对于训练深度学习，设计神经网络结构是其中技术含高最高的任务，优秀的网络架构往往依赖建构模型的经验，专业领域知识，以及大量的算力试错。实际应用中往往基于类似功能的神经网络微调生成新的网络结构。</p>
<p> Auto-Keras是一个离线使用的开源库，用于构建神经网络结构和搜索超参数，支持RNN，CNN神经网络，它使用了高效神经网络搜索ENAS，利用迁移学习的原理将在前面任务中学到的权值应用于后期的模型中，效率相对较高。除了支持keras，它还提供TensorFlow他PyTorch的版本。</p>
<h3 id="安装">1. 安装</h3>
<p> 由于需要把输出的神经网络结构保存成图片，使用了pydot和graphviz图像工具支持，auto-keras支持torch等多种工具支持，因此，安装时会下载大量依赖软件。使用以下方法安装auto-keras：</p>
<pre><code>$ apt install graphviz   
$ pip3 install pydot  
$ pip3 install autokeras  </code></pre>
<p> 使用以下方法下载源码：</p>
<pre><code>$ git clone https://github.com/jhfjhfj1/autokeras  </code></pre>
<h3 id="举例">2. 举例</h3>
<p> 本例中使用了mnist数据集，它是一个入门级的图像识别数据集，用于训练手写数字识别模型，例程自动下载训练数据，然后创建了图片分类器，训练时间设置为10分钟，模型在测试集上的正确率为99.21%。建议使用带GPU的机器训练模型，它比使用CPU训练速度快几十倍。</p>
<pre><code>from keras.datasets import mnist  
from autokeras import ImageClassifier  
from autokeras.constant import Constant  
import autokeras  
from keras.utils import plot_model  
      
if __name__ == &#39;__main__&#39;:  
    (x_train, y_train), (x_test, y_test) = mnist.load_data()  
    x_train = x_train.reshape(x_train.shape + (1,))  
    x_test = x_test.reshape(x_test.shape + (1,))  
    clf = ImageClassifier(verbose=True, augment=False)  
    clf.fit(x_train, y_train, time_limit=10 * 60)  
    clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)  
    y = clf.evaluate(x_test, y_test)  
    print(y * 100)  
    clf.export_keras_model(&#39;model.h5&#39;)  
    plot_model(None)  
# 返回值: 99.21  
# 谢彦的技术博客  </code></pre>
<p> 上述程序在我的机器上运行后训练出了17层网络，其中包括dropout层，池化层，卷积层，全连接层等，程序以图片方式将描述信息保存在model.png中，下面截取了图片中的部分层作为示例，如下图所示：<br />
<img
src="https://upload-images.jianshu.io/upload_images/5357893-cbdadce5a968b2f4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>自动机器学习框架之二_AutoML</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%87%AA%E5%8A%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E4%B9%8B%E4%BA%8C_AutoML/</url>
    <content><![CDATA[<h1 id="自动机器学习框架之二_automl">自动机器学习框架之二_AutoML</h1>
<p>#机器学习 #自动建模</p>
<p> Auto ML（Auto Machine
Learning）自动机器学习是个宽泛的概念，有不只一个软件以此命名，本篇介绍的Auto-ML并非谷歌基于云平台的
AUTOML。本篇介绍的Auto-ML也是一款开源的离线工具，它的优势在于简单快速，且输出信息比较丰富。它默认支持Keras、TensorFlow、XGBoost、LightGBM
、CatBoost和
Sklearn等机器学习模型，整体使用进化网格搜索的方法完成特征处理和模型优化。</p>
<h3 id="安装">安装</h3>
<p> Auto-ML安装方法如下：</p>
<pre><code>$ pip install auto-ml  </code></pre>
<p> 为更多地了解auto-ml的功能和用法，建议下载其源码：</p>
<pre><code>$ git clone https://github.com/ClimbsRocks/auto_ml  </code></pre>
<h3 id="举例">举例</h3>
<p> 本例也使用96年美国大选数据，将”投票vote”作为因变量，它有只0/1两种取值，因此使用分类方法type_of_estimator=’classifier’，训练时需要用字典的方式指定各字段类型：其中包括：因变量output，分类型变量categorical，时间型变量date，文本nlp，以及不参与训练的变量ignore。</p>
<pre><code>from auto_ml import Predictor  
import statsmodels.api as sm  
  
data = sm.datasets.anes96.load_pandas().data  
column_descriptions = &#123;  
     &#39;vote&#39;: &#39;output&#39;,  
     &#39;TVnews&#39;: &#39;categorical&#39;,  
     &#39;educ&#39;: &#39;categorical&#39;,  
     &#39;income&#39;: &#39;categorical&#39;,  
&#125;  
  
ml_predictor = Predictor(type_of_estimator=&#39;classifier&#39;,   
                         column_descriptions=column_descriptions)  
model = ml_predictor.train(data)  
model.score(data, data.vote)  
# 谢彦技术博客  </code></pre>
<p> 程序的输出较多，不在此列出，相对Auto-Sklearn，Auto-ML的输出内容丰富得多，包含最佳模型，特征重要性，对预测结果的各种评分，建议读者自行运行上述例程。由于它同时支持深度学习模型和机器学习模型，可使用深度学习模型提取特征，用机器学习模型完成具体的预测，从而得到更好的训练结果。</p>
<p>(转载请注明出处：https://www.jianshu.com/p/6e4e40d29339)</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>自动建模</tag>
      </tags>
  </entry>
  <entry>
    <title>自动机器学习框架之四_PyCaret</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%87%AA%E5%8A%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E4%B9%8B%E5%9B%9B_PyCaret/</url>
    <content><![CDATA[<h1 id="自动机器学习框架之四_pycaret">自动机器学习框架之四_PyCaret</h1>
<p>#机器学习 #自动建模</p>
<p>机器学习涉及数据分析、清洗、建模、评价、对比模型……无论是初学者，还是有经验的开发者在面对新的项目时，都想要简化这些工作，最好能用简单的代码、较短时间，就能得出初步验证结果，之后再进一步优化。</p>
<p>希望能用一个简单的数据文件，几行通用的Python语句，就能实现分析、建模和部署。PyCaret就是这样的工具：虽然没有太多创新算法，但极大地简化了工作流程。这也让机器学习的门槛越来越低。</p>
<p>PyCaret是Python开发的机器学习库，它封装了Sklearn，XGBoost，LightGBM，Spacy，Shap，PyOD，Gensim，WordCloud等工具，几乎包括机器学习所有的使用场景和方法（不含深度学习）：异常检测Anomaly
Detection，关联规则Association
Rules，分类Classification，回归Regression，聚类Clustering，自然语言处理NLP等。其中支持最丰富的还是分类和回归。</p>
<p>PyCaret屏蔽了具体使用细节，比如各种库在建模，绘图，特征排序的不同调用方法。向外提供端到端（end-to-end）的统一开发工具，减少了学习成本，让不熟悉编程的其它领域人士，也能快速建模，而无需关注各种API的使用细节；同时也帮助专业人士更加高效地工作。</p>
<h3 id="安装">安装</h3>
<p>对于第一次使用者，建议下载github源码，约166M，含代码、示例和数据。 <a
href="https://github.com/pycaret/pycaret">https://github.com/pycaret/pycaret</a></p>
<p>源码的tutorials目录下有针对聚类分类等典型问题各种级别的入门示例，除了普通建模以外，还有集成模型、做图分析等功能。目前2.2K
GitHub
Star，并一直在不断更新。因为在快速开发迭代过程中，有些文档和当前代码有一些对不上。内容结构虽然还不是特别严谨，但重点是确实能解决问题。即使不使用PyCaret，也可以从例程中学习到常用机器学习库的使用方法。</p>
<p>源码中提供Dockerfile，用于创建包含PyCaret的Docker镜像，不过PyCaret相对比较简单，推荐在环境中用命令直接安装。</p>
<pre><code>$ pip install pycaret  </code></pre>
<p>安装时需要注意它依赖的各个机器学习库的软件版本匹配问题。</p>
<h3 id="用法">用法</h3>
<p>其核心代码在项目的pycaret目录中，目前包括：</p>
<p>anomaly.py 异常值检测（无监督） arules.py 关联规则（无监督）<br />
classification.py 分类（有监督）<br />
clustering.py 聚类（无监督）<br />
datasets.py 数据加载（辅助工具）<br />
nlp.py 自然语言处理（无监督）<br />
preprocess.py 预处理（辅助工具，被其它模块内部调用）<br />
regression.py　回归（有监督）</p>
<p>基本流程一般包含：读取数据-&gt;建模/对比模型-&gt;模型预测-&gt;绘图分析-&gt;模型导出。包括以下常用方法：</p>
<p>get_data()
读数据，例程中多为读取示例数据，用户可以使用自己的数据代替。<br />
setup()
预处理，各种建模方法（如分类/聚类）根据自己的特点实现了不同的setup，其中几乎都包含对预处理模块的调用。<br />
models() 列出当前建模方法支持的所有模型。<br />
compare_models() 训练多个模型，并对比其效果。<br />
create_model() 训练模型。<br />
predict_model() 使用模型预测。<br />
plot_model()
显示模型相关的各种分析图，如AUC曲线，学习曲线，还包含词云图等。<br />
tune_model() 模型调参。<br />
assign_model() 查看无监督模型打标签的情况。<br />
evaluate_model() 评价模型。<br />
deploy_model() 云端部署。<br />
ensemble_model() 集成模型。<br />
finalize_model() 导出最终模型和参数。</p>
<h3 id="示例">示例</h3>
<p>下例介绍用回归模型预测波士顿房价。</p>
<pre><code>from pycaret.datasets import get_data  
from pycaret.regression import * # 使用回归方法  
  
boston = get_data(&#39;boston&#39;)  # 读取数据  
reg1 = setup(data = boston, target = &#39;medv&#39;)  # 数据分析和预处理，指定目标变量medv  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-21db4e9053e9842d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<pre><code>models() # 列出可用的建模方法  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-7628719596725eec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<pre><code>best = compare_models(include = [&#39;dt&#39;,&#39;rf&#39;,&#39;xgboost&#39;]) # 对比决策树、随机森林、XGBoost方法  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-eddaf073efe80c74.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<pre><code>model = create_model(&#39;xgboost&#39;) # 构建XGBoost模型   
plot_model(model, plot=&#39;learning&#39;) # 绘制学习曲线  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-959834e0423ebcde.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<pre><code>interpret_model(model) # shap 特征重要性分析  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-3555a1e13cfe0356.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="参考">参考</h3>
<ul>
<li><a
href="http://pycaret.org/create-model/">http://pycaret.org/</a><br />
PyCaret网站<br />
</li>
<li><a
href="https://github.com/eriklindernoren/ML-From-Scratch">https://github.com/eriklindernoren/ML-From-Scratch</a>
提取各种机器学习，深度学习，强化学习等例程，16.7 K GitHub
Start，数据挖掘排行榜首位<br />
</li>
<li><a
href="https://github.com/topics/data-mining">https://github.com/topics/data-mining</a><br />
GitHub数据挖掘排行榜<br />
</li>
<li><a
href="https://cloud.tencent.com/developer/news/397780">https://cloud.tencent.com/developer/news/397780</a>
在Python中使用PyOD进行异常值检测</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>自动建模</tag>
      </tags>
  </entry>
  <entry>
    <title>7_1_强化学习_ChatGPT为什么使用强化学习</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/7_%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/7_1_%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0_ChatGPT%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p><img
src="/attachments_2023/Pasted%20image%2020230203192647.png" /></p>
<p>最近出现很多ChatGPT相关论文，但基本都是讨论其使用场景和伦理问题，至于其原理，ChatGPT在其<a
href="https://openai.com/blog/chatgpt/">主页上</a>介绍，它使用来自人类反馈的强化学习训练模型，方法与InstructGPT相同，只在数据收集上有细微的差别。</p>
<p>那么，InstructGPT和ChatGPT为什么使用强化学习呢？先看个示例：<br />
<img src="/attachments_2023/Pasted%20image%2020230204083604.png"
alt="聊天示例|500" /></p>
<p>先不论答案是否正确，回答依赖之前的对话，且不仅是前一句。<br />
强化学习用于解决具有马尔可夫性的问题，马尔可夫性是指每个状态仅依赖前一个状态，而这种链式的关系，又使历史信息被传递到了未来。</p>
<p>强化学习使用的场景是<a
href="None">马尔可夫决策过程</a>，包含以下核心点：<br />
* 随机过程：人机聊天你一句我一句<br />
* 马尔可夫性：回答依赖问题<br />
*
奖利：问题可能有多种答案，答案没有绝对的对错，但提问者会对某个答案更满意<br />
* 行为：每一次决定如何回答都对后续对话走向产生影响<br />
可以看到聊天的场景是一个马尔可夫决策过程。</p>
<p>进而产生了另一个问题：模型需要大量数据训练，如果用户问个问题，出三个答案，让用户选一个，收集以用于训练模型。这肯定是不够友好，软件在初期效果不佳时也不会有人去用。且有些用户的回答还可能误导模型。</p>
<p>于是，需模仿真实的使用场景，根据用户对答案的偏好，生成奖励值，以进一步训练强化学习模型。即：对<strong>场景建模</strong>，这也是强化学习的重要部分：基于模型的强化学习（model-based
reinforcement learning）。</p>
<p>结合GPT自然语言模型（第一列），奖励模型（第二列），代入强化学习算法（第三列），让模型训练和更新筛选答案的策略。简言之，自然语言模型针对人提出的问题生成N种答案，由强化学习根据当前情况，选择其中最符合用户偏好的答案。</p>
<p>用什么样的文本训练它，它就会生成什么样的文字，从互联网上抓取的数据，学到的也都是大多数声音。而通过人标注数据的引导，可以影响和改变它的行为，比如：在第一列可通过喂给模型更多更高质量的数据，让它在细分领域更具专业性；而通过人工标注数据训练第二列的奖励模型，可以约束和引导它的行为。当然，日后还会发展出更好的结构。</p>
<p>至少，到目前为止，它们只是自然语言生成工具，具有一定的语言能力，可以照猫画虎地根据上文生成下文（一种或多种答案），再用强化学习方法，根据当前情境，从答案中选出相对靠谱的显示出来。所以说，不能指忘它是全知，具有上帝视角回答那些专家都不确定的问题。</p>
]]></content>
  </entry>
  <entry>
    <title>AlphaGoZero与增强学习</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/7_%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/AlphaGoZero%E4%B8%8E%E5%A2%9E%E5%BC%BA%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="alphago-zero与增强学习">AlphaGo Zero与增强学习</h1>
<p>#深度学习 #增强学习</p>
<p> 2017年10月19日凌晨，DeepMind
在《自然》杂志上发表了一篇论文，正式推出人工智能围棋程序的最新版本——AlphaGo
Zero．</p>
<h2 id="alphago-zero成长史">AlphaGo Zero成长史</h2>
<p> 最初AlphaGo
Zero除了围棋的基本规则以外，没有任何关于围棋的知识；<br />
 3个小时之后，它通过自学入门围棋，成为人类初学者水平；<br />
 19个小时之后，它自已总结出了一些＂套路＂，比如死活，打劫，先占边角等等；<br />
 自学第三天后，它战胜了AlphaGo
Lee（当初击败李世石的AlphaGo版本）；<br />
 自学第四十天后，它战胜了AlphaGo Master（今年击败柯洁的AlphaGo版本）</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-9ba906050c553df0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 与之前的AlphaGo版本相对，它不但提高了水平，而且节约了算力．</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-d6c533dffe59463e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 这还不是最重要的，最重要的是它只使用了增强学习，因此它的意义就不仅仅是赢得棋类比较这么简单了．</p>
<h2 id="增强学习">增强学习</h2>
<p> 先来看看什么是增强学习（Reinforcement
Learning），我们知道机器学习分为有监督学习和无监督学习，增强学习介于它们两个之间，它关注的是智能体如何在环境中采取一系列行为，从而获得最大的累积回报。简单地说就是边干边学．<br />
 之前的AlphaGo版本也用到了增强学习，它先使用人类专家下棋数据作为训练（有监督学习），然后再让机器自己和自己对弈（增强学习）并从中吸取经验．而AlphaGo
Zero是完全不使用专家数据训练，只使用增强学习，并且成功了．它在几天之内进行了上百万盘自我对弈，达到了人类围棋巅峰水平，而且那些＂套路＂都是它自己总结出来的，看到学习过程图真的很震撼（具体图请见论文），感觉它把人类成百上千年的围棋技术发展史浓缩在几天之内了．</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-d687a0d4041ef858.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 如果用人类专家的方法训练机器，机器一般只能发展到和人类专家相似的水平．AlphaGo
Zero证明了机器只不会鹦鹉学舌，它能自学，而且速度还挺快．从这个角度看，它确实具有里程碑的意义．</p>
<h2 id="alphago-版本比较">AlphaGo 版本比较</h2>
<p> 下面从技术角度看看Zero与AlphaGo早期版本相比，到底有哪些进步．早期的AlphaGo使用的是卷积神经网络，Zero加入了残差网络；早期使用决策和价值两个网络，Zero将它们合二为一；早期是人工提取特征，Zero直接把棋子位置直接作为输入；早期是有监督学习与增强学习相结合，Zero只使用了增强学习．（具体请见论文）<br />
 同样它们都使用了神经网络，蒙特卡洛搜索树算法，而算力从原来的48个TPU降到了4个TPU．总之，它的进步主要是采用新技术和化繁为简．有点像哥白尼的日心说，一下把复杂的事情变简单了．</p>
<h2 id="机器自学能否超越人类">机器自学能否超越人类</h2>
<p> 有人说，人的脑细胞不是更多，为什么让机器给超越了呢？机器把所有时间和运算力都放在训练棋局上，人的大脑虽然厉害，但是分块处理各种工作，每天工作时间也有限．并且神经网络算法里还加入了很多优化算法并不完全和人脑一样．<br />
 又有人说，原来说机器学习就是鹦鹉学舌，那么经过增强学习，机器是否就可以自学，跳出人类模型，创造模型，超越人类呢？<br />
 人是高级动物，把刚生出来的小孩扔到大森林里他活不了，反而一些低级动物一生出来就能自己生活．因为低级动物的生存的目标，规则，方法都比较简单，而基因中又刻画了一些先天的技能．就像棋类游戏，有确定的规则，可判定的结果．目标，价值，损失…由于人需要处理更复杂的问题，所以需要更多积淀和更灵活的框架．这也是目前算法欠缺的地方（个人观点，仅供参考）．人类还有一些明显有优势，比如：从少量的训练中积累经验（基于人的常识系统）；知识迁移（见Minsky的框架理论）等等，这属于人工智能中的其它领域了．<br />
 棋类游戏比较容易定义和模拟场景，属于一个很抽象的领域，可以不断地试错．在真实的世界里，大多数事情都没机会多试，不可能让汽车在大街上去练自动驾驶，积累经验．这也局限了增强学习的使用范围．</p>
<h2 id="论文原文">论文原文</h2>
<p> 论文原文《Mastering the game of Go without human
knowledge》请见：<br />
https://deepmind.com/documents/119/agz_unformatted_nature.pdf<br />
建议阅读原文，读起来确实激动人心，一共40多页，没空的话读前14页即可．后面是
References，技术细节和图表数据．</p>
]]></content>
      <tags>
        <tag>增强学习</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_AlphaGo_Zero</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/7_%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_AlphaGo_Zero/</url>
    <content><![CDATA[<p>journal: Nature<br />
name_ch: 在没有人类知识的情况下掌握围棋游戏<br />
name_en: Mastering the game of Go without human knowledge<br />
paper_addr: http://www.nature.com/articles/nature24270<br />
date_publish: 2017-10-01</p>
<h2 id="读后感">读后感</h2>
<p>AlphaGo
Zero是AlphaGo的改进版本，之前版本都使用有监督学习和强化学习相结合的方式。如题——它与之前版本不同的是不需要通过学习人类棋手的下法，其Zero
意思是<strong>无师自通</strong>。其核心算法是将价值网络和策略网络二合一，并在卷积网络中加入残差。</p>
<h2 id="介绍">介绍</h2>
<p>文章分两部分，第一部分介绍其整体，第二部分展示了算法细节和一些背景知识（在参考资料之后）。<br />
AlphaGo
是深度强化学习的精典应用范例，围棋领域之所以复杂是因为：在广阔的搜索空间中，需要有精确而精细的前瞻性。</p>
<p>AlphaGo的第一个版本，简称AlphaGo
Fun，指2015年战胜樊麾的版本；它使用两个神经网络：价值网络和策略网络。其中的策略网络一开始通过专家数据有监督训练，后期利用强化学习细化；价值网络通过策略网络自我对弈得到数据，从中采样训练；通过蒙特卡洛树搜索(MCTS)，价值网络用于计算树中节点的价值，策略网络用于计算最高价值的策略。Alpha
Lee是第二个版本，在2016年战胜了李世石，它相对第一版进行了微调，且具有更大的神经网络，也需要更大算力。Alpha
Master 是进一步优化版本。</p>
<p>相对于之前版本，AlphaGo Zero有以下优势：<br />
* 使用自我对弈的强化学习，不需要专家知识<br />
* 只使用了棋盘上的黑白子作为输入特征，没有手工构造特征<br />
* 使用单网络：结合了价值网络和策略网络<br />
* 使用简单的树搜索，而不依赖蒙特卡洛展开（Monte Carlo rollouts）</p>
<h3 id="alphago-zero中的强化学习">AlphaGo Zero中的强化学习</h3>
<p>设环境状态为s，它包含当前状态和历史数据；p表示策略概率，v是当前状态s最终获胜的概率：<br />
<span class="math display">\[(p,v)=f_\theta(s)\]</span><br />
其中f是神经网络，theta是网络参数，它根据当前状态输出策略和价值。Zero还对神经网络结构进行了调整：对卷积层加入了残差块，以实现批量归一化和非线性整流。</p>
<p>在每个状态s，都执行神经网络引导下的MCTS搜索，输出是每一种走法的概率π，它先于直接使用f网络输出的策略p，也就是说MCTS改进了神经网络输出的策略。自我对弈后是否胜利又可作为更强的策略评估。训练的目标包含两个：能更准确地评估p和v，且能最终取胜。</p>
<figure>
<img
src="https://obimage-1316917304.cos.ap-beijing.myqcloud.com/picgo/Pasted%20image%2020230219095704.png"
alt="图-2" />
<figcaption aria-hidden="true">图-2</figcaption>
</figure>
<p>图-2展示了每一次模拟的过程：<br />
* 树中的每个边是其上状态s和选择动作a的组合；<br />
*
每条边都包含：动作的先验概率P(s,a)，该边的访问次数N(s,a)，动作价值Q(s,a）<br />
*
每一步都选择Q+U最大(上图中子图1)，以确认下一步走法，其中U是上置信区间：<br />
<span class="math display">\[U(s, a) ∝ P(s, a) / (1 + N(s,
a))\]</span><br />
这里的P可视为神经网络f的策略输出（上图中子图2），而引入N是为了平衡探索与利用。当N值小访问次数少时，U更大，以鼓励探索未知领域。<br />
Q计算了下一步可能动作a能到达的状态s'的平均价值（上图中子图3）：<br />
<span class="math display">\[Q(s, a)=1 / N(s, a) \sum_{s^{\prime} \mid
s, a \rightarrow s^{\prime}} V\left(s^{\prime}\right)\]</span><br />
* 当搜索完成后，返回搜索概率π</p>
<p>最终公式如下：<br />
<span class="math display">\[(\boldsymbol{p}, v)=f_{\theta}(s) \text {
and } l=(z-v)^{2}-\pi^{\mathrm{T}} \log
\boldsymbol{p}+c\|\theta\|^{2}\]</span><br />
其中l是损失函数。z是实际价值，v是网络输出的价值，p是网络输出的策略概率，π是通过MCTS修正过的策略，c是正则化项，用以约束网络参数，防止过拟合。</p>
<h2 id="训练分析">训练&amp;分析</h2>
<p>在整个训练过程中，共生成了490万次自我对弈，每个MCTS使用1600次模拟，相当于每次移动大约0.4
s的思考时间。</p>
<p>图-3分别对比了，AlphaGo Lee，强化学习
Zero，以及在一开始使用有监督学习的强化学习，随着学习时间增加的模型效果，子图a中Elo
rating是用于评价棋手水平；子图b用于预测人类棋手动作；子图c用于预测谁能获胜。<br />
<img
src="https://obimage-1316917304.cos.ap-beijing.myqcloud.com/picgo/Pasted%20image%2020230219105818.png"
alt="图-3" /></p>
<p>Alpha Zero仅用了36 小时就超过了Alpha
Lee，72小时后完胜。相比之下，Alpha Zero使用4个TPU的单机，Alpha
Lee分布在多台机器上，经过了几个月的训练。</p>
<p>比较出人意料的是，前期向专家学习反而限制了最终模型的效果；另外，和专家学习能更好地预测人的动作，但不能达到最好的效果，似乎说明学习专家反而抑置机器的表现（不过，我觉得这可能和计算U时的N有关，也是可改进的）。</p>
<p>作者还实验了修改网络结构对模型的影响，发现加入残差层和神经网络二合一分别提升了模型效果。</p>
<h2 id="学到的知识和最终效果">学到的知识和最终效果</h2>
<p>AlphaGo
Zero从完全随机的动作迅速发展到对围棋概念的复杂理解，包括引信、战术、生死、ko
、yose、捕获比赛、哨兵、形状、影响和领地……<br />
图-6展示了Zero与其它模型的对比效果，Elo rating中200分的差距对应75
%的获胜概率。<br />
<img
src="https://obimage-1316917304.cos.ap-beijing.myqcloud.com/picgo/Pasted%20image%2020230219114115.png"
alt="图-6" /></p>
<h2 id="收获">收获</h2>
<ul>
<li>在边中记录次数，策略，价值：可以在知识图中使用</li>
</ul>
<h2 id="zotero地址">Zotero地址</h2>
<p><a href="http://zotero.org/users/10876188/items/8Z2VCLXT">Mastering
the game of Go without human knowledge</a><br />
zotero id: 8Z2VCLXT</p>
]]></content>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_深度强化学习综述</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/7_%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<p>journal: IEEE Conference on Industrial Electronics and Applications
(ICIEA)<br />
name_ch: 深度强化学习：简要概述<br />
name_en: A Brief Survey of Deep Reinforcement Learning<br />
date_publish: 2017</p>
<h2 id="读后感">读后感</h2>
<p>本篇介绍包含：应用场景；基于策略的和基于价值的不同方法；具体算法包含：DQN，TRPO，AC。<br />
这个文章，感觉中间那部分比较乱，结构比较乱，内容也只是皮毛，定义也没讲清楚，也不够深入，最后一部分还行。</p>
<h2 id="介绍">1. 介绍</h2>
<p>强化学习主要针对：自主的智能体通过与<strong>环境交互学习</strong>最优行为，通过<strong>试错随着时间的推移</strong>而改善模型。<br />
之前方法伸缩性差，且主要解释低维问题，深度学习算法近年的发展，借助其<strong>函数逼近</strong>和<strong>表示学习</strong>（高维状态和动作空间的降维&amp;分层表示）的能力，能更好解决上述问题。<br />
典型的应用场景，如从视频游戏的帧像素学习玩游戏，又如混合有监督学习和强化学习的AlphaGO（结合了监督，强化学习和传统的启发式搜索算法），还有机器人等等。</p>
<h2 id="奖利驱动行为">2. 奖利驱动行为</h2>
<p>原理：强化学习<strong>在交互环境中学习回报更高的行为</strong>（基于行为主义的试错法）。</p>
<p>常用表示：<br />
t: time step 时间步<br />
s: state 状态，有时也记作xt<br />
a: action 行为或动作，有时也记作ut<br />
r: reward 奖利<br />
<span class="math inline">\(\pi\)</span>: policy
目标策略，最大于奖利<br />
详见：<a href="None">强化学习中的元素</a></p>
<p>在时间步t，给定一个状态<span
class="math inline">\(s_t\)</span>，通过目前已知的所有信息计算最佳动作<span
class="math inline">\(a_t\)</span>，执行该动作后，策略返回一个奖利，状态变为st+1，如果往复，在不断试错学习过程中更新知识库。<br />
RL最大的挑战是需要通过试错学习一系列的动作（<strong>而非一个动作</strong>）。</p>
<p>每一次与环境的交互都会产生信息，智能体利用这些信息来更新自己的知识。这种感知-行为学习回路如图2所示。<br />
<img src="None" alt="Pasted%20image%2020230109181228.png|500" /></p>
<h3 id="a.-马尔可夫决策过程">A. 马尔可夫决策过程</h3>
<p><a
href="1_Note/2_算法/7_强化学习/1_强化学习_基础知识#3%20马尔可用决策过程">马尔可用决策过程</a></p>
<h3 id="b.-rl面临的挑战">B. RL面临的挑战</h3>
<ul>
<li>最优策略必须与环境的试错交互，它接收到学习信号只有奖励。<br />
</li>
<li>观察依赖行为，且有很强的时序相关性。<br />
</li>
<li>需要处理长期的时间依赖性：一个动作的结果通常只有在多次环境转换之后才会显现出来（是动作累积的结果），这被称为"时序信用分配问题"。<br />
比如：机器人在迷宫里走，它看到了什么取决了它选择怎么走，这也是探索/利用的问题，这些问题都可以在RL的框架中得到解决。</li>
</ul>
<h2 id="强化学习算法">3. 强化学习算法</h2>
<p>下面将讨论不同类型的强化学习算法。主要包含：基于价值函数的算法，基策略搜索的算法和混合二者的算法A-C。</p>
<h3 id="a.-价值函数">A. 价值函数</h3>
<p>详见： <a href="1_强化学习_基础知识#4.6%20价值%20Value">价值
Value</a></p>
<h4 id="动态规划">动态规划</h4>
<p>贝尔曼方程是动态规划算法的一种重要的组成部分。它通常用来描述一个问题的最优解是由之前状态的最优解转移而来的。<br />
详见：<a
href="4_强化学习_经典算法#1.2%20动态规划法（dynamic%20programming）">动态规划法</a></p>
<h3 id="b.-采样">B. 采样</h3>
<p>相对于动态规划逐步计算值函数，蒙特卡洛方法通过平均多次rollout（尝试探索一条路径）的收益进行来估计一个状态的预期收益。结合TD和蒙特卡罗可以发挥二者的优势。</p>
<p>另一种计算值函数的方法引入了优势函数A，用于表示某个策略不同与其它策略的价值，使用此方法可以对比不同行为的差异。<br />
<span class="math display">\[A^{\pi}=Q^{\pi}-V^{\pi}\]</span><br />
具体用法可参见：<a
href="5_强化学习_深度学习算法#1.2.2%20Dueling%20DQN">Dueling DQN</a></p>
<p>采样方法如图-3所示：<br />
<img src="/attachments_2022/Pasted%20image%2020230109192854.png"
alt="Pasted%20image%2020230109192854.png" /><br />
这里的BACKUP指的是数据，(a)是动态规划，(b)是穷举搜索，它们都使用所有数据计算策略；(c)是时序差分(bootstrap)，(d)是蒙特卡罗，它们使用对数据采样的方法。</p>
<h3 id="c.-搜索策略">C. 搜索策略</h3>
<p>策略搜索方法不需要维护价值函数，而是直接优化策略<span
class="math inline">\(\pi\)</span>，以获得最大的奖利E(R)，这种方法可以使用梯度或非梯度方法优化，使用神经网络实现。梯度方法尤其在参数维度高的情况下更加适用。它一般直接输出概率分布，然后利用概率对行为进行采样；神经网络也可支持无梯度策略，比如低维空间，它不需要策略是可微的。</p>
<h4 id="策略梯度">策略梯度</h4>
<p><a
href="1_Note/2_算法/7_强化学习/5_强化学习_深度学习算法#2%20基于策略的方法：INFORCE算法">基于策略的方法：INFORCE算法</a></p>
<h4 id="a-c方法">A-C方法</h4>
<p><a href="None">整合价值和策略 A-C</a><br />
后面将AC作为策略方法的子集介绍。</p>
<h3 id="d.-计划和学习">D. 计划和学习</h3>
<p>Sutton和Barto将规划定义为利用模型来产生或改进政策的任何方法。这包括分布模型(包括T和R)和样本模型(对状态转换关系采样)。</p>
<p>基于模型的RL方法可以用模型模拟状态转换，以提升采样效率，但是学习模型也可能带来误差，常用的解决方法是只在短序列（局部）使用模型。</p>
<h3 id="e.-使用深度学习方法带来的提升">E.
使用深度学习方法带来的提升</h3>
<p>一般RL方法只适用于低维空间，深度学习方法可将其扩展到高维空间（特征映射，低维表示）；另外，它可以处理像图像等更复杂的数据；更多时候用深度学习来优化策略，价值函数等。</p>
<p>其主要的优势在于梯度能
很好的引导学习。另外，深度学习可以同时优化多个目标，比如同时优化策略、模型、价值函数等，使其相互促进。另外，在rollouts的过程中错误会自动积累，这也避免也手动累加。</p>
<p>下面两章将主要介绍深度学习实现价值函数和策略中的方法。</p>
<h2 id="价值函数详解">4. 价值函数详解</h2>
<p><strong>最早从值函数开始</strong><br />
深度学习最早使用TD（时序差分）90年代在双陆棋中的应用。后来RL研究的发展倾向于使用价值函数，用以捕捉环境的底层结构。DRL中早期的值函数方法将简单的状态作为输入，现在的方法能够处理视觉上和概念上复杂的环境。</p>
<h3 id="a.-函数逼近和dqn">A. 函数逼近和DQN</h3>
<p><img src="/attachments_2022/Pasted%20image%2020230107115047.png"
alt="Pasted%20image%2020230107115047.png" /><br />
DQN可以用于学习视频游戏的玩法，其输入是图片，使用CNN提取时空特征，最后再连接全连接层从而对行为决策。最早的出现的NFQ(neural
fitted Q)，可接收视频输入，降低数据维度，用一个单独分枝预测Q值。<br />
DQN可以接受环境中各种各样的输入，不仅可以让最后一层更好的选择动作，也让卷积层更好的学习与动作无关的表示，从而学到的显著的视觉特征。</p>
<p>如果不用深度学习，如果把每不同的帧作为状态（长x宽x色深），再考虑可能的行为，二项相乘得到Q将是非常大而稀疏的，且学到的一个状态-行为不能传递给附近的状态-行为。</p>
<p>深度学习使用了函数逼近方法解决上述问题，具体方法是：<br />
* 重放 replay<br />
重放机制将历史经历(st, at, st+1,
rt+1)存储在循环缓冲区中，并从中重新采样这些经验来更新策略或决策过程（离线）。这样，在训练过程中就可以使用大量的经验数据，提高模型的效率（批处理提升吞吐量）和泛化能力，并避免数据的冗余或不足。<br />
* 目标网络 target networks<br />
目标网络初始值是制定策略的网络权重，在开始的一般时间只更新Q值，而不更新目标网络，直到一定步数后才更新。<br />
详见：<a href="5_强化学习_深度学习算法#1.1%20DQN技术">DQN技术</a></p>
<h3 id="b.-修改q函数">B. 修改Q函数</h3>
<p>DQN的关键组成部分之一是Q函数的函数逼近器，它依赖于Q函数的实现和优化。本节列出了Q函数优化方法：<br />
Q学习中使用单一的评价，使用最大动作价值作为期望值因此高估的收益，<strong>Double-DQN</strong>学习需要学习一个额外的函数，实现了更好的评估。<br />
另一种方法是学习价值分布而不仅是价值期望。它提供了额外的信息，比如潜在的奖励是来自偏态分布还是多模态分布。<br />
还有一种方法是把Q函数分解成状态价值和优势(我觉得是动作价值)：Q=V+A，相对来说A更容易学习，<strong>对决DQN(dueling)</strong>
与有优先级的replay相结合是离散动作最先进的模型之一；Gu提出的凸性优势层将算法扩展到连续的动作空间，建立了标准化优势函数，结合replay,
目标网络主优势更新，是连续动作最先进的模型之一。<br />
一些领域有大量的离散行为，比如推荐系统，Dulac-Arnold提出“行为嵌入”，使用k近邻产生“原行为”以利用传统的RL方法，或者使用表示学习。<br />
另一个场景是同时决策多个行为，比如机器人动作，组合也会使action指数性增长。比较简单的方法是把复杂行为分解成简单行为分别处理；还有自回归的方法来处理多步预测，离散化大的行为空间；在更广泛的背景下，不直接处理原始行动，可以选择从更高层级的政策中调用"子策略"，称为分层强化学习(
HRL )。<br />
详见：<a
href="1_Note/2_算法/7_强化学习/5_强化学习_深度学习算法#1.2%20其它DQN">其它DQN</a></p>
<h2 id="策略搜索详解">5. 策略搜索详解</h2>
<p>策略搜索是直接寻找策略的方法，它可以是基于梯度，也可以是不基于梯度的。比如不基于剃度的进行算法，这种算法计算量大，但应用范围广，不像梯度方法只能作用于连续空间。也有一些将进化算法和神经网络压缩相结合的方法。</p>
<h3 id="a.-随机函数反向传播">A. 随机函数反向传播</h3>
<p>反向传播不仅能解决强化学习中具体的跟踪，图片分类等问题，而且利用反向传播能力优化参数，它也是SVGs[^1]等算法中的关键原理。</p>
<h3 id="b.-错误积累">B. 错误积累</h3>
<p>直接搜索参数多的神经网络可能很困难，并受到局部最小值的影响。下面介绍一些解决错误积累的方法：<a
href="1_Note/2_算法/7_强化学习/5_强化学习_深度学习算法#4%20其它优化">其它优化</a></p>
<h3 id="c.-a-c方法">C. A-C方法</h3>
<p>详见：<a href="None">整合价值和策略 A-C</a></p>
<h2 id="目前的研究和挑战">目前的研究和挑战</h2>
<p>详见：<a
href="1_Note/2_算法/7_强化学习/6_强化学习_进阶">强化学习_进阶</a></p>
<h2 id="总结超越模型识别">总结：超越模型识别</h2>
<p>除DRL以外，最近还有一些新发展，比如生成式因果模型（非深度学习）相对于A3C表现出了更优越的泛化能力。<br />
目前DRL已与搜索和规划相结果，与传统方法相比有更好的泛化性，可解释性，支持更复杂的环境，但有待进一步提升。<br />
RL能与周围环境互动，更贴近现实世界，让agent通过实验更好理解周围环境，学到更高层的因果关系。</p>
<h2 id="其它">其它</h2>
<ul>
<li><strong>SARSA算法</strong><br />
state-action-reward-state-action<br />
</li>
<li>动态规划<br />
动态规划的基本思想是：将待求解的问题分成若干个子问题，按顺序求解子问题，前面的子问题的解用于后面的子问题的求解，最终得出整个问题的解。</li>
</ul>
<h3 id="启发">启发</h3>
<ul>
<li>可不可以用深度学习把高维特征转到低维，可以的，输入视频学玩游戏就是这样。<br />
</li>
<li>在ICU里训练一个可以模拟环境的目标网络和决策网络同时训练有可能是可以的。</li>
</ul>
]]></content>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_近端策略优化_PPO</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/7_%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E8%BF%91%E7%AB%AF%E7%AD%96%E7%95%A5%E4%BC%98%E5%8C%96_PPO/</url>
    <content><![CDATA[<p>name_ch: 近端策略优化算法<br />
name_en: Proximal Policy Optimization Algorithms<br />
paper_addr: http://arxiv.org/abs/1707.06347<br />
date_publish: 2017-08-28</p>
<h2 id="读后感">读后感</h2>
<p>PPO近端策略优化是一种强化学习算法，具体是对深度学习策略梯度方法的优化。<br />
策略是强化学习中用于决定在每个时刻采取哪个动作的函数。近端约束用于限制策略的变化，以避免过于激进地改变策略。<br />
文中介绍了两种方法：截断和KL散度，近端约束通常使用梯度截断来实现，即将梯度限制在一个特定范围内，让学习的步调不要太大。</p>
<h2 id="介绍">介绍</h2>
<p>一种改进版的强化学习策略梯度算法。它从与环境交互的数据中采样。不同于标准的策略梯度方法对每次采样执行一次梯度更新，文中提出了一个新的目标函数，可以实现多个epoch的minibatch数据更新，另外，它是TRPO的改进算法，相对TRPO更为简单，InstructGPT的强化学习用的就是PPO（ChatGPT可能也是）。</p>
<h2 id="方法">方法</h2>
<h3 id="优化算法">优化算法</h3>
<p>文章介绍了三种方法，其差别主要在损失函数，公式如下图所示：<br />
<img
src="/attachments_2023/Pasted%20image%2020230304165950.png" /><br />
第一种方法的目标是对神经网络theta调参，其中L表示损失Loss，At是时间步t的优势函数，注意这里的r不是奖励，而是新旧策略的变化，当策略不变时r=1：<br />
<span class="math display">\[  
r_{t}(\theta)=\frac{\pi_{\theta}\left(a_{t} \mid
s_{t}\right)}{\pi_{\theta_{\text {old }}}\left(a_{t} \mid s_{t}\right)},
\text { so } r\left(\theta_{\text {old }}\right)=1\]</span><br />
第二种是本文中推荐的<strong>剪裁方法</strong>，它通过限制损失函数，从而限制了后续调参；其中epsilon是超参数，一般是0.2，它将变化范围限制在0.8-1.2之间（上图是论文的截图，我觉得括号位置好像写错了）。<br />
第三种是将<strong>KL散度作为惩罚项</strong>加入了公式，以保证旧策略pi_old与新策略pi尽量相似，其中Beta是超参数，可以是固定的，也可以自动计算，文中还引入了一种自动计算Beta的方法，dtarg为超参数，先根据当前状态计算d，然后计算beta：<br />
<span class="math display">\[  
\begin{array}{l}  
d=\hat{\mathbb{E}}_{t}\left[\operatorname{KL}\left[\pi_{\theta_{\text
{old }}}\left(\cdot \mid s_{t}\right), \pi_{\theta}\left(\cdot \mid
s_{t}\right)\right]\right] \\  
\text { - If } d&lt;d_{\operatorname{targ}} / 1.5, \beta \leftarrow
\beta / 2 \\  
\text { - If } d&gt;d_{\operatorname{targ}} \times 1.5, \beta \leftarrow
\beta \times 2  
\end{array}  
\]</span></p>
<h3 id="具体实现">具体实现</h3>
<p>PPO也属于一种A-C方法，即结合策略和价值的方法。为了同时优化价值和策略，设置最终的目标函数如下：<br />
<span class="math display">\[  
L_{t}^{C L I P+V F+S}(\theta)=\hat{\mathbb{E}}_{t}\left[L_{t}^{C L I
P}(\theta)-c_{1} L_{t}^{V F}(\theta)+c_{2}
S\left[\pi_{\theta}\right]\left(s_{t}\right)\right]  
\]</span><br />
其中c1,c2是超参数，用于设置各方占比；CLIP指的是策略目标，即上面描述的裁剪方法；LV
是状态价值的差；优化的目标是最大化整体L，所以对其中的VF项做减法；和S是熵奖励，用于增强熵，以确保充分的探索。</p>
<p>具体算法如下：<br />
<img
src="/attachments_2023/Pasted%20image%2020230304175759.png" /><br />
其中优化的点是：使用并行的N个actors分别收集T时间步的数据；然后针对NT数据，通过K次epoch，用小批量数据M调整梯度，实验证明效果更好。</p>
<h2 id="实验">实验</h2>
<p>三种方法对比效果如表-1所示：<br />
<img
src="/attachments_2023/Pasted%20image%2020230304171147.png" /><br />
其中Clipping在epsilon设为0.2时效果最好；对于KL散度方法，测试了通过dtarg自动计算beta和设固定beta两种方式，可以看到自动计算的方式略好。</p>
<p>与其它强化学习相比，从图-3可以看到，在大多数任务中PPO(Clip)都优于其它算法。除此以外，实验部分还针对连续领域及atari游戏对比了PPO与其它算法的效果。<br />
<img src="/attachments_2023/Pasted%20image%2020230304171553.png" /></p>
<h2 id="收获">收获</h2>
<ul>
<li>这个剪裁挺好的，调得太过了，就剪掉<br />
</li>
<li>KL是比较分布，所以似乎更优美</li>
</ul>
]]></content>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Fasttext快速文本分类</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/Fasttext%E5%BF%AB%E9%80%9F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[<p>#自然语言处理</p>
<h2 id="简介">1 简介</h2>
<p>Fasttext源于2016年的论文《Bag of Tricks for Efficient Text
Classification》，论文地址：<a
href="https://arxiv.org/pdf/1607.01759.pdf">https://arxiv.org/pdf/1607.01759.pdf</a>。论文非常短，加上References不过五页，Model
architecture只有一页。</p>
<p>深度学习神经网络在自然语言处理中表现非常优秀，但动辄几十层，上亿参数的大型网络速度慢且需要大量算力支持，限制了使用场景。FastText是Facebook开源的一款简单而高效的文本分类器，它使用浅层的神经网络实现了word2vec以及文本分类功能，效果与深层网络差不多，节约资源，且有百倍的速度提升，可谓高效的工业级解决方案。本篇将介绍Fasttext的相关概念、原理及用法。</p>
<h2 id="相关技术">2 相关技术</h2>
<h3 id="bow">2.1 BOW</h3>
<p>BOW BOW是词袋Bag of
Words的简称，BOW是文本分类中常用的文本向量化的方法，它忽略了顺序和语法，将文本看成词汇的集合，且词汇间相互独立，如同把词放进了一个袋子。在分类任务中使用BOW时，就是根据各个词义综合分析文本的类型，常用于感情色彩分类等领域。</p>
<h3 id="cbow">2.2 CBOW</h3>
<p>CBOW是连续词袋模型Continuous Bag-of-Word
Model的简称，它常用于上下文词来预测中间词。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-8cb55a48a5a1a2f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>如图所示，使用前两个和后两个词（共C=4个）预测中间的词w，其中每个词被映射成V维的词向量；每个词向量乘以参数矩阵A(VxN维矩阵)，转换成N维数据，然后将所有词对应的N维的数据相加取均值，计算出N维的隐藏层Hidden；再用隐藏层乘参数矩阵B(NxV维)，计算待预测的词w对应的V维词向量；最终用预测出的w与真实的w作比较计算误差函数，然后用梯度下降调整A,B两个参数矩阵。由此，使用简单的神经网络就完成了预测任务。</p>
<h3 id="n-gram">2.3 N-gram</h3>
<p>N-gram是由N个token（词）组成的有序集合，常用的有Bi-gram
(N=2)和Tri-gram
(N=3)，实际使用中2或3-gram就够用了。Fasttext论文中使用Bi-gram将文本拆成词对。</p>
<p>如I love deep learning可拆成：<br />
Bi-gram : {I, love}, {love, deep}, {deep, learning}<br />
Tri-gram : {I, love, deep}, {love, deep, learning}</p>
<p>这样使一个词它之前的词建立联系。<br />
以Bi-gram为例，Wn-1出现时，Wn出现的概率是：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-195b144156ec3ad8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中C()表示计数，N-gram技术在自然语言处理中广泛使用。</p>
<h4 id="优势">优势</h4>
<ul>
<li>与词序无关<br />
</li>
<li>允许模糊匹配，即使不完全匹配也能识别</li>
</ul>
<h4 id="python示例">Python示例</h4>
<p>（针对英文）</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>LANG <span class="op">=</span> <span class="st">&#39;ZH&#39;</span>  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_ngrams(text, n):  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">&#39;&#39;&#39;  </span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">    用于生成文本的N-gram  </span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">    &#39;&#39;&#39;</span>  </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> LANG <span class="op">==</span> <span class="st">&#39;ZH&#39;</span>:  </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        words <span class="op">=</span> [w <span class="cf">for</span> w <span class="kw">in</span> text]  </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:  </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        words <span class="op">=</span> text.split()  </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    ngrams <span class="op">=</span> []  </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(words) <span class="op">-</span> n <span class="op">+</span> <span class="dv">1</span>):  </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        ngram <span class="op">=</span> <span class="st">&#39; &#39;</span>.join(words[i:i <span class="op">+</span> n])  </span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        ngrams.append(ngram)  </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ngrams  </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fuzzy_ngram_search(query, text, n, threshold):  </span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">&#39;&#39;&#39;  </span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co">    函数用于执行模糊查询  </span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co">    &#39;&#39;&#39;</span>  </span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    query_ngrams <span class="op">=</span> generate_ngrams(query, n)  </span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    text_ngrams <span class="op">=</span> generate_ngrams(text, n)      </span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    match_counts <span class="op">=</span> defaultdict(<span class="bu">int</span>)  </span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> query_ngram <span class="kw">in</span> query_ngrams:  </span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> text_ngram <span class="kw">in</span> text_ngrams:  </span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 计算Jaccard相似性系数，计算交集与并集之比，即使不完全匹配也能成功  </span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>            intersection <span class="op">=</span> <span class="bu">set</span>(query_ngram.split()) <span class="op">&amp;</span> <span class="bu">set</span>(text_ngram.split())  </span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>            union <span class="op">=</span> <span class="bu">set</span>(query_ngram.split()) <span class="op">|</span> <span class="bu">set</span>(text_ngram.split())  </span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>            jaccard_similarity <span class="op">=</span> <span class="bu">len</span>(intersection) <span class="op">/</span> <span class="bu">len</span>(union)  </span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>              </span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> jaccard_similarity <span class="op">&gt;=</span> threshold:  </span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>                match_counts[text_ngram] <span class="op">+=</span> <span class="dv">1</span>  </span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> match_counts  </span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="co"># 示例用法  </span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> LANG <span class="op">==</span> <span class="st">&#39;ZH&#39;</span>:  </span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> <span class="st">&quot;投资者和xx公司均享有回购权，如发生下列任一情形（以较早者为准）&quot;</span>  </span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    query <span class="op">=</span> <span class="st">&quot;回购&quot;</span>  </span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:  </span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> <span class="st">&quot;This is a sample text for demonstration purposes.&quot;</span>  </span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>    query <span class="op">=</span> <span class="st">&quot;sample text&quot;</span>  </span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">2</span>  <span class="co"># 使用2-gram  </span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> <span class="fl">0.5</span>  <span class="co"># 阈值，用于确定相似性  </span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>matches <span class="op">=</span> fuzzy_ngram_search(query, text, n, threshold)  </span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> matches:  </span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>    sorted_matches <span class="op">=</span> <span class="bu">sorted</span>(matches.items(), key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>], reverse<span class="op">=</span><span class="va">True</span>)  </span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;相似的N-gram及其匹配次数：&quot;</span>)  </span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> match, count <span class="kw">in</span> sorted_matches:  </span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">&#123;</span>match<span class="sc">&#125;</span><span class="ss">: </span><span class="sc">&#123;</span>count<span class="sc">&#125;</span><span class="ss"> 次&quot;</span>)  </span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:  </span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;未找到匹配的N-gram。&quot;</span>)  </span></code></pre></div>
<h2 id="fasttext">3 FastText</h2>
<h3 id="原理">3.1 原理</h3>
<p>在文本分类问题中，早期的算法一般将词袋BOW作为输入，使用线性模型作为算法计算类别，这种方法在类别不均衡时效果不好，后来用将线性分类器分解为低秩矩阵或者多层网络的方法解决这一问题。</p>
<p>FastText与CBOW结构类似，如下图所示：</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-23be00c467979b1f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片摘自论文" />
<figcaption aria-hidden="true">图片摘自论文</figcaption>
</figure>
<p>其中输入是文档中的词，使用词嵌入方法，和CBOW一样，通过乘A矩阵转换到Hidden，再乘B矩阵转换到输出层，与CBOW不同的是它的输出不是空缺的单词，而是分类的类别。</p>
<p>FastText用负对数似然作为损失函数：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-2939b040fd38ce00.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中N是文档数，xn是文档中的词特征。yn是标签，A和B是权重矩阵，A用于转换到文本表示，B用于线性变换计算类别，f是一个softmax函数用于计算最终分类的概率。</p>
<p>当分类的类别较多时，计算的时间复杂度是O(hk)，其中k是类别的个数，h是文本表示的维度。Fasttext使用了基于霍夫曼编码树的分级softmax，使训练的时间复杂度降为O(hlog2(k))。每一个节点的概率大小与从树根到该节点经过的路径有关，例如某节点深度为l+1，它的父节点分别是n1…n2，则它的概率是：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-706aea651d28d340.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>这就意味着，节点的概率小于它父节点的概率，因此访问树时，就可以忽略概率小的分枝。如果只需预测取前TopN，则复杂度可降至O(log(TopN))。</p>
<p>下面列出了FastText与深度学习模型的速度比较，可以看到，其提速非常明显。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-bdd02b48d6bc165d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>个人感觉，层次少的好处不只在于运算速度快，而且更容易归因，定位重要特征，以及估计对应的权重，不像深度网络的数据都散布在各层的节点之中。</p>
<h3 id="fasttext用法">3.2 FastText用法</h3>
<h4 id="安装">3.2.1 安装</h4>
<pre><code>$ pip install fasttext  </code></pre>
<h4 id="训练和预测">3.2.2 训练和预测</h4>
<p>数据格式为：__label__标签 ,
已经分词的文档（注意：label两边都需要又下划线）</p>
<p>如下例所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-0fbc05e9964301ee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> fasttext  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(): <span class="co"># 训练模型  </span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> fasttext.train_supervised(<span class="st">&quot;train.txt&quot;</span>, lr<span class="op">=</span><span class="fl">0.1</span>, dim<span class="op">=</span><span class="dv">100</span>,  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>             epoch<span class="op">=</span><span class="dv">5</span>, word_ngrams<span class="op">=</span><span class="dv">2</span>, loss<span class="op">=</span><span class="st">&#39;softmax&#39;</span>)  </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    model.save_model(<span class="st">&quot;model_file.bin&quot;</span>)  </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test(): <span class="co"># 预测  </span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    classifier <span class="op">=</span> fasttext.load_model(<span class="st">&quot;model_file.bin&quot;</span>)  </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> classifier.test(<span class="st">&quot;test.txt&quot;</span>)  </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;准确率:&quot;</span>, result)  </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(<span class="st">&#39;test.txt&#39;</span>, encoding<span class="op">=</span><span class="st">&#39;utf-8&#39;</span>) <span class="im">as</span> fp:  </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> line <span class="kw">in</span> fp.readlines():  </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>            line <span class="op">=</span> line.strip()  </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> line <span class="op">==</span> <span class="st">&#39;&#39;</span>:  </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>                <span class="cf">continue</span>  </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(line, classifier.predict([line])[<span class="dv">0</span>][<span class="dv">0</span>][<span class="dv">0</span>])  </span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&#39;__main__&#39;</span>:  </span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    train()  </span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    test()  </span></code></pre></div>
<h2 id="资料">4 资料</h2>
<p>建议下载源码：<br />
<a
href="https://github.com/facebookresearch/fastText#example-use-cases">https://github.com/facebookresearch/fastText#</a></p>
<p>更详细的用法示例请见：<br />
<a
href="https://github.com/facebookresearch/fastText#example-use-cases">https://github.com/facebookresearch/fastText#example-use-cases</a></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>Lucene在Linux下环境的搭建和运行</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/Lucene%E5%9C%A8Linux%E4%B8%8B%E7%8E%AF%E5%A2%83%E7%9A%84%E6%90%AD%E5%BB%BA%E5%92%8C%E8%BF%90%E8%A1%8C/</url>
    <content><![CDATA[<h1
id="lucene在linux下环境的搭建和运行">Lucene在Linux下环境的搭建和运行</h1>
<p>#linux #自然语言处理</p>
<p>1. 介绍<br />
_ Lucene _<br />
是一个用Java写的全文索引引擎工具包，软件包中包括一些简单的例程，可以直接试用。本例将测试对一个目录中的txt文件进行索引，并通过索引找到相应的文件。</p>
<p>2. 原理<br />
反向搜索机制，维护了一个词/短语表，对于这个表中的每个词/短语，都有一个链表描述了有哪些文档包含了这个词/短语。<br />
Lucene 软件包的发布形式是一个 JAR 文件，包说明<br />
org.apache.lucene.analysis 用于分词<br />
org.apache.lucene.index 用于建立索引<br />
org.apache.lucene.search 用于搜索</p>
<p>3. 安装</p>
<ol type="1">
<li><p>下载：<br />
<a
href="http://xiexiejiao.cn/java/lucene-3-0-2-release-download.html">http://xiexiejiao.cn/java/lucene-3-0-2-release-download.html<br />
</a><br />
本文以lucene-3.0.3-src.tar.gz为例，在Linux中安装运行</p></li>
<li><p>安装相关工具</p></li>
</ol>
<ol type="a">
<li><p>安装JDK 1.5以上版本</p></li>
<li><p>安装Ant工具（Ant是编译Java的工具，与make功能相似）<br />
$ apt-get install ant</p></li>
</ol>
<ol start="3" type="1">
<li><p>安装（参见源码包中BUILD.txt说明）<br />
$ tar xvzf lucene-3.0.3-src.tar.gz<br />
$ cd lucene<br />
$ ant // 此时在build目录下产生jar包<br />
$ ant compile-demo<br />
$ ant jar-demo // 此时在build目录下产生demo的jar包</p></li>
<li><p>运行<br />
$ export CLASSPATH=$CLASSPATH:xxx/build/lucene-<br />
core-3.0.3-dev.jar:xxx/build/lucene-demos-3.0.3-dev.jar //
设置jar包环境变量<br />
$ java org.apache.lecene.demo.IndexFiles TXT所在的目录名 //
此时生成了索引<br />
$ java org.apache.lecene.demo.SearchFiles
//然后按提示输入要查的词，即可找到相应的txt</p></li>
</ol>
<p>4. 参考</p>
<ol type="1">
<li>Lucene入门<br />
<a
href="http://www.iteye.com/topic/33241">http://www.iteye.com/topic/33241</a></li>
</ol>
<p>(转载请注明出处)</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP模型应用之一：基础知识</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/NLP%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E4%B9%8B%E4%B8%80%EF%BC%9A%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<h1 id="nlp模型应用之一基础知识">NLP模型应用之一：基础知识</h1>
<p>#自然语言处理</p>
<h3 id="引入">引入</h3>
<p>2018年底发布的BERT模型和2019年初发布的GPT-2模型，开始挑战人类的语言处理能力。二者都基于之前介绍过的Transformer基础模型。</p>
<p>对模型的研究有几个层次：研究基础模型、扩展模型、应用模型</p>
<ul>
<li><p>研究基础模型
我们熟知的卷积神经网络CNN，循环神经网络RNN，Transformer模型，残差网络ResNet等等，都是底层模型，它们是神经网络应用的基础。</p></li>
<li><p>扩展模型
基础模型需要经过适配和扩展，才能应用到更多领域。如图像识别一开始主要支持图片分类，而后扩展到人脸识别、图像分割等等领域。在自然语言处理领域Transformer模型最初被用于解决翻译问题，而后扩展到解决问答、判断一致性、完型填空等问题之中，比如BERT通过Mask遮蔽技术优化了自然语言处理中的更多问题的解决方法。</p></li>
<li><p>应用模型
再上层是针对某一个领域的具体应用和细化，调用模型解决问题并调优模型。例如使用模型判断正常和病变细胞、预测股票趋势，使用预训练好的语言模型撰写某种类型的文章……这些大多是由工程师完成的工作。从算法角度看创新并不多，但是涉及一些领域相关知识，甚至包括怎么定义问题，描述问题，与模型结合，相对偏重应用，也是软件工程师比较擅长的领域。</p></li>
</ul>
<h3 id="有监督学习和无监督学习">有监督学习和无监督学习</h3>
<p>传统的深度学习在解决某个问题时都需要大量数据反复训练，在数据量和算力足够的情况下，直接训练模型效果更好。但在很多实际应用中，却很难实现。比如：在医学诊断中使用机器视觉技术时，需要大量标注好的正例和反例，反复训练，实际情况是有问题的病例只占少数，评价函数将使模型偏向大多数正常；且标注起来非常困难，从一个300M的图像上标注出所有异常细胞的难度和人工成本可想而知。</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-785b19f9830e09e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片来自天池大数据竞赛平台" />
<figcaption aria-hidden="true">图片来自天池大数据竞赛平台</figcaption>
</figure>
<p>人类解决此问题时，只需要了解正常细胞与异常细胞形状、大小等重要特征的差异即可判断。这是由于人的常识系统，可从图像中提取出形状、颜色等信息。于是人们致力于开发类似人类的常识系统，希望从相关的任务中学习，通过大量数据和训练形成机器的知识体系，在解决具体问题时，只需要少量训练，即可正常工作。</p>
<h3 id="零样本学习">零样本学习</h3>
<p>零样本学习Zero-shot
Learning指的是之前没接触过某一类别的训练样本，但通过在实际目标和训练目标之间建立映射关系，实现识别该类别的功能。比如：之前没见过老虎，但是照猫画虎也能对老虎有大致了解，在判断过程中更容易把老虎和桌子、香蕉区分开来。</p>
<p>单样本学习 One-shot Learning，少量样本学习Few-shot
Learning也与之类似，它们针对的都是只有少量正例或者单个正例的情况下的学习问题，实际上是一种普遍规则到特殊规则的映射。</p>
<p>ELMo、GPT、BERT和GTP-2的目标都是使用大量无标签语料预训练模型，然后用有标签的小数据调优模型。GPT-2主要针对零样本学习，挑战近似无监督学习的问题，后面可以看到，它通过对海量数据的训练生成了常识系统。</p>
<h3 id="半监督学习">半监督学习</h3>
<p>由于神经网络是一种有监督学习模型，必须有特征x和目标y，才能使用误差函数比较实际目标y与预测值y’的差异，反向传播误差来调整参数。接下来的问题是，如何使用无标签的语料来训练模型？</p>
<p>最基本的方法是利用前面的N个词预测后面的第N+1个词，比如：通过序列的前三个元素“白日依”，预测第四个元素“山”是最基本的处理方法，也是GPT模型使用的预训练方法。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-7593b0eada1efc37.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>进而，随机屏蔽序列中的某一元素，如“山”，然后通过它的前文和后文共同预测出该位置的元素。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-c11649942df3436f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>自然语言处理问题中，一般先利用无标签数据按上述方法训练基础模型，然后再用针对具体问题的少量有标签数据进一步训练最终的模型。</p>
<h3 id="迁移学习">迁移学习</h3>
<p>迁移学习Transfer
learning指把训练目标A的模型作为基础，通过进一步训练，实现对目标B的预测。迁移学习有两种方式：</p>
<ul>
<li><p>使用模型提取特征
使用已有模型提取特征作为新模型的输入，这样不一定需要算力强大的GPU，训练上百层的神经网络，也能实现很好的效果。在自然语言处理中，常用训练好的模型提取词向量（词义）或者网络某些层的输出作为特征，比如通过训练把词的索引号转换成一系列的属性值，从而比较两词的相互关系，如得到Play的近义词playing,
game, games, played, players等等。</p></li>
<li><p>预训练和微调
预训练Pretrain加微调Fine-tuning是目前主流的解决方案，先用大量的普通数据训练模型获取一般性知识Pretrain，再在小的目标数据集上调优Fine-tuning。它既能使用别人训练好的成熟模型，又能有针对性的解决问题。
Pretrain+Finetuning的问题在于预训练与调优需要同样形式的数据，比如，解决感情色彩分类的问题，BERT的方法是：前期使用大量的无标签文本训练时也在序列开头预留一个CLS位，用于可能处理的分类问题。</p></li>
</ul>
<p>两种方式各有利弊，提取特征方法更加灵活，可以处理更多不可预知的问题类型，Pretain+Finetuning能更好地利用模型中学到的知识。</p>
<h3 id="自然语言评测">自然语言评测</h3>
<p>自然语言常使用GLUE和SquAD测试，来评价模型的效果。这些测试基本涵盖了自然语言处理领域的常见问题类型。</p>
<p>QLUE全称是General Language Understanding
Evaluation，它涉及自然语言处理的各个子模块，QLUE不公开测试集结果，开发者上传预测结果后，它给出评分。包括十一项测试，如：</p>
<ul>
<li>MNLI：判断两个句子间是继承，反驳，中间关系（双句，分类）<br />
</li>
<li>QQP：两个问句的类似程度（双句，分类）<br />
</li>
<li>QNLI：问答系统，区分问题的正确答案和同一段中的其它描述
（双句，分类）<br />
</li>
<li>SST-2：电影评论的感情色彩标注 （单句，分类）<br />
</li>
<li>CoLA：判断语法是否正确 （单句，分类）<br />
</li>
<li>STS-B：语义相似度打分（1-5级）（双句，分类）<br />
</li>
<li>MRPC：两句语义是否等价（双句，分类）<br />
</li>
<li>RTE识别继承关系，类似MNLI，但数据集较小（双句，分类）</li>
</ul>
<p>SquAD全称The Standford Question Answering
Dataset，它是斯坦福大学于2016年推出的阅读理解数据集，给定一篇文章，准备相应问题，需要算法给出问题的答案。一共有107,785问题，以及配套的
536 篇文章。与GLUE的分类不同，它寻找的是一个答案在段落中的位置。</p>
<p>自然语言评测包含几种任务：判断句与句之间的关系，分类和标注，在后续的BERT部分将介绍具体的实现方法。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP模型应用之三：GPT与GPT-2</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/NLP%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E4%B9%8B%E4%B8%89%EF%BC%9AGPT%E4%B8%8EGPT-2/</url>
    <content><![CDATA[<h1 id="nlp模型应用之三gpt与gpt-2">NLP模型应用之三：GPT与GPT-2</h1>
<p>#自然语言处理</p>
<h3 id="gpt模型">GPT模型</h3>
<p>GPT全称Generative Pre-Training，出自2018年OpenAi发布的论文《Improving
Language Understandingby Generative Pre-Training》，论文地址：<a
href="https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf">https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf</a>。</p>
<p>在自然语言处理问题中，可从互联网上下载大量无标注数据，而针对具体问题的有标注数据却非常少，GPT是一种半监督学习方法，它致力于用大量无标注数据让模型学习“常识”，以缓解标注信息不足的问题。其具体方法是在针对有标签数据训练Fine-tune之前，用无标签数据预训练模型Pretrain，并保证两种训练具有同样的网络结构。</p>
<p>GPT底层也基于Transformer模型，与针对翻译任务的Transformer模型不同的是：它只使用了多个Deocder层。</p>
<p>下图展示了在不修改模型主体结构的情况下，如何使用模型适配多分类、文本蕴含、相似度、多项选择这几类问题。</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-b4431bc4140fc442.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片摘自论文" />
<figcaption aria-hidden="true">图片摘自论文</figcaption>
</figure>
<p>其左侧展示了12层的Transformer
Decoder模型，与Transformer基础模型一致。右侧展示了在Fine-Tune时，先将不同任务通过数据组合，代入Transformer模型，然后在基础模型输出的数据后加全连接层（Linear）以适配标注数据的格式。</p>
<p>例如其中最简单的分类任务，如对于句子的感情色彩识别问题，只涉及单个句子，结果是二分类。因此，只需要代入句子，其在最后加一个全连接层即可；而判断相似度问题，由于两句之间没有相互关系，则需要将两句用加入定界符按不同前后顺序连接，分别输入模型，生成不同的隐藏层数据再代入最终的全连接层。</p>
<p><strong>模型实现</strong></p>
<p>在预训练Pretrain部分，用u表示每一个token(词)，当设置窗口长度为k，预测句中的第i个词时，则使用第i个词之前的k个词，同时也根据超参数Θ，来预测第i个词最可能是什么。简言之，用前面的词预测后面的词。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-f5364ede0fe6ddb3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>具体方法是代入Transformer模型，下式中的模型由l组（组也可称为块block）隐藏层组成，最初输入隐藏层的数据是词编码U乘词嵌入参数We加上位置参数Wp；后面经过l个层（如上图左侧的Transformer组）处理。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-2d2c4557f691a965.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>在有监督训练Fine-tune部分，比如判断句子感情色彩(二分类问题)的句子中包含m个词x1…xm，在pretain训练好的模型之加后再加一个全连接层，用于学习描述输入信息x与目标y关系的参数Wy，最终预测目标y。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-160bd999a3baadbf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>兼顾上式中的L1和L2，加入权重参数λ控制其比例计算出L3，作为优化的依据。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-9f19e035381aadf4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>GPT与基本的Transformer相比，还进行了以下修改：</p>
<ul>
<li>将GLUE（Gaussian Error Linear Unit）作为误差函数
GLUE可视为ReLU的改进方法，ReLU将小于1的数据转换成0，大于1的部分不变，而GELU对其稍做调整，如下图所示:</li>
</ul>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d73800df7efd3f5e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<ul>
<li>位置编码，基础Transformer使用正余弦函数构造位置信息，位置信息不需要训练相应的参数；而GPT将绝对位置信息作为编码。</li>
</ul>
<p><strong>模型效果</strong></p>
<p>GPT基于Transformer修改，在一个8亿单词的语料库上训练，12个Decoder层，12个attention头，隐藏层维度为768。</p>
<p>GPT在自然语言推理、分类、问答、对比相似度的多种测评中均超越了之前的模型（具体的测试以及对比效果详见论文）。且从小数据集如STS-B（约5.7k训练数据实例）到大数据集（550k训练数据）都表现优异。甚至通过预训练，也能实现一些Zero-Shot任务。但由于无标签数据与具体问题的契合度低，因此，学起来更慢，需要的算力也更多。</p>
<h3 id="gpt-2模型">GPT-2模型</h3>
<p>GPT-2模型来自OpenAi的论文《Language Models are Unsupervised Multitask
Learners》无监督的多任务学习语言模型，论文地址：<a
href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf">https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf</a>。</p>
<p>尽管目前很多有监督学习NLP模型效果已经很好，但都需要有针对单个任务训练使用大量有标注数据训练，当目标的分布稍有变化则不能继续使用，因此只能在狭窄的领域中起作用。GPT-2希望通过海量数据和庞大的模型参数训练出一个类似百科全书的模型，无需标注数据也能解决具体问题。</p>
<p>GPT-2希望在完全不理解词的情况下建模，以便让模型可以处理任何编码的语言。GPT-2主要针对zero-shot问题。它在解决多种无监督问题时有很大提升，但是对于有监督学习则差一些。</p>
<p>无监督学习和有监督学习的效果对比，就像两个小孩子学习，一个博览群书，但看的不一定考；另一个专看考点，定点优化。结果就是一个在考试里面成绩更好，另一个能力更强，能解决各种问题，尤其适用于无确定答案的问题。它们在不同的领域各具特长。</p>
<p>目前翻译、问答、阅读理解、总结等以文字作答的领域都可使用GPT-2生成答案，其中最热门的是续写故事模型，其续写水平达到人类水平，具体使用方法是给出文章开头，让模型续写接下来的故事。由于无法控制接下来故事的内容，也有人将其称为造谣神器，从而引发了一些可能出现的道德问题，以致于在论文发表初期并没有发布效果最好的模型，以免被人滥用。这也提示人们：写作如果空话连篇言之无物，人还不如机器。</p>
<p><strong>模型实现</strong></p>
<p>GPT-2的结构类似于GPT模型（也称GPT-1.0），仍然使用单向的Transformer模型，只做了一些局部修改：如将归一化层移到Block的输入位置；在最后一个自注意力块之后加了一层归一化；增大词汇量等等。</p>
<p>与之前的实现方法最大的不同是：GPT-2的训练数据在数量、质量、广泛度上都有大幅度提高：抓取了大量不同类型的网页，并且经过筛选去重生成高质量的训练数据，同时训练出体量更巨大的模型。</p>
<p>在Pretrain部分基本与GPT方法相同，在Fine-tune部分把第二阶段的Fine-tuning有监督训练具体NLP任务，换成了无监督训练具体任务，这样使得预训练和Fine-tuning的结构完全一致。当问题的输入和输出均为文字时，只需要用特定方法组织不同类型的有标注数据即可代入模型，如对于问答使用“问题+答案+文档”的组织形式，对于翻译使用“英文+法文”形式。用前文预测后文，而非使用标注数据调整模型参数。这样既使用了统一的结构做训练，又可适配不同类型的任务。虽然学习速度较慢，但也能达到相对不错的效果。</p>
<p>对于Zero-Shot问题，则需要考虑目标的风格以及分布情况，并实现一些训练集到测试集的映射（如处理特殊符号、缩写等），从而实现从已知领域到未知领域的迁移学习。GPT-2在Zero-Shot（尤其是小数据集Zero-Shot）以及长文本（长距离依赖）中都表现优异。下图为GPT-2在童书词性识别测试中的成绩：位于人类水平之下，但超过了之前模型的水平。</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-c8df0a3f982b10e9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片摘自论文" />
<figcaption aria-hidden="true">图片摘自论文</figcaption>
</figure>
<p><strong>模型效果</strong></p>
<p>GPT-2是一个在海量数据集上训练的基于 transformer
的巨大模型。它从网络上爬取800万网页40G的超大数据集「WebText」作为语言模型的训练数据，并训练了大小不同的多个模型。</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-e98d69a777db0ccf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片摘自论文" />
<figcaption aria-hidden="true">图片摘自论文</figcaption>
</figure>
<p>最小的模型堆叠了 12 层与GPT正常模型大小一样，中号24
层与BERT大模型等大，大号36 层，特大号堆叠了 48
层仍能继续fit，特大号的模型被称为GPT-2，它有1600维隐藏层，参数规模达1.5G，还支持比之前更长的序列，和更长的batch_size。涵盖更多的知识，更大的存储空间。特大模型在32个TPU上也需要约一周时间才能训练完成。海量的训练数据，庞大的网络参数，昂贵的算力，模型优化逐渐变成了资本战争，使普通人在该方向已经很难超越。</p>
<h3 id="代码">代码</h3>
<p>推荐Pytorch版本的<a
href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a>，其中包括各种基于Transformer的模型实现，也包括GPT-2模型，代码共700多行。既可训练模型，也可使用现成模型。由于GPT与GPT-2逻辑变化不大，因此也可参考该代码学习GPT。</p>
<p>推荐GPT-2中文版本：<a
href="https://github.com/Morizeyao/GPT2-Chinese">https://github.com/Morizeyao/GPT2-Chinese</a>，也由Pytorch工具开发，其核心基于上面介绍的GIT项目transformers，并在外层做了一些封装，主体是用于训练的train.py和用于生成文章的generate.py，程序都在200行左右，非常适合用来学习调用Transformer模型以及实现中文模型的方法，其README中列出了各个文件对应的具体功能。使用其核心代码开发的诗歌生成器地址：<a
href="https://jiuge.thunlp.cn/lvshi.html">https://jiuge.thunlp.cn/lvshi.html</a>，下面为藏头诗功能示例：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-302d841c46129b53.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><strong>使用方法：</strong></p>
<ul>
<li>安装<br />
</li>
</ul>
<pre><code>$ git clone https://github.com/Morizeyao/GPT2-Chinese  </code></pre>
<p>安装requirements.txt中列出的支持工具，如：</p>
<pre><code>$ pip install transformers==2.1.1  </code></pre>
<ul>
<li>训练<br />
创建data目录，将训练数据写入该目录中的train.json文件中。 $ mkdir
data<br />
</li>
</ul>
<pre><code>$ mv train.json data/ # 根目录下有train.json示例文件   
$ python train.py --raw # 开始训练train.py   </code></pre>
<p>如能正常运行，训练之后model目录下生成对应模型。</p>
<ul>
<li><p>使用已有模型<br />
训练模型用时较长，可下载现成模型。下载GPT2-Chinese
git项目的README中展示的散文模型，它是使用130MB语料，Batch size
16，深度10层，训练10轮得到的散文模型，将下载的文件复制到model/final_model/目录中（默认模型位置）。</p></li>
<li><p>生成文章<br />
</p></li>
</ul>
<pre><code>$ python ./generate.py --length=300 --nsamples=4 --prefix=秋日午后 --fast_pattern --save_samples --save_samples_path=/tmp/a   </code></pre>
<p>生成以“秋日午后”开头，长度为300个字符的散文，抓取其中一段如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-67686f54d2aceb7d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><strong>解决具体问题</strong></p>
<p>这里训练一个模仿小学生写作文的模型，具体步骤如下：</p>
<ul>
<li><p>写程序从某作文网站抓取四年级作文1000篇，以每篇500字计算，数据约1M多。</p></li>
<li><p>数据清洗，去掉一些特殊字符。 *
在散文模型的基础上继续训练，命令形如：</p></li>
</ul>
<pre><code>$ python train.py --raw --batch_size=3 --pretrained_model=model/model_base/  </code></pre>
<ul>
<li>使用第3轮训练的模型，生成以“秋日午后”为开头的300字作文</li>
</ul>
<pre><code>$ python ./generate.py --length=300 --nsamples=3 --prefix=秋日午后 --fast_pattern --save_samples --save_samples_path=/tmp/a/ --model_path=model/model_epoch3/   </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-e78142ad90eb3675.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>如果不使用预训练模型，只使用1000篇小学生作文训练3轮的模型几乎连不成句。这里将散文模型作为预训练模型Pretrain，用小学生作文Fine-tune，相对于独立的散文模型，内容中多了一些学校相关的内容，由于二次训练的数据太少和训练次数都较少，生成文章的效果不如之前的模型。</p>
<p>增加语料以及训练次数之后，模型将越发成熟：一开始的模型可能会重复一些常用字比如“我我的的”；然后逐渐形成通畅地表达；去掉重复以及相互矛盾的部分；掌握更高级表达技巧……以上的结果只使用了1M-130M语料训练，可以想见，当语料增加到几十G且使用更大模型时的效果。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP模型应用之二：BERT</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/NLP%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E4%B9%8B%E4%BA%8C%EF%BC%9ABERT/</url>
    <content><![CDATA[<h1 id="nlp模型应用之二bert">NLP模型应用之二：BERT</h1>
<p>#自然语言处理</p>
<h3 id="引入">引入</h3>
<p>BERT是谷歌在2018年10月发布的自然语言处理模型，它在十一项自然语言任务中打破记录，在有些任务中有显著提高，并超越了人类水平，被誉为开启了NLP的新时代。虽然，在之后又出现了大量新算法，这两年BERT仍然是各大比赛以及产品中的主流算法。论文地址：<a
href="https://arxiv.org/pdf/1810.04805.pdf">https://arxiv.org/pdf/1810.04805.pdf</a>。</p>
<p>BERT全称为Bidirectional Encoder Representations from
Transformers，从名字可以看出，它基于Transformer基础模型。在BERT之前，ELMo模型已经开始用预测训练方法从无监督数据中提取与上下文相关的词义；而GPT模型用Pretrain/Fine-tune方法，延用了预训练模型的结构和参数，但由于它是单向模型，主要用于据前文估计后文。而BERT使用了双向模型，<strong>遮蔽句中部分单词，训练句间关系</strong>等方法，提出了一套完整的解决方案，在模型结构不变的情况下，适配各种各样的NLP任务。</p>
<h3 id="模型规模">模型规模</h3>
<p>BERT通过前期对大量的无标签数据的预训练pretain，显著地提高了后期在少量数据有标签任务上的表现fine-tune。在33亿单词（BooksCorpus
800M words，English Wikipedia 2,500M
words）的无标注语料库上做预训练，BERT最终发布了BASE和LARGE两个版本的模型，官方也发布了中文模型。</p>
<p>BERT_BASE (L=12, H=768, A=12, Total Param-eters=110M) <br />
BERT_LARGE (L=24, H=1024,A=16, Total Parameters=340M)<br />
BERT_CHINESE(L=12, H=768, A=12, Total Param-eters=110M)</p>
<p>其中L为Transformer layer+ feed
forward层数，H为隐藏层的维度，A为注意力头数。</p>
<h3 id="原理">原理</h3>
<p>BERT是一个多层、双向，且<strong>只有Encoding</strong>编码部分的Transformer模型，先使用大量无标签数据训练，然后针对具体任务，加入最后一层，然后微调模型fine-tune。从而解决分类、推理、问答、命名实体识别等多种问题。</p>
<p>前篇讲到迁移学习的两种主流方法：第一种方法是用训练好的模型作为特征提取器；第二种方法是延用之前训练出的模型整体结构。因此，在预训练时，就要把接口给留出来，比如怎么支持分类，怎么判断前后关系……，设计模型时难度较高，这也是BERT模型的关键技术。</p>
<p>BERT的底层使用Transformer模型，改进了训练方法，更好地利用无监督数据，把一段话中词的之间关系（Attention）用参数描述出来。其中包含了词义、位置的先后关系、句间关系（Segment）。</p>
<p>预训练包括两个任务：第一个任务是屏蔽语言模型（后面详述）；第二个任务是将上下句作为训练样本，用模型判断两句是否相关。两个任务各有一个损失函数值loss，将两个损失加起来作为总的损失进行优化。</p>
<p><strong>遮蔽语言模型（训练句中词的关系）</strong></p>
<p>屏蔽语言模型masked language model（Masked
LM），它随机抠掉句中15%的单词，其中80%替换成[MASK]，10%替换成随机词，另外10%只做替换标记，但不替换内容，让模型根据上下文猜测该单词。由于BERT是双向模型，它不仅能从前文中寻找线索，也能从后文中寻找线索，MLM极大地扩展了模型的适用场景，如解决完型填空之类的问题。</p>
<p><strong>下一句预测（训练句间关系）</strong></p>
<p>下一句预测next Sentence Prediction
(NSP)，用于训练模型识别句子之间的关系。将训练样本作为上下句，有50%样本，下句和上句存在真实的连续关系的，另外50%样本，下句和上句无关，用模型训练判断两句是否相关，从而将无标签数据变为有标签数据。</p>
<p><strong>具体实现</strong></p>
<p>BERT设计同一结构解决不同问题，pretain与fine-tune时模型结构几乎不变，从而利用少量数据fine-tune增量训练，生成高质量的模型。</p>
<p>首先，BERT定义了几种特殊字符： '[PAD]' : 0,
句子不够长时填补的空白字符 '[CLS]' : 1,
位于句首，为分类任务预留，可存储两句间的关系 '[SEP]' : 2,
标记句尾和句间位置 '[MASK]' : 3，随机遮蔽
例如随机取两个句子，组装在一起:
[CLS]+句1+[SEP]+句2+[SEP]；句中15%的词被替换；不够长的句子补[PAD]。如下图所示：</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-18533fe444209099.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片来自论文" />
<figcaption aria-hidden="true">图片来自论文</figcaption>
</figure>
<p>输入数据由三部分组成：词的具体含义(token)，分段信息(segment)，位置信息(position)。这一结构在fine-tune时即可支持双句输入，也可支持单句输入。Pretain训练好的模型参数和结构，用于初始化针对特定目的训练fine-tune。</p>
<h3 id="代码分析">代码分析</h3>
<p>论文中官方发布的代码地址<a
href="https://github.com/google-research/bert">https://github.com/google-research/bert</a>，由Tensorflow实现。</p>
<p>如果使用pytorch，推荐<a
href="https://github.com/graykode/nlp-tutorial">https://github.com/graykode/nlp-tutorial</a>，它是一个自然语言处理教程，由Pytorch实现。其中包括从Word2Vec、TextCNN到Transformer多个模型的演进。其主要优点是代码非常简单。比如BERT实现在nlp-tutorial/5-2.BERT/BERT_Torch.py文件中，只有200多行代码，其中一半以上和前篇Transformer相同，同时比Transformer翻译任务减少了Decoder部分，因此只需要考虑不到一半的基础逻辑。</p>
<p>也可参考<a
href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a>，它的下载量仅次于google官方发布的TensorFlow版本。其中除了BERT还包括GPT2、CTRL、ROBERTA等多个基于transformer模型NLP工具的实现，它同时提供BERT和Pytorch代码。其中BERT的Pytorch实现包括1500行代码，例程相对完整，对于问答、分类、句间关系等问题均有具体实现的类及调用方法。</p>
<p>下面列出了解决问答的实例（在程序的最后部分）：</p>
<pre><code>class BertForQuestionAnswering(BertPreTrainedModel):  
    def __init__(self, config):  
        super(BertForQuestionAnswering, self).__init__(config)  
        self.num_labels = config.num_labels  
        self.bert = BertModel(config)  
        self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)  
        self.init_weights()  
  
    @add_start_docstrings_to_callable(BERT_INPUTS_DOCSTRING)  
    def forward(self, input_ids=None,  
         attention_mask=None,  token_type_ids=None,  
         position_ids=None,  head_mask=None,  
         inputs_embeds=None, start_positions=None,  
         end_positions=None,):  
  
         outputs = self.bert(input_ids,  
             attention_mask=attention_mask,  token_type_ids=token_type_ids,  
             position_ids=position_ids,  head_mask=head_mask,  
             inputs_embeds=inputs_embeds,)  
  
         sequence_output = outputs[0]  
         logits = self.qa_outputs(sequence_output)  
         start_logits, end_logits = logits.split(1, dim=-1)  
         start_logits = start_logits.squeeze(-1)  
         end_logits = end_logits.squeeze(-1)  
         outputs = (start_logits, end_logits,) + outputs[2:]  
  
         if start_positions is not None and end_positions is not None:  
             # If we are on multi-GPU, split add a dimension  
             if len(start_positions.size()) &gt; 1:  
                 start_positions = start_positions.squeeze(-1)  
             if len(end_positions.size()) &gt; 1:  
                 end_positions = end_positions.squeeze(-1)  
             # sometimes the start/end positions are outside our model inputs, we ignore these terms  
  
             ignored_index = start_logits.size(1)  
             start_positions.clamp_(0, ignored_index)  
             end_positions.clamp_(0, ignored_index)  
             loss_fct = CrossEntropyLoss(ignore_index=ignored_index)  
             start_loss = loss_fct(start_logits, start_positions)  
             end_loss = loss_fct(end_logits, end_positions)  
             total_loss = (start_loss + end_loss) / 2  
             outputs = (total_loss,) + outputs  
         return outputs # (loss), start_logits, end_logits, (hidden_states), (attentions)  </code></pre>
<p>问答给出两部分数据，第一部分是问题，第二部分是包含答案的段落，目标是找到答案在段落中的开始和结束位置。上例重写了其父类的初始化init和前向传播forward两个函数，在整个网络结构的最后加入了一个全连接层来计算位置；其核心是用预测的位置与实际位置的差异计算误差函数。</p>
<p>程序中也示例了该类的调用方法：</p>
<pre><code>import torch  
  
tokenizer = BertTokenizer.from_pretrained(&#39;bert-base-uncased&#39;)  
model = BertForQuestionAnswering.from_pretrained(&#39;bert-large-uncased-whole-word-masking-finetuned-squad&#39;)  
question, text = &quot;Who was Jim Henson?&quot;, &quot;Jim Henson was a nice puppet&quot;  
  
input_ids = tokenizer.encode(question, text)  
token_type_ids = [0 if i &lt;= input_ids.index(102) else 1 for i in range(len(input_ids))]  
start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([token_type_ids]))  
all_tokens = tokenizer.convert_ids_to_tokens(input_ids)  
answer = &#39; &#39;.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1])  
assert answer == &quot;a nice puppet&quot;  </code></pre>
<p>由于Pytorch，TensorFlow已经提供了大量的工具，很多“高深”的模型，站在工具的基础上看并不困难。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>NLTK中文词性自动标注</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/NLTK%E4%B8%AD%E6%96%87%E8%AF%8D%E6%80%A7%E8%87%AA%E5%8A%A8%E6%A0%87%E6%B3%A8/</url>
    <content><![CDATA[<h1 id="nltk中文词性自动标注">NLTK中文词性自动标注</h1>
<p>#自然语言处理</p>
<h2 id="说明">1 说明</h2>
<p>学习自然语言处理，一定会参考NLTK,主要是学习它的思路,
从设计地角度看看能做什么.
其本质就是把语言看成字符串，字符串组，字符串集，寻找其间规律．<br />
NLTK是多语言支持的,
但目前网上的例程几乎没有用NLTK处理中文的，其实可以做。比如标注功能,
它自身提供了带标注的中文语库(繁体语料库sinica_treebank).
下面来看看怎样通过数据训练来实现中文词性自动标注.<br />
可以利用它来标注中本，也可以寻找和验证一些隐性的规律.</p>
<h2 id="相关知识">2 相关知识</h2>
<h4 id="词性标注">2.1.1 词性标注</h4>
<p>词汇按它们的词性(parts-of-speech,POS)分类以及相应的标注它们的过程,
词性包括:名词、动词、形容词, 副词等.</p>
<h4 id="中文字符的显示">2.1.2 中文字符的显示</h4>
<p>Python内部编码是unicode, 所以输出中文常常像这样＂ebade5＂,
用print函数输出时, 将自动转换成本地字符集,
也可以使用encode(‘utf-8’)函数转换．</p>
<h4 id="数据集训练集评估">2.1.3 数据集,训练集,评估</h4>
<p>有监督的机器学习一般都是把数据分成两个部分, 一部分用于训练,
一部分用于测试, 还可以通过不同分组交叉验证.
Nltk提供了evaluate()函数评估标注效果.</p>
<h4 id="默认标注default-tagger">2.1.4 默认标注（Default Tagger）</h4>
<p>事先对语料库做了统计(利用nltk.FreqDist()), 出现最多的是名词.<br />
在这里，默认标注为名词.</p>
<h4 id="正则表达式标注regexp-tagger">2.1.5 正则表达式标注（Regexp
Tagger）</h4>
<p>用匹配模式分配标记给标识符．在英文处理中，常用此方式识别各种形态（时态，后缀等），中文识别中也可以使用它来识别标点，数字等．</p>
<h4 id="一元标注unigram-tagger">2.1.6 一元标注（Unigram Tagger）</h4>
<p>一元标注基于一个简单的统计算法:
对每个标识符分配这个独特的标识符最有可能的标记．<br />
在这里就是分配给具体单词，它最常出现的词性．</p>
<h4 id="多元标注n-gram-tagger">2.1.7 多元标注（N-gram Tagger）</h4>
<p>多元标注使用训练集来确定对每个上下文哪个词性标记最有可能。上下文指当前词和它前面
n-1 个标识符的词性标记．<br />
在这里，就是找一些规律, 比如: XX常出现在名词之前, YY常出现在动词之后.
通过某个词以及它之前那个词的词性来判断它的词性. 这就是二元标注.
同理，可以生成三元甚至多元标注．词的距离越远影响越小, 也更占用资源,
一般二元到三元就够了.</p>
<h4 id="组合标注">2.1.8 组合标注</h4>
<p>更精确的算法在很多时候落后于具有更广覆盖范围的算法（比如满足三元标的词可能非常少）,
所以有时我们组合多个标注器，<br />
在这里，组合 bigram 标注器、unigram 标注器和一个默认标注器</p>
<h2 id="代码">3 代码</h2>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># encoding=utf-8    </span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> nltk    </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> nltk.corpus <span class="im">import</span> sinica_treebank <span class="co"># 带标注的中文语料库    </span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 用print输出本地字符格式    </span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> dump_result(result):    </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> item <span class="kw">in</span> result:    </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span> item[<span class="dv">0</span>],<span class="st">&quot;,&quot;</span>,item[<span class="dv">1</span>],    </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>    </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 等标注的词，以空格分词（分词问题不在此讨论）    </span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    raw <span class="op">=</span> <span class="st">&#39;讓 人工 智能 能夠 更 有效地 甄別 虛假 和 低俗 內容 並 控制 其 傳播 是 當前 業界 和 學界 要 重點 研究 的 問題&#39;</span>.decode(<span class="st">&#39;utf-8&#39;</span>)    </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> nltk.word_tokenize(raw)    </span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    sinica_treebank_tagged_sents <span class="op">=</span> sinica_treebank.tagged_sents()   <span class="co"># 以句为单位标    </span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(sinica_treebank_tagged_sents) <span class="op">*</span> <span class="fl">0.9</span>)    </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    train_sents <span class="op">=</span> sinica_treebank_tagged_sents[:size]   <span class="co"># 90% 数据作为训练集    </span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    test_sents <span class="op">=</span> sinica_treebank_tagged_sents[size:]    <span class="co"># 10% 数据作为测试集    </span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    t0 <span class="op">=</span> nltk.DefaultTagger(<span class="st">&#39;Nab&#39;</span>)  <span class="co"># 词性的默认值为名词    </span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    t1 <span class="op">=</span> nltk.UnigramTagger(train_sents, backoff<span class="op">=</span>t0)    <span class="co"># 一元标注    </span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    t2 <span class="op">=</span> nltk.BigramTagger(train_sents, backoff<span class="op">=</span>t1) <span class="co"># 多元（二元）标注    </span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    dump_result(t2.tag(tokens))    </span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span> t2.evaluate(test_sents)   <span class="co"># 根据带标注的文本，评估标注器的正确率    </span></span></code></pre></div>
<h2 id="主要思想">4 主要思想</h2>
<p>词性标注的主要思想是提炼最容易出现的可能性 (在不同层次: 所有词,
具体词, 词间关系)，它是一套统计方法，也是分类器的一个应用．<br />
NLTK的词性标注只是抛砖引玉，使用同样方法，还也可以实现标注词义(一词多义的消歧),
字音(多音字)等等.<br />
通过它来看看自然语言的处理方法, 有了自己的工具,
也能更灵活地使用这个功能, 目前还很简陋，下面来看看怎么改进它.</p>
<h2 id="改进">5 改进</h2>
<h4 id="缺少训练数据">5.1.1 缺少训练数据</h4>
<p>训练数据不足, 或者一些标注本身的问题,
需要改进和增加训练数据．错误分类可以通过大量数据的校正，同时也需考虑语境，选择不同训练集．<br />
上例中的sinica_treebank语料库自带1万个句子,
10万左右的词，文本也比较单一，执行以上程序后可以看到,
准确率在75%左右.<br />
想要训练出更理想的标注器, 需要更多带标注的数据(有监督学习).
数据从哪儿来呢? 其实也简单, 可以用现有靠谱的分词工具(比如:
在线的”语言云”, 离线的”结巴”)的标注结果去训练你自己的标注器.</p>
<h4 id="有一些词本身就是特例-就如同海豚不是鱼类">5.1.2
有一些词本身就是特例, 就如同”海豚不是鱼类”</h4>
<p>统计归类本身无法处理, 除了统计的方案,
还可以添加一一对应的词与标注的映射表来解决此类问题．</p>
<h4 id="新词不常用词">5.1.3 新词/不常用词</h4>
<p>未被训练过的词，可以用一些特殊标记加入字典，在数据积累到一定数量时总结其规律．<br />
N元标注再抽象一个层次是发现词性间的规律，比如＂名词前是形容词的可能性比较大＂，借此来处理不能识别的＂新词＂．<br />
也可以通过WordNet等字典查看具体词的词性．有一些词虽然很少出现,
但词义和词性比较单一. 对多义词，可以选择其最常用的词性．</p>
<h4 id="特殊规则">5.1.4 特殊规则</h4>
<p>有些专业领域会有一些特殊的习惯用法, 也可以通过它制定一些规则.
通过正则表达式标注器实现.</p>
<h4 id="语义-形态">5.1.5 语义, 形态…</h4>
<p>更深层次的语义分析</p>
<h2 id="模型下载">6 模型下载</h2>
<p>报错连接不成功时，直接下载数据：在https://www.nltk.org/nltk_data/中下载插件<br />
下载后解压到：$HOME/nltk_data/corpora/目录下</p>
<h2 id="参考">7 参考</h2>
<h4 id="categorizing-and-tagging-words">7.1.1 Categorizing and Tagging
Words</h4>
<p>http://www.nltk.org/book_1ed/ch05.html</p>
<h4 id="结巴词性标注">7.1.2 结巴词性标注</h4>
<p>http://www.mamicode.com/info-detail-562618.html##</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>随笔_从《芳华》影评到TFIDF算法</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/TF-IDF%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h1 id="随笔_从芳华影评到tfidf算法">随笔_从《芳华》影评到TF/IDF算法</h1>
<p>#随笔 #自然语言处理</p>
<p> 前两天看好多《芳华》的影评说：为什么好人没好报？于是感叹一堆世态炎凉，人性丑陋什么的。我觉得这问题是：为什么中央空调（对谁都温暖）往往不被看好。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-6618c9607d97e738.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 先说说TF/IDF算法，这是一种信息处理和数据挖掘的重要算法，属于统计类方法。比如说，找一篇文章的关键词，TF（词频）是某个词在这篇文章中出现的频率，频率越高越可能是关键字。IDF（逆向文件频率）是这个词出现在其它文章的频率，比如“的”字，它在任何文章都出现，因为必然不是关键字。把TF和IDF乘在一起，就是这个词在这篇文章中的重要程度。</p>
<p> 我们对一个人的态度也往往取决于：他对大家的态度IDF，和他对我的态度TF。刘峰对谁都很好，因此IDF是一个固定值，他对所有人都好这是个加分项吗？很遗憾，看公式：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-0e12cb91482564ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中分子是所有人，分母是刘峰给几个人送过温暖。也就是说他送温暖的人越多，分母越大，IDF值越低。不过也请注意log，它把这个值影响力给降低了。比如说，他给5个人送过温暖，再给第6个人送温暖时，分母变大，IDF降低，导致前5个人对他的好感度降低，不对呀？说好的“爱人者人恒爱之，敬人者人恒敬之”，于是我们的价值观受到了冲击。不过，与此同时，第6个人对他的好感度也增加了，而且idf公式里还有一个log降低了这种影响。</p>
<p> 再来看TF的算法，分子是刘峰送的温暖，分子来自周围人所有温暖之和。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-18fec8893357429c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>对于林丁丁来说，尽管分子很大，但分母更大，所以tf值并不大；而对于何小萍，分母实在是太小了，即使分子不大，tf值也会很大。所以说女孩过于穷养，分母太小，别人稍微对她好点就以身相许了；过于富养，分母太大，看不到别人的善意，又是公主病。</p>
<p> 最终，刘峰在每人心中的分量由下式得出。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-c23919efc39a57c6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 心理价值主要源于比较，跟均值（或者基线值）的比较。这也许就是心里那杆称吧，谁也不是没良心的白眼儿狼，只是正常的心理现象。刘峰人生的不顺利，也不是一个简单的因果关系，其中有好人好报的概率问题，社会环境中的马太效应，以及他自己在关键点的选择等等，TF/IDF只是其中一个因素。至于电影，仁者见仁，智者见智吧。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>TF-IDF逆文本频率指数</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/TF-IDF%E9%80%86%E6%96%87%E6%9C%AC%E9%A2%91%E7%8E%87%E6%8C%87%E6%95%B0/</url>
    <content><![CDATA[<h1 id="tf-idf逆文本频率指数">TF-IDF逆文本频率指数</h1>
<p>#自然语言处理</p>
<p><strong>1. 原理</strong></p>
<p>TF-IDF（term frequency–inverse document
frequency）是信息处理和数据挖掘的重要算法，它属于统计类方法。最常见的用法是寻找一篇文章的关键词。</p>
<p>其公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d36b8e268da0a0a8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>TF（词频）是某个词在这篇文章中出现的频率，频率越高越可能是关键字。它具体的计算方法如上面公式所示：某关键在文章中出现的次数除以该文章中所有词的个数，其中的i是词索引号，j是文章的索引号，k是文件中出现的所有词。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-810411a5f2448c57.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>IDF（逆向文档频率）是这个词出现在其它文章的频率，它具体的计算方法如上式所示：其中分子是文章总数，分母是包含该关键字的文章数目，如果包含该关键字的文件数为0，则分母为0，为解决此问题，分母计算时常常加1。当关键字，如“的”，在大多数文章中都出现，计算出的idf值算小。<br />
词出现次数越多，idf为越大的负数，说明这词没什么用；出现少，则为正值；不多不少为0</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-2e7d4440003c31b2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>把TF和IDF相乘，就是这个词在该文章中的重要程度。</p>
<p><strong>2. 使用Sklearn提供的TF-IDF方法</strong></p>
<p>Sklearn是最常用的机器学习第三方模型，它也支持对TF-IDF算法。</p>
<p>本例中，先使用Jieba工具分词，并模仿英文句子，将其组装成以空格分割的字符串。</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> <span class="im">import</span> jieba  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">2</span> <span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">3</span> <span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">4</span> <span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfTransformer   </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">5</span>    </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">6</span> arr <span class="op">=</span> [<span class="st">&#39;第一天我参观了美术馆&#39;</span>,  </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">7</span> <span class="st">&#39;第二天我参观了博物馆&#39;</span>,  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">8</span> <span class="st">&#39;第三天我参观了动物园&#39;</span>,]  </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">9</span>    </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="dv">10</span> arr <span class="op">=</span> [<span class="st">&#39; &#39;</span>.join(jieba.lcut(i)) <span class="cf">for</span> i <span class="kw">in</span> arr] <span class="co"># 分词  </span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="dv">11</span> <span class="bu">print</span>(arr)  </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="dv">12</span> <span class="co"># 返回结果：（谢彦的技术博客）  </span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="dv">13</span> [<span class="st">&#39;第一天 我 参观 了 美术馆&#39;</span>, <span class="st">&#39;第二天 我 参观 了 博物馆&#39;</span>, <span class="st">&#39;第三天 我 参观 了 动物园&#39;</span>]  </span></code></pre></div>
<p>然后使用sklearn提供的CountVectorizer工具将句子列表转换成词频矩阵，并将其组装成DataFrame。</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> vectorizer <span class="op">=</span> CountVectorizer()  </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">2</span> X <span class="op">=</span> vectorizer.fit_transform(arr)  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">3</span> word <span class="op">=</span> vectorizer.get_feature_names()  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">4</span> df <span class="op">=</span> pd.DataFrame(X.toarray(), columns<span class="op">=</span>word)  </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">5</span> <span class="bu">print</span>(df)  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">6</span> <span class="co"># 返回结果：（谢彦的技术博客）  </span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">7</span> <span class="co"># 动物园  博物馆  参观  第一天  第三天  第二天  美术馆  </span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">8</span> <span class="co"># 0 0       0      1     1      0      0       1  </span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">9</span> <span class="co"># 1 0       1      1     0      0      1      0  </span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="dv">10</span> <span class="co"># 2 1       0      1     0      1      0      0  </span></span></code></pre></div>
<p>其方法get_feature_names返回数据中包含的所有词，需要注意的是它去掉了长度为1的单个词，且重复的词只保留一个。X.toarray()返回了词频数组，组合后生成了包含关键词的字段，这些操作相当于对中文切分后做OneHot展开。每条记录对应列表中的一个句子，如第一句“第一天我参观了美术馆”，其关键字“参观”、“第一天”、“美术馆”被置为1，其它关键字置0。</p>
<p>接下来使用TfidfTransformer方法计算每个关键词的TF-IDF值，值越大，该词在它所在的句子中越重要：</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> transformer <span class="op">=</span> TfidfTransformer()  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">2</span> tfidf <span class="op">=</span> transformer.fit_transform(X)  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">3</span> weight <span class="op">=</span> tfidf.toarray()  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">4</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(weight)): <span class="co"># 访问每一句  </span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">5</span> <span class="bu">print</span>(<span class="st">&quot;第</span><span class="sc">&#123;&#125;</span><span class="st">句：&quot;</span>.<span class="bu">format</span>(i))  </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">6</span>     for j <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(word)): <span class="co"># 访问每个词  </span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">7</span>         if weight[i][j] <span class="op">&gt;</span> <span class="fl">0.05</span>: <span class="co"># 只显示重要关键字  </span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">8</span>             print(word[j],<span class="bu">round</span>(weight[i][j],<span class="dv">2</span>)) <span class="co"># 保留两位小数  </span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">9</span> <span class="co"># 返回结果 （谢彦的技术博客）  </span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="dv">10</span> <span class="co"># 第0句：美术馆 0.65 参观 0.39 第一天 0.65     </span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="dv">11</span> <span class="co"># 第1句：博物馆 0.65 参观 0.39 第二天 0.65  </span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="dv">12</span> <span class="co"># 第2句：动物园 0.65 参观 0.39 第三天 0.65  </span></span></code></pre></div>
<p>经过对数据X的计算之后，返回了权重矩阵，句中的每个词都只在该句中出现了一次，因此其TF值相等，由于“参观”在三句中都出现了，其IDF较其它关键字更低。细心的读者可以发现，其TF-IDF结果与上述公式中计算得出的结果这一致，这是由于Sklearn除了实现基本的TF-IDF算法外，还其行了归一化、平滑等一系列优化操作。详细操作可参见Sklearn源码中的sklearn/feature_extraction/text.py具体实现。</p>
<p><strong>3. 写程序实现TF-IDF方法</strong></p>
<p>TF-IDF算法相对比较简单，手动实现代码量也不大，并且可以在其中加入定制作化操作，例如：下例中也加入了单个字重要性的计算。</p>
<p>本例中使用了Counter方法统计各个词在所在句中出现的次数。</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> <span class="im">from</span> collections <span class="im">import</span> Counter  </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">2</span> <span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">3</span>    </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">4</span> countlist <span class="op">=</span> []  </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">5</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(arr)):  </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">6</span>     count <span class="op">=</span> Counter(arr[i].split(<span class="st">&#39; &#39;</span>)) <span class="co"># 用空格将字串切分成字符串列表，统计每个词出现次数  </span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">7</span>     countlist.append(count)  </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">8</span> <span class="bu">print</span>(countlist)  </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">9</span> <span class="co"># 返回结果：（谢彦的技术博客）  </span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="dv">10</span> <span class="co"># [Counter(&#123;&#39;第一天&#39;: 1, &#39;我&#39;: 1, &#39;参观&#39;: 1, &#39;了&#39;: 1, &#39;美术馆&#39;: 1&#125;),  </span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="dv">11</span> <span class="co">#  Counter(&#123;&#39;第二天&#39;: 1, &#39;我&#39;: 1, &#39;参观&#39;: 1, &#39;了&#39;: 1, &#39;博物馆&#39;: 1&#125;),  </span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="dv">12</span> <span class="co"># Counter(&#123;&#39;第三天&#39;: 1, &#39;我&#39;: 1, &#39;参观&#39;: 1, &#39;了&#39;: 1, &#39;动物园&#39;: 1&#125;)]  </span></span></code></pre></div>
<p>接下来定义了函数分别计算TF，IDF等值。</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> <span class="kw">def</span> tf(word, count):  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">2</span>     return count[word] <span class="op">/</span> <span class="bu">sum</span>(count.values())  </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">3</span> <span class="kw">def</span> contain(word, count_list): <span class="co"># 统计包含关键词word的句子数量  </span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">4</span>     return <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> count <span class="kw">in</span> count_list <span class="cf">if</span> word <span class="kw">in</span> count)  </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">5</span> <span class="kw">def</span> idf(word, count_list):  </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">6</span>     return np.log(<span class="bu">len</span>(count_list) <span class="op">/</span> (contain(word, count_list)) <span class="op">+</span> <span class="dv">1</span>)  <span class="co">#为避免分母为0，分母加1  </span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">7</span> <span class="kw">def</span> tfidf(word, count, count_list):  </span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">8</span>     return tf(word, count) <span class="op">*</span> idf(word, count_list)  </span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">9</span> <span class="cf">for</span> i, count <span class="kw">in</span> <span class="bu">enumerate</span>(countlist):  </span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="dv">10</span> <span class="bu">print</span>(<span class="st">&quot;第</span><span class="sc">&#123;&#125;</span><span class="st">句：&quot;</span>.<span class="bu">format</span>(i))  </span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="dv">11</span>     scores <span class="op">=</span> &#123;word: tfidf(word, count, countlist) <span class="cf">for</span> word <span class="kw">in</span> count&#125;  </span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="dv">12</span>     for word, score <span class="kw">in</span> scores.items():  </span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="dv">13</span>         print(word, <span class="bu">round</span>(score, <span class="dv">2</span>))  </span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="dv">14</span> <span class="co"># 运行结果：（谢彦的技术博客）  </span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="dv">15</span> <span class="co"># 第0句：第一天 0.28 我 0.14 参观 0.14 了 0.14 美术馆 0.28  </span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="dv">16</span> <span class="co"># 第1句：第二天 0.28 我 0.14 参观 0.14 了 0.14 博物馆 0.28  </span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="dv">17</span> <span class="co"># 第2句：第三天 0.28 我 0.14 参观 0.14 了 0.14 动物园 0.28  </span></span></code></pre></div>
<p>从返回结果可以看出，其TF-IDF值与Sklearn计算出的值略有不同，但比例类似，且对单个字进行了统计。</p>
<p>最后，需要再探讨一下TF-IDF的使用场景。在做特征工程时，常遇到这样的问题：从一个短语或短句中提取关键字构造新特征，然后将新特征代入分类或者回归模型，是否需要使用TF-IDF方法？首先，TF是词频，即它需要在一个文本中出现多次才有意义，如果在短句中，每个词最多只出现一次，那么计算TF不如直接判断其是否存在。</p>
<p>另外，TF-IDF的结果展示的是某一词针对于它所在文档的重要性，而不是对比两文档的差异。比如上例中虽然三个短句都包含“参观”，IDF较小，由于词量小TF较大，其最终得分TF-IDF仍然不太低。如果两个短语属于不同类别，新特征对于提取分类特征可能没有意义，但是对于生成文摘就是有意义的关键字。对于此类问题，建议使用：先切分出关键词，将是否包含该关键词作为新特征，然后对新特征和目标变量做假设检验，以判断是否保留该变量的方法提取新特征。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>TFIDF与BM25</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/TFIDF%E4%B8%8EBM25/</url>
    <content><![CDATA[<h3 id="tfidf">TFIDF</h3>
<p>先复习一下 tfidf，tf是词频，即某个词 i 在 文章 j
中出现的频率。分母是文章中所有词的个数，分母是词 i
出现的次数。tf越高说明该词越重要，对于短文本匹配，每个词一般只出现一次，tf
的大小就取决于分母，即文章的长度。<br />
<span class="math display">\[  
tf_{i,j}=\frac{n_{i,j}}{\sum_kn_{k,j}}  
\]</span><br />
idf是逆文档频率，计算该词出现在所有文章中的频率，此时，分母是包含该关键字
i 的文章数，分子是所有文章数
N。用log相当于趋势不变，数值变小了。该词出现越多，分子越大，idf值越小，比如："的"
经常出现，因此不是关键词。当词 i 在 文章 j
中完全不出现，分母为0，因此给分母加 1。<br />
<span class="math display">\[  
idf_i=log\frac{N}{df_i+1}  
\]</span><br />
tf和idf的乘积就是词 i 在文章 j 中的重要性。<br />
<span class="math display">\[tfidf_{i,j}=tf_{i,j} \times
idf_i\]</span><br />
在搜索中，计算搜索串中的多个关键词 与 文章 j 的相似度：将各词的 tfidf
相加：<br />
<span class="math display">\[   
similarity = \sum_{i} tfidf_{i,j}  
\]</span><br />
搜索之前，需要知道各个词在已知文章集中的分布。</p>
<p>详见：[[TF-IDF逆文本频率指数]]</p>
<h3 id="bm25">BM25</h3>
<p>BM25是基于TF-IDF的改进算法，BM 是Best
Match最佳匹配的缩写，25指的是第25次算法迭代。</p>
<p>idf 部分只做了微调：<br />
<span class="math display">\[  
idf_i=log\frac{N-df_i+0.5}{df_i+0.5}  
\]</span><br />
其中分母部分从所有文章中减去了包含 i 的文章，0.5用于平滑。</p>
<p>接下来，又对 tf 做了如下调整：<br />
<span class="math display">\[tfscore= \frac {(k + 1) \times tf} { k
\times (1 - b + b \times \frac{L_d}{L_{avg}}) + tf}\]</span><br />
这里引入了超参数 k 和 b。</p>
<p>先看分母中的括号，Ld是文章长度，Lavg是所有文章的平均长度，当文章长度与平均长度一致时，括号里值为
1，相当于未乘系数；当文章比平均长度短时，括号里的值小于1，分母越小，上式结果越大，也就是说文章越短，每一个词越重要，这也与直觉一致。另外，长度的影响与b有关，b越大，影响越大，b的取值在0-1之间，当b为0时，完全不考虑长度的影响，b
一般取值为 0.75。</p>
<p>k 用于标准化词频的范围，将 tf 值压缩到 0~k+1
之间，其函数曲线如下：<br />
<span class="math display">\[  
tfscore = \frac{(k + 1) \times tf}{k + tf}  
\]</span><br />
<img src="/attachments_2022/Pasted%20image%2020220625134558.png"
alt="Pasted%20image%2020220625134558.png" /></p>
<p>其横轴为 tf，纵轴为 tfscore，分别针对 k=0,1,2,3,4
画图。当k=0时，tfscore为 1，不考虑词频的影响，而 k
越大词频越趋近于原始词频。因此，如果文章只包含短文本，或者无需关注词出现几次，则可将其设成
k=0。</p>
<p>有时还考虑到词 i 在搜索文本中的频率，上式扩展成：<br />
<span class="math display">\[  
\sum_{t \in q} log[\frac{N-df_i+0.5}{df_i+0.5}] \times
\frac{(k_1+1)tf_{td}}{k_1(1-b+b \times \frac{L_d}{L_{avg}})+tf_{td}}
\times \frac{(k_2+1)tf_{tq}}{k_2+tf_{tq}}   
\]</span><br />
其中td指被搜索文本，tq指搜索文本。<br />
另外，看了一些代码，发现这里的 tf
与tfidf中的tf不同，它不是词出现在文档中的次数除文档长度，而是词的出现次数，通过k1控制tfscore的范围，通过Ld/Lavg控制文档长度的影响。</p>
<p>这样我们就可以细化的控制 tf
的占比，以及文章长度的影响，以适应各种不同情况下的搜索和匹配任务。注意设置参数k和b。</p>
<p>之前的BM25算法集成在gensim里，最新的版本没有了，如果想使用，可以从旧版本里抽出来。</p>
<p>代码参考：<br />
https://github.com/RaRe-Technologies/gensim/blob/3.8.3/gensim/summarization/bm25.py</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>中文自然语言处理工具介绍</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E4%B8%AD%E6%96%87%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h1 id="中文自然语言处理工具介绍">中文自然语言处理工具介绍</h1>
<p>#自然语言处理</p>
<p>自然语言处理是人工智能领域中的一个重要方向。它研究能人机之间通讯的方式，并涉及机器对人类知识体系的学习和应用．从分词，相似度计算，情感分析，文章摘要，到学习文献，知识推理，都涉及自然语言分析．下面介绍一些中文语言语义分析的资源．（以下只讨论能嵌入到我们程序里的资源）</p>
<h2 id="同义词词林">1 同义词词林</h2>
<p>《同义词词林》是80年代出版的一本词典，这提供了词的归类，相关性信息，起始主要用于翻译，哈工大对它进行了细化和扩充，出了《词林扩展版》，其中含有7万多词，17000多种语义，五层编码．12大类，94中类，1428小类，形如：</p>
<pre><code>Aa01A01= 人 士 人物 人士 人氏 人选  </code></pre>
<p>每一个条目对应一种语义，根据分类编号：第一位大写表示大类，第二位小写表示中类…其中涉及了一词多义和一义多词．</p>
<p>《词林扩展版》网上的下载很多，大小不到1M，可以直接load到程序中，用于简单的分词，文章分类，模糊查找，统计，情感分析（不同感情色彩对应不同类别号）等等．</p>
<h2 id="哈工大语言云ltp">2 哈工大语言云(LTP)</h2>
<p>中文的语义分析工具，大多数都像LTP这样，提供一个在线的分析器，一组API，比较简单稳定的功能．LTP是其中做得比较好的．<br />
它提供了中文分词、词性标注、命名实体识别、依存句法分析、语义角色标注等等功能．但对于进一步语义方面的深入的开发，用处不大，而且需要连网使用，速度和处理数量上都有一些限制．</p>
<p>详见： <a
href="http://www.ltp-cloud.com/demo">http://www.ltp-cloud.com/demo</a></p>
<h2 id="结巴分词">3 结巴分词</h2>
<p>结巴是一个Python的中文分词组件．它提供了分词和词性标注功能．能在本地自由使用,
是Python实现的,<br />
可以很好的和其它Python工具相结合，使用方法如下：</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#encoding=utf-8  </span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jieba.posseg <span class="im">as</span> pseg  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jieba  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>seg_list <span class="op">=</span> jieba.cut(<span class="st">&quot;我爱北京天安门&quot;</span>, cut_all<span class="op">=</span><span class="va">True</span>)  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> <span class="st">&quot;Full Mode:&quot;</span>, <span class="st">&quot;/ &quot;</span>.join(seg_list)  </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>words <span class="op">=</span> pseg.cut(<span class="st">&quot;我爱北京天安门&quot;</span>)  </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> w <span class="kw">in</span> words:  </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>   <span class="bu">print</span> w.word,w.flag  </span></code></pre></div>
<p>执行结果是:</p>
<pre><code>Full Mode: 我/ 爱/ 北京/ 天安/ 天安门  
我 r  
爱 v  
北京 ns  
天安门 ns  </code></pre>
<p>详见: <a
href="http://www.oschina.net/p/jieba/">http://www.oschina.net/p/jieba/</a></p>
<h2 id="知网-hownet">4 知网 HowNet</h2>
<p>对于语言的理解,
人们更关注语义，即研究文字真正的含义是什么，并希望机器能像人脑一样把知识组织成体系．<br />
中文语义库开放的资源非常少，《现代汉语语义词典》，《中文概念辞书》这些都是听说过没见过，总之人家是不开放.
就算能去书店买一本, 也用不到程序里.<br />
我在网上只找到了HowNet (可以在csdn下载, 压缩包1.5M左右). 形如:</p>
<pre><code>NO.=069980  
W_C=群众  
G_C=N  
E_C=  
W_E=the masses  
G_E=N  
E_E=  
DEF=human|人,mass|众  </code></pre>
<p>可以看到它包含：编号, 中文词, 对应英文词, 词性, 约12万多项.</p>
<p>HowNet在2013年后就不更新了,
以上版本差不多是能在网上找到的比较全的数据了. 它还提供了一些库,
可用于判断相似度等．</p>
<p>详见： <a
href="http://www.keenage.com/html/c_index.html">http://www.keenage.com/html/c_index.html<br />
</a></p>
<h2 id="nltk与wordnet-sentiwordnet">5 NLTK与WordNet (sentiwordnet)</h2>
<p>WordNet是一个语义词典,
NLTK是Python的一个自然语言处理工具，它提供了访问WordNet各种功能的函数。WordNet形如:</p>
<pre><code>n   03790512    0   0   motorcycle#1 bike#1 a motor vehicle with two wheels and a strong frame  </code></pre>
<p>其中含有词性, 编号, 语义,
词汇间的关系(同义/反义,上行/下行,整体/部分…), 大家都觉得＂它很棒,
只可惜没有中文支持＂. 其实也不是没中文支持.<br />
WordNet有中文以及其它更多语言的支持, 可以从以下网址下载: <a
href="http://globalwordnet.org/wordnets-in-the-world/"><br />
</a></p>
<p><a
href="http://globalwordnet.org/wordnets-in-the-world/">http://globalwordnet.org/wordnets-in-the-world/<br />
</a></p>
<p>其中的数据文件形如：</p>
<pre><code>03790512-n  cmn:lemma   摩托车  </code></pre>
<p>可以看到，它与sentiwordnet的词条编号一致，尽管对应可能不是特别完美，但理论上是：对英文能做的处理，对中文也能做．<br />
NLTK+WordNet功能非常丰富，强烈推荐《PYTHON自然语言处理NLTK Natural
LanguageProcessing with<br />
Python》这本书，它已由爱好者译成中文版，可从网上下载．里面不但讨论了具体的实现方法，还讨论了一些研究方向，比如＂从自然语言到一阶逻辑＂…</p>
<h2 id="下载深度学习语言模型">6 下载深度学习语言模型</h2>
<h3 id="查找模型名">6.1 查找模型名</h3>
<p>https://huggingface.co/<br />
输入模型名</p>
<h3 id="下载用法">6.2 下载用法</h3>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer, AutoModel  </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">&quot;nghuyong/ernie-1.0&quot;</span>)  </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModel.from_pretrained(<span class="st">&quot;nghuyong/ernie-1.0&quot;</span>)  </span></code></pre></div>
<h2 id="其它工具">7 其它工具</h2>
<h3 id="自动挖掘短语">7.1 自动挖掘短语</h3>
<p>Autophrase</p>
<h2 id="随想">8 随想</h2>
<p>对语言的处理，首先是分词，然后是消歧, 判断词在句中的成份,
识别语义．形成知识网络．．．希望最终机器能像人类一样，学习，思考和创造．<br />
语言处理在不同的层次有不同的应用：从文章分类，内容提取，到自动诊断病情（IBM<br />
Watson），或者存在更通用的逻辑，使机器成为比搜索引擎更智能的各个行业的专家系统．</p>
<p>自然语言和语义看似多对多的关系，我觉得本质上语义转换成语言是从高维到低的投影．从词林的分类看，真正核心的概念并不太多，但是语义的关系和组合很复杂，再深层次还涉及知识线等等．而语言只是它的表象．在分析过程中，越拟合那表象，差得越多．<br />
另外，这一领域已经有几十年的历史了，学习时尽可能利用现有工具，把精力集中在目标而非具体过程．多参考人家都实现了什么功能，人家的数据是怎么组织的．</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>中文语音合成引擎_Easytts_易言语音合成中文优化版</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E4%B8%AD%E6%96%87%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90%E5%BC%95%E6%93%8E_Easytts_%E6%98%93%E8%A8%80%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90%E4%B8%AD%E6%96%87%E4%BC%98%E5%8C%96%E7%89%88/</url>
    <content><![CDATA[<h1
id="中文语音合成引擎_easytts_易言语音合成中文优化版">中文语音合成引擎_Easytts_易言语音合成中文优化版</h1>
<p>#移动开发 #android #语音</p>
<p>今天发布了改进版的中文语音合成引擎. 分别发布在google market, lephone
market, eoemarket和掌上应用汇上.</p>
<p>可以从此处下载: <a
href="http://www.eoemarket.com/apps/19391">http://www.eoemarket.com/apps/19391<br />
</a></p>
<p>语音合成引擎,
即用于将文本转换成语言音频输出，以增强用户体验，应用程序利用它进行语音输出,
也就是说用普通应用可以借助它来实现读短信, 读小说一类的功能.</p>
<p>与当前市场上的引擎相比, 它有一些优势.</p>
<p>首先,
同其它基于espeak的语音合成引擎一样，它目前支持俄文，印尼文，越南文，英文，法文，德文，土尔其文，葡萄牙文，冰岛文等三十多国语音合成.<br />
很适合与字典一些软件配合使用.</p>
<p>其次, 对于中文, 它不使用espeak库, 而是单独做了一套优化处理,
使其听起来更连贯效果更好. 更适于小说,新闻一类的长篇文字阅读.
优化如下:</p>
<p>1. 支持词连读及声调优化,更好的断句停顿效果.<br />
2. 支持朗读数字和符号<br />
3. 支持更丰富的中文常用词汇<br />
4. 支持全部中文一二级汉字<br />
5. 加入儿化支持<br />
6. 加入轻声支持<br />
7. 对多音字的读音进行优化处理</p>
<p>最重要的是它不是一个单独的应用, 而是Android的一个构件,
使用它的应用程序只要调用Android的标准语音合成API,<br />
使用时在设置中选择该引擎即可, 无需针对该软件做任何专门的开发.</p>
<p>有些合成引擎虽然效果好, 但只在定制的机型上可以使用,
并不发布在market上, 其它机型无法从正规途径获得.
而易言合成适用于所有android<br />
2.2以上版本的手机.</p>
<p>如果有想做语音相关应用的朋友可以关注一下!</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>语音</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>使用有向无环图实现分词</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E4%BD%BF%E7%94%A8%E6%9C%89%E5%90%91%E6%97%A0%E7%8E%AF%E5%9B%BE%E5%AE%9E%E7%8E%B0%E5%88%86%E8%AF%8D/</url>
    <content><![CDATA[<h1 id="使用有向无环图实现分词">使用有向无环图实现分词</h1>
<p>#自然语言处理</p>
<h2 id="结巴分词">结巴分词</h2>
<p>如果搜索”Python
分词”，跳出来的前五个除了广告基本都包括“结巴分词”（Jieba）。可以说它是Python自然语言中使用最广泛的分词工具。它属于基于概率的模型，其原理主要是利用了显性的中文词库（包含常用词及词性和频率）。形如：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-c5a483c88cfb47e0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>同时也支持隐马尔可夫模型从数据中训练出的发射概率，转移概率等不易理解的数据。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-072281a8c43969a8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>简单地说，分词就是识别句中的词组，然后把句子拆分成尽量大的块。但由于上下文语境不同，拆分时也常常出现规则冲突，比如“研究生命的起源”，既可拆成“研究生
命 的 起源”，也可拆成“研究 生命 的
起源”。因此，需要制定一些规则处理这些冲突。</p>
<p>和当前很多基于深度学习的自然语言模型相比，结巴轻量级，使用简单，原理不复杂，效果也不错的分词工具。利用结巴的原理，不仅能实现分词，还能实现切分短语，判断词性，计算短语在句中成份，提取特定成份等一系列的功能。与复杂模型相比，它更容易运用已知的规则，占用更少的资源，避免了大量的文本标注；与自己直接处理相比，它能处理更复杂的情况。尤其在某些语法相对单一的专门领域效果很好。</p>
<p>本文将分析结巴分词的核心代码，看看它是如何解决冲突，并学习有向无环图的数据结构如何在其中发挥作用。</p>
<h2 id="创建有向无环图">创建有向无环图</h2>
<p>结巴的核心代码在jieba/<strong>init</strong>.py文件中，先以“研究生命的起源”为例，看看它如何分词。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-f7078961e6ed13a4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>首先，进行get_DAG()函数构造一个有向无环图，具体方法是以句子的每一个字为开头（184行）能组成什么词。</p>
<p>函数返回的结果是字典DAG，其中每个元素都是位置的索引号：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-10c79d1b1f47700c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>“研”字可以单独成词，也可以和“研究”，“研究生”组合，这是一个开头三种结尾的情况0:[0,1,2]；</p>
<p>“究”不能与后面的“生”组合成词，因此第1个开始位置只对应一个结束位置1:[1]；</p>
<p>“生”字可以单独成词，也可以和“生命”组合，一个开头两种结尾2:[2,3]</p>
<p>后面的其它字以此类推。</p>
<p>我们将其中每个可能出现的词（含一字词和多字词）作为单个元素，组合成图，方向按文字从左到右，既有向且无环（如果同一个词出现在句子的不同位置也认为是不同元素）。可以得到以下图。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-72a24fbb08081e79.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>目标是找到一条从“开始”到“结束”的路径，且整体路径的权重之和最大，每一个点的权重是该词汇出现的频率（后面详述）。</p>
<p>这是一个非常简单的有向无环图DAG应用场景。定义了入口，出口，可用节点，节点权重和节点间可达的方向和关系。通过计算权重选择最佳路径（最佳子图）。</p>
<p>DAG有向无环图指的是一个无回路的有向图（如果有一个非有向无环图，且A点出发向B经C可回到A，形成一个环）。DAG可看作是树结构的扩展，所有的有向树都是有向无环图。</p>
<h2 id="寻找最佳路径">寻找最佳路径</h2>
<p>下面来看看如何从多条可达路径中选取最佳路径，在结巴中由calc函数实现：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-3e8a4cbade9de9ee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>函数运行后，route内容填充如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-180fa308ff19cf20.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>句子包含七个字“研究生命的起源”，返回字典中的每个元素对应以每个位置为起点的最佳终点和分值，终点7也作为一个元素存入字典，其分值为0。具体实现方法是：</p>
<p>先设置终点7的值，加入字典（174行）；</p>
<p>计算最高频率的log值logtatal，其中self.total是将字典中所有词汇的词频值加和（175行）；</p>
<p>从后向前遍历句中的每个位置（176）;</p>
<p>计算以每个字开头的最佳终点及分值：先遍历以该字开头所有可能的词（for x
in
DAG[idx]），计算其中分值最高的组，具体方法是用该词频率的log值减去一个非常大的词频logtotal，再加上该词之后路径的最佳分值（177-178行）；</p>
<p>举个具体例子，对于第一个位置，有三种选择“研”，“研究”，“研究生”，这三词的词频不同，logtotal相同，其后路径的最佳分值也不同。“研”之后路径的分值是“1:(-32.3…)”，“研究”是“2:(-35.9…)”，“研究生”是“3:-(24.8…)”，而且log(‘研究’)又明显大于log(‘研究生’)，因此将“研究”作为该位置的最佳选项。</p>
<h2 id="划分词段">划分词段</h2>
<p>整体分词逻辑如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-c404902722eceb5c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>最终划分时非常简单，代码中使用yield实现了迭代器，看起来比较复杂。如果不考虑英文字母处理（代码中buf部分），简化后的逻辑是：从起始位置0开始，x为起点，y为以x为起点的最佳终点位置，取出该词作为正确切分，然后将结束点y作为新的起点，找下一词的最佳结束点，直至处理完句中所有句。</p>
<p>如本例中，第一次进循环x=0，y=1+1=2，则切出“研究”，然后赋值x=y=2；第二次循环时x=2，y=3+1=4，切出“生命”，然后赋值x=y=4；以此类推。</p>
<p>注意：此函数不包括隐马尔可夫链的逻辑处理，分词时需要加参数HMM=False，才能运行到该函数。</p>
<p>图结构就像树结构一样，其本身非常抽象，可以实现多种多样的功能。个人觉得只要了解其原理即可，用时再深入也不迟。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>全文搜索引擎ElasticSearch</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E5%85%A8%E6%96%87%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8EElasticSearch/</url>
    <content><![CDATA[<h1 id="全文搜索引擎elasticsearch">全文搜索引擎ElasticSearch</h1>
<p>#大数据 #ES #Python</p>
<h2 id="介绍">1. 介绍</h2>
<p>ElasticSearch简称ES。</p>
<p>先来看它的用途：如果只是在多个机器同步，存储和检索大量数据，它与数据库的差别在哪儿，为什么非要使用ES呢？</p>
<p>ES是目前全文搜索引擎的首选。全文检索是指计算机索引程序通过扫描文章中的每一个词，对每一个词建立一个索引，指明该词在文章中出现的次数和位置，当用户查询时，检索程序就根据事先建立的索引进行查找，并将查找的结果反馈给用户的检索方式。简单地说它的优势在于文本检索。ES还可搭建成集群，有良好的扩展性。</p>
<p>如果把ES和数据库相比，ES中包含多个索引index（相当于数据库中的库），索引又包括多个类型type（相当于数据库中的表）。</p>
<p>Kibana是一个开源的分析与可视化平台,设计出来用于和Elasticsearch一起使用的。</p>
<h2 id="es环境搭建">2. ES环境搭建</h2>
<h4 id="安装8以上的java版本">(1) 安装8以上的Java版本</h4>
<p> ES是由java编写的，所以先要安装与其版本匹配的JAVA工具<br />
 在以下网址下载Java8版本：<br />
http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</p>
<pre><code>$ cd /usr/lib/jvm/  
$ tar xvzf jdk-8u181-linux-x64.tar.gz # 解包  
$ sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/jdk1.8.0_181/bin/java # 把新版java纳入版本管理  
$ sudo update-alternatives --config java　#　选择新版本为默认java版本  </code></pre>
<p> 用以上方法设置可以省去手动设置JAVA_HOME等环境变量。</p>
<h4 id="安装es和kibana">(2) 安装ES和Kibana</h4>
<p> 安装时，需要考虑ES和它的辅助软件kibana的版本匹配，于是在网站https://www.elastic.co/downloads，下载了最新版本的deb包（目前最新为6.3.2）</p>
<pre><code>$ sudo dpkg -i elasticsearch-6.3.2.deb # ubuntu系统下安装  
$ sudo dpkg -i kibana-6.3.2-amd64.deb  </code></pre>
<h4 id="配置es">(3) 配置ES</h4>
<pre><code>$ sudo vi /etc/elasticsearch/elasticsearch.yml # 编辑配置文件，也可以通过该配置文件，配置ES集群（一个设成master node, 多个data node，使用同一集群名）  
此处介绍最简单的配置，将host替换为你的地址  
network.host: 127.0.0.1　#　我用的是本机地址  </code></pre>
<h4 id="启动es">(4) 启动ES</h4>
<pre><code>$ sudo service elasticsearch restart # 重启ES  
如果无法启动，也可尝试手动启动服务，命令如下：  
$ sudo /usr/share/elasticsearch/bin/elasticsearch -d  
此时在浏览器中打开：http://127.0.0.1:9200/，可看到端口已打开。  </code></pre>
<h4 id="配置kibana">(5) 配置Kibana</h4>
<pre><code>$ sudo vi /etc/kibana/kibana.yml # 修改配置文件  
此处介绍最简单的配置，打开对以下行的注释：  
server.port: 5601  
server.host: &quot;127.0.0.1&quot;  
server.name: &quot;testme&quot;  
elasticsearch.url: &quot;http://127.0.0.1:9200&quot;  
elasticsearch.preserveHost: true  
kibana.index: &quot;.kibana&quot;  </code></pre>
<h4 id="启动kibana">(6) 启动Kibana</h4>
<pre><code>$ sudo service kibana restart  </code></pre>
<p> 此时在浏览器中，打开http://127.0.0.1:5601，即可看到kibana已启动</p>
<h4 id="一次性安装es和kibana">(7) 一次性安装ES和Kibana</h4>
<pre><code>$ docker pull nshou/elasticsearch-kibana  
$ docker run -it --name es-kibana -d -p 9200:9200 -p 5601:5601 nshou/elasticsearch-kibana  </code></pre>
<p>目前下载的是较新的 7.16.2 版本</p>
<h2 id="使用curl命令访问es">3. 使用curl命令访问ES</h2>
<h4 id="查看服务状态也可以在浏览器中查看">(1)
查看服务状态（也可以在浏览器中查看）</h4>
<pre><code>$ curl &#39;localhost:9200/_cat/health?v&#39;  </code></pre>
<h4 id="查看当前的node节点">(2) 查看当前的Node节点</h4>
<pre><code>$ curl &#39;localhost:9200/_cat/nodes?v&#39;  </code></pre>
<h4 id="新建一个index类似于数据库操作中的建库">(3)
新建一个index（类似于数据库操作中的建库）</h4>
<pre><code>$ curl -XPUT &#39;localhost:9200/test_1&#39;  </code></pre>
<p> 此时在浏览器输入http://127.0.0.1:9200/test_1?pretty，可看到具体信息。</p>
<h4 id="查看当前所有index">(4) 查看当前所有index</h4>
<pre><code>$ curl &#39;localhost:9200/_cat/indices?v&#39;  </code></pre>
<h4 id="向index中添加数据">(5) 向index中添加数据</h4>
<pre><code>$ curl -XPOST http://localhost:9200/test_1/product/ -d &#39;&#123;&quot;author&quot; : &quot;Jack&quot;, , &quot;age&quot;: 32&#125;&#39;  </code></pre>
<p> 如果报错406，请加入参数-H，如下：</p>
<pre><code>$ curl -XPOST http://localhost:9200/test_1/product/ -H &#39;Content-Type: application/json&#39; -d &#39;&#123;&quot;author&quot; : &quot;Xie Yan&quot;&#125;&#39;  </code></pre>
<p> 插入的index是test_1，type是product，此处可以看到，输入ES数据的格式是相当灵活的，它以key-value的方式存取，不像数据库中固定的字段。</p>
<h4 id="查询所有数据">(6) 查询所有数据</h4>
<pre><code>$ curl -XPOST &#39;localhost:9200/test_1/_search&#39; -d &#39; &#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125; &#125;&#39;  </code></pre>
<h4 id="条件查询">(7) 条件查询</h4>
<pre><code>$ curl -XGET http://localhost:9200/test_1/_search?q=age:32  </code></pre>
<p>##4. 使用Kibana查看ES数据<br />
 浏览器访问http://127.0.0.1:5601，在Management-&gt;
Elasticsearch中即可以查看当前的index和type，及其它们的内容，以及进一步分析。</p>
<h2 id="用python访问es数据">5. 用Python访问ES数据</h2>
<h4 id="安装python支持库">(1) 安装python支持库</h4>
<pre><code>$ sudo pip install elasticsearch  </code></pre>
<h4 id="代码">(2) 代码</h4>
<pre><code>from elasticsearch import Elasticsearch  
  
es_host = &#39;127.0.0.1&#39;  
es_index = &#39;test_1&#39;  
es = Elasticsearch(es_host)  
  
result = es.search(index=es_index, body=&#123;&#125;, size=10)  
for item in result[&#39;hits&#39;][&#39;hits&#39;]:  
    print(item)  </code></pre>
<h4 id="说明">(3) 说明</h4>
<p> 可以在body中加入一些用json串描述的查询条件和需要的字段，条件最多1024个，在size中可设置返回条目的多少，用此方法查询最多能返回一万条。<br />
如果超过一万条，用helpers.scan，详见参考的第三部分<br />
如果只关心其中某几个字段，可以body中指定"_source":
['字段1','字段2'...]。</p>
<h2 id="参考">6. 参考</h2>
<h4 id="es与传统数据库的比较">(1) ES与传统数据库的比较</h4>
<p>https://blog.csdn.net/playgrrrrr/article/details/79008124</p>
<h4 id="搭建elasticsearch-5.4分布式集群">(2) 搭建Elasticsearch
5.4分布式集群</h4>
<p>https://blog.csdn.net/napoay/article/details/52202877</p>
<h4 id="elasticsearch-scan和scroll功能-python-实现">(3) ElasticSearch
scan和scroll功能 python 实现</h4>
<p>https://blog.csdn.net/xsdxs/article/details/72876703</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>大数据</tag>
        <tag>ES</tag>
      </tags>
  </entry>
  <entry>
    <title>几种词嵌入方法</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E5%87%A0%E7%A7%8D%E8%AF%8D%E5%B5%8C%E5%85%A5%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h2 id="几种词嵌入方法">几种词嵌入方法</h2>
<p>在自然语言处理中常常使用词嵌入。先来看看词嵌入是什么，以及为什么使用词嵌入。</p>
<h3 id="为什么要使用词嵌入">为什么要使用词嵌入</h3>
<p>以中文为例，词库中至少包括几千个字，几万个词，将其代入模型时，如果使用onehot编码，则变量有成千上万个维度，参数数量和计算量都非常庞大；且无法计算词间的近似性，无法使用“类比”方法将学到的规则泛化到近义词上，也不利于进一步的迁移学习。</p>
<p>词嵌入可将词的特征映射到较低的维度，比如用200维特征描述词库中所有的词，使用模型参数更少，训练更快。</p>
<p>词嵌入可视为给每个组一个n维的编码，能某一维度可能描述词性，另一维度描述感情色彩；用特征描述取代符号描述，类似于机器视觉中使用深度网络提取图片的基本特征。也便于对比、泛化、以及知识迁移。比如使用大量自然语言数据训练了足够好的词表征，在具体任务中使用少量实例fine-tune和pretrain训练好的词嵌入数据训练模型。模型对于fine-tune训练集中从未出现，但在词嵌入中出现的词也能有很好效果，从而实现知识迁移。</p>
<p>除了作为特征提取器，还可通过词嵌入实现运算，比如：男-女=国王-王后，因此可通过国王-男+女的运算得出王后，从而实现一些类比相关的逻辑推理功能，以及性质变换。</p>
<h3 id="将onehot编码转换成词嵌入">将onehot编码转换成词嵌入</h3>
<p>通过矩阵乘法可完成onehot编码到词嵌入的转换，假设词库中包含10000个词，词嵌入200维，onehot变量乘矩阵E可得到词嵌入，E的大小为10000x200，onehot编码型如[0,0,…1,…0]，因此乘法相当于过滤出E矩阵中的某一列，作为该词的词向量表示。矩阵中的权重通过训练得到。可以视为用每一列描述一个具体词的特征。</p>
<h3 id="训练embedding层">训练Embedding层</h3>
<p>训练深度学习模型是一种有监督学习，为了利用互联网上庞大的文本数据。一般使用前N个词预测第N+1个词，比如使用“白日依山”作为x，通过词嵌入编码为200x4=800维的输入特征，预测下一个字为y’，y’是词库中每个词是第N+1字的概率。通过上述算法，即可使用未人工标注的数据训练模型。像BERT，GPT-2等目前流行的模型都使用这种方法训练，它们不仅训练了词向量，还使用深度网络学习了语法语义等其它关系。</p>
<h3 id="word2vec的skip-gram模型">Word2Vec的skip-gram模型</h3>
<p>skip-gram的原理是根据相关词同时出现的情况估计词义。它在句中随机选定一个词作为上下文context，然后从其附近n个词的范围内随机选择一词作为目标target，构建有监督学习的训练集，用上下文训练目标。模型包含词嵌入矩阵，并在最后一层加入Softmax，以便输出概率。它只有一个词输入和一个词输出，比上面介绍的模型更加简单。训练出的模型并不用于解决具体问题，只用于训练词嵌入。上述只是基本原理，具体使用时，还涉及采样时对停用词以及低频词的处理，优化Softmax速度等方法。</p>
<p>腾讯词向量使用了skip-gram的改进版本，其中包括800多万中文词和短语，将每个词展开成200维向量。</p>
<h3 id="word2vec的cbow模型">Word2Vec的CBOW模型</h3>
<p>CBOW是连续词袋模型Continuous Bag-of-Word
Model的简称，它用上下文词来预测中间词。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-4b7f92ca33dcbdb4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>如图所示，使用前两个和后两个词（共C=4个）预测中间的词w，其中每个词被映射成V维的词向量；每个词向量乘以参数矩阵A(VN维矩阵)，转换成N维数据，然后将所有词对应的N维的数据相加取均值，计算出N维的隐藏层Hidden；再用隐藏层乘参数矩阵B(NV维)，计算待预测的词w对应的V维词向量；最终用预测出的w与真实的w作比较计算误差函数，然后用梯度下降调整A,B两个参数矩阵。由此，使用简单的神经网络就完成了预测任务。</p>
<h3 id="glove词向量">GloVe词向量</h3>
<p>GloVe方法比较简单，全称是Global vectors of word
representation。它计算目标target有多少次出现在上下文context中。对于每一个句子，其中的词a出现时词b出现与b出现时a也出现的次数是一致的，因此二者具有对称性。</p>
<p>比如k是单词orange，那么它juice（设为单词i）同时与它出现的概率肯定比它与book（设为单词j）同时出现的概率高。相比单词同时出现的概率，单词同时出现的概率的比率能够更好地区分单词。经过推导，最终得到公式：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5fa2a8eabad0deb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中V为词库中的所有词，X为词汇共现矩阵，Xik表示词k出现在词汇i上下文中的次数总和，wi,wk分别为词i和k对应的词向量，f是权重函数，如果ik未同时出现过，则f(Xik)=0，不将其计入目标函数，f还用于均衡高频词于低频词的影响。通过统计词库中各个词组合同时出现的概率训练模型。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>国产的自然语言处理框架ERNIE</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E5%9B%BD%E4%BA%A7%E7%9A%84%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6ERNIE/</url>
    <content><![CDATA[<h1 id="国产的自然语言处理框架ernie">国产的自然语言处理框架ERNIE</h1>
<p>#自然语言处理</p>
<p>看到题目是否引发一些刻板印象？国产的自然语言处理，主要是用于处理中文？有没有用到最前沿的技术？是不是只提供服务，里面是黑盒？是否全面开源并提供模型？平台是否通用？本文将为您一一解答。</p>
<p>ERNIE是继BERT，ELMo之后又一个以芝麻街人物命名的自然语言模型。ERNIE全称
Enhanced Language Representation with Informative Entities。<br />
<img
src="https://upload-images.jianshu.io/upload_images/5357893-c9f7114b16d648fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="原理">原理</h3>
<p>ERNIE的结构类似BERT框架，或可视为BERT的延续。也是通过海量无标签数据预训练模型，并在特定领域使用fine-tuning调优，同样也使用了在序列中插入符号，以适配不同的训练任务，以及Mask遮蔽部分数据的方法。</p>
<p>从全称可以看出，它最初主要致力于在自然语言处理中<strong>加入关于实体的信息</strong>。在ERNIE
1.0阶段，着重改进了遮蔽策略，BERT遮蔽语料中的词，<strong>而ERNIE把短语和一些专有名词也作为遮蔽的对象</strong>。之前的自然语言模型都是国外模型，因为分词有一定难度，所以处理中文时只是简单地以字为单位。可以想见，引入了词和短语后，ERNIE
1.0处理中文时有明显优势，在其它语言处理中也有提升。从原理上看，ERNIE在数据处理和模型结构中融入了更多的人类知识，比如短语、专有名词等等。</p>
<p>在ERNIE
2.0阶段着眼于模型的应用和发展，提出了连续学习的概念，其论文名为《ERNIE
2.0: A Continual Pre-Training Framework for Language
Understanding》，论文地址： <a
href="https://arxiv.org/pdf/1907.12412.pdf">https://arxiv.org/pdf/1907.12412.pdf</a>。
旨在持续从多项任务中学习，其灵感源于人类的学习方法：<strong>连续学习和多任务学习</strong>。</p>
<h4 id="发展趋势">发展趋势</h4>
<p>从互联网上抓取大量数据训练是自然语言处理的天然优势。那么，是不是掌握了所有数据就能解决所有问题？如何使用通用的知识解决具体问题？如何利用这些庞杂的数据，如何将散落在神经网络参数的中“知识”用于具体的场景之中，是目前研究的重要方向。</p>
<p><strong>起初是从网络是训练和提取词的特征（GloVe）；而后是提取词在某种前提下（如上下文）的特征（ELMo）；然后是调整模型结构使之从一开始就适合解决多种问题，以便后期针对具体问题基于整个模型调优（GPT,
BERT）；继而希望使用单个模型解决各种问题（CTRL, ENRIE）</strong>。</p>
<h4 id="ernie-2.0-核心">ERNIE 2.0 核心</h4>
<p>ERNIE 2.0核心目标有两点：同一模型适配多种任务，逐步进化。</p>
<p>同一模型适配多种任务，之前介绍用于续写的<strong>CTRL</strong>模型也有同样的目标，它具体的实现方法是把<strong>文章的类型信息作为序列的第一个元素代入训练</strong>，以便在预测时生成不同类型
文章；而ERNIE 2.0则是将任务类型<strong>Task Embedding</strong>与Word
Embedding、Position Embedding、Segment Embedding一起作为模型的输入。</p>
<p>起初，模型的输入是词向量Word
Embedding用于学习词义，用多个特征描述一个词汇；而后从RNN过渡到Attention模型时，加入了位置信息Position
Embedding，通过训练学习位置的作用，模型不再依赖循环神经网络处理词的先后关系；BERT模型加入了段信息Segment
Embedding用于组织数据，使单个可模型用于多种场景，比如单句的感情色彩分类，两句语义是否相同等等；<strong>ERNIE
2.0又引入了任务类型，用于学习不同的任务</strong>。</p>
<p>逐步进化也是一个难点，之前的架构基于海量数据预训练一个大模型，在解决具体问题时基于该模型调优。这样即利用了海量的知识，又减少了解决具体问题运算量。引发的问题是如何将调优时积累的知识汇入基础模型。看似不是什么核心技术，实际应用中却至关重要。</p>
<p>如果每一次加入少量信息都重新训练整个模型，其运算量是不可想象的；如果用针对具体任务fine-tuning后的模型替换通用模型，则<strong>某些通用知识会被具体任务中的领域知识所覆盖，损失了通用性</strong>。所以需要在学习新任务时不忘记前面学到的知识，同时还要保证学习速度。ERNIE在训练新任务时，先用之前的参数设置模型，然后用新任务的数据和原来的类似数据一起训练模型，以保证旧知识不被忘掉，而训练新任务的迭代次数自动计算生成，以保证学习速度。</p>
<p>ERNIE
2.0可谓良心之作，除了逐步多任务训练，<strong>还加入了一些新的技术：ERNIE可同时支持两个损失函数：一个在句子层面，一个在词层面。除了词和句，ERNIE还把任务划分成三类：词任务、句法任务、语义任务。</strong>
在使用无标签数据方面，也更上一层楼。</p>
<p>词任务（Word）：引入短语和专有名词的Mask（ERNIE
1.0功能）；英文方面可预测大小写；<strong>标记同一文档中多次出现的词</strong>（可能在同一文档中含义相同，某词出现次数多也可能与主题相关）。</p>
<p>句法任务（Structure）：通过重排段落中的句子，学习句与句之间的关系；<strong>句子间的距离是相邻关系、处于同一文档中、或者完全无关</strong>。</p>
<p>语义任务（Semantic）：判断两句间语义或者修辞的相似度；<strong>通过搜索引擎技术提取某段文字的主旨</strong>，有三种关系：最强的关系是输入“主旨”，引擎找到了相应内容，且该内容被用户点击；弱关系是输入“主旨”，引擎找到了相应内容，但未被用户点击；第三种是无关，输入“主旨”查不到相应内容。</p>
<h4 id="ernie-2.0-效果">ERNIE 2.0 效果</h4>
<p>ERNIE
2.0在中文任务中效果自不必说，在共计16个中英文任务上也超越了BERT和XLNet。</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-99e289365227b0ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片摘自论文" />
<figcaption aria-hidden="true">图片摘自论文</figcaption>
</figure>
<p>sota是State of the Arts的缩写，一般理解为比较先进的模型。</p>
<p>标准模型包含12个Encoder层，12头Attention，隐藏层维度768，是与BERT的基础版本类似的中型模型，为了提升ERNIE模型在实际工业应用中的落地能力，百度还发布了中文的ERNIE-tiny模型，预测提速4.3倍，减少了层数，加大了宽度（隐藏层元素个数）。从评测结果看，效果也不错，不过模型也不小，压缩包大小为1G左右。Git支持中文说明，其中展示了各种评测的具体效果。</p>
<h3 id="代码分析">代码分析</h3>
<p>百度发布了ERNIE的完整代码和预训练模型，并且包含中文的说明文档。它的代码既不是TensorFlow也不是Pytorch，而是百度的深度学习平台飞桨PaddlePaddle，这提高了大多数开发者的学习成本。</p>
<p>代码位置在：<a
href="https://github.com/PaddlePaddle/ERNIE/">https://github.com/PaddlePaddle/ERNIE/</a></p>
<p>核心代码在ernie/model/目录中，不过一两千行，目录中包含三个文件：</p>
<ul>
<li>ernie.py  ERNIE 2.0模型实现<br />
</li>
<li>ernie_v1.py ERINE 1.0模型实现<br />
</li>
<li>transformer_encoder.py 底层模型支持</li>
</ul>
<p>其基础也是Transformer框架的Encoder部分，从实现transformer
encoder可以看到飞桨平台和其它平台的语法差异。它与其它平台实现的函数名几乎都一样，如果熟悉其它深度学习工具，上手应该很快。</p>
<p>在核心模型外层，还实现了三组调用方法：预训练pretrain*
，调优fine-tuning<em>，使用模型run_</em>，还全面提供周边的辅助工具和文档，很像一个完整的软件，不加修改也可通过Python训练和使用。</p>
<h3 id="深度学习框架哪家强">深度学习框架哪家强</h3>
<p>深度学习框架初看各有差异，实际都是实现各种层，优化器，误差函数，正反向传递；训练、预测、评估也都大同小异。只是思路和适配的场景略有不同。当然，从学习入门的角度看，只可能选择一个切入点，寻找最高效的方法，然后向外延展。</p>
<p>选择平台时，可参考以下几方面：</p>
<ul>
<li><p>通用<br />
首先，框架必须通用，看完一个新技术的论文之后都需要直接看代码，从这个角度看TensorFlow是首选，其次是Pytorch。</p></li>
<li><p>易用性<br />
飞桨和Pytorch的易用和理解难度都小于TensorFlow，都能很快上手。</p></li>
<li><p>使用场景<br />
使用场景又分移动端和主机端，移动端有其专门的工具；主机端需要考虑模型的大小、响应速度、稳定性等等因素。TensorFlow也是工业级应用的首选，飞桨支持多机多卡，在高效训练方面也有优势，而学术界更多地使用Pytorch。</p></li>
<li><p>发展趋势<br />
目前Pytorch和TensorFlow是两个最流行的深度学习框架，下图为最近几年各个领域发布论文的趋势图，实线是Pytorch，虚线为TensorFlow。不仅可从中看到深度学习领域的高速发展，也可看到近两年Pytorch的飞速发展。而今天的研究，将在明天成为产品。</p></li>
</ul>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-9495ea788799aab7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>TensorFlow
于2015年面世，这几年深度学习的高速发展，让TensorFlow超越之前的Caffe，Theano变为主流；TensorFlow框架出现较早，大家都使用它发论文，做产品；在行业快速兴起之后，它便成了主流。</p>
<p>Pytorch在2017年初推出，借助易用性成为学术界的新宠。Pytorch能快速发展，除了它本身的优点以外，很可能是由于它主要出现在研究领域，而研究领域对时间成本不是非常敏感。</p>
<p>某一框架能否被广泛使用，周边生态很重要。对于开源软件，大多数人都是拿来主义，越简单，工作量越少越好。工业领域需要计算学习成本、移植成本、收益、风险、稳定性，目前和未来的工作量，技术越成熟，成本计算越精确。投资回报可能比平台好坏更重要。垄断一旦形成，后来的平台如果没有决定性的优势，就很难发展起来。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>实战_用TF/IDF算法对比相似度</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E5%AE%9E%E6%88%98_%E7%94%A8TFIDF%E7%AE%97%E6%B3%95%E5%AF%B9%E6%AF%94%E7%9B%B8%E4%BC%BC%E5%BA%A6/</url>
    <content><![CDATA[<h2 id="实战_用tfidf算法对比相似度">实战_用TF/IDF算法对比相似度</h2>
<h3 id="原理">原理</h3>
<p>TF/IDF方法于1983年题出，它先计算每个单词出现的频率，然后适当归一化。利用TF-IDF方法将任意长度的文档缩减为固定长度的数字列表，然后对比文本相似度，gensim工具包提供该方法。</p>
<p>简单复习一下具体算法：</p>
<p><strong>词频TF</strong><br />
<span class="math display">\[  
tf_{i,j}=\frac{n_{i,j}}{\sum_kn_{k,j}}  
\]</span><br />
其中n是句中词，i是词的索引号，j是文章索引号，k是文章中所有词，上式计算的是词i在本篇出现的比率。请注意：在短文本的情况下，绝大多数词只出现一次，tf就只和文章长短有关了。</p>
<p><strong>逆向文档频率IDF</strong><br />
<span class="math display">\[  
idf_{i}=log \frac{|D|}{|j:t_i\in d_j|}  
\]</span><br />
其中分母是文章总数，分子是包含词i的文章数。</p>
<p><strong>TF/IDF</strong><br />
<span class="math display">\[tfidf_{i,j}=tf_{i,j} \times
idf_{i}\]</span><br />
tfidf值反映的是每个词在文档中的重要程度。请注意：这是一种基于计数的方法，不直接使用词义。</p>
<p>该算法的优点在于算法简单，计算量小；而缺点在于无法处理对同一概念的不同描述，另外，它是词袋类模型，不考虑词的先后顺序和关系。</p>
<p>详见<a
href="https://blog.csdn.net/xieyan0811/article/details/89790729">TF-IDF逆文本频率指数</a></p>
<h3 id="流程">流程</h3>
<p>计算文本相似度，指的是从多个文档中找到与句子相似度最高的文档，常用于实现搜索，匹配，文本标准化等功能。具体流程如下：<br />
* 用待搜语料训练TFIDF<br />
* 将待搜语料转成包含的关键字及关键字对应评分 M<br />
* 将搜索文本转换成关键字和评分 K<br />
* 逐条计算M中内容与K的相似度评分<br />
* 选最相近的前N条</p>
<h3 id="代码分析">代码分析</h3>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> jieba <span class="im">import</span> lcut  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.similarities <span class="im">import</span> SparseMatrixSimilarity  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.corpora <span class="im">import</span> Dictionary  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> TfidfModel  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [<span class="st">&#39;古典生物型霍乱&#39;</span>,  </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;霍乱，由于O1群霍乱弧菌，埃尔托生物型所致&#39;</span>,  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;埃尔托生物型霍乱&#39;</span>,  </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;霍乱暴发型&#39;</span>,  </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;伤寒&#39;</span>]  </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> [lcut(s) <span class="cf">for</span> s <span class="kw">in</span> data]  </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;  </span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co">此时 texts中每个元素是一个句子，句子又由词组成  </span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">[[&#39;古典&#39;, &#39;生物&#39;, &#39;型&#39;, &#39;霍乱&#39;],  </span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"> [&#39;霍乱&#39;, &#39;，&#39;, &#39;由于&#39;, &#39;O1&#39;, &#39;群&#39;, &#39;霍乱弧菌&#39;, &#39;，&#39;, &#39;埃尔托&#39;, &#39;生物&#39;, &#39;型&#39;, &#39;所致&#39;],  </span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"> [&#39;埃尔托&#39;, &#39;生物&#39;, &#39;型&#39;, &#39;霍乱&#39;],  </span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"> [&#39;霍乱&#39;, &#39;暴发型&#39;],  </span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"> [&#39;伤寒&#39;]]  </span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;</span>  </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>dictionary <span class="op">=</span> Dictionary(texts)  </span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;  </span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co">dictionary 结构类似字典，包含索引号和词的关系  </span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co">&#123;0: &#39;古典&#39;, 1: &#39;型&#39;, 2: &#39;生物&#39;, 3: &#39;霍乱&#39;, 4: &#39;O1&#39;, 5: &#39;埃尔托&#39;, 6: &#39;所致&#39;,  </span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co"> 7: &#39;由于&#39;, 8: &#39;群&#39;, 9: &#39;霍乱弧菌&#39;, 10: &#39;，&#39;, 11: &#39;暴发型&#39;, 12: &#39;伤寒&#39;&#125;  </span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;</span>  </span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> [dictionary.doc2bow(text) <span class="cf">for</span> text <span class="kw">in</span> texts]  </span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;  </span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co">corpus 语料库，结构同texts，但每个子元素不是字，而是id及其在本句中出现的次数  </span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="co">[[(0, 1), (1, 1), (2, 1), (3, 1)],  </span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="co"> [(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2)],  </span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="co"> [(1, 1), (2, 1), (3, 1), (5, 1)],  </span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="co"> [(3, 1), (11, 1)],  </span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="co"> [(12, 1)]]  </span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;</span>  </span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>tfidf <span class="op">=</span> TfidfModel(corpus) <span class="co"># 用语料库训练模型  </span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>tf_texts <span class="op">=</span> tfidf[corpus] <span class="co"># 将语料库作为被搜索数据  </span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>sparse_matrix <span class="op">=</span> SparseMatrixSimilarity(tf_texts, <span class="bu">len</span>(dictionary)) <span class="co"># 构建工具类的实例  </span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;  </span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="co">sparse_matrix.index内容如下：  </span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="co">  (0, 0)    0.9050976  </span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="co">  (0, 1)    0.28727236  </span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="co">  (0, 2)    0.28727236  </span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="co">  (0, 3)    0.12548897  </span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="co">  (1, 1)    0.10273404  </span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="co">  (1, 2)    0.10273404  </span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="co">  (1, 3)    0.044877227  </span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="co">  ...  </span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co">此时sparse_matrix中存储的是各句中包含的关键字及其tfidf值  </span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;</span>  </span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>keyword <span class="op">=</span> <span class="st">&#39;埃尔托生物霍乱&#39;</span>  </span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>kw_vector <span class="op">=</span> dictionary.doc2bow(lcut(keyword))  </span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;  </span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="co">转换待搜索字符串，返回包含的关键字id及其出现次数  </span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="co">kw_vector: [(2, 1), (3, 1), (5, 1)]  </span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;</span>  </span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>tf_kw <span class="op">=</span> tfidf[kw_vector]  </span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;  </span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="co">获取关键词对应的的tfidf值  </span></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="co">tf_kw: [(2, 0.476), (3, 0.208), (5, 0.854)]  </span></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;</span>  </span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>similarities <span class="op">=</span> sparse_matrix.get_similarities(tf_kw)  </span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> e, s <span class="kw">in</span> <span class="bu">enumerate</span>(similarities):  </span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;与 </span><span class="sc">%d</span><span class="st"> 相似度为：</span><span class="sc">%.2f</span><span class="st">&#39;</span> <span class="op">%</span> (e, s))  </span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;  </span></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a><span class="co">计算搜索串与被搜索数据中每一项的相似度  </span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a><span class="co">与 0 相似度为：0.16  </span></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a><span class="co">与 1 相似度为：0.22  </span></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a><span class="co">与 2 相似度为：0.90  </span></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a><span class="co">与 3 相似度为：0.03  </span></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a><span class="co">与 4 相似度为：0.00  </span></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;</span>  </span></code></pre></div>
<h3 id="完整代码">完整代码</h3>
<p>封装一下，以便拿来就用</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> jieba <span class="im">import</span> lcut  </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.similarities <span class="im">import</span> SparseMatrixSimilarity  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.corpora <span class="im">import</span> Dictionary  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> TfidfModel  </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TFIDFSimilarity:  </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):  </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span>  </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train(<span class="va">self</span>, data):  </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        <span class="co">&#39;&#39;&#39;  </span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co">        训练模型，需转入待匹配列表  </span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co">        &#39;&#39;&#39;</span>  </span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        texts <span class="op">=</span> [lcut(s) <span class="cf">for</span> s <span class="kw">in</span> data]  </span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dictionary <span class="op">=</span> Dictionary(texts)  </span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        corpus <span class="op">=</span> [<span class="va">self</span>.dictionary.doc2bow(text) <span class="cf">for</span> text <span class="kw">in</span> texts]  </span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tfidf <span class="op">=</span> TfidfModel(corpus)  </span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        tf_texts <span class="op">=</span> <span class="va">self</span>.tfidf[corpus]  </span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        num_features <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.dictionary.token2id)  </span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sparse_matrix <span class="op">=</span> SparseMatrixSimilarity(tf_texts, num_features)  </span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_similarities(<span class="va">self</span>, string, topN <span class="op">=</span> <span class="dv">3</span>):  </span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>        <span class="co">&#39;&#39;&#39;  </span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="co">        从模型中找最相近的 topN 个匹配项，返回其索引号和近似度  </span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="co">        &#39;&#39;&#39;</span>  </span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> lcut(string)  </span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>        kw_vector <span class="op">=</span> <span class="va">self</span>.dictionary.doc2bow(text)  </span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>        tf_kw <span class="op">=</span> <span class="va">self</span>.tfidf[kw_vector]  </span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>        similarities <span class="op">=</span> <span class="va">self</span>.sparse_matrix.get_similarities(tf_kw)  </span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>        index <span class="op">=</span> np.argsort(similarities)[:<span class="op">-</span>topN<span class="op">-</span><span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>]  </span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [(i,s) <span class="cf">for</span> i,s <span class="kw">in</span> <span class="bu">zip</span>(index,similarities[index])]  </span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [<span class="st">&#39;霍乱，由于O1群霍乱弧菌，霍乱生物型所致&#39;</span>,   </span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;古典生物型霍乱&#39;</span>,   </span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;霍乱，由于O1群霍乱弧菌，埃尔托生物型所致&#39;</span>]  </span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>s_tools <span class="op">=</span> TFIDFSimilarity()  </span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>s_tools.train(data)  </span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>s_tools.get_similarities(<span class="st">&#39;埃尔托生物霍乱&#39;</span>,<span class="dv">3</span>)  </span></code></pre></div>
<h3 id="技巧">技巧</h3>
<ul>
<li>生成词典可以选择以词为单位，以字为单位，或拆分成所有可能的词...<br />
</li>
<li>可去掉停用词和与主题无关的词<br />
</li>
<li>可加入其它的语料训练TFIDF，以学习词的重要性（不加入候选集即可）<br />
</li>
<li>如果搜索句子中的词未出现在字典中，将自动忽略该词<br />
</li>
<li>如包含英文，请注意大小写</li>
</ul>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>建立垂直搜索引擎&amp;中文分词</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E5%BB%BA%E7%AB%8B%E5%9E%82%E7%9B%B4%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E&amp;%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D/</url>
    <content><![CDATA[<h1 id="建立垂直搜索引擎中文分词">建立垂直搜索引擎&amp;中文分词</h1>
<p>#自然语言处理</p>
<p>关键字：垂直搜索引擎中文分词 nutch tomcat linux</p>
<p>1． 说明<br />
建立简单的垂直搜索引擎。<br />
通过实际操作信息搜索软件，环境配置，了解主要模块的构成，及交互方式。通过修改搜索软件，了解软件架构，接口及插件等运作方式。<br />
通过对分词部分的修改，了解了分词原理及主流的中文分词技术及其应用。</p>
<p>2． 目标<br />
利用信息检索工具，搜索 <a
href="http://beijing.cncn.com/">http://beijing.cncn.com/</a><br />
网站中的景点介绍网页，对其进行索引，使用户可通过关键字查询，快速定位感兴趣的景点。</p>
<p>3． 软件介绍<br />
由于搜索引擎是多个软件协作完成的，软件之间版本相互依赖，以下选择了
nutch1.2 及相关版本软件。</p>
<ol type="1">
<li><p>软件环境： Ubuntu 10.04 ， JDK-1.6</p></li>
<li><p>信息检索工具： Nutch 1.2 源码<br />
当前 nutch 版本 1.4 ，此版本不直接支持 tomcat ，需要通过 solr ，因而选择
nutch 1.2 ，该版本可以通过<br />
svn 标签下载</p></li>
<li><p>Web 服务器： tomcat<br />
Apache-tomcat-6.0.26 安装包</p></li>
<li><p>辅助工具（用于查看搜索结果）： luke<br />
lukeall-1.0.1.jar 包， 1.0 以上版本才能与 nutch1.2 配合</p></li>
<li><p>汉语分词工具： IKAnalysis<br />
针对 nutch 1.2 版本修改过的 IKAnalyzer3.2.8_wave.jar （直接下载标准版
jar 包，在使用 web<br />
页面搜索时有问题）</p></li>
</ol>
<p>4． 配置环境<br />
实现环境为 linux ubuntu 10.04 ，需要编译 java 源码，所以安装相关工具</p>
<ol type="1">
<li><p>安装 ant<br />
** $ apt-get install ant1.8 **</p></li>
<li><p>安装 svn （用于下载 nutch1.2 源码）<br />
** $ apt-get install subversion **</p></li>
<li><p>安装配置 java 环境<br />
** $ apt-get install openjdk-6-jdk<br />
$ export JAVA_HOME=/usr/lib/jvm/openjdk-6-jdk **</p></li>
<li><p>安装 javacc （用于中文分词时生成 java 代码）<br />
** $ apt-get install javacc **</p></li>
</ol>
<p>5．Nutch 安装及配置</p>
<ol type="1">
<li><p>下载安装<br />
** $ svn co <a
href="http://svn.apache.org/repos/asf/nutch/tags/release-1.2%20./nutch-1.2">http://svn.apache.org/repos/asf/nutch/tags/release-1.2<br />
./nutch-1.2<br />
</a><br />
$ cd nutch-1.2<br />
$ ant ** 编译，生成可执行程序和库 **<br />
$ ant war ** 编译 war 文件，供 tomcat 使用</p></li>
<li><p>设置要搜索的 URL<br />
** $ mkdir urls<br />
$ echo "http://beijing.cncn.com/jingdian/" &gt; urls/addr.txt<br />
$ vi conf/nutch-default.xml ** 编辑如下（否则运行时会报 agent
相关错误）<br />
** <name>http.agent.name</name><br />
<value>test</value> **</p></li>
<li><p>设置搜索地址过滤<br />
** $ vi conf/crawl-urlfilter.txt ** 编辑如下<br />
** #+^http://([a-z0-9]<em>\.)</em>MY.DOMAIN.NAME/<br />
+^http://([a-z0-9]<em>\.)</em>beijing.cncn.com/jingdian/ **</p></li>
<li><p>开始对网页生成索引（爬虫）<br />
** $ bin/nutch crawl urls -dir crawl -depth 5 -topN 5 -threads 1
**<br />
此时建立 crawl 目录，其中含索引信息，可通过命令或 luke
程序查看索引结果</p></li>
<li><p>查看生成的索引（可以看到抓取的网页个数）<br />
** $ bin/nutch readdb crawl/crawldb –stats **</p></li>
<li><p>用命令行检索（用命令行方式检索相关“北海”的信息）<br />
** $ bin/nutch org.apache.nutch.searcher.NutchBean ' 北海 ** ** '
**</p></li>
</ol>
<p>6．Tomcat 安装及配置</p>
<ol type="1">
<li><p>下载（此版本含可执行程序，无需编译）<br />
apache-tomcat-6.0.26.tar.gz</p></li>
<li><p>设置相关环境变量（可设置在 $HOME/.bashrc 中）<br />
** $ export
CATALINA_BASE="/exports/download/src/apache-tomcat-6.0.26/"<br />
$ export
CATALINA_HOME="/exports/download/src/apache-tomcat-6.0.26/"<br />
$ export PATH=<span
class="math inline">\(PATH:\)</span>CATALINA_HOME/bin **</p></li>
<li><p>设置 tomcat 与 nutch 接口（复制 war 文件到 tomcat 目录）<br />
** $ cp /exports/download/src/nutch-1.2/build/nutch-1.2.war<br />
$CATALINA_BASE/webapps/nutch-1.2.war **</p></li>
<li><p>支持中文显示<br />
** $ vi /exports/download/src/apache-tomcat-6.0.26/conf/server.xml
编辑如下<br />
<Connector port="8080" protocol="HTTP/1.1"    
connectionTimeout="20000"    
redirectPort="8443"    
URIEncoding="UTF-8" useBodyEncodingForURI="true"/> **</p></li>
<li><p>指定搜索结果存储的目录<br />
注意 webapps/nutch-1.2 目录为通过 war 包生成的目录，替换 war
包时需要删除此目录<br />
** $ vi $CATALINA_BASE/webapps/nutch-1.2/WEB-INF/classes/nutch-site.xml
**<br />
编辑如下<br />
** <configuration><br />
<property><br />
<name>searcher.dir</name><br />
<value>/exports/download/src/nutch-1.2/crawl/</value><br />
</property><br />
</configuration> **</p></li>
<li><p>开启 web 服务<br />
** $ catalina.sh run **</p></li>
<li><p>通过网页访问搜索结果<br />
打开 firefox ，在地址栏输入 <a
href="http://127.0.0.1:8080/nutch-1.2/">http://127.0.0.1:8080/nutch-1.2/<br />
</a></p></li>
</ol>
<p>7． 中文分词</p>
<ol type="1">
<li>修改 jj 源码，生成支持词索引的 java 文件<br />
** $ cd $nutch-1.2/<br />
$ vim src/java/org/apache/nutch/analysis/NutchAnalysis.jj **<br />
做以下修改，以支持中文词的搜索<br />
** | &lt;SIGRAM: (<CJK>)+ &gt; **<br />
以下为生成 java 文件，并覆盖原有文件<br />
** $ cd $nutch-1.2/src/java/org/apache/nutch/analysis<br />
$ javacc -OUTPUT_DIRECTORY=./ika/ NutchAnalysis.jj<br />
$ mv ./ika/* ./ ; rmdir ika; **</li>
</ol>
<p>** 2) ** 修改刚编译出来的 NutchAnalysis.java<br />
** $ vim
$nutch-1.2/src/java/org/apache/nutch/analysis/NutchAnalysis.java
**<br />
两处加入 ParseException( 否则编译时会报错 )<br />
** public static Query parseQuery(String queryString, Configuration
conf)<br />
throws IOException,ParseException {<br />
……<br />
public static Query parseQuery(String queryString, Analyzer
analyzer,<br />
Configuration conf) throws IOException,ParseException {<br />
…… **</p>
<ol start="3" type="1">
<li><p>下载修改好的 IKAnalysis.jar 包，以下网载是修改好的 jar
包，从官网下载的 jar 包在见面查询时有问题<br />
<a
href="http://trac.nchc.org.tw/cloud/attachment/wiki/waue/2011/0801/IKAnalyzer3.2.8_waue.jar"><br />
http://trac.nchc.org.tw/cloud/attachment/wiki/waue/2011/0801/IKAnalyzer3.2.8_waue.jar<br />
</a><br />
将 jar 包复制到相应目录下<br />
** $ cp IKAnalyzer3.2.8.jar $nutch-1.2/lib/ **</p></li>
<li><p>修改分词调用函数<br />
** $ vim src/java/org/apache/nutch/analysis/NutchDocumentAnalyzer.java
**<br />
调用 IK 分词工具，修改 tokenStream 函数如下<br />
** public TokenStream tokenStream(String fieldName, Reader reader)
{<br />
Analyzer analyzer;<br />
if ("anchor".equals(fieldName))<br />
analyzer = ANCHOR_ANALYZER;<br />
else<br />
//analyzer = CONTENT_ANALYZER;<br />
analyzer = new org.wltea.analyzer.lucene.IKAnalyzer();<br />
return analyzer.tokenStream(fieldName, reader);<br />
} **</p></li>
<li><p>修改编译脚本 build.xml<br />
编译时加入 IK 的 jar 包，在 <lib></lib> 之间（约 200 行）加入：<br />
** <include name="IKAnalyzer3.2.8.jar"/> **<br />
设置自动编译 war 包，之后无需再 ant war<br />
修改 ** <targe tname="job" depends="compile"> ** ，改为 **
<target name="job"  
depends="compile,war"> **</p></li>
<li><p>编译<br />
** $ ant **</p></li>
<li><p>设置 tomcat 与 nutch 接口（复制 war 文件到 tomcat 目录）<br />
** $ rm /exports/download/src/apache-tomcat-6.0.26/webapps/nutch-1.2 –r
**<br />
目录 webapps/nutch-1.2 是自动生成的，替换 war 包时需要将其删掉，新的 war
包才能生效<br />
** $ cp /exports/download/src/nutch-1.2/build/nutch-1.2.war<br />
$CATALINA_HOME/webapps/nutch-1.2.war **</p></li>
<li><p>重新生成索引<br />
** $ bin/nutch crawl urls -dir crawl -depth 5 -topN 5 -threads 1
**</p></li>
<li><p>重启 tomcat ，在网页中搜索即可</p></li>
</ol>
<p>8． 支持与或非运算<br />
使用 +- 号可进行与非运算，使用时需要注意 +-
号前需加空格，后面直接与词相连，不加空格<br />
在有些情况下，换替了分词工具后，无法进行布尔运算了，这是由于有些分词工具将布尔运算符当成停用词或符号去掉了（详见
NutchAnalysis.java<br />
的分词返回结果），分词后索引的接口是 IndexSearch 。</p>
<p>9． 参考</p>
<ol type="1">
<li>分词介绍<br />
http://trac.nchc.org.tw/cloud/wiki/waue/2011/0801</li>
</ol>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>用WordNet实现中文情感分析</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E7%94%A8WordNet%E5%AE%9E%E7%8E%B0%E4%B8%AD%E6%96%87%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="用wordnet实现中文情感分析">用WordNet实现中文情感分析</h1>
<p>#自然语言处理</p>
<h2 id="分析">1. 分析</h2>
<p>中文的情感分析可以用词林做，词林有一大类（Ｇ类）对应心理活动，但是相对于wordnet还是太简单了．因此使用nltk+wordnet的方案，如下：</p>
<ol type="1">
<li><p>中文分词：结巴分词</p></li>
<li><p>中英文翻译：wordnet汉语开放词网，可从以下网址下载：<br />
<a
href="http://compling.hss.ntu.edu.sg/cow/">http://compling.hss.ntu.edu.sg/cow/</a></p></li>
<li><p>情感分析：wordnet的sentiwordnet组件</p></li>
<li><p>停用词：参考以下网页，另外加入常用标点符号<br />
<a
href="http://blog.csdn.net/u010533386/article/details/51458591">http://blog.csdn.net/u010533386/article/details/51458591<br />
</a></p></li>
</ol>
<h2 id="代码">2. 代码</h2>
<pre><code># encoding=utf-8  
import jieba  
import sys  
import codecs  
  
reload(sys)  
  
import nltk  
from nltk.corpus import wordnet as wn  
from nltk.corpus import sentiwordnet as swn  
  
sys.setdefaultencoding(&#39;utf8&#39;)  
  
def doSeg(filename) :  
    f = open(filename, &#39;r+&#39;)  
    file_list = f.read()  
    f.close()  
  
    seg_list = jieba.cut(file_list)  
  
    stopwords = []    
    for word in open(&quot;./stop_words.txt&quot;, &quot;r&quot;):    
        stopwords.append(word.strip())   
  
    ll = []  
    for seg in seg_list :  
        if (seg.encode(&quot;utf-8&quot;) not in stopwords and seg != &#39; &#39; and seg != &#39;&#39; and seg != &quot;\n&quot; and seg != &quot;\n\n&quot;):  
            ll.append(seg)  
    return ll  
  
def loadWordNet():  
    f = codecs.open(&quot;./cow-not-full.txt&quot;, &quot;rb&quot;, &quot;utf-8&quot;)  
    known = set()  
    for l in f:  
        if l.startswith(&#39;#&#39;) or not l.strip():  
            continue  
        row = l.strip().split(&quot;\t&quot;)  
        if len(row) == 3:  
            (synset, lemma, status) = row   
        elif len(row) == 2:  
            (synset, lemma) = row   
            status = &#39;Y&#39;  
        else:  
            print &quot;illformed line: &quot;, l.strip()  
        if status in [&#39;Y&#39;, &#39;O&#39; ]:  
            if not (synset.strip(), lemma.strip()) in known:  
                known.add((synset.strip(), lemma.strip()))  
    return known  
  
def findWordNet(known, key):  
    ll = [];  
    for kk in known:  
        if (kk[1] == key):  
             ll.append(kk[0])  
    return ll  
  
def id2ss(ID):  
    return wn._synset_from_pos_and_offset(str(ID[-1:]), int(ID[:8]))  
  
def getSenti(word):  
    return swn.senti_synset(word.name())  
  
if __name__ == &#39;__main__&#39; :  
    known = loadWordNet()  
    words = doSeg(sys.argv[1])  
  
    n = 0  
    p = 0  
    for word in words:  
      ll = findWordNet(known, word)  
      if (len(ll) != 0):  
          n1 = 0.0  
          p1 = 0.0  
          for wid in ll:  
              desc = id2ss(wid)  
              swninfo = getSenti(desc)  
              p1 = p1 + swninfo.pos_score()  
              n1 = n1 + swninfo.neg_score()  
          if (p1 != 0.0 or n1 != 0.0):  
              print word, &#39;-&gt; n &#39;, (n1 / len(ll)), &quot;, p &quot;, (p1 / len(ll))  
          p = p + p1 / len(ll)  
          n = n + n1 / len(ll)  
    print &quot;n&quot;, n, &quot;, p&quot;, p  </code></pre>
<h2 id="待解决的问题">3. 待解决的问题</h2>
<ol type="1">
<li><p>结巴分词与wordnet chinese中的词不能一一对应<br />
结巴分词虽然可以导入自定义的词典，但仍有些结巴分出的词，在wordnet找不到对应词义，比如＂太后＂，＂童子＂，还有一些组合词如＂很早已前＂，＂黄山＂等等．大多是名词，需要进一步＂学习＂．<br />
临时的解决方案是：将其当作＂专有名词＂处理</p></li>
<li><p>一词多义／一义多词<br />
无论是情感分析，还是语义分析，中文或者英文，都需要解决词和义的对应问题.<br />
临时的解决方案是：找到该词的所有语义，取其平均的情感值．另外，结巴也可判断出词性作为进一步参考．</p></li>
<li><p>语义问题<br />
语义问题是最根本的问题，一方面需要分析句子的结构，另外也和内容也有关，尤其是长文章，经常会使用＂先抑后扬＂＂对比分析＂，这样就比较难以判断感情色彩了．</p></li>
</ol>
<h2 id="参考">4. 参考</h2>
<ol type="1">
<li><p>Learning lexical scales:WordNet and SentiWordNet<br />
<a
href="http://compprag.christopherpotts.net/wordnet.html">http://compprag.christopherpotts.net/wordnet.html<br />
</a></p></li>
<li><p>SentiWordNet Interface<br />
<a
href="http://www.nltk.org/howto/sentiwordnet.html">http://www.nltk.org/howto/sentiwordnet.html<br />
</a></p></li>
</ol>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>用Lucene构造垂直搜索引擎</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E7%94%A8Lucene%E6%9E%84%E9%80%A0%E5%9E%82%E7%9B%B4%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/</url>
    <content><![CDATA[<h1 id="用lucene构造垂直搜索引擎">用Lucene构造垂直搜索引擎</h1>
<p>#Python #自然语言处理</p>
<p>Lucene是用于全文检索的开源库，Apache软件基金会提供支持。它由Java语言开发，也提供Python接口调用。</p>
<p>本文介绍使用开源项目Lupyne构建垂直搜索引擎，搜索本地网页中的内容。它使用Python语言编写，搜索功能用Lucene引擎实现，使用html2text从本地网页中提取数据，实现对网页中文本的搜索，前端调用CherryPy框架（flask的web
server常用作开发测试。而cherrypy的web
server常用于生产环境），提供网页搜索功能。</p>
<p>运行文中实例需要匹配Java，Python，Lucene等各个软件版本，环境配置比较复杂，因而基于Lucene提供的docker
image环境构建。</p>
<h3 id="lucene元素">Lucene元素</h3>
<p>使用Lucene之前，先来了解一些相关概念。</p>
<p>Directory：指定如何保存构建的索引，测试时常保存在内存中，实际应用中，一般将其保存在文件系统中，本例将索引保存在/tmp/a目录下。<br />
Analyzer：分析器，用于处理文本，如分词，去停用词等。<br />
IndexWriter：对索引进行增删查改的工具，一般的操作都围绕IndexWriter展开。<br />
Document：构造搜索的基本单位，一般是网页、文档、邮件等。<br />
Field：一个Document可能包含多个域Field，比如标题、正文、作者等。</p>
<h3 id="实例">实例</h3>
<p>下面介绍垂直搜索引擎的具体构建方法。</p>
<p>下载Lupyne源码</p>
<pre><code>$ git clone [https://github.com/coady/lupyne](https://github.com/coady/lupyne)   </code></pre>
<p>下载docker镜像（在Linux系统中运行） $ docker pull coady/pylucene #
约2.52G</p>
<p>运行镜像</p>
<pre><code>$ docker run --rm -v /exports:/exports --net=host -it coady/pylucene bash  </code></pre>
<p>启动docker时使用了--net=host，使docker内外使用相同端口号访问，-v将宿主机目录映射到镜像内部目录。</p>
<p>在镜像内安装支持软件</p>
<pre><code>$ cd /exports/xxx # 切换到lupyne源码所在目录  
$ python setup.py install  
$ pip install cherrypy  
$ pip install pytest  
$ pip install clients  
$ pip install jupyter # 供进一步开发使用  
$ pip install html2text # 解析html内容  </code></pre>
<p>运行jupyter开发环境：</p>
<pre><code>$ jupyter notebook --allow-root -y --no-browser --ip=0.0.0.0  </code></pre>
<p>在docker之外的浏览器中访问示例文件：<a
href="http://localhost:8888/notebooks/docs/examples.ipynb">http://localhost:8888/notebooks/docs/examples.ipynb</a>，其中对比使用lupyne封装与直接使用pylucene分别建立索引、查询、检索、排序和分组的不同代码，可直接运行。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ecbc9761ee35e37f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>读取目录下的网页内容，写入索引数据：</p>
<pre><code>import lucene  
from lupyne import engine  
from org.apache.lucene import analysis, document, index, queryparser, search, store  
import os  
import html2text  
  
def parse_html(root_dir, path, indexer, debug=False):  
    f = open(path,&quot;r&quot;)  
    content = f.read()  
    text = html2text.html2text(content)  
    strings = [i for i in text.split(&quot;\n&quot;) if len(i) &gt; 0]  
    for i in strings:  
        if debug:  
            print(len(strings), &quot;insert&quot;, i)  
        path = path.replace(root_dir, &quot;http://localhost:8080/&quot;)  
        indexer.add(content=i, path=path)  
    indexer.commit()  
  
def insert_dir(root_dir, book_dir):  
    html_dir = os.path.join(root_dir, book_dir)  
    for root, dirs, files in os.walk(html_dir):  
        for f in files:  
            if f.endswith(&quot;html&quot;) or f.endswith(&quot;htm&quot;):  
                path = os.path.join(root, f)  
                print(path)  
                parse_html(root_dir, path, indexer)  
                  
def search(keyword):  
    hits = indexer.search(keyword, field=&#39;content&#39;)  
    for hit in hits:  
        print(hit)  
  
if __name__ == &#39;__main__&#39;:  
    BOOK_ROOTDIR = &#39;/exports/books/contents/&#39; # 数据根目录，与Lucene中配置文件一致  
    assert lucene.getVMEnv() or lucene.initVM()  
    indexer = engine.Indexer(directory=&quot;/tmp/a/&quot;) # 数据存储目录  
    indexer.set(&#39;content&#39;, engine.Field.Text, stored=True)    
    indexer.set(&#39;path&#39;, engine.Field.Text, stored=True)    
    # 插入  
    insert_dir(BOOK_ROOTDIR, &#39;知识图谱/text&#39;)  
    # 搜索  
    search(&#39;Lucene&#39;)  
    indexer.close()  </code></pre>
<p>设置Lupyne的配置文件：</p>
<pre><code>[global]  
tools.staticdir.on=True  
tools.staticdir.dir=&#39;/exports/books/contents/&#39;  
tools.staticdir.section=&#39;&#39;  </code></pre>
<p>启动Lupyne服务</p>
<pre><code>$ python -m lupyne.server /tmp/a -c a.cfg  </code></pre>
<p>搜索：在浏览器打开 http://localhost:8080/search?q=content:lucene
如只取前三个使用：
http://localhost:8080/search?q=content:lucene&amp;count=3</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-27ecef6660867063.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>打开被搜索网页：
http://localhost:8080/知识图谱/text/part0013_split_006.html</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d7a08aac027ebced.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>此时，就实现了搜索本地网页的最简版本垂直搜索引擎，尽管网页还比较简陋。</p>
<h3 id="扩展">扩展</h3>
<p>Elasticsearch (ES)是一个开源的搜索引擎，建立在Lucene基础之上。
Lucene可能是目前存在的，不论开源还是私有的，拥有最先进，高性能和全功能搜索引擎功能的库。但是
Lucene
仅仅只是一个库，相对来说ES+Kibana更像是一套相对成熟的方案。它提供Web服务，客户端可通过Http请求或者API接口增删查改，它相对于Lupyne更复杂，功能也更多。当然无论使用何种底层库，都需要自己解释和插入数据。</p>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>知识图谱之WordNet</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E4%B9%8BWordNet/</url>
    <content><![CDATA[<h1 id="知识图谱之wordnet">知识图谱之WordNet</h1>
<p>#自然语言处理</p>
<h2 id="说明">1. 说明</h2>
<p> 今天讨论的是自然语言中的知识抽取和知识表示，换言之，就是如何从大量的书籍文献中剥离出我们关心的所谓“知识”，并将起组织保存成简单可用的描述。</p>
<p> 不同的知识类型需要采用不同的知识表示方式，温有奎教授总结了10种知识类型
（具体见参考部分）
。对于静态概念及概念之间关系用面向对象形式来表示，对命题型问题用一阶逻辑来表示，对于系统流程和实验流程等过程性知识用脚本表示法。</p>
<p> 静态概念是思维最基本的组成单元（以下简称基元），无论是命题还是流程，都离不开基元。我们应该把基元看作一种语义，而非一个单词。因为很多单词不具唯一性，常有一词多义，和一义多词的问题。</p>
<p> 再来看看基元之间的关系，比如：水果，苹果，红富士，它们可能指向同一物体，又可能不同；它们在一定程度上拥有共同属性，又拥有各自特征；基元相互之间又可能有类别的包含，近义，反义，整体与局部等各种关系……</p>
<p> 中文中的单词至少有几万个，这还不包括简单词组成的短语，如果有一个命题是“苹果是圆的”，那么是否也需要同时加入“红富士是圆的”，如果这样描述属性，恐怕是举不胜举了。而人类一般可以针对具体问题总结一些规则，并使用到类似的场景之中，即泛化。当我们在知识库中找不到“红富士”的描述特征时，我们可以参考它的父类“苹果”。</p>
<p> 泛化的基础是基元之间的关系，这种关系又如何表示呢？来看看WordNet。</p>
<h2 id="wordnet">2. WordNet</h2>
<p> WordNet是由Princeton
大学的心理学家，语言学家和计算机工程师联合设计的一种基于认知语言学的英语词典。它不是光把单词以字母顺序排列，而且按照单词的意义组成一个“单词的网络”。</p>
<p> 它是一个覆盖范围宽广的英语词汇语义网。名词，动词，形容词和副词各自被组织成一个同义词的网络，每个同义词集合都代表一个基本的语义概念，并且这些集合之间也由各种关系连接。</p>
<p> WordNet包含描述概念含义，一义多词，一词多义，类别归属，近义，反义等问题，访问以下网页，可使用wordnet的基本功能<br />
http://wordnetweb.princeton.edu/perl/webwn</p>
<p> 下面来看看具体用法</p>
<h2 id="安装">3. 安装</h2>
<p> wordnet是nltk（natural language
toolkit）的一个组件，因此需要先下载nltk</p>
<pre><code>$ sudo pip install nltk  </code></pre>
<p> 下载wordnet组件相关数据（python程序）</p>
<pre><code>import nltk  
nltk.download(&#39;wordnet&#39;)  </code></pre>
<h2 id="测试程序">4. 测试程序</h2>
<pre><code>from nltk.corpus import wordnet as wn  
print(wn.synsets(&#39;published&#39;))    #　打印publish的多个词义  
  
dog = wn.synset(&#39;dog.n.01&#39;)  #　狗的概念  
print(dog.hypernyms())　#　狗的父类（上位词）  
print(dog.hyponyms())　#　狗的子类（下位词）  </code></pre>
<h2 id="主要功能介绍">5. 主要功能介绍</h2>
<h4 id="上位词下位词">(1) 上位词/下位词</h4>
<pre><code>hypernyms() # 上位（父类）  
hyponyms() # 下位（子类）  </code></pre>
<h4 id="同义词反义词">(2) 同义词/反义词</h4>
<pre><code>lemma_names() # 同义  
antonyms() # 反义  </code></pre>
<h4 id="蕴涵关系">(3) 蕴涵关系</h4>
<pre><code>entailments()  </code></pre>
<h4 id="整体与部位">(4) 整体与部位</h4>
<pre><code>part_meronyms() # 部分  
substance_meronyms() # 实质  
member_holonyms() # 成员  </code></pre>
<h4 id="计算概念之间距离">(5) 计算概念之间距离</h4>
<pre><code>path_similarity()　#　相似度  
lowest_common_hypernyms() # 在何种层面相似  </code></pre>
<h2 id="一些思考">6. 一些思考</h2>
<p> Wordnet目前主要针对英文处理，想要使用它处理中文就需要构建中文的wordnet，把现有的知识加入该结构，其实也不需要从零做起，比如类别归属，同义，反义，通用的有“同义词词林”字典可供使用，在很多的专业领域，也有概念的类别及关系定义（如各种医学词典），只是格式有所不同。另外，还可以通过翻译，使用英文的WordNet的一部分数据，翻译过程中的问题主要是词汇的多义性，不过有些专有名词，歧义不大。</p>
<h2 id="参考">7. 参考</h2>
<h4 id="自然语言20.1-wordnet介绍和使用">(1) 自然语言20.1
WordNet介绍和使用</h4>
<p>https://www.cnblogs.com/webRobot/p/6094311.html</p>
<h4 id="基于-nlp的知识抽取系统架构研究">(2) 基于
NLP的知识抽取系统架构研究</h4>
<p>https://wenku.baidu.com/view/5370b50a763231126edb11c5.html</p>
<h4 id="基于知识元的文本知识标引">(3) 基于知识元的文本知识标引</h4>
<p>http://www.doc88.com/p-1816818922759.html</p>
<h4 id="python-自然语言处理五____wordnet">(4) python
自然语言处理（五）____WordNet</h4>
<p>https://www.cnblogs.com/no-tears-girl/p/6416765.html</p>
<h4 id="wordnet主页">(5) WordNet主页</h4>
<p>https://wordnet.princeton.edu/</p>
<h4 id="中文词汇网路chinese-wordnet">(6) 中文词汇网路(Chinese
Wordnet)</h4>
<p>http://openkg.cn/dataset/chinese-wordnet</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>自然语言处理——使用词向量（腾讯词向量）</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%EF%BC%88%E8%85%BE%E8%AE%AF%E8%AF%8D%E5%90%91%E9%87%8F%EF%BC%89/</url>
    <content><![CDATA[<h1
id="自然语言处理使用词向量腾讯词向量">自然语言处理——使用词向量（腾讯词向量）</h1>
<p>#自然语言处理</p>
<p>向量化是使用一套统一的标准打分，比如填写表格：年龄、性别、性格、学历、经验、资产列表，并逐项打分，分数范围[-1,1]，用一套分值代表一个人，就叫作向量化，虽然不能代表全部，但至少是个量度。因此，可以说，万物皆可向量化。</p>
<h3 id="词向量">词向量</h3>
<p>同理，词也可以向量化word2vec（word to
vector），可以从词性、感情色彩、程度等等方面量度，用一套分值代表一个词，从而词之间可以替换，比较。词与向量间的转换过程就叫作词的向量化。与人为评分不同的是，词向量一般通过训练生成，其每一维量度的作用也并不明确。词向量化常用于提取词的特征，提取后的特征再代入模型计算。</p>
<p>词向量如下图所示：</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-aadf36aa24a0730e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片出自https://jalammar.github.io/illustrated-word2vec/" />
<figcaption
aria-hidden="true">图片出自https://jalammar.github.io/illustrated-word2vec/</figcaption>
</figure>
<p>上图把每个单词映射到50个维度（用50种特征表示一个词），每个维度在[-1,1]范围内取值，上图中1为红色，0为白色，-1为蓝色，中间各值为过渡色，从图中可以直观看到词间的相似度。
获取了词向量之后，除了可以计算词间或句间相似度，查找近义词，代入模型以外，还可以做组合词义，以及排除某种含义，如下图所示：</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-22fabb8f71a4077a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="https://jalammar.github.io/illustrated-word2vec/" />
<figcaption
aria-hidden="true">https://jalammar.github.io/illustrated-word2vec/</figcaption>
</figure>
<h3 id="gensim">Gensim</h3>
<p>Gensim是一款常用的自然语言处理工具，提供Python三方工具包，常用于从文本中提取特征，提供TF-IDF，LSA，LDA，word2vec等功能。开发者可以用它训练自己的词向量，也可以使用他人训练好的词向量。</p>
<p>使用Gensim支持用数据训练词向量，网上例程很多。其原理是一种无监督学习，通过代入大量文章，根据各个词与其上下文关系，挖掘词义。一般自然语言处理的深度学习模型的第一层都是词向量化，因此，除了使用Gensim训练，还可以从其它模型中导出词向量。需要注意的是：高相似度表示两个词通常可以互换。并不一定是同义词，很多情况下，替换成反意词后句子也能读通，但含义完全不同。</p>
<h3 id="腾讯词向量">腾讯词向量</h3>
<p>腾讯词向量提供800多万中文词条，每个词条展开成200维向量，解压后16G。它使用Directional
Skip-Gram（Skip-Gram的改进版）训练而成，可使用Ginsim调用。相对于传统的同义词词林和词表，可以说非常先进了。它提供的是通常意义上的词义，但对于具体任务不是很完美。可从以下网址下载腾讯词向量：
<a
href="https://ai.tencent.com/ailab/nlp/embedding.html">https://ai.tencent.com/ailab/nlp/embedding.html</a>
下面是官方示例。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-f1ed8e56f0f4a42c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>那么何时选择腾讯词向量，何时又需要自己训练模型计算词向量？二者各有利弊，腾讯词向量体量大，速度慢，但涵盖的词和短语非常丰富，准确率也比较高。如果使用模型训练，则可针对某一目标训练，比如判别感情色彩时，某个词的表征和通常情况下的表征很可能有所不同，模型训练需要有足够的训练集，还要考虑模型支持词表（以字为单位还是以词为单位，如何分词），向量维度等等问题，难度更大，选择应视情况而定。</p>
<h3 id="示例">示例：</h3>
<h4 id="找近义词">找近义词</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from gensim.models import KeyedVectors  </span><br><span class="line">file = &#x27;/exports/nlp/Tencent_AILab_ChineseEmbedding.txt&#x27;  </span><br><span class="line">wv_from_text = KeyedVectors.load_word2vec_format(file, binary=False) # 加载时间比较长  </span><br><span class="line">wv_from_text.init_sims(replace=True)  </span><br><span class="line">word = &#x27;膝关节置换手术&#x27;  </span><br><span class="line">if word in wv_from_text.wv.vocab.keys():  </span><br><span class="line">    vec = wv_from_text[word]  </span><br><span class="line">    print(wv_from_text.most_similar(positive=[vec], topn=20))  </span><br><span class="line">else:  </span><br><span class="line">    print(&quot;没找到&quot;)  </span><br><span class="line">```  </span><br><span class="line">其运行结果如下图所示，看似比较合理。  </span><br><span class="line">  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/5357893-d80447ae070548b1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line">有一些专有名词或者短语，可能没收录在词库中，这种情况下可以使用先拆词，对其中各个词分别映射向量，然后取均值的方法计算。    </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 计算词距  </span><br><span class="line">这里指的距离，并不是近义词或者反义词，只是句中该处是否可被另一个词替换的可能性。  </span><br><span class="line">```  </span><br><span class="line">print(wv_from_text.distance(&quot;喜欢&quot;, &quot;讨厌&quot;)) # 0.299, 数越小越近  </span><br><span class="line">print(wv_from_text.distance(&quot;喜欢&quot;, &quot;爱&quot;)) # 0.295  </span><br><span class="line">print(wv_from_text.distance(&quot;喜欢&quot;, &quot;西瓜&quot;)) # 0.670  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 计算字串距离  </span><br><span class="line">通过余弦距离计算距离[[数学方法]]，结果为1时为正相关，为0时不相关，为-1时负相关。  </span><br><span class="line">```  </span><br><span class="line">print(wv_from_text.n_similarity([&#x27;风景&#x27;, &#x27;怡人&#x27;],[&#x27;山美&#x27;,&#x27;水美&#x27;])) # 0.60  </span><br><span class="line">print(wv_from_text.n_similarity([&#x27;风景&#x27;, &#x27;怡人&#x27;],[&#x27;上&#x27;,&#x27;厕所&#x27;])) # 0.43  </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>自然语言处理之_SentencePiece分词</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B9%8B_SentencePiece%E5%88%86%E8%AF%8D/</url>
    <content><![CDATA[<h1
id="自然语言处理之_sentencepiece分词">自然语言处理之_SentencePiece分词</h1>
<p>#自然语言处理</p>
<h2 id="说明">1、 说明</h2>
<p> SentencePiece是一个google开源的自然语言处理工具包。网上是这么描述它的：数据驱动、跨语言、高性能、轻量级——面向神经网络文本生成系统的无监督文本词条化工具。</p>
<p> 那么它究竟是干什么的呢？先举个例子：假设在数据挖掘时，有一列特征T是文本描述，我们需要将其转成枚举型，或者多个布尔型代入模型，即：需要从文本中提供信息构造新特征。</p>
<p> 首先，我们可以用标点将长句长分成短句，以短句作为关键词，看每个实例的特征T中是否包含该关键词，从而构造新的布尔型特征。但有时候表达同一个意思所使用的文本并不完全一致，比如“买三送一”和“买三送一啦！”是一个意思。</p>
<p> 此时，我们可以用SnowNLP或者jieba分词把描述拆成单个词，看T是否包括该关键词。但这样用也有一个问题：可能把一个意思拆成了多个特征，比如“袖子较短，领子较大”被拆成了四个独立的特征“袖子”“较短”“领子”“较大”，组合效果没有了。</p>
<p> 我们想要的效果是：如果“袖子较短”这个组合经常出现，就把它当成一个词处理。jieba中可以用自定义词典的方式加入已知的词。</p>
<p> 还有一些组合常常出现，但事先并不知道，于是我们想让机器自动学习经常组合出现的短语和词。SentencePiece就是来解决这个问题的。它需要大量文本来训练。</p>
<p> SentencePiece的用途不限于自然语言处理，记得DC之前有一个药物分子筛选的比赛，蛋白质的一级结构是氨基酸序列，需要研究氨基酸序列片断，片断的长度又是不固定的，此处就可以用SentencePiece进行切分。原理是重复出现次数多的片断，就认为是一个意群（词）。</p>
<h2 id="安装">2、 安装</h2>
<p> SentencePiece分为两部分：训练模型和使用模型，训练模型部分是用C语言实现的，可编成二进程程序执行，训练结果是生成一个model和一个词典文件。</p>
<p> 模型使用部分同时支持二进制程序和Python调用两种方式，训练完生成的词典数据是明文，可编辑，因此也可以用任何语言读取和使用。</p>
<h4 id="在ubuntu系统中安装python支持">1)
在Ubuntu系统中安装Python支持</h4>
<pre><code>$ sudo pip install SentencePiece  </code></pre>
<h4 id="下载源码">2) 下载源码</h4>
<pre><code>$ git clone https://github.com/google/sentencepiece  
$ cd sentencepiece  
$ ./autogen.sh  
$ ./confiture; make; sudo make install # 注意需要先安装autogen,automake等编译工具  </code></pre>
<h2 id="训练模型">3、 训练模型</h2>
<pre><code>$ spm_train --input=/tmp/a.txt --model_prefix=/tmp/test  
# --input指定需要训练的文本文件，--model_prefix指定训练好的模型名，本例中生成/tmp/test.model和/tmp/test.vocab两个文件，vocab是词典信息。  </code></pre>
<h2 id="使用模型">4、 使用模型</h2>
<h4 id="命令行调用">(1) 命令行调用</h4>
<pre><code>$ echo &quot;食材上不会有这样的纠结&quot; | spm_encode --model=/tmp/test.model  </code></pre>
<h4 id="python程序调用">(2) Python程序调用</h4>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sentencepiece <span class="im">as</span> spm  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>sp <span class="op">=</span> spm.SentencePieceProcessor()  </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">&quot;食材上不会有这样的纠结&quot;</span>   </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>sp.Load(<span class="st">&quot;/tmp/test.model&quot;</span>)   </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sp.EncodeAsPieces(text))  </span></code></pre></div>
<h2 id="使用技巧">5、 使用技巧</h2>
<p> 如果我们分析某个领域相关问题，可以用该领域的书籍和文档去训练模型。并不限于被分析的内容本身。训练数据越多，模型效果越好。更多参数及用法，请见git上的说明文件。</p>
<h2 id="参考">6、 参考</h2>
<h4 id="用法示例">(1) 用法示例</h4>
<p>https://pypi.org/project/sentencepiece/0.0.0/</p>
<h4 id="训练示例">(2) 训练示例</h4>
<p>https://github.com/google/sentencepiece#train-sentencepiece-model</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_BERT-wwm</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_BERT-wwm/</url>
    <content><![CDATA[<h2 id="介绍">1 介绍</h2>
<p>英文题目：Pre-Training with Whole Word Masking for Chinese BERT<br />
中文题目：中文BERT的全词掩码预训练<br />
论文地址：https://arxiv.org/pdf/1906.08101.pdf<br />
领域：自然语言处理<br />
发表时间：2019<br />
作者：Yiming Cui，社会计算和信息检索研究中心，哈工大，讯飞<br />
出处：第二届“讯飞杯”中文机器阅读理解评测，CMRC 2018<br />
被引量：255<br />
代码和数据：https://github.com/ymcui/Chinese-BERT-wwm<br />
阅读时间：2022.05.10</p>
<h2 id="读后感">2 读后感</h2>
<p>中文和英文不同，一般通过词而非字来表意，而分词也有难度，BERT以字单位建模，这样损失了词义。文中将之前用于英文的<strong>全词MASK方法</strong>应用于中文，文中没什么公式，原理也简单，但对中文确实是一个重要的方法，该模型也被广泛使用。</p>
<h2 id="介绍-1">3 介绍</h2>
<p>BERT(2019)利用Transformer，未标注的数据，综合上下文信息，使模型达到很好效果，之后，<strong>BERT的作者又提出升级版WWM</strong>，它利用全词MASK进一步提升BERT效果，本文将WWM方法应用于中文。用中文词作MASK以替代字为单位。如图-1所示，它同时遮蔽了来源于一个词的所有字：<br />
<img src="/attachments_2022/Pasted%20image%2020220510085605.png"
alt="Pasted%20image%2020220510085605.png" /></p>
<p>文中模型利用<strong>简体和繁体</strong>语料训练，在多种任务及不同规模模型实验中表现出很好效果。</p>
<p>文章贡献如下：<br />
* 提出了<strong>中文全词遮蔽</strong>的预训练模型<br />
* 实验证明了模型的先进性<br />
* 提出了一些使用该模型的技巧</p>
<h2 id="方法">4 方法</h2>
<p>使用与之前方法相同的数据和参数训练模型。</p>
<p>下载最新的<strong>Wikipedia</strong>，清洗（去掉HTML标记）后，约13.6M行，在分词方面，使用<strong>LPT（哈工大分词模型）实现中文分词</strong>（Chinese
Word Segmentation
：CWS），在训练时长度分别设为128和512，以支持长文。</p>
<p>模型基于中文的BERT模型训练，使用TensorFlow框架，在 Google Cloud TPU
v3 with 128G HBM上训练（模型参数见论文2.3节）。</p>
<p>对于下游任务也没做改动，只把基本模型换成了文中模型。下游任务包括：阅读理解
（MRC），自然语言推理（NLI），句子分类（SC），句子对匹配（SPM），文档分类（DC）。</p>
<h2 id="实验">5 实验</h2>
<p>实验数据集如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220510091103.png"
alt="Pasted%20image%2020220510091103.png" /></p>
<p>将文中模型与BERT，ERNIE对比：<br />
<img src="/attachments_2022/Pasted%20image%2020220510091236.png"
alt="Pasted%20image%2020220510091236.png" /></p>
<p>实验效果表太多，简单贴一个看看：<br />
<img src="/attachments_2022/Pasted%20image%2020220510091921.png"
alt="Pasted%20image%2020220510091921.png" /><br />
BERT-wwm-ext 相对 BERT-wwm 主要有两点改进：<br />
增加预训练数据集，<strong>达到5.4B</strong>；<br />
训练步数增大，第一阶段1M步，第二阶段400K步。</p>
<h2 id="技巧">6 技巧</h2>
<ul>
<li>初始化学习率是最重要的超参数。<br />
</li>
<li>BERT和BERT-WWM共享几乎相同的最佳初始学习率，但与ERNIE不同。<br />
</li>
<li><strong>BERT和BERT-wwm使用维基百科训练，它对正式文本效果更好；而ERNIE使用更大规模数据训练，它对较随意的文本效果也好</strong>。<br />
</li>
<li><strong>在长文本任务中（如阅读理解，文档分类）建议使用BERT或BERT-wwm</strong>。<br />
</li>
<li>如果任务与预训练数据差异大，建议使用其它预训练模型。<br />
</li>
<li>如果希望在性能上有进一步的提升，建议训练自己的模型，如果无法训练，则可选择使用下游任务精调。<br />
</li>
<li><strong>对于繁体中文，建立使用BERT或BERT-wwm（ERNIE在训练时去掉了繁体数据）</strong>。</li>
</ul>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读：BiLSTM-CRF实现序列标注</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_BiLSTM-CRF%E5%AE%9E%E7%8E%B0%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8/</url>
    <content><![CDATA[<h1
id="论文阅读bilstm-crf实现序列标注">论文阅读：BiLSTM-CRF实现序列标注</h1>
<p>论文名称：《Bidirectional LSTM-CRF Models for Sequence
Tagging》<br />
论文地址：<a
href="https://arxiv.org/pdf/1508.01991v1.pdf">https://arxiv.org/pdf/1508.01991v1.pdf</a><br />
相关代码：<a
href="https://github.com/BrikerMan/Kashgari">https://github.com/BrikerMan/Kashgari</a>（Keras）</p>
<p>《Bidirectional LSTM-CRF Models for Sequence Tagging》是Baidu
Research在2015年发表的一篇论文，它使用双向长短期记忆网络LSTM加条件随机场CRF的方式解决文本标注的问题。该方法至今仍是命名实体识别的主流方法之一。</p>
<p>之前一直不理解的是RNN、LSTM、CRF、HMM都可以单独实现文本标注，为什么要将LSTM和CRF结合起来？本文就来看看它是如何实现的。文后结合命名实体识别NER，展示了它的具体使用方法。</p>
<p>文本标注用途非常广泛，不仅标注切分，还可以通过标注拆分出关键信息，供下游应用使用。在该文发表之前，实现文本标注常用的方法有线性统计模型，比如隐马尔可夫模型HMM、最大熵马尔可夫模型MEMM、条件随机场CRF；卷积网络、卷积网络与CRF相结合的方式；以及循环神经网RNN。</p>
<p>文中对比了长短期记忆网络LSTM，双向长短期记忆网络Bi-LSTM，以及Bi-LSTM+CRF处理自然语言标注。论文的主要贡献是：(1)系统地对比了上述三种模型在各数据集上的效果；(2)LSTM模型更好地利用了文本上下文中的信息，CRF处理标签之间的关系，二者结合较之前模型效果更佳；(3)相较于之前模型，从上下文中获取了更多信息，从而减小了对词向量的依赖。</p>
<h2 id="模型原理">模型原理</h2>
<p>在模型原理部分，文中介绍了从RNN到CRF各个模型，以及LSTM+CRF结合的原理。</p>
<h4 id="rnn">RNN</h4>
<p>论文中对循环RNN在命名实体识别NER上的应用描述非常清晰到位，简单翻译如下：</p>
<p>下图描绘了RNN结构，它由输入层x，隐藏层h和输出层y组成。在命名实体识别问题中，x是输入文本，y是输出标签。模型给输入文本中的每个词做标注。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-cd12225b5847067d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>命名实体识别常用BIO标法和BIOES标法，其中B-begin表示开始，I-inside表示内部，O-outside表示非实体，E-end表示实体尾部，S-single表示该词本身就是一个实体。文中使用BIO标注，其中EU是ORG组织型实体，rejects非实体，German为Miscellaneous型实体，call非实体。</p>
<p>输入文本数据时还需要进行一些处理，比如提取词向量，one-hot变量，或提取其它统计特征（图中忽略此步骤），作为x输入，输出y是该词对应各个类别的概率。每个词一般称作一个时间点t。</p>
<p>RNN计算公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a368de12be42e6e9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中t时刻隐藏层的值h(t)，由前一个隐藏层的值h(t-1)和该时刻的输入x(t)计算得出；t时刻输出值y(t)，由当前隐藏层h(t)计算得出，U,W,V是模型参数，通过调参得到；公式中f和g是激活函数。</p>
<h4 id="lstm与bi-lstm">LSTM与Bi-LSTM</h4>
<p>LSTM是RNN的加强版，主要解决RNN对距离较远文本之间关联较差的问题；文中虽然给出了原理图和公式，但对于之前没有学习过LSTM的读者来说，还是无法理解，此处略过，将其看成升级版RNN即可。Bi-LSTM是双向LSTM，它同时关注前文和后文对标注的影响，如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-95dd18d13d12aa40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="crf">CRF</h4>
<p>条件随机场CRF是从隐马尔可夫模型HMM以及最大熵马尔可夫模型MEMM进化而来的。论文中只做了一些简要的介绍，下面以命名实体识别为例，引入一些CRF相关原理。</p>
<p>比如标注“EU rejects German call”，
文本输入记作X(x1,x2,x3,x4)；它的标签为“B-ORG, O, B-MISC,
O”，即输出为y(y1,y2,y3,y4)，通过N组数据训练出模型，最终目标是输入任意文字，模型可输出标注信息。计算yi的具体方法是：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d3195915bebd879b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>Yv是由所有位置的文本X，以及除位置v外其它位置的Y决定的（前后标签都可以用）；比如上例中标签y2（O）是由词序列X“EU
rejects German
call”这四个词的词义及其位置，以及除y2外其它位置的词性Y“B-ORG,  ?,
 B-MISC,  O”计算得出的。</p>
<p>其中序列X和Y内部的规律可以理解成图结构，它们由点V(标签)和连接各点的边E(标签间相互关系)组成。1971年提出的随机场的理论，给定条件X下标签Y的联合分布为：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-b318a570133c077c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中g可理解为X映射到Y的规则，比如X“EU”一般是“B-ORG”。而f是相邻Y之间的关系，比如一般两个动词不会接连出现。计算的目标是调节模型参数θ（包括λ和μ），使在X的条件下最可能计算出Y。</p>
<p>相比之前模型，CRF计算整个标记序列的联合概率分布，而不是在给定当前状态条件下，定义下一个状态的状态分布，但CRF的参数也更多，训练量更大，复杂度更高。</p>
<p>综上，与LSTM相比，CRF的优势是考虑了标签间的关系。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-61839dfc2e3f55b0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="lstm-crf">LSTM-CRF</h4>
<p>LSTM-CRF结合了上述两种模型。CRF将状态转移矩阵作为参数，并使用之前和之后的标签预测当前标签。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-8a4731f26154b2c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>如图所示，从下到上依次是：文本数据输入LSTM网络，再传入上层的CRF网络，最终生成标注数据。具体从公式可见：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-1e8f6be87aea3cef.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>（个人认为上述公式中的+不是指矩阵加法，而是同时考虑两种逻辑）</p>
<p>输出根据各时点的输入词x，标签i（后面具体解释），以及模型的参数θ决定；具体计算方法是对于每个时点t（每个单词），计算LSTM的f和CRF的A。</p>
<p>其中的f是LSTM的输出，它是一个矩阵，其中包含LSTM模型计算出的每一个单词，对应每一个标签的概率，如果标签个数为L，LSTM输出的矩阵大小为L×T，每点存储一个概率值。转移评分A是从前一个标签到后一个标签的转移概率，如果标签种类为L，则转移矩阵的大小为LxL。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-27e850df6af78829.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>具体讲，上图中的圆点是LSTM的输出f，即每一个字是各种标签的概率，颜色越深表示可能性越大，图中的连线是A，它描述了从前一种标签到后一种标签转换概率，比如B-MISC之后更可能是O而不是其它的B-MISC。综合二者，最终得到了得分最高的橙色路径。</p>
<p>CRF的连接方式和调参方式也类似神经网络。整个网络也是先向前传播LSTM-&gt;CRF-&gt;loss，再反向传播调参。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-8b575e5b857841a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>当前更加流行的实现是BERT+Bi-LSTM+CRF，使用BERT提取的词向量，LSTM+CRF结合的标注算法。</p>
<h2 id="实战">实战</h2>
<p>下面来看看具体的实现方法，Kashgari是一种工业化的命名实体识别解决方案，github加星1.9K，其中支持多种NER方法，也包含论文中介绍的LSTM+CRF，来自github的介绍如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5027ec6b0aee8853.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>建议阅读代码，以便更好理解具体实现。</p>
<p>下载源码：</p>
<pre class="shell"><code>$ git clone [https://github.com/BrikerMan/Kashgari](https://github.com/BrikerMan/Kashgari)  </code></pre>
<p>下载环境docker镜像：</p>
<pre class="shell"><code>$ docker pull tensorflow/tensorflow:2.3.1-gpu-jupyter  </code></pre>
<p>目前最高版本tensorflow+gpu+jupyters，其python版本3.6.9</p>
<p>启动镜像：</p>
<pre class="shell"><code>$ nvidia-docker run -d -p 8894:8888 -v/raid/xieyan/2020:/tf/2020/ tensorflow/tensorflow: 2.3.1-gpu-jupyter  </code></pre>
<p>进docker之后，安装Kashgari（先编辑一下pip.conf，下载比较快）</p>
<pre class="shell"><code>$ cd Kashgari下载目录  
$ pip install -r requirements.txt  
$ python setup.py install  </code></pre>
<h2 id="参考">参考</h2>
<p><a
href="https://www.jianshu.com/p/1d6689851622">五分钟搭建一个基于BERT的NER模型</a></p>
<p><a
href="https://github.com/bojone/albert_zh">Albert模型国内下载地址（下载tiny版本即可）</a></p>
<p><a href="https://eliyar.biz/nlp_chinese_bert_ner/">效果评测</a></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_KnowPrompt</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_KnowPrompt%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96/</url>
    <content><![CDATA[<h1 id="读后感">读后感</h1>
<ul>
<li>针对问题：few-shot场景下从文本中抽取关系（知识检索、对话、问答）。<br />
</li>
<li>结果：在5个数据集，及少量标注情况下，测试效果优于之前模型<br />
</li>
<li>核心方法：希望在pretrain后不再fine-tuning，于是引入了提示prompt，<strong>通过构建提问（提问方法/答案范围）来实现类似tuning的效果</strong>。<br />
</li>
<li>难点：之前对知识抽取和提示学习都不太了解；后来读了代码才了解，文中指的知识不是来自外界引入，而是<strong>将词嵌入作为知识</strong>。<br />
</li>
<li>泛读后理解程度：60%<br />
（看完题目、摘要、结论、图表及小标题）</li>
</ul>
<p><strong><em>围绕句子的逻辑，利用之前定义好的模板提问，回答</em></strong></p>
<h1 id="基于知识的提示学习knowprompt">基于知识的提示学习KnowPrompt</h1>
<p>英文题目：KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic
Optimizationfor Relation Extraction<br />
中文题目：KnowPrompt:
基于协同优化的知识感知快速调优<strong>关系提取</strong><br />
论文地址：https://arxiv.org/pdf/2104.07650.pdf<br />
领域：自然语言处理，关系提取<br />
发表时间：2021<br />
作者：Xiang Chen（浙江大学&amp;阿里巴巴）<br />
出处：TheWebConf(WWW)<br />
被引量：13<br />
代码和数据：https://github.com/zjunlp/KnowPrompt<br />
阅读时间：2022.04.15</p>
<h1 id="精读">精读</h1>
<h2 id="摘要">摘要</h2>
<p>最近，<strong>提示调优</strong>(Prompt-tuning)在一些few-shot分类任务中取得了令人满意的结果。它的核心思想是通过插入文本，将分类任务转化为MASK语言模型（MASK原理详见BERT）。对于关系抽取问题，选择提示模板需要较多的领域知识和较大工作量，且在实体和边之间蕴藏的大量知识也不应该被忽略。文中提出了一种<strong>基于知识协同优化的调优方法(KnowPrompt)</strong>。通过学习<strong>模板词</strong>和<strong>答案词</strong>，将实体和关系的知识注入模型，并在知识约束下协同优化它们的表示。</p>
<h2 id="介绍">1. 介绍</h2>
<p>关系抽取(RE)是文件抽取中的一个重要任务，抽取后的信息可供更多下游NLP任务使用，比如：信息检索、对话生成和问答。</p>
<p>之前自监督的自然语言模型（PLM）如BERT，它可以学习到带有上下文的表征，在很多RE任务中表现很好，而精调(fine-tuning)需要在模型顶部加层并需要额外的训练。它的效果依赖于耗时费力的大量标注，且不容易泛化到其它任务中。为解决此问题，出现了prompt-tuning：使用预训练的语言模型作为预测器实现完型填空任务。它在few-shot任务中表现良好。如图-1所示：</p>
<p><img src="/attachments_2022/Pasted%20image%2020220416135611.png"
alt="Pasted%20image%2020220416135611.png" /><br />
* 模型的原始输入是“Hamilton is the first British champion”<br />
* 模型在原始输入后，加了一个模板"Mamilton [MASK]
British"，同时给定了一组标签词“country,city,residenct...”作为MASK的可选项<br />
（Hamilton可能是人名，也可能是品牌）<br />
*
模型将原始输入和模板作为条件，预测MASK为某选项的概率，从而抽取模板中主语Hamilton和宾语British的关系。</p>
<p>总之，Prompt-tuning的目标是找到合适的模板和答案空间。而此工作常需要领域知识，以及复杂而大量的计算。而且关系标签不一定能在词典中找到合适的词。另外，实体、关系、三元组中包含的词义也不应被忽略，如图-1的例子中，如果主语和宾语都是人，则"org:city_of_headquters"就不太可能成立。相对的，关系也可以约束主语和宾语的类型。</p>
<p>文中提出的解决方法是：先将知识注入提示，然后用提示调优模型实现知识抽取。具体方法是使用学习“虚拟模板词”和“虚拟答案词”。具体的方法是：使用集合实体嵌入初始化的实体周围的类型标记，作为可学习的虚拟模板词来注入实体类型知识。同时使用标签计算平均嵌入作为虚拟答案来注入关系知识。在这个结构中，实体和关系相互约束，虚拟词需要与上下文保持一致性，文中引入了协同优化来校正模板和答案词。</p>
<p>文章主要贡献如下：</p>
<ul>
<li>提出了知识提示（KnowPrompt）方法，将知识注中提示模板的设计和答案构建，以解决关系抽取问题。<br />
</li>
<li>使用知识约束，联合优化提示模板和带有答案的表示。第一次提出在连续空间内，联合优化提示模板和答案。<br />
</li>
<li>在五个RE基准数据集上实验表明，KnowPrompt在标准和低资源环境下都是有效的。</li>
</ul>
<h2 id="相关工作">2. 相关工作</h2>
<h3 id="知识抽取">2.1 知识抽取</h3>
<p>知识抽取，早期使用基于模式的方法，基于CNN/RNN的方法，以及基于图的方法，后来，将预训练语言模型作为基础的知识提取成为主流，尤其是基于BERT的模型显示出比之前模型更好的效果。最近Xue等提出的基出BERT的多视图方法达到了目前最高水平。由于标注的限制，few-shot任务受到关注。</p>
<h3 id="提示学习">2.2 提示学习</h3>
<p>提示学习方法源于GPT-3（2020年），其在很多NLP任务中达到更好的效果。有些研究基于人工构建提示；2021年Hu提出引入外部知识；2021年Ding使用实体类型学习，来构建面向实体的词生成器和模板；为避免大量的人工构建提示，2020年Gao等首次提出了自动构建模板和答案词，Shin又进一步提出了梯度自动搜索，来自动生成模板和打标签。最近，有人直接利用可学习的连续嵌入作为提示模板。</p>
<p>在知识抽取方面，2021年Han提出PTR，使用逻辑规则构建子提示。本文中方法的先进性在于：使用知识注入方法，学习虚拟模板和模拟答案来代替人工定义规则，可以泛化到多种任务之中。另外，使用知识约束协同优化模板和答案词，使嵌入相互关联。</p>
<h2 id="背景知识">3. 背景知识</h2>
<p>定义D={X,Y}，X是实例（句子），Y是关系标签，每个实例由词组成：x={w1,w2,ws...wo...wn}，RE的目标是预测主语ws与宾语wo之间的关系y
∈ Y。</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220416154625.png"
alt="Pasted%20image%2020220416154625.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220416154625.png</figcaption>
</figure>
<h3 id="精调语言模型">3.1 精调语言模型</h3>
<p>预训练的自然语言模型是L，之前的fine-tuning模型将x作为模型的输入，加入类别[CLS]和分隔符[SEP]，见图-2(a)，其输出是隐藏层h，最后用h预测该实例属于各个类别CLS的概率，使用交叉熵作为多分类的损失函数，在训练过程中自然语言模型参数L和用于最终分类的参数W被训练。</p>
<h3 id="提示调优语言模型">3.2 提示调优语言模型</h3>
<p>提示调优的目标是在预测模型和下游任务间建立桥梁，主要挑战是如何建立问题模板T(.)和可选答案标签V，将它们统称为提示P。对于每个实例x，模型构建它新的输入：xprompt=T(x)。它一般包含原始文本和附加文本；V使用自然语言模型L词表中词作为标签，定义M：Y-&gt;V作为注入映射表，连接任务标签Y（最终抽取的关系）和标签词V（用于回答提示问题）。</p>
<p>在保留了原有文本x的基础上，遮蔽(MASK)了xprompt中的一个或几个词，并用标签词替换，用模型L预测遮蔽位置的词，p用于描述V在MASK处的分布：<br />
<span
class="math display">\[p(y|x)=p([MASK]=M(y)|x_{prompt})\]</span><br />
如图-2(b)所示，在原始文本后又加了一段带有MASK的文本，此时，可以通过模型L计算MASK对应的向量，并计算概率分布p，用于描述V中各个可选项对于MASK位置的匹配程度，M映射对于两个可选项分别有：M(y
= “per :data_of_birth”) →
“birth”（当y分类per:data_of_birth，V是birth），M(y = “org :founded_by”)
→“founder”（当y为org:founded_by，V为founder），然后判定哪个选项更合适。</p>
<h2 id="方法">4. 方法</h2>
<p>此部分主要介绍KnowPrompt协同优化方法的实现，将实体类型和关系标签中的知识用于关系提取。4.1阐述构建方法，4.2阐述优化方法。</p>
<h3 id="利用知识注入构建提示">4.1 利用知识注入构建提示</h3>
<p>典型的提示包括两部分：构建模板和答案集。本文目标是利用知识注入构建虚拟模板词和模拟答案词，以实现知识抽取任务。</p>
<h4 id="实体知识注入">实体知识注入</h4>
<p>2021年Zhou提出了实体类型标注，他在实体前后加入了特征的标记[E]和[/E]，详见图-2(a)，这一技术在关系抽取中得到广泛使用。它用实体的类别信息提升模型效果，但是需要对类型进行额外的标注。然而，我们可以利用关系对实体的限制得到主语和宾语的大概范围，比如：当关系是““per:country_of_birth”时，主语是人，宾语是国家。此时可以得到主语和宾语候选集合Csub={"person","organization",...}和Cobj={"organization","data",...}，及其中元素的分布φsub
和φobj。</p>
<p>如图-2所示，用可学习的连续数据来描述实体类别，具体来说，是利用加权平均实体类型作为嵌入来初始化虚拟模板词：<br />
<img src="/attachments_2022/Pasted%20image%2020220416164748.png"
alt="Pasted%20image%2020220416164748.png" /><br />
式中的e<sup>sub和e</sup>obj也是嵌入，用于描述主语和宾语的类型（它不是一种具体的类型，而是一种综合类型，因此是虚拟的），它被插入到主语和宾语的前后（图-2中绿色框），而e()从语言模型的词嵌入层提取词嵌入。使用上述方法可以从知识中自动学习更丰富的实体类型，其效果与之前方法差不多，但不需要额外标注。</p>
<p>简言之，这里的模板，就是后加的那半句话，需要分别确定其 主语 和 谓语
的类型，而通过 谓语 可以大概估计出主语和宾语是什么类型。</p>
<h4 id="关系知识注入">关系知识注入</h4>
<p>之前提示调优的研究主要是构建标签词和任务标签的一对一映射表，它不能表达关系标签中丰富的语义知识。我们设置虚拟答案词
v′∈V′，它能表达关系的语义，在模型L之后再加一层，用于学习关系嵌入，用虚拟答案集V'完全表示关系标签Y。用p(y|x)来表示V'在MASK位置的分布。</p>
<p>和实体类型嵌入类似，使用Crel来表示可能的关系集合，φrel表示其中各项的概率分布。通过对关系类型的分解，在关系语义词的候选集Crel上设置了概率分布φRel。具体方法是，计算关系中每个token的加权平均作为初始化嵌入，以此注入语义信息。比如：y1
=per : countries_of_residence，集合Crel1 = {“person”,“countries”,
“residence” }，具体方法如下：。<br />
<img src="/attachments_2022/Pasted%20image%2020220416173528.png"
alt="Pasted%20image%2020220416173528.png" /></p>
<h3 id="使用知识约束实现协同优化">4.2 使用知识约束实现协同优化</h3>
<p>实体类型和关系标签之间存在着丰富的交互和联系，且这些虚拟模板词和答案词应该与周围的上下文相关联。因此进一步协同优化虚拟模板词和虚拟答案词的参数集：<br />
<img src="/attachments_2022/Pasted%20image%2020220416180024.png"
alt="Pasted%20image%2020220416180024.png" /></p>
<h4 id="根据上下文校准提示">根据上下文校准提示</h4>
<p>尽管模拟模型和答案都基于语义信息初始化，但是它们可能不是最优的，且与上下文相关。因此，可用上下文进一步优化其表征。通过计算真实关系y和p(y|x)之间的交叉熵的损失函数来优化虚拟模板词和答案词，如下所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220416180742.png"
alt="Pasted%20image%2020220416180742.png" /><br />
此处的|X|是训练集中的实例个数，可学习的连续表征可以通过模板和答案的协同优化，自适应地学习最优表征。</p>
<p>简言之，就是通过预测的关系和真实的关系计算损失优化模型。</p>
<h4 id="隐含的结构约束">隐含的结构约束</h4>
<p>为注入结构信息，我们采用了知识嵌入(KE)目标函数作为约束。使用三元组
(s,r,o)
描述关系，s,o描述主和宾的类别，r是预定义的答案V‘的关系标签。我们直接用虚拟模板和虚拟答案输出的嵌入通过语言模型参与计算。损失函数定义如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220416182217.png"
alt="Pasted%20image%2020220416182217.png" /><br />
带'的是负例；γ是边界；dr用于衡量头实体尾实体及关系（算法同TransE），三元组成立时其值趋于0，不成立时其值较大；n表示所有负采样。负采样时，使用正确的答案填充MASK位置，随机取主语和宾语，替换为不相关的类型以构造损坏的三元组。（这里更多细节请见代码）</p>
<p>y=-log(sigmoid(x))如下图所示：</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220416185125.png"
alt="Pasted%20image%2020220416185125.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220416185125.png</figcaption>
</figure>
<p>括号里的值越大，最终损失函数越小；对于正例，d相对边界值γ越小越好，对于负例，d相对γ越大越好。</p>
<h3 id="训练细节">4.3 训练细节</h3>
<p>训练分为两个阶段，第一阶段使用大学习率协同优化虚拟模板词和模拟答案词：<br />
<img src="/attachments_2022/Pasted%20image%2020220416190031.png"
alt="Pasted%20image%2020220416190031.png" /><br />
其中 λ是用于权衡两个损失函数的超参数。<br />
第二阶段基于被优化的虚拟模板词和模拟答案词，仅利用J[MASK]损失函数为语言模型调参，用较小的学习率优化所有参数。</p>
<h2 id="实验">5. 实验</h2>
<h3 id="数据集">5.1 数据集</h3>
<p>为全面测试，使用了表-1中列出的5个数据集<br />
<img src="/attachments_2022/Pasted%20image%2020220416192059.png"
alt="Pasted%20image%2020220416192059.png" /></p>
<h3 id="实验设置">5.2 实验设置</h3>
<p>使用BERT_LARGE作为基础模型。</p>
<h4 id="基本配置">基本配置</h4>
<p>使用全部训练数据训练，与之前的四个模型对比。</p>
<h4 id="低资源配置">低资源配置</h4>
<p>使用LM-BFF提出的 8-, 16-, 32-
(n为每种类别的样例个数)方法采样，从初始训练和验证集中抽取每个类的k个实例，以形成few-shot的训练和验证集。</p>
<h3 id="实验结果">5.3 实验结果</h3>
<h4 id="基本配置-1">基本配置</h4>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220416194220.png"
alt="Pasted%20image%2020220416194220.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220416194220.png</figcaption>
</figure>
<h4 id="低资源配置-1">低资源配置</h4>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220416194454.png"
alt="Pasted%20image%2020220416194454.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220416194454.png</figcaption>
</figure>
<p>可以看到，样例越少，KnowPrompt相对其它模型效果越好。</p>
<h3 id="消融研究">5.4 消融研究</h3>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220416194858.png"
alt="Pasted%20image%2020220416194858.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220416194858.png</figcaption>
</figure>
<h1 id="代码解析">代码解析</h1>
<h3 id="数据">数据</h3>
<p>dataset/*<br />
*
代码中包含五个数据集的数据，分为两种格式，dialogue为对话数据；其它数据格式均为同一种<br />
*
数据集包含几千到几万条训练数据不等，除dialogure外的其它数据模式为：每条数据包含一个原始字符串，和一个头实体、尾实体、关系的三元组，用于训练和评测模型。<br />
*
每个数据目标下都包含rel2id.json文件，它定义了可被抽取的关系及其对应id，可以看到，“答案”(或称标签)是有限的。</p>
<h3 id="代码">代码</h3>
<ul>
<li>data/* 用于解析数据<br />
</li>
<li>dataset/* 供训练和测试的数据<br />
</li>
<li>scripts/* 训练各种模型使用的示例脚本<br />
</li>
<li>models/* 各种底层的预训练模型<br />
</li>
<li>lit_models/* 核心函数
<ul>
<li>lit_models/transformer.py 文中模型的具体实现
<ul>
<li>_init_label_word(), 140行，初始化各种权重<br />
</li>
<li>training_step()，185 行，主要流程<br />
</li>
<li>ke_loss()，262行<br />
上述几个函数几乎实现了文中所有公式</li>
</ul></li>
</ul></li>
</ul>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>关系抽取</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_中文命名实体识别 Lattice LSTM</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E4%B8%AD%E6%96%87%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%20Lattice%20LSTM/</url>
    <content><![CDATA[<p>论文题目：Chinese NER Using Lattice LSTM<br />
论文地址：<a
href="%5Bhttps://arxiv.org/pdf/1805.02023.pdf%5D">https://arxiv.org/pdf/1805.02023.pdf</a><br />
相关源码：<a
href="https://github.com/jiesutd/LatticeLSTM">https://github.com/jiesutd/LatticeLSTM</a>
约1.5K Star<br />
中文翻译：<a
href="https://blog.csdn.net/u014475479/article/details/81137671">中文实体抽取（NER）论文笔记</a><br />
中文翻译2：<a href="https://zhuanlan.zhihu.com/p/42414521">ChineseNER
Using LatticeLSTM笔记</a></p>
<h2 id="读后感">读后感</h2>
<p>优化中文的命名实体识别，加入了对中文词的支持</p>
<h2 id="介绍">介绍</h2>
<p>这是一篇2018年发表于 ACL（自然语言处理顶会）
的论文，文中提出了一种基于格子（Lattice）结构的LSTM模型，用于优化中文的命名实体识别。具体方法结合了字序列和词序列两种方式（考虑可能出现的各种分词情况）。相对于基于"字序列”的方法，模型能兼顾词间关系；相对于”词序列“的方法，模型不受分词错误的影响。门控单元让模型选择最为相关的字和词以实现实体识别。</p>
<p>近年来英文命名实体识别（NER）常用LSTM-CRF方法实现。中文的NER直觉上似乎应该是先做分词，再进行实体识别。然而由于跨界领域的分词问题难以解决，所以中文以字符为单位的NER往往优于以词为单位的NER。</p>
<h2 id="模型">模型</h2>
<p>定义t(i,k)，其中i是词的位置，k是在词中字的位置，如“南京市
长江大桥”中，t(2,1)是“长”，t(1,3)是“市”。<br />
<img
src="https://upload-images.jianshu.io/upload_images/5357893-a9252106910bd927.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="基于字符的模型">4.1 基于字符的模型</h4>
<p><strong>基础方法</strong><br />
如图3-a所示，其中<span
class="math display">\[x_j^c=e^c(c_j)\]</span><br />
e是通过查表得到的字符c的词嵌入。<br />
双向的lstm从前后两个方向分别计算隐藏层，得到两组参数<br />
<span class="math display">\[ h_j^c=[\overrightarrow{h_j^c};
\overleftarrow{h_j^c}]\]</span><br />
隐藏层的输出最终代入CRF模型。</p>
<p><strong>Char + bichar</strong><br />
与基础方法不同的是，除了当前字符外，还考虑了下一字符，<span
class="math inline">\(e^b\)</span>用于查询双字对应的词嵌入。<br />
<span
class="math display">\[x_j^c=[e^c(c_j);e^b(c_j,c_j+1)]\]</span><br />
<strong>Char + softword</strong><br />
将分段方法作为标签与词嵌入相连接，并作为软特征代入模型。<span
class="math inline">\(e^s\)</span>用于查询分词标记的嵌入。也使用双向的LSTM，最终将隐藏层代入CRF模型。<br />
<span class="math display">\[x_j^c=[e^c(c_j);e^s(seg(c_j))]\]</span></p>
<h4 id="基于词的模型">4.2 基于词的模型</h4>
<p><strong>基础方法</strong><br />
基于词的模型结构如图3-b所示，<br />
<span class="math display">\[x_i^w=e^w(w_i)\]</span><br />
其中<span
class="math inline">\(e^w\)</span>用于词嵌入查询，双向的lstm最终也生成了两个方向的隐藏层。</p>
<p><strong>Word + char LSTM</strong><br />
将词嵌入和字符嵌入结合在一起：<br />
<span class="math display">\[x_i^w=[e^w(w_i);x_i^c]\]</span><br />
其中<span
class="math inline">\(x_i^c\)</span>表征了词i包含所有的字符嵌入，通过以下公式计算：<br />
<span class="math display">\[x_i^c=[\overrightarrow{h_{t(i,len(i))}^c};
\overleftarrow{h_{t(i,1)}^c}]\]</span><br />
使用双向LSTM，学习隐藏层（我理解：由于LSTM计算的是一个序列，所以从左向右的最后一个就能代表整个串，同右向左的的1能代表所有隐藏层传递结果)。</p>
<p><strong>Word + char LSTM'</strong><br />
这是对上一模型的微调，它使用同一个LSTM结构去训练正向和反向的词隐藏层h。</p>
<p><strong>Word + char CNN</strong></p>
<p>使用CNN方法对每个词生成一个字符表征<span
class="math inline">\(x_i^c\)</span>，其计算方法如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-e400df5ca1009b1f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>取一个最佳值j，使上式结果值最大，其中W和b是网络参数，ke=3是卷积核大小。</p>
<h4 id="格子模型">4.3 格子模型</h4>
<p>LSTM的格子模型结构如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-65c0672189ecee32.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>它扩展了基于字符的LSTM，加入了基于词的记忆单元和门控。</p>
<p>从上面的图3-c可以看到，输入是字符序列，同时增加了由该字符开头的字典D中可能出现的所有词。用<span
class="math inline">\(w_{b,e}^d\)</span>来表示字符串从位置b开始，到位置e结束，比如在图1中的<span
class="math inline">\(w_{1,2}^d=南京\)</span>, <span
class="math inline">\(w_{7,8}^d=大桥\)</span><br />
（我觉得下标好像是写错了）</p>
<p>模型涉及了四种类型的向量：输入向量、输出隐藏向量、记忆单元向量、门控向量。作为重要元素，每一个输入字符<span
class="math inline">\(c_j\)</span>和基于字符的模型一样：<br />
<span class="math display">\[x_j^c=e^c(c_j)\]</span><br />
每个字符<span
class="math inline">\(c_j\)</span>都被代入基本循环结构<span
class="math inline">\(c_j^c\)</span>和<span
class="math inline">\(h_j^c\)</span>，记忆单元<span
class="math inline">\(c_j^c\)</span>用于记录从头到j的信息，隐藏层<span
class="math inline">\(h_j^c\)</span>用作CRF（条件随机场）的输入。</p>
<p>LSTM的基本结构如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-3ac1e38ef8c1e7b8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中的i,f,o分别是输入，遗忘和输出门，<span
class="math inline">\(W^{cT}\)</span>和<span
class="math inline">\(b^c\)</span>是模型参数，σ是sigmoid激活函数。</p>
<p>本文提出的方法与基于字符方法不同的是：计算<span
class="math inline">\(c_j^c\)</span>还涉及了词序列<span
class="math inline">\(w_{b,e}^d\)</span>：<br />
<span class="math display">\[x_{b,e}^w=e^w(w_{b,e}^d)\]</span><br />
这里的<span
class="math inline">\(e^w\)</span>与词嵌入模型的查表方法相同。</p>
<p><span
class="math inline">\(c_{b,c}^w\)</span>用于表示记忆单元，具体计算方法如下：<br />
<img
src="https://upload-images.jianshu.io/upload_images/5357893-5d4a82e7927ecccb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /><br />
i是输入向量，f是遗忘门，需要注意的是由于没有对词元素的标签，所以这里不考虑词相关的输出门。</p>
<p>上式中的<span
class="math inline">\(c_{b,e}^w\)</span>有多种可能性，比如：“桥“、“大桥“、“长江大桥“都是可选词，所有以”桥“结尾的词，最终都被连接到单元”桥“，用<span
class="math inline">\(c_e^c\)</span>表示。对每个<span
class="math inline">\(c_{b,e}^w\)</span>加入门控<span
class="math inline">\(i_{b,e}^c\)</span>，用于控制每个词对记忆单元<span
class="math inline">\(c_{b,e}^c\)</span>的贡献度：<br />
<span class="math display">\[i_{b,e}^c=\sigma(W^{lT}\left[
\begin{matrix}  
   x_e^c \\  
   c_{b,e}^w \\  
\end{matrix} \right]+b^l)\]</span><br />
对于记忆单元的计算变为（通过前一个单元和本次输入计算）：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-bc46dc5331a55d20.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中α是输入门i归一化的方法，具体计算方法如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ea5e826f4b464a04.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>通过对损失函数的反向传播训练模型参数W和b，让模型动态地聚焦于与词更相关的label。</p>
<h4 id="解码和训练">3.4 解码和训练</h4>
<p>最终的CRF层使用最上层的隐藏层结果作为输入。</p>
<p>标签y=l1,l2....lτ，最终计算概率：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d2ebcacea6d77b35.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>式中的W是对应标签第i个位置的模型参数，b是li-1到li的偏移。</p>
<p>文中使用维特比算法找到对于基于词或基于字的输入打分最高的标签，利用L2损失函数训练模型：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-130901dffb67cfb2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中λ是正则化参数，Θ是设置参数。</p>
<h2 id="实验">4. 实验</h2>
<h4 id="实验设置">4.1 实验设置</h4>
<p><strong>数据</strong><br />
实验部分使用了四个数据集：OntoNotes 4（新闻）, MSRA（新闻）, Weibo NER,
Chinese resume（金融领域简历）。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-da40f12ad7ea937c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><strong>分词方法</strong><br />
OntoNotes的训练和测试集，MSRA的训练集，都提供了分词的金标准，而其它的数据则没有直接可用的分词方法，则使用了Yang等人提出的自动分词算法，以及通过上述金标准训练的分词器。</p>
<p><strong>词嵌入</strong><br />
使用 word2vector 的方法提取了 704.4k
个词的词嵌入作为预训练词典，其中两字词57.7k，三字词291.5k，四字词278.1k。并在模型训练时进行了微调。</p>
<p><strong>超参数设置</strong><br />
超参数如下表所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-f1b40f443d8c1a4f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="进一步实验">4.2 进一步实验</h4>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a710bac7d7e61c56.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>表4中对比了基于字符、词、格子三种模型的效果，</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-4b37fde2a7d17ae1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>从图4,表5中可以看出Lattice方法不仅效果好，在没有分词器的情况下，也达到了好于自动分词器，仅次于金标准的效果。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_中文语言技术平台LTP</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E4%B8%AD%E6%96%87%E8%AF%AD%E8%A8%80%E6%8A%80%E6%9C%AF%E5%B9%B3%E5%8F%B0LTP/</url>
    <content><![CDATA[<p>英文题目：N-LTP: An Open-source Neural Language Technology Platform
for Chinese<br />
中文题目：开源中文神经网络语言技术平台N-LTP<br />
论文地址：https://arxiv.org/pdf/2009.11616v4.pdf<br />
代码：https://github.com/HIT-SCIR/ltp<br />
发表时间：2021<br />
作者：Wanxiang Che等，哈工大<br />
出处：EMNLP<br />
被引量：18+</p>
<h2 id="读后感">1 读后感</h2>
<p>它是一个基于<strong>Pytorch</strong>的针对<strong>中文</strong>的<strong>离线工具</strong>，带训练好的模型，<strong>最小模型仅164M</strong>。直接支持分词，命名实体识别等六种任务，六种任务基本都围绕分词、确定词的成份、关系。<br />
实测：比想象中好用，如果用于识别人名，效果还可以，直接用于垂直领域，效果一般，可能还需要进一步精调。</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220620152139.png"
alt="Pasted%20image%2020220620152139.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220620152139.png</figcaption>
</figure>
<h2 id="介绍">2 介绍</h2>
<h3 id="文章贡献">2.1 文章贡献</h3>
<ul>
<li>支持六项中文自然语言任务。<br />
</li>
<li>基于<strong>多任务框架</strong>，共享知识，减少内存用量，加快速度。<br />
</li>
<li>高扩展性：支持<strong>用户引入的BERT类模型</strong>。<br />
</li>
<li>容易使用：支持<strong>多语言接口 C++, Python, Java,
Rust</strong><br />
</li>
<li>达到比之前模型更好的效果</li>
</ul>
<h2 id="设计和架构">3 设计和架构</h2>
<p><img src="/attachments_2022/Pasted%20image%2020220620153735.png"
alt="Pasted%20image%2020220620153735.png" /><br />
图-2展示了软件架构，由一个多任务共享的编码层和各任务别实现的解码层组成。</p>
<h4 id="共享编码层">3.1.1 共享编码层</h4>
<p>使用预训练的模型
ELECTRA，输入序列是s=(s1,s2,...,sn)，加入符号将其变成 s = ([CLS], s1,
s2, . . . , sn, [SEP])，请见BERT原理，输出为对应的隐藏层编码<br />
H = (h[CLS],h1, h2, . . . , hn, h[SEP])。</p>
<h4 id="中文分词-cws">3.1.2 中文分词 CWS</h4>
<p>将编码后的H代入线性解码器，对每个字符分类：<br />
<img src="/attachments_2022/Pasted%20image%2020220620154431.png"
alt="Pasted%20image%2020220620154431.png" /><br />
y是每个字符类别为各标签的概率。</p>
<h4 id="位置标注-pos">3.1.3 位置标注 POS</h4>
<p>位置标注也是NLP中的一个重要任务，用于进一步的语法解析。目前的主流方法是将其视为序列标注问题。也是将编码后的H作为输入，输出位置的标签：<br />
<img src="/attachments_2022/Pasted%20image%2020220620154810.png"
alt="Pasted%20image%2020220620154810.png" /><br />
y是该位置字符属于某一标签的概率，其中i是位置信息。</p>
<h4 id="命名实体识别-ner">3.1.4 命名实体识别 NER</h4>
<p>命名实体识别的目标是寻找实体的开始位置和结束位置，以及该实体的类别。工具中使用Adapted-Transformer方法，加入方向和距离特征：<br />
<img src="/attachments_2022/Pasted%20image%2020220620155424.png"
alt="Pasted%20image%2020220620155424.png" /><br />
最后一步也使用线性分类器计算每个词的类别：<br />
<img src="/attachments_2022/Pasted%20image%2020220620155409.png"
alt="Pasted%20image%2020220620155409.png" /><br />
其中y是NER属于某一标签的概率。</p>
<h4 id="依赖性解析-dep">3.1.5 依赖性解析 DEP</h4>
<p>依赖性解析主要是分析句子的语义结构（详见网上示例），寻找词与词之间的关系。软件中具体使用了双仿射神经网络和einser算法。<br />
<img src="/attachments_2022/Pasted%20image%2020220620160302.png"
alt="Pasted%20image%2020220620160302.png" /><br />
<img src="/attachments_2022/Pasted%20image%2020220620160323.png"
alt="Pasted%20image%2020220620160323.png" /></p>
<h4 id="语义依解析-sdp">3.1.6 语义依解析 SDP</h4>
<p>与依赖性分析相似，语义依赖分析也是捕捉句子的语义结构。它将句子分析成一棵依存句法树，描述出各个词语之间的依存关系。也即指出了词语之间在句法上的搭配关系，这种搭配关系是和语义相关联的。具体包括：主谓关系SBV，动宾关系VOB，定中关系ATT等，详见：<br />
<a
href="https://blog.csdn.net/zw0Pi8G5C1x/article/details/94683412?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-13-94683412-null-null.pc_agg_new_rank&amp;utm_term=%E5%93%88%E5%B7%A5%E5%A4%A7ltp%E7%9A%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E6%96%99&amp;spm=1000.2123.3001.4430">从0到1，手把手教你如何使用哈工大NLP工具——PyLTP</a><br />
具方法是查找语义上相互关联的词对，并找到预定义的语义关系。实现也使用了双仿射模型。<br />
<img src="/attachments_2022/Pasted%20image%2020220620160718.png"
alt="Pasted%20image%2020220620160718.png" /><br />
当p&gt;0.5时，则认为词 i 与 j 之间存在关联。</p>
<h4 id="语义角色标注-srl">3.1.7 语义角色标注 SRL</h4>
<p>语义角色标注主要目标是识别句子以谓语为中心的结构，具体方法是使用端到端的SRL模型，它结合了双仿射神经网络和条件随机场作为编码器，条件随机场公式如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220620162307.png"
alt="Pasted%20image%2020220620162307.png" /><br />
其中f用于计算从yi,j-1到yi,j的转移概率。</p>
<h4 id="知识蒸馏">3.1.8 知识蒸馏</h4>
<p>为了比较单独训练任务和多任务训练，引入了BAM方法：<br />
<img src="/attachments_2022/Pasted%20image%2020220620162821.png"
alt="Pasted%20image%2020220620162821.png" /></p>
<h2 id="用法">4 用法</h2>
<h3 id="安装">4.1 安装</h3>
<pre><code>$ pip install ltp  </code></pre>
<h3 id="在线demo">4.2 在线demo</h3>
<p>http://ltp.ai/demo.html</p>
<h3 id="示例代码">4.3 示例代码</h3>
<h4 id="旧-api">4.3.1 旧 API</h4>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ltp <span class="im">import</span> LTP  </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>ltp <span class="op">=</span> LTP()  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>seg, hidden <span class="op">=</span> ltp.seg([<span class="st">&quot;他叫汤姆去拿外衣。&quot;</span>])  </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>pos <span class="op">=</span> ltp.pos(hidden)  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>ner <span class="op">=</span> ltp.ner(hidden)  </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>srl <span class="op">=</span> ltp.srl(hidden)  </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>dep <span class="op">=</span> ltp.dep(hidden)  </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>sdp <span class="op">=</span> ltp.sdp(hidden)  </span></code></pre></div>
<p>其中seg函数实现了分词，并输出了切分结果，及各词的向量表示。</p>
<h4 id="新-api">4.3.2 新 API</h4>
<p>（220923）</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> ltp.pipeline([<span class="st">&quot;他叫汤姆去拿外衣。&quot;</span>], tasks<span class="op">=</span>[<span class="st">&quot;cws&quot;</span>, <span class="st">&quot;pos&quot;</span>, <span class="st">&quot;ner&quot;</span>, <span class="st">&quot;srl&quot;</span>, <span class="st">&quot;dep&quot;</span>, <span class="st">&quot;sdp&quot;</span>])  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 使用字典格式作为返回结果  </span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(output.cws)  <span class="co"># print(output[0]) / print(output[&#39;cws&#39;]) # 也可以使用下标访问  </span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(output.pos)  </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(output.sdp)  </span></code></pre></div>
<h3 id="精调模型">4.4 精调模型</h3>
<p>下载源码</p>
<pre><code>$ git clone https://github.com/HIT-SCIR/ltp  </code></pre>
<p>在其 ltp 目录中有
task_xx.py，可训练及调优模型，用法详见py内部的示例。形如：</p>
<pre><code>python ltp/task_segmention.py --data_dir=data/seg --num_labels=2 --max_epochs=10 --batch_size=16 --gpus=1 --precision=16 --auto_lr_find=lr  </code></pre>
<h2 id="实验">5 实验</h2>
<p>Stanza是支持一个多语言的NLP工具，中文建模效果比较如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220620164258.png"
alt="Pasted%20image%2020220620164258.png" /><br />
<img src="/attachments_2022/Pasted%20image%2020220620164616.png"
alt="Pasted%20image%2020220620164616.png" /><br />
另外，实验也证明，使用联合模型速度更快，占用内存更少。</p>
<h2 id="使用方法">6 使用方法</h2>
<ul>
<li>需要从 huggingface 下载模型，详见 README.md<br />
</li>
<li>模型都不大，每个几百兆<br />
</li>
<li>CPU版本转换一句不到 1s，大概 50句/秒<br />
</li>
<li>当前版本（230911）<strong>感知机算法 Legacy
模型速度</strong>非常快，是 LTP v3 的 3.55 倍，开启多线程更可获得 17.17
倍的速度提升，但目前仅支持分词、词性、命名实体任务</li>
</ul>
<h2 id="参考">7 参考</h2>
<p><a
href="https://blog.csdn.net/weixin_42223207/article/details/116110532">用法示例:LTP--提取时间人物地点</a></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_关系抽取_CASREL</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96_CASREL/</url>
    <content><![CDATA[<h1 id="介绍">介绍</h1>
<p>英文题目：A Novel Cascade Binary Tagging Framework for Relational
Triple Extraction<br />
中文题目：抽取关系三元组的级联二元标注框架<br />
论文地址：https://aclanthology.org/2020.acl-main.136.pdf<br />
领域：自然语言处理，知识抽取<br />
发表时间：2019<br />
作者：Zhepei Wei, 吉林大学<br />
出处：ACL<br />
被引量：3<br />
代码和数据：<br />
https://github.com/xiangking/ark-nlp<br />
https://github.com/weizhepei/CasRel<br />
阅读时间：2022.06.17</p>
<h1 id="读后感">读后感</h1>
<p>主要解决了三元组重叠问题，相较之前模型，在架构上进行了大调整。</p>
<h1 id="介绍-1">介绍</h1>
<p>知识抽取 Information extraction
(IE）是从文本构建知识图谱的重要环节。具体操作是从文中抽取关系三元组，它包含：主语s，关系r，宾语o。早期一般使用管道
pipeline
方法：先识别句中的实体，然后对每个实体对建立关系，这可能引起错误的传播；后来出现了基于人工构建特征的，抽取实体和关系的联合模型；在深度学习模型流行之后，模型可自行构建特征，使关系抽取得到了进一步发展。</p>
<p>三元组重叠问题，即：一句中的多个关系三元组共用同一实体。该问题一直没得到很好地解决，因为，它打破了早期为简化问题提出的假设：每个token只被标记一次，以及每个实体对只包含一种关系。<br />
<img src="/attachments_2022/Pasted%20image%2020220618221713.png"
alt="Pasted%20image%2020220618221713.png" /><br />
图-1包含三种情况：Normal情况下，被识别的两个三元组互不重叠；EPO情况下，两个实体之间包含多种关系；SEO情况下，存在多个相互重叠的三元组。</p>
<p>之前的方法分离了实体标注和提取关系，忽略了两步之间的相互作用。由于关系类别分布不均，且对于单一的关系，实体对在多数情况下都不满足指定的关系，形成了大量负例，还有缺少各类别足够实例的问题。另外，分离的逻辑处理重叠三元组效果也不好。</p>
<p>为解决上术问题，文中提出文中提出了CASREL框架，将关系作为主语到宾语的映射函数。<strong>具体分为两步：第一步识别句中所有可能的主语；第二步针对每个主题探测各种关系及其对应的宾语</strong>。最终设计了一个端到端的级联双标签（主语标签，关系宾语标签）框架。</p>
<h2 id="方法">方法</h2>
<p>设D为训练集，x为单条训练数据，T为其中包含的所有三元组：<br />
<img src="/attachments_2022/Pasted%20image%2020220619083737.png"
alt="Pasted%20image%2020220619083737.png" /><br />
通过链式法则推导，最终，将抽取三元组拆分成三部分，首先，搜索其中的主语s；然后在文本x和s的条件下，遍历所有可能的关系r，计算对应宾语o发生的概率；右边的部分中，R|s表示没有发生的关系，o∅为空宾语，也就是说不可能发生的关系也找不到对应宾语。</p>
<p>这样做，第一可以直接优化最终三元组层面的评价标准，第二允许了实体充当多个三元组成份，互不干扰，支持了重叠；第三，由式(3)启发了一种新的抽取方法，把实体对的分类问题，变成了映射问题。</p>
<h3 id="bert编码器">BERT编码器</h3>
<p>使用预训练的BERT作为特征抽取器，将文本转换成向量。详见BERT论文。</p>
<h3 id="级联解码器">级联解码器</h3>
<p>核心思想是通过两步级联抽取三元组：先找主语，再找每个主语对应的关系和宾语。<br />
<img src="/attachments_2022/Pasted%20image%2020220619090101.png"
alt="Pasted%20image%2020220619090101.png" /></p>
<h4 id="标记主语">标记主语</h4>
<p>图的下面部分用于识别输入句中所有主语，通过BERT编码成向量h，然后传入Subject
Tagger，对每个token分别检测是否为主题的开始位置或结束位置。<br />
<img src="/attachments_2022/Pasted%20image%2020220619090525.png"
alt="Pasted%20image%2020220619090525.png" /><br />
对于多主题检测，需要对开始和结束位置配对，使用最近start-end匹配的方法，忽略end在start之前的情况。在预测正确的情况下，start与end将成对出现。</p>
<h4 id="指定关系标记宾语">指定关系标记宾语</h4>
<p>图的上半部分展示了识别宾语的过程，图-2中，颜色区分了识别到的不同主语，比如橙色
Jackie R. Brown 被识别成主语时，它是一个人名，所以不存在Capital of
的关系，虽然有可能存在 Work in
关系，但句中没有提及。因此，反应在图上部同样是橙色，对 Birth_place
关系找到了两个可能的宾语，分别是 Washington 和 United States Of
America。</p>
<p>除了BERT输出的向量表示，计算时还考虑到了主语的向量表示 v：<br />
<img src="/attachments_2022/Pasted%20image%2020220619091936.png"
alt="Pasted%20image%2020220619091936.png" /></p>
<p>对每个主题，使用相同的解码器。由于主题可能是多个词，长度不固定，使用对向量取均值的方法来计算上式中主语的向量v。</p>
<p>在关系不存在的情况下，概率计算方法如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220619092329.png"
alt="Pasted%20image%2020220619092329.png" /><br />
对于空的宾语，每个起止位置的标记y都为0。如图-2中 Work in
对应的所有位置都是0（详见图下面的说明）。</p>
<h3 id="目标函数">目标函数</h3>
<p>目标函数J(Θ) 计算方法如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220619103205.png"
alt="Pasted%20image%2020220619103205.png" /></p>
<h2 id="实验">实验</h2>
<h3 id="数据集">数据集</h3>
<p>实验使用了两个公开数据集NYT和WebNLG。关系类型分布不同：<br />
<img src="/attachments_2022/Pasted%20image%2020220619103416.png"
alt="Pasted%20image%2020220619103416.png" /></p>
<h3 id="实验结果">实验结果</h3>
<p>为了比较不同编码器的效果，在CASREL中测试了三种编码器，最下面是使用预训练的BERT，效果最好，random是不使用预训练的BERT模型，LSTM不使用BERT。即使不使用预测训练的BERT，CASREL模型效果也优于其它模型，预训练的BERT进一步提升了模型效果。<br />
<img src="/attachments_2022/Pasted%20image%2020220619103822.png"
alt="Pasted%20image%2020220619103822.png" /><br />
在三元组重叠及句中包含多个三元组的情况下，CASREL效果尤其明显。<br />
<img src="/attachments_2022/Pasted%20image%2020220619103641.png"
alt="Pasted%20image%2020220619103641.png" /></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>关系抽取</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_图像生成文本_CLIP</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E6%96%87%E6%9C%AC_CLIP/</url>
    <content><![CDATA[<h2 id="读后感">读后感</h2>
<p>使用大量数据的对比学习，基于对齐图片和文本嵌入的原理，实现了根据图像生成描述文本的功能，为后续根据文本生成图像奠定了基础。</p>
<h2 id="介绍">介绍</h2>
<p>文中提出CLIP（Contrastive Language-Image
Pre-training）方法，即：对比式语言-图像预训练。它的先进性在于：之前模型只能判断图片是否属于固定类别，而它可以根据一张图片内容，生成文本描述，或者利用文本描述的新类别匹配图片，而无需根据新类别调优模型，即零样本学习。<br />
具体实现方法利用少量有标注数据和大量无标注数据（4亿个图片文本对）方法建模，利用对比学习训练模型，对齐文本和图像的嵌入。
通过在30多个不同的现有视觉数据集上进行基准测试，证明该模型能很好地应用到大多数任务中。<br />
它为后面一系列的图像生成模型（利用文本生成图片）奠定了基础。比如：用DALL-E(unCLIP)
用“小狗吹喇叭”自动生成对应的图片。</p>
<h2 id="方法">方法</h2>
<h3 id="数据">数据</h3>
<p>虽然MS - COCO和Visual
Genome是高质量的人工标记数据集，但按现代标准它们都很小。YFCC100M，在1亿张照片中，保留带有自然语言标题和/或英文描述的图片，仅有1500万张。这与ImageNet的大小大致相同。<br />
CLIP
构建了一个新的数据集，从互联网上的各种公开来源收集了4亿(图像、文字)对，得到的数据集与用于训练GPT
- 2的超文本数据集具有相似的总词数，并将该数据集称为WIT for
WebImageText。</p>
<h3 id="方法-1">方法</h3>
<p>将目标定义为：预测文本与图像配对，而不是文本的确切单词。这种方法与之前方法相比大大提升了效率。</p>
<p>下图总结了具体的实现方法，左侧为训练，右测为预测。针对文本T和图像I分别训练编码器，然后用模型学习正确的配对（对角线上为正确配对）；在预测阶段，根据类别生成描述文本，并选择与图片最为匹配的文本作为描述，以实现零样本分类器。<br />
<img src="/attachments_2023/Pasted%20image%2020230212095019.png" /></p>
<p>具体训练时，假设一个Batch中包含N个图文对，则有NxN种可能的组合。利用多模态技术，训练图片编码器（如ResNet）和文本编码器（如CBOW），将图文转换到嵌入空间，使同一含义的图文表示的cosine距离更近，不同含义的距离更远。具体方法如图-3所示：<br />
<img
src="/attachments_2023/Pasted%20image%2020230211211542.png" /><br />
CLIP
使用了大量数据从头训练图片和文本模型参数。并只使用线性投影，将每个编码器的表示映射到多模态嵌入空间。数据增强方法仅使用了从调整大小的图像中随机产生的正方形裁剪。</p>
<h3 id="底层模型">底层模型</h3>
<p>在图像编码器方面尝试了两种架构，一种是在ResNet基础版本上做了一些修改，如：锯齿模糊池化，将全局平均池化层替换为注意力池化机制等。另一个是在较新的Vision
Transformer架构上做了微调。文本编码器使用了Transformer模型。在图像的宽度深度扩展方面，使用了Tan
&amp; Le ( 2019 )提出的EfficientNet架构。</p>
<h2 id="实验">实验</h2>
<p>实现主要涉及零样本分类问题和表示学习。<br />
对于零样本迁移图像分类结果，和Visual
N-Grams对比结果如下（当然CLIP计算量也大得多）：<br />
<img
src="/attachments_2023/Pasted%20image%2020230211215140.png" /><br />
另一方面也讨论了模型表征学习的能力，评测时使用的主要方法是：在从模型中提取的表示上拟合一个线性分类器，并在各种数据集上测量其性能。以评测与任务无关的数据表征，对比效果如下：<br />
<img
src="/attachments_2023/Pasted%20image%2020230212100711.png" /><br />
可以看到，当在足够大的数据集上训练时，视觉转换器(vision
transformers)比卷积神经网络具有更好的效果。</p>
<h2 id="zotero地址">Zotero地址</h2>
<p><a href="http://zotero.org/users/10876188/items/3GY8HZ4R">Learning
Transferable Visual Models From Natural Language Supervision</a><br />
zotero id: 3GY8HZ4R</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>用字典提升基于BERT的中文标注效果</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%AD%97%E5%85%B8%E6%8F%90%E5%8D%87%E5%9F%BA%E4%BA%8EBERT%E7%9A%84NER/</url>
    <content><![CDATA[<p>#自然语言处理</p>
<h1
id="用字典提升基于bert的中文标注效果">用字典提升基于BERT的中文标注效果</h1>
<p>论文题目：Lexicon Enhanced Chinese Sequence Labeling Using BERT
Adapter<br />
论文地址：https://arxiv.org/abs/2105.07148</p>
<h2 id="读后感">读后感</h2>
<p>论文提出将字典融入BERT网络层记作<strong>字典加强BERT</strong>（Lexicon
Enhanced BERT，LEBERT)
，用于提升中文标注效果。新模型在命名实体识别、分词、成份标注实验中均达到了目前最佳水平。</p>
<h2 id="简介">简介</h2>
<p>这是一篇自表于2021 ACL（NLP顶会）的论文。</p>
<p>由于存在分词（CWS）问题，中文面临更大的挑战，对多数任务，以字为单位比以词为单位效果更好。</p>
<p>目前大多优化方法都是修改上层（网络末端），而未修改核心网络。文中提出的方法利用字典得到更多可能的分词，动态计算最佳分词方法，并修改了网络的Transformers层，如图-1中的右图所示：</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220112130432.png"
alt="Pasted%20image%2020220112130432.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220112130432.png</figcaption>
</figure>
<h2 id="模型">模型</h2>
<p><img src="/attachments_2022/Pasted%20image%2020220112130755.png"
alt="Pasted%20image%2020220112130755.png" /><br />
模型的核心结构如图-2所示，相对于BERT，LEBERT有两个明显差别：（1）输入变成了字符特征+字典特征（2）字典适配层在Transformer层之间。</p>
<h3 id="字词配对">字词配对</h3>
<p>文中方法将基础的字符序列扩展成字符+词对序列，设句S由字符c组成：Sc={c1,c2,c3,...,cn}，在字典D中找到在句中包含字符c所有可能的词ws，如图-3所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220112131412.png"
alt="Pasted%20image%2020220112131412.png" /><br />
最终生成序列：<br />
s_cw={(c1,ws1),(c2,ws2),...(cn,wsn)}</p>
<h3 id="字典适配">字典适配</h3>
<p>将字符和词信息融入BERT网络的字典适配层，方法如图-4所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220112132027.png"
alt="Pasted%20image%2020220112132027.png" /><br />
字典适配层有两个输入：字符和词对，即上图中的h和x，其中h是前一个transformer层输出的字符向量，x是m个可能包含该字符的词组成的词嵌入，其中j是m中的第j个词：<br />
<span class="math display">\[ x_{ij}^w=e^w(w_{i,j})\]</span><br />
其中e是预训练得到的词向量映射表。<br />
为了对齐长短不一的序列，对词向量进行非线性变换如下：<br />
<span
class="math display">\[v_{ij}^w=W_2(tanh(W_1x_{ij}^w+b_1))+b_2\]</span><br />
其中W1是大小为dc-dw的矩阵，W2是大小dc-dc的矩阵，b1和b2是偏移，dw是词向量的维度，c是隐藏层的维度。</p>
<p>由图-3可知，一个字可能对应多个词，对于不同的任务，最匹配的词可能并不相同。</p>
<p>具体算法是使用vi表示第i个字符对应的所有词表，m是该字符可能对应的词个数，计算注意力attention如下：<br />
<span class="math display">\[
a_i=softmax(h_i^cW_{attn}V_i^T)\]</span><br />
其中W是注意力权重矩阵。<br />
然后对每个词乘其权重加和，得到位置i对应的词表示：<br />
<span class="math display">\[z_i^w=\sum_{j=1}^m
a_{ij}v_{ij}^w\]</span><br />
最终，将词典信息与字符的向量相加，得到了该位置的新向量：<br />
<span class="math display">\[\widetilde{h}_j=h_i^c+z_i^w\]</span><br />
处理后的数据再送入dropout层和归一化层继续处理。</p>
<h3 id="用字典加强bert">用字典加强BERT</h3>
<p>将字符输入词嵌入层，加入token,
segment和position信息，然后将该层输出的词嵌入输入Transformer层：<br />
<span class="math display">\[G=LN(H^{l-1}+HMAttn(H^{l-1}))\]</span><span
class="math display">\[H^l=LN(G+FFN(G)\]</span><br />
输出的<span
class="math inline">\(H^l\)</span>是第l个隐藏层的输出，LN是归一化层，HMAttn是多头注意力机制，FFN是两个前馈网络层，使用ReLU作为激活函数。</p>
<p>在k-th和(k+1)-th Transformer之间加入字典信息<br />
<span
class="math display">\[\widetilde{h}_i^k=LA(h_i^k,x_i^{ws})\]</span></p>
<h3 id="训练和解码">训练和解码</h3>
<p>考虑到标签的前后关系，使用CRF层来预测最终的标签，将最后一个隐藏层h的输出作为输入，计算输出层O：<br />
<span class="math display">\[O=W_oH^L+b_o\]</span><br />
然后将输出层代入CRF模型，计算标签y的概率p。<br />
<img src="/attachments_2022/Pasted%20image%2020220113191725.png"
alt="Pasted%20image%2020220113191725.png" /></p>
<p>训练时给出句子S和标签Y，计算全句的负对数似然作为误差。<br />
<span class="math display">\[L=-\sum_jlog(p(y|s))\]</span><br />
解码时，使用维特比算法计算得分最高的序列。</p>
<h2 id="实验">实验</h2>
<p>论文针对命名实体识别NER，分词CWS、位置POS标注进行了实验，实验数据如表-1所示（中文NLP常用实验数据）。<br />
<img src="/attachments_2022/Pasted%20image%2020220114132920.png"
alt="Pasted%20image%2020220114132920.png" /><br />
图-5展示了相对于BERT和基于BERT的最新模型，文中模型误差的减少情况。<br />
<img src="/attachments_2022/Pasted%20image%2020220114133747.png"
alt="Pasted%20image%2020220114133747.png" /></p>
<p>除了与其它模型比较之外，论文还比较了LEBERT方法与在组装模型的Bert+Word方法的差异。<br />
<img src="/attachments_2022/Pasted%20image%2020220114134212.png"
alt="Pasted%20image%2020220114134212.png" /></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_对比学习_SimCSE</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0_SimCSE/</url>
    <content><![CDATA[<p>英文题目：SimCSE: Simple Contrastive Learning of Sentence
Embeddings<br />
中文题目：SimCSE：用简单的对比学习提升句嵌入的质量<br />
论文地址：https://export.arxiv.org/pdf/2104.08821.pdf<br />
领域：自然语言处理，对比学习<br />
发表时间：2021.04<br />
作者：Tianyu Gao, 普林斯顿大学，清华大学<br />
出处：EMNLP<br />
被引量：83<br />
代码和数据：https://github.com/princeton-nlp/SimCSE<br />
阅读时间：2022.09.18<br />
(周五同事分享，简单整理笔记)</p>
<h2 id="读后感">读后感</h2>
<p>主要用于提升句嵌入的质量。方法很简单，利用BERT模型本身的dropout性质，通过同一输入输出不同嵌入作为正例对，然后取同一batch下的反例对训练模型。</p>
<h2 id="介绍">介绍</h2>
<p>自监督学习主要包含：生成式，对比式，对抗式。其中的对比学习原理是：利用无监督数据，通过巧妙的方法构造正例/反例（一般是一个正例对应多个反例），训练模型，让正例距离足够近，反例距离足够远，以利用无监督数据，进行更好地表示（表征）。<br />
一般设计包含三部分：构造正/负例；优化损失函数；调整模型编码器。</p>
<p>评价对比学习的质量有两个关键指标：alignment和uniformity。其中alignment指的是正例中数据对表示的一致性；<br />
<img src="/attachments_2022/Pasted%20image%2020220917224104.png"
alt="Pasted%20image%2020220917224104.png" /><br />
uniformity指的是嵌入空间分布的均匀性：<br />
<img src="/attachments_2022/Pasted%20image%2020220917224206.png"
alt="Pasted%20image%2020220917224206.png" /><br />
其中Pdata指空间中所有实例。也就是说正例距离越近越好，而随机采样的数据对的距离应该分布在超球体表面。</p>
<h2 id="方法">方法</h2>
<h3 id="无监督数据训练simcse">无监督数据训练SimCSE</h3>
<p>之前生成近似正例的方法有：随机增删，近义词替换，交换词序等。本文利用
BERT 模型本身包含
dropout，这样同一个句子两次送入模型，由于随机dropout，最终的编码也不同。用这种方法作为数据增强，生成对比学习中的正例对，使用同一batch中的其它实例作为反例。损失函数定义如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220917225207.png"
alt="Pasted%20image%2020220917225207.png" /><br />
表-1对比了文中方法和其它常用方法（删词，剪切），在同义句子匹配STS-B任务中的效果：<br />
<img src="/attachments_2022/Pasted%20image%2020220917225354.png"
alt="Pasted%20image%2020220917225354.png" /><br />
图-2把损失拆分成alignment和uniformity，位置处于左下角时效果最好（两个loss都小）；可以看到随着迭代训练损失的变化（箭头方向），其中红色线为SimSCE在两个评测方向的变化相对最好。</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220917225707.png"
alt="Pasted%20image%2020220917225707.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220917225707.png</figcaption>
</figure>
<h3 id="有监督数据训练simcse">有监督数据训练SimCSE</h3>
<p>文中还研究了SimSCE对比学习如何利用有监督学习的数据来提升模型的表现力。具体使用自然语言推理任务（NLI）数据，NLI用以判断两个句子的关系是：蕴含、中性或矛盾。利用训练集中的标注信息产生对比学习中的正/负例。</p>
<p><strong>选择标注数据</strong><br />
为对比 NLI 的提升效果，先探索了一些构造正例的方法：<br />
*
使用Kaggle比赛的QQP数据集，它的训练数据标注了两个问句语义是否相同。<br />
*
使用Flickr30，对每个图片人工标注了五个标题，可将其中的两两标注组成正例对。<br />
*
使用ParaNMT，大规模的反向翻译数据集（如：中-&gt;英-&gt;中），作为正例对。<br />
*
使用NLI任务数据集，最终NLI数据集效果最好，这是由于它包含高质量的众包人工标注，并且正例中词汇重合度小（同一词在两个正例对中均出现）。</p>
<p><strong>将矛盾关系对作为硬负例</strong><br />
为了更好利用NLI数据集，利用标注为矛盾的实例，生成硬负例，并修改了损失函数，实验证明了它的有效性：<br />
<img src="/attachments_2022/Pasted%20image%2020220917232306.png"
alt="Pasted%20image%2020220917232306.png" /><br />
可以看到，这里硬负例被充分利用（被计入了N次），图-4展示了实验结果：<br />
<img src="/attachments_2022/Pasted%20image%2020220917232417.png"
alt="Pasted%20image%2020220917232417.png" /><br />
为了公正的对比，sample列只采样了134k正例来训练模型。可以看到不同任务训练的模型对
STS-B 效果的提升。</p>
<h3 id="各向异性">各向异性</h3>
<p>各向异性意思是所有向量都被映射在了一个“狭窄”的高维空间。而uniformity是评价所有实例在向量空间中是否均匀分布，SimCSE在uniformity方面提升，也改善了自然语言编码的各向异性问题。</p>
<p>图-3对比了目前各种流行模型的alignment和uniformity：<br />
<img src="/attachments_2022/Pasted%20image%2020220917235416.png"
alt="Pasted%20image%2020220917235416.png" /></p>
<h2 id="实验">实验</h2>
<p>主实验使用句子相似度任务，在有监督和无监督两方面，对比了不同方法的效果：<br />
<img src="/attachments_2022/Pasted%20image%2020220917233327.png"
alt="Pasted%20image%2020220917233327.png" /><br />
可以看到SimSCE效果已超过了目前业界使用最为广泛SBERT（挛生网络）模型。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>深度框架</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_清华ERNIE</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E6%B8%85%E5%8D%8EERNIE/</url>
    <content><![CDATA[<p>英文题目：ERNIE: Enhanced Language Representation with Informative
Entities<br />
中文题目：ERNIE: 使用信息实体增强语言表示<br />
论文地址：https://arxiv.org/pdf/1905.07129v3/n<br />
领域：自然语言处理<br />
发表时间：2019<br />
作者：Zhengyan Zhang，清华大学<br />
出处：ACL<br />
被引量：37<br />
代码和数据：https://github.com/thunlp/ERNIE<br />
阅读时间：2002.06.25</p>
<h1 id="读后感">读后感</h1>
<p>2019年前后清华和百度都提出了名为ERNIE的模型，名字相同，方法不同。清华的ERNIE把<strong>知识图融入了文本的向量</strong>表示，也叫KEPLM，想法比较有意思，模型改进效果：<strong>使用少量数据训练模型时，ERNIE比其它模型效果更好</strong>。从技术角度，它示范了<strong>整合异构数据的方法</strong>。</p>
<h2 id="介绍">介绍</h2>
<p>本文提出ERNIE，它是结合知识图和大规模数据的预训练语言模型。引入知识图面临两个重要挑战：<br />
* 如何在文本表示中提取和表示知识图中的结构<br />
* 整合异构数据：将预训练模型表示和知识图表示映射到同一向量空间</p>
<p>ERNIE的解决方法如下：<br />
*
<strong>识别文本中提到的命名实体</strong>，然后将<strong>实体与知识图中对应的实体对齐</strong>，<strong>利用文本语义作为知识图的实体嵌入</strong>，<strong>再使用TransE方法学习图的结构</strong>。<br />
*
在预训练语言模型方面，也使用类似BERT的MLM方法，同时利用对齐方法，找<strong>知识图中的实体做遮蔽</strong>；聚合了上下文和知识图共同预测token和实体。</p>
<h2 id="方法">方法</h2>
<h3 id="定义符号">定义符号</h3>
<p>token（操作的最小单位：一般是字或词）使用 {w1,...,wn}
表示，对齐后的<strong>实体用 {e1,..., em}</strong>
表示。需要注意m与n一般个数不同，实体可能包含不只一个字或词。定义V为包含所有token的词表，知识图中的所有实体用E表示。用函数f(w)=e表示对齐函数，文中使用实体中的第一个token对齐。</p>
<h3 id="模型结构">模型结构</h3>
<p>模型结构如图-2所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220625210929.png"
alt="Pasted%20image%2020220625210929.png" /><br />
模型结构包含两块，T-Encoder用于提取token相关的文本信息；K-Encoder整合了扩展的图信息，将异构数据转换到统一的空间中。</p>
<p>首先，将利用token {w1,..., wn} 的词嵌入、段嵌入、位置嵌入，代入
T-Encoder 层，计算其语义特征：<br />
<img src="/attachments_2022/Pasted%20image%2020220625211438.png"
alt="Pasted%20image%2020220625211438.png" /><br />
<strong>T-Encoder类似普通的BERT</strong>，它由N个Transformer层组成，用粗体的
{e1,...., em} 表示通过 TransE
预训练的图嵌入，将粗体的w和e代入K-Encoder，整合异构数据，生成输出
wo和eo：<br />
<img src="/attachments_2022/Pasted%20image%2020220625211746.png"
alt="Pasted%20image%2020220625211746.png" /><br />
wo和eo将被用于下游任务。</p>
<h3 id="知识编码">知识编码</h3>
<p>从图-2的右半部分可以看到，K-Encoder一般包含M层，以第 i
层为例，输入是第 i-1 层的 w 和
e，分别使用两个多头的self-attention。<br />
<img src="/attachments_2022/Pasted%20image%2020220625212407.png"
alt="Pasted%20image%2020220625212407.png" /><br />
对于token：wj
和与它<strong>对齐</strong>的实体：ek=f(wj)，使用以下方法融合数据：<br />
<img src="/attachments_2022/Pasted%20image%2020220625212629.png"
alt="Pasted%20image%2020220625212629.png" /><br />
这里的 hj
是内部隐藏层，它结合了token和实体表示，σ是非线性激活函数，这里使用GELU。对于找不到对应实体的token，无需融合：<br />
<img src="/attachments_2022/Pasted%20image%2020220625212818.png"
alt="Pasted%20image%2020220625212818.png" /><br />
第 i 层简化表示如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220625212915.png"
alt="Pasted%20image%2020220625212915.png" /></p>
<h3 id="利用预训练模型注入知识">利用预训练模型注入知识</h3>
<p>预训练时，随机<strong>遮蔽对齐的
token-entity</strong>，让模型预测对应的多个token。这个过程类似自编码器dEA。知识图中可能包含非常多的实体，做softmax时计算量非常大，而我们只关注系统需要的实体，以减少计算量。在给定token序列和实体序列的条件下，定义对齐分布计算：<br />
<img src="/attachments_2022/Pasted%20image%2020220625213658.png"
alt="Pasted%20image%2020220625213658.png" /><br />
它计算在w条件下，对齐实体为ej的概率，式(7)用于计算交叉熵损失函数。<br />
<strong>在5%的情况下，将实体替换成其它实体，以训练模型纠正token与实体对齐的错误；在15%的情况下，遮蔽token与实体间的对齐，以训练模型纠正没有识别到对齐的情况；其它情况保持对齐关系，学习token与实体间的关系。</strong></p>
<p>训练的损失函数综合了dEA（自编码），MLM（遮蔽）和NSP（句子顺序）的损失。</p>
<h3 id="针对具体任务精调模型">针对具体任务精调模型</h3>
<p>如图-3所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220625214509.png"
alt="Pasted%20image%2020220625214509.png" /><br />
对于一般任务，将编码后的词嵌入代入下游模型即可。对于知识驱动的任务，比如关系分类，或者预测实体类型，使用以下方法精调。</p>
<p>对于关系分类问题，最直接的方法是在输出的实体向量之后加池化层，串联实体对，然后送入分类器。而文中提出的方法如图-3所示，它在头实体和尾实体的前后分别加了标签，标签的效果类似于传统关系分类中的位置嵌入，仍然使用CLS来标记类别。</p>
<p>预测实体类型是关系分类的简化版，也使用ENT标签来引导模型结合上下文信息和实体信息。</p>
<h2 id="实验">实验</h2>
<p>清华的ERNIE是针对英文训练的模型，实验证明，额外的知识可以帮助模型充分利用小的训练数据，这对很多数据有限的任务非常有用。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_用引导调优模型</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E7%94%A8%E5%BC%95%E5%AF%BC%E8%B0%83%E4%BC%98%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>name_ch: 微调语言模型是零样本学习者<br />
name_en: Finetuned Language Models Are Zero-Shot Learners<br />
paper_addr: http://arxiv.org/abs/2109.01652<br />
code: https://github.com/google-research/flan<br />
date_publish: 2022-02-08</p>
<h2 id="读后感">读后感</h2>
<h2 id="介绍">介绍</h2>
<p>指令调优是：在通过指令描述的一组数据集上微调语言模型，它显著提高了未见任务的
zeroshot 性能。将此类模型称为FLAN（Finetuned Language Net），采用 137B
参数预训练语言模型，并在 60 多个通过自然语言指令模板的 NLP
数据集上对其进行指令调优。</p>
<p>模型效果，图-1展示了模型在不同类型任务上的效果对比：<br />
<img src="/attachments_2023/Pasted%20image%2020230325164342.png" /></p>
<h2 id="方法">方法</h2>
<h3 id="原理图">原理图</h3>
<p><img
src="/attachments_2023/Pasted%20image%2020230325164517.png" /><br />
用 Tensorflow Datasets 上公开可用的 62
个文本数据集（包括语言理解和语言生成任务）聚合到一起，每个数据集被分类为十二个任务集之一。<br />
<img
src="/attachments_2023/Pasted%20image%2020230325165317.png" /><br />
对于每个数据集，我们手动编写了十个独特的模板，这些模板使用自然语言指令来描述该数据集的任务。<br />
模板如下图所示：<br />
<img src="/attachments_2023/Pasted%20image%2020230325170834.png" /></p>
<h3 id="模型架构和预训练">模型架构和预训练</h3>
<p>我们使用 LaMDA-PT，这是一种密集的从左到右、仅解码器的 137B
参数变换语言模型。该模型在一组网络文档、对话数据和维基百科上进行了预训练，并使用
SentencePiece 库标记为具有 32k 词汇的 2.49T BPE 标记。大约 10%
的预训练数据是非英语的，PT 指的是预训练语言模型。</p>
<h3 id="指令调整程序">指令调整程序</h3>
<p>FLAN 是 LaMDA-PT
的指令调整版本。指令调优管道混合了所有数据集并从每个数据集中随机抽样。为了平衡不同大小的数据集，将每个数据集的训练示例数量限制为
30k，并遵循示例比例混合方案。<strong>在具有 128 个内核的 TPUv3
上，此指令调整大约需要 60 个小时</strong>。对于所有评估，并报告了经过
30k 步训练的最终检查点的结果。</p>
<h2 id="实验">实验</h2>
<p>在自然语言推理、阅读理解、闭卷
QA、翻译、常识推理、共指消解和结构到文本方面评估 FLAN。<br />
观察到指令调优对自然语言化为指令的任务（例如，NLI、QA、翻译、结构到文本）非常有效，而对直接表述为语言建模的任务效果较差，其中指令在很大程度上是冗余的。<br />
<img
src="/attachments_2023/Pasted%20image%2020230325171555.png" /><br />
FLAN 的性能相对于LaMDA每个任务平均值提升了10左右。</p>
<p>在指令调优中添加额外的任务集，可以提高保留任务集的零样本性能。<br />
<img
src="/attachments_2023/Pasted%20image%2020230325172038.png" /><br />
尽管指令调优有助于大型模型泛化到新任务，但对于小型模型，它实际上会损害对未见过任务的泛化。<br />
<img src="/attachments_2023/Pasted%20image%2020230325173647.png" /></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_自然语言模型GPT-3</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BGPT-3/</url>
    <content><![CDATA[<h1 id="自然语言模型gpt-3">自然语言模型GPT-3</h1>
<p>#论文阅读 #自然语言处理</p>
<p>论文：https://arxiv.org/abs/2005.14165<br />
代码：https://github.com/openai/gpt-3</p>
<p>OpenAI于2020年6月发表了GPT-3论文《Language Models are Few-Shot
Learners》，模型包括1750亿参数，比之前最大模型又大了10倍，使用45T数据训练，31位作者，论文长达75页，尝试了不同量级的GPT-3模型，在20多个NLP数据集上做了评价。其核心是<strong>不使用Fine-tune的GPT-3模型</strong>。</p>
<p>目前前沿的自然语言模型一般是先用大规模无监督数据预测训练（pretrain）模型之后，然后使用带标注的领域数据微调模型(fine-tune)，费时费力，且有些领域难以实现标注；模型也可能被领域数据的分布带偏，从而损失了泛化能力；另外，微调后的模型只能解决特定问题，不像人类，可以在众多类似的问题之间切换，并使用综合技能解决复杂的问题。</p>
<p>Pretrain&amp;fine-tune方法一般用于有大量标注的数据（带标注数据一般含几千到几十万的数据量），对于仅有少量标注（few-shot如10-100标注）或者单标注（one-shot，一个标注数据）、无标注（zero-shot）的数据效果都不好。</p>
<p>从下图中可以看到，当训练实例和参数规模增加后，模型对Few-shot问题学习效果有明显地提升，也就是说加入海量无标注数据学习后，模型举一反三的能力明显提高了。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-381022801a647b12.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>GPT-3训练出的模型不需要fine-tune，但它主要针对的也是few-shot,
one-shot,
zero-shot问题，对于包含大量标注的数据，一般使用fine-tune效果更好。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d64615aa75a14ff7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>可以看到，最大的模型，1750亿参数，96层，128头的attention，并在处理更大规模数据时提升了batch_size，减少了学习率。除了海量的数据和参数，在多个数据集上测试以外，与GPT-2相比，GPT-3并没有引入大量的先进技术。GPT-2论文发布于2019年《Language
models are unsupervised multitask learners》，其中包含更多技术细节。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5bbe77365b3ac7ed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>论文很长，第一部分是介绍；第二部分是算法实现和评价方法；第三部分展示了训练效果；第四部分讨论了数据污染（训练和测试集重合问题）；第五部分讨论了GPT-3的局限性；第六部分是模型的影响，包括伦理相关讨论；第七部分是近期自然语言模型回顾；第八部分为总结。尽管全文70多页，但核心内容主要集中在正文的前8-10页。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>语音识别方法三：使用Service调用语音识别程序</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95%E4%B8%89%EF%BC%9A%E4%BD%BF%E7%94%A8Service%E8%B0%83%E7%94%A8%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%A8%8B%E5%BA%8F/</url>
    <content><![CDATA[<h1
id="语音识别方法三使用service调用语音识别程序">语音识别方法三：使用Service调用语音识别程序</h1>
<p>1. 说明<br />
以下例程功能为：在应用程序中使用通于访问 service
调用语言识别功能，录音并识别后将识别的字串通过 Listener<br />
返回给应用程序。注意：使用前需要安装语音识别服务，如编译安装源码中的
development/samples/VoiceRecogitionService<br />
。</p>
<p>2. 本例参考自 android 源码</p>
<ol type="a">
<li><p>后台服务<br />
参见 development/samples/VoiceRecognitionService/*<br />
此处实现了一个模拟的后台服务 ， 它并未实现真的语音识别 ，
而只是一个框架以示例 ， 编译并安装它 ，
即可在设置的语音输入与输出中看到它<br />
， 它包含了一个设置界面 ， 当连接这个 Service 时 ， 如果设置了 Letters
， 则直接返回 abc ，<br />
如果设置了 Numbers ， 则直接返回 123<br />
你可以自己实现 ， 用于连接 android 源码自带的识别引擎 srec.</p></li>
<li><p>前台程序<br />
参见 frameworks/base/core/java/android/speech/Recognition*<br />
它 与后台 Service 交互 ， 此段代码实现在应用程序界面中</p></li>
</ol>
<p>3. 可从此处下载可独立运行的代码 ( 前台程序 ) ：<br />
<a
href="http://download.csdn.net/source/2591401">http://download.csdn.net/source/2591401<br />
</a></p>
<p>4. 核心代码及说明</p>
<p>_ package com.android.mystt3; _</p>
<p>_ _</p>
<p>_ import android.app.Activity; _</p>
<p>_ import android.content.Intent; _</p>
<p>_ import android.os.Bundle; _</p>
<p>_ import android.view.View; _</p>
<p>_ import android.view.View.OnClickListener; _</p>
<p>_ import android.speech.RecognitionListener; _</p>
<p>_ import android.speech.RecognizerIntent; _</p>
<p>_ import android.speech.SpeechRecognizer; _</p>
<p>_ import android.widget.Button; _</p>
<p>_ import android.widget.TextView; _</p>
<p>_ import java.util.ArrayList; _</p>
<p>_ import android.util.Log; _</p>
<p>_ _</p>
<p>_ public class MyStt3Activity extends Activity implements
OnClickListener { _</p>
<p>_ private TextView mText; _</p>
<p>_ private SpeechRecognizer sr; _</p>
<p>_ private static final String TAG = "MyStt3Activity"; _</p>
<p>_ _</p>
<p>_ <span class="citation" data-cites="Override">@Override</span> _</p>
<p>_ public void onCreate(Bundle savedInstanceState) { _</p>
<p>_ super.onCreate(savedInstanceState); _</p>
<p>_ setContentView(R.layout.main); _</p>
<p>_ Button speakButton = (Button) findViewById(R.id.btn_speak); // _ _
识别按钮 _<br />
__</p>
<p>_ mText = (TextView) findViewById(R.id.text); // _ _ 显示识别字串 _
__</p>
<p>_ speakButton.setOnClickListener(this); _</p>
<p>_ sr = SpeechRecognizer.createSpeechRecognizer(this); // _ _
初始化识别工具，得到句柄 _<br />
__</p>
<p>_ sr.setRecognitionListener(new listener()); // _ _ 注册回调类及函数
_ __</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ class listener implements RecognitionListener // _ _ 回调类的实现 _
__</p>
<p>_ { _</p>
<p>_ public void onReadyForSpeech(Bundle params) _</p>
<p>_ { _</p>
<p>_ Log.d(TAG, "onReadyForSpeech"); _</p>
<p>_ } _</p>
<p>_ public void onBeginningOfSpeech() _</p>
<p>_ { _</p>
<p>_ Log.d(TAG, "onBeginningOfSpeech"); _</p>
<p>_ } _</p>
<p>_ public void onRmsChanged(float rmsdB) _</p>
<p>_ { _</p>
<p>_ Log.d(TAG, "onRmsChanged"); _</p>
<p>_ } _</p>
<p>_ public void onBufferReceived(byte[] buffer) _</p>
<p>_ { _</p>
<p>_ Log.d(TAG, "onBufferReceived"); _</p>
<p>_ } _</p>
<p>_ public void onEndOfSpeech() _</p>
<p>_ { _</p>
<p>_ Log.d(TAG, "onEndofSpeech"); _</p>
<p>_ } _</p>
<p>_ public void onError(int error) _</p>
<p>_ _ _ { _</p>
<p>_ Log.d(TAG, "error " + error); _</p>
<p>_ _ _ mText.setText("error " + error); _</p>
<p>_ } _</p>
<p>_ public void onResults(Bundle results) // _ _ 返回识别到的数据 _
__</p>
<p>_ { _</p>
<p>_ String str = new String(); _</p>
<p>_ Log.d(TAG, "onResults " + results); _</p>
<p>_ ArrayList data =<br />
results.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION); _</p>
<p>_ for (int i = 0; i &lt; data.size(); i++) _</p>
<p>_ { _</p>
<p>_ Log.d(TAG, "result " + data.get(i)); _</p>
<p>_ str += data.get(i); _</p>
<p>_ } _</p>
<p>_ mText.setText(str); // _ _ 显示被识别的数据 _ __</p>
<p>_ } _</p>
<p>_ public void onPartialResults(Bundle partialResults) _</p>
<p>_ { _</p>
<p>_ Log.d(TAG, "onPartialResults"); _</p>
<p>_ } _</p>
<p>_ public void onEvent(int eventType, Bundle params) _</p>
<p>_ { _</p>
<p>_ Log.d(TAG, "onEvent " + eventType); _</p>
<p>_ } _</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ public void onClick(View v) { _</p>
<p>_ if (v.getId() == R.id.btn_speak) { _</p>
<p>_ sr.startListening(new
Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH)); _</p>
<p>_ } _</p>
<p>_ } _</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ (转载请注明出处: <a
href="http://xy0811.spaces.live.com/">http://xy0811.spaces.live.com/</a><br />
) _</p>
<p>_ _</p>
]]></content>
      <tags>
        <tag>语音</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_语义嵌入</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E8%AF%AD%E4%B9%89%E5%B5%8C%E5%85%A5/</url>
    <content><![CDATA[<p>论文题目：Making Sense of Word Embeddings<br />
相关源码：<a
href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fuhh-lt%2Fsensegram">https://github.com/uhh-lt/sensegram</a><br />
论文地址：<a
href="https://links.jianshu.com/go?to=https%3A%2F%2Farxiv.org%2Fabs%2F1708.03390">https://arxiv.org/abs/1708.03390</a></p>
<h2 id="读后感">读后感</h2>
<p>语义嵌入：从语料库和字典学习，或从已有词向量数据归纳学习</p>
<h2 id="简介">简介</h2>
<p>论文是2016年发表于ACL(Association for Computational
Linguistics，自然语言处理顶会，一年召开一次，CCF等级/JCR分区：A类)的会议论文。</p>
<h2 id="背景知识">背景知识</h2>
<p>论文介绍了一种简单有效的方法用于学习语义嵌入。文中方法既可以直接从语料库和字典学习，也可以根据已有的词向量数据通过自我网络聚类的方法归纳学习。它提升了下游应用的效果，与当时最好的模型效果类似。</p>
<h4 id="词向量">词向量</h4>
<ul>
<li>预处理时将词映射成稠密向量代入模型，降低稀疏性<br />
</li>
<li>对比不同词的语义相似度，实现近义词的迁移<br />
</li>
<li>表征不同语义单位：词向量-&gt;词组向量-&gt;短语向量<br />
</li>
<li>通过词嵌入实现运算，比如：男-女=国王-王后，国王-男+女-&gt;王后，实现类比相关的逻辑推理功能，以及性质变换。</li>
</ul>
<h4 id="语义向量">语义向量</h4>
<p>无论是稠密的还是稀疏的表示，大部分的词嵌入方法都面临一词多义的问题。后来有人提出了意义向量（sense
vector）的概念来解决这个问题，从而提升一些应用的效果，如成份标注、语义关系识别。</p>
<p>论文中提出了一种意义向量学习方法，它使用自我中心网络聚类，将已存在的词嵌入转换成意义嵌入。最终实现了利用上下文实现语义消歧机制（WSD）。</p>
<h4 id="自我中心网络">自我中心网络</h4>
<p>自我中心网络 ego
network，它的节点是由唯一的中心节点(ego)，以及这个节点的邻居(alters)组成的，它的边只包括了ego和alter之间，以及alter与alter之间的边。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-0fd742efa2d77bed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/624/format/webp" /></p>
<p>image.png</p>
<h4 id="词嵌入方法">词嵌入方法</h4>
<p>请参考我之前的文档：<a
href="https://links.jianshu.com/go?to=https%3A%2F%2Fblog.csdn.net%2Fxieyan0811%2Farticle%2Fdetails%2F107007955">几种词嵌入方法</a></p>
<h4 id="chinese_whisper算法">Chinese_whisper算法</h4>
<p>话从第一个人传给第二个人，第二个人再传给第三个人，一直传下去，越传越走样。<br />
Chinese_whisper 是一种图聚类算法：</p>
<ul>
<li>原则：构建无向图，将每个词做为无向图中的一个节点，词之间的相似度，作为节点之间的边，如果词之间的相似度小于设定的阈值那么，这两个词对应的节点之间就没有边。<br />
</li>
<li>步骤一：迭代开始前，将每个词作为一个节点，每个词都被赋予一个id作为该词的类别。<br />
</li>
<li>步骤二：遍历所有节点，把每个节点移动到邻居所属最多的类（在连接相等的情况下，从中随机选择一个）。<br />
</li>
<li>步骤三：重复步骤二，直到达到预定的迭代次数或收敛。</li>
</ul>
<h2 id="前人的方法">前人的方法</h2>
<h4 id="一词多义">一词多义</h4>
<ul>
<li>聚类方法不断迭代，将簇心作为语义嵌入（词聚类/上下文聚类）<br />
</li>
<li>稠密向量常使用神经网络方法<br />
</li>
<li>基于知识的方法，如将知识库中的任何实体表实为稠密向量，以及利用WordNet和词嵌入来构建语义嵌入。</li>
</ul>
<h4 id="词义消歧">词义消歧</h4>
<p>有监督学习，常常为每一个目标词建立一个模型，使用有监督方法训练，这需要大量标注。另外，还有基于知识的方法，比如从WordNet中导出意义的表示。</p>
<p>无监督学习，从数据中自动归纳语义清单，具体的方法有两种：分别是上下文聚类，和词(自我中心网络)聚类；是否为歧义由其上下文的重叠度来确定；计算上下文词与中心词的距离。</p>
<h2 id="语义嵌入算法">语义嵌入算法</h2>
<p><strong>算法具体包含四步</strong></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-302a773e49a625ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1023/format/webp" /></p>
<p>image</p>
<ul>
<li>学习词嵌入<br />
</li>
<li>基于向量的相似度建立最近邻图<br />
</li>
<li>使用ego-network聚类归纳语义向量（分组）<br />
</li>
<li>用词向量计算语义向量</li>
</ul>
<p>上述主要流程也是可以被替换的，比如：已经存在词嵌入，则可省略第一步；如果使用已经构建的词相似度图，可替代第二步；如果使用众包的方式构建语义列表，则可替代第二三步。</p>
<h4 id="学习词嵌入">学习词嵌入</h4>
<p>论文使用了Word2Vec的CBOW模型训练100维(或300维)的词向量，具体的上下文大小是3，词出现的最小频率是5。并在后面的评测阶段将其作为baseline模型。使用Wikipedia和ukWaC作为训练数据。</p>
<h4 id="计算相似图">计算相似图</h4>
<p>建立基于近义词的图，比如桌子和椅子近似度为0.78，对每个词取其200个最近邻（对于绝大多数词来说是足够的）。这个图既可以基于上一步的词向量，也可以使用JoBimText（JBT）架构提供的语义相似度。</p>
<ul>
<li>词向量相关性</li>
</ul>
<p>使用cosine距离来计算词向量相似度最高的最近邻，具体使用矩阵乘法实现。</p>
<ul>
<li>JBT 相关性</li>
</ul>
<p>这是一种无监督的方法，每个词被表征为基于依赖关系的稀疏特征词袋，使用MALT解析器提取。特征使用LM1方法归一化。其剪枝方法是：对每个词保留1000个特征，每个特征与1000个词关联。两个词的相似度通过它们共有特征的个数计算。</p>
<p>JBT有两个优点：<br />
(1) 基于依赖特征<strong>准确</strong>地估计词的相似度。<br />
(2) <strong>高效</strong>地计算语料库中所有词的最近邻域。<br />
此外，即使次要意义在训练语料库中有显著的支持，单词嵌入的近邻往往也倾向于属于主要意义。</p>
<h4 id="语义归纳分组">语义归纳（分组）</h4>
<p>首先，对词 t 建立一个ego-network
G，然后使用网络聚类，用聚类去解释词t的各个语义（sense）。同样的语义一般会紧密相连，反之则认为语义不同。</p>
<p>具体算法如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-fe70825abc553f41.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/593/format/webp" /></p>
<p>每一次迭代从相关图T中取一个词t，首先，取与t语义最相近的N个词作为结点V构建ego-network
G（图中不含t）；然后，对于G中的每个结点v在T中寻找与之最相近的n个词V'，并建立v到v'的边；最后，使用Chinese
Whispers算法（不需要超参数）对ego-network聚类。输出是多个簇，每个聚St包含它的N个最近邻。</p>
<p>算法中有三个超参数：N是ego-network的大小；n是v近邻的最大连接数，k是簇中元素的最小个数。参数n决定了描述的细化程度(n越大关系越密)。经验值是N=200,
n为50,100或200，k为5或15(k越小越细分)。</p>
<p>每个词在义群里都有权重，其权重是该词与歧义词t的距离。</p>
<p>综上，该方法是计算每个词t可能有几种意思，并对每种意思抽像成一个sense
vector（由其它词组成的list）表示。</p>
<h4 id="用词向量计算语义向量">用词向量计算语义向量</h4>
<p>为每一种词义归纳出一组语义向量。假设一个词义可能由多个词表示。</p>
<p>设W是训练语料中所有词的集合，Si={w1,...wn}
⊆W，Si是从前一步计算得到的语义簇，设一个函数vecw，用于将词映射到向量；函数γi
计算其在簇中的权重，分别使用两种方法计算语义向量。</p>
<p>不加权方法：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-87478addc37cae2a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/299/format/webp" /></p>
<p>加权方法：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d71e744b272746cd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/344/format/webp" /></p>
<p>加权结果如表1所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-3691356f9ddc731e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/527/format/webp" /></p>
<p>“桌子”一词既与家具相关，又与数据相关，而词义向量的邻域拆分后不同时与家具和数据相关（通过语义向理计算而非词向量）。</p>
<h2 id="词义消歧-1">词义消歧</h2>
<p>此部分介绍语义向量的具体用法：利用上下文进行语义消歧。<br />
设目标词为w，其上下文为C = {c1,...,ck}, 首先，将w映射成一系列的语义簇S
={s1,...,sn}，用两种方法来确定其在上下文中最确切的语义。</p>
<ul>
<li>方法一：计算基于上下文的语义概率</li>
</ul>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ce4ef894e12367d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/537/format/webp" /></p>
<p>右侧的公式实际上是一个sigmoid函数——将具体值转换成概率：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-0fb55f3c1fafde23.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/230/format/webp" /></p>
<p>sigmoid函数图像：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-e1ebe21e07c24a79.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/587/format/webp" /></p>
<p>公式中的c是<strong>上下文嵌入</strong>的均值，使用上下文均值来计算中心词的词义本身就类似于CBOW的基础方法。使用这种方法对随机词有较低的标量积，对上下文中出现的词有较高的标量积。</p>
<ul>
<li>方法二：基于计算中心词与上下文的相似度</li>
</ul>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-90809f0a03e71d03.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/551/format/webp" /></p>
<p>公式中的c是<strong>上下文词嵌入</strong>的均值，与方法一不同的是它不需要使用上下文嵌入，而只需要每个词的词嵌入（Word2Vec工具默认不保存上下文嵌入）。</p>
<p>为进一步提升效果，论文还使用了上下文过滤方法，比如上下文中一些词“chairs”"kitchen"可能对“table”的词义起到更重要的作用，具体算法如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-3bf288866ee10006.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/381/format/webp" /></p>
<p>其中f是上述公式中的计算方法，i为具体的语义簇，j是上下文中词的位置，对每一个词cj，计算它与各个词义的距离（如果cj有辨识度，上式的值就比较大），从而找到最具消歧能力的词。</p>
<h2 id="实验">实验</h2>
<p>分别在两个数据集上对模型进行评价，一个是用众包方式收集的带上下文的语义标注；一个是公用的SemEval数据集。</p>
<h3 id="twsi评测">TWSI评测</h3>
<p>主要评测不同参数对模型的影响。</p>
<p>TWSI是一个众包系统，其中包含1012个高频名词，每个词平均2.26个语义，提供145140个标注的句子。另外，它还提供一个清单，其中列出了所有可以替代该单词语义的词表。</p>
<p>数据分布是有偏的，其中79%指向最常用的语义，因此除了TWSI数据全集以外，还构造了无偏子集（balanced
subset），每个语义除它本身以外，有五个上下文词。</p>
<h4 id="评价方法">评价方法</h4>
<p>创建一个映射表用于对比预测值和标注值。语义被表征为一袋词向量，可用余弦相似度进行比较。每个归纳的语义对应一个最相似TWSI语义作为预测值，对比预测值和TWSI标注值，即可使用准确率、召回率等指标给模型打分。</p>
<h4 id="指标">指标</h4>
<p>为了方便比较，还定义了一些指标：</p>
<ul>
<li>归纳上界<br />
当该含义的映射存在时，定义归纳上界为理论上能达到的最佳值。<br />
</li>
<li>TWSI最高频<br />
TWSI数据集中某个词对应最高频的词义。<br />
</li>
<li>归纳最高频<br />
某个词归纳后，最大的聚簇。<br />
</li>
<li>随机语义<br />
从某个词语义中随机取一个作为baseline。</li>
</ul>
<h4 id="结果">结果</h4>
<p>表3展示了基于不同底层模型，在不同粒度下模型的表现：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-3d511a808578c499.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/724/format/webp" /></p>
<p>认为其能达到的最好情况是众包标注结果（TWSI）；可以看到粒度越细，表现越好；同时也可以看到语义个数（Sense）与识别性能成反比。</p>
<p>表4展示了有偏数据与校正数据，以及过滤的效果，结果是使用上下文中的两个词p=2过滤时效果最好。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a948c18652d4f55f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/727/format/webp" /></p>
<p>最终图3展示了实验结果：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-4d27c3388dbb13be.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/716/format/webp" /></p>
<p>实验对比了随机算法、基于概率的均值、加权重，基于相似度的加权值，加p=2过滤，最高频语义，以及理论最佳效果(upper
bound)。</p>
<h4 id="semeval-评测">SemEval 评测</h4>
<p>国际语义评测SemEval
是国际权威的词义消歧评测，文中使用了其中的任务13，用于与其它模型对比效果。</p>
<p>提供20个名词、20个动词和10个形容词。包含20-100个上下文单词，总共4664个上下文。</p>
<p>对比结果如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-c65d6f1ac7222bf5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/746/format/webp" /></p>
<h2 id="参考">参考</h2>
<p><a
href="https://links.jianshu.com/go?to=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F354136256">超全word
embedding论文总结</a><br />
<a
href="https://links.jianshu.com/go?to=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F26306795">秒懂词向量Word2vec的本质</a><br />
<a
href="https://links.jianshu.com/go?to=https%3A%2F%2Fblog.csdn.net%2Fxieyan0811%2Farticle%2Fdetails%2F82314042">知识图谱之WordNet</a><br />
<a
href="https://links.jianshu.com/go?to=https%3A%2F%2Fwww.cnblogs.com%2Fguolei%2Fp%2F3388123.html">ego-network概念</a><br />
<a
href="https://links.jianshu.com/go?to=https%3A%2F%2Farxiv.org%2Fpdf%2F1801.09536.pdf">A
Survey of Word Embeddings Evaluation</a><br />
<a
href="https://links.jianshu.com/go?to=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F344158120_A_Survey_on_Language_Models">A
Survey on Language Models</a><br />
<a
href="https://links.jianshu.com/go?to=https%3A%2F%2Fblog.csdn.net%2Fu011808673%2Farticle%2Fdetails%2F78644485">Chinese
Whisper 人脸聚类算法实现</a></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>知识表示</tag>
      </tags>
  </entry>
  <entry>
    <title>TorchVision</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/TorchVision/</url>
    <content><![CDATA[<h1 id="torchvision">TorchVision</h1>
<p>#Pytorch #图形图像</p>
<h3 id="说明">说明</h3>
<p>很多基于Pytorch的工具集都非常好用，比如处理自然语言的torchtext，处理音频的torchaudio，以及处理图像视频的torchvision。</p>
<p>torchvision包含一些常用的数据集、模型、转换函数等等。当前版本0.5.0包括图片分类、语义切分、目标识别、实例分割、关键点检测、视频分类等工具，如mask-rcnn功能也都包含在内了。mask-rcnn的pytorch版本最高支持torchvision
0.2.*，0.3.0之后就将mask-rcnn包含到tensorvision之中了。</p>
<h3 id="安装">安装</h3>
<p>torchvision安装非常方便。 $ pip install torchvision</p>
<p>但需要注意版本匹配：</p>
<pre><code>torch 1.1.0/1.1.0 + vision 0.2.* + CUDA 9  
torch 1.2.0/1.3.0 + vision 0.3.* + CUDA 10  
torch 1.2.0/1.3.0 + vision 0.4.* + CUDA 10  
torch 1.4.0 + vision 0.5.* + CUDA 10  </code></pre>
<p>高版本的torchvision提供更多的功能，但需要升级torch库，同时还需要与CUDA版本匹配，否则无法正常工作。从CUDA
9 升级成CUDA 10，还需要升级与CUDA
10匹配的显卡驱动，如nvidia-drivers-430。如果使用docker，则需要升级宿主机的显卡驱动。</p>
<h3 id="代码">代码</h3>
<p>由于源码中带有使用例程和训练模型的工具，建议下载源码。地址：<a
href="https://github.com/pytorch/vision">https://github.com/pytorch/vision</a></p>
<p>官方说明文档： <a
href="https://pytorch.org/docs/master/torchvision/">https://pytorch.org/docs/master/torchvision/</a></p>
<p>以目标检测为例，其源码在vision/torchvision/models/detection目录下，内容与maskrcnn_benchmark非常相似，同时还做了一些简化。</p>
<h3 id="例程">例程</h3>
<p>下面使用预训练的模型识别图片中的物体：</p>
<pre><code>import torch  
import torchvision  
from PIL import Image  
import torchvision.transforms as transforms  
  
device = torch.device(&#39;cuda&#39;) if torch.cuda.is_available() else torch.device(&#39;cpu&#39;)  
model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)  
model.to(device)  
model.eval()  
  
loader = transforms.Compose([  
 transforms.ToTensor()])  
image = Image.open(None).convert(&#39;RGB&#39;)  
image = loader(image)  
image = image.to(device, torch.float)  
x = [image]  
  
predictions = model(x)  
print(predictions)  </code></pre>
<h3 id="fine-tune目标检测模型">Fine-tune目标检测模型</h3>
<p>之前笔者尝试使用Mask-RCNN官方的TensorFlow和Pytorch版本实现目标识别和图片分割的Fine-tune。与之相比，TorchVision更加简单。</p>
<p>无论使用何种工具，Fine-tune都以调库为主，比较复杂容易出错的是构造数据文件，在尝试过程中，要么就需要下载大量的数据，比如COCO数据集，要么需要标注和调试自己的数据，在外围工作上花费大量时间。</p>
<p>“行人检测”是“PyTorch官方教程中文版”中的fine-tune实例，全部代码100多行，数据也只有100多张图片，从例程中可以看到，自己做数据类，比下载COCO数据训练更加方便。如果使用GPU，如1080ti，十次迭代在十分钟以内即可完成。具体请见：
http://www.pytorch123.com/FourSection/ObjectDetectionFinetuning/</p>
<p>如需训练模型，则要下载git源码，其中的references目录中提供了一些训练使用的工具和例程。上述例程需要在源码的references/detection目录下运行，训练数据也需要放在该目录下。另外，需要注意分类的第0个索引是背景，在不同任务中，类别号可能需要做+1处理。</p>
]]></content>
      <tags>
        <tag>图形图像</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>图像处理之_ARToolKit自定义Marker</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B9%8B_ARToolKit%E8%87%AA%E5%AE%9A%E4%B9%89Marker/</url>
    <content><![CDATA[<h1
id="图像处理之_artoolkit自定义marker">图像处理之_ARToolKit自定义Marker</h1>
<p>#图形图像</p>
<h3 id="制作marker">1. 制作marker</h3>
<p> ARToolKit支持两种标记，一种是黑白图，另一种是普通图。
黑白图使用工具mk_patt制作，它有一些硬性的规定，比如必须是黑白图，正方形，且有边框等等。</p>
<p> 普通图更灵活，它可以是我们生活中的图像，比如公交卡，身份证等等，但相对黑白图，不那么容易识别，其原理主要是根据图片上的边缘，识别其中的一些点，把这些点之间的关系保存下来，并在摄像机图片中寻找对应的关系，以实现图片识别和跟踪，本文主要介绍操作普通图。</p>
<p> ARToolKit入门文档请见： <a
href="https://www.jianshu.com/writer#/notebooks/12122851/notes/38418999">图像处理之_增强现实工具ARToolKit</a></p>
<h3 id="用普通图片制作marker">2. 用普通图片制作marker</h3>
<p><strong>(1) 拍一张工交卡的相片，只留前景</strong></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-6e4321f18ef1fef7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><strong>(2) 计算特征点</strong></p>
<pre><code>$ bin/genTexData /tmp/card.jpg  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-1f4aa831a42c6156.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 置换时需要输入几个参数，我设置的参数如上图所示，尽量多取特征点，并把DPI范围设大，以达到更好的识别效果。</p>
<p><strong>(3) 查看特征点</strong></p>
<pre><code>$ bin/dispFeatureSet /tmp/card.jpg  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-1a542be52f1dc114.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 可以看到边缘大多被识别到了，对比度越强的边缘识别越好。</p>
<p><strong>(4) 修改设置</strong></p>
<pre><code>$ cp /tmp/card.* share/nftSimple/DataNFT/  
$ vi share/nftSimple/Data2/markers.dat 将../DataNFT/pinball改为../DataNFT/card  
$ bin/ntfSimple  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-667ee6e856df40a6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
]]></content>
      <tags>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>图像处理之_OpenCV入门</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B9%8B_OpenCV%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h1 id="图像处理之_opencv入门">图像处理之_OpenCV入门</h1>
<p>#图形图像</p>
<h2 id="带着问题看opencv">1. 带着问题看OpenCV</h2>
<h4 id="实现了哪些功能如何调用">1) 实现了哪些功能，如何调用？</h4>
<p>OpenCV实现了图像处理（类似PhotoShop），校正，分割前景背景，视频监控，运动跟踪，人脸识别，手势识别等功能，并支持机器学习算法。和很多开源工具一样，它提供的是很基础的功能。程序开发者利用基本函数的组合，适配场景，实现具体功能。它本身只是一个工具集，不是具体问题的解决方案。<br />
只在应用层面调用的话，知道基本的数据结构，函数接口，就可以了。</p>
<h4 id="如何应用数学知识">2) 如何应用数学知识？</h4>
<p>可以把学习OpenCV看做应用“数学”的过程，空间，矩阵，微积分，统计等工具都在其中使用。图像处理是应用数学较多的领域，具体实现可以通过源码看到，更重要的是了解数学方法的具体用途，才能举一反三。<br />
了解其中的数学方法，是较深入的层面，如果大学数学都已经忘记了，就很容易卡住，或者似乎明白了，又似乎不明白。不妨把它作为一个切入点，带着这些问题去看数学书，然后会发现数学很有用。OpenCV还有一个好处是，它能很直观地看到操作之后的效果，用实例理解抽象的概念。</p>
<h4 id="如何组织和处理视觉信息">3) 如何组织和处理视觉信息？</h4>
<p>OpenCV在数据存储，压缩，快速处理，数据共用等方面的很多技术很值得借鉴，主要是围绕其原始数据和特征值展开。详见其数据结构，函数，以及流程。<br />
视觉信息对于三维空间，只是单个侧面的投射，想还原真实场景，还需要更多先验知识。虽然OpenCV中自带机器学习功能，可以训练对人脸手势的识别，以及测距等等，这些也只是功能点，而未连成面，好像并没有一套逻辑去存储和处理三维空间。<br />
和人对视觉信息的处理，还差得非常远，基本没有可比性。只实现的眼睛的功能，缺少脑子的功能，人工智能训练出来的又往往“不可道，不可名”，在中间还有个断档，比如说分解子任务，总结和存储背景知识等等（个人看法）。</p>
<h2 id="简介">2. 简介</h2>
<h4 id="使用">1) 使用</h4>
<p>OpenCV采用C/C++编写，还提供了Phthon，Ruby，MATLAB，Android接口。</p>
<h4 id="协议">2) 协议</h4>
<p>OpenCV基于BSD协议，可商用，且不强制开放改善后的源码。</p>
<h4 id="组成具体见源码目录">3) 组成（具体见源码目录）</h4>
<ol type="i">
<li><pre><code>        基本数据结构（CXCore）  </code></pre></li>
<li><pre><code>        图像处理和算法（CV）  </code></pre></li>
<li><pre><code>        机器学习（ＭL）  </code></pre></li>
<li><pre><code>        外部支持：图像视频输入/输出（HighGUI）  </code></pre></li>
</ol>
<h2 id="ubuntu系统安装opencv">3. Ubuntu系统安装OpenCV</h2>
<h4 id="简单安装">1) 简单安装</h4>
<pre><code>$ sudo apt-get install libcv-devapt-get  </code></pre>
<p>自动安装了libcv-dev的所有依赖库，比较省事。</p>
<p>####2) 源码安装<br />
相对麻烦，但是可以看到源码和例程<br />
i. 下载<br />
http://wiki.opencv.org.cn/index.php/Download<br />
下载最新的Android和Linux版本<br />
ii. 安装</p>
<pre><code>$ unzip opencv-3.2.0.zip  
$ cd opencv-3.2.0/  
$ mkdir release  
$ cd release$ cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local ..  
$ make  
$ sudo make install  </code></pre>
<ol start="3" type="i">
<li><pre><code>        编译和试用  </code></pre>
例程OpenCV源码目录/samples/cpp目录下的例程，编译后可以直接执行看效果<br />
</li>
</ol>
<pre><code>$ cd ../../samples  
$ mkdir release  
$ cd release  
$ cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local ..  
$ make  
$ ./cpp/cpp-example-ffilldemo  </code></pre>
<h2 id="例程">4. 例程</h2>
<h4 id="功能">1) 功能</h4>
<p>显示一幅图片（最基本的流程，大多数变换都可在此基础上通过添加函数实现）</p>
<h4 id="代码">2) 代码</h4>
<pre><code>#include &lt;stdio.h&gt;  
#include &lt;iostream&gt;  
#include &lt;opencv2/imgproc.hpp&gt;  
#include &lt;opencv2/highgui.hpp&gt;  
   
  
using namespace cv;  
using namespace std;  
   
  
int main( int argc, char** argv )  
&#123;  
   string imagename = argv[1];  
   Ptr&lt;IplImage&gt; iplimg(cvLoadImage(imagename.c_str()));  
   if(!iplimg)  
    &#123;  
       fprintf(stderr, &quot;Can not load image %s\n&quot;, imagename.c_str());  
       return -1;  
    &#125;  
   namedWindow(&quot;image&quot;, WINDOW_AUTOSIZE);  
   cvShowImage(&quot;image&quot;, iplimg);  
   waitKey();  
   return 0;  
&#125;  </code></pre>
<h4 id="编译执行">3) 编译执行</h4>
<pre><code>$ g++ test.cpp -o test `pkg-config --cflags --libs opencv`  
$ ./test  </code></pre>
<h2 id="参考">5. 参考</h2>
<p>《学习OpenCV》中文版（清华大学出版杜）</p>
]]></content>
      <tags>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>图像处理之_仿射变换与透视变换</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B9%8B_%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2%E4%B8%8E%E9%80%8F%E8%A7%86%E5%8F%98%E6%8D%A2/</url>
    <content><![CDATA[<h1
id="图像处理之_仿射变换与透视变换">图像处理之_仿射变换与透视变换</h1>
<p>#图形图像</p>
<h2 id="仿射变换">1. 仿射变换</h2>
<h4 id="用途">1) 用途</h4>
<p>旋转 (线性变换)，平移(向量加)．缩放(线性变换)，错切，反转</p>
<h4 id="方法">2) 方法</h4>
<p>仿射变换是一种二维坐标到二维坐标之间的线性变换，它保持了二维图形的“平直性”（直线经过变换之后依然是直线）和“平行性”（二维图形之间的相对位置关系保持不变，平行线依然是平行线，且直线上点的位置顺序不变）。任意的仿射变换都能表示为乘以一个矩阵(线性变换)，再加上一个向量
(平移) 的形式．</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-41716a2c41c0d355.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>以上公式将点(x,y)映射到(x’,y’)，在OpenCV中通过指定一个2x3矩阵实现此功能（公式中的m矩阵，是线性变换和平移的组合，m11,m12,m21,m22为线性变化参数，m13,m23为平移参数，其最后一行固定为0,0,1，因此，将3x3矩阵简化为2x3）</p>
<h4 id="举例">3) 举例</h4>
<ol type="a">
<li><pre><code>   以原点为中心旋转，2x3矩阵为：  </code></pre></li>
</ol>
<pre><code>[ cos(theta), -sin(theta), 0 ],  
[ sin(theta), cos(theta), 0 ]  
则  
x’ = x * cos(theta) - sin(theta) * y  
y’ = x * sin(theta) + cos(theta) * y  </code></pre>
<ol start="2" type="a">
<li><pre><code>  平移，2x3矩阵为   </code></pre></li>
</ol>
<pre><code>[1,0,tx],  
[0,1,ty]  
则  
x’ = x * 1 + y * 0 + tx = x + tx  
y’ = x * 0 + y * 1 + ty = y + ty  </code></pre>
<h4 id="具体应用">4) 具体应用</h4>
<p>在OpenCV中，仿射变换通过函数cvWrapAffine(src,dst,mat)实现，其中mat是2x3的仿射矩阵，该矩阵可以利用函数cvGetAffineTransform(srcTri,dstTri,mat)得到，其中mat是被该函数填充的仿射矩阵，srcTri和dstTri分别是由三个顶点定义的平行四边形（由于是平行四边形，只需要指定三个顶点即可确定），即：给出变换前的ABCD和变换后的A’B’C’D’</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-796ead91abed032c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<h2 id="透视变换投影变换">2. 透视变换（投影变换）</h2>
<h4 id="用途-1">1) 用途</h4>
<p>将2D矩阵图像变换成3D的空间显示效果，全景拼接．</p>
<h4 id="方法-1">2) 方法</h4>
<p>透视变换是将图片投影到一个新的视平面，也称作投影映射．它是二维（x,y）到三维(X,Y,Z)，再到另一个二维(x’,y’)空间的映射．相对于仿射变换，它提供了更大的灵活性，将一个四边形区域映射到另一个四边形区域（不一定是平行四边形）．它不止是线性变换．但也是通过矩阵乘法实现的，使用的是一个3x3的矩阵，矩阵的前两行与仿射矩阵相同(m11,m12,m13,m21,m22,m23)，也实现了线性变换和平移，第三行用于实现透视变换．</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-09ebc9ea95c24c48.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>以上公式设变换之前的点是z值为1的点，它三维平面上的值是x,y,1，在二维平面上的投影是x,y，通过矩阵变换成三维中的点X,Y,Z，再通过除以三维中Ｚ轴的值，转换成二维中的点x’,y’.从以上公式可知，仿射变换是透视变换的一种特殊情况．它把二维转到三维，变换后，再转映射回之前的二维空间（而不是另一个二维空间）．</p>
<h4 id="具体应用-1">3) 具体应用</h4>
<p>在OpenCV中，透视变换通过函数cvWrapPerspective(src,dst,mat)实现,
与仿射变换不同的是，透视矩阵是一个3x3的矩阵，在计算矩阵时，可利用函数cvGetPerspectiveTransform(srcQuad,dstQuad,mat)，由于不再是平行四边形，需要提供四边形的四个顶点</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-371c100008f8a0cf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<h2 id="区别">3. 区别</h2>
<p>仿射变换后平行四边形的各边仍操持平行，透视变换结果允许是梯形等四边形，所以仿射变换是透视变换的子集</p>
]]></content>
      <tags>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>图像处理之_傅立叶变换</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B9%8B_%E5%82%85%E7%AB%8B%E5%8F%B6%E5%8F%98%E6%8D%A2/</url>
    <content><![CDATA[<h1 id="图像处理之_傅立叶变换">图像处理之_傅立叶变换</h1>
<p>#图形图像</p>
<h2 id="图像处理中的傅立叶变换">1. 图像处理中的傅立叶变换</h2>
<p>将一幅图像从其空间域（spatial domain）转换为频域（frequency
domain）。图像处理用到的主要是离散傅立叶变换（Discrete Fourier
Transform），下文中简称DFT。</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-f37b410f6f9e65c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>如上图所示，左边是原始图像（左白右黑），中间是DFT变换，右侧为变换后生成的频谱图（幅度相位共同决定了图中点亮度）。<br />
上图展示了红色点(x,y)的变换，在纵轴方向，它所在的列颜色值都为0（黑色），因此组成它的波形也能量也都为0，在横轴方向，如中间图所示，左则为255（白色），右则为0（黑色），将其拆分成正弦波的组合，再利用拆分后的各个波的幅度（亮度）相位（亮度）以及频率大小（位置）生成频谱图（上图中简化了相位）。<br />
原始图中的每个像素点，是由不同频率波投射在该点的能量叠加而成的，而频谱图中的每个点是原始图中每个像素点在该频率上的能量叠加而成的。它们之间都是一对多的关系，不存在一一对应。</p>
<h2 id="如何理解公式">2. 如何理解公式</h2>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-565d314268378100.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>以上公式分别是一维和二维DFT的定义（摘自《学习OpenCV》），先看看一维DFT公式，其中x0…xN-1是Ｎ个复数，它是原始数据，如音频数据中的每一帧，图像的像素点的灰度等，f是映射到频域后的值，也是复数．下标n是x的变化范围，下标k是f的变化范围．二维空间公式同理．<br />
图像对应的二维空间举例：把一个256x256像素（Ｎx=256，Ny=256，共65536个点，每一点视为x，其值为亮度）的灰度图转换到频域，得到的也是一个256x256的矩阵，矩阵中的每个点都是复数（每一点视为f）．</p>
<h2 id="频域矩阵中的各个点的值怎么求">3.
频域矩阵中的各个点的值怎么求？</h2>
<p>每一个f点的值，都由所有的x点通过上述公式累加求得．</p>
<p>##4. 自然指数exp()的作用是什么？exp()和正弦/余弦波有什么关系？<br />
拆分点x在各个频率上的相位和幅度分量．exp()和正弦/余弦波的关系，详见欧拉公式：</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-ed6f42894063660e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<h2 id="如何描述频域中的值">5. 如何描述频域中的值</h2>
<p>描述频率三个重要属性是：频率高低、幅值、相位。<br />
输出的频域数据也由矩阵表示，其中每个点都是复数，实部和虚部分别对应幅值和相位，而该点在矩阵中的位置表示它的频率高低。</p>
<h2 id="怎么看dft变换后的输出图">6 . 怎么看DFT变换后的输出图 </h2>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-b831ab4de8fdf648.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>在很多例程中，变换后，都得到一个从中间到四周的放射状图形，如上图所示。<br />
右侧图就是频率分布图谱，其中越靠近中心的位置频率越低，越亮的位置代表该频率的信号振幅越大。示意图大多是经过频谱中心化之后的图，如：OpenCV的例程OpenCV/samples/cpp/dft.cpp．在该程序中可以看到调整象限的操作。即左上右下互换，右上左下互换。数字图像的二维DFT所得结果，左上角是直流成分（图像的平均灰度级），四个角周围对应于低频成分，中央部分对应于高频部分。通过象限调整后，低频位置被换到了中间，这称为频谱中心化。对显示的频谱图而言，我们知道中间是低频，周围是高频即可。低频对应图像大致轮廓，高频对应图像细节。<br />
一维DFT的系数对称(2N点的数据做DFT，变换系数关于N点位置对称，类似图5)。这是因为DFT的的变换基是对0～2π分析的，因为0到π和π到2π对称所以对称。二维可理解为两个一维的组合（见图1,2,3），因此它是从中心向四周扩散的。<br />
图像中的像素点与频谱中的点虽然大小一样，但并没有一一对应的关系（见图4）</p>
<h2 id="如何使用dft实现滤波">7. 如何使用DFT实现滤波</h2>
<p>图6中能量分布在中高频区，从原始上看，它的细节比较多，局部跳变明显（梯度大），可想见，组成它的波成也是在某一中高频波的能量更大，也就是说边缘越多，变化的剧烈程序，中高频波分量越多。<br />
滤波一般分为：低通（Low-pass）、高通（High-pass）、带通（Band-pass）。所谓高通就是保留图像中的高频成分，过滤低频成分，它类似于通过梯度求图像边缘。需要注意的是它过滤的是频率，而不是亮度。<br />
具体实现就是将图片转成频谱图，过滤某一部分后，再通过逆变换转成灰度图。</p>
<h2 id="图像的变换与频谱图">8. 图像的变换与频谱图</h2>
<p>图像的旋转平移等操作，只是位置变化，整体的亮度（能量）不变，但是在频谱图中却有差异。这是由于变换之后相位的差异，在频谱图上看到的点，实际是由幅度和相位共同算出的（见dft.cpp中的magnitude函数）</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-6b59fac9e1705fc4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<h2 id="dft与卷积">9. DFT与卷积</h2>
<p>利用DFT可以大大加快卷积运算的速度。卷积定理：空间域的卷积运算可以转换为频域的乘法运算。具体实现是将图片转换到频域，将卷积核也转换到频域，计算频域乘法，最后将乘积进行逆变换，转回空间域。<br />
一般只在卷积核比较大时，才使用该方法优化。</p>
<h2 id="对频域一些想法">10. 对频域一些想法</h2>
<p>把声音拆成正弦波比较好理解，声音是声波的叠加：不同高度，宽度，起始位置的波的叠加。比如弹奏“do”，发出的声音是琴弦振动的结果，弦的连续振动，必然是有规律的。人听到的是一系列基音和泛音组合的结果。声音是时域到频域的映射，维度是一，即y=f(x)，其中x是帧发生的时间，y是该帧强度的大小。我们可以通过切分出一个小的时间片
（do所在的时间段），把它拆分到频谱，找个它的各个基音和泛音，进行对比，重组等等后续处理，人声也是一样，当发出“啊“声音的时候，也是一系列振动引起的。频率是声音的局部特征，即从整条音频中切出“do”或”啊”的时间片段，求取其频谱。<br />
把一张画拆分成频率，首先把一张彩图拆成不同通道的灰度图，考虑单张灰度图的频谱。图片是空间到频域的映射，维度是二，即z=f(x,y)，其中x,y是像素点的坐标，z是灰度。我们认为像素点间的灰度变化（即梯度）是有规律的。比如画中，墙和窗相交边缘上的各个点，变化都差不多（变化快，梯度大，频率高），远处云与蓝天的边缘也有相似性（变化慢），在单色的区域，比如蓝天整体变化不大（无变化），多处具体共同的性质，也是视作一种重复，我们就把它提取为规律和特征。除了图像音频，还有很多地方都可以用到频域映射，只要是有规律的重复出现即可，进而通过频谱分析，什么东西重复出现最多？它背后原因是什么？</p>
<h2 id="参考">11. 参考</h2>
<ol type="1">
<li><p>图像傅里叶变换<br />
<a
href="http://blog.csdn.net/abcjennifer/article/details/7622228">http://blog.csdn.net/abcjennifer/article/details/7622228<br />
</a></p></li>
<li><p>理解深度学习中的卷积<br />
<a
href="http://www.jiqizhixin.com/article/2558">http://www.jiqizhixin.com/article/2558<br />
</a></p></li>
<li><p>(精心整理)图像的傅里叶变换<br />
<a
href="https://wenku.baidu.com/view/c5e2cca8fab069dc502201db.html">https://wenku.baidu.com/view/c5e2cca8fab069dc502201db.html<br />
</a></p></li>
<li><p>傅里叶分析之掐死教程（完整版）<br />
<a
href="https://zhuanlan.zhihu.com/p/19763358?columnSlug=wille">https://zhuanlan.zhihu.com/p/19763358?columnSlug=wille<br />
</a></p></li>
<li><p>如何通俗易懂地解释欧拉公式<br />
<a
href="http://www.matongxue.com/madocs/8.html">http://www.matongxue.com/madocs/8.html<br />
</a></p></li>
</ol>
]]></content>
      <tags>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>图像处理之_卡尔曼滤波</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B9%8B_%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2/</url>
    <content><![CDATA[<h1 id="图像处理之_卡尔曼滤波">图像处理之_卡尔曼滤波</h1>
<p>#图形图像 #数学</p>
<h2 id="用途">1. 用途</h2>
<p>根据一些已知的量来预测未知的量。常用于运动预测。</p>
<h2 id="定义">2. 定义</h2>
<p>卡尔曼滤波（Kalman
filtering）一种利用线性系统状态方程，通过系统输入输出观测数据，对系统状态进行最优估计的算法。<br />
由于观测数据中包括系统中的噪声和干扰的影响，最优估计也可看作是滤波过程，因此叫作卡尔曼滤波。</p>
<h2 id="原理分析">3. 原理分析</h2>
<h4 id="第一部分预测值与误差">1) 第一部分：预测值与误差</h4>
<ol type="a">
<li><pre><code>   假设你和我两个人每天给同一头猪测体重，但两个称都不准。你测x1斤，正负误差在σ1斤左右（假设预测成高斯分布，标准差反映了测量值好坏程度的不确定性），我测x2斤，正负误差在σ2斤左右。结合两个人的预测，简单计算猪的体重是x1和x2的平均值。  </code></pre></li>
</ol>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-c06167b92328b4bc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<ol start="2" type="a">
<li><pre><code>  假如我的称更准，即误差更小，σ2&lt;σ1，结合两个人的测量，应该以我为主，因此根据误差加权组合。  </code></pre></li>
</ol>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-e2ac4bdfbd6b6d6b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>（通过概率函数导数的最大值推出上述公式，不在此详述）<br />
由公式可知：如果你的不确定性σ1越大，我的测量值x2在新均值中占的比例越大（权值更大）。<br />
c)
后来你走了，用上一次的加权平均（x1<sup>,σ1</sup>）替代你的测量，我的测量值仍是（x2,
σ2）（此后我们把加权平均的结果称为预测值）。同样采取加权平均的算法，算出本次预测值（x2<sup>,σ2</sup>），这是一个迭代的过程。通过化简得到以下公式：</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-0b5f303131076f99.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>请注意，现在公式中的1,2不再代表你和我，而代表时间点，带<sup>的为预测值，不带</sup>的为测量值。也就是说新的预测值（x2^,
σ2<sup>）由前一个预测值（x1</sup>, σ1^）和本次测量值（x2,
σ2）求得。为简化公式引入更新率Ｋ，即卡尔曼增益(Kalman
Gain)。将公式简化为以下形式：</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-293b147f51c3c7a2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>从简化之后的公式可知，K是由误差算出的，K用于预测新的x和误差σ。由公式可知：前次预测的不确定性σ1^越大，K越大，我的预测x2越重要。<br />
d)
综上，我们已经看到了最简单（单值且预测与测量的值相同）情况下的测量值与前次的预测值，是如何预测之后的值x与误差σ的，下面我们将它推广到更复杂的情况。</p>
<h4 id="第二部分如何预测">2) 第二部分：如何预测</h4>
<ol type="a">
<li><pre><code>   已知当前点的状态，如何预测下一时间点的状态。  </code></pre>
首先要考虑猪前一天的状态Xk-1，猪的成长变化，正常情况下每天长两斤（F）；它每跑步一圈减半斤（B），某天可能跑（uk）圈；还要考虑天气等不可控外力（wk）。因此，猪从第k天的体重Xk由下式预测：</li>
</ol>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-bd07310a91fe435b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>总之，想预测他的未来，先要知道它之前的状态，自身成长系数，培养教育，对培养教育的反应，以及不可控的机遇，哈哈，好像人一样。<br />
b)
后来，称猪的称丢了，现在只有一个尺子，我们通过量猪腰围Zk。然后乘以系数Hk，来估计猪的体重，同时还要考虑尺子的测量误差vk。</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-b3adb72204b29d1c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>此时，测量值和预测值已经不是同一属性了。<br />
c)
再后来，发现只量腰围还不够，还需要量身高，也就是说Zk不再是单一变量，而是一组向量，此时H就变成了一个矩阵，用于转换测量维度z和预测维度x。<br />
同理我们可能预测更多的x状态，比如猪的大小，体脂；另外影响猪长肉的外在因素也不只跑圈，可能还有喂食多少。上述公式就从一维扩展到了N维。<br />
公式中的F,B,H,w,v是一维到多维矩阵。x ,u,
z是一维到多维向量。但本质没变，都是通过测量值和之前预测值的误差，求卡尔曼增益，然后进行下一次预测。<br />
d) 综上，引出卡尔曼方程如下：</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-61d08128979e4d24.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>xk是k时刻的系统状态，是一个n维状态向量。<br />
F是传递矩阵，它是一个nxn的矩阵，描述的是xk-1与xk间变化的关系。它是变化的内因。<br />
uk是k时刻的控制输入，它是变化的外因，它由c维向量组成。<br />
B是控制矩阵，它是一个nxc的矩阵，它是变化的外因。<br />
wk是过程噪声，它是具有高斯分布的随机事件，nxn的协方差矩阵。<br />
zk是k时刻的测量值，是一个m维状态向量。<br />
Hk是测量矩阵，它是mxn的矩阵。描述的是Xk与Zk间的关系。<br />
Vk是测量误差，它是具有高斯分布的随机事件，mxm的协方差矩阵。</p>
<h4 id="第三部分复杂的多维数据代入加权平均算法">3)
第三部分：复杂的多维数据代入加权平均算法</h4>
<ol type="a">
<li><pre><code>   至此我们看到了x和x^是如何变化的，下面来考虑σ以及K  </code></pre></li>
</ol>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-cec75091364d57a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>Xk^是对Xk的预测，对应第一部分中的x。<br />
Pk^是误差协方差矩阵，对应第一部分中的误差σ。<br />
Qk-1是过程噪声。<br />
Kk是卡尔曼增益。<br />
Rk是测试噪声。</p>
<h2 id="相关程序">4. 相关程序</h2>
<p>在opencv中使用kalman预测的效果，可通过例程opencv/samples/cpp/kalman.cpp调用。<br />
程序基本分为三个部分：初始化，预测，更新。在初始化时，我们先指定传递矩阵，控制矩阵，测量矩阵，噪声矩阵；迭代过程中通过测量值更新；预测新的状态。<br />
Kalman的具体实现，请参考程序opencv/modules/video/src/kalman.cpp，下面是其预测和更新部分（对应第三部分的公式）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">const Mat&amp; KalmanFilter::predict(constMat&amp; control)  </span><br><span class="line">&#123;  </span><br><span class="line">   CV_INSTRUMENT_REGION()  </span><br><span class="line">   </span><br><span class="line">   // update the state: x&#x27;(k) = A*x(k)，通过xk-1^预测xk^  </span><br><span class="line">   statePre = transitionMatrix*statePost;  </span><br><span class="line">   </span><br><span class="line">   if( !control.empty() )  </span><br><span class="line">       // x&#x27;(k) = x&#x27;(k) + B*u(k)，计算外因影响：控制矩阵  </span><br><span class="line">       statePre += controlMatrix*control;  </span><br><span class="line">   </span><br><span class="line">   // update error covariance matrices: temp1 = A*P(k)  </span><br><span class="line">   temp1 = transitionMatrix*errorCovPost;  </span><br><span class="line">   </span><br><span class="line">   // P&#x27;(k) = temp1*At + Q，更新误差Pk^  </span><br><span class="line">   gemm(temp1, transitionMatrix, 1, processNoiseCov, 1, errorCovPre,GEMM_2_T);  </span><br><span class="line">   </span><br><span class="line">   // handle the case when there will be measurement before the nextpredict.  </span><br><span class="line">   statePre.copyTo(statePost);  </span><br><span class="line">   errorCovPre.copyTo(errorCovPost);  </span><br><span class="line">  </span><br><span class="line">    //至此可以看到，预测后得到了xk^，以及误差Pk^  </span><br><span class="line">   return statePre;  </span><br><span class="line">&#125;  </span><br><span class="line">   </span><br><span class="line">const Mat&amp; KalmanFilter::correct(constMat&amp; measurement)  </span><br><span class="line">&#123;  </span><br><span class="line">   CV_INSTRUMENT_REGION()  </span><br><span class="line">   </span><br><span class="line">   // temp2 = H*P&#x27;(k)  </span><br><span class="line">   temp2 = measurementMatrix * errorCovPre;  </span><br><span class="line">   </span><br><span class="line">   // temp3 = temp2*Ht + R  </span><br><span class="line">   gemm(temp2, measurementMatrix, 1, measurementNoiseCov, 1, temp3,GEMM_2_T);  </span><br><span class="line">   </span><br><span class="line">   // temp4 = inv(temp3)*temp2 = Kt(k)  </span><br><span class="line">   solve(temp3, temp2, temp4, DECOMP_SVD);  </span><br><span class="line">   </span><br><span class="line">   // K(k)，卡尔曼增益K  </span><br><span class="line">   gain = temp4.t();   </span><br><span class="line">  </span><br><span class="line">   // temp5 = z(k) - H*x&#x27;(k)，见第一部分中的x2-x1^  </span><br><span class="line">   temp5 = measurement - measurementMatrix*statePre;  </span><br><span class="line">   </span><br><span class="line">   // x(k) = x&#x27;(k) + K(k)*temp5，计算xk-1^  </span><br><span class="line">   statePost = statePre + gain*temp5;  </span><br><span class="line">   </span><br><span class="line">   // P(k) = P&#x27;(k) - K(k)*temp2，计算误差  </span><br><span class="line">   errorCovPost = errorCovPre - gain*temp2;  </span><br><span class="line">   </span><br><span class="line">   return statePost;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>数学</tag>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>图像处理之_增强现实工具ARToolKit</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B9%8B_%E5%A2%9E%E5%BC%BA%E7%8E%B0%E5%AE%9E%E5%B7%A5%E5%85%B7ARToolKit/</url>
    <content><![CDATA[<h1
id="图像处理之_增强现实工具artoolkit">图像处理之_增强现实工具ARToolKit</h1>
<p>#图形图像</p>
<h3 id="增强现实">1. 增强现实</h3>
<p> 增强现实（AR）是将电脑虚拟的图像覆盖到真实世界画面中，这个技术在工业和理论研究方面都存在着极大的潜能。</p>
<h3 id="相关概念">2. 相关概念</h3>
<p><strong>(1) ARToolkit</strong></p>
<p> ARToolkit，是一个开源的AR(增强现实)SDK。它是用C/C++
语言编写的库，通过它可以很容易地编写增强现实应用程序。
增强现实中最困难的部分在于实时的将虚拟图像覆盖到用户视口，并且和真实世界中的对象精确对齐。ARToolKit使用电脑图像技术计算摄像机和标记卡之间的相对位置，从而使程序员能够将他们的虚拟对象覆盖到标记卡上面。ARToolKit
提供的快速和准确的标记跟踪，能够让你快速的开发出许多更新更有趣的AR程序。</p>
<p><strong>(2) OpenGL</strong></p>
<p> OpenGL是 Open Graphics
Library，用于渲染2D、3D矢量图形的跨语言、跨平台的应用程序编程接口（API），可绘制从简单的图形到复杂的三维景象。</p>
<p><strong>(3) OpenCV</strong></p>
<p> OpenCV是 Open Source Computer Vision
Library。它提供图像处理和视频处理的基础算法库，还涉及一些机器学习的算法。比如实现视频的降噪、运动物体的跟踪、目标（比如人脸）的识别等。</p>
<p><strong>(4) 关系</strong></p>
<p> OpenCV专注于从采集到的视觉图像中获取信息，是用机器来理解图像；OpenGL是用机器绘制合适的视觉图像给人看，ARToolkit依赖OpenCV和OpenGL，虽然大多功能用OpenCV也能实现，但使用ARToolkit更加方便和高效。</p>
<h3 id="安装软件">3. 安装软件</h3>
<p><strong>(1) OpenGL</strong></p>
<pre><code>$ sudo apt-get install build-essential libgl1-mesa-dev  
$ sudo apt-get install freeglut3-dev  
$ sudo apt-get install libglew-dev libsdl2-dev libsdl2-image-dev libglm-dev libfreetype6-dev 上面提到的  </code></pre>
<p> mesa是一个软件实现的OpenGL功能，虽然慢，但在你的显卡或者系统不支持硬件加速时，它使程序还能运行。</p>
<p><strong>(2) OpenCV</strong></p>
<pre><code>$ wget http://sourceforge.net/projects/opencvlibrary/files/opencv-unix/3.1.0/opencv-3.1.0.zip  
$ unzip opencv-3.1.0.zip  
$ cd opencv-3.1.0/  
$ cmake  
$ make  
$ sudo make install  </code></pre>
<p> OpenCV也可使用apt安装，不过建议下载编译源码，源码中有很多示例可以参考，也能追进函数，查看其功能具体如何实现。</p>
<p><strong>(3) 安装ARToolKit</strong></p>
<pre><code>$ sudo apt install clang libc++-dev libc++1 libdc1394-22 libraw1394-dev libv4l-dev  
$ git clone [https://github.com/artoolkit/artoolkit5](https://github.com/artoolkit/artoolkit5)  
$ cd artoolkit5/  
$ ./Configure # 这步最重要，根据自己的环境设置，否则编不过   
$ make   </code></pre>
<p> 对于数据源，它支持gstreamer和V4L（Video For
Linux），这里我主要使用了V4L。另外还有一个小问题，编译时可能提示找不到opencv的头文件，我把它修改成了#include
&lt;opencv/cv.h&gt;。</p>
<h3 id="运行示例">4. 运行示例</h3>
<p> 还是在ARToolKit目录下，编译后运行</p>
<p><strong>(1) 校正摄像头</strong></p>
<p> calib_camera是校正摄像头的程序，代码在util/calib_camera目录下，编译后程序生成在bin目录下，运行此程序时，需要一个5x7的棋盘图，位置在./doc/patterns/Calibration
chessboard**.pdf，我用手机拍了一张相片，即可和摄像头配合使用，可以看到视频上出现了对棋盘位置的标注。</p>
<pre><code>$ ./bin/calib_camera  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-cdf27a750717cf9d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><strong>(2) 图片追踪示例</strong></p>
<p> nftSimple是图像追踪的示例，代码在examples/nftSimple目录下，只要在摄像头前移动该图片，三维的小方块就能跟着它移动，且能随之变换三维角度，也就是简单的增强现实效果。它所需要的Marker在./examples/ARAppNFTOSG/Markers/pinball.jpg，当然你也可以用工具制作
自己marker，用程序把jpg文件转换成set标注。</p>
<pre><code>$ ./bin/nftSimple  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-14931aca849b3819.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><strong>(3) 调试说明</strong></p>
<p> 太多东西累加到一起，遇到问题时，难以定位是opengl,
opencv还是artoolkit的问题。上面两个例程在调试的时候，屏幕上的标注和立体效果一开始出不来，看到一些ioctl的报错，怀疑是不是摄像头不支持某些功能引起的，后来又在opencv的源码里找相似的校正例程，怀疑是摄像头捕捉的图片和opencv支持的格式不一致（校正程序只支持1通道8位灰图），之后又在代码中把捕捉到的每帧图像存成jpg找线索。后来发现：需要在拍摄的第一帧中就出现maker——左手运行程序，右手举着图片，这也同样很奇怪，只能识别第一帧。</p>
<p> 最终看代码，AR2VideoBufferT帧数据有两种buff，一种是存储的是各通道颜色数据buff，另一种为亮度数据buffLuma，我们使用的主要是这个亮度数据，我在两台ubuntu笔记本上都遇到同一问题：默认情况下，buffLuma只在第一帧时更新，之后里面的内容就不变了，修改方法是改其源码lib/SRC/Video/video2.c，在ar2VideoGetImage函数中,
将"if (!ret-&gt;buffLuma)“判断去掉，在任何情况下都重新计算buffLuma。</p>
<h3 id="参考">5. 参考</h3>
<p><strong>(1) 制作marker和NFT</strong><br />
<a
href="https://www.cnblogs.com/polobymulberry/p/5905912.html">https://www.cnblogs.com/polobymulberry/p/5905912.html</a></p>
<p><strong>(2) ARToolKit例程及对应效果</strong><br />
<a
href="http://www.cnblogs.com/polobymulberry/p/5905680.html">http://www.cnblogs.com/polobymulberry/p/5905680.html</a></p>
<p><strong>(3) ARToolKit流程图</strong><br />
<a
href="http://www.mamicode.com/info-detail-2331367.html">http://www.mamicode.com/info-detail-2331367.html</a></p>
<p><strong>(4) 标准相机</strong><br />
<a
href="http://blog.sina.com.cn/s/blog_6e7e94bc0100m9jw.html">http://blog.sina.com.cn/s/blog_6e7e94bc0100m9jw.html</a></p>
]]></content>
      <tags>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>图像处理之_导数微分</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B9%8B_%E5%AF%BC%E6%95%B0%E5%BE%AE%E5%88%86/</url>
    <content><![CDATA[<h1 id="图像处理之_导数微分">图像处理之_导数微分</h1>
<p>#图形图像 #数学</p>
<h2 id="一阶导数应用图像的梯度">1. 一阶导数应用：图像的梯度</h2>
<h4 id="用途">1) 用途:</h4>
<p>在图像处理中, 常用梯度求取图像的边缘, 这是一个很基础的应用.
下图为在OpenCV中使用cvSobel()函数的具体效果. 四张图分别为: 原图,
在x方向上的梯度, y方向上的梯度, xy方向上的梯度.<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-d84d9947787a3bc3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" /></p>
<h4 id="二元函数">2) 二元函数</h4>
<p>这里我们只讨论二元函数z=f(x,y)的导数, 通常把二元函数想像成一个曲面,
公式中的x,y,z分别映射到坐标系中的x,y,z轴.
于是我们看到了很多像山坡一样的三维图, 切线, 切面,
很看来很复杂．我觉得从图像处理的角度看二元函数似乎更容易理解, 为了简化,
我们以一张黑白图为例. x,y轴分别对应成图像的宽和高, 颜色的灰度对应z值: z
= f(x,y)，每个像素点的颜色值是其坐标(x,y)的函数．<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-5937f480355baeb3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" /></p>
<h4 id="梯度的定义">3) 梯度的定义</h4>
<p>函数 z =
f(x,y)在区域D内具有一阶连续偏导数，则对于每一个属于D的点P(x,y)，都可定出一个向量，这个向量称为函数
z = f(x,y)在点P处的梯度．记作gradf(x,y). 一般通过求导(微分)来实现的.
导数是函数的局部性质。描述了函数在某一点附近的变化率。</p>
<h4 id="离散图像的梯度">4) 离散图像的梯度</h4>
<p>由于图像是一个离散空间，无法求真正的导数，只能通过多项式拟合．图像中某一点的导数，就是该点在x方向和y方向上的变化率．图像梯度公式如下：gradf(x,y)
= dx i + dy j;dx(i,j) = I(i+1,j) - I(i,j); //
x方向偏导，近似为某行与其上一行的差值dy(i,j) = I(i,j+1) - I(i,j); //
y方向偏导，近似为某列与其上一列的差值其中，I是图像像素的值(亮度值)，(i,j)为像素的坐标。</p>
<h4 id="如何衡量梯度">5) 如何衡量梯度</h4>
<p>梯度就是某一点的变化率, 比如图像中的一点, 它可在多个方向上变化
(比如：上,下,左,右,左上,右下，各个角度…), 到底哪个方向上变化最大?
变化有大呢? 这就是梯度的两个重要量度：梯度的方向和梯度的值．梯度的方向:
函数f(x,y)在P(x,y)点增长最快的方向,
即方向导数中取到最大值的方向.梯度的值：方向导数的最大值．<br />
a) 方向导数<br />
如果函数z=f(x,y)在点P(x,y)是可微分的，那么函数在该点沿任一方向l的方向导数都存在，且有<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-b3ae1b9905c3989c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" /></p>
<p>其中φ为x轴到方向l的转角.<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-2caa1a0df19582b8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" /><br />
b) 梯度的模<br />
梯度是方向导数分别在x,y轴的投影（dx(i,j)，dy(i,j)）．梯度的模就是方向导数的值，用勾股定理求得.</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-66d45519435f1bd0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<ol start="3" type="a">
<li><pre><code>   梯度的方向  </code></pre>
x轴到l的转角的正切为</li>
</ol>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-580c292b46b4b319.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>已知x,y方向上的偏导, 再通过反正切, 就可以求出具体的角度(与x轴的夹角),
即梯度的方向．</p>
<h4 id="更复杂的情况">6) 更复杂的情况</h4>
<p>为简单说明，上面只考虑了一个象素与它上一行／上一列的差值，实际运算时，一般考虑以它为中心的NxN的小区域，小区域中各点权重不同，通过卷积计算（离得越远的点，权重越小），从而计算它各个方向上的变化．</p>
<h4 id="梯度图像">7) 梯度图像</h4>
<p>由图像上各点的梯度值构成的图像成为梯度图像, 往往放在另一个矩阵中,
看起来就是轮廓图, 即上面公式中的gradf(x,y)在各个x,y点上的值的序列.</p>
<h2 id="二阶导数应用拉普拉斯变换">2. 二阶导数应用：拉普拉斯变换</h2>
<h4 id="用途-1">1) 用途</h4>
<p>用于检测团块，边缘检测，突出图像中的孤立点、孤立线或线端点为目的的场合；图像的锐化操作（拉普拉斯变换后的图与原图叠加）</p>
<h4 id="方法">2) 方法</h4>
<p>对x和y方向求二阶偏导数，然后相加</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-25061763b1ca0e8d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>该方程的离散形式是</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-5e1b9bebf309c4cd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>为什么二阶导数这样离散成这种形式呢？以x方向为例（见下图），点与其邻近点的差导是一阶导数，如：(f(x+1,y)
- f(x,y) 和(f(x,y) -
f(x-1,y))一阶导数（梯度图像）的差异就是二阶导数(f(x+1,y) - f(x,y)) -
(f(x,y) - f(x-1,y)) = f(x+1,y) + f(x-1,y) –
2f(x,y)y方同理，即得出以上公式<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-0a77bc32e034409f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" /><br />
当在图像边缘作用时（例如，从暗到亮）我们可以观察到灰度值的上升必然意味着从正曲度（强度升高）到负曲度（强度达到瓶颈）的变化。因此，拉普拉斯变换结果从正到负（或者相反）组成了一个图像边沿的很好的指示器。另一种方法表达这个事实是说，边沿出现在拉普拉斯变换的过零点处。</p>
<h2 id="参考">3. 参考</h2>
<ol type="1">
<li><pre><code>        多元函数微分法及其应用《高等数学》下册，“方向导数与梯度”章节  </code></pre></li>
<li><pre><code>        图像处理中的拉普拉斯算子http://www.cnblogs.com/xfzhang/archive/2011/01/19/1939020.html</code></pre></li>
</ol>
]]></content>
      <tags>
        <tag>数学</tag>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>图像处理之_聚焦效果LogPolar</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B9%8B_%E8%81%9A%E7%84%A6%E6%95%88%E6%9E%9CLogPolar/</url>
    <content><![CDATA[<h1 id="图像处理之_聚焦效果logpolar">图像处理之_聚焦效果LogPolar</h1>
<p>#图形图像 #数学</p>
<h2 id="logpolar">1. LogPolar</h2>
<p>LogPolar是将笛卡尔坐标到对数极坐标的变换．即：将(x,y) 映射到
(log(ρ),θ)</p>
<h2 id="笛卡尔空间笛卡尔坐标">2. 笛卡尔空间＆笛卡尔坐标</h2>
<p>笛卡尔坐标系(Cartesiancoordinates)就是直角坐标系和斜角坐标系的统称．本文中用到的是平面直角坐标系．</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-f73f7aa62343774a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<h2 id="极坐标">3. 极坐标</h2>
<p>在平面上取一定点o，称为极点，由o出发的一条射线ox，称为极轴。再取定一个长度单位，通常规定角度取逆时针方向为正。这样，平面上任一点P的位置就可以用线段OP的长度ρ以及从Ox到OP的角度θ来确定，有序数对（ρ，θ）就称为P点的极坐标，记为P（ρ，θ）；ρ称为P点的极径，θ称为P点的极角。</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-d649aac21011d855.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<h2 id="笛卡尔坐标到极坐标变换">4. 笛卡尔坐标到极坐标变换</h2>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-57ad82df4fa6f383.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>在OpenCV中使用函数CartToPolar()实现．</p>
<h2 id="自然常数e欧拉数">5. 自然常数e（欧拉数）</h2>
<p>自然常数e（约为2.71828）其是公式为</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-232f24036d451b22.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<h2 id="对数定义">6. 对数定义</h2>
<p>若a^n=b(a&gt;0且a≠1)
则n=logab。其中，a叫做“底数”，b叫做“真数”，n叫做“以a为底的b的对数”。零和负数没有对数。在数学中，当不写底数时，一般默认以10为底数。在c语言函数中，log()是以e为底的对数，log10()是以10为底的对数。这里讨论的是以e为底的对数．log(20)
=&gt; e^n=20 =&gt; n=2.99　(自然对数)</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-ab8d2a9793975136.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>exp(2.99)=&gt; e^2.99 =&gt; 20 (自然指数)</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-18aec5465bd39806.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<h2 id="具体应用">7. 具体应用</h2>
<p>指数和对数的转换，可以理解为一种映射，以自然对数为例，x大幅变化，y将小幅变化，因此可将大幅变化投射到相对小的区域，从而简化运算．在图像处理中的应用，LogPolar将笛卡尔坐标系映射到对数极坐标系后，再做对数变换，原理是：人眼的视觉中心有很高的分辨率，但是随着离心距离的增大，分辨率不断降低。于是达到类似聚焦的效果．即视焦点区域清晰，外围逐渐模糊．LogPolar实现了类似变换，通过取对数操作弱化了焦点以外的区域，简化图像，以便进一步处理．</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-b0f8e5dac0cbbf57.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
]]></content>
      <tags>
        <tag>数学</tag>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>图像处理之_轮廓匹配</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B9%8B_%E8%BD%AE%E5%BB%93%E5%8C%B9%E9%85%8D/</url>
    <content><![CDATA[<h1 id="图像处理之_轮廓匹配">图像处理之_轮廓匹配</h1>
<p>#图形图像 #数学</p>
<h2 id="引子">1. 引子</h2>
<p>图像识别可通过轮廓，直方图等方式实现，像人脸识别这种复杂应用，实现它的方法很多，通常是基础方法的改进版与机器学习组合。<br />
基于轮廓的识别，需要把图像拆分通道，寻找边缘，转换为轮廓（多边形逼近，特性概括等），然后进行轮廓匹配（图像与图像匹配，图像与模板匹配）。<br />
程序员根据不同情境，选择适合图像抽象方法和匹配方法。<br />
轮廓的匹配主要是解决大小，位置，旋转角度，精度不同图像间的匹配问题。方法包括轮廓矩，成对几何直方图，凸包和凸缺陷，等级匹配等等，下面以轮廓矩为例，看看它是如何实现的，同时也了解一下矩在图像处理中的应用（基于统计的方法）。</p>
<h2 id="是什么矩moment">2. 是什么矩（moment）</h2>
<p>数学定义：实函数相对于值c的n阶矩为</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-4903ab807f65a970.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>从上述公式可以看到，它就是一个加了权重的积分，而权重是(x-c)<sup>n，其中n是阶数（n阶矩），如果把它想成一个平面直角系中，c是x轴上的一点，(x-c)</sup>n是各个x点相对于c点值的n次方。以下是个积分的图示，只要想象一下，它的每个小方块再乘上权重：(xi-c)^n即可得到矩。</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-085be1cf368197e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>轮廓处理中用到的矩，是它在统计学中的应用。<br />
以上公式是一元的情况，扩展到图片所在的二元，想象我们有一个图像矩阵，经过了寻找边缘，转换轮廓之后，矩阵中每个值点f(x,y)的值或为0（不是轮廓点），或为1（是轮廓点），当f(x,y)为0时，该积分项也为0，可以不计算，因此，对我们有意义的只有f(x,y)=1的n个点，即轮廓点。在后面公式中记为I(x,y)，x,y为其在图中的坐标，c点扩展到二元，可以视为轮廓的中心点，我们求得的所谓n阶中心矩，就如上述公式所示，积分的权重是轮廓上各点相对于中心位置c的n次方。<br />
此时我们可以得到一些统计规律，比如：轮廓边界长度（零阶矩），x/y方向上的均值（即质心，由一阶矩求得），方差（由二阶中心矩求得）,形状特性（Hu矩）</p>
<h2 id="常用的矩">3. 常用的矩</h2>
<h4 id="空间矩spatial-moment">1) 空间矩（spatial moment）</h4>
<ol type="i">
<li><pre><code>        用途  </code></pre>
最简单地轮廓比较，只能用于对比位置，大小，角度完全一致的轮廓。<br />
</li>
<li><pre><code>        公式  </code></pre></li>
</ol>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-08348fba48343d20.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>mpq表示图像的（p+q）阶矩，一般计算所有3阶的矩（p+q&lt;=3）。其中
I(x,y) 是象素点 (x, y)
的值，一般是1，n是轮廓上点的个数，p和q分别是x维度和y维度上的矩，即m00,m10,m01…m03。<br />
零阶矩m00是轮廓上点的简单累加，即轮廓上有多少个点 。<br />
一阶矩m10，m01分别是x和y方向上的累加<br />
iii. OpenCV相关函数<br />
cvContoursMoments()<br />
cvGetSpatialMoment()</p>
<p>####2) 中心矩（central moment）<br />
i. 用途<br />
xavg和yavg由一阶矩和零阶矩的比值算出（见公式），它是重心坐标，中心矩即是根据x,y与重心的相对位置求取的矩，它使得结果与图像相对于x,y轴的位置无关（与平移无关）。<br />
ii. 公式</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-8fba1da7f198962b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<ol start="3" type="i">
<li><pre><code>        OpenCV相关函数  </code></pre>
cvMoments()cvGetCentralMoment()</li>
</ol>
<p>####3) 归一化的中心矩<br />
i. 用途<br />
使用m00的幂对中心矩归一化，使得结果与图像大小无关<br />
ii. 公式</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-4bedd4da60e6f10c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<ol start="3" type="i">
<li><pre><code>        OpenCV相关函数  </code></pre>
cvGetNormalizedCentralMoment()</li>
</ol>
<p>####4) Hu不变矩<br />
i. 用途<br />
Hu矩是归一化中心矩的线性组合，它对于缩放，旋转，镜像映射具有不变性。<br />
ii. 公式</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-0fccdd56f28466b1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<ol start="3" type="i">
<li><pre><code>        OpenCV相关函数  </code></pre>
cvGetHuMents()cvMatchShapes()</li>
</ol>
<p>##4. 示例代码<br />
opencv/samples/cpp/tutorial_code/ShapeDescriptors/moments_demo.cpp</p>
]]></content>
      <tags>
        <tag>数学</tag>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>图像处理之_霍夫（Hough）变换</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B9%8B_%E9%9C%8D%E5%A4%AB%EF%BC%88Hough%EF%BC%89%E5%8F%98%E6%8D%A2/</url>
    <content><![CDATA[<h1 id="图像处理之_霍夫hough变换">图像处理之_霍夫（Hough）变换</h1>
<p>#图形图像</p>
<h2 id="用途">1. 用途</h2>
<p>Hough变换是一种在图像中寻找直线，圆及其它简单形状的方法．当我们对图像进行边缘检测之后，可用Hough变换识别图像中的简单形状．该转换也是对图像的一种抽象（由繁到简）．下面介绍最基本Hough变换：寻找直线算法．</p>
<h2 id="思路">2. 思路</h2>
<p>Hough变换通过从直角坐标系到极坐标系的转换，将直角坐标系中的一条＂直线＂，转换为极坐标系上的一个＂点＂，落在这条＂直线＂上的像素点越多，这个极坐标中＂点＂的权越重，最终通过分析各个＂点＂的权重（局部最大值），获取重要线段．为区别直角坐标系中的点和极坐标系中的点，下面我们将直角坐标系中的点称为像素点．</p>
<h2 id="具体实现">3. 具体实现</h2>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-899aa3597e75abbb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" /><br />
如图所示，假设我们有一个桃心图形，由多个红色像素点组成（红色为其有意义的像素点，即轮廓值），想提取出其中的直线．如果将各个像素点连成直线，直线将会有很多条，有些有意义，有些没意义．一般认为像素点足够多的直线更具意义，比如图中的绿色和蓝色的直线．在直角坐标系中，可以用斜截式y=kx+b来表示一条直线（k是斜率，b是y轴上的截距）．转换到极坐标系P（ρ，θ）；ρ称为P点的极径（从原点到直线的垂直距离，上图中的虚线），θ称为P点的极角（极径与x轴的夹角）．直角坐标系中的一条＂直线＂，可转换为极坐标系上的一个＂点＂（上图中的黑圈），也就是说：把直角坐标系中的多个像素点，对应成极坐标系中的一个点．落在该＂直线＂上的像素点越多，极坐标系中的该点的权重越大，通过比较权重，取得重要直线．</p>
<h2 id="总结">4. 总结</h2>
<p>Hough变换通过映射，将一个形状识别问题，转换成了一个统计问题，在寻找直线的过程中，将落入一条直线上的点映射成了极径和极角（二元），在寻找圆的过程中，将落入圆弧上的点映射成了圆心点坐标x,y与半径r的组合（三元），通过映射简化了数据描述，映射后的数据也可以作为图像的一种抽象特征进行其它运算．可其扩展到识别更复杂的形状，加入颜色更一步判断，以及利用基本形状之间的关系，层层抽象，组合出更加复杂的功能．</p>
]]></content>
      <tags>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>BEVFormer：通过时空Transformers从多摄像头图像学习鸟瞰图表示</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_BEVFormer/</url>
    <content><![CDATA[<h2 id="介绍">介绍</h2>
<p>英文题目：BEVFormer: Learning Bird's-Eye-View Representation from
Multi-Camera Images via Spatiotemporal Transformers<br />
中文题目：BEVFormer:
通过时空Transformers从多摄像头图像学习鸟瞰图表示<br />
论文地址：https://arxiv.org/pdf/2203.17270v1.pdf<br />
领域：机器视觉，自动驾驶<br />
发表时间：2022年3月<br />
作者：Zhiqi Li等<br />
出处：南京大学，上海人工智能实验室，香港大学<br />
代码和数据：https://github.com/zhiqi-li/BEVFormer<br />
阅读时间：2022.05.22</p>
<h2 id="读后感">读后感</h2>
<p>文中方法和特斯拉视频（<a
href="https://www.bilibili.com/video/BV1YU4y1F7UL?spm_id_from=333.337.search-card.all.click">特斯拉2021人工智能日AI
Day完整视频</a>）架构相似。比较有意思的地方是在<strong>BEV层面结合了时间和空间信息</strong>。</p>
<h2 id="介绍-1">介绍</h2>
<p>在3D感知领域，<strong>雷达</strong>已取得了很好效果，机器视觉近几年也受到关注，除了成本低，相对雷达，它还能感知远距离物体，以及识别道路标识。</p>
<p>BEV鸟瞰图从<strong>多个摄像头</strong>信息计算表征，用于描述周围场景。分割任务证明了BEV的有效性，但由于该方法基于深度信息生成BEV容易出错，所以在三维目标检测方面效果不显著。</p>
<p>另外，时间信息也很重要，比如车往前开的时候，现在被遮挡的物体，之前可能是能看到的。但是目前用到<strong>时序数据</strong>的不多，主要因为运动中的情况不断变化，不能通过简单堆叠前帧的方法来辅助当前预测。</p>
<p>文中提出了结合多摄像头和历史BEV特征的方法BEVFormer，如图-1所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220524103231.png"
alt="Pasted%20image%2020220524103231.png" /><br />
左图是<strong>BEV的网格图，即鸟瞰图</strong>，Ego是汽车本身，黑色方块是关注的物体；中图的交叉注意力结合了多个摄像头信息的空间信息；右图使用<strong>自注意力模型，结合了之前数据的BEV信息</strong>。以此来解决估计运动物体的速度和检测严重遮挡物体的问题。</p>
<h3 id="文章贡献">文章贡献</h3>
<ul>
<li>提出BEVFormer，结合时空信息，支持下游任务。<br />
</li>
<li>使用自注意力和交叉注意力，<strong>将特征结合到BEV</strong>。<br />
</li>
<li>实验效果好。</li>
</ul>
<h2 id="devformer">DEVFormer</h2>
<h3 id="总体架构">总体架构</h3>
<p>BEVFormer有六个Encoder层，每层如图-2所示，<br />
<img src="/attachments_2022/Pasted%20image%2020220524104742.png"
alt="Pasted%20image%2020220524104742.png" /><br />
左图描述了车载的6个摄像头，通过底层 Backbone 提取多层图像特征（Feature
Map）；中间图
(a)展示了一个编码层包含时间的自注意力和空间的交叉注意力，空间信息由左图提供，它的输入还包括前一层的网格BEV特征(橙色)和BEV查询(蓝色)，输出是BEV特征；右侧的图(b)细化了空间交叉注意力，BEV查询只与它感兴趣的摄像机图片特征交互；右图(c)细化了时间自注意力，查询与之前的BEV特征和当前的BEV特征交互。</p>
<p>其中BEV查询是网格形状的可学习参数，用于从摄像头中查询BEV特征。</p>
<p>预测阶段，在时间t，读取多摄像头的图片特征F，以及t-1时刻的BEV特征，通过上述处理，输出BEV在t时刻的特征，送入下一层；多层处理完最后输出的BEV特征送入下游任务。</p>
<h3 id="bev-查询">BEV 查询</h3>
<p>定义一个网格形状的可学习的参数Q ∈
RH×W×C，其中H,W是BEV平面的大小，其中每个点p=(x,y)指向现实世界中s米的区域，每个点对应一个大小为C的查询Qp。BEV的中心点一般是汽车本身所在的区域。依照惯例，在输入BEVFormer框架前，将位置嵌入到Q查询中。</p>
<h3 id="空间交叉注意力">空间交叉注意力</h3>
<p>多个摄像头，每个摄像头又有多层特征输出时，数据量非常大，因此使用了多头注意力。具体使用形变注意力deformable
attention（一篇非常精典的论文）。BEV查询使每个点只与某些摄像头（视图）相关。</p>
<p>本文将形变注意力从2D扩展到3D。如图-2(b)所示，先将查询扩展成了一个柱形，采样3D参考点，再投影到2D。把与某点相关的视图记作Vhit。把2D点作为查询Qp的参考点，从相关视图中这些点周围采样。最终得到采样特征的加权和作为空间交叉注意力的输出：<br />
<img src="/attachments_2022/Pasted%20image%2020220524113809.png"
alt="Pasted%20image%2020220524113809.png" /><br />
式中的i是摄像头索引，j是参考点，N是柱中所有高度参考点，F是特征，Q是查询，P(p,i,r)是投影函数，用于获取第i图中的第j个参考点。</p>
<p>使用投影函数计算参考点方法如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220524114202.png"
alt="Pasted%20image%2020220524114202.png" /><br />
x',y'是真实世界坐标，x,y是BEV上的坐标，W,H是BEV大小，S是每个BEV小格对应现实世界的米数。</p>
<p>现实中，不仅有位置x',y'，还有高度z'，对于每个查询点p，获取一个3D柱<br />
<img src="/attachments_2022/Pasted%20image%2020220524114604.png"
alt="Pasted%20image%2020220524114604.png" /><br />
，通过相机的投影矩阵将三维参考点投影到不同的图像视图上。<br />
<img src="/attachments_2022/Pasted%20image%2020220524115345.png"
alt="Pasted%20image%2020220524115345.png" /></p>
<p>此处的P(p, i, j)是由第j个3D点(x',
y',z'j)投影到第i个视图上的2D点，Ti是第i个相机的已知投影矩阵。</p>
<h3 id="时间自注意力">时间自注意力</h3>
<p>通过结合历史BEV来表征当前环境。查询Q和前一时间的Bt-1，首先要对齐运动中的Bt-1和Q，将对齐后的B记作B'，由于物体在运动中，因此，通过自注意力建模：<br />
<img src="/attachments_2022/Pasted%20image%2020220524115744.png"
alt="Pasted%20image%2020220524115744.png" /><br />
与之前的形变注意力不同的时，此处的位置偏移∆p是通过串联Q和B't-1来预测的。<br />
相对于简单的堆叠之前的BEV，自注意力更有效地对长时依赖建模，也减少了计算量和信息干扰。</p>
<h3 id="应用bev特征">应用BEV特征</h3>
<p>Encoder输出的DEV特征Bt大小为HxWxC，可用于自动驾驶的3D物体探测（预测三维边界框和速度，无需NMS后处理）和地图分割等任务中。</p>
<h3 id="实现细节">实现细节</h3>
<h4 id="训练阶段">训练阶段</h4>
<p>从过去2s中随机抽取3个样本，表示为t-3,t-2,t-1,t，在时间t，根据多摄像头的输入和Bt-1生成Bt，Bt包含四个样本的时空信息，最终输出到下游任务，计算损失函数。</p>
<h4 id="预测阶段">预测阶段</h4>
<p>对视频中的每帧计算，并保留BEV特征用于后续计算，尽管使用了时间信息，但是文中方法的预测时间与其它方法差不多。</p>
<h2 id="实验">实验</h2>
<h3 id="数据集">数据集</h3>
<p>实验使用两个公开的自动驾驶数据集：nuScenes和Waymo。</p>
<p>nuScense包含1000个，每个约20s的数据，标注2Hz，每个样本包含6个摄像机具有360度的水平场景。对于目标检测任务有标注了1.4M个3D框，共包含10个类别。5种评价标准：ATE,
ASE, AEO, AVE, AAE，另外，nuScense还提出了NDS来计算综合评分。</p>
<p>Waymo Open
Dataset包含798个训练序列和202个验证序列，每帧5张图片，摄像机具有252度的水平场景，但提供了360度的标注。由于Waymo是高分辨率且高采样的，所以利用5秒采样切分数据，并只检测车辆类别。</p>
<h3 id="实验设置">实验设置</h3>
<p>基础模型使用使ResNet101-DCN和VoVnet-99，三层256通道的FPN，BEV大小为200x200，每小块对应0.512米，用6层编码层，从-5米到3米取4个高度的参考点，24次迭代。由于Waymo不能取到360度全景，由此对BEV大小做了调整。</p>
<p>基线使用VPN和Lift-Splat模型做对比，另外，还对比了不使用时间信息的BEVFormer-S模型。</p>
<h3 id="d目标检测">3D目标检测</h3>
<p><img src="/attachments_2022/Pasted%20image%2020220528102547.png"
alt="Pasted%20image%2020220528102547.png" /><br />
Modality中L表示雷达，C表示摄像机，可以看到BEVFormer与雷达效果相似。另外，对于速度mAVE也有明显提升。</p>
<h3 id="多任务感知">多任务感知</h3>
<p>针对3D检测和地图分割同时训练两种任务，以节省资源，结果如表-4所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220528103658.png"
alt="Pasted%20image%2020220528103658.png" /><br />
可以看到，在车辆分割中多任务训练效果更好，而道路和车道分割效果较差，这可能是负迁移导致的。</p>
<h3 id="消融实验">消融实验</h3>
<h4 id="空间交叉注意力-1">空间交叉注意力</h4>
<p>与之前模型相比，使用了Deformable的BEV模型有明显提升。相对于全局注意力，只关注参考点的注意力（限制了感受野），稀疏注意力利用了先验的感兴趣区域，取得了更好效果，且相对比较节省资源。<br />
<img src="/attachments_2022/Pasted%20image%2020220528105619.png"
alt="Pasted%20image%2020220528105619.png" /></p>
<h4 id="时间自注意力-1">时间自注意力</h4>
<p>通过BEVFormer与BEVFormer-S的比较可以看出，使用时间注意力的效果，其优势如下：更好地预测速度；预测位置方向更准确；对遮挡物体有更高召回率。</p>
<h4 id="模型规模和延迟">模型规模和延迟</h4>
<p><img src="/attachments_2022/Pasted%20image%2020220528110159.png"
alt="Pasted%20image%2020220528110159.png" /><br />
由于需要处理多视图，时间主要用于backbone模型；另外，缩减了BEVFormer后，效果下降也能接受。</p>
<h3 id="可视化效果">可视化效果</h3>
<p><img src="/attachments_2022/Pasted%20image%2020220528104206.png"
alt="Pasted%20image%2020220528104206.png" /><br />
如图-4所示，模型只在较远和小型物体识别有误。</p>
]]></content>
      <tags>
        <tag>自动驾驶</tag>
      </tags>
  </entry>
  <entry>
    <title>BEVSegFormer：基于任意相机的鸟瞰图语义分割</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_BEVSegFormer/</url>
    <content><![CDATA[<h1 id="介绍">介绍</h1>
<p>英文题目：BEVSegFormer: Bird’s Eye View Semantic Segmentation From
Arbitrary Camera Rigs<br />
中文题目：BEVSegFormer: 基于任意相机的鸟瞰图语义分割<br />
论文地址：https://arxiv.org/abs/2203.04050<br />
领域：机器视觉,自动驾驶<br />
发表时间：2022年3月<br />
作者：来自上海的自动驾驶创业公司Nullmax<br />
阅读时间：2022.05.28<br />
其它相关网文：https://blog.csdn.net/Yong_Qi2015/article/details/124311369</p>
<h3 id="介绍-1">介绍</h3>
<p>之前从摄像机视图转成BEV的方法多以IPM为主，该方法需要知道摄像机的内外参数以及位置信息。在有遮挡及距离比较远的情况下，都无法达到很好的效果。近年来更多应用了深度学习方法。</p>
<h3 id="优点">优点</h3>
<ul>
<li>不需要摄像机的参数<br />
</li>
<li>有效聚合多摄像头数据<br />
</li>
<li>优化了图像分割效果</li>
</ul>
<h3 id="核心算法">核心算法</h3>
<p>（论文正文第3页）</p>
<p>三个步骤：<br />
(1) 从一个共享Backbone处理各摄像机，输出Feature map。<br />
(2) 基于Transformer的编码器加强Feature map。<br />
(3) 解码器通过交叉注意机制处理BEV查询。<br />
最终利用输出的查询结果进行语义分割。</p>
<p>文章的核心基本就在以下图和公式：<br />
<img src="/attachments_2022/Pasted%20image%2020220528155210.png"
alt="Pasted%20image%2020220528155210.png" /><br />
其中m是头数，c是摄像头，k是采样点个数。∆P是k个采样点的偏移，A是注意力权重。p^是参考点，φ用于标准化坐标和特征图位置的转换，q表示BEV中每一个小块。</p>
<p>第三步Decoder如下图所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220528153932.png"
alt="Pasted%20image%2020220528153932.png" /><br />
对于BEV中的每一个小块，箭头过程描述了每个小块是如何更新。输入是摄像头影像（黄色和橙色表示不同的摄像头，对应公式中的x），以及之前BEV的查询query
q其该块的位置query pos q（所有块zq，及每块的参考点pq）。</p>
<p>对于每一个小块q，使用可学习的投影层对其位置嵌入到二维的参考点<br />
<span class="math display">\[\hat p_q \in R ^ {M \times
N_c\times2}\]</span><br />
其中是指使用两个可学习的线性映射层，以生成参考点周围的采样点（见右侧中间的虚线框），采样后线成一个序列（右侧四个黄块和橙块），再通过Attention为这些小块加权，最终产生了新的序列（右下角）。</p>
<p>与DETR不同的时，文中方法通过多摄像头的Feature
map学习独立的参考点，因此网络可以根据不同的镜像机特征，自动选择不同位置的参考点。</p>
<h3 id="前置知识">前置知识</h3>
<h3 id="detr">DETR</h3>
<p>DETR的全称是DEtection
TRansformer，是Facebook提出的基于Transformer的端到端目标检测网络。</p>
<p>之前目标检测方法主要是基于Anchor，简单地说就是对图片中不同位置和大小的小方框进分类，然后再做回归精调框的大小。</p>
<p>DETR同样也使用了backbone的Feature
map，不同的是它还加入了位置嵌入，然后送入encoder；另外，还使用object
queries（可学习的动态anchor）作为解码器的输入，最终将解码器的输出送入最终分类器。<br />
<img src="/attachments_2022/Pasted%20image%2020220528163337.png"
alt="Pasted%20image%2020220528163337.png" /></p>
<h3 id="deformable-detr">Deformable DETR</h3>
<p>Deformable DETR
是注意力模块只关注参考点周围的少量关键采样点，而不是所有点。</p>
]]></content>
      <tags>
        <tag>自动驾驶</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_ViT</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_ViT/</url>
    <content><![CDATA[<p>name_ch: 将16x16的块看作词：用Transformers实现大规模图像识别<br />
name_en: An Image is Worth 16x16 Words：Transformers for Image
Recognition at Scale<br />
paper_addr: http://arxiv.org/abs/2010.11929<br />
code: https://github.com/google-research/vision_transformer<br />
date_publish: 2021-06-03<br />
other src:
ViT论文逐段精读：https://www.bilibili.com/video/BV15P4y137jb/?spm_id_from=333.999.0.0</p>
<h2 id="读后感">读后感</h2>
<p>ViT是Vision
Transformer的缩写，是2020年Google团队提出的将Transformer应用在图像分类的模型。ViT将输入图片分为多个patch，再将每个patch投影为固定长度的向量送入Transformer，后续encoder的操作和原始Transformer中完全相同。</p>
<p>ViT虽然不是第一篇将transformer应用在视觉任务的论文，但是因为其模型“简单”且效果好，可扩展性强（scalable，模型越大效果越好），成为了transformer在CV领域应用的里程碑著作。</p>
<p>在不修改优化Transformer的基础上，通过将切块的图片像word一样转入Transformer模型，并使用类似BERT的结构处理分类问题，在大数据集训练后效果好于已有模型。后面的很多模型都基于该模型为基础调优，可以说它奠定了视觉大模型的基础。</p>
<h2 id="方法">方法</h2>
<p><img
src="/attachments_2023/Pasted%20image%2020230408134022.png" /><br />
图-1示例将图切成9个16x16大小的块，然后用线性映射成Patch
Embedding；由于图片有上下左右的顺序，又加了Position
Embedding（与BERT方法一致）；另外，前面还加了一个星的token，它类似于BERT对分类的处理，最终也是通过这个token来完成分类任务。</p>
<p>比如：图片是224x224x3，拆成14x14块，每块：16x16x3=768，经过映射（768x768）后输出也是768（可以设置），结果就是：每句196个单词，每个单词用768维表示（Patch
Embedding）。</p>
<p>公式如下：</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230408140924.png" /></p>
<p>Z0为第一层，E为映射到嵌入空间，Epos为位置嵌入，Xclass为类别token；Zt为后n层；MSA是多头注意力；MLP是全连接层。ViT没有用太多归纳偏置（先验知识），所以在中小数据集中效果不如CNN。</p>
<h2 id="实验">实验</h2>
<p>结果证明ViT比另两个模型训练快且效果好：<br />
<img src="/attachments_2023/Pasted%20image%2020230408142521.png" /></p>
<p>数据越多，模型效果越好，扩展性更好；数据少里ViT更容易过拟合，效果不如ResNet。<br />
<img src="/attachments_2023/Pasted%20image%2020230408142840.png" /></p>
<p>对比不同资源占用，证明ViT更节约资源：<br />
<img src="/attachments_2023/Pasted%20image%2020230408143228.png" /></p>
<p>从左图可以看到，ViT和CNN学到了类似的图像表征；<br />
从中间图可以看到，虽然使用了一维的position，但是明显学到了上下左右的位置信息；<br />
从右图可以看到，根据注意力权重计算图像空间中集成信息的平均距离（类似于
CNN
中的感受野大小），在低层的注意力距离一直很小，即注意力相对局部化，注意力距离随着网络深度的增加而增加，高层的关系更概括抽象。<br />
<img src="/attachments_2023/Pasted%20image%2020230408150618.png" /></p>
]]></content>
      <tags>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_善用Midjourney</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%96%84%E7%94%A8Midjourney/</url>
    <content><![CDATA[<p>中文名称: 用Midjourney生成格林童话插图<br />
英文名称: Grimm in Wonderland：Prompt Engineering with Midjourney to
Illustrate Fairytales<br />
论文地址: http://arxiv.org/abs/2302.08961<br />
时间：2023-02-17</p>
<h2 id="读后感">读后感</h2>
<p>针对生成图的提示工程，利用工具 Midjourney
v4，进行了一系列实验。得出一个生成提示的4阶段过程：初始提示，成分调整，风格细化，加入变化。另外还讨论了生成图像效果不佳的三个原因：
计数困难，难以生成假定的场景，无法描述过于奇异的情况。作者认为这不仅用于生成图片，且对未来的生成模型具有普适性。</p>
<h2 id="介绍">介绍</h2>
<p>之前的提示工程研究包含：主语，动词，环境，风格；之后又有人提出：主题词，风格修饰语，图像提示，质量助推器，重复，和魔术术语的方法。<br />
Midjourney是实践中最受欢迎的工具之一，尽管它是商业的，对建筑也知之甚少。目前的Midjourney
V4更为复杂，它支持更多知识，能生成更多细节，可接受更复杂的提示，能处理多实体的场景。</p>
<h2 id="方法">方法</h2>
<p>当前的图像生成器不仅能通过文本作为输入并产生图像，还支持输入修饰语对图像进行修正。目前已知VQGAN
+ CLIP和Stable Diffusion具有截然不同的架构，对Dall -
E和Midjourney的架构知之甚少。因此，文中未讨论Midjourney专用的魔术术语和质量设置参数，而主要关注一些通用的方法，如主题风格等。</p>
<h3 id="主题">主题</h3>
<p>第一步，从原始文本中推导出主题提示，并对其进行<strong>简化</strong>和调整（如用特定的名词替换代词），以改善结果。</p>
<h3 id="风格">风格</h3>
<p>这里的风格指代了前人文中的媒体和风格，由于生成童话插画，希望生成器不要引入过多细节（Midjourney默认的艺术画风格细节比较丰富），所以尝试了书籍插图或极简主义插图等风格修饰语来限制风格。</p>
<h3 id="图像提示">图像提示</h3>
<p>实验并没有上传参考图片，利用了Midjourney提供的图像微调功能。在不使用基于图像的微调的情况下，图像之间的一致性是一个挑战，比如对同一个童话生成不同场景时，同一人物可能生成的完全不同，本文不讨论此问题。</p>
<h2 id="结果">结果</h2>
<h3 id="生成图所的四个阶段">生成图所的四个阶段</h3>
<ul>
<li>初始提示：概括原文，尽可能地使用一个简单的句子<br />
</li>
<li>分成调整：逐步调节提示，优先考虑小的变化，以生成好的反馈迭代。特别注意对歧义词可能曲解。分以下三个层次：
<ul>
<li>调整词语，可选择性地简化或用同义词替换，可能更好地代表语境的词语。可能包括将短语动词减少到代表动作的动词，牺牲叙事的丰富性和忠实性来提升表达准确性。<br />
</li>
<li>为实体(主体与客体)添加或删除形容词或为动词添加副词。<br />
</li>
<li>添加对象以更好地表示上下文和/或强制删除不必要的对象。<br />
</li>
</ul></li>
<li>细化风格：每当发现生成器有多余内容时，可以通过在基本的、简单的、最小的、平坦的颜色上强制使用带有修饰符的风格来抑制它（生成童话无需太多细节）。<br />
</li>
<li>调整已有的图像：一旦图片整体内容稳定下来，只要生成器支持微调（MidJounery是扩展模型，支持微调），就可以在图像的基础上调整。例如：调整实体的数量。</li>
</ul>
<p>图-1展示了原始文本，调整后的提示文本，以及最终生成的比较满意的图片。<br />
<img src="/attachments_2023/Pasted%20image%2020230304232252.png" /></p>
<h3 id="生成器当前的问题">生成器当前的问题</h3>
<ul>
<li>计数困难：比如描述画三只乌鸦结果生成五只，手指数量不对等，这可以通过多试几次或微调来修正。<br />
</li>
<li>难以生成假定的场景：模型不具备先验知识，如图-2中第1条。<br />
</li>
<li>无法描述过于奇异的情况：对于非传统情境，自非现实文本(也称为不可能场景)，生成效果不好，如图-2中第2,3条。<br />
<img src="/attachments_2023/Pasted%20image%2020230304232055.png" /></li>
</ul>
<h2 id="midjourney用法">Midjourney用法</h2>
<h3 id="网址">网址</h3>
<p>https://www.midjourney.com/</p>
<h3 id="注册">注册</h3>
<p>科学上网<br />
主界面点Sign in，选无帐号，创建一个，然后通过邮件激活<br />
（我的老用户名密码，用的新浪邮箱)<br />
必须手机收短信才能完成注册，可以支持国内手机</p>
<h3 id="打开midjounery">打开Midjounery</h3>
<p>主界面点Join the
Beta，此时就进入了绘画的聊天室，可以看到别人的画作</p>
<h2 id="zotero地址">Zotero地址</h2>
<p><a href="http://zotero.org/users/10876188/items/DME4KXU3">Grimm in
Wonderland: Prompt Engineering with Midjourney to Illustrate
Fairytales</a><br />
zotero id: DME4KXU3</p>
]]></content>
      <tags>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_图像生成_unCLIP</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90_unCLIP/</url>
    <content><![CDATA[<h2 id="读后感">读后感</h2>
<p>OpenAI出品，应用于DALL-E
2。主要实现了以文本为条件生成图像。它在图像的还原和生成过程中，利用了图像与文本间的映射关系，文本可以看作是人对图片内容的抽象，<strong>它让模型从人的视角“看”图片，识别了其中人觉得最重要的内容</strong>；在图片内容和人类概念之间建立联系，并能通过文本描述的概念来生成和编辑图片。<br />
从技术层面看，它主要基于CLIP，Diffusion模型，并在GLIDE的方法之上进行了改进（之前GLIDE尝试了有分类的CLIP，本文尝试了无分类的CLIP；GLIDE对Diffusion中加噪图片训练CLIP对齐嵌入，本文用不加噪图片做CLIP）。</p>
<h2 id="介绍">介绍</h2>
<p>CLIP模型在图片和文本之间建立映射关系，能很好的获取图片的含义和风格。本文基于CLIP，提出了两阶段模型（如图）：首先，生成给定文本描述对应的CLIP图像嵌入，然后，用解码器生成以图像嵌入为条件的图像。其解码器尝试了自回归和扩散两种方法，发现扩散模型效率更高。</p>
<p>其核心逻辑如图所示：虚线上结合了文本和图像的表示空间；虚线下是生成图片的过程，用文本嵌入产生一个图像嵌入，然后利用这个嵌入在条件约束下送入扩散解码器产生最终图像。</p>
<figure>
<img src="/attachments_2023/image-Pasted%20image%2020230216175637.png"
alt="image-Pasted image 20230216175637" />
<figcaption aria-hidden="true">image-Pasted image
20230216175637</figcaption>
</figure>
<h2 id="方法">方法</h2>
<p>数据集由成对的( x ,
y)：图像x和它们对应的描述y组成，用zi和zt分别表示CLIP图像和文本嵌入。<br />
<span class="math display">\[P(x \mid y)=P\left(x, z_{i} \mid
y\right)=P\left(x \mid z_{i}, y\right) P\left(z_{i} \mid
y\right)\]</span><br />
利用上述公式，生成图片，其中先验（上图中prior）P (zi |
y)，生成以字幕y为条件的CLIP图像嵌入zi；解码器（上图中Decoder）P (x|zi ,
y)，生成以CLIP图像嵌入zi
(以及可选的文本标题y)为条件的图像x(具体训练细见附录C)。</p>
<h3 id="解码器-decoder">解码器 Decoder</h3>
<p>使用扩散模型生成基于CLIP图像嵌入(以及可选的文本标题)的图像。基于GLIDE模型做了一些修改（GLIDE模型使用加噪后的图片训练CLIP），将CLIP嵌入投影到额外的4个上下文标记中，这些上下文标记串联到GLIDE文本编码器的输出序列中；并在训练过程中随机丢弃文本标题50
%的来实现无分类器指导；另外，还考虑了上采样以改进模型精度，以及提升模型鲁棒性的方法。</p>
<h3 id="先验-prior">先验 Prior</h3>
<p>上述编码器可用嵌入空间数据生成图像，但还需要一个先验模型，从标题y生成zi，以便从文本生成图像。本文探索了两种不同的模型作为先验模型：<br />
* 自回归先验<br />
* 扩散先验<br />
其中扩散模型效率更高。训练一个带因果注意力掩膜的解码器Transformer，之前的扩散先验由：编码文本、CLIP文本嵌入、扩散时间步嵌入、带噪CLIP图像嵌入、最终通过Transformer预测不带噪CLIP图像嵌入。本文生成zi的两个样本，并选择与zt点积较高的样本来提高采样质量。并且发现更好的Diffusion方法是<strong>训练模型直接预测不带噪的zi</strong>，因此改进了
Diffusion 损失函数。</p>
<p><span class="math display">\[L_{\text {prior }}=\mathbb{E}_{t \sim[1,
T], z_{i}^{(t)} \sim q_{t}}\left[\left\|f_{\theta}\left(z_{i}^{(t)}, t,
y\right)-z_{i}\right\|^{2}\right]\]</span></p>
<p>另外，还使用主成分分析( PCA
)对CLIP图像嵌入zi进行降维。通过在原始的1024个主成分中只保留320个主成分，能够保留几乎所有的信息，从后面实验部分，主成分中越重要的维度对应的概念越核心。</p>
<h2 id="操作图像">操作图像</h2>
<p>下面展示了几种应用模型的方法：</p>
<h3 id="生成语义相似的图像">生成语义相似的图像</h3>
<p>给定一幅图像x，可以生成具有相同本质内容（主体元素和风格）但在其他方面不同的相关图像，如形状和方向。具体方法是通过η值控制DDIM采样的随机性。<br />
<img src="/attachments_2023/image-Pasted%20image%2020230219141652.png"
alt="image-Pasted image 20230219141652" /><br />
上方是原图，下面九张为修改后生成的图。</p>
<h3 id="混合图像">混合图像</h3>
<p>混合x1,x2两张图（最左和最右两张），通过对输入图像的嵌入使用球面插值在它们的zi1和zi2之间旋转。<br />
<img src="/attachments_2023/image-Pasted%20image%2020230219141741.png"
alt="image-Pasted image 20230219141741" /></p>
<h3 id="修改图像">修改图像</h3>
<p>通过语义描述修改图像。输入是一个图像和对它的描述，以及转换目标的描述，如图第四行：输入为冬天图片，目标是将其转成秋天的图片。实现方法是计算两个输入标题嵌入的差值，然后使用插件方法在图像嵌入和文本差值间旋转。<br />
<img src="/attachments_2023/image-Pasted%20image%2020230219141808.png"
alt="image-Pasted image 20230219141808" /></p>
<h2 id="探索稳空间">探索稳空间</h2>
<p>PCA重构提供了一种探测CLIP潜在空间结构的工具。在图-7中，右侧是原图，对CLIP的嵌入空间降维，原空间维度为1024，仅保留重性为24,30,40...
320的PCA维度进行重建。可以看到不同维度编码了哪些语义信息。</p>
<p>我们观察到重要性高的PCA维度保留了粗粒度的语义信息，如场景中的物体类型，而重要性相对低的PCA维度编码了更细粒度的细节，如物体的形状和精确形式。</p>
<p>例如，在第一个场景中，重要的维度只有食物，也许还有一个容器，而增加维度后则有西红柿、绿植和瓶子。<br />
<img src="/attachments_2023/image-Pasted%20image%2020230219141844.png"
alt="image-Pasted image 20230219141844" /></p>
<p>之后，作者还对图片的逼真度、多样性和美学性进行了评测，展示unCLIP优于之前模型。</p>
<h2 id="zotero地址">Zotero地址</h2>
<p><a
href="http://zotero.org/users/10876188/items/I52IZHL8">Hierarchical
Text-Conditional Image Generation with CLIP Latents</a><br />
zotero id: I52IZHL8</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>深度学习</tag>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>ts_tsfresh</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/9_%E6%97%B6%E5%BA%8F/ts_tsfresh/</url>
    <content><![CDATA[<h1 id="时间序列分析工具包-tsfresh">时间序列分析工具包 – tsfresh</h1>
<p>#时序 #特征工程</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020211127213158.png"
alt="Pasted%20image%2020211127213158.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020211127213158.png</figcaption>
</figure>
<h2 id="简介">1 简介</h2>
<ul>
<li>官方文档：https://tsfresh.readthedocs.io/en/latest/index.html<br />
</li>
<li>源码：https://github.com/blue-yonder/tsfresh<br />
</li>
<li>Star：目前 6.1K<br />
</li>
<li>笔者推荐：看一遍官方文档，再试一下源码中的例程
tsfresh/notebooks/examples/<br />
</li>
<li>介绍：
<ul>
<li>可对应的长短不一的周期序列进行时间序列特征的提取。<br />
</li>
<li>能够自动地从时间序列数据中提取上百种基本的时序特征，如：峰数量，均值，最值等等</li>
</ul></li>
</ul>
<h2 id="适用性">2 适用性</h2>
<h3 id="适用">2.1 适用</h3>
<ul>
<li>自动地提取时序数据特征，扩充建模时的特征维度<br />
</li>
<li>只基于时间序列的聚类、分类和回归任务。</li>
</ul>
<h3 id="不适用">2.2 不适用</h3>
<ul>
<li>不适用于在线数据<br />
</li>
<li>不适用于对时间序列数据直接训练建模（sklearn更加适合）。<br />
</li>
<li>不适用于高度不规则的时间序列，对于此类数据，tsfresh可用于与时间间隔无关的特征提取（如峰值数量）；但对于非等间隔的数据（如趋势）应谨慎使用。</li>
</ul>
<h2 id="安装">3 安装</h2>
<pre><code>$ pip install tsfresh  </code></pre>
<p>目前版本为 0.18.0（21年12月）</p>
<h2 id="基本用法">4 基本用法</h2>
<h4 id="下载数据">4.1.1 下载数据</h4>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tsfresh.examples.robot_execution_failures <span class="im">import</span> download_robot_execution_failures, load_robot_execution_failures  </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>download_robot_execution_failures()  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>timeseries, y <span class="op">=</span> load_robot_execution_failures()  </span></code></pre></div>
<p><img src="/attachments_2022/Pasted%20image%2020211205205244.png"
alt="Pasted%20image%2020211205205244.png" /><br />
其中id用于区别不同机器，time采集数据的时间点，每个机器对应15个时间点（0-14）；F_x,
F_y, F_z, x, T_y, T_z分别采集六个传感器的值，标签y标记是否故障。<br />
（上述是为格式数据，tsfresh还支持长格式数据，以及多类传感器拆分后的数据）</p>
<h4 id="查看数据">4.1.2 查看数据</h4>
<p>对某一机器的所有优越感器序列做图：</p>
<pre><code>timeseries[timeseries[&#39;id&#39;] ==20].plot(subplots=True, sharex=True, figsize=(10,10))  </code></pre>
<p><img src="/attachments_2022/Pasted%20image%2020211205210456.png"
alt="Pasted%20image%2020211205210456.png" /><br />
通过对比可以看到不同正常和异常的情况下，传感器波形的差异。</p>
<h4 id="特征提取">4.1.3 特征提取</h4>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tsfresh <span class="im">import</span> extract_features  </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>extracted_features <span class="op">=</span> extract_features(timeseries, column_id<span class="op">=</span><span class="st">&quot;id&quot;</span>, column_sort<span class="op">=</span><span class="st">&quot;time&quot;</span>)  </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>extracted_features.shape  </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 运行结果： 88, 4722  </span></span></code></pre></div>
<p>可以看到针对88个不同id每成了4000多维特征。<br />
一般情况下，输入和输出数据一般都为dataframe格式，column_id用于指定时间序列所属的实体，本例中是不同机器；column_sort用于标记时间顺序，某些功能可能仅适用于等距时间戳。如果不设置，则假定数据帧已按升序排序。<br />
提取特征的具体定义请见：<br />
<a
href="https://tsfresh.readthedocs.io/en/latest/text/list_of_features.html">Overview
on extracted features</a></p>
<h4 id="特征筛选">4.1.4 特征筛选</h4>
<p><strong>方法一</strong><br />
根据y筛选X特征（假设检验），并去掉空特征：</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tsfresh <span class="im">import</span> select_features  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tsfresh.utilities.dataframe_functions <span class="im">import</span> impute  </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>impute(extracted_features)  </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>features_filtered <span class="op">=</span> select_features(extracted_features, y)  </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>features_filtered.shape  </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 运行结果： 88, 676  </span></span></code></pre></div>
<p>清理后可以看到还剩600多维特征。</p>
<p><strong>方法二</strong><br />
也可使用calculate_relevance_table函数做特征选择，用法如下：</p>
<pre><code>def calculate_relevance_table(X, y, ml_task=&#39;auto&#39;, n_jobs=1, show_warnings=False, chunksize=None, test_for_binary_target_binary_feature=&#39;fisher&#39;, test_for_binary_target_real_feature=&#39;mann&#39;, test_for_real_target_binary_feature=&#39;mann&#39;, test_for_real_target_real_feature=&#39;kendall&#39;, fdr_level=0.05, hypotheses_independent=False):  </code></pre>
<p>它可以针对特征和目标变量的类型，设置具体的假设检验方法，返回数据为pandas.DataFrame，主要包括特征、特征类型、假设检验p值、相关性等信息。</p>
<p><strong>方法三</strong><br />
用以下命令将特征提取和特征选择合二为一：</p>
<pre><code>from tsfresh import extract_relevant_features  
  
features_filtered_direct = extract_relevant_features(timeseries, y, column_id=&#39;id&#39;, column_sort=&#39;time&#39;)  </code></pre>
<p>tsfresh可与sklearn连接使用，具体使用sklearn中的pipeline连接。</p>
<h2 id="进阶">5 进阶</h2>
<h3 id="特征提取设置">5.1 特征提取设置</h3>
<p>上例中最终产生了600多维特征，当数据较多时，运行时间也比较长。tsfresh提供了三种特征集：<br />
settings.ComprehensiveFCParameters 全面参数<br />
settings.EfficientFCParameters 有将参数<br />
settings.MinimalFCParameters 最小参数<br />
可以通过以下命令查看和编辑：</p>
<pre><code>from tsfresh.feature_extraction import settings  
settings_minimal = settings.MinimalFCParameters()  </code></pre>
<p>提取特征时可通过default_fc_parameters或kind_to_fc_parameters来设置提取哪些特征，如：</p>
<pre><code>extracted_features = extract_features(timeseries, column_id=&quot;id&quot;, column_sort=&quot;time&quot;, default_fc_parameters=settings_minimal)  </code></pre>
<p>参数default_fc_parameters:
用于全局配置所需计算的特征；kind_to_fc_parameters用于单独配置每一类数据所需计算的特征（推荐使用）。</p>
<p>default_fc_parameters除了指定三种特征集，还可以使用字典指定具体参数，形如：</p>
<pre><code>fc_parameters = &#123;  
    &quot;length&quot;: None,  
    &quot;large_standard_deviation&quot;: [&#123;&quot;r&quot;: 0.05&#125;, &#123;&quot;r&quot;: 0.1&#125;]  
&#125;  </code></pre>
<p>kind_to_fc_parameters也使用字典指定设置项，形如：</p>
<pre><code>kind_to_fc_parameters = &#123;  
    &quot;temperature&quot;: &#123;&quot;mean&quot;: None&#125;,  
    &quot;pressure&quot;: &#123;&quot;maximum&quot;: None, &quot;minimum&quot;: None&#125;  
&#125;  </code></pre>
<h3 id="特征命名">5.2 特征命名</h3>
<p>提取的出特征都依据一定的命名规则（注意单下划线和多下划线，一般包括方法、参数等），可以从处理的数据中查看提取了哪些特征。</p>
<pre><code>settings.from_columns(extracted_features)  </code></pre>
<p>另外，还可以针对不同的特征设置不同的提取项，以及设置具体的提取参数，请见源码中的例程：</p>
<pre><code>tsfresh/notebooks/examples/03%20Feature%20Extraction%20Settings.ipynb  </code></pre>
<h3 id="自定义特征提取">5.3 自定义特征提取</h3>
<h4 id="实现特征提取函数">5.3.1 实现特征提取函数</h4>
<p>如最简单的示例：加特征提取方法，用于计算众数：</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tsfresh.feature_extraction <span class="im">import</span> feature_calculators  </span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="at">@feature_calculators.set_property</span>(<span class="st">&quot;fctype&quot;</span>, <span class="st">&quot;simple&quot;</span>)  </span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mode(x):  </span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    c <span class="op">=</span> Counter(x)  </span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">tuple</span>(x <span class="cf">for</span> x, count <span class="kw">in</span> c.items() <span class="cf">if</span> count <span class="op">==</span> c.most_common(<span class="dv">1</span>)[<span class="dv">0</span>][<span class="dv">1</span>])  </span></code></pre></div>
<p>其中simple指的是简单方法：只返回单个值。</p>
<h4 id="注册特征提取函数">5.3.2 注册特征提取函数</h4>
<p>方法一：<br />
加入字典：tsfresh.feature_extraction.settings.ComprehensiveFCParameters<br />
方法二：（推荐）<br />
setattr(feature_calculators,name,func)</p>
<h3 id="大量数据处理并行计算">5.4 大量数据处理&amp;并行计算</h3>
<p>tsfresh底层使用numpy而非pandas，相对来说速度更快。但由于numpy不包含索引，因此丢弃了dataframe的索引信息，如需要使用或返回索引信息，则需要自行处理。<br />
tsfresh当数据量较很大时，对内存进行了优化（每次加载一些小块，其它存在磁盘上）。<br />
tsfresh底层也支持dask（类似pandas的并行框架），但是默认使用。Dask与pandas对比详见：<a
href="https://banxian-w.com/article/2022/2/25/2072.html">Pandas模块替代品分析</a></p>
<p>tsfresh默认开启了并行化，且支持分布式支持。</p>
<h3 id="滑动时间窗口">5.5 滑动时间窗口</h3>
<p><strong><em>待加</em></strong></p>
<h2 id="问题与解答">6 问题与解答</h2>
<ul>
<li>tsfresh库import时很慢<br />
把版本从0.18降成0.17之后就好了</li>
</ul>
<h2 id="一些想法">7 一些想法</h2>
<p>tsfresh确实提取了几百维时序特征，但我们还是不知应该怎么使用，全部作为特征代入模型，让模型自行筛选？</p>
<h2 id="参考">8 参考</h2>
<ul>
<li>较长的综述<br />
<a href="https://zhuanlan.zhihu.com/p/102186988">tsfresh</a><br />
</li>
<li>一个简单的例子<br />
<a
href="https://zhuanlan.zhihu.com/p/93310900">特征工程工具总结(1)——Tsfresh</a><br />
</li>
<li>各种特征的原理<br />
<a href="https://blog.csdn.net/yunini2/article/details/92805230">python
tsfresh特征中文详解（更新中）</a><br />
</li>
<li>王半仙的tsfresh讲义<br />
<a
href="https://banxian-w.com/article/2022/2/24/2073.html">tsfresh概述</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>时序预测之一_概述</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/9_%E6%97%B6%E5%BA%8F/%E6%97%B6%E5%BA%8F%E9%A2%84%E6%B5%8B%E4%B9%8B%E4%B8%80_%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<h1 id="时序预测之一_概述">时序预测之一_概述</h1>
<p>#机器学习 #时序</p>
<h2 id="说明">1. 说明</h2>
<p> 前一段参加了天池的“盐城汽车上牌量预测“比赛。第一次面对大规模的时序问题，从比赛的过程，到赛后各位大佬的算法分享，收获很多。也将解决该类问题的套路在此总结一下。<br />
 本篇是总述，其中提到的具体算法，如：加窗，ARIMA，傅里叶/小波变换，LSTM等等将在本系列的后续文章中一一详述。</p>
<h2 id="问题描述">2. 问题描述</h2>
<p> 上牌量预测是一个典型的时序问题，且数据简单清晰，以复赛Ａ榜数据为例，它提供了前3年的10种品牌汽车每天的上牌量，预测未来半年中每天的各品牌的上牌量。<br />
 提供的信息只有之前的上牌量，日期数据和星期几，是一个单变量的预测问题（暂不计各品牌间的相互影响），比较困难的是：它不是预测一天，而是预测几百天，有些时序模型无法使用。</p>
<h2 id="步骤">3. 步骤</h2>
<p> 对比一下自己和大家的解决方案，基本都可以拆解成以下步骤</p>
<h4 id="还原日期">(1) 还原日期</h4>
<p> 比赛数据对日期进行了脱敏处理，没给具体年月日，但提供了周几的信息，其中有些节假日上牌量为0的也没有给出对应记录。第一步大家都补全了日期，加入了真实日期，和节假日信息。<br />
 这里介绍两个相关阴历的时间转换库：<br />
chinese_calendar，Lunar-Solar-Calendar-Converter</p>
<h4 id="从日期中提取信息">(2) 从日期中提取信息</h4>
<p> 这是各显神通的环节，大家根据自各经验，提取了各种各样的特征，总结如下：<br />
 假期长度、调休日期、与节假日的时间距离；<br />
 某年中的第几个月，某年有的第几周，某月中的第几周，某月中的第几日，某年中的第几日（阴历/阳历分别取），正数/倒数第几个工作日。</p>
<h4 id="提取周期信息">(3) 提取周期信息</h4>
<p> 对于周期提取，基本有两种做法，一种是手工计算出同比，环比，往期数据，直接加入Feature，然后用GBDT生成决策。另一种是用ARIMA预测出大致的周期趋势，然后用GBDT描述其余细节。</p>
<ol type="i">
<li>手工加入周期数据</li>
</ol>
<p> 有一些方案完全没使用趋势和周期算法，排名也挺靠前的，其原因是，他们直接把周期和统计数据做成了特征，比如：用shift()把前N天的上牌量做为当天的特征，用rolling()将前Ｎ天均值作为当天特征，将阴历/阳历的去年同期（月、周）数据作为当期特征，环比的最大值，最小值，分位数等等。这种方法的好处是模型可以同时处理维度的各种特征，美中不足是可能损失一些对趋势的预测。</p>
<ol start="2" type="i">
<li>算法预测周期和趋势数据</li>
</ol>
<p> 此类方案以ARIMA代表，ARIMA，小波变换，线性拟合，它们是解决时序问题的传统方法。再与GBDT算法相结合，处理一些不能被周期性识别的细节。这种方法的优点是兼顾整体和细节，问题时在预测长周期时，后期有严重的衰减。</p>
<h4 id="梯度下降决策树">(4) 梯度下降决策树</h4>
<p> 几乎所有的人都使用了梯度下降决策树（GBDT）类算法和交叉验证（CV），值得注意的是，有一些特征需要处理成“类别”而非“数据”，比如“月份”，“周几”，“品牌”等等，否则很影响效果。</p>
<h2 id="原理">4. 原理</h2>
<p> 对于时序问题，一般可以拆解为：趋势+周期+突发事件。</p>
<h4 id="趋势">(1) 趋势</h4>
<p> 一般需要先拟合趋势，比如使用：滑动平均模型，指数平均模型，线性回归等等。其中需要注意的是拐点的识别（不限于此题），比如一些股票缓涨急跌，即它在上升和下降的趋势中规律完全不同，则需要分段处理。另外我理解，趋势有含有两部分，一部分和均值相关，一部分和方差相关。均值描述位置的高低，方差描述波动的大小。</p>
<h4 id="周期">(2) 周期</h4>
<p> 这里指的周期是大周期，中周期，小周期，相互交错，包含的情况。比如年内变化，周内变化都呈明显周期性。一般可使用：季节模型，小波/傅里叶变换，差分周期等等。我觉得ARIMA也可算做一种周期性工具，它的主旨也是用过去的Ｎ项预测未来。<br />
 周期与趋势的组合，又有交乘和叠加等不同方式。</p>
<h4 id="突发事件">(3) 突发事件</h4>
<p> 现在一般都用机器学习的工具处理突发事件和结果的关系，比如随机森林，梯度下降决策树，还可能用到关联规则等等。</p>
<h4 id="扩展">(4) 扩展</h4>
<p> 不只是时序问题，其它的机器学习问题也是一样，比如说大分类包含小分类这种情况，也类似于周期。都需要去考虑统计特征。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>时序</tag>
      </tags>
  </entry>
  <entry>
    <title>时序预测之三_傅立叶和小波变换</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/9_%E6%97%B6%E5%BA%8F/%E6%97%B6%E5%BA%8F%E9%A2%84%E6%B5%8B%E4%B9%8B%E4%B8%89_%E5%82%85%E7%AB%8B%E5%8F%B6%E5%92%8C%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2/</url>
    <content><![CDATA[<h1
id="时序预测之三_傅立叶和小波变换">时序预测之三_傅立叶和小波变换</h1>
<p>#机器学习 #数学</p>
<h2 id="说明">1. 说明</h2>
<p> 用傅立叶变换预测时序数据，原理是把时域数据转换到频域，再转换回来．python的numpy和scipy里面都有现成的转换工具fft()和ifft()，但使用时会遇到一个问题：比如25天的数据转到频域再转回时域，还是25天，虽然拟合了数据，但没法直接预测未来，本篇介绍用它实现预测的方法．</p>
<h2 id="傅立叶变换">2. 傅立叶变换</h2>
<h4 id="相关知识">(1) 相关知识</h4>
<p> 之前写过关于傅立叶变换原理的文档，这次就不再重复了，具体请见：https://www.jianshu.com/p/9e786be6dccb<br />
 本篇只从程序的角度看如何使用它．
经过FFT转换的数据和转换前长度一致，每个数据分为实部和虚部两部分，假设时序时数长度为N（Ｎ最好是2的整数次幂，这样算起来更快），用fft()转换后：下标为0和
N /2的两个复数的虚数部分为0，下标为i和 N - i
的两个复数共辄，也就是其虚部数值相同、符号相反。再用ifft()从频域转回时域之后，出现了由误差引起的很小的虚部，用np.real()取其实部即可．<br />
 由于一半是另一半的共轭，因此只需要关心一半数据．fft转换后下标为0的实数表示时域信号中的直流成分（不随时间变化），下标为i的复数
a + bj，其中a表示余弦成分，b表示其正弦成分．</p>
<h4 id="示例功能">(2) 示例功能</h4>
<p> 数据是航空乘客数据＂AirPassengers.csv＂，可以从CSDN下载，其中包括从1949-1960年，每月旅客的数量，程序预测未来几年的旅客数据．</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-f2a5caa500f4c9fa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 如图所示，数据为非平稳数据，其趋势向上，且波动加俱，为将其变为平稳数据，
先对其做了对数和差分处理．</p>
<h4 id="示例代码">(3) 示例代码</h4>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 函数功能：将频域数据转换成时序数据  </span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># bins为频域数据，n设置使用前多少个频域数据，loop设置生成数据的长度  </span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fft_combine(bins, n, loops<span class="op">=</span><span class="dv">1</span>):  </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a> length <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(bins) <span class="op">*</span> loops)  </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a> data <span class="op">=</span> np.zeros(length)  </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a> index <span class="op">=</span> loops <span class="op">*</span> np.arange(<span class="dv">0</span>, length, <span class="fl">1.0</span>) <span class="op">/</span> length <span class="op">*</span> (<span class="dv">2</span> <span class="op">*</span> np.pi)  </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a> <span class="cf">for</span> k, p <span class="kw">in</span> <span class="bu">enumerate</span>(bins[:n]):  </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>   <span class="cf">if</span> k <span class="op">!=</span> <span class="dv">0</span> : p <span class="op">*=</span> <span class="dv">2</span> <span class="co"># 除去直流成分之外, 其余的系数都 * 2  </span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>   data <span class="op">+=</span> np.real(p) <span class="op">*</span> np.cos(k<span class="op">*</span>index) <span class="co"># 余弦成分的系数为实数部分  </span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>   data <span class="op">-=</span> np.imag(p) <span class="op">*</span> np.sin(k<span class="op">*</span>index) <span class="co"># 正弦成分的系数为负的虚数部分  </span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a> <span class="cf">return</span> index, data  </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&#39;__main__&#39;</span>:  </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a> data <span class="op">=</span> pd.read_csv(<span class="st">&#39;AirPassengers.csv&#39;</span>)  </span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a> ts <span class="op">=</span> data[<span class="st">&#39;Passengers&#39;</span>]  </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 平稳化  </span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a> ts_log <span class="op">=</span> np.log(ts)  </span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a> ts_diff <span class="op">=</span> ts_log.diff(<span class="dv">1</span>)  </span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a> ts_diff <span class="op">=</span> ts_diff.dropna()  </span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a> <span class="bu">print</span>(fy[:<span class="dv">10</span>]) <span class="co"># 显示前10个频域数据  </span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a> fy <span class="op">=</span> np.fft.fft(ts_diff)  </span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a> conv1 <span class="op">=</span> np.real(np.fft.ifft(fy)) <span class="co"># 逆变换  </span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a> index, conv2 <span class="op">=</span> fft_combine(fy <span class="op">/</span> <span class="bu">len</span>(ts_diff), <span class="bu">int</span>(<span class="bu">len</span>(fy)<span class="op">/</span><span class="dv">2</span><span class="op">-</span><span class="dv">1</span>), <span class="fl">1.3</span>) <span class="co"># 只关心一半数据  </span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a> plt.plot(ts_diff)  </span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a> plt.plot(conv1 <span class="op">-</span> <span class="fl">0.5</span>) <span class="co"># 为看清楚，将显示区域下拉0.5  </span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a> plt.plot(conv2 <span class="op">-</span> <span class="dv">1</span>)  </span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>plt.show()  </span></code></pre></div>
<h4 id="运行结果">(4) 运行结果</h4>
<pre><code>[ 1.34992672+0. j -0.09526905-0.14569535j -0.03664114-0.12007802j  
 -0.2670005 +0.24512406j -0.10075074+0.0314084 j -0.26409417+0.04197159j  
 0.14411338+0.18703009j 0.07467991+0.05367644j -0.26663142+0.15324939j  
 0.03248223+0.14130114j]  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-246ffb1c068b5507.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="示例分析">(5). 示例分析</h4>
<p> 输出的是fft转换后的数据，只显示了前十个，形式为复数．复数模(绝对值)的两倍为对应频率的余弦波的振幅；复数的辐角表示对应频率的余弦波的相位。第0个元素表示直流分量，虚部为0．在数据中的位置标记了频率大小，值标记了振幅大小．<br />
 图中显示的三条曲线分别为原始数据，做了fft以及ifft逆变换后的数据，以及fft后自己实现算法还原并预测了未来的数据，从图中可见，基本拟合了原始曲线，预测曲线看起来也比较合理．<br />
 上述方法可实现用傅里叶变换预测时序数据．与ARMA算法相比，它没有明显衰减，更适合长时间的预测．<br />
 对于随时间变化的波形，比如语音数据，一般使用加窗后做傅立叶变量的方法拟合数据．</p>
<h2 id="小波变换">3. 小波变换</h2>
<h4 id="相关知识-1">(1) 相关知识</h4>
<p> 有了傅立叶变换，为什么还用小波呢？上面提到，如果波型随时间变化，就需要对波型加窗分段后再处理，而且有时候需要大窗口，有时候需要小窗口，处理起来就更加麻烦．于是引入了更灵活的小波．<br />
 傅立叶变换的基是正余弦函数，而小波的基是各种形状小波，也就是说它把整个波形看成是多个位置和宽度不同的小波的叠加．小波有两个变量：尺度a和平移量t，尺度控制小伸的伸缩，平移量控制小波的平移，它不需将数据切分成段，就可以处理时变数据．尤其对突变信号处理得更好．<br />
 下图是几种常见的小波．</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-3655132404e03920.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 离散小波变换，Discrete Wavelet Transformatio
(dwt)，可以说是小波变换中最简单的一种。这里使用Python调用pywt库实现最简单的功能．<br />
 经过变换之后的返回值：cA:Approximation（近似）,
cD:Detail（细节），其中近似cA是周期性有规律的部分，可以被模拟和预测，而cD可看做是噪声。换言之，用此方法可以拆分周期性数据，和其上的扰动数据。</p>
<h4 id="示例功能-1">(2) 示例功能</h4>
<p> 示例使用的仍然是乘客数据，下面代码是将细节D设为0，然后还原。</p>
<h4 id="示例代码-1">(3) 示例代码</h4>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pywt  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt  </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&#39;__main__&#39;</span>:  </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a> data <span class="op">=</span> pd.read_csv(<span class="st">&#39;AirPassengers.csv&#39;</span>)  </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a> ts <span class="op">=</span> data[<span class="st">&#39;Passengers&#39;</span>]  </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a> <span class="co"># 平稳化  </span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a> ts_log <span class="op">=</span> np.log(ts)  </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a> ts_diff <span class="op">=</span> ts_log.diff(<span class="dv">1</span>)  </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a> ts_diff <span class="op">=</span> ts_diff.dropna()  </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a> cA,cD <span class="op">=</span> pywt.dwt(ts_diff, <span class="st">&#39;db2&#39;</span>)  </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a> cD <span class="op">=</span> np.zeros(<span class="bu">len</span>(cD))  </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a> new_data <span class="op">=</span> pywt.idwt(cA, cD, <span class="st">&#39;db2&#39;</span>)  </span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a> plt.plot(ts_diff)  </span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a> plt.plot(new_data <span class="op">-</span> <span class="fl">0.5</span>)  </span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a> plt.show()  </span></code></pre></div>
<h4 id="运行结果-1">(4) 运行结果</h4>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-97244123acfde118.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="示例分析-1">(5) 示例分析</h4>
<p> 可以看到，用小波拟合的效果也还可以，一般可以使用小波拟合cA，使用ARMA拟合cD部分，两种方法配合使用．</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>时序预测之二_ARIMA</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/9_%E6%97%B6%E5%BA%8F/%E6%97%B6%E5%BA%8F%E9%A2%84%E6%B5%8B%E4%B9%8B%E4%BA%8C_ARIMA/</url>
    <content><![CDATA[<h1 id="时序预测之二_arima">时序预测之二_ARIMA</h1>
<p>#机器学习 #时序</p>
<h2 id="说明">1. 说明</h2>
<p> ARMA回归滑动平均模型(Autoregressive Moving Average
Model,简记ARIMA)，是研究时间序列的重要方法，由自回归模型（简称AR模型）与滑动平均模型（简称MA模型）为基础“混合”构成。常用于具有季节变动特征的销售量、市场规模的预测等。ARIMA模型相对ARMA模型，仅多了差分操作。</p>
<h2 id="相关概念">2. 相关概念</h2>
<h4 id="自回归模型ar">(1) 自回归模型（AR）</h4>
<p> 自回归模型autoregressive
model，简称AR．在时序分析中，描述时间序列｛yt｝自身某一时刻和前p个时刻之间相互关系的模型称自回归模型，其形式为：<br />
<img
src="https://upload-images.jianshu.io/upload_images/5357893-4c833f770c8c6b2d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /><br />
 其中Φ1, Φ2,…,
Φp是模型参数，εt是白噪声序列，它反映了所有其它随机因素的干扰．其中p为模型阶次，即yt由前p个值决定．</p>
<h4 id="滑动平均模型ma">(2) 滑动平均模型（MA）</h4>
<p> 滑动平均模型moving average
model，也称移动平均模型，它将时间序列{yt}看成白噪声序列的线性组合，为什么误差能描述模型呢？假设某个值可通过之间前N个值的平均值预测，稍作变化，即实际值可以通过前一值的预测值加误差得到．因此实际值可用多个误差值的累加来表示．其形式为：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-6e181d2b8ead7117.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="回归滑动平均模型arma">(3) 回归滑动平均模型（ARMA）</h4>
<p> 简单地说：AR模型是建立当前值和历史值之间的联系，MA模型是计算AR部分累积的误差。ARMA是两个维度的和．</p>
<h4 id="数据预处理">(4) 数据预处理</h4>
<p> ARMA要求被分析的数据呈正态分布，平稳，零均值．平稳性一般是指：均值为常数，方差为常数，且自协方差为常数．比如说上升的趋势中，均值就不是常数；如果震荡幅度越来越大，则方差不是常数。<br />
 如果仅是均值非０的情况，可减去均值；如果趋势可用线性拟合，可以减去拟合后的趋势；另外还可以用差分，或者季节性差分的方法使之平稳；对于非正态分布，可使用对数处理．</p>
<h4 id="差分">(5) 差分</h4>
<p> 差分是将数据进行移动之后与原数据进行比较得出的差异数据，这里的移动是指上移或者下移．简单的说，比如对某支股票的价格数据做一阶差分，就是将每日价格减去前一天的价格．<br />
 在python中，差分运算可使用pandas的diff(periods=n)函数实现，其中n为阶数，默认为一阶差分，一阶差分的具体操作是df.shift()-df．用于生成平稳数据，比如下面的曲线．</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-8c5354c873aa203c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 一阶差分后</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-4acc0da58cce2f10.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 由此可见，差分之后，去掉了趋势，均值趋于０．有助于分析其它特征．</p>
<h4 id="自相关与偏自相关acfpacf">(6)
自相关与偏自相关（ACF&amp;PACF）</h4>
<p> 自相关acf和偏自相关pacf是分析时序数据的重要方法，是在平稳条件下求得的．<br />
 自相关函数Auto Correlation Function，简称ACF．形如：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-7faa3325d7567fb2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> Ｘ轴表示滞后值，Ｙ轴从[-1,1]，表示了这些值的相关性．比如左边第一点相关性为1，就是说该点与它自己完全相关．从图中可观察到：12个月为周期的相关性相当明显的．调用方法如下：</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.graphics.tsaplots <span class="im">import</span> plot_acf  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>plot_acf(df[<span class="st">&#39;xxx&#39;</span>])  </span></code></pre></div>
<p> 注意时序数据中不能包括空值，如果之前用了一次一阶差分和一次十二阶差分，应去掉前13个为空的值．<br />
 图中蓝色部分是描述的统计显著性，如果数据随机分布，Y轴的位置会在蓝色区域之内．因此，要着重看蓝色区域以外的点．<br />
 自相关系数包含了其它变量影响下的相关关系，有时需要只考虑某两个变量的相关关系，即偏相关系数．其中的偏字，指的是只考虑首尾两项的关系，把中间项当成常数，使用了偏导数的方法．使用方法如下：</p>
<pre><code>from statsmodels.graphics.tsaplots import plot_pacf  
plot_pacf(df[&#39;xxx&#39;])  </code></pre>
<h4 id="拖尾和截尾">(7) 拖尾和截尾</h4>
<p> 我们通过观察自相关图和偏自相关图来确使用哪种模型，以自相关图为例，先看看图片呈现的几种形式．</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-f25162242928877b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 左边的图呈直线形式衰减，说明可能包括趋势，需要进一步差分；中间是截尾图，它指的是在某个值（如图中的7）后截止为0；右则是拖尾图，指的是按指数形式或正弦形式有规律地衰减．<br />
 如果自相关系数拖尾，偏自相关系数p阶截尾，则使用p阶的AR模型．<br />
 如果自相关系数q阶截尾，偏自相关函数拖尾，则使用q阶的MA模型．<br />
 简单的讲，它们两个都是看截尾截在哪儿．<br />
 如果自相关函数和偏自相关函数均拖尾，则使用ARMA模型，由于AR和MA相互影响，阶数需要从小到大逐步尝试．</p>
<h4 id="模型检验">(8) 模型检验</h4>
<ol type="i">
<li><p>模型对训练数据的拟合<br />
 用模型对训练数据做拟合，用观察或者计算误差的方式，查看二者差异，差异越小越好．</p></li>
<li><p>检查残差的自相关函数<br />
 残差的自相关函数应该没有可识别的结构．</p></li>
<li><p>AIC信息准则<br />
 AIC信息准则Akaike information
criterion，是衡量统计模型拟合优良性的一种标准，AIC值越小越好，也有根据AIC自动选参数的工具．</p></li>
</ol>
<h2 id="步骤">3. 步骤</h2>
<p> 具体使用python调用statsmodels库实现．statsmodels是一套统计工具集．具体需要考虑三个参数：d，p，q．其中d是消除趋势的差分阶数，p是AR阶层，q是MA的阶数．步骤如下：</p>
<ol type="1">
<li><p>做时序图观察基本的趋势和周期．</p></li>
<li><p>分析平稳性，正态性，周期性；并对数据进行转换．</p></li>
<li><p>做自相关和偏自相关图，确定模型阶次．</p></li>
<li><p>模型检验</p></li>
<li><p>用模型预测．</p></li>
</ol>
<h2 id="问题与解答">4. 问题与解答</h2>
<ol type="1">
<li><p>做ARMA分析前是否应该剔除周期性因素？<br />
 我们可以从自相关图中看出周期性波动，比如上边右侧的拖尾图，它说明某天与前7,14,21天都强相关．如果发现强相关，可先进行多阶差分（季节差分）后，再进一步使用ARMA模型处理．需要注意的是各层次差分在预测时都需要对应的还原．</p></li>
<li><p>做长期预测时如何应对衰减？<br />
 我在做盐城上牌预测时就遇到了严重的衰减问题，当时需要预测之后几百天的数据，而ARMA在预测了几十天之后，就从类似正弦波型衰减成了一条直线，导致我最终放弃了该模型，改为使用线性拟合趋势，严重损失了精度．后来看复赛排名第一的大神分享，他也使用ARMA，并且也有衰减问题，不同的是他采用按月预测，相比于按日预测，衰减就好得多，非常赞！</p></li>
</ol>
<h2 id="参考">5. 参考</h2>
<ol type="1">
<li>第七篇时间序列分析<br />
https://max.book118.com/html/2014/1223/10828140.shtm</li>
</ol>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>时序</tag>
      </tags>
  </entry>
  <entry>
    <title>时序预测之四_Prophet时序模型</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/9_%E6%97%B6%E5%BA%8F/%E6%97%B6%E5%BA%8F%E9%A2%84%E6%B5%8B%E4%B9%8B%E5%9B%9B_Prophet%E6%97%B6%E5%BA%8F%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="时序预测之四_prophet时序模型">时序预测之四_Prophet时序模型</h1>
<p>#机器学习 #时序</p>
<h2 id="说明">1. 说明</h2>
<p>Prophet是FaceBook开源的时序框架。非常简单实用，你不需要理解复杂的公式，看图，调参，调用十几行代码即可完成从数据输入到分析的全部工作，可谓懒人之利器。</p>
<p>在效果方面，我在同一项目中尝试了ARIMA，将星期和节假日作为特征代入GBDT，Prophet，相对来说，Prophet效果最好，当然这与数据有关，也不能一概而论。总之，Prophet效果挺好的，训练速度也挺快。</p>
<p>Prophet的原理是分析各种时间序列特征：周期性、趋势性、节假日效应，以及部分异常值。在趋势方面，它支持加入变化点，实现分段线性拟合。在周期方面，它使用傅里叶级数（Fourier
series）来建立周期模型(sin+cos)，在节假和突发事件方面，用户可以通过表的方式指定节假日，及其前后相关的N天。可将Prophet视为一种针对时序的集成解决方案。</p>
<p>使用Prophet具体使用步骤就是：根据格式要求填入训练数据，节假日数据，指定要预测的时段，然后训练即可。除了预测具体数值，Prophet还将预测结果拆分成trend,
year, season,
week等成份，并提供了各成份预测区间的上下边界。不仅是预测工具，也是一个很好的统计分析工具。</p>
<p>当然Prophet也有它的弱项，比如可调节的参数不多，不支持与其时序特征结合等等，不过这些也可以通过预测处理和模型融合来解决。</p>
<h2 id="安装">2. 安装</h2>
<p>在Ubuntu系统中可通过以下命令安装prophet：</p>
<pre><code>$ sudo pip install fbprophet  </code></pre>
<p>通过以下命令下载源码（下面例程中用到了源码中的数据，请先下载源码）</p>
<pre><code>$ git clone https://github.com/facebookincubator/prophet.git  </code></pre>
<h2 id="例程">3. 例程</h2>
<p> 具体使用可参考源码的notebook目录中的例程，很多中文例程都使用了其中的quick_start.ipynb，代码在下面列出。</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fbprophet <span class="im">import</span> Prophet  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt  </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 读取时间数据文件，文件也在源码目录中  </span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>file_path<span class="op">=</span> <span class="st">&#39;examples/example_wp_peyton_manning.csv&#39;</span>    </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(file_path)    </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 输入节假日数据，注意lower_window, upper_window是前后影响天数  </span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>playoffs <span class="op">=</span> pd.DataFrame(&#123;    </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;holiday&#39;</span>: <span class="st">&#39;playoff&#39;</span>,    </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;ds&#39;</span>: pd.to_datetime([<span class="st">&#39;2008-01-13&#39;</span>, <span class="st">&#39;2009-01-03&#39;</span>, <span class="st">&#39;2010-01-16&#39;</span>,    </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;2010-01-24&#39;</span>, <span class="st">&#39;2010-02-07&#39;</span>, <span class="st">&#39;2011-01-08&#39;</span>,    </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;2013-01-12&#39;</span>, <span class="st">&#39;2014-01-12&#39;</span>, <span class="st">&#39;2014-01-19&#39;</span>,    </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;2014-02-02&#39;</span>, <span class="st">&#39;2015-01-11&#39;</span>, <span class="st">&#39;2016-01-17&#39;</span>,    </span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;2016-01-24&#39;</span>, <span class="st">&#39;2016-02-07&#39;</span>]),    </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;lower_window&#39;</span>: <span class="dv">0</span>,    </span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;upper_window&#39;</span>: <span class="dv">1</span>,    </span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>&#125;)    </span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>superbowls <span class="op">=</span> pd.DataFrame(&#123;    </span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;holiday&#39;</span>: <span class="st">&#39;superbowl&#39;</span>,    </span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;ds&#39;</span>: pd.to_datetime([<span class="st">&#39;2010-02-07&#39;</span>, <span class="st">&#39;2014-02-02&#39;</span>, <span class="st">&#39;2016-02-07&#39;</span>]),    </span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;lower_window&#39;</span>: <span class="dv">0</span>,    </span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;upper_window&#39;</span>: <span class="dv">1</span>,    </span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>&#125;)    </span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>holidays <span class="op">=</span> pd.concat((playoffs, superbowls))   </span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="co"># 训练和预测  </span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>prophet <span class="op">=</span> Prophet()   </span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;y&#39;</span>] <span class="op">=</span> np.log(df[<span class="st">&#39;y&#39;</span>])    </span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>prophet.fit(df)    </span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>future <span class="op">=</span> prophet.make_future_dataframe(freq<span class="op">=</span><span class="st">&#39;D&#39;</span>,periods<span class="op">=</span><span class="dv">10</span>)  <span class="co"># 测试之后十天  </span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>forecasts <span class="op">=</span> prophet.predict(future)    </span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a><span class="co"># 训练结果作图  </span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>prophet.plot(forecasts).show()    </span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>prophet.plot_components(forecasts).show()    </span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>plt.show()  </span></code></pre></div>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-faeccf282d709518.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>趋势，周期分析图</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d23d87ce8c601713.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>时序</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习_用树回归方法画股票趋势线</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/9_%E6%97%B6%E5%BA%8F/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97_%E7%94%A8%E6%A0%91%E5%9B%9E%E5%BD%92%E6%96%B9%E6%B3%95%E7%94%BB%E8%82%A1%E7%A5%A8%E8%B6%8B%E5%8A%BF%E7%BA%BF/</url>
    <content><![CDATA[<h1
id="机器学习_用树回归方法画股票趋势线">机器学习_用树回归方法画股票趋势线</h1>
<p>#机器学习</p>
<p> 本篇的主题是分段线性拟合，也叫回归树，是一种集成算法，它同时使用了决策和线性回归的原理，其中有两点不太容易理解，一个是决策树中熵的概念，一个是线性拟合时求参数的公式为什么是由矩阵乘法实现的。如需详解，请见前篇：</p>
<p><a
href="http://blog.csdn.net/xieyan0811/article/details/78556366">《机器学习_决策树与信息熵》</a><br />
<a
href="http://blog.csdn.net/xieyan0811/article/details/78562610">《机器学习_最小二乘法，线性回归与逻辑回归》</a></p>
<h2 id="画出股票的趋势线">1. 画出股票的趋势线</h2>
<p> 我们常在股票节目里看到这样的驱势线：<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-6ff3221bee4a3d29.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /><br />
 比如说平台突破就可以买入了，几千支股票，能不能用程序的方式筛选哪支突破了呢？需要解决的主要问题是：怎么判断一段时间内股票的涨/跌/横盘，以及一段趋势的起止点和角度呢？<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-73e481f40910d7dc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /><br />
 这里我们使用分段线性拟合，图中蓝色的点是某支股票每日的收盘价，红色的直线为程序画出的趋势线。稍做修改，还可以轻松地画出每段趋势所在的箱体，阻力线和支撑线，以及判断此前一般时间的趋势。下面我们就来看看原理和具体算法。</p>
<h2 id="线性回归">2. 线性回归</h2>
<p> 先看看线性回归（Linear
regression），线性回归是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法。简单地说，二维中就是画一条直线，让它离所有点都尽量地近（距离之和最小），用线抽象地表达这些点。具体请见《机器学习_最小二乘法，线性回归与逻辑回归》。<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-744f47eddf7c9b13.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="决策树">3. 决策树</h2>
<p> 我们再看看决策树，决策树(Decision
Tree）决策树是一个预测模型；它是通过一系列的判断达到决策的方法。具体请见《机器学习_决策树与信息熵》。<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-6a298cf90e36051f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="树回归">4. 树回归</h2>
<p> 树回归把决策树和线性回归集成在一起，先决策树，在每个叶节点上构建一个线性方程。比如说数据的最佳拟合是一条折线，那就把它切成几段用线性拟合，每段切多长呢？我们定义一个步长（以忽略小的波动，更好地控制周斯），在整个区域上遍历，找最合适的点（树的分叉点），用该点切分成两段后，分别线性拟合，取整体误差和最小的点，以此类拟，再分到三段，四段……，为避免过拟合，具体实现一般同时使用前剪枝和后剪枝。</p>
<h2 id="代码">5. 代码</h2>
<pre><code># -*- coding: utf-8 -*-  
  
import tushare as ts  
import pandas as pd  
import numpy as np  
import matplotlib.pyplot as plt  
  
# 用feature把dataSet按value分成两个子集  
def binSplitDataSet(dataSet, feature, value):  
    mat0 = dataSet[np.nonzero(dataSet[:,feature] &gt; value)[0],:]  
    mat1 = dataSet[np.nonzero(dataSet[:,feature] &lt;= value)[0],:]  
    return mat0,mat1  
  
# 求给定数据集的线性方程  
def linearSolve(dataSet):  
    m,n = np.shape(dataSet)  
    X = np.mat(np.ones((m,n))); # 第一行补1，线性拟合要求  
    Y = np.mat(np.ones((m,1)))  
    X[:,1:n] = dataSet[:,0:n-1];  
    Y = dataSet[:,-1] # 数据最后一列是y  
    xTx = X.T*X  
    if np.linalg.det(xTx) == 0.0:  
        raise NameError(&#39;This matrix is singular, cannot do inverse,\n\  
        try increasing dur&#39;)  
    ws = xTx.I * (X.T * Y) # 公式推导较难理解  
    return ws,X,Y  
  
# 求线性方程的参数  
def modelLeaf(dataSet):  
    ws,X,Y = linearSolve(dataSet)  
    return ws  
  
# 预测值和y的方差  
def modelErr(dataSet):  
    ws,X,Y = linearSolve(dataSet)  
    yHat = X * ws  
    return sum(np.power(Y - yHat,2))  
  
def chooseBestSplit(dataSet, rate, dur):  
    # 判断所有样本是否为同一分类  
    if len(set(dataSet[:,-1].T.tolist()[0])) == 1:  
        return None, modelLeaf(dataSet)  
    m,n = np.shape(dataSet)  
    S = modelErr(dataSet) # 整体误差  
    bestS = np.inf  
    bestIndex = 0  
    bestValue = 0  
    for featIndex in range(n-1): # 遍历所有特征, 此处只有一个  
        # 遍历特征中每种取值  
        for splitVal in set(dataSet[:,featIndex].T.tolist()[0]):  
            mat0, mat1 = binSplitDataSet(dataSet, featIndex, splitVal)   
            if (np.shape(mat0)[0] &lt; dur) or (np.shape(mat1)[0] &lt; dur):   
                continue # 样本数太少, 前剪枝  
            newS = modelErr(mat0) + modelErr(mat1) # 计算整体误差  
            if newS &lt; bestS:   
                bestIndex = featIndex  
                bestValue = splitVal  
                bestS = newS  
    if (S - bestS) &lt; rate: # 如差误差下降得太少，则不切分   
        return None, modelLeaf(dataSet)  
    mat0, mat1 = binSplitDataSet(dataSet, bestIndex, bestValue)  
    return bestIndex,bestValue  
  
def isTree(obj):  
    return (type(obj).__name__==&#39;dict&#39;)  
  
# 预测函数,数据乘模型,模型是斜率和截距的矩阵  
def modelTreeEval(model, inDat):  
    n = np.shape(inDat)[1]  
    X = np.mat(np.ones((1,n+1)))  
    X[:,1:n+1]=inDat  
    return float(X*model)  
  
# 预测函数  
def treeForeCast(tree, inData):  
    if not isTree(tree):  
        return modelTreeEval(tree, inData)  
    if inData[tree[&#39;spInd&#39;]] &gt; tree[&#39;spVal&#39;]:  
        if isTree(tree[&#39;left&#39;]):  
            return treeForeCast(tree[&#39;left&#39;], inData)  
        else:  
            return modelTreeEval(tree[&#39;left&#39;], inData)  
    else:  
        if isTree(tree[&#39;right&#39;]):  
            return treeForeCast(tree[&#39;right&#39;], inData)  
        else:  
            return modelTreeEval(tree[&#39;right&#39;], inData)  
  
# 对测试数据集预测一系列结果, 用于做图  
def createForeCast(tree, testData):  
    m=len(testData)  
    yHat = np.mat(np.zeros((m,1)))  
    for i in range(m): # m是item个数  
        yHat[i,0] = treeForeCast(tree, np.mat(testData[i]))  
    return yHat  
  
# 绘图  
def draw(dataSet, tree):  
    plt.scatter(dataSet[:,0], dataSet[:,1], s=5) # 在图中以点画收盘价  
    yHat = createForeCast(tree, dataSet[:,0])  
    plt.plot(dataSet[:,0], yHat, linewidth=2.0, color=&#39;red&#39;)  
    plt.show()  
  
# 生成回归树, dataSet是数据, rate是误差下降, dur是叶节点的最小样本数  
def createTree(dataSet, rate, dur):  
    # 寻找最佳划分点, feat为切分点, val为值  
    feat, val = chooseBestSplit(dataSet, rate, dur)  
    if feat == None:  
        return val # 不再可分  
    retTree = &#123;&#125;  
    retTree[&#39;spInd&#39;] = feat  
    retTree[&#39;spVal&#39;] = val   
    lSet, rSet = binSplitDataSet(dataSet, feat, val) # 把数据切给左右两树  
    retTree[&#39;left&#39;] = createTree(lSet, rate, dur)  
    retTree[&#39;right&#39;] = createTree(rSet, rate, dur)  
    return retTree  
  
if __name__ == &#39;__main__&#39;:  
    df = ts.get_k_data(code = &#39;002230&#39;, start = &#39;2017-01-01&#39;) # 科大讯飞今年的股票数据  
    e = pd.DataFrame()  
    e[&#39;idx&#39;] = df.index # 用索引号保证顺序X轴  
    e[&#39;close&#39;] = df[&#39;close&#39;] # 用收盘价作为分类标准Y轴, 以Y轴高低划分X成段，并分段拟合  
    arr = np.array(e)  
    tree = createTree(np.mat(arr), 100, 10)  
draw(arr, tree)  </code></pre>
<h2 id="分析">6. 分析：</h2>
<p> 算法的拟合度和复杂度是使用步长，误差下降和最小样本数控制的，计算的时间跨度（一月/一年）也影响着程序运行时间。例程中计算的是“科大讯飞”近一年来的股价趋势，计算用时约十秒左右（我的机器速度还可以）。</p>
<p> 要计算所有的股票，也需要不少时间。所以具体实现时，一方面可以利用当前价格和移动均线的相对位置过滤掉一些股票，另一方面，也可以将计算结果存储下来，以避免对之前数据的重复计算。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习_隐马尔可夫模型HMM</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/9_%E6%97%B6%E5%BA%8F/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97_%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8BHMM/</url>
    <content><![CDATA[<h1 id="机器学习_隐马尔可夫模型hmm">机器学习_隐马尔可夫模型HMM</h1>
<p>#机器学习 #时序</p>
<h2 id="马尔可夫链">1. 马尔可夫链</h2>
<p>马尔可夫链是满足马尔可夫性质的随机过程。马尔可夫性质是无记忆性。</p>
<p>也就是说，这一时刻的状态，受且只受前一时刻的影响，而不受更往前时刻的状态的影响。我们下面说的隐藏状态序列就马尔可夫链。</p>
<h2 id="隐马尔可夫模型">2. 隐马尔可夫模型</h2>
<p>隐马尔可夫模型（Hidden Markov
Model，HMM）是统计模型，用它处理的问题一般有两个特征：</p>
<p>第一：问题是基于序列的，比如时间序列，或者状态序列。</p>
<p>第二：问题中有两类数据，一类序列数据是可以观测到的，即观测序列；而另一类数据是不能观测到的，即隐藏状态序列，简称状态序列，该序列是马尔可夫链，由于该链不能直观观测，所以叫“隐”马尔可夫模型。</p>
<p>简单地说，状态序列前项能算出后项，但观测不到，观测序列前项算不出后项，但能观测到，观测序列可由状态序列算出。</p>
<p>HMM模型的主要参数是λ=(A,B,Π)，数据的流程是通过初始状态Pi生成第一个隐藏状态h1，h1结合生成矩阵B生成观测状态o1，h1根据转移矩阵A生成h2，h2和B再生成o2，以此类推，生成一系列的观测值。</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-3bcb6ed08224daa3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="HMM" />
<figcaption aria-hidden="true">HMM</figcaption>
</figure>
<h2 id="举例">3. 举例</h2>
<h4 id="问题描述">1) 问题描述</h4>
<p>假设我关注了一支股票，它背后有主力高度控盘，我只能看到股票涨/跌（预测值：2种取值），看不到主力的操作：卖/不动/买（隐藏值：３种取值）。涨跌受主力操作影响大，现在我知道一周之内股票的涨跌，想推测这段时间主力的操作。假设我知道有以下信息：</p>
<ol type="i">
<li><p>观测序列 <span
class="math inline">\(O={o1,o2,...oT}\)</span><br />
一周的涨跌 <span class="math inline">\(O={1, 0, 1, 1,
1}\)</span></p></li>
<li><p>HMM模型 <span class="math inline">\(λ=(A,B,Π)\)</span><br />
</p></li>
</ol>
<ul>
<li>隐藏状态转移矩阵A<br />
主力从前一个操作到后一操作的转换概率
<code>A=&#123;&#123;0.5, 0.3, 0.2&#125;,&#123;0.2, 0.5, 0.3&#125;,&#123;0.3, 0.2, 0.5&#125;&#125;</code><br />
</li>
<li>隐藏状态对观测状态的生成矩阵B（3种-&gt;2种）<br />
主力操作对价格的影响 <code>B=&#123;&#123;0.6, 0.3, 0.1&#125;,&#123;0.2, 0.3, 0.5&#125;&#125;</code><br />
</li>
<li>隐藏状态的初始概率分布 $Pi(Π)<br />
主力一开始的操作的可能性 <code>Pi=&#123;0.7, 0.2, 0.1&#125;</code></li>
</ul>
<h4 id="代码">2) 代码</h4>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hmmlearn <span class="im">import</span> hmm  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>states <span class="op">=</span> [<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>]  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>n_states <span class="op">=</span> <span class="bu">len</span>(states)  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>observations <span class="op">=</span> [<span class="st">&quot;down&quot;</span>,<span class="st">&quot;up&quot;</span>]  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>n_observations <span class="op">=</span> <span class="bu">len</span>(observations)  </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> np.array([<span class="fl">0.7</span>, <span class="fl">0.2</span>, <span class="fl">0.1</span>])  </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> np.array([  </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">0.5</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>],  </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">0.3</span>, <span class="fl">0.5</span>, <span class="fl">0.2</span>],  </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.5</span>]  </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>])  </span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.array([  </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">0.6</span>, <span class="fl">0.2</span>],  </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">0.3</span>, <span class="fl">0.3</span>],  </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">0.1</span>, <span class="fl">0.5</span>]  </span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>])  </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>o <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]]).T  </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> hmm.MultinomialHMM(n_components<span class="op">=</span>n_states)  </span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>model.startprob_<span class="op">=</span> p  </span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>model.transmat_<span class="op">=</span> a  </span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>model.emissionprob_<span class="op">=</span> b  </span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>logprob, h <span class="op">=</span> model.decode(o, algorithm<span class="op">=</span><span class="st">&quot;viterbi&quot;</span>)  </span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;The hidden h&quot;</span>, <span class="st">&quot;, &quot;</span>.join(<span class="bu">map</span>(<span class="kw">lambda</span> x: states[x], h)))  </span></code></pre></div>
<h4 id="c-分析">c) 分析</h4>
<p>这里我们使用了Python的马尔可夫库hmmlearn，可通过命令</p>
<pre><code>$ pip install hmmlearn  </code></pre>
<p>安装（sklearn的hmm已停止更新，无法正常使用，所以用了hmmlearn库）<br />
马尔可夫模型 <span
class="math inline">\(λ=(A,B,Π)\)</span>，A,B,Π是模型的参数，此例中我们直接给出，并填充到模型中，通过观测值和模型的参数，求取隐藏状态。</p>
<h2 id="hmm的具体算法">4. HMM的具体算法</h2>
<p>第一：根据当前的观测序列求解其背后的状态序列，即示例中decode()函数（Viterbi方法）。<br />
第二：根据模型 <span
class="math inline">\(λ=(A,B,Π)\)</span>，求当前观测序列O出现的概率（向前向后算法）<br />
 第三：给出几组观测序列Ｏ，求模型 <span
class="math inline">\(λ=(A,B,Π)\)</span>
中的参数（Baum-Welch方法）。具体方法是随机初始化模型参数A,B,Π；用样本O计算寻找更合适的参数；更新参数，再用样本拟合参数，直至参数收敛。</p>
<p>在实际使用中，比如语音识别，我们先用一些已有的观测数据O，训练模型λ的参数，然后用训练好的模型λ估计新的输入数据Ｏ出现的概率。</p>
<p>至此，我们介绍了HMM的核心操作及对应算法，如果你对具体的Viterbi或者Baum-Welch算法的实现感兴趣，推荐以下两篇文章，一篇是算法公式及说明，一篇是具体Python代码实现，建议对照着看：<br />
http://www.cnblogs.com/hanahimi/p/4011765.html<br />
http://www.cnblogs.com/pinard/p/6945257.html</p>
<h2 id="最大期望em算法">5. 最大期望EM算法</h2>
<p>EM（Expectation
Maximization）最大期望算法是十大数据挖掘经典算法之一。之前一直没见过EM的实现工具和应用场景，直到看见HMM的具体算法。HMM的核心算法是通过观测值计算模型参数，具体使用Baum-Welch算法，它是EM的具体实现，下面来看看EM算法。</p>
<p>假设条件是X，结果是Y，条件能推出结果X-&gt;Y，但结果推不出条件，现在手里有一些对结果Y的观测值，想求X，那么我们举出X的所有可能性，再使用X-&gt;Y的公式求Y，看哪个X计算出的Y和当前观测最契合，就选哪个X。这就是最大似然的原理。</p>
<p>在数据多的情况下，穷举因计算量太大而无法实现，最大期望EM是通过迭代逼近方式求取最大似然。</p>
<p>EM算法分为两个步骤：Ｅ步骤是求在当前参数值和样本下的期望函数，M步骤利用期望函数调整模型中的估计值，循环执行E和M直到参数收敛。</p>
<p>补充 (2022-04-01
大鹏)：有两个东西未知，固定X，找最好的Y，再控制住Y，找到最好的X，不断迭代，最后得到较好的X和Y。应用于底层理论基础好，比较容易数学化的方法。</p>
<h2 id="隐马尔可夫模型hmm与循环神经网络rnnlstm">6.
隐马尔可夫模型HMM与循环神经网络RNN&amp;LSTM</h2>
<p>RNN是循环神经网络，LSTM是RNN的一种优化算法，近年来，RNN在很多领域取代了HMM。下面我们来看看它们的异同。</p>
<p>首先，RNN和HMM解决的都是基于序列的问题，也都有隐藏层的概念，它们都通过隐藏层的状态来生成可观测状态。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-9615d952eb4c607f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>从对比图中可以看出，它们的数据流程很相似（Pi与U，A与W，B与V对应），调参数矩阵的过程都使用梯度方法（对各参数求偏导），RNN利用误差函数在梯度方向上调U,V,W（其中还涉及了激活函数），而HMM利用最大期望在梯度方向上调Pi,A,B（Baum-Welch算法），调参过程中也都用到类似学习率的参数。</p>
<p>不同的是，RNN中使用激活函数（红色方块）让该模型的表现力更强，以及LSTM方法修补了RNN中梯度消失的问题；相对来说RNN框架也更加灵活。</p>
<p>RNN和HMM不是完全不同的两类算法，它们有很多相似之处，我们也可以把RNN看成HMM的加强版。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>时序</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_时序模型Shapelet</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/9_%E6%97%B6%E5%BA%8F/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E6%97%B6%E5%BA%8F%E6%A8%A1%E5%9E%8BShapelet/</url>
    <content><![CDATA[<p>#时序 #论文阅读</p>
<h2 id="基本信息">基本信息</h2>
<ul>
<li>论文题目：《Time Series Shapelets: A New Primitive for Data
Mining》<br />
</li>
<li>论文地址：https://readpaper.com/paper/2029438113<br />
</li>
<li>相关源码：<a
href="https://github.com/johannfaouzi/pyts">https://github.com/johannfaouzi/pyts</a></li>
</ul>
<h2 id="原理">原理</h2>
<p>2009年，Ye和Keogh在KDD上发表论文，首次提出了时序数据中的 Shapelet
的概念。Shapelet是最近邻算法的扩展，它提取最典型的特征子集作为判断依据。</p>
<p>例如：马鞭草和荨麻的叶片很相似，如果将它们的叶片边缘形状整体作为序列建模，则难以区分。<br />
<img src="None" alt="Pasted%20image%2020211211160835.png" /><br />
它们的重要差别是叶柄与叶片之间的角度，一个是直角，一个是钝角。因此，如果使用序列中的小片断（子序列）作为序列的表征，就很容易将二者区分开来。<br />
<img src="None" alt="Pasted%20image%2020211211160313.png" /></p>
<h2 id="优缺点">优缺点</h2>
<h3 id="优点">优点</h3>
<ul>
<li>具有可解释性<br />
</li>
<li>鲁棒性强<br />
</li>
<li>相对于最近邻算法速度快</li>
</ul>
<h2 id="缺点">缺点</h2>
<ul>
<li>算法相对简单，花费时间较长<br />
</li>
<li>一般用于二分类和聚类，不支持多分类</li>
</ul>
<h2 id="用途">用途</h2>
<ul>
<li>训练分类模型<br />
</li>
<li>解释分类原因<br />
</li>
<li>用于选择时间区间和维度</li>
</ul>
<h2 id="方法">方法</h2>
<p>算法的核心是如何找到最有代表子序列（文章第三部分）。首先使用滑动时间窗口获取所有可能子序列，然后，使用使信息增益高的作为切分策略。</p>
<h3 id="暴力找">暴力找</h3>
<p>其最简单的实现方法包含如下两步：<br />
* 利用穷举方法找到所有可选子序列作为备选项。<br />
* 找到其中信息增益（该子序列能否能更好区分不同类别）最大的片断。<br />
后面的方法都基于这个算法。<br />
<img src="None" alt="Pasted%20image%2020211210102435.png" /><br />
其中D是训练使用的数据集，取滑动窗口的长度最小为MINLEN，最长为MAXLEN的所有子序列作为候选集Candidates，函数CheckCandidate()用于计算信息增益，具体方法是计算每个时间序列到候选对象的距离。将其放在实数线上，并标注上类别。<br />
<img src="None" alt="Pasted%20image%2020211211162736.png" /><br />
可以看到，如果其中某个候选者，所有正例离它都近，所有反例离它都远，也就是说它可以很好地区分二者，则它的信息增益较大。<br />
其中一个序列T与了一个子序列S的距离被定义为：<br />
SubsequenceDist(T, S) = min(Dist(S, S'))<br />
其中S'是序列T的子序列，在序列T中查找与子序列S最近似的子序列S‘，并计算S到S'间的距离。因此，不需要把叶子方向摆正，只要两片叶子里包含相似的子序列就能找到。</p>
<h3 id="子序列早弃">子序列早弃</h3>
<p>为减少计算量，在计算过程中发现距离比已知最大的距离还大时，则不再继续计算。<br />
<img src="None" alt="Pasted%20image%2020211210180855.png" /></p>
<h3 id="熵剪枝">熵剪枝</h3>
<p>为减少计算量，在计算过程中如果信息增益比当前值还小，则不再继续计算。</p>
<p>在几种方法中，熵剪枝速度最快<br />
<img src="None" alt="Pasted%20image%2020211210172113.png" /></p>
<h2 id="用法">用法</h2>
<ul>
<li>安装<br />
代码集成在pyts包中（1.1K
Star），pyts是处理时间序列的类似scikit-learn的函数库。<br />
<code>$ pip install pyts</code><br />
</li>
<li>示例：<br />
<a
href="https://zhuanlan.zhihu.com/p/359666547">基于Shapelet的时间序列分类方法实战</a><br />
<a href="https://zhuanlan.zhihu.com/p/272691705">pyts库的介绍</a></li>
</ul>
<h2 id="启发">启发</h2>
<ul>
<li>可以将时序看作决策树，子序列看作特征。<br />
</li>
<li>找到最典型的特征，类似于人的思考方式。</li>
</ul>
]]></content>
      <tags>
        <tag>时序</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_时序模型TDTS</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/9_%E6%97%B6%E5%BA%8F/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E6%97%B6%E5%BA%8F%E6%A8%A1%E5%9E%8BTDTS/</url>
    <content><![CDATA[<p>#论文阅读 #时序</p>
<h2 id="基本信息">基本信息</h2>
<ul>
<li>论文题目：基于趋势特征表示的shapelet分类方法<br />
（Shapelet classification method based on trend feature
representation）<br />
</li>
<li>论文地址：http://www.joca.cn/EN/Y2017/V37/I8/2343</li>
</ul>
<h2 id="原理">原理</h2>
<p>在Shaplet被提出后的几年里，出现了很多算法来提高Shapelet效率和扩展其应用范围，《Shapelet
classification method based on trend feature
representation》简称TDTS提出了一种基于趋势的top-K shapelet。</p>
<p>其核心方法有三个：</p>
<ul>
<li><p>对分段后的子序列进行基于趋势的符号化处理<br />
符号化的原理请见SAX论文，简单地说，它实现了连续到离散的转化，用简单的值表征一个序列，包含趋势的符号化方法用二元组&lt;K,u&gt;表示序列，其中K是斜率，u是该序列的终点值。<br />
它使用滑动窗口计算窗口内的斜率，当斜率变化大于某一阀值时（趋势改变时），则产生一个分段点u并继续滑动．所有分段完成后，后对每一段进行符号化，最终生成转换后的
TFSA．<br />
<img
src="https://upload-images.jianshu.io/upload_images/5357893-a7739795f61d2f84.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/997" /><br />
</p></li>
<li><p>保持趋势特征的shapelet发现算法<br />
随机覆盖序列的子序列，然后对未覆盖的子序列进行Hash碰撞检测，得出碰撞频次，进行频次分析．使用该方法选出的shapelet在自身所在类中碰撞频次较高，而在其它类中频次较低，因此更具代表性．</p></li>
<li><p>使用图对子序列进行相关性分析，去除相关特征。<br />
把上一步得到的shapelets按信息增益排序，然后作为点加入图中；依次遍历所有点，计算它与其它点是否相似，如果相似，则在两点间建立一条边；然后开始从信息增益最大的点开始加入目标集合，如果与该点相似的其它点（有边相连）已加入目标集合，则跳过该点．由此保证目标集合中的点尽量不相关．</p></li>
</ul>
<h2 id="问与答">问与答</h2>
<ul>
<li>趋势指啥？<br />
趋势指上升（正值）、降（负值）、平稳（零）等时间趋势<br />
</li>
<li>用图干啥？<br />
当获取多个子序列时，去掉其中相关性强的子序列<br />
</li>
<li>为啥取Top-k？<br />
从所有可选的shapelets里选前k个最重要的子序列，相对于只取最重要的一个子序列，有更强的表征能力。<br />
</li>
<li>图和趋势有什么关系？<br />
文中同时使用了这两种方法，它们之前没有什么关系。</li>
</ul>
]]></content>
      <tags>
        <tag>时序</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino简单实例之一_人体传感器</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/01%EF%BC%BFArduino%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B%E4%B9%8B%E4%B8%80_%E4%BA%BA%E4%BD%93%E4%BC%A0%E6%84%9F%E5%99%A8/</url>
    <content><![CDATA[<h1
id="arduino简单实例之一_人体传感器">Arduino简单实例之一_人体传感器</h1>
<p>#Arduino</p>
<h3 id="说明">1) 说明</h3>
<p>人体红外感应模块是基于红外线技术的自动控制产品。附近有人时，对应引脚高电平，反之为低平台。<br />
5米内有效。可用螺丝（下图中橙色部分）调节灵敏度和延时。</p>
<h3 id="硬件">2) 硬件</h3>
<p>HC-SR501 人体红外感应模块，Arduinouno，杜邦线</p>
<h3 id="连接">3) 连接</h3>
<p>VCC接 Arduino 3.3V<br />
GND接 Arduino GND<br />
OUT接 Digital 2</p>
<p><img
src="https://img-%20blog.csdn.net/20170220124753890?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<h4 id="代码">4) 代码</h4>
<pre><code>#define PIN_NUM 2  
  
void setup()  &#123;  
  Serial.begin(9600);  
  pinMode(PIN_NUM,INPUT);  
&#125;  
  
void loop()  &#123;  
  if(digitalRead(PIN_NUM)==HIGH)&#123;  
    Serial.println(&quot;Someone here!&quot;);  
  &#125;     
  else &#123;  
    Serial.println(&quot;Nobody&quot;);  
  &#125;  
  delay(1000);  
&#125;  
  </code></pre>
<p><strong>（请注意：因各厂商硬件不同，引脚位置可能有差异,具体请见硬件说明书）</strong></p>
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino综合实例之一_避障小车</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/01%EF%BC%BFArduino%E7%BB%BC%E5%90%88%E5%AE%9E%E4%BE%8B%E4%B9%8B%E4%B8%80_%E9%81%BF%E9%9A%9C%E5%B0%8F%E8%BD%A6/</url>
    <content><![CDATA[<h1 id="arduino综合实例之一_避障小车">Arduino综合实例之一_避障小车</h1>
<p>#Arduino</p>
<h3 id="说明">1. 说明：</h3>
<p>此实例实现了通过蓝牙连接小车和手机，在手机端用软件控制小车前进，后退，左／右转向，控制行驶速度。并能让小车自动行驶，躲避障碍。<br />
我买的是最便宜的黄色四驱小车，加了一个电机驱动模块（用于控制小车），一个蓝牙模块（用于与手机连接），一个距离传感器（测试前方是否有障碍物），一个舵机（在遇到障碍时，控制距离传感器转动，判断左／右哪边空间更大）。</p>
<h3 id="硬件">2. 硬件：</h3>
<p>（加起来百十来块钱）</p>
<h4 id="小车硬件">1) 小车硬件</h4>
<p>小车（30+），含车架，车轮，电动机等。最便宜的一套30块钱左右（四驱），当然也不怎么结实。实验用没什么问题。</p>
<h4 id="电机驱动">2) 电机驱动</h4>
<p>电机驱动模块可使用L298n（5+）或L293D（8+）。一个L298N可驱动两个电机，一个L293D可驱动四个电机。我使用的是一个L298N，控制四个电机（两两串联，也带得动）。<br />
不太喜欢L293D扩展板，它是Arduino UNO<br />
R3的扩展板，是直接插在Arduino板上用的，我买的那一块，虽然能接几个舵机，几个直流电机，但是要想再插传感器就比较麻烦了，还有TX/RX接蓝牙好像也没引出来。它虽然把A0-5以及几个供电引出来，可以焊上针脚使用，但还是麻烦。</p>
<h4 id="传感器和步进电机">3) 传感器和步进电机</h4>
<p>在小车上，一般用超声距离传感器（4+）加小舵机（6+）或红外距离传感器x
2<br />
（2+）用作判断前方是否有障碍物。有的小车正面安装一个超声，左前右前各安一个红外；有的把超声安在一个小舵机上，通过步进电机实现“转头”的功能。<br />
超声距离传感器可测到具体的距离，而红外距离传感器则是设定一个阀值，据此判断回传0或1。由于日光里也有红外线，所以在户外会有一定影响，建议使用超声传感器加舵机的方案。</p>
<h4 id="电池和充电器">4) 电池和充电器</h4>
<p>可使用航模电池加充电器（35+），也可以用电池盒。由于需要提供Arduino板和电机驱动的供电，一般使用6-12V，用电池盒试了一次，电压降得很快，建议购买航模充电电池。</p>
<h4 id="arduino板">5) Arduino板</h4>
<p>本例中使用了ArduinoUNO R3 (15+) 和sensor shieldv5.0
扩展板（6+）<br />
Arduino上一般有一个3.3V和一个5V供电，三个GND，外接硬件超过两个，供电就比较难插，这里至少需要一个蓝牙模块，一个距离传感器，一个控制传感器方向的舵机，一个电机驱动模块。扩展板为每个IO都配上了VCC和GND；且sensor<br />
shield v5.0可直接插在Arduino UNO R3上，非常方便。</p>
<h4 id="小车控制">6) 小车控制</h4>
<p>红外遥控接收器（2+）或蓝牙模块（17+）<br />
红外遥控和蓝牙模块取其中之一即可，各有优势：红遥控接收器很便宜，可以和任何一个家用遥控板配合使用，但是必须对准，才起作用，小车行进的过程中就不太好用，另外因为日光中有红外线，所以户外不太好用；蓝牙模块稍贵，只要在附近就能收到，但需要其它蓝牙设备控制，如：手机控制，同时还要在手机端写相应程序，比较复杂。</p>
<h4 id="其它小配件">7) 其它小配件</h4>
<p>杜邦线若干（5+）：公对公，母对公，公对母，15-20cm，开关一个（0.2+）</p>
<h3 id="小问题">3. 小问题</h3>
<h4 id="超声传感器如何固定">1) 超声传感器如何固定？</h4>
<p>超声传感器一般安装在小车前端，有时通过舵机相连。有的店卖一些塑料的连接板，购买时请注意和超声传感器是否配套，如不配套，可能安装不上，或者影响侦测距离。</p>
<h4 id="如何调速">2) 如何调速？</h4>
<p>对于调速，有人说通过使能端调速ENA/ENB，我用的是L298n红板，试了不管用，于是用Arduino的5,6,9,10（PWM）连接电机驱动板，并用AnalogWrite写入0-255即可调速。</p>
<h4 id="小车电机如何与电机驱动板相连">3)
小车电机如何与电机驱动板相连？</h4>
<p>我买的小车电动机有个铜片，我在其上焊了两条杜邦线，然后用胶封了一下。</p>
<h3 id="后记">4. 后记：</h3>
<p>总体来说，装硬件调试还是很麻烦。对于增加更多功能，我觉得比较好的解决方案是与手机相连，把更多软件的逻辑放在手机端，也能更好地利用手机的传感器，声音，以及摄像头等等，以实现更多功能，同时又不会让电路变得过于复杂。比如：把手机放车上，使用其上的重力传感和指南针，判断小车位置，绘制地图（手机上也有距离传感器）；手机用蓝牙控制小车；用OpenGL辨别图像，实现追踪等功能；根据小车情况，加一些语音提示…</p>
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino简单实例之二_光敏传感器</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/02%EF%BC%BFArduino%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B%E4%B9%8B%E4%BA%8C_%E5%85%89%E6%95%8F%E4%BC%A0%E6%84%9F%E5%99%A8/</url>
    <content><![CDATA[<h1
id="arduino简单实例之二_光敏传感器">Arduino简单实例之二_光敏传感器</h1>
<p>#Arduino</p>
<h3 id="说明">1) 说明：</h3>
<p>光敏传感器是把光信号变成电信号的一种传感器，它利用半导体的光电效应制成的一种电阻值随入射光的强弱而改变的电阻器;入射光强,电阻减小,入射光弱,电阻增大。<br />
可用电位器（螺丝）调节亮度阀值，亮度大于设定值时DO输出低电平，反之输出高电平。AO输出具体的亮度值。建议购买四脚的（三脚的没有AO）</p>
<h3 id="硬件">2) 硬件：</h3>
<p>光敏传感器模块，Arduinouno，杜邦线</p>
<h3 id="连接">3) 连接：</h3>
<p>VCC接 arduino 的3.3或5V<br />
GND接 arduino的GND<br />
DO 接 arduino的Digital 2<br />
AO 接 arduino的Analog 0</p>
<p><img
src="https://img-%20blog.csdn.net/20170220125150050?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<h3 id="代码">4) 代码</h3>
<pre><code>#define PIN_A 0  
#define PIN_D 2  
  
void setup()   
&#123;  
  Serial.begin(9600);  
&#125;  
  
void loop()   
&#123;  
  int val;  
  val=analogRead(PIN_A);  
  Serial.print(&quot;a:&quot;);  
  Serial.print(val);  
  Serial.print(&quot;, d:&quot;);  
  val=digitalRead(PIN_D);  
  Serial.println(val);  
  delay(500);  
&#125;  </code></pre>
<p><strong>（请注意：因各厂商硬件不同，引脚位置可能有差异,具体请见硬件说明书）</strong></p>
<hr />
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino简单实例之三_土壤湿度传感器</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/03%EF%BC%BFArduino%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B%E4%B9%8B%E4%B8%89_%E5%9C%9F%E5%A3%A4%E6%B9%BF%E5%BA%A6%E4%BC%A0%E6%84%9F%E5%99%A8/</url>
    <content><![CDATA[<h1
id="arduino简单实例之三_土壤湿度传感器">Arduino简单实例之三_土壤湿度传感器</h1>
<p>#Arduino</p>
<h3 id="说明">1) 说明：</h3>
<p>用于土壤的湿度检测。<br />
可通过电位器调节土壤湿度的阀值，顺时针调节，控制的湿度会越大，逆时针越小；湿度低于设定值时，DO输出高电平，模块提示灯亮；湿度高于设定值时，DO输出低电平，模块提示灯灭。<br />
工作电压3.3V-5V。3V时，在空气中AO读取的值最大为695 ， 浸泡在水里的
最小值245；5V时，在空气中AO读取的值最大为1023<br />
，浸泡在水里的最小值 245。</p>
<h3 id="硬件">2) 硬件：</h3>
<p>土壤湿度传感器，Arduinouno，杜邦线</p>
<h3 id="连接">3) 连接：</h3>
<p>VCC接 Arduino 3.3V或5V<br />
GND接 Arduino GND<br />
AO 接 ArduinoAnalog<br />
DO接 Arduino Digital 4</p>
<p><img
src="https://img-%20blog.csdn.net/20170220130149517?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<h3 id="代码">4) 代码：</h3>
<pre><code>#define PIN_AO 2  
#define PIN_DO 4  
  
void setup() &#123;    
  pinMode(PIN_AO, INPUT);  
  pinMode(PIN_DO, INPUT);    
  Serial.begin(9600);    
&#125;    
  
void loop() &#123;  
  Serial.print(&quot;AO=&quot;);    
  Serial.print(analogRead(PIN_AO));  
  Serial.print(&quot;, DO=&quot;);    
  Serial.println(digitalRead(PIN_DO));  
  delay(500);    
&#125;   
  </code></pre>
<p>** **
<strong>（请注意：因各厂商硬件不同，引脚位置可能有差异,具体请见硬件说明书）</strong></p>
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino简单实例之四_PS2游戏摇杆</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/04%EF%BC%BFArduino%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B%E4%B9%8B%E5%9B%9B_PS2%E6%B8%B8%E6%88%8F%E6%91%87%E6%9D%86/</url>
    <content><![CDATA[<h1
id="arduino简单实例之四_ps2游戏摇杆">Arduino简单实例之四_PS2游戏摇杆</h1>
<p>#Arduino</p>
<h3 id="说明">1) 说明：</h3>
<p>PS2 游戏双轴摇杆传感器模块由采用金属 PS2 摇杆电位器制作，具有(X,Y)2
轴模拟输出，(Z) 1路按钮数字输出。可制作遥控器等互动作品。<br />
SW引脚按下去时输出低电平，反之输出高电平</p>
<h3 id="硬件">2) 硬件：</h3>
<p>PS2游戏摇杆joystick，Arduino uno，杜邦线</p>
<h3 id="连接">3) 连接：</h3>
<p>5V接 Arduino 5V<br />
GND接 Arduino GND<br />
URx接 Analog 0<br />
URy接 Analog 1<br />
SW 接 Digital 2</p>
<p><img
src="https://img-%20blog.csdn.net/20170220130702165?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<h3 id="代码">4) 代码</h3>
<pre><code>#define PIN_X 0    
#define PIN_Y 1    
#define PIN_Z 2    
  
void setup() &#123;    
  pinMode(PIN_X, INPUT);  
  pinMode(PIN_Y, INPUT);  
  pinMode(PIN_Z, INPUT);  
  Serial.begin(9600);  
&#125;    
  
void loop() &#123;    
  int x,y,z;    
  
  x=analogRead(PIN_X);    
  y=analogRead(PIN_Y);    
  z=analogRead(PIN_Z);    
  
  Serial.print(&quot;X=&quot;);    
  Serial.print(x);     
  Serial.print(&quot;\tY=&quot;);       
  Serial.print(y);    
  Serial.print(&quot;\tZ=&quot;);       
  Serial.println(z);    
  
  delay(1000);    
&#125;  
  </code></pre>
<p><strong>（请注意：因各厂商硬件不同，引脚位置可能有差异,具体请见硬件说明书）</strong></p>
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino简单实例之五_红外避障传感器模块</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/05%EF%BC%BFArduino%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B%E4%B9%8B%E4%BA%94_%E7%BA%A2%E5%A4%96%E9%81%BF%E9%9A%9C%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A8%A1%E5%9D%97/</url>
    <content><![CDATA[<h1
id="arduino简单实例之五_红外避障传感器模块">Arduino简单实例之五_红外避障传感器模块</h1>
<p>#Arduino</p>
<h3 id="说明">1) 说明：</h3>
<p>红外避障传感器具有一对红外线发射与接收管，发射管发射出一定频率的红外线，当检测方向遇到障碍物（反射面）时，红外线反射回来被接收管接收。它常用于安装在小车上，判断前方是否有障碍物。可通过电位器设置阀值。正前方有障碍时绿灯亮起，OUT引脚为低电平，反之为高电平。<br />
由于日光是也含红外线，所以大多数便宜红外模块在户外使用就会遇到问题。</p>
<h3 id="硬件">2) 硬件：</h3>
<p>红外避障模块，arduinouno，杜邦线</p>
<h3 id="连接">3) 连接:：</h3>
<p>VCC连接: Arduino
5V(说明书上写3.3V-5V，我的硬件只在5V下正常工作)<br />
GND连接: Arduino GND<br />
OUT连接: Digital 13<br />
<img
src="https://img-%20blog.csdn.net/20170220131517981?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<h3 id="代码">4) 代码:</h3>
<pre><code>int PIN_SENSOR = 13;  
  
void setup() &#123;  
  pinMode(PIN_SENSOR, INPUT);  
  Serial.begin(9600);  
&#125;  
  
void loop() &#123;  
  int x = digitalRead(PIN_SENSOR);  
  Serial.println(x);  
&#125;  
  </code></pre>
<p><strong>（请注意：因各厂商硬件不同，引脚位置可能有差异,具体请见硬件说明书）</strong></p>
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino简单实例之六_超声测距离传感器</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/06%EF%BC%BFArduino%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B%E4%B9%8B%E5%85%AD_%E8%B6%85%E5%A3%B0%E6%B5%8B%E8%B7%9D%E7%A6%BB%E4%BC%A0%E6%84%9F%E5%99%A8/</url>
    <content><![CDATA[<h1
id="arduino简单实例之六_超声测距离传感器">Arduino简单实例之六_超声测距离传感器</h1>
<p>#Arduino</p>
<h3 id="说明">1) 说明：</h3>
<p>超声波测距离传感器常用于小车的障碍物检测。它采用超声波回波测距原理，运用精确的时差测量技术，检测传感器与目标物之间的距离。<br />
Trig<br />
触发控制信号输入，Echo回响信号输出。写程序给Trig发送一个低高低的短时间脉冲,触发测距；pulseIn函数会等待引脚变为HIGH,开始计算时间,再等待变为LOW并停止计时。<br />
声速是:340m/1s 换算成 34000cm/ 1000000μs =&gt; 34
/1000。因为发送到接收,实际是相同距离走了2回,所以要除以2。<br />
距离(厘米) = (回波时间 * (34 / 1000)) / 2， 简化后的计算公式为 (回波时间
* 17)/ 1000</p>
<h3 id="硬件">2) 硬件：</h3>
<p>超声距离传感器HC-SR04，Arduino uno板，杜邦线</p>
<h3 id="连接">3) 连接：</h3>
<p>VCC接 Arduino 5V<br />
GND接 Arduino GND<br />
TRIG接 ArduinoDigital 12<br />
ECHO接 Arduino Digital 11<br />
<img
src="https://img-%20blog.csdn.net/20170220132302703?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<h3 id="代码">4) 代码：</h3>
<pre><code>#define PIN_TRIG 12  
#define PIN_ECHO 11  
    
float cm;  
float temp;  
    
void setup() &#123;    
  Serial.begin(9600);    
  pinMode(PIN_TRIG, OUTPUT);    
  pinMode(PIN_ECHO, INPUT);    
&#125;    
    
void loop() &#123;  
  digitalWrite(PIN_TRIG, LOW);  
  delayMicroseconds(2);  
  digitalWrite(PIN_TRIG, HIGH);  
  delayMicroseconds(10);  
  digitalWrite(PIN_TRIG, LOW);  
      
  temp = float(pulseIn(PIN_ECHO, HIGH));  
  cm = (temp * 17 )/1000;  
    
  Serial.print(&quot;Echo = &quot;);    
  Serial.print(temp);  
  Serial.print(&quot;,  Distance = &quot;);    
  Serial.print(cm);  
  Serial.println(&quot;cm&quot;);    
  delay(300);    
&#125;   
  </code></pre>
<p><strong>（请注意：因各厂商硬件不同，引脚位置可能有差异,具体请见硬件说明书）</strong></p>
<hr />
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino简单实例之七_红外遥控接收</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/07%EF%BC%BFArduino%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B%E4%B9%8B%E4%B8%83_%E7%BA%A2%E5%A4%96%E9%81%A5%E6%8E%A7%E6%8E%A5%E6%94%B6/</url>
    <content><![CDATA[<h1
id="arduino简单实例之七_红外遥控接收">Arduino简单实例之七_红外遥控接收</h1>
<p>#Arduino</p>
<h3 id="说明">1) 说明：</h3>
<p>红外接收模块适用于红外线遥控和红外线数据传输。对于不同的遥控器，区别只是接到的数字不同。<br />
注意要买三脚的红外接收头，而不是直接购买红外对管。当然也可以买电子积木的红外接收模块，它还多了一块小板和小灯，质量也相对好一些，容易固定，价钱稍贵。<br />
因为日光中有红外线，所以在室外使用可能受到影响。</p>
<h3 id="硬件">2) 硬件：</h3>
<p>TL1838万能接收头，Arduinouno，杜邦线</p>
<h3 id="连接">3) 连接：</h3>
<p>VCC接 Arduino 3.3V或5.5V<br />
GND接 Arduino GND <br />
OUT接 Digital 11</p>
<p><img
src="https://img-%20blog.csdn.net/20170220133058312?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<h3 id="代码">4) 代码</h3>
<pre><code>#include &lt;IRremote.h&gt;  
   
int PIN_RECV = 11;  
IRrecv irrecv(PIN_RECV);  
decode_results results;  
   
void setup()  
&#123;  
  Serial.begin(9600);  
  irrecv.enableIRIn();  
&#125;  
   
void loop() &#123;  
  if (irrecv.decode(&amp;results)) &#123;  
    Serial.println(results.value);  
    irrecv.resume();  
  &#125;  
&#125;  
  </code></pre>
<p>代码中用到了IRemote库，需要下载Arduino_IRremote_master.zip包，解压后，放入/usr/share/arduino/libraries/目录下。</p>
<p><strong>（请注意：因各厂商硬件不同，引脚位置可能有差异,
具体请见硬件说明书）</strong></p>
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino简单实例之八_蓝牙模块</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/08%EF%BC%BFArduino%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B%E4%B9%8B%E5%85%AB_%E8%93%9D%E7%89%99%E6%A8%A1%E5%9D%97/</url>
    <content><![CDATA[<h1 id="arduino简单实例之八_蓝牙模块">Arduino简单实例之八_蓝牙模块</h1>
<p>#Arduino</p>
<h3 id="说明">1) 说明：</h3>
<p>蓝牙模块用于和手机或其它带蓝牙的设备通讯。蓝牙设备分为主从两种模式，作为主设备时，它查找和连接其它设备；作为从设备时只能被只它设备连接；通讯模式分透明传输和AT命令模式。最好购买主从一体的蓝牙模块。<br />
下面介绍的是最常用的是作为从设备与手机相接，之后进入透明传输。这也是最简单的一种。<br />
注意:
Arduino与电脑和蓝牙模块通讯都使用串口TX/RX，同时操作时产生冲突，程序写入Arduino时要断开与蓝牙相连的RX,<br />
执行时要注意，Serial.println()会将内容输出到蓝牙的另一端，而不是在电脑端显示信息。<br />
另外，蓝牙的默认密码是0000或1234。</p>
<h3 id="硬件">2) 硬件：</h3>
<p>蓝牙模块HC-06，Arduino uno，Android手机，杜邦线</p>
<h3 id="连接">3) 连接</h3>
<p>VCC：接Arduino的5V或者3.3V<br />
GND：接Arduino的GND<br />
TXD：发送端，接Arduino的RX<br />
RXD：接收端，接Arduino的TX<br />
<img
src="https://img-%20blog.csdn.net/20170220133613630?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /><br />
（千万注意，不能接错，若接收发端与电源连接，会烧掉）</p>
<h3 id="代码">4) 代码</h3>
<pre><code>void setup()  
&#123;  
  Serial.begin(9600);  
&#125;  
  
void loop()  
&#123;  
  while(Serial.available())  
  &#123;  
    char c=Serial.read();  
    Serial.println(c);  
  &#125;  
&#125;   </code></pre>
<p>以上程序运行时，我拔掉了Android上的TX线(也就是Arduino向蓝牙模块发数据的线),此时串口的输出可显示在电脑上。</p>
<p>Android端程序，可以从CSDN下载car137源码，我试过，可正常运行。</p>
<p><strong>（请注意：因各厂商硬件不同，引脚位置可能有差异,具体请见硬件说明书）</strong></p>
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino简单实例之九_温湿度传感器模块</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/09%EF%BC%BFArduino%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B%E4%B9%8B%E4%B9%9D_%E6%B8%A9%E6%B9%BF%E5%BA%A6%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A8%A1%E5%9D%97/</url>
    <content><![CDATA[<h1
id="arduino简单实例之九_温湿度传感器模块">Arduino简单实例之九_温湿度传感器模块</h1>
<p>#Arduino</p>
<h3 id="说明">1) 说明：</h3>
<p>DHT11数字温湿度传感器是一款含有已校准数字信号输出的温湿度复合传感器。</p>
<h3 id="硬件">2) 硬件：</h3>
<p>DTH11温湿度传感器电子积木模块，Arduinouno，杜邦线</p>
<h3 id="连接">3) 连接：</h3>
<p>VCC接 Arduino 3.3V或5V<br />
GND接 Arduino GND<br />
OUT接 Digital 2</p>
<p><img
src="https://img-%20blog.csdn.net/20170220134021152?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<h3 id="代码">4) 代码</h3>
<pre><code>#include &lt;dht11.h&gt;  
  
dht11 DHT11;  
#define PIN_DHT11 2  
  
void setup()  
&#123;  
  Serial.begin(9600);  
&#125;  
  
void loop()  
&#123;  
  DHT11.read(PIN_DHT11);  
  Serial.print(&quot;Humidity (%): &quot;);  
  Serial.println((float)DHT11.humidity, 2);  
  Serial.print(&quot;Temperature (oC): &quot;);  
  Serial.println((float)DHT11.temperature, 2);  
  delay(500);  
&#125;  
  </code></pre>
<p>代码中用到了dht11库，需要下载Dht11.zip
包，解压后，放入/usr/share/arduino/libraries/目录下。</p>
<p>** （请注意：因各厂商硬件不同，引脚位置可能有差异 ,
具体请见硬件说明书） **</p>
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino简单实例之十_舵机</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/10%EF%BC%BFArduino%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B%E4%B9%8B%E5%8D%81_%E8%88%B5%E6%9C%BA/</url>
    <content><![CDATA[<h1 id="arduino简单实例之十_舵机">Arduino简单实例之十_舵机</h1>
<p>#Arduino</p>
<h4 id="说明">说明</h4>
<p>舵机的旋转不像普通电机那样只是转圈圈，它可以根据你的指令旋转到0至180度之间的任意角度然后精准的停下来，常用于控制机器人。</p>
<p>舵机的转动的角度是通过调节PWM（脉冲宽度调制）信号的占空比来实现的。需要使用Arduino上的PWM口控制（数字前带~的），Arduino的驱动能力有限，所以当需要控制1个以上的舵机时需要外接电源。一个机器人经常需要很多个舵机同时工作，此时需要加一个舵机控制板，舵机控制板本身是一个单片机，它不但能接16/24/32个舵机，同时也简化了舵机操作命令。</p>
<p>下例中使用的是9g的小舵机，用arduino板上的5V供电，大的舵机有的需要外部供电才能驱动，外接电源时需要将降到舵机指定的电压，否则会烧坏舵机。</p>
<h4 id="硬件">硬件</h4>
<p>舵机SG90，Arduino uno，杜邦线</p>
<h4 id="接线">接线</h4>
<p>GND(棕色)接 Arduino GND<br />
PWM(橙色)接 Arduino Digital 10<br />
VCC(红色)接 Arduino 5V</p>
<p><img
src="https://img-blog.csdn.net/20170220134325714?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<h4 id="代码">代码</h4>
<div class="sourceCode" id="cb1"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;Servo.h&gt;</span><span class="pp">  </span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="pp">#define PIN_SERVO 10  </span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>Servo myservo<span class="op">;</span>  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> setup<span class="op">()</span>  </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="op">&#123;</span>  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  myservo<span class="op">.</span>attach<span class="op">(</span>PIN_SERVO<span class="op">);</span>  </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="op">&#125;</span>  </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> loop<span class="op">()</span>  </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="op">&#123;</span>  </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  myservo<span class="op">.</span>write<span class="op">(</span><span class="dv">0</span><span class="op">);</span>  </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  delay<span class="op">(</span><span class="dv">1000</span><span class="op">);</span>  </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  myservo<span class="op">.</span>write<span class="op">(</span><span class="dv">80</span><span class="op">);</span>  </span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>  delay<span class="op">(</span><span class="dv">1000</span><span class="op">);</span>  </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  myservo<span class="op">.</span>write<span class="op">(</span><span class="dv">160</span><span class="op">);</span>  </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  delay<span class="op">(</span><span class="dv">1000</span><span class="op">);</span>  </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>  myservo<span class="op">.</span>write<span class="op">(</span><span class="dv">80</span><span class="op">);</span>  </span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  delay<span class="op">(</span><span class="dv">1000</span><span class="op">);</span>  </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  myservo<span class="op">.</span>write<span class="op">(</span><span class="dv">0</span><span class="op">);</span>  </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  delay<span class="op">(</span><span class="dv">1000</span><span class="op">);</span>  </span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="op">&#125;</span>   </span></code></pre></div>
<p>代码中用到了Servo库，它是Arduino自带的库，不需要另外下载安装。</p>
<p><strong>请注意：因各厂商硬件不同，引脚位置可能有差异 ,
具体请见硬件说明书）</strong></p>
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino简单实例十一_四脚三色LED灯</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/11%EF%BC%BFArduino%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B%E5%8D%81%E4%B8%80_%E5%9B%9B%E8%84%9A%E4%B8%89%E8%89%B2LED%E7%81%AF/</url>
    <content><![CDATA[<h1
id="arduino简单实例十一_四脚三色led灯">Arduino简单实例十一_四脚三色LED灯</h1>
<p>#Arduino</p>
<h3 id="说明">1) 说明：</h3>
<p>LED灯是发光二级管，反着接电阻无穷大，正着接不需要考虑电阻。一般小的LED灯可通过的最大电流为30mA，如电压为5V，加一个220欧电阻后，电流约22mA左右，则可以保证不烧坏LED。<br />
另外，控制明暗需要接Arduino的PWM口（数字前带~的）</p>
<h3 id="硬件">2) 硬件：</h3>
<p>四脚三色LED灯，面包板，电阻220欧三只，Arduino uno，杜邦线</p>
<h3 id="连接">3) 连接：</h3>
<p>下例为共阳的LED灯，长脚的为阳极接3.3V<br />
三个颜色的引脚分别接一个220欧的电阻</p>
<p><img
src="https://img-%20blog.csdn.net/20170220134950307?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<h3 id="代码">4) 代码</h3>
<pre><code>int led1 = 9;  
int led2 = 10;  
int led3 = 11;  
  
void setup()  
&#123;  
  pinMode(led1,OUTPUT);  
  pinMode(led2,OUTPUT);  
  pinMode(led3,OUTPUT);  
&#125;  
  
void setColor(int red,int green,int blue)  
&#123;  
  analogWrite(led1,255-red);  
  analogWrite(led2,255-green);  
  analogWrite(led3,255-blue);  
&#125;  
  
void loop()  
&#123;  
  int i,j;  
  for(i=0,j=255;i&lt;256;i++)  
  &#123;  
    setColor(i,j,0);  
    delay(4);  
    j--;  
  &#125;  
  delay(100);           //绿色向红色渐变  
  for(i=0,j=255;i&lt;256;i++)  
  &#123;  
    setColor(j,0,i);  
    delay(4);  
    j--;  
  &#125;  
  delay(100);           //红色向蓝色渐变  
  for(i=0,j=255;i&lt;256;i++)  
  &#123;  
    setColor(0,i,j);  
    delay(4);  
    j--;  
  &#125;  
  delay(100);          //蓝色向绿色渐变  
&#125;  
  </code></pre>
<p>** （请注意：因各厂商硬件不同，引脚位置可能有差异 ,
具体请见硬件说明书） **</p>
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino简单实例十二_蜂鸣器播放生日快乐</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/12%EF%BC%BFArduino%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B%E5%8D%81%E4%BA%8C_%E8%9C%82%E9%B8%A3%E5%99%A8%E6%92%AD%E6%94%BE%E7%94%9F%E6%97%A5%E5%BF%AB%E4%B9%90/</url>
    <content><![CDATA[<h1
id="arduino简单实例十二_蜂鸣器播放生日快乐">Arduino简单实例十二_蜂鸣器播放生日快乐</h1>
<p>#Arduino</p>
<h3 id="说明">1) 说明：</h3>
<p>蜂鸣器是一种一体化结构的电子讯响器，采用直流电压供电，广泛应用于计算电子玩具、定时器等电子产品中作发声器件。<br />
蜂鸣器分有源和无源。如果是有源的，单片机只要输出高低电平就可以，如果是无源的，单片机就要输出PWM波才可以让蜂鸣器发声。</p>
<h3 id="硬件">2) 硬件：</h3>
<p>5V有源蜂鸣器，Arduinouno，杜邦线</p>
<h3 id="连接">3) 连接：</h3>
<p>正极连 ArduinoDigital 4<br />
负极连 Arduino GND</p>
<p><img
src="https://img-%20blog.csdn.net/20170220135301780?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<h3 id="代码">4) ­­代码：</h3>
<pre><code>int PIN_SPEAKER = 4;  
int length = 25;  
char notes[] = &quot;ggagCbggagDCggGECbaffECDC&quot;;  
int beats[] = &#123;1,1,2,2,2,4, 1,1,2,2,2,4, 1,1,2,2,2,2,2, 1,1,2,2,2,4,1&#125;;  
int tempo = 300;  
   
void playTone(int tone, int duration) &#123;  
  for (long i = 0; i &lt; duration * 1000L; i += tone * 2) &#123;  
    digitalWrite(PIN_SPEAKER, HIGH);  
    delayMicroseconds(tone);  
    digitalWrite(PIN_SPEAKER, LOW);  
    delayMicroseconds(tone);  
  &#125;  
&#125;  
   
void playNote(char note, int duration) &#123;  
  char names[] = &#123;&#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;, &#39;g&#39;, &#39;a&#39;, &#39;b&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;&#125;;  
  int tones[] = &#123;1915, 1700, 1519, 1432, 1275, 1136, 1014, 956, 853, 759, 716, 637, 568&#125;;  
   
  for (int i = 0; i &lt; 12; i++) &#123;  
    if (names[i] == note) &#123;  
      Serial.print(&quot;value:&quot;);  
      Serial.println(note);  
      playTone(tones[i]*2, duration);  
    &#125;  
  &#125;  
&#125;  
   
void setup() &#123;  
  pinMode(PIN_SPEAKER, OUTPUT);  
&#125;  
   
void loop() &#123;  
  for (int i = 0; i &lt; length; i++) &#123;  
    if (notes[i] == &#39; &#39;) &#123;  
      delay(beats[i] * tempo);   
    &#125; else &#123;  
      playNote(notes[i], beats[i] * tempo);  
    &#125;  
    delay(tempo / 2);   
  &#125;  
&#125;  
  </code></pre>
<p>** （请注意：因各厂商硬件不同，引脚位置可能有差异 ,
具体请见硬件说明书） **</p>
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino简单实例十三_四位数码管</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/13%EF%BC%BFArduino%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B%E5%8D%81%E4%B8%89_%E5%9B%9B%E4%BD%8D%E6%95%B0%E7%A0%81%E7%AE%A1/</url>
    <content><![CDATA[<h1
id="arduino简单实例十三_四位数码管">Arduino简单实例十三_四位数码管</h1>
<p>#Arduino</p>
<h3 id="说明">1) 说明：</h3>
<p>数码管是一种半导体发光器件，其基本单元是发光二极管。因此也需要串联电阻，以防电流过大。每个数字由7条线组成，用a-<br />
g控制，同时用A1-A4控制当前设置的四个数字中的哪一个。</p>
<h3 id="硬件">2) 硬件：</h3>
<p>5461AS四位共阴数码管，Arduinouno，220欧电阻四个，线若干</p>
<h3 id="连接">3) 连接：</h3>
<p>限流电阻（4个）串联在阴极。A1，A2，A3，A4用于选择显示哪个字符，也是阴极。</p>
<p><img
src="https://img-%20blog.csdn.net/20170220135802330?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<h3 id="代码">4) 代码</h3>
<pre><code>#define d_a 2    
#define d_b 3    
#define d_c 4    
#define d_d 5     
#define d_e 6    
#define d_f 7    
#define d_g 8    
#define d_h 9    
    
#define COM1 10    
#define COM2 11    
#define COM3 12    
#define COM4 13    
    
unsigned char num[17][8] = &#123;    
 //a  b  c  d  e  f  g  h     
  &#123;1, 1, 1, 1, 1, 1, 0, 0&#125;,     //0    
  &#123;0, 1, 1, 0, 0, 0, 0, 0&#125;,     //1    
  &#123;1, 1, 0, 1, 1, 0, 1, 0&#125;,     //2    
  &#123;1, 1, 1, 1, 0, 0, 1, 0&#125;,     //3    
  &#123;0, 1, 1, 0, 0, 1, 1, 0&#125;,     //4    
  &#123;1, 0, 1, 1, 0, 1, 1, 0&#125;,     //5    
  &#123;1, 0, 1, 1, 1, 1, 1, 0&#125;,     //6    
  &#123;1, 1, 1, 0, 0, 0, 0, 0&#125;,     //7    
  &#123;1, 1, 1, 1, 1, 1, 1, 0&#125;,     //8    
  &#123;1, 1, 1, 1, 0, 1, 1, 0&#125;,     //9    
  &#123;1, 1, 1, 0, 1, 1, 1, 1&#125;,     //A    
  &#123;1, 1, 1, 1, 1, 1, 1, 1&#125;,     //B    
  &#123;1, 0, 0, 1, 1, 1, 0, 1&#125;,     //C    
  &#123;1, 1, 1, 1, 1, 1, 0, 1&#125;,     //D    
  &#123;1, 0, 0, 1, 1, 1, 1, 1&#125;,     //E    
  &#123;1, 0, 0, 0, 1, 1, 1, 1&#125;,     //F    
  &#123;0, 0, 0, 0, 0, 0, 0, 1&#125;,     //.    
&#125;;    
    
void setup()    
&#123;    
    pinMode(d_a,OUTPUT);    
    pinMode(d_b,OUTPUT);    
    pinMode(d_c,OUTPUT);    
    pinMode(d_d,OUTPUT);    
    pinMode(d_e,OUTPUT);    
    pinMode(d_f,OUTPUT);    
    pinMode(d_g,OUTPUT);    
    pinMode(d_h,OUTPUT);    
    
    pinMode(COM1,OUTPUT);    
    pinMode(COM2,OUTPUT);    
    pinMode(COM3,OUTPUT);    
    pinMode(COM4,OUTPUT);    
&#125;    
    
void loop()    
&#123;   
  for(int l = 0;l &lt; 10;l++ )    
  &#123;    
    for(int k = 0; k &lt; 10;k++)    
    &#123;    
      for(int j = 0; j &lt; 10; j++)    
      &#123;    
        for(int i = 0;i &lt; 10;i++)    
        &#123;    
          //1000/8=125    
          for(int q = 0;q&lt;125;q++)    
          &#123;    
            Display(1,l);   
            delay(2);    
            Display(2,k);    
            delay(2);    
            Display(3,j);    
            delay(2);    
            Display(4,i);    
            delay(2);    
          &#125;    
        &#125;    
      &#125;    
    &#125;    
  &#125;    
&#125;    
    
void Display(unsigned char com,unsigned char n) &#123;    
    digitalWrite(d_a,LOW);    
    digitalWrite(d_b,LOW);    
    digitalWrite(d_c,LOW);    
    digitalWrite(d_d,LOW);    
    digitalWrite(d_e,LOW);    
    digitalWrite(d_f,LOW);    
    digitalWrite(d_g,LOW);    
    digitalWrite(d_h,LOW);    
    
    switch(com) &#123;    
        case 1:    
            digitalWrite(COM1,LOW);    
            digitalWrite(COM2,HIGH);    
            digitalWrite(COM3,HIGH);    
            digitalWrite(COM4,HIGH);    
            break;    
        case 2:    
            digitalWrite(COM1,HIGH);    
            digitalWrite(COM2,LOW);    
            digitalWrite(COM3,HIGH);    
            digitalWrite(COM4,HIGH);    
            break;    
        case 3:    
            digitalWrite(COM1,HIGH);    
            digitalWrite(COM2,HIGH);    
            digitalWrite(COM3,LOW);    
            digitalWrite(COM4,HIGH);    
            break;    
        case 4:    
            digitalWrite(COM1,HIGH);    
            digitalWrite(COM2,HIGH);    
            digitalWrite(COM3,HIGH);    
            digitalWrite(COM4,LOW);   
            break;    
        default:break;    
    &#125;    
    digitalWrite(d_a,num[n][0]);       
    digitalWrite(d_b,num[n][1]);    
    digitalWrite(d_c,num[n][2]);    
    digitalWrite(d_d,num[n][3]);    
    digitalWrite(d_e,num[n][4]);    
    digitalWrite(d_f,num[n][5]);    
    digitalWrite(d_g,num[n][6]);    
    digitalWrite(d_h,num[n][7]);    
&#125;    
  </code></pre>
<p>** （请注意：因各厂商硬件不同，引脚位置可能有差异 ,
具体请见硬件说明书） **</p>
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino简单实例十四_小车</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/14%EF%BC%BFArduino%E7%AE%80%E5%8D%95%E5%AE%9E%E4%BE%8B%E5%8D%81%E5%9B%9B_%E5%B0%8F%E8%BD%A6/</url>
    <content><![CDATA[<h1 id="arduino简单实例十四_小车">Arduino简单实例十四_小车</h1>
<p>#Arduino</p>
<h3 id="说明">1) 说明：</h3>
<h4 id="a-l298n直流电机驱动模块控制两项步进电机">a)
L298N/直流电机驱动模块(控制两项步进电机)</h4>
<p>IN1-IN4 控制转动的方向，IN1为低电平, IN2为高电平,
电机反转；IN1为高电平,IN2 为低电平,电机正转；IN3和IN4控制另一轮。<br />
为了方便，把EN使动端与跳线连接（高电平），然后使用IN的状态控制走停</p>
<p>ENA</p>
<div class="line-block"></div>
<p>IN1</p>
<div class="line-block"></div>
<p>IN2</p>
<div class="line-block"></div>
<p>运行状态</p>
<p>---|---|---|---</p>
<p>0</p>
<div class="line-block"></div>
<p>任意</p>
<div class="line-block"></div>
<p>任意</p>
<div class="line-block"></div>
<p>停止</p>
<p>1</p>
<div class="line-block"></div>
<p>0</p>
<div class="line-block"></div>
<p>1</p>
<div class="line-block"></div>
<p>正转</p>
<p>1</p>
<div class="line-block"></div>
<p>1</p>
<div class="line-block"></div>
<p>0</p>
<div class="line-block"></div>
<p>反转</p>
<p>1</p>
<div class="line-block"></div>
<p>1</p>
<div class="line-block"></div>
<p>1</p>
<div class="line-block"></div>
<p>刹停</p>
<p>1</p>
<div class="line-block"></div>
<p>0</p>
<div class="line-block"></div>
<p>0</p>
<div class="line-block"></div>
<p>停止</p>
<h4 id="b-供电">b) 供电</h4>
<p>使用了航模专用的锂电池，主要考虑到它可以充电，标示为7.2V，充电后测量为8.4V，电池接电机控制模块的VCC，然后用电机控制模块输出的5V给Arduino板供电。输入电压在6V以下时，它就不能给Arduino板供电了。</p>
<h3 id="硬件">2) 硬件：</h3>
<p>直流电机驱动模块，Arduino
uno，杜邦线，电池，智能小车套装（含车架，车轮，电动机等）</p>
<h3 id="连接">3) 连接：</h3>
<p>电机驱动模块IN1-IN4 接单片机: IN1-D6 IN2-D7 IN3-D4 IN4-D5<br />
电机驱动模块GND 接电源GND 和 单片机GND<br />
电机驱动模块VCC 接电源VCC<br />
电机驱动模块+5 接单片机 VIN<br />
电机驱动模块OUT1-OUT2接步进电机1,OUT3-OUT4 接步进电机2</p>
<p><img
src="https://img-%20blog.csdn.net/20170220140159911?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<h3 id="代码">4) 代码：</h3>
<pre><code>#define PIN_CAR_IN1 5  
#define PIN_CAR_IN2 6  
#define PIN_CAR_IN3 9  
#define PIN_CAR_IN4 10  
  
void doForward() &#123;  
  digitalWrite(PIN_CAR_IN3,LOW);  
  digitalWrite(PIN_CAR_IN4,HIGH);  
  digitalWrite(PIN_CAR_IN1,LOW);  
  digitalWrite(PIN_CAR_IN2,HIGH);  
&#125;  
  
void doBackward() &#123;  
  digitalWrite(PIN_CAR_IN3,HIGH);  
  digitalWrite(PIN_CAR_IN4,LOW);  
  digitalWrite(PIN_CAR_IN1,HIGH);  
  digitalWrite(PIN_CAR_IN2,LOW);  
&#125;  
  
void doStop() &#123;  
  digitalWrite(PIN_CAR_IN3,LOW);  
  digitalWrite(PIN_CAR_IN4,LOW);  
  digitalWrite(PIN_CAR_IN1,LOW);  
  digitalWrite(PIN_CAR_IN2,LOW);  
  
  digitalWrite(PIN_CAR_IN3,HIGH);  
  digitalWrite(PIN_CAR_IN4,HIGH);  
  digitalWrite(PIN_CAR_IN1,HIGH);  
  digitalWrite(PIN_CAR_IN2,HIGH);  
&#125;  
  
void doLeft() &#123;  
  digitalWrite(PIN_CAR_IN3,HIGH);  
  digitalWrite(PIN_CAR_IN4,LOW);  
  digitalWrite(PIN_CAR_IN1,LOW);  
  digitalWrite(PIN_CAR_IN2,HIGH);     
&#125;  
  
void doRight() &#123;  
  digitalWrite(PIN_CAR_IN3,LOW);  
  digitalWrite(PIN_CAR_IN4,HIGH);  
  digitalWrite(PIN_CAR_IN1,HIGH);  
  digitalWrite(PIN_CAR_IN2,LOW);  
&#125;  
  
void setup()  
&#123;  
  pinMode(PIN_CAR_IN1,OUTPUT);  
  pinMode(PIN_CAR_IN2,OUTPUT);  
  pinMode(PIN_CAR_IN3,OUTPUT);  
  pinMode(PIN_CAR_IN4,OUTPUT);  
  
  digitalWrite(PIN_CAR_IN1, OUTPUT);  
  digitalWrite(PIN_CAR_IN2, OUTPUT);  
  digitalWrite(PIN_CAR_IN3, OUTPUT);  
  digitalWrite(PIN_CAR_IN4, OUTPUT);  
  
  Serial.begin(9600);  
&#125;  
  
void loop()  
&#123;  
  doForward();  
  delay(1000);    
  doStop();  
  delay(1000);  
  doBackward();  
  delay(1000);  
  doStop();  
  delay(1000);    
  doLeft();  
  delay(1000);    
  doStop();  
  delay(1000);  
  doRight();  
  delay(1000);  
  doStop();  
  delay(1000);   
&#125;  
  </code></pre>
<p>** （请注意：因各厂商硬件不同，引脚位置可能有差异 ,
具体请见硬件说明书） **</p>
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino介绍_硬件</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/Arduino%E4%BB%8B%E7%BB%8D_%E7%A1%AC%E4%BB%B6/</url>
    <content><![CDATA[<h1 id="arduino介绍_硬件">Arduino介绍_硬件</h1>
<p>#Arduino</p>
<h2 id="初学者都要买什么">1 初学者都要买什么？</h2>
<p>一块Arduino板（推荐Arduino uno，买时带线）<br />
杜邦线（公对公，公对母，母对母都要一些）<br />
一块面包板<br />
一些发光二极管<br />
一些电阻（几块钱一包的组合装）</p>
<p>以上硬件就可以做最简单的实验，加上运费五十块钱也够了，比小孩玩的电子积木还便宜。也可以顺便买上几个便宜的传感器，无需一次买全，也许过两天就不玩了呢？最好等掌握了基本的再补货。<br />
如果没有万用表，最好花几块钱买个小电压表（比如：在户外测试小车时，经常遇到气温影响电压的问题）。我用的是：两线，量程是3.2-30V<br />
的数显电压表(D3B3)。焊上了两上公头。<br />
<img
src="https://img-%20blog.csdn.net/20170220115906926?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<h2 id="几种常用的arduino板">2 几种常用的Arduino板</h2>
<h3 id="arduino-uno">1) Arduino uno</h3>
<p><img
src="https://img-%20blog.csdn.net/20170220120349917?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /><br />
Arduino<br />
uno是Arduino平台的参考标准模板。初学一般都买它。uno比较中规中矩，相应的扩展板也多，自带USB转串口，供电和烧写都比较容易，也好插。不过真正做成玩具时，就可以选择一些小而便宜的，比如mini板。如需要更强的功能，可选择mega板。简要说明如下：</p>
<ol type="a">
<li><p>uno支持三种供电：<br />
通过外接电源供电（黑圆口，可以接较高电压，传说是7-12V，最好7V）<br />
USB供电（通常是USB供电，即写程序时就由PC供电了）。<br />
Vin引脚供电（InputVoltage，一般接电池，连接到这个端口的电源需要稳压，否则非常容易损坏板子，我接过5V使用正常，有传说它和黑圆口是通着的）。</p></li>
<li><p>数字端口：D0-D13，每个数字端口可以提供最高40mA电流和5V电压</p></li>
<li><p>PWM<sub>：以</sub>开头的数字端口，脉冲宽度调制，它是利用微处理器的数字输出来控制模拟电路的一种技术。最简单的例子就是控制LED的亮度</p></li>
<li><p>模拟端口：A0-A5，完全具备上面数字端口的功能，另外还具备10位的分辨率（整型0~1023）来作为输入读取电压大小。</p></li>
<li><p>ICSP：in circuit serial programmable （在线串行编程），</p></li>
<li><p>AREF：Reference voltage for the analoginputs<br />
(模拟输入的基准电压），数字信号只有两种形态，高电平和低电平。高低电平是通过一个参考电压（AREF）确定的，高于AREF的电平即被认为是高电平，低于AREF的电平即被认为是低电平。Arduino默认的参考电压大约是1.1V，可以通过AREF端口设置外部参考电压。</p></li>
<li><p>IOREF：IO是输入输出口 REF的意思是参考电压</p></li>
</ol>
<h3 id="android-nano">2) Android nano</h3>
<p><img
src="https://img-%20blog.csdn.net/20170220120410277?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /><br />
nano比uno小一些，也稍便宜，它也自带usb口（USB<br />
mini-B），大多数情况下针都焊在下边，插在面包板上使用。接线和uno没什么差别。使用时需要在Arduino<br />
IDE中Tools-&gt;Board-&gt;选择对应的型号即可。</p>
<h3 id="android-mini">3) Android mini</h3>
<p><img
src="https://img-%20blog.csdn.net/20170220120526514?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /><br />
这个板子便宜，小巧，基本功能都有。它和uno的主要差别在于不自带串口烧写，需要外加USB
to TTL板烧写程序。使用时需要在Arduino<br />
IDE中Tools-&gt;Board-&gt;选择对应的型号即可。（买mini板时要看好型号，我买的是ATMEGA328P5V/16M，在Arduino<br />
IDE中需要做对应设置Tools-&gt;Board-&gt;AndroidPro or Pro Mini
5V/16MHz,W/ATmega 328)<br />
USB to<br />
TTL板用于电脑向mini板烧写程序，现在一般有两种，一种带Reset引脚，一种不带。对于不带Reset引脚的板子，在烧写时，IDE先显示Compiling<br />
sketch…，然后显示uploading，此时（显示uploading时）按下Reset键，即可正常烧写（这样就不用改硬件了）。当然最好买带Reset引脚的，就省去了麻烦。<br />
接线：（我用的是CH340，没有Reset的那种，接线如下）<br />
Arduino mini的VCC接 烧写模块的5V<br />
Arduino mini的GND接 烧写模块的GND<br />
Arduino mini的RXD接 烧写模块的TXO<br />
Arduino mini的TXD接 烧写模块的RXI</p>
<h2 id="相关硬件">3 相关硬件</h2>
<h3 id="扩展板android-sensor-shield-v5">1) 扩展板Android Sensor Shield
V5</h3>
<p><img
src="https://img-%20blog.csdn.net/20170220120713793?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<p>当外部设备增加时，Arduino的供电口就不够了，此时加上传感器扩展板（很多扩展板可以直接插在Arduinouno板上，无需另外接线），数字和模拟的接口并没增加，而供电增加了。用3P连接线连接传感器，看起来也更整齐，且不容易插错。因为它只是转接板，所以不需要加其它库。<br />
还有一些共它功能的扩展板，如电动机扩展板等。</p>
<h3 id="section"></h3>
<h3 id="舵机控制板">2) 舵机控制板</h3>
<p><img
src="https://img-%20blog.csdn.net/20170220120614027?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /><br />
在做机器人或者机械臂的时候，往往需要同时控制多个舵机，且需外部供电，一个Arduino控制不了，因为需要外加舵机控制板，注意外加供电的板子一定要看清供电供范围，用降压模块控制好电压，尤其是舵机，否则很容易烧坏。</p>
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Arduino介绍_软件（以ubuntu系统上安装为例）</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/Arduino%E4%BB%8B%E7%BB%8D_%E8%BD%AF%E4%BB%B6%EF%BC%88%E4%BB%A5ubuntu%E7%B3%BB%E7%BB%9F%E4%B8%8A%E5%AE%89%E8%A3%85%E4%B8%BA%E4%BE%8B%EF%BC%89/</url>
    <content><![CDATA[<h1
id="arduino介绍_软件以ubuntu系统上安装为例">Arduino介绍_软件（以ubuntu系统上安装为例）</h1>
<p>#Arduino</p>
<p>Arduino是一款便捷灵活、方便上手的开源电子原型平台，包含硬件（Arduino板）和软件（Arduino<br />
IDE）。它的价格便宜（板子十来块钱），编程简单（类似C语言），相关资料也多。</p>
<h2 id="arduino-ide">1 Arduino IDE</h2>
<p>Arduino
IDE是Arduino的集成开发环境，一般使用它编程，并将程序下载到开发板。</p>
<h3 id="安装">1) 安装</h3>
<p>$ sudo apt-get install arduino<br />
$ sudo arduino<br />
运行Arduino需要较高权限，为了方便，暂使用root权限运行（比较正规的方法是将用户加入高权限的组）。<br />
如果觉得自动安装的IDE版本不够新，请下载安装源码包（一般不用）。</p>
<h3 id="最简单程序">2) 最简单程序</h3>
<pre><code>void setup() &#123;  
  Serial.begin(9600);  
&#125;  
  
void loop() &#123;  
  Serial.println(&quot;hello world&quot;);  
&#125;  </code></pre>
<hr />
<p>setup()在程序开始执行时运行一次，loop()则会不停地执行多次。<br />
它的语法和C语言相近，我倒是觉得对于初学者或是小孩来说，只要单词量在100以上，学这个比学乐高机器人的编程界面好，顺便还能学一些C语言。</p>
<h3 id="烧写">3) 烧写</h3>
<p>左上角的两个图标分别是编译程序和安装到开发板，在安装之前需要设置：<br />
菜单Tools- &gt;Board-&gt;选择板子对应型号<br />
菜单Tools-&gt;SerialPort-&gt;选择对应的设备端口<br />
右上角图标用于打开SerialMonitor，查看开发者回传的信息（如显示上例中的”hello
word”）</p>
<h2 id="fritzing">2 Fritzing</h2>
<p>Fritzing是图形化Arduino电路开发软件，用它画一些图，看起来更加直观。</p>
<h3 id="安装-1">1) 安装</h3>
<p>$ sudo apt-get install fritzing<br />
$ Fritzing</p>
<h3 id="说明">2) 说明</h3>
<p>Fritzing提供了一些基本的元件；也可以用：菜单-&gt;Part-&gt;New通过导入图的方式加入新的元件。做好之后，可以导出图片。</p>
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>Fritzing画电路图</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/Fritzing%E7%94%BB%E7%94%B5%E8%B7%AF%E5%9B%BE/</url>
    <content><![CDATA[<h1 id="fritzing画电路图">Fritzing画电路图</h1>
<p>#Arduino</p>
<p>Fritzing是一套设计PCB (Printed Circuit Board) 印刷电路板的软件</p>
<p>1. Ubuntu系统安装方法</p>
<pre><code>$ sudo apt-get install fritzing  
$ Fritzing # 运行  </code></pre>
<p>2. 其它平台软件下载地址：<br />
<a
href="http://fritzing.org/download/">http://fritzing.org/download/</a></p>
<p>3. 新建元件<br />
做图过程中难免有图库中没有的元件，需要新建元件。Fritzing<br />
1.7之后的版本不能直接创建元件，需要在相似元件的基础上修改，比较麻烦。我只想画一个连线示意图，操作越简单越好，故下载了Fritzing<br />
0.6.4b版本，它的元件菜单中支持"新建"。</p>
<p>最终绘图效果如下图所示：</p>
<p><img
src="https://img-blog.csdnimg.cn/20190721192642250.png?x-oss-%20process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpZXlhbjA4MTE=,size_16,color_FFFFFF,t_70" /></p>
]]></content>
      <tags>
        <tag>Arduino</tag>
      </tags>
  </entry>
  <entry>
    <title>安装和卸载Android应用程序_apk包</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Arduino/%E5%AE%89%E8%A3%85%E5%92%8C%E5%8D%B8%E8%BD%BDAndroid%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F_apk%E5%8C%85/</url>
    <content><![CDATA[<h1
id="安装和卸载android应用程序_apk包">安装和卸载Android应用程序_apk包</h1>
<p>#移动开发 #android</p>
<p>一、 安装</p>
<p>1. 安装第三方应用<br />
** $ adb install apk ** ** 文件名 **</p>
<p>2. 安装系统应用<br />
** $ adb remount **<br />
** $ adb push apk ** ** 文件名 ** /system/app // apk 文件名形如
testme.apk</p>
<p>二、 卸载</p>
<p>1. ** $ adb uninstall ** ** 包名 ** // 包名形如
com.android.testme</p>
<p>2. Home- &gt; 设置 -&gt; 应用程序 -&gt; 管理应用程序 -&gt;
选择某应用程序 -&gt; 卸载</p>
<p>三、 相关文件</p>
<p>1. /system/app/apk 文件<br />
系统应用</p>
<p>2. /data/app/ 包名 .apk<br />
第三方应用</p>
<p>3. /data/data/ 包名<br />
此位置用于存储用户数据</p>
<p>4. /data/dalvik-cache/ 组合名 .dex<br />
dex 文件是 Android 虚拟机 Dalvik 支持的字节码文件格式</p>
<p>5. /data/data/com.android.launcher/databases/launcher.db<br />
Launcher 是 Android 应用程序的启动器， launcher.db
是应用程序数据库。<br />
若应用程序数据发生混乱，删掉数据库文件，并杀掉 com.android.launcher
进程，再使 Launcher<br />
重新启动并重新生成应用程序数据库，以恢复错误<br />
** $ adb shell<br />
$ cd /data/data/com.android.launcher/databases/<br />
$ rm launcher.db **<br />
** $ ps ** // 找到 com.android.launcher 对应的进程号<br />
** $ killall ** ** 进程号 **<br />
重新进入应用列表界面（ Home ），此时 launcher
自动被重启，数据库重新生成</p>
<p>四、 apk 的格式<br />
apk 文件将 AndroidManifest.xml 文件、应用程序代码 (.dex 文件 )
、资源文件和其他文件打成一个压缩包<br />
** $ mv testme.apk xx.zip<br />
$ mkdir tmp; cd tmp<br />
$ unzip ../xx.zip<br />
** 此时可看到 apk 包中的内容</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Python与AI之一_入门</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/Python%E4%B8%8EAI%E4%B9%8B%E4%B8%80_%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h1 id="python与ai之一_入门">Python与AI之一_入门</h1>
<p>#Python #机器学习</p>
<p>Python与Java, C, C++并列为全球4大最流行语言.
从C到C++,到Java再到Python, 细节越来越少,<br />
让开发者把更多的精力放在”做什么”, 而不是”怎么做”.</p>
<p>早就听说Python容易, 但没想到这么容易, 机器学习的分类器,
或是中文分词能在十行内搞定. 开始时几乎完全不用考虑具体的数据结构.<br />
在熟悉了Python之后, 用它看程序逻辑就很清晰, 有点像伪代码,
让LISP爱好者们也如同找到了亲人.</p>
<p>以下是Python在ubuntu系统下的简单实例.</p>
<h3 id="第一个程序hello-world">1. 第一个程序Hello world</h3>
<ol type="1">
<li>写入文件/tmp/a.py<br />
</li>
</ol>
<pre><code>print(&#39;hello world&#39;)  </code></pre>
<ol start="2" type="1">
<li>运行<br />
</li>
</ol>
<pre><code>$ python /tmp/a.py  </code></pre>
<h3 id="集成开发环境-eclipse支持python">2. 集成开发环境:
Eclipse支持Python</h3>
<p>Eclipse在Help菜单中，选择Install New Software<br />
Add,输入 <a href="http://pydev.org/updates">http://pydev.org/updates</a>
,按提示安装即可</p>
<h3 id="实例一-机器学习svm分类器">3. 实例一: 机器学习SVM分类器</h3>
<ol type="1">
<li><p>目标<br />
用SVM分类器训练数据, 然后实现分类</p></li>
<li><p>安装机器学习的相关库</p></li>
</ol>
<pre><code>$ sudo apt-get install python-sklearn  </code></pre>
<ol start="3" type="1">
<li>代码</li>
</ol>
<pre><code>from sklearn import svm  
        
X = [[0, 0], [1, 1], [1, 0]]  # training samples     
y = [0, 1, 1]  # training target    
clf = svm.SVC()  # class     
clf.fit(X, y)  # training the svc model    
result = clf.predict([2, 2]) # predict the target of testing samples     
print result  # target   </code></pre>
<ol start="4" type="1">
<li>运行结果</li>
</ol>
<p>[1]<br />
(将训练数据分类为y=1)</p>
<h3 id="实例二-绘图">4. 实例二: 绘图</h3>
<ol type="1">
<li><p>目标<br />
绘制饼图</p></li>
<li><p>代码</p></li>
</ol>
<pre><code>import matplotlib.pyplot as plt    
labels=&#39;frogs&#39;,&#39;hogs&#39;,&#39;dogs&#39;,&#39;logs&#39;    
sizes=15,20,45,10    
colors=&#39;yellowgreen&#39;,&#39;gold&#39;,&#39;lightskyblue&#39;,&#39;lightcoral&#39;    
explode=0,0.1,0,0    
plt.pie(sizes,explode=explode,labels=labels,colors=colors,autopct=&#39;%1.1f%%&#39;,shadow=True,startangle=50)    
plt.axis(&#39;equal&#39;)    
plt.show()   </code></pre>
<ol start="3" type="1">
<li>运行结果</li>
</ol>
<p><img
src="https://img-%20blog.csdn.net/20170228093054207?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>
<h3 id="实例三-中文分词">5. 实例三: 中文分词</h3>
<ol type="1">
<li><p>目标<br />
把一个中文句子分成单个词</p></li>
<li><p>安装分词库</p></li>
</ol>
<p>下载安装包jieba-0.38.zip</p>
<pre><code>$ unzip jieba-0.38.zip    
$ jieba-0.38    
$ sudo python setup.py install  </code></pre>
<ol start="3" type="1">
<li>代码</li>
</ol>
<pre><code>#! -*- coding:utf-8 -*-  
import jieba  
seg_list = jieba.cut(&quot;北京野生动物园轿车遭黑熊围堵&quot;)  
print &quot;Default Mode:&quot;, &#39; &#39;.join(seg_list)  </code></pre>
<ol type="1">
<li>运行结果:</li>
</ol>
<p>北京 野生 动物园 轿车 遭 黑熊 围堵</p>
<h3 id="参考">6. 参考</h3>
<ol type="1">
<li><p>Python入门教材<br />
<a
href="http://www.cnblogs.com/vamei/archive/2012/09/13/2682778.html">http://www.cnblogs.com/vamei/archive/2012/09/13/2682778.html<br />
</a></p></li>
<li><p>Python绘图<br />
<a
href="http://blog.csdn.net/panda1234lee/article/details/52311593">http://blog.csdn.net/panda1234lee/article/details/52311593<br />
</a></p></li>
<li><p>Python在人工智能中的作用<br />
<a
href="http://mt.sohu.com/20160807/n462992458.shtml">http://mt.sohu.com/20160807/n462992458.shtml<br />
</a></p></li>
</ol>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Python人脸识别</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/Python%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/</url>
    <content><![CDATA[<h1 id="python人脸识别">Python人脸识别</h1>
<p>#图形图像 #Python</p>
<p> “人脸识别”是人工智能的一个重要应用，听起来技术含量很高，貌似非常复杂，具体的实现也的确非常复杂，目前的算法一般都基于深度学习神经网络。但如果仅仅是使用识别功能，目前已有封装好的功能模块，并不需要训练模型，甚至不需要了解任何算法原理，只需调用Python的三方模块，几行代码即可实现人脸识别。</p>
<p> face_recognition是目前使用方法最简单，效果也非常好的人脸识别库，它的离线识别率高达99.38%。除了检测面部位置，它还能快速识别出面部特征：如眉毛、眼睛、鼻子、嘴，识别具体的人，对比两张脸的相似度等等。从后面例程可以看到，识别位置相当准确。</p>
<h3 id="一安装和原理">一、安装和原理</h3>
<p> face_recognition底层基于dlib实现。dlib是一个人脸关键点检测库，它的核心功能由C++实现，适用于多个平台。不同于一般的Python三方模块，它在安装时需要编译，其Github上主要介绍了它在Linux和MacOS系统的安装方法。在Windows系统下编译安装过程比较复杂，需要安装Visual
Studio的 Visual C++ for
Linux环境，相关工具几十个G，安装步骤和注意事项也很多，因此还是建议使用Linux系统（尽管这可能让一些读者望而却步）。</p>
<p> 在Linux下安装方法非常简单：</p>
<pre><code> $ pip install face_recognition  </code></pre>
<p> Linux将自动安装face_recognition及其依赖的三方工具集。同时，建议下载源码：</p>
<pre><code> $ git clone https://github.com/davisking/dlib.git  
 $ git clone https://github.com/ageitgey/face_recognition_models  
 $ git clone https://github.com/ageitgey/face_recognition  </code></pre>
<p> 下载源码主要为了通过其示例学习三方模块的使用方法，以及了解底层调用的库和具体的实现方法，以及相关的文档。</p>
<p> dlib模块实现最核心的功能——人脸关键点检测，从源码中可以看到，它主要由C++语言实现，并提供了C++和Python接口，因此，可以在不同环境下开发和使用，目前也有开发者将其移植到android手机上。</p>
<p> face_recognition_models存储了训练好的模型，供face_recognition模块调用，模型的扩展名为“.dat”。</p>
<p> face_recognition模块的功能代码并不多，主要是封装了dlib，简化了开发者的调用步骤。其example中有很多有趣的例程，比如：虚化人脸（类似于马赛克效果），化妆，追踪视频中的人脸，甚至还启动WebService，识别用户上传的图片；还包括与机器学习模型KNN，SVM结合使用的例程，其原理也是用dlib提取人脸特征，再加入机器学习模型训练，根据需求，生成新的模型。可将其看作图像识别在人脸识别垂直领域的细化和封装。</p>
<p> dlib的使用方法并不复杂，而face_recognition则更加简单，face_recognition还提供了直接运行的两个工具：人脸检测face_dection和人脸识别face_recognition。</p>
<h3 id="二face_recognition例程">二、face_recognition例程</h3>
<p> 本例程调用face_recognition模块，实现了人脸识别，画眉、画眼线和涂口线的功能。</p>
<pre><code>from PIL import Image, ImageDraw  
import face_recognition  
image = face_recognition.load_image_file(None)  
  
face_landmarks_list = face_recognition.face_landmarks(image)  
for face_landmarks in face_landmarks_list:  
 color = [238,42,68]  
 pil_image = Image.fromarray(image)  
 d = ImageDraw.Draw(pil_image, &#39;RGBA&#39;)  
 print(face_landmarks.keys())  
 d.polygon(face_landmarks[&#39;left_eyebrow&#39;], fill=(68, 54, 39, 50))  
 d.polygon(face_landmarks[&#39;right_eyebrow&#39;], fill=(68, 54, 39, 50))  
  
 d.polygon(face_landmarks[&#39;top_lip&#39;], fill=(color[0], color[1], color[2], 80))  
 d.polygon(face_landmarks[&#39;bottom_lip&#39;], fill=(color[0], color[1], color[2], 80))  
  
 d.line(face_landmarks[&#39;left_eye&#39;] + [face_landmarks[&#39;left_eye&#39;][0]], fill=(0, 0, 0, 50), width=3)  
 d.line(face_landmarks[&#39;right_eye&#39;] + [face_landmarks[&#39;right_eye&#39;][0]], fill=(0, 0, 0, 50), width=3)  
  
pil_image.show()  
pil_image.save(None)  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-8f04675b7afa0ace.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="三dlib例程">三、dlib例程</h3>
<p> 本例程直接调用dlib模块，使用face_recognition_models中训练好的模型，识别人脸上的68个特征点。</p>
<pre><code>import dlib  
import cv2  
  
detector = dlib.get_frontal_face_detector()  
predictor = dlib.shape_predictor(&#39;/exports/git/face_recognition_models/face_recognition_models/models/shape_predictor_68_face_landmarks.dat&#39;)  
img = cv2.imread(None)  
dets = detector(img, 1)  
  
for k, d in enumerate(dets):  
 print(&quot;Detection &#123;&#125;: Left: &#123;&#125; Top: &#123;&#125; Right: &#123;&#125; Bottom: &#123;&#125;&quot;.format(  
 k, d.left(), d.top(), d.right(), d.bottom()))  
 shape = predictor(img, d)  
  
 for index, pt in enumerate(shape.parts()):  
  print(&#39;Part &#123;&#125;: &#123;&#125;&#39;.format(index, pt))  
  pt_pos = (pt.x, pt.y)  
  cv2.circle(img, pt_pos, 1, (255, 0, 0), 2)  
  font = cv2.FONT_HERSHEY_SIMPLEX  
  cv2.putText(img, str(index+1),pt_pos,font, 0.3, (0, 0, 255), 1, cv2.LINE_AA)  
cv2.imshow(&#39;img&#39;, img)  
k = cv2.waitKey()  
cv2.destroyAllWindows()  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-006ab7f04bbb23b6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="四总结">四、总结</h3>
<p> 对于大多数的Python程序，开发者需要的90%功能三方模块都已经实现完成，很多功能都已非常成熟，剩余的10%由开发者根据需求进行适配即可完成。这使得开发者在短时间内即可实现基本功能，并且看起来非常强大，但是后期效果提升比较困难。</p>
<p> 个人觉得：人脸识别工具真的很适合美妆卖家，买家上传一张相片，合成各种色号的效果；在视频通话过程中察言观色；图片识别，刷脸支付，美颜相机；稍加一些艺术处理，自动生成漫画等等。</p>
<h3 id="五参考">五、参考</h3>
<p><strong>1. 具体用法介绍</strong><br />
<a
href="https://github.com/ageitgey/face_recognition">https://github.com/ageitgey/face_recognition</a></p>
<p><strong>2．表情识别规则</strong><br />
<a
href="https://www.jianshu.com/p/7596e428bcfe">https://www.jianshu.com/p/7596e428bcfe</a></p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>Python实现PDF内容抽取</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/Python%E5%AE%9E%E7%8E%B0PDF%E5%86%85%E5%AE%B9%E6%8A%BD%E5%8F%96/</url>
    <content><![CDATA[<p>#Python</p>
<h2 id="python-的-pdf-工具">1 Python 的 PDF 工具</h2>
<ul>
<li>PyMuPDF: 支持更多高级功能和处理复杂PDF文件<br />
</li>
<li>pdfplumber：从PDF中提取文本、表格或生成简单的PDF文档<br />
</li>
<li>联合使用两个库是一种常用方法</li>
</ul>
<h2 id="pymupdf">2 PyMuPDF</h2>
<p>最近需要把扫描的PDF转换成文本，试用了pdfminer，pypdf2等工具，解析图片的效果都不太好，用起来也比较麻烦，后来试用了PyMuPDF，相对其它工具，它最新版本屏蔽了更多细节，围绕Page进行操作，调用非常方便。除了PDF它还支持解析epub等电子书格式。</p>
<p>目前网上例程大多是只抽取图片，没有同时转换图片和文字，且因为旧版本API，大多已无法正常运行。本文将示例其用法。</p>
<h2 id="安装">3 安装</h2>
<pre><code>$ pip install pymupdf==1.18.19  </code></pre>
<p>如果提取找不到fiz.h，建议更新pip版本</p>
<pre><code>$ pip3.6 install --upgrade pip  </code></pre>
<h2 id="例程">4 例程</h2>
<pre><code>def parse(inpath, outpath):  
    remove(TMPDIR) # 清除临时目录   
    os.mkdir(TMPDIR)  
    remove(outpath) # 清除输出文件  
  
    t0 = time.clock()  
    doc = fitz.open(inpath)  
    lenXREF = doc.xrefLength()  
    print(&quot;文件名:&#123;&#125;, 页数: &#123;&#125;, 对象: &#123;&#125;&quot;.format(inpath, len(doc), lenXREF - 1))  
  
    imgcount = 0  
    for i,page in enumerate(doc):  
        t1 = time.clock()  
        # 文字  
        text = page.get_text()  
        if len(text) &gt; 0:  
             write_file(outpath, text, &#39;a&#39;)  
        # 图片          
        imglist = page.get_images() # 解析该页中图片  
        for item in imglist:  
            xref = item[0]  
            pix = fitz.Pixmap(doc, xref)  
            new_name = &quot;&#123;&#125;.png&quot;.format(imgcount)  
            # 如果pix.n&lt;5,可以直接存为PNG  
            path = os.path.join(TMPDIR, new_name)  
            if pix.n &lt; 5:  
                pix.writePNG(path)  
            # 否则先转换CMYK  
            else:  
                pix0 = fitz.Pixmap(fitz.csRGB, pix)  
                pix0.writePNG(path)  
                pix0 = None  
            pix = None  
            if OCR_ONLINE:  
                text = img_to_str_baidu(path)  
            else:  
                text = img_to_str_tesseract(path)  
            print(&quot;img-&gt;text&quot;, text)  
            write_file(outpath, text, &#39;a&#39;)  
            write_file(outpath, &#39;\n&#39; + &#39;-----------&#39; + &#39;\n&#39;, &#39;a&#39;)  
            imgcount += 1  
        print(&quot;page &#123;&#125; 运行时间:&#123;&#125;s&quot;.format(i, &#123;t1 - t0&#125;))  </code></pre>
<p>完整例程请见参考部分</p>
<h2 id="参考">5 参考</h2>
<p>帮助文档 <a
href="https://pymupdf.readthedocs.io/en/latest/tutorial.html">https://pymupdf.readthedocs.io/en/latest/tutorial.html</a><br />
源码地址 <a
href="https://github.com/pymupdf/PyMuPDF">https://github.com/pymupdf/PyMuPDF</a><br />
完整例程 <a
href="https://github.com/xieyan0811/pdfconv.git">https://github.com/xieyan0811/pdfconv.git</a></p>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python实现PDF转TXT</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/Python%E5%AE%9E%E7%8E%B0PDF%E8%BD%ACTXT/</url>
    <content><![CDATA[<h1 id="python实现pdf转txt">Python实现PDF转TXT</h1>
<p>#自然语言处理 #Python</p>
<p> 用手机或者Kindle看PDF文档字实太是太小了，总觉得PDF转TXT是个刚需，却一直没找到PDF转TXT的简单方法，最近有空，不妨自己用Python写一个。</p>
<p> 将PDF格式转换成纯文本的TXT，虽然会损失掉一些排版和图片，却可以给文件瘦身，也可将其中的文字用于更多场合。</p>
<p> PDF里一般都包含文字和图片，有些文字以图片形式存储，比如大多数以扫描方式制作的PDF图书都使用这种方式，以此方式存储的PDF文件占空间也比较大，一般都有几十兆。另一种，以文本方式存储字符，同时存储字符的大小和位置，在显示对应的页面时绘制图片和文字，以此方式存储的PDF文件占空间较小，一般只有几兆大小。</p>
<p> 分辨文字的存储方式很简单，只需要用任意支持PDF格式的软件打开文件，放大几倍，如果文字依然清晰，则是以字符方式存储的，如果字的边缘变得模糊，则一般是以图片方式存储文字。</p>
<p> 以字符方式存储PDF的文本比较容易获取，使用Linux下的pdftotxt命令即可过滤出其中的文字。以图片方式存储的相对比较复杂，需要识别图片中的文字，会用到OCR技术，OCR是光学字符识别的简称，目前的OCR一般利用深度学习技术实现，同样也是训练模型比较困难，但单纯地使用模型则非常简单。</p>
<p> 本文使用现成的Python三方库，实现对PDF中文本和图片两种文字的识别，程序运行环境仍然是Linux（主要因为笔者不怎么用Windows），Python版本为3.6（与Python
2.7的三方库略有差异）。</p>
<h2 id="安装软件">安装软件</h2>
<p> 程序主要包括解析PDF格式和OCR识别两部分，首先安装三方库：</p>
<pre><code>$ sudo pip install pdfminer3k # PDF格式解析  
$ sudo apt-get install tesseract-ocr # 离线OCR工具tesseract  
$ sudo apt-get install tesseract-ocr-chi-sim # OCR简体中文支持  
$ sudo pip install pytesseract # OCR工具的Python支持包  
$ sudo pip install baidu-aip # 在线OCR：百度提供的字符识别工具。  </code></pre>
<p> 本例中使用了在线和离线两种OCR，离线版本识别率稍差，在线版本是百度提供的字符识别服务，对中文识别效果更好，它提供一定的免费额度，但是使用量大时需要付费。</p>
<h2 id="离线ocr">离线OCR</h2>
<p> 使用OCR的目的是识别图片中的文字，Tesseract是一款由HP实验室开发，由Google维护的开源OCR，支持多种文字，下面看看它的用法。</p>
<pre><code>from PIL import Image  
import pytesseract  
  
def img_to_str_tesseract(image_path, lang=&#39;eng&#39;):  
    return pytesseract.image_to_string(Image.open(image_path), lang)  
    
print(None))  </code></pre>
<h2 id="在线ocr">在线OCR</h2>
<p> 百度、搜狗、有道等智能云平台都提供在线OCR服务，使用方法也大同小异，下面介绍百度OCR的使用方法。</p>
<pre><code>from aip import AipOcr  
  
config = &#123;  
    &#39;appId&#39;: &#39;&#39;,  
    &#39;apiKey&#39;: &#39;&#39;,  
    &#39;secretKey&#39;: &#39;&#39;  
&#125;  
client = AipOcr(**config)  
  
def img_to_str_baidu(image_path):  
    with open(image_path, &#39;rb&#39;) as fp:  
        image = fp.read()  
        result = client.basicGeneral(image)  
        if &#39;words_result&#39; in result:  
            return &#39;\n&#39;.join([w[&#39;words&#39;] for w in result[&#39;words_result&#39;]])  
    return &quot;&quot;  
  
print(None))  </code></pre>
<p> 其中的appId, apiKey,
secretKey需要在百度智能云中创建自己的“文字识别”项目后获取，请访问：<a
href="https://console.bce.baidu.com/">https://console.bce.baidu.com/</a>。<br />
<img
src="https://upload-images.jianshu.io/upload_images/5357893-81a3d3a7638f496d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 识别效果如下图所示，其中左侧是被识别的原始图像，右侧上方是tesseract识别的效果图，右侧下方是百度OCR识别的效果图。百度OCR比tesseract识别效果稍好，尤其是对中英文混排、标点符号和数字效果更好，不过tesseract也基本可用。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-951b1bfab4d2d78c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="pdf格式解析">PDF格式解析</h2>
<p> 本例中使用pdfminer库解析PDF文档，完整代码请从github下载：</p>
<p>https://github.com/xieyan0811/pdfconv.git</p>
<pre><code>from pdfminer.pdftypes import LITERALS_DCT_DECODE, LITERALS_FLATE_DECODE  
from pdfminer.pdfcolor import LITERAL_DEVICE_GRAY, LITERAL_DEVICE_RGB  
from pdfminer.pdfparser import PDFParser,PDFDocument  
from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter  
from pdfminer.converter import PDFPageAggregator  
from pdfminer.layout import LTTextBoxHorizontal, LAParams, LTFigure, LTImage, LTChar, LTTextLine  
from pdfminer.pdfinterp import PDFTextExtractionNotAllowed  
import os  
import sys  
import numpy as np  
import importlib  
importlib.reload(sys)  
  
TMPDIR = &#39;tmp/&#39;  
PARSEIMG = True  
OCR_ONLINE = False  
  
# 保存图片  
def write_image(image, outdir):  
    stream = image.stream  
    filters = stream.get_filters()  
    if len(filters) == 1 and filters[0] in LITERALS_DCT_DECODE:  
        ext = &#39;.jpg&#39;  
        data = stream.get_rawdata()  
    elif image.colorspace is LITERAL_DEVICE_RGB:  
        ext = &#39;.bmp&#39;  
        data = create_bmp(stream.get_data(), stream.bits*3, image.width, image.height)  
    elif image.colorspace is LITERAL_DEVICE_GRAY:  
        ext = &#39;.bmp&#39;  
        data = create_bmp(stream.get_data(), stream.bits, image.width, image.height)  
    else:  
        ext = &#39;.img&#39;  
        data = stream.get_data()  
    name = image.name+ext  
    path = os.path.join(outdir, name)  
    fp = open(path, &#39;wb&#39;)  
    fp.write(data)  
    fp.close()  
    return path, len(data)  
  
# 写入文件  
def write_file(path, text, ftype, debug=False):  
    with open(path, ftype) as f:  
        if debug:  
            print(&quot;write&quot;, len(text))  
        f.write(text)  
  
# 去掉文中多余的回车  
def adjust(inpath, outpath):  
    f = open(inpath)  
    lines = f.readlines()  
    arr = [len(line) for line in lines]  
    length = np.median(arr) # 行字符数中值  
      
    string = &quot;&quot;  
    for line in lines:  
        if len(line) &gt;= length and line[-1]==&#39;\n&#39;:  
            string += line[:-1] # 去掉句尾的回车  
        elif line == &#39;-----------\n&#39;:  
            pass  
        else:  
            string += line  
    write_file(outpath, string, &#39;w&#39;)  
    return  
  
# 解析每个数据块  
def parse_section(layout, outpath, debug = False):  
    for x in layout:  
        if (isinstance(x, LTTextBoxHorizontal)): # 文本  
            write_file(outpath, x.get_text(), &#39;a&#39;)  
        elif (isinstance(x, LTFigure)):  
            parse_section(x, outpath)  
        elif (isinstance(x, LTImage)) and PARSEIMG: # 图片  
            path,length = write_image(x, TMPDIR)  
            if length &gt; 0:  
                if OCR_ONLINE:  
                    write_file(outpath, img_to_str_baidu(path), &#39;a&#39;)  
                else:  
                    write_file(outpath, img_to_str_tesseract(path), &#39;a&#39;)  
                write_file(outpath, &#39;\n&#39; + &#39;-----------&#39; + &#39;\n&#39;, &#39;a&#39;)  
  
# 删除文件    
def remove(path):  
    if not os.path.exists(path):  
        return  
    if os.path.isfile(path):  
        os.remove(path)  
        return  
    dirs = os.listdir(path)  
    for f in dirs:  
        file_name = os.path.join(path, f)  
        if os.path.isfile(file_name):  
            os.remove(file_name)  
        else:  
            remove(file_name)  
    os.rmdir(path)  
  
# 解析PDF文件  
def parse(inpath, outpath):  
    remove(TMPDIR) # 清除临时目录   
    os.mkdir(TMPDIR)  
    remove(outpath) # 清除输出文件  
    fp = open(inpath, &#39;rb&#39;)  
    praser = PDFParser(fp) # pdf文档分析器  
    doc = PDFDocument() # 创建一个PDF文档  
    praser.set_document(doc) # 连接分析器与文档对象  
    doc.set_parser(praser)  
    doc.initialize()  
      
    if not doc.is_extractable: # 是否提供txt转换  
        raise PDFTextExtractionNotAllowed  
    else:  
        rsrcmgr = PDFResourceManager() # 创建PDF资源管理器  
        laparams = LAParams()   
        device = PDFPageAggregator(rsrcmgr, laparams=laparams)  
        interpreter = PDFPageInterpreter(rsrcmgr, device) # 创建PDF解释器对象  
                  
        for idx,page in enumerate(doc.get_pages()): # 获取page列表  
            interpreter.process_page(page)  
            layout = device.get_result()  
            print(&quot;parse&quot;, idx)  
            parse_section(layout, outpath)  
  
if __name__ == &#39;__main__&#39;:  
    pdffile = &quot;xxxx.pdf&quot;  
    tmpfile = pdffile.replace(&#39;pdf&#39;,&#39;tmp&#39;)  
    txtfile = pdffile.replace(&#39;pdf&#39;,&#39;txt&#39;)  
    parse(pdffile, tmpfile)  
    adjust(tmpfile, txtfile)  </code></pre>
<p> 其中parse_section用于解析数据块，PDF的数据块有LTTextBox，LTFigure，LTImage，LTRect，LTCurve和LTLine等子对象。LTTextBox表示一组文本块可能包含在一个矩形区域；
LTTextLine表示单个文本行LTChar对象的列表；LTImage表示一个图像对象；LTLine表示一条直线；
LTRect:表示矩形；LTCurve表示曲线。有些对象之间包括嵌套关系。</p>
<h2 id="一些问题">一些问题</h2>
<p> 程序通过百余行代码实现转换功能，解析普通的PDF文件问题不大，但仍存在一些问题：</p>
<ol type="1">
<li>本文中使用的pdfminer库中对pdf文件中数据块的解析不够完美，只支持主流的jpg、bmp格式文件，有一些pdf中的图片无法被识别。<br />
</li>
<li>竖版文字也被识别成横版。<br />
</li>
<li>解析字符型文本时，比较简单粗暴，对于特殊的版式不一定按照从上到下，从左到右的顺序解析，有待更进。<br />
</li>
<li>程序目前以支持中文PDF文件为主，支持其它语言需要在代码中稍做调整。</li>
</ol>
<h2 id="参考">参考</h2>
<ol type="1">
<li>百度接口用法<br />
<a
href="https://cloud.baidu.com/doc/OCR/OCR-Python-SDK.html#.E9.80.9A.E7.94.A8.E6.96.87.E5.AD.97.E8.AF.86.E5.88.AB">https://cloud.baidu.com/doc/OCR/OCR-Python-SDK.html#.E9.80.9A.E7.94.A8.E6.96.87.E5.AD.97.E8.AF.86.E5.88.AB</a></li>
</ol>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>flask多并发</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/flask%E5%A4%9A%E5%B9%B6%E5%8F%91/</url>
    <content><![CDATA[<h3 id="多线程">多线程</h3>
<p>flask默认使用多进程处理请求，因此，是支持并发的。比如两个调用a.html和b.html，<br />
* 请求a.html未运行完成，在浏览访问b.html不会阻塞。<br />
*
开两个不同浏览器，分别请求请求运行时间较长的a.html也不阻塞。只要不用一个浏览去调，它都是不阻塞的；如果开一个浏览器在不同tab页请求同一阻塞页面，则会阻塞，这是浏览器引起的。</p>
<h3 id="wsgi协议">WSGI协议</h3>
<p>WSGI是Web Server Gateway
Interface的缩写，它是Python应用程序或者框架（如Flask）和web服务器之间的一种接口。flask默认使用werkzeug库实现WSGI协议。<br />
只要实现了WSGI协议的任何web server都可以作为flask
app的服务器，比如uWSGI， Gunicorn，mod_wsgi都可以替换Werkzeug作为 web
server。</p>
<h3 id="flask自带的多进程">flask自带的多进程</h3>
<ul>
<li>在app.run()时加入参数：threaded=False, processes=5,
debug=False时，可使用5个进程。<br />
</li>
<li>进入flash的app.run()函数内部，可以看到真正使用werkzeug库来实现后台服务。<br />
</li>
<li>flask自带的多进程有一个问题，每次请求时进程开启，该请求运行结束进程关闭，因此无法在每个进程中保留现场，每次都做初始化，也会浪费很多时间。</li>
</ul>
<h3 id="gunicorn">gunicorn</h3>
<ul>
<li>如果想在flash一开始就启多个进程，可使用gunicorn<br />
</li>
<li>做如下的test.py<br />
</li>
</ul>
<pre><code>from flask import Flask  
app = Flask(__name__)  
  
@app.route(&quot;/&quot;)  
def hello():  
    return &quot;Hello World!&quot;  </code></pre>
<p>注意：使用gunicorn后，无需在程序中运行app.run()。<br />
* 运行命令</p>
<pre><code>gunicorn -w 3 -b 0.0.0.0:8080 test:app  </code></pre>
<p>这里设成开启3个进程，0.0.0.0使得在docker内部启动的服务可在宿主机上被访问，test是py文件名，app是其中的flask服务名。此时，使用ps命令即可看到一开始就启动了多个进程。</p>
<h2 id="具体应用场景的讨论">具体应用场景的讨论</h2>
<p>flask
框架本身支持多线程和多进程处理，但二者均不适用于输血模型预测。首先，flask
的线程基于 Python
线程，它不是系统级的线程，因此无法充分使用系统资源，经测试此方式使用多线程并不能提升效率；flask
的多进程在请求时新建进程，模型预测需要初始化和加载大量资源，如果不能复用，每次都加载反花费更多时间，因此也无法使用
flask 进程方法。</p>
<p>最终选择使用 gunicorn 方法实现多进程，通过 gunicorn
命令启动服务，启动时设置进程数，该方法在一开始就启动了多个进程，且各进程始终不退出，用以在保留工作环境，同时响应并发处理。</p>
<p>另外，需要权衡内存占用和预测效率。同时开启多个进程将占用大量内存，同时可以处理更多并发请求。经过测试，默认设置为4个进程，可通可环境变量设置。并发时，内存可也限制在2G以内，且并发预测时间降低为之前的50%及以下，同时也兼顾了医院场景中具体的峰值情况。</p>
<h3 id="参考">参考</h3>
<p><a href="https://zhuanlan.zhihu.com/p/99669985">Flask:
flask框架是如何实现非阻塞并发的</a></p>
]]></content>
  </entry>
  <entry>
    <title>markdown解析器</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/markdown%E8%A7%A3%E6%9E%90%E5%99%A8/</url>
    <content><![CDATA[<h2 id="python-markdown-解析器">1 python markdown 解析器</h2>
<ul>
<li>mistletoe<br />
</li>
<li>mistune<br />
</li>
<li>markdown_it<br />
</li>
<li>markdown<br />
</li>
<li>markdown2</li>
</ul>
<h2 id="mistune-github地址">2 mistune github地址</h2>
<p>https://github.com/lepture/mistune</p>
<h2 id="输入-markdown输出-html-文本">3 输入 markdown，输出 html
文本。</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> mistune  </span><br><span class="line">mistune.markdown(<span class="string">&#x27;I am using **mistune markdown parser**&#x27;</span>)  </span><br><span class="line"><span class="comment"># 输出: &lt;p&gt;I am using &lt;strong&gt;mistune markdown parser&lt;/strong&gt;&lt;/p&gt;  </span></span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">mistune还支持插件，显示更复杂的界面。  </span><br><span class="line">主要这是一个纯python的，不涉及前端工具链。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 4 输出树型结构  </span></span><br><span class="line">```  </span><br><span class="line"><span class="keyword">import</span> mistune  </span><br><span class="line">  </span><br><span class="line">markdown = mistune.create_markdown(renderer=<span class="literal">None</span>)  </span><br><span class="line">markdown(markdown_text)  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 5 参考  </span></span><br><span class="line">[Mistune中文指导文档](https://blog.csdn.net/a942242856/article/details/<span class="number">88598193</span>)  </span><br><span class="line">  </span><br><span class="line">```  </span><br><span class="line">$ pip install mistune  </span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>streamlit构造Web应用</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/streamlit%E6%9E%84%E9%80%A0Web%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<p>#Python #机器学习 #前端</p>
<h1 id="streamlit构造web应用">StreamLit构造Web应用</h1>
<h2 id="功能">功能</h2>
<p>Streamlit 帮助机器学习工程师快速开发用户交互工具，几乎可取代 Flask
在机器学习项目中的地位。</p>
<h3 id="个人感受">个人感受</h3>
<ul>
<li>确实非常方便，安装python库的streamlit后，可快速入门<br />
</li>
<li>和学习前端相比，学习成本非常低<br />
</li>
<li>界面比较美观，适合用于demo和内部展示<br />
</li>
<li>通过简单的代码，就可以展示丰富的功能；但对于复杂的UI还没试<br />
</li>
<li>不需要可见的 b/s 通讯，几乎所有交互都通过操作 streamlit
句柄完成<br />
</li>
<li>使用很方便，功能是否强大还没试<br />
</li>
<li>运行需要基于streamlit框架</li>
</ul>
<h3 id="安装">安装</h3>
<pre class="shell"><code>$ pip install streamlit  </code></pre>
<h3 id="运行示例">运行示例</h3>
<pre class="shell"><code>$ streamlit hello --server.port 8080  </code></pre>
<p>我指定了端口，否则其默认运行端口是 8501</p>
<p>在其左侧可以选择几种主要的demo<br />
<img src="/attachments_2022/Pasted%20image%2020220212132427.png"
alt="Pasted%20image%2020220212132427.png" /></p>
<h3 id="运行程序">运行程序</h3>
<p>将其中dataframe的demo写入一个文件test.py，然后运行</p>
<pre class="shell"><code>$ streamlit run test.py --server.port 8080  </code></pre>
<p>最简单的程序段示例：</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> streamlit <span class="im">as</span> st  </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>dataframe <span class="op">=</span> pd.DataFrame(  </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    np.random.randn(<span class="dv">10</span>, <span class="dv">20</span>),  </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>(<span class="st">&#39;col </span><span class="sc">%d</span><span class="st">&#39;</span> <span class="op">%</span> i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>)))  </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>st.dataframe(dataframe.style.highlight_max(axis<span class="op">=</span><span class="dv">0</span>))  </span></code></pre></div>
<p>可以看到，操作几乎都基于句柄 st</p>
<h2 id="对-markdown-文本支持">对 Markdown 文本支持</h2>
<pre class="shell"><code>import streamlit as st  
text = &#39;&#39;&#39;  
# title1  

## title2   

### title3  
Streamlit is **_really_ cool**.  
&#39;&#39;&#39;  
st.markdown(text)  </code></pre>
<p><img src="/attachments_2022/Pasted%20image%2020220212141105.png"
alt="Pasted%20image%2020220212141105.png" /><br />
看起来也还不错，可以考虑 Obsidian+github+streamlit
建立自己的笔记网站，其优势在于支持强大的图表功能，且使用简单，不需要学习众多前端工具。</p>
<h2 id="云功能streamlit-cloud">云功能（Streamlit Cloud）</h2>
<p>部署到服务器：把 stream could 与 github 连接，运行其上的 python
代码或者展示其上笔记。</p>
<h3 id="注册帐号">注册帐号</h3>
<p>因为网络问题，建议使用github帐号登录streamlit。</p>
<h3 id="发布应用">发布应用</h3>
<ul>
<li>打开：https://share.streamlit.io/<br />
</li>
<li>点New App按钮<br />
</li>
<li>选：Paste GitHub URL<br />
</li>
<li>然后将自己github中的代码地址复制到框内<br />
</li>
<li>点Deploy后，即可在网页中看到运行后的代码效果</li>
</ul>
<h3 id="管理应用">管理应用</h3>
<p>在已创建的 app 右测点Setting，在 Who can view this app 中选：This app
is visible to anyone with the link，程序即可被所有用户访问。</p>
<h2 id="参考">参考</h2>
<p><a href="https://docs.streamlit.io/">官网</a><br />
<a
href="http://cw.hubwiz.com/card/c/streamlit-manual/1/6/6/">streamlit开发手册</a><br />
<a
href="https://blog.csdn.net/sinat_26917383/article/details/113485525">python︱写markdown一样写网页，代码快速生成web工具：streamlit
重要组件介绍（二）</a></p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>机器学习</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch_LSTM与GRU</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Pytorch/Pytorch_LSTM%E4%B8%8EGRU/</url>
    <content><![CDATA[<h1 id="pytorch_lstm与gru">Pytorch_LSTM与GRU</h1>
<p>#Pytorch #时序</p>
<p>RNN循环网络在序列问题处理中得到了广泛的应用。但使用标准版本的RNN模型时，常遇到梯度消失gradient
vanishing和梯度爆炸gradient explosion问题。</p>
<h3 id="rnn的缺点">RNN的缺点</h3>
<p>RNN的梯度消失和梯度爆炸不同于其它网络，全连接网络和卷积网络每一层有不同参数，而RNN
的每个处理单元Cell（处理单个序列元素的操作称为处理单元Cell）共用同一组权重矩阵W。在上一篇介绍RNN网络算法时可以看到，处理单元之间是全连接关系，序列向前传播的过程中将不断乘以权重矩阵W，从而构成了连乘W<sup>n</sup>，当W&lt;1时，如果序列很长，则结果趋近0；当w&gt;1时，经过多次迭代，数值将迅速增长。反向传播也有同样问题。</p>
<p>梯度爆炸问题一般通过“梯度裁剪”方法改善，而梯度消失则使得序列前面的数据无法起到应有的作用，造成“长距离依赖”（Long-Term
Dependencies）问题，也就是说RNN只能处理短距离的依赖关系。</p>
<p>这类似于卷积神经网络在处理图像问题时加深网络层数，无法改进效果。尽管理论上可以通过调参改进，但难度很大，最后图像处理通过修改网络结构使用残差网络解决了这一问题。同样，RNN也改进了结构，使用LSTM和GRU网络。作为RNN的变种，它们使用率更高。</p>
<h3 id="lstm长短时记忆网络">LSTM长短时记忆网络</h3>
<p>LSTM是Long Short Term Memory
Networks的缩写，即长短时记忆网络，该方法在1997年被提出，主要用于解决“长距离依赖”问题。不同于RNN用单一的隐藏层描述规律，LSTM新增加了细胞状态Cell
state，简称c，并用多个门控参数分别控制读、写、遗忘操作。</p>
<h4 id="门控gate">门控gate</h4>
<p>门控理论源于生物学，指脊髓中的一些细胞像门一样（门开了才能通过），切断和阻止一些痛觉信号进入大脑。在神经网络中通常是使用激活函数控制数据的传输，如激活函数sigmoid常被用于控制信号是否通过，它的取值范围从0-1，0表示阻断，1表示完全通过，0-1之间数据部分通过，从而实现有选择的输入、有选择的输出、有选择的记忆。</p>
<h4 id="算法">算法</h4>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-cfcd9b1fc57540a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>上图描述了LSTM网络对输入X<sub>t</sub>（序列中每个元素）处理生成输出h<sub>t</sub>的前向传播过程。笔者将其分为六步，在图中用圆圈加数字表示。</p>
<p>第一步：计算遗忘门，遗忘门forget
gate简称f，用于控制是否<strong>遗忘上一层</strong>的状态Cell
state。该门的输入是前一个隐藏层的状态h<sub>(t-1)</sub>以及当前的x<sub>t</sub>，通过一个sigmoid（用σ表示）激活函数，得到当前时间t的遗忘门的值f<sub>t</sub>
，W和b是该门的参数和偏置。比如：当输入词为“但是”时，认为前面的记忆不再重要，f<sub>t</sub>值为0，清空之前的记忆（只是举例，不要较真儿）。其公式为：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-40717cade337c040.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>第二步：计算输入门，输入门input gate简称i，它用于向Cell
state中<strong>增加新的内容</strong>，该门的输入也是前一个隐藏层的状态h<sub>(t-1)</sub>以及当前的x<sub>t</sub>计算i<sub>t</sub>。例如：当输入是“，”时，认为该输入没有携带有贡献的信息，i<sub>t</sub>值为0，忽略该输入。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d37339bad71a243d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>第三步：计算输入值，这一步类似于RNN中计算隐藏层参数的算法，输入也是前一个隐藏层的状态h<sub>(t-1)</sub>以及当前的x<sub>t</sub>计算g<sub>t</sub>，它是这一步输入产生的具体影响，此处的激活函数使用tanh。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-b62e6a79fc1f7b42.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>第四步：计算输出门，输出门output gate，简称o，在用Cell
state值计算输出值h<sub>t</sub>的过程中用o<sub>t</sub><strong>控制输出</strong>，该门的输入也是前一个隐藏层的状态h<sub>(t-1)</sub>以及当前的x<sub>t</sub>。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-dc31368e12871a5b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>第五步：计算当前的细胞状态Cell
state，用遗忘门f控制上一步的状态c<sub>(t-1)</sub>，用输入门i控制当前输入g，从而计算当前状态c<sub>t</sub>（遗忘了部分以往信息，加入了部分新信息）。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-11416b02562f99f8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>第六步：通过当前细胞状态c和输出门o计算隐藏层h，最后两步将通过各个门的数据组织起来。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-671407e0c7dcaad5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>标准的RNN模型比较粗糙，只调节一组参数，而LSTM把问题细化成几个子问题，需要反复迭代计算多组W参数，运算量比普通的RNN大很多。LSTM的核心原理是保持信息的完整性，它假设每一个状态都是由上一状态叠加一个变化得来的（类似于残差网络），即两组信息做加法，它不同于RNN的逐层做乘法，由此改进了梯度爆炸/梯度消失的问题。它对于较长的序列效果更好。</p>
<p><strong>用法</strong></p>
<p>Pytorch提供的LSTM调用方法与RNN类似，只要把上篇例程中的“RNN”改成“LSTM”即可，不需要其它调整。</p>
<p>与RNN不同的是，在调用前向传递函数forward时，传入和传出的参数都可包含h和c两组值，其格式为：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a713959ec8e40844.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中input是输入，output是输出，第二个参数(h<sub>0</sub>,c<sub>0</sub>)为Tuple类型，h<sub>0</sub>和c<sub>0</sub>分别是两个隐藏层的初始值；同样LSTM也将计算后隐藏层的值(h<sub>n</sub>,c<sub>n</sub>)作为返回值。h<sub><em></sub>和c<sub></em></sub>的维度是(num_layers,
batch_size, hidden_size)。</p>
<h3 id="gru门控循环单元">GRU门控循环单元</h3>
<p>GRU是门控循环单元Gated Recurrent
Unit的缩写，该方法在2014年被提出，是LSTM网络的变体，它比LSTM网络结构更简单，逻辑更加清晰，速度更快，且效果也很好。GRU模型只有两个门：更新门和重置门。它的网络结构与RNN更为相似，在每一步接收序列中的数据输入，上一个隐藏层的输出，并输出隐藏层。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d4110e79ebcc661c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>上图描述了对GRU处理输入X<sub>t</sub>生成输出h<sub>t</sub>的前向传播过程。笔者将其分为四步，在图中用圆圈加数字表示。</p>
<p>第一步：计算更新门，更新门update
gate简称为z，它的功能类似于LSTM中的遗忘门，用于控制以往信息和新输入数据的在当前状态中的比例，该门的输入也是前一个隐藏层的状态h<sub>t-1</sub>以及当前的输入x<sub>t</sub>，省略了偏置参数b。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-fbcd61b4da3d6bd1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>第二步：计算重置门，重置门reset
gate常简称为r，它的功能类似于LSTM中的输入门，该门的输入也是前一个隐藏层的状态h<sub>t-1</sub>以及当前的输入x<sub>t</sub>。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ab2e2207cb0ac2e4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>第三步：计算输入值，输入值由前一个隐藏层的状态h<sub>t-1</sub>，当前的x<sub>t</sub>以及重置门r<sub>t</sub>计算得来。可视为当前输入对状态的影响。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d292b45d6e38dba2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>第四步：计算当前状态，当前状态由两部分组成，前一部分是以往信息的影响，后一部分是当前输入的影响，参数z<sub>t</sub>是更新门的值，它经过激活函数sigmoid，取值在0-1之间，也就是说，前后两部分的权重之和为1，通过更新门均衡二者的占比。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-34ebfdd02ed7e8d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>与LSTM相比，状态层State
cell被省略，由隐藏层h实现它的功能，并省略了输出门o，去掉了各层的偏置参数b，在多个步骤进行了简化，占用资源更少。</p>
<p>Pytorch的具体调用方法和RNN类似，此处不再赘述。</p>
<h3 id="优化rnn网络">优化RNN网络</h3>
<p>深度学习工具一般都提供API直接调用RNN模型，像Keras工具只使用一条语句即建立一个LSTM模型，在建模过程中除了调用API程序员需要做哪些工作呢？</p>
<p>循环神经的网络每一个处理单元都通过一个或者多个全连接网络与下一个单元相连，类似于CNN的多层网络，因此序列越长，计算越复杂，设计网络时需要考虑模型复杂度，估计训练时间，涉及：迭代次数、序列长度，如何切分序列，隐藏层数，隐藏层元素个数，学习率，是否将隐藏层状态传入下一次迭代，超参数、以及参数初值等因素。</p>
<p>比如：RNN的误差往往不是平滑收敛的，尤其是序列较长时，学习率很难固定下来，建议使用Adam优化器自动调节学习参数。</p>
]]></content>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch_基于预训练的ResNet模型训练自己的分类器</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Pytorch/Pytorch_%E5%9F%BA%E4%BA%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84ResNet%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E5%88%86%E7%B1%BB%E5%99%A8/</url>
    <content><![CDATA[<h1
id="pytorch_基于预训练的resnet模型训练自己的分类器">Pytorch_基于预训练的ResNet模型训练自己的分类器</h1>
<p>#Pytorch #深度学习<br />
1. 加载数据<br />
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os  </span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data  </span><br><span class="line"><span class="keyword">import</span> torch  </span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim  </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn  </span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> lr_scheduler  </span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, models, transforms  </span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image  </span><br><span class="line"><span class="keyword">import</span> time  </span><br><span class="line"><span class="keyword">import</span> copy  </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd  </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line">%matplotlib inline  </span><br><span class="line">  </span><br><span class="line">NUM_EPOCH=<span class="number">5</span> <span class="comment"># 默认迭代次数  </span></span><br><span class="line">batch_size = <span class="number">100</span> <span class="comment"># 约占 10G 显存  </span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span>) <span class="comment"># 默认使用 GPU  </span></span><br><span class="line">NUMCLASS = <span class="number">4</span> <span class="comment"># 类别数  </span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">default_loader</span>(<span class="params">path</span>):  </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">        <span class="keyword">with</span> Image.<span class="built_in">open</span>(f) <span class="keyword">as</span> img:  </span><br><span class="line">            <span class="keyword">return</span> img.convert(<span class="string">&#x27;RGB&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomImageLoader</span>(data.Dataset): <span class="comment"># 定义自己的数据类  </span></span><br><span class="line">    <span class="comment">##自定义类型数据输入  </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_path, txt_path, dataset = <span class="string">&#x27;&#x27;</span>, data_transforms=<span class="literal">None</span>, loader = default_loader</span>):  </span><br><span class="line">        im_list = []  </span><br><span class="line">        im_labels = []  </span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(txt_path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> files:  </span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> files:  </span><br><span class="line">                items = line.split()  </span><br><span class="line">                <span class="keyword">if</span> items[<span class="number">0</span>][<span class="number">0</span>] == <span class="string">&#x27;/&#x27;</span>:  </span><br><span class="line">                    imname = line.split()[<span class="number">0</span>][<span class="number">1</span>:]  </span><br><span class="line">                <span class="keyword">else</span>:  </span><br><span class="line">                    imname = line.split()[<span class="number">0</span>]  </span><br><span class="line">                im_list.append(os.path.join(img_path, imname))  </span><br><span class="line">                im_labels.append(<span class="built_in">int</span>(items[<span class="number">1</span>]))  </span><br><span class="line">        self.imgs = im_list  </span><br><span class="line">        self.labels = im_labels  </span><br><span class="line">        self.data_tranforms = data_transforms  </span><br><span class="line">        self.loader = loader  </span><br><span class="line">        self.dataset = dataset  </span><br><span class="line">   </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.imgs)  </span><br><span class="line">   </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):  </span><br><span class="line">        img_name = self.imgs[item]  </span><br><span class="line">        label = self.labels[item]  </span><br><span class="line">        img = self.loader(img_name)  </span><br><span class="line">   </span><br><span class="line">        <span class="keyword">if</span> self.data_tranforms <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  </span><br><span class="line">            <span class="keyword">try</span>:  </span><br><span class="line">                img = self.data_tranforms[self.dataset](img)  </span><br><span class="line">            <span class="keyword">except</span>:  </span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Cannot transform image: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(img_name))  </span><br><span class="line">        <span class="keyword">return</span> img, label  </span><br><span class="line">      </span><br><span class="line">data_tranforms=&#123;  </span><br><span class="line">    <span class="string">&#x27;Train&#x27;</span>:transforms.Compose([  </span><br><span class="line">        transforms.RandomResizedCrop(<span class="number">224</span>), <span class="comment"># 随机裁剪为不同的大小和宽高比,缩放所为制定的大小  </span></span><br><span class="line">        transforms.RandomHorizontalFlip(),  </span><br><span class="line">        transforms.ToTensor(),  </span><br><span class="line">        transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]) <span class="comment"># 各通道颜色的均值和方差,用于归一化  </span></span><br><span class="line">    ]),  </span><br><span class="line">    <span class="string">&#x27;Test&#x27;</span>:transforms.Compose([  </span><br><span class="line">        transforms.Resize(<span class="number">256</span>), <span class="comment"># 变换大小  </span></span><br><span class="line">        transforms.CenterCrop(<span class="number">224</span>), <span class="comment"># 中心裁剪  </span></span><br><span class="line">        transforms.ToTensor(),  </span><br><span class="line">        transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])  </span><br><span class="line">    ])  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">image_datasets = &#123;x : CustomImageLoader(<span class="string">&#x27;/&#x27;</span>, <span class="comment"># 默认目录为根目录，配搭文件中使用全路径  </span></span><br><span class="line">                                        txt_path=(<span class="string">&#x27;/tmp/&#x27;</span>+x+<span class="string">&#x27;Images.label&#x27;</span>), <span class="comment"># 标签文件  </span></span><br><span class="line">                                        data_transforms=data_tranforms,  </span><br><span class="line">                                        dataset=x) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;Train&#x27;</span>, <span class="string">&#x27;Test&#x27;</span>]  </span><br><span class="line">                  &#125;  </span><br><span class="line">   </span><br><span class="line">dataloders = &#123;x: torch.utils.data.DataLoader(image_datasets[x],  </span><br><span class="line">                                                 batch_size=batch_size,  </span><br><span class="line">                                                 shuffle=<span class="literal">True</span>) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;Train&#x27;</span>, <span class="string">&#x27;Test&#x27;</span>]&#125;  </span><br><span class="line">  </span><br><span class="line">dataset_sizes = &#123;x: <span class="built_in">len</span>(image_datasets[x]) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;Train&#x27;</span>, <span class="string">&#x27;Test&#x27;</span>]&#125; <span class="comment"># 数据大小  </span></span><br><span class="line">```  </span><br><span class="line"><span class="number">2.</span> 训练模型   </span><br><span class="line">``` Python  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">model, crtiation, optimizer,schedular, num_epochs=NUM_EPOCH</span>):  </span><br><span class="line">    begin_time = time.time()  </span><br><span class="line">    best_weights = copy.deepcopy(model.state_dict())<span class="comment">#copy the weights from the model  </span></span><br><span class="line">    best_acc = <span class="number">0.0</span>  </span><br><span class="line">    arr_acc = [] <span class="comment"># 用于作图  </span></span><br><span class="line">   </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;-*-&quot;</span> * <span class="number">20</span>)  </span><br><span class="line">        item_acc = []  </span><br><span class="line">        <span class="keyword">for</span> phase <span class="keyword">in</span> [<span class="string">&#x27;Train&#x27;</span>, <span class="string">&#x27;Test&#x27;</span>]:  </span><br><span class="line">            <span class="keyword">if</span> phase==<span class="string">&#x27;Train&#x27;</span>:  </span><br><span class="line">                schedular.step()  </span><br><span class="line">                model.train()  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                model.<span class="built_in">eval</span>()  </span><br><span class="line">            running_loss = <span class="number">0.0</span>  </span><br><span class="line">            running_acc = <span class="number">0.0</span>  </span><br><span class="line">   </span><br><span class="line">            <span class="keyword">for</span> images, labels <span class="keyword">in</span> dataloders[phase]:  </span><br><span class="line">                images.to(device)  </span><br><span class="line">                labels.to(device)  </span><br><span class="line">                optimizer.zero_grad()  </span><br><span class="line">   </span><br><span class="line">                <span class="keyword">with</span> torch.set_grad_enabled(phase==<span class="string">&#x27;Train&#x27;</span>):  </span><br><span class="line">                    opt = model(images.cuda())  </span><br><span class="line">                    <span class="comment"># opt = model(images)  </span></span><br><span class="line">                    _,pred = torch.<span class="built_in">max</span>(opt,<span class="number">1</span>)  </span><br><span class="line">                    labels = labels.cuda()  </span><br><span class="line">                    loss = crtiation(opt, labels)  </span><br><span class="line">                    <span class="keyword">if</span> phase==<span class="string">&#x27;Train&#x27;</span>:  </span><br><span class="line">                        loss.backward()  </span><br><span class="line">                        optimizer.step()  </span><br><span class="line">   </span><br><span class="line">                running_loss += loss.item()*images.size(<span class="number">0</span>)  </span><br><span class="line">                running_acc += torch.<span class="built_in">sum</span>(pred==labels)  </span><br><span class="line">            epoch_loss = running_loss/dataset_sizes[phase]  </span><br><span class="line">            epoch_acc = running_acc.double()/dataset_sizes[phase]  </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;epoch=&#123;&#125;, Phase=&#123;&#125;, Loss=&#123;:.4f&#125;, ACC:&#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, phase,   </span><br><span class="line">                                                                       epoch_loss, epoch_acc))  </span><br><span class="line">            item_acc.append(epoch_acc)  </span><br><span class="line">   </span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;Test&#x27;</span> <span class="keyword">and</span> epoch_acc&gt;best_acc:  </span><br><span class="line">                <span class="comment"># Upgrade the weights  </span></span><br><span class="line">                best_acc=epoch_acc  </span><br><span class="line">                best_weights = copy.deepcopy(model.state_dict())  </span><br><span class="line">        arr_acc.append(item_acc)  </span><br><span class="line">    time_elapes = time.time() - begin_time  </span><br><span class="line">        time_elapes // <span class="number">60</span>, time_elapes % <span class="number">60</span>  </span><br><span class="line">    ))  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Best Val ACC: &#123;:&#125;&#x27;</span>.<span class="built_in">format</span>(best_acc))  </span><br><span class="line">   </span><br><span class="line">    model.load_state_dict(best_weights) <span class="comment"># 保存最好的参数  </span></span><br><span class="line">    <span class="keyword">return</span> models,arr_acc  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  </span><br><span class="line">    model_ft = models.resnet50(pretrained=<span class="literal">True</span>)   </span><br><span class="line">    num_fits = model_ft.fc.in_features  </span><br><span class="line">    model_ft.fc = nn.Linear(num_fits, NUMCLASS) <span class="comment"># 替换最后一个全连接层  </span></span><br><span class="line">    model_ft = model_ft.to(device)  </span><br><span class="line">    model_ft.cuda()  </span><br><span class="line">    criterion = nn.CrossEntropyLoss()  </span><br><span class="line">    optimizer_ft = optim.SGD(model_ft.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)  </span><br><span class="line">    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=<span class="number">10</span>, gamma=<span class="number">0.1</span>)  </span><br><span class="line">    model_ft,arr_acc = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, <span class="number">20</span>)  </span><br><span class="line">```  </span><br><span class="line"><span class="number">3.</span> 绘图  </span><br><span class="line">``` Python  </span><br><span class="line">ll = np.array(arr_acc)  </span><br><span class="line">plt.plot(ll[:,<span class="number">0</span>])  </span><br><span class="line">plt.plot(ll[:,<span class="number">1</span>])  </span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch_循环神经网络RNN</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Pytorch/Pytorch_%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN/</url>
    <content><![CDATA[<h1 id="pytorch_循环神经网络rnn">Pytorch_循环神经网络RNN</h1>
<p>#Pytorch #时序</p>
<p>RNN是Recurrent Neural
Networks的缩写，即循环神经网络，它常用于解决序列问题。RNN有记忆功能，除了当前输入，还把上下文环境作为预测的依据。它常用于语音识别、翻译等场景之中。</p>
<p>RNN是序列模型的基础，尽管能够直接调用现成的RNN算法，但后续的复杂网络很多构建在RNN网络的基础之上，如Attention方法需要使用RNN的隐藏层数据。RNN的原理并不复杂，但由于其中包括循环，很难用语言或者画图来描述，最好的方法是自己手动编写一个RNN网络。本篇将介绍RNN网络的原理及具体实现。</p>
<h3 id="序列">序列</h3>
<p>在学习循环神经网络之前，先看看什么是序列。序列sequence简称seq，是有先后顺序的一组数据。自然语言处理是最为典型的序列问题，比如将一句话翻译成另一句话时，其中某个词汇的含义不仅取决于它本身，还与它前后的多个单词相关。类似的，如果想预测电影的情节发展，不仅与当前的画面有关，还与当前的一系列前情有关。在使用序列模型预测的过程中，输入是序列，而输出是一个或多个预测值。</p>
<p>在使用深度学习模型解决序列问题时，<strong>最容易混淆的是，序列与序列中的元素</strong>。在不同的场景中，定义序列的方式不同，当分析单词的感情色彩时，一个单词是一个序列seq；当分析句子感情色彩时，一个句子是一个seq，其中的每个单词是序列中的元素；当分析文章感情色彩时，一篇文章是一个seq。简单地说，seq是最终使用模型时的输入数据，由一系列元素组成。</p>
<p>当分析句子的感情色彩时，以句为seq，而句中包含的各个单词的含义，以及单词间的关系是具体分析的对象，此时，单词是序列中的元素，每一个单词又可有多维特征。从单词中提取特征的方法将在后面的自然语言处理中介绍。</p>
<h4 id="循环神经网络">循环神经网络</h4>
<p>RNN有很多种形式，单个输入单个输入；多个输入多个输出，单个输入多个输出等等。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-93546d98c65ff36c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>举个最简单的例子：用模型预测一个四字短语的感情色彩，它的输入为四个元素X={x1,x2,x3,x4}，它的输出为单个值Y={y1}。字的排列顺序至关重要，比如“从好变坏”和“从坏变好”，表达的意思完全相反。之所以输入输出的个数不需要一一对应，是因为中间的隐藏层，变向存储中间信息。</p>
<p>如果把模型设想成黑盒，如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-94367aac7a6e2248.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>如果模型使用全连接网络，在每次迭代时，模型将计算各个元素x1,x2...中各个特征f1,f2...代入网络，求它们对结果y的贡献度。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-1c793a8d6c22a22d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>RNN网络则要复杂一些，在模型内部，它不是将序列中所有元素的特征一次性输入模型，而是每一次将序列中单个元素的特征输入模型，下图描述了RNN的数据处理过程，左图为分步展示，右图将所有时序步骤抽象成单一模块。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-0e878021316d9d79.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>第一步：将第一个元素x1的特征f1,f2...输入模型，模型根据输入计算出隐藏层h。</p>
<p>第二步：将第二个元素x2的特征输入模型，模型根据输入和上一步产生的h再计算隐藏层h，其它元素以此类推。</p>
<p>第三步：将最后一个元素xn的特征输入模型，模型根据输入和上一步产生的h计算隐藏层h和预测值y。</p>
<p>隐藏层h可视为将序列中前面元素的特征和位置通过编码向前传递，从而对输出y发生作用，隐藏层的大小决定了模型携带信息量的多少。隐藏层也可以作为模型的输入从外部传入，以及作为模型的输出返回给外部调用。</p>
<h3 id="代码分析">代码分析</h3>
<p>本例仍使用上篇中的航空乘客序列数据，分别用两种方法实现RNN：自己编写程序实现RNN模型，以及调用Pytorch提供的RNN模型。前一种方法主要用于剖析原理，后一种用于展示常用的调用方法。</p>
<h4 id="读取数据">1．读取数据</h4>
<p>首先导入头文件，读取乘客数据，做归一化处理，并将数据切分为测试集和训练集，与之前不同的是加入了create_dataset函数，用于生成序列数据，序列的输入部分，每个元素中包括两个特征：前一个月的乘客量prev和月份值mon，这里的月份值并不是关键特征，主要用于在例程中展示如何使用多个特征。</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch  </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.autograd <span class="im">import</span> Variable  </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 归一化  </span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> feature_normalize(data):  </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> np.mean(data,axis<span class="op">=</span><span class="dv">0</span>)  </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> np.std(data,axis<span class="op">=</span><span class="dv">0</span>)  </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (data <span class="op">-</span> mu)<span class="op">/</span>std  </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 数据转换  </span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_dataset(df):  </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    dataX <span class="op">=</span> torch.from_numpy(np.array(df[[<span class="st">&#39;prev&#39;</span>,<span class="st">&#39;mon&#39;</span>]].astype(<span class="st">&#39;float32&#39;</span>)).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>))  </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    dataY <span class="op">=</span> torch.from_numpy(np.array(df[<span class="st">&#39;y&#39;</span>].astype(<span class="st">&#39;float32&#39;</span>)).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>))  </span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dataX, dataY  </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&#39;data/AirPassengers.csv&#39;</span>)  </span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;y&#39;</span>] <span class="op">=</span> feature_normalize(df[<span class="st">&#39;#Passengers&#39;</span>])  </span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;mon&#39;</span>] <span class="op">=</span> feature_normalize(df[<span class="st">&#39;Month&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="bu">float</span>(x[<span class="dv">5</span>:])))  </span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;prev&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;y&#39;</span>].shift() <span class="co"># 将前一个月的乘客量写入prev特征  </span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.dropna() <span class="co"># 去掉包含空值的行  </span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>TRAIN_PERCENT <span class="op">=</span> <span class="fl">0.7</span>  </span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>train_size <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(df) <span class="op">*</span> TRAIN_PERCENT)  </span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> df[:train_size]  </span></code></pre></div>
<h4 id="实现rnn模型">2．实现RNN模型</h4>
<p>第一步：实现模型类，此例中的RNN模型除了全连接层，还生成了一个隐藏层，并在下一次前向传播时将隐藏层输出的数据与输入数据组合后再代入模型运算。</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RNN1(nn.Module):  </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size, hidden_size, output_size):  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(RNN1, <span class="va">self</span>).<span class="fu">__init__</span>()  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_size <span class="op">=</span> hidden_size  </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rnn <span class="op">=</span> nn.Linear(input_size <span class="op">+</span> hidden_size, hidden_size)  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.reg <span class="op">=</span> nn.Linear(input_size <span class="op">+</span> hidden_size, output_size)  </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>, hidden):  </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        combined <span class="op">=</span> torch.cat((<span class="bu">input</span>, hidden), <span class="dv">1</span>) <span class="co"># combined: [1,(128+6)]  </span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        hidden <span class="op">=</span> <span class="va">self</span>.rnn(combined)  </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.reg(combined)  </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output, hidden  </span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> initHidden(<span class="va">self</span>): <span class="co"># 初始化隐藏层  </span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> Variable(torch.zeros(<span class="dv">1</span>, <span class="va">self</span>.hidden_size))  </span></code></pre></div>
<p>第二步，训练模型，使用全部数据训练500次，在每次训练时，内部for循环将序列中的每个元素代入模型，并将模型输出的隐藏层和下一个元素一起送入下一次迭代。</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>FEATURE_SIZE <span class="op">=</span> <span class="dv">2</span>  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>OUTPUT_SIZE <span class="op">=</span> <span class="dv">1</span>  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> RNN1(FEATURE_SIZE, <span class="dv">128</span>, OUTPUT_SIZE)  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>loss_func <span class="op">=</span> nn.MSELoss() <span class="co"># 损失函数  </span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>) <span class="co"># 优化器  </span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>train_x, train_y <span class="op">=</span> create_dataset(train)  </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>all_x, all_y <span class="op">=</span> create_dataset(df)  </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> e <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">500</span>):  </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    h_state <span class="op">=</span> model.initHidden()  </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (x,y) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(train_x, train_y)):  </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        prediction, _h_state <span class="op">=</span> model(x, h_state) <span class="co"># 返回隐藏层  </span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>        h_state <span class="op">=</span> _h_state.data <span class="co"># 隐藏层的参数部分  </span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_func(prediction, y)  </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()  </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        loss.backward()  </span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        optimizer.step()  </span></code></pre></div>
<p>第三步：预测和作图，预测的过程与训练一样，把全部数据拆分成元素代入模型，并将每一次预测结果存储在数组中，并作图显示。</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.<span class="bu">eval</span>()  </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>arr_pred <span class="op">=</span> []  </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>h_state <span class="op">=</span> model.initHidden()  </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x,y <span class="kw">in</span> <span class="bu">zip</span>(all_x, all_y):  </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    prediction, _h_state <span class="op">=</span> model(x, h_state) <span class="co"># 返回隐藏层  </span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    h_state <span class="op">=</span> _h_state.data  </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    arr_pred.append(prediction.detach().numpy().flatten()[<span class="dv">0</span>])  </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>plt.plot(all_y.numpy().flatten(), <span class="st">&#39;y&#39;</span>, label<span class="op">=</span><span class="st">&#39;real&#39;</span>)  </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>plt.plot(arr_pred, label<span class="op">=</span><span class="st">&#39;prediction&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)  </span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;best&#39;</span>)  </span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>plt.grid()  </span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>plt.show()  </span></code></pre></div>
<p>需要注意的是，在训练和预测过程中，每一次开始输入新序列之前，都重置了隐藏层，这是由于隐藏层的内容只与当前序列相关，序列之间并无连续性。</p>
<p>程序输出结果如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-89cb4e0a244604db.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>经过500次迭代，使用RNN的效果明显优于上一篇中使用全连接网络的拟合效果，还可以通过调整超参数以及选择不同特征，进一步优化。</p>
<h4 id="调用现有rnn模型">3．调用现有RNN模型</h4>
<p>使用Pytorch提供的RNN模型，torch.nn.RNN类可直接使用，是循环网络最常用的解决方案。RNN，LSTM，GRU等循环网络都实现在同一源码文件torch/nn/modules/rnn.py中。</p>
<p>第一步：创建模型，模型包含两部分，第一部分是Pytorch提供的RNN层，第二部分是一个全连接层，用于将RNN的输出转换成输出目标的维度。</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RNN2(nn.Module):  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size, hidden_size, output_size<span class="op">=</span><span class="dv">1</span>, num_layers<span class="op">=</span><span class="dv">2</span>):  </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(RNN2, <span class="va">self</span>).<span class="fu">__init__</span>()  </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rnn <span class="op">=</span> nn.RNN(input_size, hidden_size, num_layers)  </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.reg <span class="op">=</span> nn.Linear(hidden_size, output_size)  </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):  </span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        x, _ <span class="op">=</span> <span class="va">self</span>.rnn(x) <span class="co"># 未在不同序列中传递hidden_state  </span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.reg(x)  </span></code></pre></div>
<p>Pytorch的RNN前向传播允许将隐藏层数据h作为参数传入模型，并将模型产生的h和y作为函数返回值。形如：
pred, h_state = model(x, h_state)</p>
<p>什么情况下需要接收隐藏层的状态h_state，并转入下一次迭代呢？当处理单个seq时，h在内部前向传递；当序列与序列之间也存在前后依赖关系时，可以接收h_state并传入下一步迭代。另外，当模型比较复杂如LSTM模型包含众多参数，传递会增加模型的复杂度，使训练过程变慢。本例未将隐藏层转到模型外部，这是由于模型内部实现了对整个序列的处理，而非处理单个元素，而每次代入的序列之间又没有连续性。</p>
<p>第二步：训练模型，与上例中把序列中的元素逐个代入模型不同，本例一次性把整个序列代入了模型，因此，只有一个for循环。</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>FEATURE_SIZE <span class="op">=</span> <span class="dv">2</span>  </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>OUTPUT_SIZE <span class="op">=</span> <span class="dv">1</span>  </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> RNN2(FEATURE_SIZE, <span class="dv">64</span>, OUTPUT_SIZE)  </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>loss_func <span class="op">=</span> nn.MSELoss()  </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>)  </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>train_x, train_y <span class="op">=</span> create_dataset(train)  </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>all_x, all_y <span class="op">=</span> create_dataset(df) <span class="co"># 全部数据  </span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> e <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">500</span>):  </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    var_x <span class="op">=</span> Variable(train_x)  </span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    var_y <span class="op">=</span> Variable(train_y)  </span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> model(var_x) <span class="co"># var_x: [100, 1, 2]  </span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_func(out, var_y)  </span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()  </span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    loss.backward()  </span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    optimizer.step()  </span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (e<span class="op">+</span><span class="dv">1</span>)<span class="op">%</span><span class="dv">100</span><span class="op">==</span><span class="dv">0</span>:  </span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&#39;Epoch:</span><span class="sc">&#123;&#125;</span><span class="st">, Loss:</span><span class="sc">&#123;:.5f&#125;</span><span class="st">&#39;</span>.<span class="bu">format</span>(e<span class="op">+</span><span class="dv">1</span>, loss.item()))  </span></code></pre></div>
<p>Pythorch支持批量处理，前向传递时输入数据格式是[seq_len, batch_size,
input_dim)，本例中输入数据的维度是[100, 1,
2]，input_dim是每个元素的特征数，batch_size是训练的序列个数，seq_len是序列的长度，这里使用70%作为训练数据，seq_len为100。如果数据维度的顺序与要求不一致，一般使用transpose转换。</p>
<p>第三步：预测和作图，将全部数据作为序列代入模型，并用预测值作图。</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.<span class="bu">eval</span>()  </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>pred_y <span class="op">=</span> model(Variable(all_x)) <span class="co"># 预测  </span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>plt.plot(all_y.view(<span class="op">-</span><span class="dv">1</span>).data.numpy(), <span class="st">&#39;y&#39;</span>, label<span class="op">=</span><span class="st">&#39;real&#39;</span>)  </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>plt.plot(pred_y.view(<span class="op">-</span><span class="dv">1</span>).data.numpy(), label<span class="op">=</span><span class="st">&#39;prediction&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)  </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;best&#39;</span>)  </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>plt.grid()  </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>plt.show()  </span></code></pre></div>
<p>程序输出结果如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ce8012e8cba685aa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>可以看到，经过500次迭代，在前100个元素的训练集上拟合得很好，但在测试集效果较差，可能存在过拟合。</p>
]]></content>
      <tags>
        <tag>Pytorch</tag>
        <tag>时序</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch_数据基础</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Pytorch/Pytorch_%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h1 id="pytorch_数据基础">Pytorch_数据基础</h1>
<p>#Pytorch</p>
<p>机器学习需要掌握数据处理工具Pandas、Numpy，同理，深度学习也需要掌握相应的数据处理工具，在Pytorch中数据存储在张量Tensor和变量Variable之中，本篇将介绍它们的基本用法以及与之相关的常用函数。</p>
<p>掌握必要的基础知识，让后期看代码更加流畅，避免陷入太多细节。</p>
<h3 id="tensor-张量">Tensor 张量</h3>
<p>Tensor用于表示矩阵（多维数据），类似Numpy的ndarray，不同的是，可以使用GPU加速。</p>
<h4 id="生成张量">1．生成张量</h4>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch  </span></code></pre></div>
<p>用Tensor方法将其它格式数据转换成张量：</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.Tensor([[<span class="dv">1</span>,<span class="dv">2</span>],[<span class="dv">3</span>,<span class="dv">4</span>],[<span class="dv">5</span>,<span class="dv">6</span>]])  </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a)  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a.size())  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 输出结果：  </span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[1., 2.],  </span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">#         [3., 4.],  </span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">#         [5., 6.]])  </span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># torch.Size([3, 2])  </span></span></code></pre></div>
<p>另外，也可以使用torch.zeros()，torch.randn()生成张量。</p>
<h4 id="修改张量">2．修改张量</h4>
<p>用赋值的方法即可修改张量，比如将上面生成张量，将其位置1,1的元素赋值成50。</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>a[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">=</span><span class="dv">50</span>  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a)  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 输出结果：  </span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[ 1.,  2.],  </span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">#         [ 3., 50.],  </span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">#         [ 5.,  6.]])  </span></span></code></pre></div>
<h4 id="类型转换">3．类型转换</h4>
<p>张量与numpy数据相互转换</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> a.numpy()  </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(b)  </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># [[ 1.  2.]  </span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">#  [ 3. 50.]  </span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">#  [ 5.  6.]]  </span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> torch.from_numpy(b)  </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(c)  </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[ 1.,  2.],  </span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">#         [ 3., 50.],  </span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co">#         [ 5.,  6.]])  </span></span></code></pre></div>
<p>转换成GPU上运行的cuda数据格式</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available(): <span class="co"># 如果支持cuda硬件加速  </span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    d <span class="op">=</span> a.cuda()  </span></code></pre></div>
<h3 id="variable变量">Variable变量</h3>
<p>Variable是神经网络计算图中特有的概念，它提供了自动求导的功能。</p>
<h4 id="类型转换-1">1．类型转换</h4>
<p>将Tensor转成Variable</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.autograd <span class="im">import</span> Variable  </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Variable(a, requires_grad<span class="op">=</span><span class="va">True</span>)  </span></code></pre></div>
<p>使用了参数requires_grad，用于指定是否求梯度，默认为False。</p>
<h4 id="求导">2．求导</h4>
<p>先声明三个变量x,a,b，用它们计算变量y，之后用y.backward()求y对x,a,b三个变量的偏导数，这也是深度学习中常说的“反向”过程。求出的值存储在变量的grad元素中，如x.grad。</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> Variable(torch.Tensor([<span class="dv">1</span>]), requires_grad<span class="op">=</span><span class="va">True</span>)  </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Variable(torch.Tensor([<span class="dv">2</span>]), requires_grad<span class="op">=</span><span class="va">True</span>)  </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Variable(torch.Tensor([<span class="dv">3</span>]), requires_grad<span class="op">=</span><span class="va">True</span>)  </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> a <span class="op">*</span> x <span class="op">+</span> b  </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>y.backward()  </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad) <span class="co"># 输出结果: tensor([2.])  </span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a.grad) <span class="co"># 输出结果: tensor([1.])  </span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(b.grad) <span class="co"># 输出结果: tensor([1.])  </span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(b.data) <span class="co"># 输出结果: tensor([3.])  </span></span></code></pre></div>
<p>从输出结果可以看到，Variable包含两个元素，data是它的Tensor值，grad保存的是求得的导数。</p>
<h3 id="常用的数据处理函数">常用的数据处理函数</h3>
<h4 id="增加维度">1．增加维度</h4>
<p>在深度学习过程中，现有的数据格式和模型要求的格式往往不同，层与层之间的数据也需要转换后才能对接，因此，维度转换是最常用的方法。<br />
squeeze意为压缩，即去掉维度，unsqueeze则相反，为添加维度。</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>unsqueeze(<span class="bu">input</span>, dim, out<span class="op">=</span><span class="va">None</span>)   </span></code></pre></div>
<p>用于增添第dim维度为1。具体用法见以下示例：</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.Tensor([<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>])  </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a, a.shape)  </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([1., 2., 3.]) torch.Size([3])  </span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.unsqueeze(a, <span class="dv">1</span>)  </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(b, b.shape)  </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[1.],[2.],[3.]]) torch.Size([3, 1])  </span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> torch.unsqueeze(a, <span class="dv">0</span>)  </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(c, c.shape)  </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[1., 2., 3.]]) torch.Size([1, 3])  </span></span></code></pre></div>
<h4 id="减小维度">2．减小维度</h4>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>squeeze(<span class="bu">input</span>, dim<span class="op">=</span><span class="va">None</span>, out<span class="op">=</span><span class="va">None</span>)   </span></code></pre></div>
<p>用于删除第dim个维度，如果当前不包括指定的维度，则不会进行删除。如果不指定dim，函数将删除值为1的维度。<br />
本例中延用上例中的数据：</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.squeeze(c,<span class="dv">0</span>))  </span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([1., 2., 3.])  </span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.squeeze(b,<span class="dv">1</span>))  </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([1., 2., 3.])  </span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.squeeze(b))  </span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([1., 2., 3.])  </span></span></code></pre></div>
<h4 id="转换维度">3．转换维度</h4>
<p>比squeeze和unsqueeze更简单的方法是直接把张量转换成指定维度，使用view函数实现，它类似于numpy的reshape。</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>view(<span class="op">*</span>shape)   </span></code></pre></div>
<p>将张量转换成指定的形状，示例：</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.Tensor([<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>])  </span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.view(<span class="dv">2</span>,<span class="dv">2</span>))  </span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[1., 2.], [3., 4.]])  </span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.view(<span class="dv">1</span>,<span class="dv">4</span>))  </span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[1., 2., 3., 4.]])  </span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.view(<span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>)) <span class="co"># 设定为-1时自动计算该维度大小  </span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[1., 2., 3., 4.]])  </span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.view(<span class="dv">4</span>))  </span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([1., 2., 3., 4.])  </span></span></code></pre></div>
<h4 id="cat拼接">4．cat拼接</h4>
<p>cat函数用于在指定维度上拼接多个张量。</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>cat(tensors, dim<span class="op">=</span><span class="dv">0</span>, out<span class="op">=</span><span class="va">None</span>)   </span></code></pre></div>
<p>将tensors中的多个张量按dim指定的维度拼接成一个张量，拼接后总维数不变。</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.Tensor([[<span class="dv">1</span>,<span class="dv">2</span>],[<span class="dv">3</span>,<span class="dv">4</span>]])  </span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.Tensor([[<span class="dv">5</span>,<span class="dv">6</span>],[<span class="dv">7</span>,<span class="dv">8</span>]])  </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.cat((x,y),<span class="dv">0</span>))  </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[1., 2.],  </span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co">#        [3., 4.],  </span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co">#        [5., 6.],  </span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co">#        [7., 8.]])  </span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.cat((x,y),<span class="dv">1</span>))  </span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[1., 2., 5., 6.],  </span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co">#        [3., 4., 7., 8.]])  </span></span></code></pre></div>
<p>一般面对的数据最多三维，并以一两维居多，可以将其理解为横向加或者纵向加。</p>
<h4 id="stack拼接">5．stack拼接</h4>
<p>与cat拼接不同的是，stack拼接后维度增加，其用法如下：</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>stack(tensors, dim<span class="op">=</span><span class="dv">0</span>, out<span class="op">=</span><span class="va">None</span>)  </span></code></pre></div>
<p>示例：</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.Tensor([<span class="dv">1</span>,<span class="dv">2</span>])  </span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.Tensor([<span class="dv">3</span>,<span class="dv">4</span>])  </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.stack((x,y),dim<span class="op">=</span><span class="dv">0</span>))  </span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[1., 2.],  </span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co">#         [3., 4.]])  </span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.stack((x,y),dim<span class="op">=</span><span class="dv">1</span>))  </span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[1., 3.],  </span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co">#         [2., 4.]])  </span></span></code></pre></div>
<p>从输出内容可以看到，拼接后张量变成了两维，dim=0是最常用的情况，它直接把两个张量拼在一起，当dim=1时，拼接时转换了位置。</p>
<h4 id="transpose两维度互换">6．transpose两维度互换</h4>
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>transpose(<span class="bu">input</span>, dim0, dim1)  </span></code></pre></div>
<p>互换dim0, dim1两个维度，具体方法见示例：</p>
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.Tensor([[<span class="dv">1</span>,<span class="dv">2</span>],[<span class="dv">3</span>,<span class="dv">4</span>]])  </span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.transpose(x,<span class="dv">0</span>,<span class="dv">1</span>))  </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[1., 3.],  </span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co">#        [2., 4.]])  </span></span></code></pre></div>
<h4 id="perumute多维度互换">7．perumute多维度互换</h4>
<p>permute与transpose功能类似，但更加灵活，它可以指定多个维度互换。</p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>permute(dim)   </span></code></pre></div>
<p>用于将张量转换成dim指定的维度。</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>)  </span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.shape, x.permute(<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>).shape)  </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># torch.Size([2, 3, 4]) torch.Size([4, 3, 2])  </span></span></code></pre></div>
<p>本例先产生了一组3维的随机数，每个维度的元素个数分别是2,3,4，然后使用permute将其第2维转成第0维，第1维不变，第0维转成第2维，从打印信息中可以看到各维元素个数的变化。</p>
]]></content>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch全连接网络</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Pytorch/Pytorch%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h1 id="pytorch全连接网络">Pytorch全连接网络</h1>
<p>#Pytorch</p>
<p>本篇开始学习搭建真正的神经网络，前一部分讨论深度学习中预处理数据的基本流程；后一部分构建了两种全连接网络，用三种不同方案拟合时序数据；并在例程中详细分析误差函数，优化器，网络调参，以及数据反向求导的过程。</p>
<h3 id="数据预处理">数据预处理</h3>
<p>本篇使用航空乘客数据AirPassengers.csv，其中包括从1949-1960年每月旅客的数量，程序则用于预测未来几年中每月的旅客数量，数据可从以下Git项目中下载。</p>
<p>https://github.com/aarshayj/analytics_vidhya/blob/master/Articles/Time_Series_Analysis/AirPassengers.csv</p>
<h4 id="读取数据">1．读取数据</h4>
<p>首先，引入必要的头文件，并从文件中读入数据：</p>
<pre><code>import pandas as pd  
import numpy as np  
import matplotlib.pyplot as plt  
%matplotlib inline  
  
import torch  
import torch.nn as nn  
from torch.autograd import Variable  
  
df = pd.read_csv(&#39;data/AirPassengers.csv&#39;)  
plt.plot(df[&#39;#Passengers&#39;])  
plt.show()   </code></pre>
<p>程序输出如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-2e82535a6d9a0828.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="归一化">2．归一化</h4>
<p>无论机器学习还是深度学习，使用哪一种框架，归一化都是必要环节。归一化的目标是将每一维特征压缩到一定范围之内，以免不同特征因取值范围不同而影响其权重。非常大或非常小的值搭配上不恰当的学习率，往往使得收敛过慢，或者因每次调整的波动太大最终无法收敛。归一化去除了这些不稳定因素。</p>
<p>归一化的具体做法是将某一列特征转换成均值为
0、标准差为1的数据，在图像处理过程中，也常把0-255之间的颜色值转换为0-1之间的小数。</p>
<p>本例中使用了均值和标准差编写了归一化和反归一化函数：</p>
<pre><code>def feature_normalize(data):  
    mu = np.mean(data,axis=0) # 均值  
    std = np.std(data,axis=0) # 标准差  
    return (data - mu)/std  
  
def feature_unnormalize(data, arr):  
    mu = np.mean(data,axis=0)  
    std = np.std(data,axis=0)  
    return arr * std + mu  </code></pre>
<h4 id="提取新特征">3．提取新特征</h4>
<p>提取新特征是指从现有特征中提取更多可以代入模型的信息，从而生成新特征，本例中的数据包括两列，第一列“Month”是字符串类型的时间，第二列“#Passengers”是乘客量，也就是需要预测的数据y。下面通过拆分和类型转换，从第一列中提取具体的年“year”和月“mon”，将索引列变为特征“x”，并使用上面定义的函数实现归一化功能。</p>
<pre><code>df[&#39;year&#39;] = df[&#39;Month&#39;].apply(lambda x: float(x[:4]))  
df[&#39;mon&#39;] = df[&#39;Month&#39;].apply(lambda x: float(x[5:]))  
df[&#39;x&#39;] = feature_normalize(df.index)  
df[&#39;y&#39;] = feature_normalize(df[&#39;#Passengers&#39;])  
df[&#39;year&#39;] = feature_normalize(df[&#39;year&#39;])  
df[&#39;mon&#39;] = feature_normalize(df[&#39;mon&#39;])  
df[&#39;real&#39;] = feature_unnormalize(df[&#39;#Passengers&#39;], df[&#39;y&#39;])  </code></pre>
<p>处理后的数据如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-de2f1c13b153c31a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="处理缺失值和异常值">4．处理缺失值和异常值</h4>
<p>处理缺失值和异常值也是特征工程的重要环节，有时花费的时间比建模还多。处理缺失值的常用方法是删除重要特征缺失的item，或者用均值，前后值填充；处理异常值是监测数据中不正常的值，并做出相应处理，由于本例中数据比较“干净”，无需做缺失值和异常值处理。</p>
<h4 id="向量化">5．向量化</h4>
<p>向量化是将读出的数据转换成模型需要的数据格式，根据不同的模型做法不同，本例中的向量化将在后面的模型部分实现。</p>
<h4 id="切分训练集和测试集">6．切分训练集和测试集</h4>
<p>训练前还需要把数据切分成训练集和测试集，以避免过拟合，本例中将70%的数据用于训练，最终模型将对所有数据预测并做图。</p>
<pre><code>TRAIN_PERCENT = 0.7  
train_size = int(len(df) * TRAIN_PERCENT)  
train = df[:train_size]  </code></pre>
<h3 id="拟合直线">拟合直线</h3>
<p>拟合程序分成三部分：定义模型、优化器和误差函数；训练模型；预测并做图。</p>
<h4 id="定义模型优化器误差函数">1．定义模型、优化器、误差函数</h4>
<p>模型继承自mm.Module，并实现了两个核心函数，__init__用于初始化模型结构，forward用于定义前向传播的过程。本例中实现了最为简单的模型，其中只包含一个全连接层，使用nn.Linear定义，torch.nn中定义了常用的网络层实现。</p>
<pre><code>class LinearRegression(nn.Module):  
    def __init__(self):  
        super(LinearRegression, self).__init__()  
        self.linear = nn.Linear(1, 1) # 输入和输出的维度都是1  
  
    def forward(self, x):  
        x = self.linear(x)  
        return x  
  
model = LinearRegression()  
criterion = nn.MSELoss() # 损失函数：均方误差  
optimizer = torch.optim.SGD(model.parameters(), lr=0.001) # 优化算法：随机梯度下降  </code></pre>
<p>损失函数使用了均方误差
MSELoss，它计算的是预测值与真值之差平方的期望值，MSELoss也是回归中最常用的损失函数，torch.nn中实现了一些常用的损失函数，可以直接使用，</p>
<p>优化的目标是更好地更新参数，使模型快速收敛。优化算法就是调整模型参数更新的策略，优化器是优化算法的具体实现。本例中优化器optimizer使用了最基础的随机梯度下降optim.SGD优化方法，torch.optim中定义了常用的优化器。在参数中设置了学习率为0.001，并将模型的参数句柄传入优化器，优化器后期将调整这些参数。</p>
<p>注意：学习率是一个重要参数，最好从小到大设置，如果设置太大，可能造成每次对参数修改过大，造成抖动，使得最终无法收敛。</p>
<h4 id="训练模型">2．训练模型</h4>
<p>训练之前，先把数据转换成模型需要的数据格式，将pandas的数据格式转换为float32格式的Tensor张量，然后用unsqueeze扩展维度到2维（unsqueeze已在上一篇详细介绍）。</p>
<pre><code>x = torch.unsqueeze(torch.tensor(np.array(train[&#39;x&#39;]), dtype=torch.float32), dim=1)  
y = torch.unsqueeze(torch.tensor(np.array(train[&#39;y&#39;]), dtype=torch.float32), dim=1)  
  
for e in range(10000):  
    inputs = Variable(x)  
    target = Variable(y)  
    out = model(inputs) # 前向传播  
    loss = criterion(out, target) # 计算误差  
    optimizer.zero_grad() # 梯度清零  
    loss.backward() # 后向传播  
    optimizer.step() # 调整参数  
    if (e+1) % 1000 == 0: # 每1000次迭代打印一次误差值  
        print(&#39;Epoch:&#123;&#125;, Loss:&#123;:.5f&#125;&#39;.format(e+1, loss.item()))  </code></pre>
<p>后面的循环部分进行了10000次迭代，也就是说将所有数据放进模型训练了10000次，从而使模型收敛。每一次循环之中，将x,y分别转换成变量Variable格式。</p>
<p>然后进行前先传播，model(inputs)调用的是nn.Module
的__call__()函数（__call__是Python类中的一个特殊方法，如果类中定义了此方法，可以通过实例名加括号的方式调用该方法）父类的<strong>call</strong>()调用了前向函数forward()将数据传入层中处理。</p>
<p>接下来是误差函数和优化器配合调整模型参数，此处到底修改了哪些值，又是如何修改的，是最难理解的部分。先通过定义的误差函数计算误差，从loss值可以看到每一次迭代之后误差的情况。</p>
<p>下一步是优化器清零，调用优化器的zero_grad方法，清除了model.parameters中的梯度grad。</p>
<p>之后是反向传播，误差函数的backward，调用了torch.autograd.backward()函数，backward()是上面定义的forward()的反向过程，对每层每一个参数求导，并填充在model.parameters的grad中。</p>
<p>最后调用优化器的step方法（step的具体实现可参考torch源码中optim/sgd.py中的step函数），它使用model.parameters中的梯度grad和设置的学习率、动量等参数计算出model.parameters的新data值，形如：weight
= weight - learning_rate * gradient。</p>
<p>可以说，最后几步都是针对model.parameters模型参数的修改。整个过程可以通过跟踪model.parameters的data和grad的内容变化来分析。方法如下：</p>
<pre><code>for p in model.parameters():  
    print(p.data, p.grad)  </code></pre>
<p>也可以在程序中加入以下代码，用于跟踪后向传播的过程：</p>
<pre><code>f = loss.grad_fn  
while True:  
    print(f)  
    if len(f.next_functions) == 0:  
        break  
    f = f.next_functions[0][0]  </code></pre>
<h4 id="预测和做图">3．预测和做图</h4>
<p>本例中用70%数据作为训练集，用所有数据作为测试集，因此，用全部数据重新计算了x,y值；使用eval函数将模型转换为测试模式（有一些层在训练模型和预测模型时有差别）；将数据代入模型预测，并转换成numpy格式作图显示。</p>
<pre><code>x = torch.unsqueeze(torch.tensor(np.array(df[&#39;x&#39;]), dtype=torch.float32), dim=1)  
y = torch.unsqueeze(torch.tensor(np.array(df[&#39;y&#39;]), dtype=torch.float32), dim=1)  
model.eval() #将模型变为测试模式  
predict = model(Variable(x)) # 预测  
predict = predict.data.numpy() # 转换成numpy格式  
plt.plot(x.numpy(), y.numpy(), &#39;y&#39;)  
plt.plot(x.numpy(), predict)  
plt.show()  </code></pre>
<p>程序运行结果如下图所示，可以看到模型用一条直线拟合曲线，在前70%的训练数据中表现更好。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-72c7d159d30b68b7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="多特征拟合">多特征拟合</h3>
<p>直线拟合的原理是y=kx+b，求斜率k和截距b。其中的x是数据产生的时间，从数据表的索引号转换求得，y是乘客量。还可以使用另一些方法进一步拟合曲线。如：</p>
<ul>
<li>方法一曲线拟合：从图像数据可以看出，乘客数据走势更拟合一条微微上翘的曲线，设y是x的多项式函数，可使用多项式拟合：y=ax<sup>3+bx</sup>2+cx+d。<br />
</li>
<li>方法二多特征拟合：代入更多条件，比如利用年份、月份作为参数代入模型。</li>
</ul>
<p>多参数拟合人x不止一个，可能是{x1,x2,x3...}，设计模型时只需要把输入参数变成多个即可。</p>
<h4 id="定义模型优化器误差函数-1">1．定义模型、优化器、误差函数</h4>
<p>与直线拟合的差异是将输入维度变为3维，模型、优化器、误差函数不变。</p>
<pre><code>class Net2(torch.nn.Module):  
    def __init__(self):  
        super(Net2, self).__init__()  
        self.linear = nn.Linear(3, 1) # 输入3维，输出1维  
  
    def forward(self, x):  
        x = self.linear(x)  
        return x  
  
model = Net2()  
criterion = nn.MSELoss()  
optimizer = torch.optim.SGD(model.parameters(), lr=0.001)  </code></pre>
<h4 id="训练模型-1">2．训练模型</h4>
<p>训练模型步分的主要差异在于处理输入数据，get_data函数分别提供了两种方法，前一种方法用于多项式拟合，后一种方法将年，月信息也作为代入模型的特征，此处，可以更好地理解全连接层的两维输入，其中一维是实例个数，另一维是实例中的各个特征。</p>
<pre><code>def get_data(train):  
    if False: # 可切换两种方法  
        inputs = [[i, i*i, i*i*i] for i in train[&#39;x&#39;]] # 一个x变成3维输入数据  
    else:  
        inputs = [[item[&#39;x&#39;], item[&#39;year&#39;], item[&#39;mon&#39;]] for idx,item in train.iterrows()]  
    X = torch.tensor(np.array(inputs), dtype=torch.float32)  
    y = torch.unsqueeze(torch.tensor(np.array(train[&#39;y&#39;]), dtype=torch.float32), dim=1)  
    return X, y  
  
X, y = get_data(train)  
for e in range(20000):  
    inputs = Variable(X)  
    target = Variable(y)  
    out = model(inputs) # 前向传播  
    loss = criterion(out, target) # 计算误差  
    optimizer.zero_grad() # 清零  
    loss.backward() # 后向传播  
    optimizer.step() # 调整参数  
    if (e+1) % 1000 == 0:  
        print(&#39;Epoch:&#123;&#125;, Loss:&#123;:.5f&#125;&#39;.format(e+1, loss.item()))  </code></pre>
<h4 id="预测和做图-1">3．预测和做图</h4>
<p>预测和做图只有取数据部分与直线拟合不同。</p>
<pre><code>model.eval() #将模型变为测试模式  
X, y = get_data(df)  
predict = model(Variable(X)) # 预测  
predict = predict.data.numpy() # 转换成numpy格式  
plt.plot(y.numpy(), &#39;y&#39;)  
plt.plot(predict)  
plt.show()  </code></pre>
<p>两种方法拟合的曲线如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-25651ca38c6c796a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ad89494399c1da89.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>上述程序都基于线性拟合，由于月份和乘客量并无单调上升关系（年峰值在七八月），因此，线性拟合方法效果也不是很好。读者如有兴趣，可以通过预处理进一步优化该程序的效果。</p>
<h3 id="总结">总结</h3>
<p>本篇介绍的方法，使用Pytorch深度学习框架解决了线性回归问题，第一个例程中实现的是一元线性回归，第二个例程使用的方法类似于SVM中的核函数以及多元线性回归。</p>
<p>使用机器学习或者传统的统计学方法也能实现线性回归，且一些机器学习方法能更好地拟合本例中的曲线。本篇主要通过例程介绍全连接层的功能和用法，只使用了一层，还谈不上深度学习。在下篇中将使用RNN网络拟合本例中的数据，以达到更好的拟合效果，并借此介绍循环网络的原理、具体实现、以及RNN相关API的调用方法。</p>
]]></content>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch初探</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Pytorch/Pytorch%E5%88%9D%E6%8E%A2/</url>
    <content><![CDATA[<h1 id="pytorch初探">Pytorch初探</h1>
<p>#Pytorch #Python</p>
<h3 id="什么是pytorch">什么是Pytorch</h3>
<p>Facebook的Pytorch和Google
的TensorFlow一样，也是一款深度学习库，TensorFlow主要应用于工业生产领域之中，GitHub上的深度学习工具也多基于TensorFlow；而Pytorch在研究领域被广泛使用，越来越多的论文和新技术都基于Pytorch开发。</p>
<p>工业场景比研究领域相对置后，且近年来Pytorch的研究论文有逐渐增加的趋势，随着前沿技术的应用，Pytorch也可能成为一种趋势。目前常用的模型也都有对应的Pytorch版本，具体请见后面参考部分。</p>
<p>本篇就来学习一下Pytorch。Pytorch是Facebook开源的包含GPU加速的神经网络框架。Pytorch是torch的Python版本，也提供C++的接口。</p>
<h3 id="相关概念">相关概念</h3>
<p>Pytorch不像TensorFlow加入了Scope、Session等新概念以及复杂的调用方法，有较高的学习成本，Pytorch只有三个重要概念Tensor（张量）、variable（变量）、Module（模块），它的易用性类似于Keras（Keras是更上层的API，可调用TensorFlow，Theano和CNTK），但比Keras更加灵活。</p>
<p><strong>Tensor</strong><br />
Tensor被译为张量或者标量，它类似于numpy的array。</p>
<p><strong>Variable</strong><br />
Variable被译为变量，可以将它看作Tensor的扩展，它带有自动求导（autogard）功能，一般通过backward()计算梯度后，通过其grad属性查看梯度。创建Variable时需要设置requires_grad=True，才能计算梯度。</p>
<p><strong>Module</strong><br />
Module可以用于定义层，也可以用于定义整个神经网络。它是神经网络的基类，一般构建网络都需要继承Module，并在构造函数__init__()中定义自己的网络结构，以及实现前向算法forward()。</p>
<p><strong>Function</strong><br />
Function针对单个功能，它不像Module可以保存数据，一般Function只需要实现__init__()、forward()、backward()三个函数。</p>
<p><strong>DataSet</strong><br />
DataSet是用于读取数据的工具类，对于较为复杂的数据，通常需要继承DataSet实现自己的数据类。</p>
<p><strong>optim</strong><br />
optimizer译为优化器，pytorch.optim.*中实现了多种优化算法，可以直接调用。
使用时，首先，需要选择一种优化算法，在创建时指定具体参数如学习率，然后在训练模型时使用优化器更新参数（调用其step方法）。优化器用于调整网络参数，其本身不存储数据，只保存优化算法及其参数和指向网络参数的指针。
Pytorch可以对不同的层设置不同的优化参数。</p>
<p><strong>动态计算图</strong><br />
计算图指构建的神经网络结构。TensorFlow使用静态计算图机制，一旦建立，训练过程中不能被修改,
静态计算在效率方面有更大的优化空间。Pytorch
使用动态计算图机制，每一次训练，都会销毁图并重新创建，这样占用了更多资源，但是更加灵活。</p>
<p>###安装</p>
<p><strong>普通安装</strong></p>
<p>不同的操作系统，Python版本和不同硬件（是否支持GPU）安装方法不同，具体方法见https://pytorch.org/，如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-7493a45ea1319835.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>安装好之后，用以下方法，可查看torch版本:</p>
<pre><code>import torch  
print(torch.__version__)  </code></pre>
<p><strong>下载源码</strong></p>
<pre><code>$ git clone --recursive [https://github.com/pytorch/pytorch](https://github.com/pytorch/pytorch) # 下载源码   
$ git clone [https://github.com/pytorch/examples.git](https://github.com/pytorch/examples.git) # 下载例程  </code></pre>
<h3 id="实例">实例</h3>
<p>pytorch/examples/中包括各种例程，其中mnist手写数字识别是深度学习中最常用的示例数据，其Pytorch例程只有百余行，核心代码在50行左右。
下面将讲解其核心函数。</p>
<p>首先，它实现了基于Module的类，用于描述神经网络，其中构造函数__init__()定义了网络结构，函数forward()描述了前向传播的方法。</p>
<pre><code>class Net(nn.Module): # 定义神经网络  
    def __init__(self): # 构建网络  
        super(Net, self).__init__()  
        self.conv1 = nn.Conv2d(1, 20, 5, 1) # 卷积层，输入为1，输出为20，卷积核5x5  
        self.conv2 = nn.Conv2d(20, 50, 5, 1)  
        self.fc1 = nn.Linear(4*4*50, 500) # 全连接层，输入为4*4*50，输出为500  
        self.fc2 = nn.Linear(500, 10)  
    def forward(self, x): # 前向传播  
        x = F.relu(self.conv1(x)) # 激活函数  
        x = F.max_pool2d(x, 2, 2) # 最大池化  
        x = F.relu(self.conv2(x))  
        x = F.max_pool2d(x, 2, 2)  
        x = x.view(-1, 4*4*50) # 改变形状，将数据展开  
        x = F.relu(self.fc1(x))  
        x = self.fc2(x)  
        return F.log_softmax(x, dim=1)  </code></pre>
<p>然后，分别实现了训练train和测试test两个函数，train将整体数据分块batch代入模型训练，再用损失函数计算误差，求梯度，并用优化器调整网络参数。</p>
<pre><code>def train(args, model, device, train_loader, optimizer, epoch):  
    model.train()  
    for batch_idx, (data, target) in enumerate(train_loader): # 整体数据分块训练  
    data, target = data.to(device), target.to(device)  
    optimizer.zero_grad() # 清空了grad，而非params  
    output = model(data)  
    loss = F.nll_loss(output, target) # 误差函数将output与target设入loss  
    loss.backward() # 反向传播，修改了网络参数中的grad  
    optimizer.step() # 根据反向传播梯度更新网络参数  
    if batch_idx % args.log_interval == 0:  
        print(&#39;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#39;.format(epoch, batch_idx * len(data), len(train_loader.dataset), 100\. * batch_idx / len(train_loader), loss.item()))  </code></pre>
<p>主程序根据迭代次数（epoch），多次调用train和test训练模型。</p>
<pre><code>model = Net().to(device)  
optimizer = optim.SGD(model.parameters(), # 神经网络参数设置给优化器  
lr=args.lr, momentum=args.momentum)  
for epoch in range(1, args.epochs + 1): # 所有数据训练多次  
    train(args, model, device, train_loader, optimizer, epoch)  
    test(args, model, device, test_loader)  </code></pre>
<h3 id="总结">总结</h3>
<p>Pytorch的难度介于keras和TensorFlow之间，最重要的是，它的顺序结构，让程序员对流程一目了然。
相对于看原理和论文，很多时候，程序员看代码效果更好，Pytorch的数据处理过程与原理契合度很高。而且预训练、对抗网络的例程也很多，公式完全能落实到代码中。</p>
<h3 id="参考">参考</h3>
<p>PyTorch流行的预训练模型和数据集列表pytorch-playground<br />
<a
href="https://ptorch.com/news/171.html">https://ptorch.com/news/171.html</a></p>
<p>PyTorch-动态计算图<br />
<a
href="https://blog.csdn.net/zhouchen1998/article/details/89562423">https://blog.csdn.net/zhouchen1998/article/details/89562423</a></p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch常用函数之一_数据类型</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Pytorch/Pytorch%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E4%B9%8B%E4%B8%80_%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="pytorch常用函数之一_数据类型">Pytorch常用函数之一_数据类型</h1>
<p>#Pytorch</p>
<p>编程语言和自然语言一样，不理解的词越多，对全文的理解就越差。掌握必要的基础知识，让后期看代码更加流畅。</p>
<p>机器学习需要掌握数据处理工具Pandas、Numpy，同理，深度学习也需要掌握相应的工具，在Pytorch中数据存储在Tensor之中，本篇将介绍它们的基本用法以及与之相关的常用函数。</p>
<h3 id="查看版本信息">查看版本信息</h3>
<p>包含头文件<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.	import torch    </span><br><span class="line">```  </span><br><span class="line">**1．查看torch版本**  </span><br><span class="line">```  </span><br><span class="line">1.	print(torch.__version__)    </span><br><span class="line">```  </span><br><span class="line">**2．查看CUDA版本**  </span><br><span class="line">```  </span><br><span class="line">1.	print(torch.version.cuda)    </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### GPU相关操作  </span><br><span class="line">  </span><br><span class="line">**1. 查看当前是否支持GPU**  </span><br><span class="line">```  </span><br><span class="line">1.	device = torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)    </span><br><span class="line">```  </span><br><span class="line">**2．GPU相关的数据转换**  </span><br><span class="line">```  </span><br><span class="line">1.	a = torch.Tensor([5])    </span><br><span class="line">2.	b = a.to(&#x27;cuda&#x27;) # 转成在 GPU 上运行的类型    </span><br><span class="line">3.	b = a.cuda() # 同上    </span><br><span class="line">4.	c = b.to(&#x27;cpu&#x27;) # 转成在 CPU 上运行的类型    </span><br><span class="line">5.	c = b.cpu() # 同上    </span><br><span class="line">```  </span><br><span class="line">**3. 查看GPU状态**  </span><br><span class="line">```  </span><br><span class="line">1.	print(torch.cuda.device_count()) # 查看可用 GPU 个数    </span><br><span class="line">2.	print(torch.cuda.current_device()) # 查看当前使用的 GPU ID    </span><br><span class="line">3.	print(torch.cuda.get_device_capability(0)) # 查看 ID 为 0 的 CUDA 容量    </span><br><span class="line">4.	print(torch.cuda.get_device_name(0)) # 查看设备名  </span><br><span class="line">```  </span><br><span class="line">**4. 清空GPU缓存**  </span><br><span class="line">```  </span><br><span class="line">1.	print(torch.cuda.empty_cache()) # 清空缓存    </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### Tensor  </span><br><span class="line">  </span><br><span class="line">Tensor用于表示矩阵（多维数据），类似Numpy的ndarray，它可以使用GPU加速。从Pytorch 0.4.0之后，Variable与Tensor合并（Variable仍存在，但很少使用）。  </span><br><span class="line">创建Tensor时参数requires_grad默认为False，若设为True，则可实现自动求导的功能，梯度保存在其内部变量grad中，计算梯度的方法存储在grad_fn中。  </span><br><span class="line">  </span><br><span class="line">**1．生成Tensor**  </span><br><span class="line">  </span><br><span class="line">用Tensor方法将其它格式数据转换成张量，转换内容一般是list或数组格式：  </span><br><span class="line">```  </span><br><span class="line">1.	a = torch.Tensor([[1,2],[3,4],[5,6]]) # 生成 3,2 维Tensor      </span><br><span class="line">2.	b = torch.zeros(3,5) # 生成内容为全0的 3，5 维Tensor      </span><br><span class="line">3.	c = torch.rand(3,5) # 生成内容为 0-1 随机数的 3,5 维Tensor      </span><br><span class="line">4.	d = c.clone() # 将c中内容复制到 d, 新旧内容指向不同的地址空间    </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">**2．修改Tensor**  </span><br><span class="line">用赋值的方法即可修改张量，比如将上面生成张量中位置1,1的元素赋值成50。  </span><br><span class="line">```  </span><br><span class="line">1.	a[1,1]=50    </span><br><span class="line">```  </span><br><span class="line">**3. 查看Tensor状态**  </span><br><span class="line">查看Tensor数据类型，大小及元素个数  </span><br><span class="line">```  </span><br><span class="line">1.	a = torch.Tensor([5])      </span><br><span class="line">2.	print(a.type()) # torch.FloatTensor，默认类型为FloatTesor       </span><br><span class="line">3.	print(a.size()) # torch.Size([1])      </span><br><span class="line">4.	print(a.shape)  # torch.Size([1])      </span><br><span class="line">5.	print(a.numel()) # 1，查看元素个数    </span><br><span class="line">6.	print(a.dim()) # 1, 查看维度    </span><br><span class="line">```  </span><br><span class="line">**4．类型转换**  </span><br><span class="line">Tensor与其它数据类型相互转换  </span><br><span class="line">```  </span><br><span class="line">1.	a = torch.Tensor([5]) # tensor([5.])  </span><br><span class="line">2.	b = a.numpy()  # 转换成numpy.array类型 [5.]    </span><br><span class="line">3.	c = a.item() # 转换成单个值 5.0    </span><br><span class="line">4.	d = torch.from_numpy(b)  # 转换成Tensor tensor([5.])    </span><br><span class="line">5.	e = d.int() # 转换成 IntTensor tensor([5], dtype=torch.int32)  </span><br><span class="line">6.	f = d.tolist() # 转换成list [5.0]    </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 维度变换  </span><br><span class="line">  </span><br><span class="line">**1．增加维度**  </span><br><span class="line">  </span><br><span class="line">在深度学习过程中，现有的数据格式和模型要求的格式往往不同，层与层之间的数据也需要转换后才能对接，维度转换是最常用的方法。  </span><br><span class="line">squeeze意为压缩，即去掉维度，unsqueeze则相反，为添加维度。  </span><br><span class="line">```  </span><br><span class="line">1.	unsqueeze(input, dim, out=None)     </span><br><span class="line">```  </span><br><span class="line">用于增添第dim维度为1。具体用法见以下示例：  </span><br><span class="line">```  </span><br><span class="line">1.	a = torch.Tensor([1,2,3])    </span><br><span class="line">2.	print(a, a.shape)  # tensor([1., 2., 3.]) torch.Size([3])    </span><br><span class="line">3.	b = torch.unsqueeze(a, 1)    </span><br><span class="line">4.	print(b, b.shape)  # tensor([[1.],[2.],[3.]]) torch.Size([3, 1])    </span><br><span class="line">5.	c = torch.unsqueeze(a, 0)    </span><br><span class="line">6.	print(c, c.shape)  # tensor([[1., 2., 3.]]) torch.Size([1, 3])    </span><br><span class="line">```  </span><br><span class="line">**2．减小维度**  </span><br><span class="line">```  </span><br><span class="line">1.	squeeze(input, dim=None, out=None)     </span><br><span class="line">```  </span><br><span class="line">用于删除第dim个维度，如果当前不包括指定的维度，则不会删除。如果不指定dim，函数将删除值为1的维度。  </span><br><span class="line">本例中延用上例中的数据：  </span><br><span class="line">```  </span><br><span class="line">1.	print(torch.squeeze(c,0))  # tensor([1., 2., 3.])    </span><br><span class="line">2.	print(torch.squeeze(b,1))  # tensor([1., 2., 3.])    </span><br><span class="line">3.	print(torch.squeeze(b))  # tensor([1., 2., 3.])    </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">**3．转换维度**  </span><br><span class="line">比squeeze和unsqueeze更简单的方法是直接把张量转换成指定维度，使用view函数实现，它类似于numpy的reshape，Tensor也提供reshape方法。  </span><br><span class="line">```  </span><br><span class="line">1.	view(*shape)     </span><br><span class="line">```  </span><br><span class="line">将张量转换成指定的形状，示例：  </span><br><span class="line">```  </span><br><span class="line">1.	x = torch.Tensor([1,2,3,4])    </span><br><span class="line">2.	print(x.view(2,2))  # tensor([[1., 2.], [3., 4.]])    </span><br><span class="line">3.	print(x.view(1,4))  # tensor([[1., 2., 3., 4.]])    </span><br><span class="line">4.	print(x.view(1,-1)) # 设为-1时自动计算该维度大小 tensor([[1., 2., 3., 4.]])    </span><br><span class="line">5.	print(x.view(4))  # tensor([1., 2., 3., 4.])    </span><br><span class="line">```  </span><br><span class="line">**4．cat拼接**  </span><br><span class="line">cat函数用于在指定维度上拼接多个张量。  </span><br><span class="line">```  </span><br><span class="line">1.	cat(tensors, dim=0, out=None)     </span><br><span class="line">```  </span><br><span class="line">将tensors中的多个张量按dim指定的维度拼接成一个张量，拼接后总维数不变。  </span><br><span class="line">```  </span><br><span class="line">1.	x = torch.Tensor([[1,2],[3,4]])    </span><br><span class="line">2.	y = torch.Tensor([[5,6],[7,8]])    </span><br><span class="line">3.	print(torch.cat((x,y),0))    </span><br><span class="line">4.	# tensor([[1., 2.],    </span><br><span class="line">5.	#        [3., 4.],    </span><br><span class="line">6.	#        [5., 6.],    </span><br><span class="line">7.	#        [7., 8.]])    </span><br><span class="line">8.	print(torch.cat((x,y),1))    </span><br><span class="line">9.	# tensor([[1., 2., 5., 6.],    </span><br><span class="line">10.	#        [3., 4., 7., 8.]])    </span><br><span class="line">```  </span><br><span class="line">一般面对的数据最多三维，并以一两维居多，可将其理解为横向加或者纵向加。  </span><br><span class="line">  </span><br><span class="line">**5．stack拼接**  </span><br><span class="line">与cat拼接不同的是，stack拼接后维度增加，其用法如下：  </span><br><span class="line">```  </span><br><span class="line">1.	stack(tensors, dim=0, out=None)    </span><br><span class="line">```  </span><br><span class="line">示例：  </span><br><span class="line">```  </span><br><span class="line">1.	x = torch.Tensor([1,2])    </span><br><span class="line">2.	y = torch.Tensor([3,4])    </span><br><span class="line">3.	print(torch.stack((x,y),dim=0))    </span><br><span class="line">4.	# tensor([[1., 2.],    </span><br><span class="line">5.	#         [3., 4.]])    </span><br><span class="line">6.	print(torch.stack((x,y),dim=1))    </span><br><span class="line">7.	# tensor([[1., 3.],    </span><br><span class="line">8.	#         [2., 4.]])    </span><br><span class="line">```  </span><br><span class="line">从输出内容可以看到，拼接后张量变成了两维，dim=0是最常用的方法，它直接把两个张量拼在一起，当dim=1时，拼接时转换了位置。  </span><br><span class="line">***注意：想把 list(tensor, tensor) 变为二维 tensor，使用 stack 即可***  </span><br><span class="line">  </span><br><span class="line">**6．transpose两维度互换**  </span><br><span class="line">```  </span><br><span class="line">1.	transpose(input, dim0, dim1)    </span><br><span class="line">```  </span><br><span class="line">互换dim0, dim1两个维度，具体用法如下：  </span><br><span class="line">```  </span><br><span class="line">1.	x = torch.Tensor([[1,2],[3,4]])    </span><br><span class="line">2.	print(torch.transpose(x,0,1))    </span><br><span class="line">3.	# tensor([[1., 3.],    </span><br><span class="line">4.	#        [2., 4.]])    </span><br><span class="line">```  </span><br><span class="line">**7．perumute多维度互换**  </span><br><span class="line">permute与transpose功能类似，但更加灵活，它可以指定多个维度互换。  </span><br><span class="line">```  </span><br><span class="line">1.	x = torch.Tensor([[1,2],[3,4]])    </span><br><span class="line">2.	print(torch.transpose(x,0,1))    </span><br><span class="line">3.	# tensor([[1., 3.],    </span><br><span class="line">4.	#        [2., 4.]])    </span><br><span class="line">```  </span><br><span class="line">用于将张量转换成dim指定的维度。  </span><br><span class="line">```  </span><br><span class="line">1.	x = torch.rand(2,3,4)    </span><br><span class="line">2.	print(x.shape, x.permute(2,1,0).shape)    </span><br><span class="line">3.	# torch.Size([2, 3, 4]) torch.Size([4, 3, 2])    </span><br><span class="line">```  </span><br><span class="line">本例先产生了一组3维的随机数，每个维度的元素个数分别是2,3,4，然后使用permute将其第2维转成第0维，第1维不变，第0维转成第2维，从打印信息可以看到各维元素个数的变化。permute常用于对转换图片格式。  </span><br><span class="line">  </span><br><span class="line">**8．维度扩展**  </span><br><span class="line">增加Tensor中元素的个数，其内容与被扩展的内容一致。  </span><br><span class="line">```  </span><br><span class="line">1.	a = torch.Tensor([5])    </span><br><span class="line">2.	print(a.expand(1, 2)) # tensor([[5., 5.]])    </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">### 求导  </span><br><span class="line">下例中使用了torch.tensor而非torch.Tensor，torch.Tensor是Pytorch中的类，确切地说是FloatTensor的别名；而torch.tensor()是函数，它更加灵活，使用方法如下：  </span><br><span class="line">```  </span><br><span class="line">1.	torch.tensor(data, dtype=None, device=None, requires_grad=False)    </span><br><span class="line">```  </span><br><span class="line">它可以创建各种类型的Tensor数据。  </span><br><span class="line">下面声明三个变量x,a,b，用它们计算变量y，之后用y.backward()求y对x,a,b三个变量的偏导数，这是深度学习中常说的“反向”过程。结果存储在变量的grad元素中，如x.grad。  </span><br><span class="line">```  </span><br><span class="line">1.	x = torch.tensor([1.0], requires_grad=True)      </span><br><span class="line">2.	a = torch.tensor([2.0], requires_grad=True)      </span><br><span class="line">3.	b = torch.tensor([3.0], requires_grad=True)      </span><br><span class="line">4.	y = a * x + b    </span><br><span class="line">5.	y.backward()      </span><br><span class="line">6.	print(x.grad) # 输出结果: tensor([2.])      </span><br><span class="line">7.	print(a.grad) # 输出结果: tensor([1.])      </span><br><span class="line">8.	print(b.grad) # 输出结果: tensor([1.])      </span><br><span class="line">9.	print(b.data) # 输出结果: tensor([3.])      </span><br><span class="line">```  </span><br><span class="line">从输出结果可以看到，Tensor包含两个元素，data是它的Tensor值，grad保存的是求得的偏导数。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 剥离无梯度变量  </span><br><span class="line">detach方法用于从普通Tensor中剥离出无梯度的变量。下面延用上例求导后有梯度的数据b。  </span><br><span class="line">```  </span><br><span class="line">1.	print(b) # tensor([3.], requires_grad=True)    </span><br><span class="line">2.	print(b.detach()) # tensor([3.])    </span><br><span class="line">3.	print(b.detach_()) # tensor([3.])    </span><br><span class="line">```  </span><br><span class="line">detach和detach_的区别是detach获取b的data数据，而detach_则是将b中的grad_fn设置为None，requires_grad设置为False，从而改变了b的内容。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### Parameter  </span><br><span class="line">一般模型参数都是torch.nn.parameter.Parameter类型的数据，它继承了Tensor，主要不同是requires_grad默认为True，以便于模型调参。  </span><br><span class="line">常在两种场景中使用Parameter，一种是fine-tune精调时冻结模型中某些层的参数；另一种是自己实现一些特殊的结构，如构建Attention时，用Parameter创建需要调节的参数。  </span><br><span class="line">  </span><br><span class="line">**1．创建Parameter数据**  </span><br><span class="line">```  </span><br><span class="line">1.	p = torch.nn.Parameter(torch.randn(2))     </span><br><span class="line">2.	print(p) # tensor([1.2087, 1.2607], requires_grad=True)    </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">**2. 查看模型的Parameter参数，大小及冻结情况**  </span><br><span class="line">  </span><br><span class="line">Pytorch模型的基类是Module，其中维护一个名为_parameters的字典，它包含每一个子元素的名字(key)和value参数(value)。如需要冻结某层，将其require_grad设为False即可。  </span><br><span class="line">```  </span><br><span class="line">1.	model = torch.nn.Linear(1,1)    </span><br><span class="line">2.	for name, param in model.named_parameters():      </span><br><span class="line">3.	    print(name, param.size(), param.requires_grad)      </span><br><span class="line">4.	# 输出结果:    </span><br><span class="line">5.	# weight torch.Size([1, 1]) True    </span><br><span class="line">6.	# bias torch.Size([1]) True    </span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch提取不同层次图片的特征</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Pytorch/Pytorch%E6%8F%90%E5%8F%96%E4%B8%8D%E5%90%8C%E5%B1%82%E6%AC%A1%E5%9B%BE%E7%89%87%E7%9A%84%E7%89%B9%E5%BE%81/</url>
    <content><![CDATA[<h1
id="pytorch提取不同层次图片的特征">Pytorch提取不同层次图片的特征</h1>
<p>#图形图像 #Pytorch</p>
<p>下例使用torchvision库提取了resnet最后一层的卷积特征；resnet各block的卷积特性，以及金字塔特性。</p>
<p>具体取哪一层特征视使用场景而定，resnet各block的输出包含更丰富的特征；从resnet最后一层提取的特征更为抽象；fpn每层通道数相等，含义也类似，可以在多层之间比较。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import os  </span><br><span class="line">import torchvision.models.detection.backbone_utils as backbone_utils  </span><br><span class="line">import torchvision  </span><br><span class="line">import torch.nn as nn  </span><br><span class="line">  </span><br><span class="line">device = &#x27;cuda&#x27;  </span><br><span class="line">os.environ[&quot;TORCH_HOME&quot;] = &#x27;/notebooks/data/mine/live/code_v7/model/&#x27;  </span><br><span class="line">USE_FPN = True  </span><br><span class="line">if USE_FPN:  </span><br><span class="line">    backbone = backbone_utils.resnet_fpn_backbone(&#x27;resnet50&#x27;, True)  </span><br><span class="line">    features = list(backbone.children())[:-1] # 去掉最后的fpn层, 得到resnet的2,3,4层输出  </span><br><span class="line">    #features = list(backbone.children()) # 计算图像金字塔输出, 低层包括具体和抽像特征  </span><br><span class="line">    model = nn.Sequential(*features)     </span><br><span class="line">else:  </span><br><span class="line">    backbone = torchvision.models.resnet50(pretrained=True)  </span><br><span class="line">    features = list(backbone.children())[:-2] # 去掉全连接和池化层, 得到最后卷积层输出   </span><br><span class="line">    model = nn.Sequential(*features)  </span><br><span class="line">      </span><br><span class="line">model = model.to(device)  </span><br><span class="line">x = torch.rand([1,3,244,244]).to(device)  </span><br><span class="line">out = model(x)  </span><br><span class="line">  </span><br><span class="line">if USE_FPN: # 多层输出  </span><br><span class="line">    for key,value in out.items():  </span><br><span class="line">        print(key, value.shape)  </span><br><span class="line">else: # 单层输出  </span><br><span class="line">    print(out.shape)  </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>图形图像</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>用Pytorch手工实现ResNet50</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Pytorch/Pytorch%E6%89%8B%E5%B7%A5%E5%AE%9E%E7%8E%B0ResNet50/</url>
    <content><![CDATA[<h1 id="用pytorch手工实现resnet50">用Pytorch手工实现ResNet50</h1>
<p>#深度学习</p>
<p>《吴恩达深度学习课程》第四课第二周的作业是：使用Keras和Tensorflow编写ResNet50，用程序实现题目中描述的网络结构。由于程序填空提供了不少示例，做完后仍感觉理解不透彻，又使用Pytorch实现了一遍。</p>
<p>ResNet50包含49个卷积层和1个全连接层，属于较大型的网络，实现起来略有难度。对于理解数据流、卷积层、残差、瓶颈层，以及对大型网络的编写和调试都有很大帮助。</p>
<p>使用的数据仍是第四课第二周中的手势图片识别，题目说明、Keras例程和相关数据可从以下网址下载：<a
href="https://blog.csdn.net/u013733326/article/details/80250818">https://blog.csdn.net/u013733326/article/details/80250818</a></p>
<p>Keras ResNet50程序填空的代码可从以下网址下载： <a
href="https://github.com/Kulbear/deep-learning-coursera/blob/master/Convolutional%20Neural%20Networks/Residual%20Networks%20-%20v1.ipynb">https://github.com/Kulbear/deep-learning-coursera/blob/master/Convolutional%20Neural%20Networks/Residual%20Networks%20-%20v1.ipynb</a></p>
<p>Torch官方版本的ResNet实现可从以下网址下载（网络结构细节略有不同）：
<a
href="https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py">https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py</a></p>
<h3 id="网络结构">网络结构</h3>
<p>ResNet网络结构如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-43d49e372e3208b7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="代码">代码</h3>
<p>下面使用约100行代码实现了ResNet50网络类（可缩减至80行左右），另外100行代码用于处理数据，训练和预测。</p>
<p>准备数据：<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import math  </span><br><span class="line">import numpy as np  </span><br><span class="line">import h5py  </span><br><span class="line">import matplotlib.pyplot as plt  </span><br><span class="line">import scipy  </span><br><span class="line">from PIL import Image  </span><br><span class="line">from scipy import ndimage  </span><br><span class="line">import torch  </span><br><span class="line">import torch.nn as nn  </span><br><span class="line">from cnn_utils import *  </span><br><span class="line">from torch import nn,optim  </span><br><span class="line">from torch.utils.data import DataLoader,Dataset  </span><br><span class="line">from torchvision import transforms  </span><br><span class="line">  </span><br><span class="line">%matplotlib inline  </span><br><span class="line">np.random.seed(1)  </span><br><span class="line">torch.manual_seed(1)  </span><br><span class="line">batch_size = 24  </span><br><span class="line">learning_rate = 0.009  </span><br><span class="line">num_epocher = 100  </span><br><span class="line">  </span><br><span class="line">X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()  </span><br><span class="line">X_train = X_train_orig/255.  </span><br><span class="line">X_test = X_test_orig/255.  </span><br><span class="line">  </span><br><span class="line">class MyData(Dataset): #继承Dataset  </span><br><span class="line">    def __init__(self, data, y, transform=None): #__init__是初始化该类的一些基础参数  </span><br><span class="line">        self.transform = transform #变换  </span><br><span class="line">        self.data = data  </span><br><span class="line">        self.y = y  </span><br><span class="line">      </span><br><span class="line">    def __len__(self):#返回整个数据集的大小  </span><br><span class="line">        return len(self.data)  </span><br><span class="line">      </span><br><span class="line">    def __getitem__(self,index):#根据索引index返回dataset[index]  </span><br><span class="line">        sample = self.data[index]  </span><br><span class="line">        if self.transform:  </span><br><span class="line">            sample = self.transform(sample)#对样本进行变换  </span><br><span class="line">        return sample, self.y[index] #返回该样本  </span><br><span class="line">      </span><br><span class="line">train_dataset = MyData(X_train, Y_train_orig[0],  </span><br><span class="line">    transform=transforms.ToTensor())  </span><br><span class="line">test_dataset = MyData(X_test, Y_test_orig[0],  </span><br><span class="line">    transform=transforms.ToTensor())  </span><br><span class="line">train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)  </span><br><span class="line">test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False)  </span><br><span class="line">```  </span><br><span class="line">实现ResNet  </span><br><span class="line">```  </span><br><span class="line">class ConvBlock(nn.Module):  </span><br><span class="line">    def __init__(self, in_channel, f, filters, s):  </span><br><span class="line">        super(ConvBlock,self).__init__()  </span><br><span class="line">        F1, F2, F3 = filters  </span><br><span class="line">        self.stage = nn.Sequential(  </span><br><span class="line">            nn.Conv2d(in_channel,F1,1,stride=s, padding=0, bias=False),  </span><br><span class="line">            nn.BatchNorm2d(F1),  </span><br><span class="line">            nn.ReLU(True),  </span><br><span class="line">            nn.Conv2d(F1,F2,f,stride=1, padding=True, bias=False),  </span><br><span class="line">            nn.BatchNorm2d(F2),  </span><br><span class="line">            nn.ReLU(True),  </span><br><span class="line">            nn.Conv2d(F2,F3,1,stride=1, padding=0, bias=False),  </span><br><span class="line">            nn.BatchNorm2d(F3),  </span><br><span class="line">        )  </span><br><span class="line">        self.shortcut_1 = nn.Conv2d(in_channel, F3, 1, stride=s, padding=0, bias=False)  </span><br><span class="line">        self.batch_1 = nn.BatchNorm2d(F3)  </span><br><span class="line">        self.relu_1 = nn.ReLU(True)  </span><br><span class="line">          </span><br><span class="line">    def forward(self, X):  </span><br><span class="line">        X_shortcut = self.shortcut_1(X)  </span><br><span class="line">        X_shortcut = self.batch_1(X_shortcut)  </span><br><span class="line">        X = self.stage(X)  </span><br><span class="line">        X = X + X_shortcut  </span><br><span class="line">        X = self.relu_1(X)  </span><br><span class="line">        return X      </span><br><span class="line">      </span><br><span class="line">class IndentityBlock(nn.Module):  </span><br><span class="line">    def __init__(self, in_channel, f, filters):  </span><br><span class="line">        super(IndentityBlock,self).__init__()  </span><br><span class="line">        F1, F2, F3 = filters  </span><br><span class="line">        self.stage = nn.Sequential(  </span><br><span class="line">            nn.Conv2d(in_channel,F1,1,stride=1, padding=0, bias=False),  </span><br><span class="line">            nn.BatchNorm2d(F1),  </span><br><span class="line">            nn.ReLU(True),  </span><br><span class="line">            nn.Conv2d(F1,F2,f,stride=1, padding=True, bias=False),  </span><br><span class="line">            nn.BatchNorm2d(F2),  </span><br><span class="line">            nn.ReLU(True),  </span><br><span class="line">            nn.Conv2d(F2,F3,1,stride=1, padding=0, bias=False),  </span><br><span class="line">            nn.BatchNorm2d(F3),  </span><br><span class="line">        )  </span><br><span class="line">        self.relu_1 = nn.ReLU(True)  </span><br><span class="line">          </span><br><span class="line">    def forward(self, X):  </span><br><span class="line">        X_shortcut = X  </span><br><span class="line">        X = self.stage(X)  </span><br><span class="line">        X = X + X_shortcut  </span><br><span class="line">        X = self.relu_1(X)  </span><br><span class="line">        return X  </span><br><span class="line">      </span><br><span class="line">class ResModel(nn.Module):  </span><br><span class="line">    def __init__(self, n_class):  </span><br><span class="line">        super(ResModel,self).__init__()  </span><br><span class="line">        self.stage1 = nn.Sequential(  </span><br><span class="line">            nn.Conv2d(3,64,7,stride=2, padding=3, bias=False),  </span><br><span class="line">            nn.BatchNorm2d(64),  </span><br><span class="line">            nn.ReLU(True),  </span><br><span class="line">            nn.MaxPool2d(3,2,padding=1),  </span><br><span class="line">        )  </span><br><span class="line">        self.stage2 = nn.Sequential(  </span><br><span class="line">            ConvBlock(64, f=3, filters=[64, 64, 256], s=1),  </span><br><span class="line">            IndentityBlock(256, 3, [64, 64, 256]),  </span><br><span class="line">            IndentityBlock(256, 3, [64, 64, 256]),  </span><br><span class="line">        )  </span><br><span class="line">        self.stage3 = nn.Sequential(  </span><br><span class="line">            ConvBlock(256, f=3, filters=[128, 128, 512], s=2),  </span><br><span class="line">            IndentityBlock(512, 3, [128, 128, 512]),  </span><br><span class="line">            IndentityBlock(512, 3, [128, 128, 512]),  </span><br><span class="line">            IndentityBlock(512, 3, [128, 128, 512]),  </span><br><span class="line">        )  </span><br><span class="line">        self.stage4 = nn.Sequential(  </span><br><span class="line">            ConvBlock(512, f=3, filters=[256, 256, 1024], s=2),  </span><br><span class="line">            IndentityBlock(1024, 3, [256, 256, 1024]),  </span><br><span class="line">            IndentityBlock(1024, 3, [256, 256, 1024]),  </span><br><span class="line">            IndentityBlock(1024, 3, [256, 256, 1024]),  </span><br><span class="line">            IndentityBlock(1024, 3, [256, 256, 1024]),  </span><br><span class="line">            IndentityBlock(1024, 3, [256, 256, 1024]),  </span><br><span class="line">        )  </span><br><span class="line">        self.stage5 = nn.Sequential(  </span><br><span class="line">            ConvBlock(1024, f=3, filters=[512, 512, 2048], s=2),  </span><br><span class="line">            IndentityBlock(2048, 3, [512, 512, 2048]),  </span><br><span class="line">            IndentityBlock(2048, 3, [512, 512, 2048]),  </span><br><span class="line">        )  </span><br><span class="line">        self.pool = nn.AvgPool2d(2,2,padding=1)  </span><br><span class="line">        self.fc = nn.Sequential(  </span><br><span class="line">            nn.Linear(8192,n_class)  </span><br><span class="line">        )  </span><br><span class="line">      </span><br><span class="line">    def forward(self, X):  </span><br><span class="line">        out = self.stage1(X)  </span><br><span class="line">        out = self.stage2(out)  </span><br><span class="line">        out = self.stage3(out)  </span><br><span class="line">        out = self.stage4(out)  </span><br><span class="line">        out = self.stage5(out)  </span><br><span class="line">        out = self.pool(out)  </span><br><span class="line">        out = out.view(out.size(0),8192)  </span><br><span class="line">        out = self.fc(out)  </span><br><span class="line">        return out  </span><br><span class="line">```  </span><br><span class="line">训练和预测  </span><br><span class="line">```  </span><br><span class="line">device = &#x27;cuda&#x27;  </span><br><span class="line">  </span><br><span class="line">def test():  </span><br><span class="line">    model.eval()    #需要说明是否模型测试  </span><br><span class="line">    eval_loss = 0  </span><br><span class="line">    eval_acc = 0  </span><br><span class="line">    for data in test_loader:  </span><br><span class="line">        img,label = data  </span><br><span class="line">        img = img.float().to(device)  </span><br><span class="line">        label = label.long().to(device)  </span><br><span class="line">        out = model(img)    #前向算法  </span><br><span class="line">        loss = criterion(out,label) #计算loss  </span><br><span class="line">        eval_loss += loss.item() * label.size(0)    #total loss  </span><br><span class="line">        _,pred = torch.max(out,1)   #预测结果  </span><br><span class="line">        num_correct = (pred == label).sum() #正确结果  </span><br><span class="line">        eval_acc += num_correct.item()  #正确结果总数  </span><br><span class="line">  </span><br><span class="line">    print(&#x27;Test Loss:&#123;:.6f&#125;,Acc: &#123;:.6f&#125;&#x27;  </span><br><span class="line">          .format(eval_loss/ (len(test_dataset)),eval_acc * 1.0/(len(test_dataset))))  </span><br><span class="line">  </span><br><span class="line">model = ResModel(6)  </span><br><span class="line">model = model.to(device)  </span><br><span class="line">criterion = nn.CrossEntropyLoss()  </span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.8)  </span><br><span class="line">  </span><br><span class="line">#开始训练  </span><br><span class="line">for epoch in range(num_epocher):  </span><br><span class="line">    model.train()  </span><br><span class="line">    running_loss = 0.0  </span><br><span class="line">    running_acc = 0.0  </span><br><span class="line">    for i,data in enumerate(train_loader,1):  </span><br><span class="line">        img,label = data  </span><br><span class="line">        img = img.float().to(device)  </span><br><span class="line">        label = label.long().to(device)  </span><br><span class="line">        #前向传播  </span><br><span class="line">        out = model(img)  </span><br><span class="line">        loss = criterion(out,label) #loss  </span><br><span class="line">        running_loss += loss.item() * label.size(0)  </span><br><span class="line">        _,pred = torch.max(out,1)   #预测结果  </span><br><span class="line">        num_correct = (pred == label).sum() #正确结果的数量  </span><br><span class="line">        running_acc += num_correct.item()   #正确结果的总数  </span><br><span class="line">          </span><br><span class="line">        optimizer.zero_grad()   #梯度清零  </span><br><span class="line">        loss.backward() #后向传播计算梯度  </span><br><span class="line">        optimizer.step()    #利用梯度更新W，b参数  </span><br><span class="line">    #打印一个循环后，训练集合上的loss和正确率  </span><br><span class="line">    if (epoch+1) % 1 == 0:  </span><br><span class="line">        print(&#x27;Train&#123;&#125; epoch, Loss: &#123;:.6f&#125;,Acc: &#123;:.6f&#125;&#x27;.format(epoch+1,running_loss / (len(train_dataset)),  </span><br><span class="line">                                                               running_acc / (len(train_dataset))))  </span><br><span class="line">        test()  </span><br><span class="line">```  </span><br><span class="line">实验1000张图片作为训练集，120张图片作为测试集，在使用GPU的情况下几分钟即可完成100次迭代，使用CPU两三个小时也能训练完成，训练好的模型约100M左右，在测试集准确率基本稳定在97.5%。对比简单的网络结构，ResNet50可以较短的时间内达到较好的效果。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">###瓶颈层  </span><br><span class="line">  </span><br><span class="line">使用Pytorch实现ResNet时，需要注意卷积层间的对接，比如在第二层conv2.x中有3个Block，Block内部3层通道输出分别是64，64，256，于是有64-&gt;64-&gt;256，较容易理解；而第二层的3个Block之间，需要将256再转回64，在第二层内部，通道变化是64-&gt;64-&gt;256-&gt;64-&gt;64-&gt;256-&gt;64-&gt;64-&gt;256。  </span><br><span class="line">  </span><br><span class="line">其数据流变化如下图所示：  </span><br><span class="line">  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/5357893-23f4278970ccf4fb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line">block中的三个卷积层：第一层，卷积核1x1用于实现通道数转换，第二层3x3实现特征提取，第三层将通道数转换成目标大小。  </span><br><span class="line">  </span><br><span class="line">不同的块内结构是Resnet50与Resnet34的主要区别：  </span><br><span class="line">  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/5357893-9c946c7f91920d11.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line">不同的结构，在Block块数相同，且参数规模相似的情况下，Resnet34提取512个特征（输出通道数），而ResNet50能提取2048个特征。从论文中可以看到同结构的对比效果。  </span><br><span class="line">  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/5357893-1be031c70fe2b50f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line">论文地址：https://arxiv.org/pdf/1512.03385.pdf  </span><br><span class="line">  </span><br><span class="line">在图像处理中卷积核是四维的，其大小为：卷积核长x卷积核宽x输入通道数x输出通道数。在数据处理后期通道数越来越大，因此左图中的结构在层数多，输出特征多的情况下，参数将变得非常庞大；而右图限制了3x3卷积处理的通道数，1x1的卷积操作运算量又比较小，有效地解决了这一问题。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 调试方法  </span><br><span class="line">  </span><br><span class="line">搭建大型网络时，数据在网络中逐层处理，常出现相邻层之间数据接口不匹配的问题。在本例中可对照官方版本的ResNet结构排查问题，使用下面程序可打印出torchvision中ResNet的网络结构。  </span><br><span class="line">```  </span><br><span class="line">import torchvision  </span><br><span class="line">  </span><br><span class="line">resnet50 = torchvision.models.resnet.ResNet(torchvision.models.resnet.Bottleneck,[3, 4, 6, 3],1000)  </span><br><span class="line">res_layer1 = torch.nn.Sequential(resnet50.conv1, resnet50.maxpool, resnet50.layer1)  </span><br><span class="line">img = torch.rand((2, 3, 224, 224)) # 生成图片  </span><br><span class="line">print(res_layer1(img).shape) # 查看第一层输出数据的形状  </span><br><span class="line">print(res_layer1) # 查看第一层网络结构  </span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch避免更新模型梯度</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Pytorch/Pytorch%E9%81%BF%E5%85%8D%E6%9B%B4%E6%96%B0%E6%A8%A1%E5%9E%8B%E6%A2%AF%E5%BA%A6/</url>
    <content><![CDATA[<h1 id="pytorch避免更新模型梯度">Pytorch避免更新模型梯度</h1>
<p>#Pytorch</p>
<h3 id="torch.no_grad">1. torch.no_grad</h3>
<p><strong>(1) 用法</strong></p>
<pre><code>with torch.no_grad():  
  具体操作  </code></pre>
<p><strong>(2) 说明</strong><br />
上例的“具体操作”中均不更新梯度，这样可以节约计算时间和内存。一般用于验证或者测试阶段。</p>
<h3 id="param.requires_grad">2. param.requires_grad</h3>
<p><strong>(1) 用法</strong></p>
<pre><code>p.requires_grad=False  </code></pre>
<p><strong>(2) 说明</strong><br />
一般用于将某一层设置为不自动更新梯度，以避免训练模型时对该层调参。</p>
<h3 id="model.eval">3. model.eval</h3>
<p><strong>(1) 用法</strong></p>
<pre><code>model.eval()  
具体操作  </code></pre>
<p><strong>(2) 说明</strong><br />
模型支持train模式和eval模式，在使用模型之前调用model.eval()，进入eval评估模型，它将改变forward，如禁止dropout，并用统计数据做batch
norm。因此，有时train模式和eval模式模型计算的结果不同。</p>
]]></content>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Seq2Seq与Attention</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Pytorch/Seq2Seq%E4%B8%8EAttention/</url>
    <content><![CDATA[<h1 id="seq2seq与attention">Seq2Seq与Attention</h1>
<p>#自然语言处理 #时序 #Pytorch</p>
<p>自然语言处理是典型的序列问题，其底层算法在最近几年迅速发展，比如去年年底发布的BERT在11项自然语言处理任务中表现卓越，今年GPT-2生成文本（写作）的水平也有了显著提高。</p>
<p>目前这些最先进的技术都基于Transformer模型，该模型从RNN，LSTM，Seq2Seq，Attention，ConvS2S，Transformer一步步进化而来，还涉及自然语言处理的相关知识，包含的知识点太多，无法一次说清。笔者将其分成几篇，从其进化过程逐步引入。之前已经介绍过RNN及LSTM，本篇将介绍Seq2Seq和Attention算法。</p>
<h3 id="翻译功能">翻译功能</h3>
<p>深度学习中的自然语言处理常用于自动翻译、语言识别、问答系统、提取概要、写作等等领域。</p>
<p>其中自动翻译是一项非常典型的应用，在翻译过程中，输入和输出的词汇个数可长可短，不能一一对应，不同语言词汇顺序又可能不同，并且还有一词多义，一义多词，词在不同位置含义不同的情况……是相对复杂的自然语言处理问题。</p>
<p>先来看看人怎么解决翻译问题，面对一种完全不认识的语言，人把句子分解成词，通过查字典的方式将词转换成母语，然后再通过语法组合成句。其中主要涉及词的实际含义、内容的先后关系，两种语言对应关系。<strong>机器既不需要了解各个词的含义和语法，也不需要字典，就能通过大量训练实现翻译功能，并且效果还不错。</strong>这让神经网络看起来更加难以理解。</p>
<p>一开始的深度学习神经网络，没有逐词翻译的逻辑，主要实现的是序列生成模型，根据前面的一个词或者几个词去推测后面的词。所以人们认为，机器并没有真正理解语言，以及两种语言之间的对应关系，通过训练生成的知识分散在网络各个节点用权重表示，也不能提炼总结，完全是个黑盒。同时，它也不能代入已有的知识，如果换成与训练数据不同的情境，就无法正常工作了。</p>
<p>翻译模型发展到今天，已很大程度改善了这一问题，现在的模型<strong>可以通过训练学习到什么是“苹果”，也可以生成翻译词典。而且这些规则不需要事先输入，是它自己“学”出来的。</strong>通过注意力算法，不仅能实现翻译，还能找到词间的对应关系（双语词典）；词向量可以从多个角度描述词的特征，对比“苹果”和“沙果”的相似度（词汇含义）；据此，就可以把高频率出现的规则总结成知识。</p>
<h3 id="seq2seq">Seq2Seq</h3>
<h4 id="引入">1. 引入</h4>
<p>设想最简单的情况，将一句中文X(x1,x2,x3,x4)翻译成英文Y(y1,y2,y3)。</p>
<p>如果把模型想像成黑盒，则如图下所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5114af22e23d1b58.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>由于不同语言的词汇不存在绝对的一一对应关系，人工翻译一般是看完输入的完整句子，才开始翻译并输出，如果有条件，最好还能看一下上下文语境。模型处理数据流也是如此。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-0a0df6eceb8dbb50.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>前几篇介绍了循环神经网络RNN，它不断向后传递隐藏层h的内容，使得序列中的信息逐步向后传递，下图是RNN网络在翻译问题中最简单的用法，LSTM和GRU原理与RNN相同。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-4336b5b22f6e0a6f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>在RNN循环网络中，神经网络的每个时间步对应同一组参数，这些参数存储着翻译功能所包含的大量信息；在翻译任务中，两种语言的词汇语法不同，用同一组参数描述它们显然比较粗糙。如果能对两种语言生成两种规则，用不同网络的不同参数描述，则更加合理。于是，将翻译过程拆分为编码Encoder和解码Decoder两个子模型，可把这个过程想像成：先把中文翻译成一种语义编码c，再把语义编码c翻译成英文。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-86a7325ed1e6741f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>进一步细化，在Decoder过程中，生成每个词汇时，除了需要依赖上一步的隐藏层输出，还需要参考输出序列的前一个词，使得生成的序列符合语法规则（如介词的位置），设置输出序列的第一个词为、、
&lt;start&gt;，最后一个词为&lt;end&gt;，细化后的逻辑如下图示。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-efe279d8b08be6d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="概念">2. 概念</h4>
<p>Seq2Seq也被称为S2S，是Sequence to
Sequence的简称，即序列到序列的转换。它始于谷歌在2014年发表的一篇论文《Sequence
to Sequence Learning with Neural Networks》。</p>
<p>上图中的Encoder-Decoder网络结构就是Seq2Seq，Encoder和Decoder可以使用RNN，LSTM，GRU等基础模型。简言之，就是把翻译中原来的一个循环网络变成了两个。</p>
<p>除了翻译，Seq2Seq也被用于提取概要，问答，语音识别等场景之中，处理输入和输出规则不同的情况，但是在生成文本的任务中，比如通过前面文字续写后续文字，输入和输出都是同样的序列，则无需Seq2Seq。</p>
<h3 id="转换词向量">转换词向量</h3>
<p>在自然语言处理中，常将单词作为序列中的元素。</p>
<p>模型只能接收数值型数据，代入模型前，需要把词汇转换成数值，如果使用One-Hot编码，数据维度将非常大，并且无法描述词与词之间的相似度。更常用的方法是词嵌入Word
Embedding，它将每个词表示成向量，比如把“hello”，转换成三维的值[-1.7123,
-0.6566,
-0.6055]，可将该操作理解成：把一个词汇拆分成为多个属性。通过比较各个属性的差异可以计算两个词汇之间的距离。</p>
<p>在不同层面，不同角度将看到事物的不同属性（特征），比如梨和苹果都是水果，但是颜色差异很大，通过模型计算出来的词属性与训练的目标以及训练数据有关。词汇的特征通过反向传播计算得来，从这个角度看，神经网络对每个词进行了特征提取，也可作为词特征提取工具来使用。</p>
<p>在Pythorch中使用torch.nn.Embedding可实现该功能，它提供了词的索引号与向量之间的转换表。用法是：
torch.nn.Embedding(m, n) 其中m 表示单词的总数目，n
表示词嵌入的维度（一个词转成几个特征，常用的维度是256-512），词嵌入相当于将输入的词序列转换成一个矩阵，矩阵的每一行表示一个单词，列为每个单词的多个特征。Embedding也是一层网络，其参数通过训练求得。而词对应的每一维特征的具体值如-1.7123通过这些参数计算得出。</p>
<p>下面例程，将词序列“hello world”转换成矩阵。</p>
<pre><code>from torch import nn  
from torch.autograd import Variable  
  
dic = &#123;&#39;hello&#39;:0, &#39;world&#39;:1&#125; # 词汇与索引号转换字典  
embed = nn.Embedding(2, 3) # 共两个词汇，每个词汇转换成三个特征    
# Embedding的输入是一个LongTensor。  
print(embed(Variable(torch.LongTensor([1])))) # 1为词汇的索引号  
# 输出结果：tensor([[-1.5716, 0.8978, 0.4581]], grad_fn=&lt;EmbeddingBackward&gt;)  
print(embed(Variable(torch.LongTensor([dic[&#39;hello&#39;],dic[&#39;world&#39;]]))))  
# 输出结果：tensor([[-1.7123, -0.6566, -0.6055],  
# [-1.5716, 0.8978, 0.4581]], grad_fn=&lt;EmbeddingBackward&gt;)  </code></pre>
<h3 id="attention">Attention</h3>
<p>注意力Attention指的是一类算法，常见的有local attention，global
attention，self attention等等。</p>
<p>注意力方法最初出现在图像处理问题之中，当人眼观察一幅图像时，某一时刻的视觉焦点只集中在一点上，其注意力是不均衡的，视觉注意力焦点可提高效率和准确性。算法借鉴了人类注意力机制，实现方法是给不同的数据分配不同的权重。</p>
<p>在上述的Seq2Seq模型中，生成目标句子中的单词时，不论生成哪个单词，都根据语义编码C，比如将“I
love you” 翻译成“我爱你”时，“I love
you”三个词对“我”的贡献度都一样，而我们希望“I”对“我”的贡献度更大，于是使用了Attention算法。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-afc801d7ef42828a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>实现Attention的方式有很多种，这里展示比较常用的一种。在Encoder的过程中保留每一步RNN单元的隐藏状态h1……hn，组成编码的状态矩阵Encoder_outputs；在解码过程中，原本是通过上一步的输出y<sub>t-1</sub>和前一个隐藏层h作为输入，现又加入了利用Encoder_outputs计算注意力权重attention_weight的步骤。</p>
<p>用图和文字很难说清楚，看代码更容易，下面分析将Pytorch官方教程Attention模型的核心部分，完整程序见：<br />
<a
href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html">https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html</a><br />
建议读者运行该例程，跟踪每一步的输入和输出，可以尝试修改代码实现中文互译功能。</p>
<p>下面为编码器Encoder的实现部分，编码器包含：词向量转换embedding和循环网络GRU。</p>
<pre><code>class EncoderRNN(nn.Module):  
    # 参数：input_size为输入语言包含的词个数  
    def __init__(self, input_size, hidden_size):  
        super(EncoderRNN, self).__init__()  
        self.hidden_size = hidden_size  
        self.embedding = nn.Embedding(input_size, hidden_size) #每词 hidden_size个属性  
        self.gru = nn.GRU(hidden_size, hidden_size)  
  
    def forward(self,input, hidden):  
        embedded = self.embedding(input).view(1,1,-1)  
        output = embedded  
        output, hidden = self.gru(output, hidden)  
         return output, hidden  
  
    def initHidden(self):  
        return torch.zeros(1,1, self.hidden_size, device=device)  </code></pre>
<p>其中forward每次处理序列中的一个元素（一个词）。</p>
<p>难度较大的是Decoder解码模块，注意力逻辑主要实现在该模块中：</p>
<pre><code>class AttnDecoderRNN(nn.Module):  
    # 参数：output_size为输出语言包含的所有单词数  
    def __init__(self,hidden_size,output_size, dropout_p=0.1, max_length = MAX_LENGTH):  
        super(AttnDecoderRNN, self).__init__()  
        self.hidden_size = hidden_size  
        self.output_size = output_size  
        self.dropout_p = dropout_p  
        self.max_length = max_length  
        self.embedding = nn.Embedding(self.output_size, self.hidden_size)  
        self.attn = nn.Linear(self.hidden_size*2, self.max_length)  
        self.attn_combine = nn.Linear(self.hidden_size*2, self.hidden_size)  
        self.dropout = nn.Dropout(self.dropout_p)  
        self.gru = nn.GRU(self.hidden_size, self.hidden_size)  
        self.out = nn.Linear(self.hidden_size, self.output_size) # 把256个特征转换成输出语言的词汇个数  
  
    # 参数：input每步输入，hidden上一步结果，encoder_outputs编码的状态矩阵  
    # 计算的值是各词出现的概率  
    def forward(self, input, hidden, encoder_outputs):  
        embedded = self.embedding(input).view(1,1,-1)  
        embedded = self.dropout(embedded)  
        attn_weights = F.softmax(  
        self.attn(torch.cat([embedded[0],hidden[0]],1)),dim=1)  
        attn_applied = torch.bmm(attn_weights.unsqueeze(0), # unsqueeze维度增加  
        encoder_outputs.unsqueeze(0))  
        output = torch.cat([embedded[0], attn_applied[0]],1) # 注意力与当前输入拼接  
        output = self.attn_combine(output).unsqueeze(0)  
        output = F.relu(output) # 激活函数  
        output, hidden = self.gru(output, hidden)  
        output = F.log_softmax(self.out(output[0]),dim=1)  
        return output, hidden, attn_weights  
  
    def initHidden(self):  
        return torch.zeros(1,1, self.hidden_size, device=devic  </code></pre>
<p>代码核心是前向传播函数forward，第一个难点是计算attn_weights，先用cat组装输入词向量embedded和隐藏层hidden信息256+256=512，转入全连接层attn，转换后输出10维数据（序列最长10个单词），再用softmax转成和为1的比例值。计算结果是注意力权重attn_weights大小为[1,10]，它描述的是输入encoder中各位置元素对当前decoder输出单词的重要性占比，比如“I
love
you”对“爱”字的重要性分别是[0.2,0.6,0.2]。训练调整attn层参数以实现这一功能。</p>
<p>然后计算attn_applied，用注意力权重attn_weights[1,10]（每个位置的重要性）乘记录encoder每一步状态的矩阵encoder_outputs[10,256]（每个位置的状态）。得到一个综合权重attn_applied[1,256]，用于描述“划了重点”之后的输入序列对当前预测这个单词的影响。得出attn_applied之后，再与词向量embed值组合、转换维度、经过激活函数处理后，和隐藏层一起传入gru循环网络。</p>
<p>最后通过全连接层out把256维特征转换成输出语言对应的单词个数，其中每维度的值描述了生成该词的可能性，再用log_softmax转换成输出要求格式，以便与其误差函数配合使用（后面详细介绍）。</p>
<p>下面是训练部分，每调用一次train训练一个句子。其中传入的encoder和decoder分别是上面定义的EncoderRNN和AttnDecoderRNN，input_tensor和target_tensor是训练的原句和译文。</p>
<pre><code>def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer,  
    decoder_optimizer, criterion, max_length = MAX_LENGTH):  
    encoder_hidden = encoder.initHidden()  
    encoder_optimizer.zero_grad() # 分别优化encoder和decoder  
    decoder_optimizer.zero_grad()  
    input_length = input_tensor.size(0)  
    target_length = target_tensor.size(0)  
    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)  
    loss = 0  
  
    for ei in range(input_length): # 每次传入序列中一个元素  
        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)  
        encoder_outputs[ei]=encoder_output[0,0] # seq_len为1，batch_size为1，大小为 hidden_size  
  
    decoder_input = torch.tensor([[SOS_token]], device=device) # SOS为标记句首  
    decoder_hidden = encoder_hidden # 把编码的最终状态作为解码的初始状态  
  
    for di in range(target_length): # 每次预测一个元素  
        decoder_output, decoder_hidden, decoder_attention = decoder(  
        decoder_input, decoder_hidden, encoder_outputs)  
        topv, topi = decoder_output.topk(1) # 将可能性最大的预测值加入译文序列  
        decoder_input = topi.squeeze().detach()  
        loss+=criterion(decoder_output, target_tensor[di])  
        if decoder_input.item()==EOS_token:  
        break  
  
    loss.backward()  
    encoder_optimizer.step()  
    decoder_optimizer.step()  
    return loss.item() / target_length  </code></pre>
<p>其中第一个循环为Encoder，程序对输入序列中每个元素做encoder，并把每一次返回的中间状态hidden存入encoder_outputs，最终生成保存所有位置状态的矩阵encoder_outputs。</p>
<p>第二个循环为Decoder，程序利用当前的隐藏状态decoder_hidden，解码序列的前一个元素decoder_input，和输入的状态矩阵encoder_outputs做解码，并从解码器的输出中选中最有可能的单词作为后序的输入，直到序列结束。其整体误差是每个元素误差的平均值。</p>
<p>Attention还有很多变型，比如local
attention为了减少计算量，加入了窗口的概念，只对其中一部分位置操作（选一个点，向右左扩展窗口），窗口以外都取0；self
attention将在下篇Transformer中详细介绍。</p>
<h3 id="词向量转换成词">词向量转换成词</h3>
<p>翻译的第一步是将词的索引号转换成词向量，相对的，最后一步将词向量转换成词的索引号，以确定具体的词。Decoder的最后部分实现了该功能，它使用全连接层out进行维度转换，最后使用log_softmax转换成概率的log值。</p>
<p>softmax输出的是概率，整体可能性为1。比如输出的语言只有三个词汇[‘a’,’b’,’c’]，softmax求出它们的可能性分别是[0.1,0.1,0.9]，那么此外最可能是’c’。Log_softmax是对softmax的结果再做log运算，生成对数概率向量。</p>
<p>log函数曲线如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5f39c2c237d06fbe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>由于softmax输出的各个值在0-1之间，梯度太小对反向传播不利，于是log_softmax将0-1映射到负无穷到0之间更宽的区域之中，从而放大了差异。同时，它与损失函数NLLLoss配合使用，NLLLoss的输入是一个对数概率向量和一个目标标签，正好对应最后一层是log_softmax的网络。另外，也可以使用交叉熵作为误差函数：CrossEntropyLoss=log_softmax
+ NLLLoss。</p>
<h3 id="参考">参考</h3>
<p>Seq2Seq论文《Sequence to Sequence Learningwith Neural
Networks》<br />
<a
href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf">https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf</a></p>
<p>Attention论文《Neural machine translation by jointly learning to
align and translate》<br />
<a
href="https://arxiv.org/pdf/1409.0473v2.pdf">https://arxiv.org/pdf/1409.0473v2.pdf</a></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>时序</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer框架</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Pytorch/Transformer%E6%A1%86%E6%9E%B6/</url>
    <content><![CDATA[<p>name_ch: 注意力就是你所需要的<br />
name_en: Attention is All you Need<br />
paper_addr:
https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</p>
<h1 id="transformer框架">Transformer框架</h1>
<p>#Pytorch #时序</p>
<h2 id="读后感">读后感</h2>
<p>应该是本世纪最重要的论文之一，提出Transformer模型，基于注意力机制，避免了递归和卷积，相比之前模型，训练速度快，模型效果好。</p>
<h2 id="摘要">摘要</h2>
<p>Transformer是Google团队在 2017
年提出的自然语言处理（NLP）框架，也是截至目前，最主流的NLP框架。BERT、GPT-2都是基于该模型的变形和扩展。</p>
<p>Transformer的具体算法在论文《Attention Is All You
Need》中描述。论文中展示了该模型的训练准确性高于之前所有模型，训练时间明显低于之前的模型，在训练集内容较少时训练效果也很好。它使用<strong>8个P100的GPU训练12小时即可生成基本翻译模型，其参数规模6.5M</strong>。</p>
<p>Transformer的优势在于：<br />
* 避免了循环网络的前后依赖，可以并行计算，加快了训练速度；<br />
*
同时也解决了长序列中运算量大和长距离的衰减问题，使模型可以处理更长的序列；<br />
* 加入残差网络又让模型可以达到足够的深度，以实现不同层次的抽象。</p>
<p>Transformer框架最核心的改进是在序列处理问题中放弃了循环网络RNN和CNN模型，使用注意力Attention算法计算序列中各个元素之间的关系。Transformer的层次和组件较多，但由于不使用RNN和CNN，单个组件的复杂度低，反而更容易理解，它的主体是全连接网络和Attention算法的堆叠，并使用了Seq2Seq编解码、词向量、位置编码、多头注意力、残差网络、多层叠加子网络等技术。本篇介绍Transformer的具体实现。</p>
<h3 id="引入">引入</h3>
<p>­上篇介绍了<a
href="/1_Note/3_编程/Pytorch/Seq2Seq与Attention">Seq2Seq与Attention</a>的原理及实现代码，相对于普通的循环神经网络，Seq2Seq使用两个循环网络，在翻译问题中，Encoder用于将源语言翻译成语义编码c，Decoder用于将语义编码c生成目标语言。下面是其结构图：其中Embedding用于将词转换成词向量，To
vocab用于翻译之后的词向量转回词汇，并加入了Attention层，用于学习源语言与目标语言间词汇的对应关系。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-f63fae2df50f04c8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>下图是Transformer的结构图，看起来比Seq2Seq复杂很多，其中多头注意力Multi-head
Attention和Pos Forward层还未展开。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-40b3b08db7799823.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>Transformer也用于实现翻译功能，和Seq2Seq一样，也分为Encoder和Decoder两部分，也包括自然语言处理中的词向量转换Embedding和To
vocab。但有几点主要差别：</p>
<ul>
<li>将循环神经网络RNN变为多个子网络叠加layer list。<br />
</li>
<li>用位置信息编码描述序列的前后关系。<br />
</li>
<li>引入自注意力Self-Attention，提取上下文中的相关性。<br />
</li>
<li>引入多头注意力Multi-head Attention算法，从多角度提取特征。</li>
</ul>
<h3 id="位置编码">位置编码</h3>
<p>从ConvS2S模型开始，位置编码被引入模型计算。这样不使用循环网络，也可以描述序列中元素的前后关系。自然语言处理以及任何序列问题都可以采用位置编码描述其位置信息。</p>
<p>位置编码将与词向量值相加，比如一个序列中有五个词，每个词用512维向量表示，词向量[1,5,512]加位置向量[1,5,512]，得到大小为[1,5,512]的结果，这个值包含意义和位置两种信息，也可看成这个词在该位置的含义。</p>
<p>如果位置编码值过大，比如一段文字长度为2048，编码为0,1,...2047，则会削弱词向量的重要性，此时，可使用归一化转换成0,0.0005.....,1；另外，还需要保证不同长度的序列词间距离相等，比如“谁
知道”这两个词在三词序列间的距离需要与它在三百个词的序列中的距离相等。Transformer使用正余弦函数给位置编码，无需训练，直接使用公式算出，其编码如下（完整例程请见参考部分）：</p>
<pre><code>def get_sinusoid_encoding_table(n_position, d_model):  
    def cal_angle(position, hid_idx): # hid_idx为维度索引  
        return position / np.power(10000, 2 * (hid_idx // 2) / d_model) # //为整数除法  
    def get_posi_angle_vec(position): # position为序列中的位置  
        return [cal_angle(position, hid_j) for hid_j in range(d_model)]  
  
    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(n_position)])  
    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2]) # 2i为双数索引位  
    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2]) # 2i+1为单数索引位  
    return torch.FloatTensor(sinusoid_table)  </code></pre>
<p>位置编码函数的输入是序列长度n_position和维数d_model（一般是256或512），输出是大小为
(n_position, d_model)
的矩阵，其中每一行对应一个单词的位置，每个位置由d_model个值表示，类似于词向量用d_model个特征描述一个词的含义。</p>
<p>其公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-b2436f32afe4e0f0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中PE是位置编码Position
Encoding矩阵，双数索引位2i使用sin函数计算，单数索引2i+1使用cos函数计算。</p>
<p>程序中cal_angle函数返回具体弧度值，2 * (hid_idx // 2) / d_model)
结果在 0-1 之间，np.power(10000, 2 * (hid_idx // 2) / d_model) 在
1-10000之间，cal_angle函数的返回结果在0-n_position之间，如序列长度为10时，返回[9,9,8.68...0]。下面左图将长度为10的序列扩展到512维，每个位置对应的弧度值（由cal_angle求得），右图为sin值。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-42954e5b67beaed8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>sin和cos的关系公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-8ba49888fa38523a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>代入PE可得：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-e38907779e4e7877.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>当距离k固定时，PE(pos+k,2i)可表示成PE(pos,2i)和PE(pos,2i+1)的线性组合，PE(pos+k,2i+1)同理。这样即可计算两位置间的距离。</p>
<p>除了正余弦编码，也可以直接嵌入位置信息，二者的训练效果差不多。如BERT的训练集非常丰富庞大，模型就直接使用了嵌入位置信息，而Transformer的基本模型考虑在小训练集的情况下，测试集句子可能比训练集中句子更长的情况，正余弦编码是周期性函数，可以给更长的句子编码。</p>
<h3 id="自注意力">自注意力</h3>
<p>上篇讲到Seq2Seq在解决翻译问题时，引入了注意力Attention机制，建立源序列和目标序列之间词汇的对应关系。</p>
<p>自注意力Self-Attention是一种特殊的注意力机制，它寻找的不是两个句子中词之间的关系，而是单词与本句中其它词之间的关系。如果把它当作黑盒，只关注输入和输出，输入的是包含多个词汇的序列X（x1,x2,x3...），输出可看做每个词在该句中更精确的含义Z(z1,z2,z3...)。比如单看文字“张无忌”是一个人名，如果看完《倚天屠龙记》，张无忌这个名字，则增加了很多特征。每个词的输出向量都包含了句中其它词的信息，词不再是孤立的。</p>
<p>注意力计算公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-b97eea3c610c8561.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>公式中Q为查询向量（当前位置），K为键向量（其它位置），V为值向量（其它位置的值），通过计算Q和K之间的相关性来调整V的贡献度。在自注意力模型中，计算方法如下：</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-ad24ac3ee0481fbe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片出自：https://jalammar.github.io/illustrated-transformer/" />
<figcaption
aria-hidden="true">图片出自：https://jalammar.github.io/illustrated-transformer/</figcaption>
</figure>
<p>自注意力模型中，输入都是同一词序列X，通过与不同的参数W相乘，分别得到Q,K,V矩阵，然后代入公式计算Z。</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-d8c5caa48b3c6a2a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片出自：https://jalammar.github.io/illustrated-transformer/" />
<figcaption
aria-hidden="true">图片出自：https://jalammar.github.io/illustrated-transformer/</figcaption>
</figure>
<p>例如翻译“Thinking Machines”，将词转为词向量x1,
x2，分别乘参数矩阵，得到q1,q2,k1,k2,v1,v2（基础模型将512维的x1转成64维的q1,
64维的k1和64维的v1）；在计算第一个词“Thinking”时，用第一个查询向量q1分别点乘各个位置的键向量k1,
k2得到112和96，然后除以k维度的开平方值（64开方得8，除该值的目的是避免结果过大，使得计算softmax后距离太小）得到14和12；做softmax归一化，得到两个位置的重要性分别是0.88和0.12，再分别用重要性乘以值向量v1,v2，最后通过累加sum得到描述“Thinking”的新向量z1。其中的各个参数矩阵W都通过训练获得。</p>
<p>以上是计算自注意力的方法，上述逻辑也可用于计算翻译中源序列与目标序列中词的关系（Enc-Attention)，不同的是与Q,K,V相乘的不再是序列X，而是dec_outputs,
enc_outputs,
enc_outputs，计算当前解码信息dec_ouputs（Q）与编码信息各个位置enc_outputs（K）之间的关系，加权调整编码信息enc_outputs（V），这也是上一篇看Attention的原理。具体代码见多头注意力部分。</p>
<p>从论文题目可以看出，Transformer的核心是Attention算法，它用注意力模型取代了RNN和CNN，从而减少了计算量，尤其在处理长距离的关系中有明显优势。比如：“在张三盗刷信用卡三十天之后，警察逮捕了他”。这里的“他”指代“张三”，但其中间隔多个词，在RNN中要计算它们的关系需要回退很多步，CNN每次也只能计算相邻的几个元素，也需要多层抽象，才能建立两词间的关系。而Self-Attention计算“他”与句中每个词的关系，计算二者相关性只需要一步。</p>
<p>当序列很长时，计算各词与句中其它成份的关系，运算量也不小，此时可以使用局部自注意力，即只计算某词与其前后N个词之间的关系。</p>
<h3 id="多头注意力">多头注意力</h3>
<p>Multi-head
Attiotion是多头注意力模型，即对同一个词向量序列，同时做多次Attention，比如做8组Attention运算，每一组都有不同的W<sup>Q</sup>,W<sup>K</sup>,W<sup>V</sup>矩阵，各个W随机初始化，通过训练调整。多头的目的是形成多个子空间，让模型去关注不同方面的信息。其公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-215a80b6c110b617.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>建立多组参数矩阵W，用每组W分别计算Attention­，得到多个head输出，再用concat把多个输出连接到一起，最后乘输出参数W<sup>o</sup>，得到MultiHead值。</p>
<p>多头注意力模型核心代码如下：</p>
<pre><code>class ScaledDotProductAttention(nn.Module): # 点乘  
    def __init__(self):  
        super(ScaledDotProductAttention, self).__init__()  
  
    def forward(self, Q, K, V, attn_mask): # 实现注意力公式  
        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)  
        scores.masked_fill_(attn_mask, -1e9)  
        attn = nn.Softmax(dim=-1)(scores)  
        context = torch.matmul(attn, V)  
        return context, attn  
  
class MultiHeadAttention(nn.Module): # 多头注意力  
    def __init__(self):  
        super(MultiHeadAttention, self).__init__()  
        self.W_Q = nn.Linear(d_model, d_k * n_heads)  
        self.W_K = nn.Linear(d_model, d_k * n_heads)  
        self.W_V = nn.Linear(d_model, d_v * n_heads)  
     
    def forward(self, Q, K, V, attn_mask):  
        residual, batch_size = Q, Q.size(0)  
        q_s = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)  
        k_s = self.W_K(K).view(batch_size, -1, n_heads, d_k).transpose(1,2)  
        v_s = self.W_V(V).view(batch_size, -1, n_heads, d_v).transpose(1,2)  
        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)  
        context, attn = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)  
        context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * d_v)  
        output = nn.Linear(n_heads * d_v, d_model)(context)  
        return nn.LayerNorm(d_model)(output + residual), attn  </code></pre>
<p>程序中还加入了残差Residual和归一化处理LayerNorm。</p>
<p>在Encoder部分，自注意力将计算每个词与其它所有词的关系；在Decoder部分，尤其是在预测过程中，如要翻译出“我爱你”，翻译到“爱”时，“你”还没产生，因此，只能参考当前位置之前的词（已经生成的词）。attn_mask用于实现该功能，具体方法是使用上三角矩阵遮蔽部分数据。</p>
<h3 id="前向传播网络">前向传播网络</h3>
<p>完成Attention之后，再使用Pos-wise Feed
Forward做前向传播，Transformer论文中介绍前向传播可以使用两个卷积层，或者两个全连接层（卷积核大小为1时，卷积与全连接效果相同），两层之间加一个ReLU激活函数，将小于0的值都置为0，其公式为：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-98062448176616bc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>代码实现如下：</p>
<pre><code>class PoswiseFeedForwardNet(nn.Module):  
    def __init__(self):  
        super(PoswiseFeedForwardNet, self).__init__()  
        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)  
        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)  
  
    def forward(self, inputs):  
        residual = inputs # inputs : [batch_size, len_q, d_model]  
        output = nn.ReLU()(self.conv1(inputs.transpose(1, 2)))  
        output = self.conv2(output).transpose(1, 2)  
        return nn.LayerNorm(d_model)(output + residual)  </code></pre>
<p>除了两个卷积层，模型还加入了残差redidual和归一化处理LayerNorm。</p>
<h3 id="多子层组合">多子层组合</h3>
<p>Transformer分为Encoder和Decoder两部分，
Encoder中又包含六个子模块Encoder Layer，每个Encoder
Layer（图中左侧展开）中都包含多头自注意力模型Self
Attention和前向传播Feed Forward两部分；Decoder中也包含六个子模块Decoder
Layer，每个Decoder
Layer（图中右侧展开）中又包含计算自身关系信息的自注意力模型Self
Attention，计算Decoder与Encoder相关性的注意力模型Enc
Attention，以及前向传播Feed Forward三部分。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-627211ad4ddd2306.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>训练时源语言序列通过词向量转换Word
Embedding后，再加上位置信息Position Embedding，转入六层Encoder
layer，编码后将中间状态，连同之前预测的目标序列传入六层解码Decoder
layer，最终结果经过一个全连接层转换后，再做softmax生成词概率。</p>
<p>图中间的黑色箭头是编码输出的encode_output，它不仅作为隐藏层传入Decoder模型，还用于计算Encoder和Decoder之间的注意力关系。另外，在每一个Attention和Feed
Forward后都加入了残差和归一化处理，这一操作保证了框架在多层堆叠后仍能正常工作。完整例程请见参考部分（代码共200多行）。</p>
<p>大量的论文表明，Transformer中下层更偏向于关注语法，上层更偏向于关注语义。</p>
<h3 id="参考">参考</h3>
<ul>
<li><p>Transformer论文：《Attention Is All You Need》<br />
<a
href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a></p></li>
<li><p>完整例程<br />
<a
href="https://github.com/graykode/nlp-tutorial/blob/master/5-1.Transformer/Transformer-Torch.py">https://github.com/graykode/nlp-tutorial/blob/master/5-1.Transformer/Transformer-Torch.py</a></p></li>
</ul>
]]></content>
      <tags>
        <tag>模型结构</tag>
      </tags>
  </entry>
  <entry>
    <title>从c++到java(一)</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%85%B6%E5%AE%83%E7%BC%96%E7%A8%8B/%E4%BB%8Ec++%E5%88%B0java(%E4%B8%80)/</url>
    <content><![CDATA[<h1 id="从c到java-一">从c++到java (一)</h1>
<p>#编程语言 #C #Java</p>
<p>学习 JAVA 编程（一）</p>
<p>一、 目的<br />
由于之前都用 C/C++ 写程序，现在改用 JAVA 写 android<br />
程序，有些相关的认识和积累，记录下来，自已保存资料，也供大家参考，帮助您在和我遇到同样问题的时候，可以快速解决。<br />
我遇到的问题基本分以下几类：</p>
<p>1. 不了解程序的流程：编译，执行，如何代码组织</p>
<p>2. 看不懂别人写的程序：重要的关键字不认识</p>
<p>3. JAVA 的特性和习惯用法：不明白什么意思</p>
<p>4. 某些功能不知如何实现：找不到 JAVA 对应的语法</p>
<p>二、 流程</p>
<p>1. 组织代码</p>
<ol type="1">
<li><p>以类组织<br />
整个 JAVA
语言建立在类的逻辑结构上，任何想法都必须封装在类中，也就是说不允许函数，变量定义在类以外。</p></li>
<li><p>程序入口<br />
既然所有函数都必须封装在类中，主函数（ main ）也不例外，
哪个类是入口，就把 main 放在该类里边。对其它类和方法的调用可以写在<br />
main 中，形如：<br />
** public class HelloWorld {<br />
public static void main(String args[]) {<br />
System.out.println("Hello World!");<br />
}<br />
} **</p></li>
<li><p>文件类型</p></li>
</ol>
<ol type="a">
<li><p>*.java<br />
源程序代码文件<br />
一般一个类写在一个 .java 文件中，也可以把两个类写在一个 java
文件中，编译出来成两个 .class<br />
public 的类因于供他人调，所以要单写一个 java
文件，文件的名字和类名一致</p></li>
<li><p>*.class<br />
编译后生成的字节码文件</p></li>
<li><p>*.jar<br />
JAVA 程序的打包文件（类似 ZIP 包，可用 WINRAR 等工具打开）</p></li>
</ol>
<p>2. 编译<br />
编译单个文件<br />
** $ javac xxx.java<br />
** 编译多个文件 **<br />
$ javac *.java<br />
** 注意 xxx 要和类名统一，此时当前目录下生成 xxx.class 文件</p>
<p>3. 执行</p>
<ol type="1">
<li><p>运行 xxx.class<br />
** $ java xxx **<br />
注意不加扩展名</p></li>
<li><p>运行 xxx.jar<br />
** $java -classpath xxx.jar packagename.classname<br />
** 解压缩 xxx.jar, 其中的目录是 package, 其中的文件是 class<br />
xxx.jar 通常是由工具生成的，含有一些字节码文件和信息文件</p></li>
</ol>
<p>三、 关键字</p>
<p>1. this 与 super</p>
<ol type="1">
<li><p>this 指当前对象， super 指它的父类</p></li>
<li><p>super 用法</p></li>
</ol>
<ol type="a">
<li><p>放在构造的头一句，调用它父类的构造函数（注意只能放在头一句）</p></li>
<li><p>super.func(xxx) 是调父类的一个函数，通常用于本类中重写（ override
）了父类的函数，用此方法调用其父类中的该函数</p></li>
</ol>
<p>2. try, cache, finally</p>
<ol type="1">
<li><p>try ：把可能出错的代码放在 try {} 里，有些代码加了 try
就可以编译通过了</p></li>
<li><p>cache ：把错误处理放在 catch (xxx) {} 中， 可有多个 catch
同时存在 ， 过不同参数指定不同错误的处理</p></li>
<li><p>finally ：无论发没发生意外， finally{} 都被执行，它用来释放 try
申请的资源（如操作数据库时）</p></li>
</ol>
<p>3. abstract class （抽象类）与 instance class （具体类）</p>
<ol type="1">
<li><p>instance class 可以实例化， abstract class 不能实例化</p></li>
<li><p>abstract class 里边抽象的方法用 public abstract func();
它定义了方法，但没有实现，就是 C++<br />
里的纯虚函数</p></li>
</ol>
<p>4. abstract class 与 interface</p>
<ol type="1">
<li><p>它们都用于实现多样性（ Polymorphism
），即继承它的类实现各有不同</p></li>
<li><p>interface 可以虚拟多重继承而 abstract class 不能</p></li>
<li><p>abstract class 可以有自己的数据成员，也可以有非 abstract
的成员方法，而 interface<br />
方式实现中，只能有静态的不能被修改的数据成员（ static final
），所有的成员方法都是 abstract 的</p></li>
<li><p>本质不同： abstract 的父子类间本质相同，而 interface
只是定义了某个方法约定或者说是性质</p></li>
</ol>
<p>5. extends 与 implements</p>
<ol type="1">
<li><p>extends ：继承父类，只要那个类不是声明为 final 或者那个类定义为
abstract 的就能继承</p></li>
<li><p>implements ： JAVA 中不支持多重继承，但是可以用 interface
来实现，这样就要用到 implements<br />
，继承只能继承一个类，但 implements
可以实现多个接口，用逗号分开就行了，形 如：<br />
** class A extends B implements C,D,E **</p></li>
<li><p>extends 用在类名和接口名前<br />
implements 用在接口名前</p></li>
</ol>
<p>6. throw 与 throws</p>
<ol type="1">
<li><p>它们 java 处理异常方式</p></li>
<li><p>throw 用在 try 后面</p></li>
<li><p>throws 用在一个方法后面</p></li>
</ol>
<p>7. final</p>
<ol type="1">
<li><p>用于修饰非抽象类，非抽象方法和变量</p></li>
<li><p>final 类：不能被继承， final 类的方法默认是 final 的</p></li>
<li><p>final
方法：不能被子类方法覆盖，可以被继承，编译时被转入内嵌机制，提高执行效率</p></li>
<li><p>final 变量：只能被赋值一次，之后不能再改变<br />
通常用 static final 声明常量，注意常量一般用大写</p></li>
</ol>
<p>8. static</p>
<ol type="1">
<li><p>用于修饰成员变量和成员方法</p></li>
<li><p>static
变量和方法独立于该类的任何对象，被类的所有实例共享，所以不需要声明任何对象就可以访问，形如：<br />
** 类名 ** ** . ** ** 静态方法名（参数列表） ** **<br />
** ** 类名 ** ** . ** ** 静态变量名 **</p></li>
<li><p>注意静态方法不能用 this 和 super 关键字</p></li>
<li><p>static 方法必须被实现，不能是抽象的</p></li>
</ol>
<p>9. layout<br />
layout ：设置容器中的排布方式<br />
FlowLayout 按添加的顺序从左到右从上到下排布<br />
BorderLayout 按东西南北中设定位置<br />
GridLayout 网格布局<br />
BoxLayout 使需要空间的组件得到最大尺寸</p>
]]></content>
      <tags>
        <tag>Java</tag>
        <tag>编程语言</tag>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title>从c++到java(二)</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%85%B6%E5%AE%83%E7%BC%96%E7%A8%8B/%E4%BB%8Ec++%E5%88%B0java(%E4%BA%8C)/</url>
    <content><![CDATA[<h1 id="从c到java-二">从c++到java (二)</h1>
<p>#编程语言 #C #Java</p>
<p>学习 JAVA 编程（二）</p>
<p>一、 JAVA 特性和习惯用法</p>
<p>1. 指针<br />
JAVA 中没有指针，用以下方法使用<br />
** Test a = new Test(); a.t(); **</p>
<p>2. 地址传递和值传递<br />
原始类型是值传递<br />
对象 （非原始）类型是地址传递</p>
<p>3. 手动回收资源<br />
一般情况下，只要 new
，系统会自动释放，但更严谨地做法是手动回收，如下：<br />
** Employee e1 = new Employee( "Susan", "Baker" );<br />
……<br />
** ** e1 = null;<br />
System.gc(); // garbage collection **<br />
此时析构函数 protected void finalize() 会被调用</p>
<p>4. 内嵌类（一个类中声明另一个类）</p>
<ol type="1">
<li><p>内嵌类可以放在类中的任意一个位置，程序都可以找到它</p></li>
<li><p>内嵌类的好处<br />
内嵌类可以使用所属类的私有变量和方法<br />
内嵌类的作用域只在所属类内部，其它类是不可见的，从而减少混乱<br />
节约资源</p></li>
</ol>
<p>5. 匿名内嵌类 ( anonymouse inner class)</p>
<ol type="1">
<li><p>没有具体名字的内嵌类，因为只使用一次，所有一般不命名</p></li>
<li><p>写法<br />
** fancyButton.addActionListener<br />
(<br />
new ActionListener() // ActionListener ** ** 是一个 interface,
含一个方法<br />
{// anonymous inner class<br />
public void actionPerformed( ActionEvent event )<br />
{<br />
JOptionPane.showMessageDialog( null,<br />
"You pressed: " + event.getActionCommand() );<br />
}<br />
}<br />
);<br />
** 它返回的是一个实例，只处理从这个 handler 来的信息</p></li>
<li><p>运行时生成内嵌类的 class 文件，形如<br />
xxx$1.class</p></li>
</ol>
<p>6. 事件处理</p>
<ol type="1">
<li><p>引入 java.awt ：事件处理包</p></li>
<li><p>需要设置 listener 和 handler</p></li>
<li><p>任何一个对象都可以被监听（ addListener ） , 当它 listen
的事件发生时就调 add 时指定的 handler<br />
处理</p></li>
</ol>
<p>7. 多线程</p>
<ol type="1">
<li><p>继承 Thead 类</p></li>
<li><p>关键的方法<br />
start() ， sleep() ， destroy() ， resume() ， stop() ，
getName()</p></li>
<li><p>线程执行优先级 1-10</p></li>
<li><p>在外部使用它<br />
PrintThread thread1 = new PrintThread( "thread1" );<br />
thread1.start(); // 此时进入 ready 状态，等待资源</p></li>
</ol>
<p>8. 界面</p>
<ol type="1">
<li><p>引入 java.swing ； JFC （用于在 java 中开发界面）</p></li>
<li><p>由于基类原因，控件即可以 draw 也可以做为 contrainer</p></li>
</ol>
<p>二、 JAVA 对应语法</p>
<p>1. 类的引入</p>
<ol type="1">
<li><p>在某一类（文件）中想使用其它类时（如同 C
语言中的包含头文件）</p></li>
<li><p>使用 import 关键字，形如<br />
** import java.io.* **</p></li>
</ol>
<p>2. 工具函数的写法<br />
C++ 中有些工具函数，可能被多处调用，本身又不属于某个类，在 JAVA 中可以
专写一个 Utility.java ，里边的函数都是<br />
static 的，直接用里边的函数，不用实例化</p>
<p>3. 枚举</p>
<p>近似类的写法，形如：<br />
** public enum FolderType {<br />
HOLDS_FILDERS, HOLDS_MESSAGES<br />
}<br />
FolderType.HOLDS_FILDERS **</p>
<p>4. 宏定义<br />
在 类中<br />
** public static final int IOERROR = 1; **</p>
<p>5. ifdef<br />
没有 ifdef
类似的功能可以使用，只能用常量或变量的判断来选择执行代码的不同部分</p>
]]></content>
      <tags>
        <tag>Java</tag>
        <tag>编程语言</tag>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title>修改上传文件按钮的风格</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%85%B6%E5%AE%83%E7%BC%96%E7%A8%8B/%E4%BF%AE%E6%94%B9%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E6%8C%89%E9%92%AE%E7%9A%84%E9%A3%8E%E6%A0%BC/</url>
    <content><![CDATA[<h1 id="修改上传文件按钮的风格">修改上传文件按钮的风格</h1>
<p>#网站</p>
<p>一段HTML代码，目标是显示bootstrap风络的上传按钮（不带路径显示），且点击后无需再点submit按钮，直接发post请求。</p>
<p><img
src="https://img-blog.csdnimg.cn/20190119165910888.png?x-oss-%20process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpZXlhbjA4MTE=,size_16,color_FFFFFF,t_70" /></p>
<pre><code>&lt;!DOCTYPE html&gt;  
&lt;html&gt;  
    &lt;head&gt;  
        &lt;link href=&quot;bootstrap.css&quot; rel=&quot;stylesheet&quot; media=&quot;screen&quot;&gt;  
        &lt;style&gt;  
            .fileinput-button &#123;  
                position: relative;  
                display: inline-block;  
                overflow: hidden;  
            &#125;  
            .fileinput-button input&#123;  
                position:absolute;  
                right: 0px;  
                top: 0px;  
                opacity: 0;  
                -ms-filter: &#39;alpha(opacity=0)&#39;;  
                font-size: 200px;  
            &#125;  
        &lt;/style&gt;  
    &lt;/head&gt;  
  
    &lt;body&gt;  
        &lt;div class=&quot;container&quot;&gt;  
            &lt;nav class=&quot;navbar navbar-default navbar-fixed-center&quot; role=&quot;navigation&quot; style=&quot;padding:5px;&quot;&gt;  
                &lt;form action=&quot;/upload&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt;  
                    &lt;span class=&quot;btn btn-primary fileinput-button&quot;&gt;  
                        &lt;span&gt;Upload&lt;/span&gt;  
                        &lt;input type=&quot;file&quot; accept=&quot;.xls, .xlsx, .csv&quot; id=&quot;inputBtn&quot; value=&quot;上传&quot;/&gt;  
                    &lt;/span&gt;  
                &lt;/form&gt;  
            &lt;/div&gt;  
            &lt;/nav&gt;  
        &lt;/div&gt;  
  
        &lt;script type=&quot;text/javascript&quot; src=&quot;jquery.js&quot; charset=&quot;UTF-8&quot;&gt;&lt;/script&gt;  
        &lt;script type=&quot;text/javascript&quot; src=&quot;bootstrap.min.js&quot;&gt;&lt;/script&gt;  
  
        &lt;script&gt;  
            $(&quot;#inputBtn&quot;).change(function(event) &#123;  
                    file = event.target.files[0];  
                    var formData = new FormData();  
                    formData.append(&quot;fileUpload&quot; , file);       
                    $.ajax(&#123;  
                        url : &quot;upload&quot;,  
                        datatype : &quot;json&quot;,  
                        type : &quot;post&quot;,  
                        data: formData ,  
                        processData : false,  
                        contentType : false,  
                        success:function(result)&#123;  
                            alert(result)  
                        &#125;  
                &#125;);  
            &#125;)  
        &lt;/script&gt;  
  
    &lt;/body&gt;  
&lt;/html&gt;  
  </code></pre>
<p>注意需要把支持bootstrap的几个css的js文件复制到同一目录下，同时提供upload程序接收文件，并反馈显示信息。</p>
]]></content>
      <tags>
        <tag>网站</tag>
      </tags>
  </entry>
  <entry>
    <title>建站之一：平台选择和环境搭建（SAE）</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%85%B6%E5%AE%83%E7%BC%96%E7%A8%8B/%E5%BB%BA%E7%AB%99%E4%B9%8B%E4%B8%80%EF%BC%9A%E5%B9%B3%E5%8F%B0%E9%80%89%E6%8B%A9%E5%92%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%EF%BC%88SAE%EF%BC%89/</url>
    <content><![CDATA[<h1
id="建站之一平台选择和环境搭建sae">建站之一：平台选择和环境搭建（SAE）</h1>
<p>#网站</p>
<p>一、为什么选择SAE建站</p>
<p>1. CS/BS架构的选择</p>
<ol type="1">
<li><p>CS（Client/Server）的服务器端通常都是由程序实现服务，并且一直在后台运行，客户端是一个程序。</p></li>
<li><p>BS（Browser/Server）的服务器端是Web服务器在后台运行（如apache），只需要写一些程序（如PHP）被Web服务器调用即可，而客户端可以是浏览器也可以是程序。</p></li>
<li><p>就实现而言，无论协议的设计，编码，还是调试，BS都相对简单。</p></li>
</ol>
<p>2. GAE与SAE的选择<br />
SAE（Sina App Engine）是新浪开发的 用于 WEB
应用程序的开发和托管的平台<br />
，它提供了Web服务器，存储空间，数据库，负载均衡，数据备份等等，开发者只需要实现应用相关编码即可使用。<br />
GAE（Google App Engine）是谷歌开发的WEB应用程序开发和托管的平台。<br />
GAE和SAE各有优势，考虑到主要面对国内用户，而GAE时常被封，无法保证稳定性，故选择SAE（参考《GAE与SAE对比》）</p>
<p>3. 费用<br />
SAE以云豆计费，对流量，CPU时间，存储空间等进行计费，只需对使用的资源付费。注册，手机认证，实名认证，开发者认证都可获得一定数量的云豆赠送，前期访问量少时，基本无需费用，后期可申请开发者认证，以争取更多的云豆赠送，来减免一些费用（赠送规则，计费说明参考《SAE文档中心》）</p>
<p>4. 编程语言的选择</p>
<p>SAE现支持PHP，JAVA，PYTHON，而JAVA，PYTHON还在测试阶段，且PHP实现比较简单，故推荐PHP</p>
<p>5. 建站注意事项<br />
鉴于平台收费的变化，应尽量加强程序的可移植性，以免被某些平台牵制。</p>
<ol type="1">
<li><p>使用更为公共的接口, 尽量少用平台自身的API</p></li>
<li><p>实现数据库的导入/导出及备份</p></li>
<li><p>准备程序及数据的备份和迁移方案</p></li>
<li><p>尽量使用域名</p></li>
</ol>
<p>二、实例</p>
<p>1. 创建一个web类型的应用</p>
<p>2. 使用SVN工具将代码上传到服务器（以Linux系统为例）<br />
$ sudo apt-get install subversion<br />
$ mkdir svnclient<br />
$ cd svnclient<br />
$ svn co https://svn.sinaapp.com/xxxxxx<br />
输入用户名是注册邮箱，密码是sae密码，并非weibo密码<br />
编辑index.php<br />
$ svn diff<br />
$ svn commit -m "desc"</p>
<p>三、其它</p>
<p>1. 数据存储<br />
大的数据和图片放在storage上，程序相关的可以放在svn代码目录下，代码目录不允许IO操作以防止用户写入数据，利用”saestor://“在storage中进行读写操作，更加安全</p>
<p>2.
SAE应用页面，点左侧的服务管理，MYSQL，按“点击初始化MYSQL”按钮，即可以看到数据库的相关信息（IP，端口，用户名，密码等）和权限</p>
<p>3. SAE创建博客类网站<br />
建议使用SAE+WordPress</p>
<p>4. 如果创建应用时选择类型错误，如何修改？<br />
SAE应用界面，左侧点应用设置，修改类型，更新应用信息<br />
SAE应用界面，左侧点代码管理，创建一个新版本，然后将新版本设置为默认版本，最后删除之前错误的版本（默认版本不能删除）</p>
<p>5. 如何数据库</p>
<p>在SAE中开启MYSQL</p>
<p>四、参考</p>
<p>1. GAE与SAE对比<br />
<a
href="http://www.laokboke.net/2011/10/23/gae-vs-sae/">http://www.laokboke.net/2011/10/23/gae-vs-sae/<br />
</a></p>
<p>2. SAE文档中心<br />
<a
href="http://sae.sina.com.cn/?m=devcenter">http://sae.sina.com.cn/?m=devcenter</a></p>
<p>3. 如何申请SAE中级开发者认证（用以免费获得云豆）<br />
<a
href="http://sae.sina.com.cn/?m=devcenter&amp;catId=243">http://sae.sina.com.cn/?m=devcenter&amp;catId=243<br />
</a><br />
<a
href="http://ben-lab.com/tech/1586.html">http://ben-lab.com/tech/1586.html</a></p>
<p>4. SAE+JSon的实现<br />
<a
href="http://code.google.com/p/bjgs/">http://code.google.com/p/bjgs/</a></p>
<p>5. 作者实现的网站<br />
<a
href="http://oatmental123.sinaapp.com/">http://oatmental123.sinaapp.com</a></p>
]]></content>
      <tags>
        <tag>网站</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>建站之三：PHP网页实现</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%85%B6%E5%AE%83%E7%BC%96%E7%A8%8B/%E5%BB%BA%E7%AB%99%E4%B9%8B%E4%B8%89%EF%BC%9APHP%E7%BD%91%E9%A1%B5%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="建站之三php网页实现">建站之三：PHP网页实现</h1>
<p>#网站</p>
<p>一、相关概念</p>
<p>1. Php与Html关系<br />
Html : 前端、静态、客户端执行<br />
Php : 后端、动态、服务器执行<br />
Html可以包含Php，Php可以生成html</p>
<p>2. Php与Javascript关系<br />
Php是服务器端脚本，Javascript是客户端脚本，功能不同，可以配合使用<br />
如在Form中button的onclick可以调Javascript函数，但不能调php函数<br />
而Javascript不能处理服务器端数据</p>
<p>3. 网页术语<br />
Css：控制网页内容如何显示<br />
Div：Div标签用于定义一个区域的显示方式（如背景，字体，对齐方式等）<br />
Style：Style标签用来设置css格式表<br />
Meta：Meta标签包含一些网页的隐藏信息</p>
<p>二、网页实现</p>
<p>1. 建议使用DreamWeaver设计网页，然后再手动编辑</p>
<p>设置页面属性（背景，屏幕宽度，链接显示等），加入文字图片等</p>
<p>一般网站，需要设计页头，页脚（可单写文件，被多个页网包含）</p>
<p>2. 网页适应浏览器分析率<br />
用百分比设置宽度：width:100%<br />
设置最大宽度：max-width:800px</p>
3. 网页适应Android手机分辨率（不影响电脑浏览器效果）<br />
设置手机默认屏宽为320<br />

<head>
<meta name="viewport"content="width=320"/>
</head>
4. 如何解决中文乱码问题？<br />
乱码可能是由于浏览器未能识别HTML中的中文字符集造成的，需要在开头指定字符集，加入<br />
<?php header('Content-Type: text/html; charset=UTF-8'); ?><br />
或者<br />

<META HTTP-EQUIV="Content-Type"CONTENT="text/html; charset=UTF8">
<p>5. 如何在退回上一页时，记住上一页表单中之前的选择？<br />
在上一页开头加入<br />
header('Cache-control: private, must-revalidate'); ?&gt;</p>
6. 返回上一页按钮的实现<br />
echo "
<form action method="post">
";<br />
echo
"<input type='Button' value='回前一页' οnclick='history.go( -1 );return  
true;'>";<br />
echo"
</form>
<p>";</p>
<p>三、PHP实现</p>
<p>1. PHP的基本语法：类似C语言</p>
<p>2. PHP的注释：与C语言一样用//，/<em>，</em>/</p>
<p>3. PHP的调试：一般用echo，print_r()调试</p>
<p>4.
PHP单引号和双引号的区别：双引号中的经过解释输出，单引号中的直接输出</p>
<p>5. PHP中函数的定义<br />
function sum($a, $b) {<br />
$c = $a + $b;<br />
return $c;<br />
}<br />
返回值支持各种类型</p>
<p>6. 传递参数：使用GET方式传参</p>
<ol type="1">
<li><p>调用端<br />
echo "</p>
<form action="loadquestion.php?test=xxxxx" method="post">
<p>";<br />
echo "<input type='submit' value='按钮'/>";<br />
echo "</p>
</form>
<p>";</p></li>
<li><p>接收端<br />
<span class="math inline">\(value=\)</span>_GET["test"];<br />
即可得到xxxxx</p></li>
</ol>
<p>7. 如何回车<br />
网页中的回车”<br/>”<br />
Html代码中回车是“”</p>
<p>8. 为什么有时候empty函数不能判断空值<br />
值为空或为零时empty函数都返回真</p>
<p>四、调试注意事项</p>
<p>1. Android手机调试<br />
最好在Android自带浏览器中调试，UC浏览器会记住用户缩放比例，可能导致歧义</p>
<p>2. 电脑调试<br />
最好用IE6调试，旧浏览器能支持的，新浏览器一般都没问题（有些参数IE6不识别，有的PNG图片不透明）</p>
<p>五、参考</p>
<p>1. Html之表单<br />
<a
href="http://www.sj33.cn/jc/wyjc/htjc/200612/10726_2.html">http://www.sj33.cn/jc/wyjc/htjc/200612/10726_2.html<br />
</a></p>
<p>2. 常用的表单中的button链接<br />
<a
href="http://www.cnblogs.com/infim/archive/2010/08/23/1806400.html">http://www.cnblogs.com/infim/archive/2010/08/23/1806400.html<br />
</a></p>
<p>3. Php操作Mysql数据库<br />
<a
href="http://www.189works.com/article-49493-1.html">http://www.189works.com/article-49493-1.html<br />
</a><br />
<a
href="http://www.jb51.net/article/14668.htm">http://www.jb51.net/article/14668.htm<br />
</a></p>
<p>4. Php解析Xml<br />
<a
href="http://www.php100.com/html/webkaifa/PHP/PHPyingyong/2012/0110/9638.html">http://www.php100.com/html/webkaifa/PHP/PHPyingyong/2012/0110/9638.html<br />
</a></p>
<p>5. Android屏幕适配<br />
<a
href="http://mobile.51cto.com/web-316935.htm">http://mobile.51cto.com/web-316935.htm<br />
</a></p>
<p>6. 作者实现的网站<br />
<a
href="http://oatmental123.sinaapp.com/">http://oatmental123.sinaapp.com</a></p>
]]></content>
      <tags>
        <tag>网站</tag>
      </tags>
  </entry>
  <entry>
    <title>建站之二：本地调试环境LAMP的搭建</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%85%B6%E5%AE%83%E7%BC%96%E7%A8%8B/%E5%BB%BA%E7%AB%99%E4%B9%8B%E4%BA%8C%EF%BC%9A%E6%9C%AC%E5%9C%B0%E8%B0%83%E8%AF%95%E7%8E%AF%E5%A2%83LAMP%E7%9A%84%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<h1
id="建站之二本地调试环境lamp的搭建">建站之二：本地调试环境LAMP的搭建</h1>
<p>#Linux #数据库</p>
<p>一、说明</p>
<p>用SAE建站时需要调试，总不能改一下，上传一下SVN，在Ubuntu中仅安装几个软件，进行简单配置即可建立本地调试环境，即LAMP（Linux+Apache+Mysql+Php）</p>
<p>二、实现</p>
<p>1. 安装Web服务器Apache<br />
$ sudo apt-get install apache2<br />
安装后在浏览器中打开http://localhost/或者http://127.0.0.1<br />
如正常显示It works!，则说明Web服务器已正常运行</p>
<p>2. 安装Php解释器对应的apache工具<br />
$ sudo apt-get install php5<br />
$ sudo apt-get install libapache2-mod-php5<br />
重启apache<br />
$ sudo /etc/init.d/apache2 restart<br />
测试php是否正常<br />
$ vi /var/www/testphp.php<br />
编辑内容如下<br />
<?php echo'<strong>Testme!</strong>'; ?&gt;<br />
在浏览器中打开<br />
<a
href="http://127.0.0.1/testphp.php">http://127.0.0.1/testphp.php</a><br />
如正常显示Testme!，则说明Php与Apache配合正常</p>
<p>3. 安装mysql数据库及相应工具<br />
$ sudo apt-get install mysql-server<br />
$ sudo apt-get install libapache2-mod-auth-mysql<br />
$ sudo apt-get install php5-mysql<br />
重启apache服务<br />
$ sudo/etc/init.d/apache2 restart<br />
测试mysql是否正常<br />
$ vi /var/www/testphp.php<br />
编辑内容如下<br />
<?php    
$link=mysql_connect("localhost","root","安装mysql时设置的密码");    
if(!$link) echo "connectfailed";    
else echo "connectsuccess";    
?><br />
如正常显示connectsuccess，则说明Php，Mysql，Apache配合正常</p>
<p>4. 注意<br />
测试时注意文件权限</p>
<p>三、参考<br />
<a
href="http://www.linuxidc.com/Linux/2010-07/27230.htm">http://www.linuxidc.com/Linux/2010-07/27230.htm<br />
</a></p>
]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>支持3D动效的窗口管理器——Mutter</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%85%B6%E5%AE%83%E7%BC%96%E7%A8%8B/%E6%94%AF%E6%8C%813D%E5%8A%A8%E6%95%88%E7%9A%84%E7%AA%97%E5%8F%A3%E7%AE%A1%E7%90%86%E5%99%A8%E2%80%94%E2%80%94Mutter/</url>
    <content><![CDATA[<h1
id="支持3d动效的窗口管理器mutter">支持3D动效的窗口管理器——Mutter</h1>
<p>#图形图像</p>
<p>一、 什么是 mutter<br />
mutter 是 metacity 窗口管理器的支持 3D 动画效果的分支，它的动画由
clutter 库实现。</p>
<p>二、 下载和安装</p>
<p>1. 下载： <a
href="http://ftp.acc.umu.se/pub/GNOME/sources/mutter/2.27/">http://ftp.acc.umu.se/pub/GNOME/sources/mutter/2.27/<br />
</a><br />
mutter-2.27.1.tar.bz2</p>
<p>2. 安装<br />
$ tar xvjf mutter-2.27.1.tar.bz2<br />
$ ./configure --without-introspection<br />
$ make install</p>
<p>三、 mutter 原理</p>
<p>1. mutter 的方式是把每个 window 作为 actor ，动画时是 actor 在 stage
上变化。</p>
<p>2. 一个窗口动画时，与其它 actor
结合效果好，尤其是可以透出后面的背景和窗口。</p>
<p>3. 很多 PC 都不支持 mutter<br />
，由于缺少硬件加速，运行即报错，或者打开关闭窗口非常慢，且不出动画效果(它的默认效果应该是在开关窗口和最大化时有缩放效果)，在嵌入式系统中运行更加不可预测。</p>
<p>4.
可扩展的效果多（如窗口的透明，扭曲，窗口内容变化中的动画效果……），但资源占用也大。</p>
<p>5. 架构好，可用插件的方式加入各种动画。</p>
<p>6. 与 compiz
相比，它的代码量小，依赖的模块少，更适合嵌入式系统，和定制窗口管理器。</p>
]]></content>
      <tags>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>数据迁移工具Kettle</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%85%B6%E5%AE%83%E7%BC%96%E7%A8%8B/%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB%E5%B7%A5%E5%85%B7Kettle/</url>
    <content><![CDATA[<h1 id="数据迁移工具kettle">数据迁移工具Kettle</h1>
<p>#工具 #大数据</p>
<h4 id="背景知识">1. 背景知识</h4>
<p><strong>(1) 什么是ETL</strong></p>
<p> ETL是Extract-Transform-Load
的缩写，用来描述将数据从来源端经过抽取（extract）、交互转换（transform）、加载（load）至目的端的过程。</p>
<p><strong>(2) Kettle简介</strong></p>
<p> Kettle是一款国外开源的ETL工具，纯java编写，可以在Window、Linux、Unix上运行，数据抽取高效稳定。Kettle
中文名称叫水壶，该项目的主程序员MATT
希望把各种数据放到一个壶里，然后以一种指定的格式流出。我们常用它定时将一些库的数据稍做转换后存入其它库。</p>
<p><strong>(3) 工作机制</strong></p>
<p> Kettle中有两种脚本文件，transformation和job，transformation完成针对数据的基础转换，job则完成整个工作流的控制。</p>
<h4 id="安装和运行">2. 安装和运行</h4>
<p><strong>(1) 安装</strong></p>
<p> kettle的最新下载地址：<a
href="http://community.pentaho.com/projects/data-integration/">http://community.pentaho.com/projects/data-integration/</a>
我在linux下安装，机器之前已装好java环境，将下载的安装包解压到/usr/local目录下。</p>
<p> 另外，还需要安装对应数据库的支持，比如我使用mysql数据库，则需要下载mysql-connector-java-5.1.41-bin.jar放到/usr/local/kettle/data-integration/lib目录下。</p>
<p><strong>(2) 启动图形界面</strong></p>
<p> kettle提供图形界面和命令行两种方式，图形界面主要用于配置和测试，命令行主要用于运行。<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ cd /usr/local/kettle/data-integration/  </span><br><span class="line">$ ./spoon.sh  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 3. 准备工作    </span><br><span class="line">  </span><br><span class="line">&amp;emsp;一般使用kettle主要是导数据，因此以数据库作为实例，选建立数据库环境。如果只使用最简单的调度，也可以不使用数据库；如果已安装数据库，请忽略安装数据库，要建表即可。  </span><br><span class="line">  </span><br><span class="line">**(1) 安装mysql数据库**  </span><br><span class="line">  </span><br><span class="line">```  </span><br><span class="line">$ sudo apt-get install mysql-server  </span><br><span class="line">$ sudo apt isntall mysql-client  </span><br><span class="line">$ sudo apt install libmysqlclient-dev  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">**(2) 建库建表**  </span><br><span class="line">  </span><br><span class="line">```  </span><br><span class="line">$ mysql -uroot -p  </span><br><span class="line">&gt; create database test_db;  </span><br><span class="line">&gt; use test_db;  </span><br><span class="line">&gt; create table table1 (id INT, name VARCHAR(20), date DATE);  </span><br><span class="line">&gt; create table table2 (id INT, name VARCHAR(20), date DATE);  </span><br><span class="line">&gt; insert into table1 values(1,&#x27;xy&#x27;,&#x27;2018-11-04&#x27;);  </span><br><span class="line">&gt; insert into table1 values(2,&#x27;llx&#x27;,&#x27;2018-11-05&#x27;);  </span><br><span class="line">$ select * from table1;   </span><br><span class="line">```  </span><br><span class="line">&amp;emsp;此时建立了库test_db, 库中有表table1, table2, 表中各有三个字段id, name, date，table1中插入了两条记录，接下来的操作是将table1中的数据导入table2。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 4. 一个简单的作业调度  </span><br><span class="line">  </span><br><span class="line">**(1) 建立一个变换Transformation**  </span><br><span class="line">  </span><br><span class="line"> i. 新建一个变换    </span><br><span class="line">  </span><br><span class="line">&amp;emsp;在Kettle界面上：菜单-&gt;New-&gt;Transformation  </span><br><span class="line">  </span><br><span class="line"> ii. 加一个输入库    </span><br><span class="line">  </span><br><span class="line">&amp;emsp;主界面：左侧-&gt;Input-&gt;Table Input，拉到工作区建立新的table input。    </span><br><span class="line">&amp;emsp;双击table input，调出其编辑界面。    </span><br><span class="line">&amp;emsp;在编辑界面点Connection-&gt;New，建立一个数据库连接。    </span><br><span class="line">&amp;emsp;在连接界面，Connection Type选MySQL，设置Host Name: 127.0.0.1, Database Name: test_db, Port Number: 3306, User Name: root, Password:你的密码，Connection Name：test1，此时点Test，可查看数据库是否连接成功，如果成功，点OK建立连接。    </span><br><span class="line">&amp;emsp;在Table Input编辑界面，选Get SQL select statement…，从库中选择你所要输入的表table1，此时自动生成了select查询语句（这就是kettle方便的地方，不用手敲，自动生成语句，简单编辑即可），选OK确定。  </span><br><span class="line">  </span><br><span class="line"> iii. 加一个输出库    </span><br><span class="line">  </span><br><span class="line">&amp;emsp;主界面：左侧-&gt;Output-&gt;Table Output，拉到工作区建立新的table output。    </span><br><span class="line">&amp;emsp;双击table output，调出其编辑界面。    </span><br><span class="line">&amp;emsp;在编辑界面，Conection中选择刚才建立的数据库连接test1，Target table选中table2，点OK确定。  </span><br><span class="line">  </span><br><span class="line"> iv. 连接输入和输出，并测试    </span><br><span class="line">  </span><br><span class="line">&amp;emsp;按住shift键，从Table input拖一条线到Table output，用菜单File-&gt;Save保存该变换名为test_trans，然后点上方的Run键运行，正常情况下，小图标右上角出现绿色对勾，说明运行正常。    </span><br><span class="line">&amp;emsp;在mysql中输入   </span><br><span class="line">```  </span><br><span class="line">&gt; select * from table2;   </span><br><span class="line">```  </span><br><span class="line">&amp;emsp;可以看到数据库table1中的数据已经被复制到table2中，此时一个Transformation就完成了。  </span><br><span class="line">  </span><br><span class="line">**(2) 建立一个工作流Job**  </span><br><span class="line">  </span><br><span class="line"> i. 新建一个Job   </span><br><span class="line">  </span><br><span class="line">&amp;emsp;在Kettle界面上：菜单-&gt;New-&gt;Job  </span><br><span class="line">  </span><br><span class="line"> ii. 加入模块    </span><br><span class="line">  </span><br><span class="line">&amp;emsp;主界面：左侧-&gt;General-&gt;START，拖出一个START（可以设定执行时间）    </span><br><span class="line">&amp;emsp;主界面：左侧-&gt;General-&gt;Transformation，拖出一个，双击调出编辑界面，Browse选刚才保存的test_trans文件，点OK确认。    </span><br><span class="line">&amp;emsp;主界面：左侧-&gt;General-&gt;Success，拖出一个Success  </span><br><span class="line">  </span><br><span class="line"> iii. 连接模型，并测试    </span><br><span class="line">  </span><br><span class="line">&amp;emsp;按住Shift依次连线：Start-&gt;Transformation-&gt;Success，然后点上方的运行按钮，正常情况下就能正常运行了。  </span><br><span class="line">  </span><br><span class="line">**(3) 变量和选择分支**  </span><br><span class="line">  </span><br><span class="line"> i. 新建一个变换    </span><br><span class="line">  </span><br><span class="line">&amp;emsp;在Kettle界面上：菜单-&gt;New-&gt;Transformation。  </span><br><span class="line">  </span><br><span class="line"> ii. 建立变量    </span><br><span class="line">  </span><br><span class="line">&amp;emsp;主界面：左侧-&gt;Job-&gt;Set Variables，拖到主工作区，双击编辑，新建一个变量flag，Default value为1。  </span><br><span class="line">  </span><br><span class="line"> iii. 建立选择分支    </span><br><span class="line">  </span><br><span class="line">&amp;emsp;主界面：左侧-&gt;Flow-&gt;Switch/Case，拖到主工作区，双击编辑，在Field name to switch指定变量flag，然后在Case values中加两个值0和1。   </span><br><span class="line">&amp;emsp; 主界面：左侧-&gt;Flow-&gt;Dummy，拖到主工作区  主界面：左侧-&gt;Flow-&gt;Abort，拖到主工作区  </span><br><span class="line">  </span><br><span class="line"> iv. 连接模型，并测试    </span><br><span class="line">  </span><br><span class="line">&amp;emsp;按住Shift依次连线：Set Variables-&gt;Switch/Case，Switch/Case连Abort时选This case target value 0，Switch/Case连Dummy时选This case target value 0。    </span><br><span class="line">  </span><br><span class="line">&amp;emsp;然后点上方的运行按钮，正常情况下就能正常运行了。  这里设置的变量也可以在整个工作流中使用，操作数据库时使用方法是$&#123;变量名&#125;，注意需要选中“use variables in script”。  </span><br><span class="line">  </span><br><span class="line">**(4) 其它**  </span><br><span class="line">  </span><br><span class="line">&amp;emsp;除了以上的导库，设变量，分支，以外，常用的还有Java程序模型（左侧Transformation-&gt;Steps-&gt;User defined Java Class），通常用于在数据库转换过程中做一些sql无法实现的数据变换，同样的，新建时，它也会生成一段基础代码，简单修改即可。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 5. 用命令行运行任务    </span><br><span class="line">  </span><br><span class="line">&amp;emsp;上面建立的Transformation扩展名为ktr，Job扩展名为kjb，可通过kitchen.sh执行，具体命令是：  </span><br><span class="line">```  </span><br><span class="line"> ./kitchen.sh -file=xxx.kjb   </span><br><span class="line">```  </span><br><span class="line">&amp;emsp;如需不受控制台关闭的影响，可以使用以下命令，使kettle一直在后台运行：   </span><br><span class="line">```  </span><br><span class="line">nohup ./kitchen.sh -file=xxx.kjb &amp;  </span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>调度工具Airflow</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%85%B6%E5%AE%83%E7%BC%96%E7%A8%8B/%E8%B0%83%E5%BA%A6%E5%B7%A5%E5%85%B7Airflow/</url>
    <content><![CDATA[<h1 id="调度工具airflow">调度工具Airflow</h1>
<p>#工具 #大数据</p>
<h4 id="什么是airflow">1. 什么是Airflow</h4>
<p> Airflow是Airbnb开源的data
pipeline调度和监控工作流的平台，用于用来创建、监控和调整data
pipeline(ETL)。</p>
<h4 id="简单的定时任务cron">2. 简单的定时任务cron</h4>
<p> 假设我们想要定时调用一个程序，比如说：每天定时从Web抓数据，我们可以使用cron。cron是一个Linux下的后台服务，用来定期的执行一些任务，在/etc/crontab中设置后即可，基本写法如下：</p>
<pre><code># 分钟 小时 日 月 周 用户  命令   
17 * * * * root date &gt;&gt; /tmp/time.log   </code></pre>
<p> 它的意思是每个小时的第18分钟，将当前时间写入log文件，注意各值的取值范围（分钟
0 - 59，小时0 - 23，天1 - 31，月1 - 12，星期0 - 6，0表示星期天）
修改/etc/crontab后，还需要用 $ sudo service cron
restart命令重启crontab任务，才能生效。</p>
<h4 id="为什么要用airflow">3. 为什么要用Airflow</h4>
<p> 有了cron为什么还需要airflow？以抓取web数据为例，可能在某天抓取数据时，网断或者关机了，当天的数据没抓进来，这种情况下，只能通过写日志定时分析日志，以及在程序中定时重连的方式保证数据完整，相对比较零碎和麻烦。另外，如果crontab设置文件中有几十上百条任务时，就比较头疼了。</p>
<p> Airflow支持图形界面和命令行两种方式，管理起来比较方便，另外，它可以把几个相互依赖的任务编成一组，并监督执行是否正常，如果不正常，调用程序重试等等。</p>
<p> 当然，Airflow也不全是优点，比如需要使用python脚本来定义任务间的依赖关系，相对于手动编辑crontab文件，相对难一些。因此，如果只调用简单的任务，使用cron即可，复杂的再考虑airflow。</p>
<h4 id="airflow的基础概念">4. Airflow的基础概念</h4>
<p> Airflow 中最基本的两个概念是：DAG 和 task。DAG 的全称是 Directed
Acyclic Graph
是所有你想执行的任务的集合，在这个集合中可以定义了他们的依赖关系，一个
DAG object可以用 Python 脚本中配置完成。每个 DAG object 代表了一个
workflow，每个 workflow 都可以包含任意个 task，task就是具体的任务。</p>
<h4 id="airflow安装和使用">5. Airflow安装和使用</h4>
<p><strong>(1) 安装airflow</strong></p>
<pre><code>$ sudo pip install airflow   </code></pre>
<p> 可以通过环境变量AIRFLOW_HOME
设置airflow的工作目录，默认为$HOME/airflow/</p>
<p><strong>(2) Mysql支持</strong></p>
<p> 如果想使用mysql存储airflow内容，请按如下方法设置mysql；如果不设置，airflow在其工作目录下建立db文件，以sqlite方式存储。</p>
<pre><code>$ mysql -u root -p  
  
mysql&gt; create database airflow default charset utf8 collate utf8_general_ci;  
mysql&gt; create user airflow@&#39;localhost&#39; identified by &#39;airflow&#39;;  
mysql&gt; grant all on airflow.* to airflow@&#39;localhost&#39;;  
mysql&gt; flush privileges;  </code></pre>
<p> 修改配置文件
$AIRFLOW_HOME/airflow.cfg，把sql_alchemy_conn对应语句替换成：</p>
<pre><code>sql_alchemy_conn = mysql://airflow:airflow@localhost:3306/airflow  </code></pre>
<p><strong>(3) 运行</strong></p>
<pre><code>$ airflow initdb  
$ airflow worker  
$ airflow webserver -p 8080 # 一直运行  
$ airflow scheduler # 一直运行    </code></pre>
<p> 此时在浏览器中输入：http://localhost:8080，即可看到airflow界面，其中有很多demo可以参考。</p>
<p><strong>(4) 建立第一个DAG：Hellow world</strong></p>
<pre><code>$ mkdir $AIRFLOW_HOME/dags/  
$ vi $AIRFLOW_HOME/dags/hello_word.py # 内容如下：  </code></pre>
<pre><code> # -*- coding: utf-8 -*-  
  
import airflow  
from airflow import DAG  
from airflow.operators.bash_operator import BashOperator  
from airflow.operators.python_operator import PythonOperator  
from datetime import timedelta  
  
default_args = &#123;  
 &#39;owner&#39;: &#39;yan.xie&#39;,  
 &#39;depends_on_past&#39;: False,  
 &#39;start_date&#39;: airflow.utils.dates.days_ago(2),  
 &#39;retries&#39;: 5, # 重试次数  
 &#39;retry_delay&#39;: timedelta(minutes=1), # 运行间隔时间  
&#125;  
  
dag = DAG(  
 &#39;test_my_dag&#39;, # DAG名字  
 default_args=default_args,  
 description=&#39;my first DAG&#39;,  
 schedule_interval=timedelta(days=1))  
  
task1 = BashOperator(  
 task_id=&#39;task_1&#39;, # TASK名  
 bash_command=&#39;date&#39;, # 运行命令  
 dag=dag)  
  
task2 = BashOperator(  
 task_id=&#39;task_2&#39;,  
 depends_on_past=False,  
 bash_command=&#39;sleep 5&#39;,  
 dag=dag)  
  
def print_hello():  
 return &#39;Hello world!&#39;  
  
test3 = PythonOperator(  
 task_id=&#39;task_3&#39;,  
 python_callable=print_hello, # 运行python程序  
 dag=dag)  
  
task2.set_upstream(task1) # 设置依赖关系  
test3.set_upstream(task1)   </code></pre>
<p> 保存之后，再浏览器刷新一下界面，即可在list中看到该DAG，点On后，即可运行。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-e418538c4abef008.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 点开DAG可以看到各Task间的依赖关系</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-52fb9c6f85c1124a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 以及树型关系</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-f9dd5df75e892bb2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><strong>(5) 调试</strong><br />
 有时候，怕不能一次写对，可以运行以下命令调试单个Task</p>
<pre><code>$ airflow test test_my_dag task_3 20181027  </code></pre>
<p><strong>(6) 清除全部DAG重置数据库</strong></p>
<pre><code>$ airflow resetdb   </code></pre>
<p> 并删除 $AIRFLOW_HOME/dags/ 下所有DAG文件，然后重启webserver。</p>
<p> 在Airflow中，如果改了一个DAG的名字，它会新建一个DAG，而不仅是改名，所以旧的DAG还在数据库和列表中存在，可以用
“$ airflow delete_dag DAG名”
的方式删除它，但不是每个airflow版本都支持delete_dag命令。此时可以只用resetdb不删除dags目录下文件的方式，删除目录中没有对应文件的DAG（删除有风险，操作须谨慎）。</p>
<h4 id="参考">6. 参考</h4>
<p><strong>(1) Ubuntu下crontab命令的用法</strong><br />
https://www.cnblogs.com/daxian2012/articles/2589894.html</p>
<p><strong>(2) 使用 Airflow 替代你的 crontab</strong><br />
https://www.juhe.cn/news/index/id/2365</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>调试lib库的一些小技巧</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%85%B6%E5%AE%83%E7%BC%96%E7%A8%8B/%E8%B0%83%E8%AF%95lib%E5%BA%93%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7/</url>
    <content><![CDATA[<h1 id="调试lib库的一些小技巧">调试lib库的一些小技巧</h1>
<p>#JNI #C</p>
<p>1. lib 库中打印 log 信息<br />
在文件头部加<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">** #define LOG_TAG “testme”    </span><br><span class="line">#undef LOG  //  ** ** 有的版本需要这句，有的版本不需要  ** **    </span><br><span class="line">#include  &lt;utils/Log.h&gt; **    </span><br><span class="line">在程序中用    </span><br><span class="line">** LOGE(“log is xxxxx”);  **    </span><br><span class="line">在编  lib  库的  Android.mk  中加    </span><br><span class="line">** LOCAL_SHARED_LIBRARIES:=libutils  **  </span><br><span class="line">```  </span><br><span class="line">2\.  lib  库中  jni  用  c++    </span><br><span class="line">在每个函数前头加，以免提示找不到函数名    </span><br><span class="line">```  </span><br><span class="line">** #ifdef __cplusplus    </span><br><span class="line">extern “C”    </span><br><span class="line">#endif  **  </span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>C</tag>
        <tag>JNI</tag>
      </tags>
  </entry>
  <entry>
    <title>前端_搭建环境</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%89%8D%E7%AB%AF%E5%85%A5%E9%97%A8/01_%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<p>#前端 #编程语言/前端</p>
<h1 id="搭建环境">搭建环境</h1>
<p>我在 Ubuntu 下用 VSCODE 搭建前端开发环境，用 Windows 也差不多。</p>
<h2 id="vscode">1 VSCode</h2>
<p>VSCode是微软推出的可运行于Mac OS X、Windows和
Linux多平台上的源码编辑器，前端开发一般都用它。</p>
<h3 id="安装">1.1 安装</h3>
<ul>
<li>下载：<a
href="https://code.visualstudio.com">https://code.visualstudio.com</a><br />
</li>
<li>下载deb包，然后用命令安装<br />
</li>
</ul>
<pre class="shell"><code>sudo dpkg -i code_1.63.2-1639562499_amd64.deb  </code></pre>
<h3 id="运行">1.2 运行</h3>
<ul>
<li>在启动器里输入code，然后选择Visual Studio Code<br />
</li>
<li>根据提示下载安装中文环境<br />
</li>
<li>安装两个插件（通过左侧扩展按钮调出）
<ul>
<li>Code Runner<br />
</li>
<li>HTML CSS Support<br />
</li>
</ul></li>
<li>打开文件夹（点左侧的资源管理器按钮）<br />
</li>
<li>创建一个html文件，加入简单代码<br />
</li>
</ul>
<div class="sourceCode" id="cb2"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;html&gt;</span>  </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;body&gt;</span>  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        <span class="kw">&lt;script&gt;</span><span class="fu">alert</span>(<span class="st">&#39;Hello World&#39;</span>)<span class="kw">&lt;/script&gt;</span>  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;/body&gt;</span>  </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/html&gt;</span>  </span></code></pre></div>
<ul>
<li>按F5之后选择Chrome，即可看Chrome浏览器被调出，并看到到弹框</li>
</ul>
<h2 id="npm">2 npm</h2>
<p>npm用于JavaScript的包管理工具。</p>
<h3 id="安装npm">2.1 安装npm</h3>
<pre class="shell"><code>$ sudo apt install npm  </code></pre>
<h4 id="修改npm数据源">2.1.1 修改npm数据源</h4>
<p>修改npm数据源，以加快下载速度</p>
<pre class="shell"><code>$ vi $HOME/.npmrc  
加入如下内容：  
registry = http://registry.npm.taobao.org/  </code></pre>
<p>看看是否设置成功</p>
<pre><code>$ npm config get registry  </code></pre>
<h3 id="安装常用软件包">2.2 安装常用软件包</h3>
<p>n是一个Node工具包</p>
<pre class="shell"><code>$ sudo npm install -g npm@8.3.2 # 升成指定版本的npm, -g为全局安装  
$ sudo npm install -g n # 安装node工具包  
$ sudo npm install n stable  # 安装最新的稳定工具包  
$ sudo npm install -g create-react-app # 安装react项目工具  </code></pre>
<p>查看包安装位置</p>
<pre class="shell"><code>$ npm config ls  </code></pre>
<p>查看安装包的可用版本</p>
<pre class="shell"><code>$ npm view 包名 versions --json  </code></pre>
<p>查看软件信息</p>
<pre class="shell"><code>$ sudo npm info xxx  </code></pre>
<p>查看当前安装的软件版本</p>
<pre class="shell"><code>$ sudo npm -v xxx  </code></pre>
<p>查看软件版本</p>
<pre class="shell"><code>$ sudo npm view xxx versions  </code></pre>
<h4 id="npm安装包语法">2.2.1 npm安装包语法</h4>
<ul>
<li>npm安装模块<br />
</li>
</ul>
<pre class="shell"><code>$ npm install xxx # 安装xxx模块到当前命令行所在目录node_moduels下  
$ npm install -g xx # 安装全局模块xxx  
$ npm install xxx –save # 安装并写入package.json的”dependencies”中  
$ npm install xxx –save-dev # 安装并写入package.json的”devDependencies”中。  </code></pre>
<ul>
<li>npm 删除模块<br />
</li>
</ul>
<pre class="shell"><code>$ npm uninstall xxx # 删除xxx模块  
$ npm uninstall -g xxx # 删除全局模块xxx  </code></pre>
<h3 id="create-react-app文件结构">2.3 create-react-app文件结构</h3>
<ul>
<li>node_modules：存放可能依赖的模块和插件<br />
</li>
<li>package.json：记录node_modules中的包其及版本信息，使用npm install
（npm isntall
--production只安装本项目依赖包）可自动安装node_modules下所有包<br />
</li>
<li>package-lock.json：记录模块之前依赖，锁定包版本，记录下载地址，加快重新下载速度<br />
</li>
<li>src：JS代码<br />
</li>
<li>public：其它html文件和资源</li>
</ul>
<p>详见：<a
href="https://www.cnblogs.com/mmzuo-798/p/14293387.html">package.json与package-lock.json文件是干什么用的？</a></p>
<h3 id="本地和全局安装">2.4 本地和全局安装</h3>
<p>npm有两种安装方式：全局和本地。使用参数-g设置为全局安装，软件安装在系统目录中，像npm，n这些基础包建立全局安装。只供本项目使用的，一般不加-g参数，即本地安装，包被安装在当前项目的node-modules子目录中。</p>
<h3 id="软件版本">2.5 软件版本</h3>
<p>一般项目目录下包含package.json，用于指定相关软件包的版本，如果未在该文件中指定，则默认安装软件的最新版本。</p>
<h2 id="参考">3 参考</h2>
<p><a
href="https://baike.baidu.com/item/visual%20studio%20code/17514281?fr=aladdin">百度百科visual
studio code</a><br />
<a href="https://www.npmjs.cn/">npm中文文档</a></p>
]]></content>
      <tags>
        <tag>前端</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title>02_HTML5</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%89%8D%E7%AB%AF%E5%85%A5%E9%97%A8/02_HTML5/</url>
    <content><![CDATA[<p>#前端 #编程语言/前端</p>
<h1 id="html">HTML</h1>
<h2 id="元素">1 元素</h2>
<h3 id="原理">1.1 原理</h3>
<p>作为一个操作单位，如被JS操作，或者其中的数据都使用同种CSS风格……</p>
<h3 id="自定义元素">1.2 自定义元素</h3>
<h6 id="定义块元素">定义块元素</h6>
<div class="sourceCode" id="cb1"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;div&gt;</span> ... <span class="kw">&lt;/div&gt;</span>  </span></code></pre></div>
<p>注意：div中可包含多个元素，即将多个元素分成一组。</p>
<h6 id="定义行内元素">定义行内元素</h6>
<div class="sourceCode" id="cb2"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span&gt;</span> ... <span class="kw">&lt;/span&gt;</span>  </span></code></pre></div>
<p>注意：只能把span放在其它元素的内部。</p>
<h3 id="元素属性id-和-class">1.3 元素属性：id 和 class</h3>
<p>id和class是元素的属性，不只是自定义元素，所有元素都可以设置id和class，以设置操作和风格。</p>
<h6 id="id">id</h6>
<p>id是元素的字名，应该是独一无二的，</p>
<h6 id="class">class</h6>
<p>class是元素它所属类别，多个元素可属于同一类别，它们可以拥有同样的显示风格，同样的操作……
一个元素还可以属于多个类别形如：</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;div</span> <span class="er">id</span><span class="ot">=</span><span class="st">&quot;ISBN0321127307&quot;</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;listing book&quot;</span><span class="kw">&gt;</span>  </span></code></pre></div>
<h3 id="通过id访问控件">1.4 通过id访问控件</h3>
<p>(好像是JQuery用法)</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">$</span>(<span class="st">&quot;#id&quot;</span>)<span class="op">.</span><span class="fu">val</span>()  </span></code></pre></div>
<h2 id="常用关键字">2 常用关键字</h2>
<ul>
<li>margin：外边距
<ul>
<li>margin: auto为居中</li>
</ul></li>
</ul>
<h2 id="flex布局">3 Flex布局</h2>
<p>特点：简洁优雅<br />
注意：不需要学得太细，够用就行<br />
教程：<a href="https://zhuanlan.zhihu.com/p/25303493">30 分钟学会 Flex
布局</a></p>
<p>flex 容器中默认存在两条轴，水平主轴(main axis，默认主轴方向是横向)
和垂直的交叉轴(cross axis)<br />
<img src="/attachments_2022/Pasted%20image%2020220206141841.png"
alt="Pasted%20image%2020220206141841.png" /><br />
在容器中的每个单元块被称之为 flex item，每个项目占据的主轴空间为 (main
size), 占据的交叉轴的空间为 (cross size)。<br />
任何一个容器都可以被指定为 flex 布局，其内部元素使用flex布局。</p>
<h4 id="容器属性">3.1.1 容器属性</h4>
<ul>
<li>flex-direction：主轴方向：row | row-reverse | column |
column-reverse<br />
</li>
<li>flex-wrap：容器内元素是否可换行：nowrap | wrap | wrap-reverse<br />
</li>
<li>flex-flow：flex-direction 和 flex-wrap 的简写形式<br />
</li>
<li>justify-content：元素在主轴的对齐方式：flex-start | flex-end |
center | space-between | space-around<br />
</li>
<li>align-items：元素在交叉轴上的对齐方式：flex-start | flex-end |
center | baseline | stretch<br />
</li>
<li>align-content：多根轴线的对齐方式</li>
</ul>
<h4 id="元素属性">3.1.2 元素属性</h4>
<ul>
<li>order：元素在容器中的排列顺序，越小越靠前<br />
</li>
<li>flex-basis：分配多余空间之前，元素占据的主轴空间：length |
auto;<br />
</li>
<li>flex-grow：元素的放大比例，默认为0不放大<br />
</li>
<li>flex-shrink：元素的缩小比例，默认为1<br />
</li>
<li>flex：flex-grow, flex-shrink 和 flex-basis的简写<br />
</li>
<li>align-self：单个元素不同的对齐方式：auto | flex-start | flex-end |
center | baseline | stretch</li>
</ul>
<h3 id="注意事项">3.2 注意事项</h3>
<ul>
<li>排版时一定要注意使用css的class，尽量不要自己去设width这些属性，以保持风格一致</li>
</ul>
<h3 id="示例">3.3 示例</h3>
<p>head中设置</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a> <span class="kw">&lt;style&gt;</span>  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="pp">#box1</span> &#123;  </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>       <span class="kw">display</span>: <span class="dv">flex</span><span class="op">;</span>  </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>       <span class="kw">flex-wrap</span>: wrap<span class="op">;</span>  </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>       <span class="kw">justify-content</span>: <span class="dv">center</span><span class="op">;</span>  </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>       <span class="kw">align-content</span>: flex-start<span class="op">;</span>  </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    &#125;  </span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a> <span class="kw">&lt;/style&gt;</span>  </span></code></pre></div>
<p>body中实现</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a> <span class="kw">&lt;div</span> <span class="er">id</span><span class="ot">=</span><span class="st">&quot;box1&quot;</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;box&quot;</span> <span class="er">style</span><span class="ot">=</span><span class="st">&quot;text-align:left; margin:5px auto&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;div</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;item&quot;</span> <span class="er">style</span><span class="ot">=</span><span class="st">&quot;align-self:flex-start;margin:2px;flex-grow:1;&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>       <span class="kw">&lt;h2&gt;</span>标题<span class="kw">&lt;/h2&gt;</span>  </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;/div&gt;</span>  </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;div</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;item&quot;</span> <span class="er">style</span><span class="ot">=</span><span class="st">&quot;align-self:center;margin:2px;&quot;</span><span class="kw">&gt;</span>   </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>       <span class="kw">&lt;button</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;btn btn-primary&quot;</span><span class="kw">&gt;</span>右钮1<span class="kw">&lt;/button&gt;</span>  </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;/div&gt;</span>  </span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;div</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;item&quot;</span> <span class="er">style</span><span class="ot">=</span><span class="st">&quot;align-self:center;margin:2px;&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>       <span class="kw">&lt;button</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;btn btn-primary&quot;</span><span class="kw">&gt;</span>右钮2<span class="kw">&lt;/button&gt;</span>  </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;/div&gt;</span>  </span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;div</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;item&quot;</span> <span class="er">style</span><span class="ot">=</span><span class="st">&quot;align-self:center;margin:2px;&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>       <span class="kw">&lt;button</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;btn btn-primary&quot;</span><span class="kw">&gt;</span>右钮3<span class="kw">&lt;/button&gt;</span>  </span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;/div&gt;</span>  </span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a> <span class="kw">&lt;/div&gt;</span>  </span></code></pre></div>
<h2 id="问题与解答">4 问题与解答</h2>
<h4 id="问题一">4.1.1 问题一</h4>
<p>问：如何设置多个控件对齐和居中<br />
答：在控件外面包div，设置其style如下：</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;div</span> <span class="er">style</span><span class="ot">=</span><span class="st">&quot;width:900px; text-align:left; margin:auto&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>...  </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/div&gt;</span>  </span></code></pre></div>
<p>其中margin定义其内容居中，注意把控件的设置写在style中，直接用等号的如下方式，不是每个控件都支持。</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;table</span> <span class="er">width</span><span class="ot">=</span><span class="st">&quot;900&quot;</span> <span class="er">cellspacing</span><span class="ot">=</span><span class="st">&quot;0&quot;</span> <span class="er">cellpadding</span><span class="ot">=</span><span class="st">&quot;0&quot;</span> <span class="er">border</span><span class="ot">=</span><span class="st">&quot;0&quot;</span> <span class="er">align</span><span class="ot">=</span><span class="st">&quot;center&quot;</span><span class="kw">&gt;</span>  </span></code></pre></div>
<h4 id="问题二">4.1.2 问题二</h4>
<p>问：如何调试前端页面<br />
答：F12调出调试（或者：右键菜单-&gt;检查），调试界面左边元素面板，右边样式面板，直接修改样式即可。</p>
<h4 id="问题三">4.1.3 问题三</h4>
<p>问题：如何实现右对齐？<br />
回答：</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;div</span> <span class="er">align</span><span class="ot">=</span><span class="st">&quot;right&quot;</span><span class="kw">&gt;</span>测试文本，测试文本<span class="kw">&lt;/div&gt;</span>  </span></code></pre></div>
<h2 id="参考">5 参考</h2>
<p><a
href="http://yige.org/tags/att_div_align.php">HTML参考手册</a><br />
<a
href="https://www.cnblogs.com/lgx5/p/11059009.html">jquery操作select(取值，设置选中）</a></p>
<h2 id="其它">6 其它</h2>
<ul>
<li>前后端可以通过模板传数据结构</li>
</ul>
]]></content>
      <tags>
        <tag>前端</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title>03_JS</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%89%8D%E7%AB%AF%E5%85%A5%E9%97%A8/03_JS/</url>
    <content><![CDATA[<h1 id="javascript">JavaScript</h1>
<p>#前端 #编程语言/前端</p>
<h2 id="原理">1 原理</h2>
<ul>
<li>运行在客户端浏览器，不需要服务端资源</li>
</ul>
<h2 id="用途">2 用途</h2>
<ul>
<li>网页中比较复杂的交互，比如提示用户输入错误，点展开列表、输入文字时自动联想……</li>
</ul>
<h2 id="基本语法">3 基本语法</h2>
<h3 id="说明">3.1 说明</h3>
<ul>
<li>大小写敏感<br />
</li>
<li>空格无意义（与Python不同）<br />
</li>
<li>建议以分号结尾<br />
</li>
<li>注释
<ul>
<li>行注释：<br />
<code>javascript         // 我是行注释</code><br />
</li>
<li>块注释:<br />
<code>javascript         /*         我是注释         */</code></li>
</ul></li>
</ul>
<h3 id="变量">3.2 变量</h3>
<p>不需要显示地声明类型，但需要用var定义变量。</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">var</span> foo <span class="op">=</span> <span class="kw">null</span><span class="op">;</span>  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="kw">var</span> foo <span class="op">=</span> <span class="kw">true</span><span class="op">;</span>  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">var</span> foo <span class="op">=</span> <span class="dv">5</span><span class="op">;</span>  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="kw">var</span> foo <span class="op">=</span> <span class="st">&quot;five&quot;</span><span class="op">;</span>  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="kw">var</span> foo <span class="op">=</span> [<span class="dv">5</span><span class="op">,</span> <span class="st">&quot;five&quot;</span><span class="op">,</span> <span class="st">&quot;5&quot;</span>]<span class="op">;</span>  </span></code></pre></div>
<h3 id="操作">3.3 操作</h3>
<p><strong>布尔操作</strong><br />
* == 等于<br />
* != 不等于<br />
* === 类型相同<br />
* !== 类型不同<br />
* &gt; , &gt;=, &lt;, &lt;= 大于、大于等于、小于、小于等于</p>
<p><strong>数值操作</strong><br />
* ++ 加1<br />
* -- 减1<br />
* += 当前值加</p>
<p><strong>逻辑运算</strong><br />
* &amp;&amp; 逻辑与<br />
* || 逻辑或<br />
* ! 逻辑非</p>
<h3 id="条件">3.4 条件</h3>
<div class="sourceCode" id="cb2"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>( <span class="kw">true</span> ) &#123;  </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Do something.  </span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>&#125; <span class="cf">else</span> &#123;  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Do somethine.  </span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>&#125;  </span></code></pre></div>
<h3 id="循环">3.5 循环</h3>
<div class="sourceCode" id="cb3"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>( <span class="kw">var</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> <span class="dv">2</span><span class="op">;</span> i<span class="op">++</span> ) &#123;  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Do something.  </span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>&#125;  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="kw">var</span> items <span class="op">=</span> [<span class="st">&quot;abc&quot;</span><span class="op">,</span> <span class="st">&quot;def&quot;</span><span class="op">,</span> <span class="st">&quot;g12&quot;</span>]<span class="op">;</span>  </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>( <span class="kw">var</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> items<span class="op">.</span><span class="at">length</span><span class="op">;</span> i<span class="op">++</span> ) &#123;  </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Do something.  </span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>&#125;  </span></code></pre></div>
<h3 id="函数">3.6 函数</h3>
<h4 id="系统函数">3.6.1 系统函数</h4>
<p>跳出对话框：<br />
* alert() 跳出警告<br />
* confirm() 确认框<br />
* prompt() 可接受输入信息的提示框</p>
<h4 id="自定义函数">3.6.2 自定义函数</h4>
<div class="sourceCode" id="cb4"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">addNumbers</span>(a<span class="op">,</span>b) &#123;  </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a <span class="op">+</span> b<span class="op">;</span>  </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>&#125;  </span></code></pre></div>
<h4 id="调用函数">3.6.3 调用函数</h4>
<div class="sourceCode" id="cb5"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">addNumbers</span>(<span class="dv">3</span><span class="op">,</span><span class="dv">4</span>)  </span></code></pre></div>
<h2 id="操作html">4 操作HTML</h2>
<h3 id="浏览器">4.1 浏览器</h3>
<p>浏览器的常用属性和方法见下表：</p>
<table>
<colgroup>
<col style="width: 16%" />
<col style="width: 83%" />
</colgroup>
<thead>
<tr class="header">
<th>Property/method</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>event</td>
<td>Represents the state of an event</td>
</tr>
<tr class="even">
<td>history</td>
<td>Contains the URLs the user has visited within a browser window</td>
</tr>
<tr class="odd">
<td>location</td>
<td>Gives read/write access to the URI in the address bar</td>
</tr>
<tr class="even">
<td>status</td>
<td>Sets or returns the text in the status bar of the window</td>
</tr>
<tr class="odd">
<td>alert()</td>
<td>Displays an alert box with a specified message and an OK button</td>
</tr>
<tr class="even">
<td>close()</td>
<td>Closes the current window</td>
</tr>
<tr class="odd">
<td>confirm()</td>
<td>Displays a dialog box with a specified message and an OK and a
Cancel button</td>
</tr>
<tr class="even">
<td>focus()</td>
<td>Sets focus on the current window</td>
</tr>
</tbody>
</table>
<p>更多方法，请见：<a
href="https://developer.mozilla.org/en-US/docs/Web/API/Window">MDN Web
Docs</a></p>
<h3 id="事件">4.2 事件</h3>
<p>在发生某个事件时调用函数，常见事件殚表如下：</p>
<table>
<thead>
<tr class="header">
<th>Event handler</th>
<th>Event description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>onblur</td>
<td>An element loses focus.</td>
</tr>
<tr class="even">
<td>onchange</td>
<td>The content of a form field changes.</td>
</tr>
<tr class="odd">
<td>onclick</td>
<td>The mouse clicks an object.</td>
</tr>
<tr class="even">
<td>onerror</td>
<td>An error occurs when the document or an image loads.</td>
</tr>
<tr class="odd">
<td>onfocus</td>
<td>An element gets focus.</td>
</tr>
<tr class="even">
<td>onkeydown</td>
<td>A key on the keyboard is pressed.</td>
</tr>
<tr class="odd">
<td>onkeypress</td>
<td>A key on the keyboard is pressed or held down.</td>
</tr>
<tr class="even">
<td>onkeyup</td>
<td>A key on the keyboard is released.</td>
</tr>
<tr class="odd">
<td>onload</td>
<td>A page or an image is finished loading.</td>
</tr>
<tr class="even">
<td>onmousedown</td>
<td>A mouse button is pressed.</td>
</tr>
<tr class="odd">
<td>onmousemove</td>
<td>The mouse is moved.</td>
</tr>
<tr class="even">
<td>onmouseout</td>
<td>The mouse is moved off an element.</td>
</tr>
<tr class="odd">
<td>onmouseover</td>
<td>The mouse is moved over an element.</td>
</tr>
<tr class="even">
<td>onmouseup</td>
<td>A mouse button is released.</td>
</tr>
<tr class="odd">
<td>onsubmit</td>
<td>The submit button is clicked in a form.</td>
</tr>
</tbody>
</table>
<p>可使用三种方法连接事件和函数：</p>
<p><strong>在属性中设置</strong></p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;body</span> <span class="er">onclick</span><span class="ot">=</span><span class="st">&quot;myFunction();&quot;</span><span class="kw">&gt;</span>  </span></code></pre></div>
<p><strong>连结方法与元素</strong></p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="bu">window</span><span class="op">.</span><span class="at">onclick</span> <span class="op">=</span> myFunction<span class="op">;</span>   </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co">// 或者  </span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="bu">window</span><span class="op">.</span><span class="at">onclick</span> <span class="op">=</span> <span class="kw">function</span>() &#123;  </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Do Somethine.  </span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>&#125;<span class="op">;</span>  </span></code></pre></div>
<p><strong>使用 addEventListener()</strong></p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="bu">window</span><span class="op">.</span><span class="fu">addEventListener</span>(<span class="st">&quot;click&quot;</span><span class="op">,</span> myFunction)<span class="op">;</span>   </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co">// 或者  </span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="bu">window</span><span class="op">.</span><span class="fu">addEventListener</span>(<span class="st">&quot;click&quot;</span><span class="op">,</span> <span class="kw">function</span>(e) &#123;  </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Do Something.  </span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>&#125;)<span class="op">;</span>  </span></code></pre></div>
<h3 id="js操作dom">4.3 JS操作DOM</h3>
<h4 id="dom简介">4.3.1 DOM简介</h4>
<p>DOM是操作HTML或XML的接口，通过它可以访问元素及其属性，以及对元素增删改查，可将其看作节点树。</p>
<h4 id="访问节点">4.3.2 访问节点</h4>
<ul>
<li>document.getElementsByTagName()<br />
</li>
<li>document.getElementById()<br />
</li>
<li>document.getElementsByClassName()<br />
</li>
<li>document.getElementById()<br />
</li>
<li>document.querySelectorAll()<br />
</li>
<li>xxx.getAttribute()</li>
</ul>
<h4 id="操作节点">4.3.3 操作节点</h4>
<ul>
<li>xxx.setAttribute()<br />
</li>
<li>xxx.getElementById()<br />
</li>
<li>xxx.style.xxx</li>
</ul>
<h4 id="增删元素">4.3.4 增删元素</h4>
<ul>
<li>document.createElement()<br />
</li>
<li>document.createTextNode()<br />
</li>
<li>xxx.appendChild()<br />
</li>
<li>xxx.insertBefore()<br />
</li>
<li>xxx.replaceChild()<br />
</li>
<li>xxx.removeChild()</li>
</ul>
<h3 id="网页定时器">4.4 网页定时器</h3>
<h4 id="一段时间后运行">4.4.1 一段时间后运行</h4>
<p>window.setTimeout(code,millisec);<br />
如5s后显示refresh框</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="pp">setTimeout</span>(<span class="st">&#39;refresh()&#39;</span><span class="op">,</span><span class="dv">5000</span>)<span class="op">;</span>  </span></code></pre></div>
<h4 id="每隔一段时间运行">4.4.2 每隔一段时间运行</h4>
<p>window.setInterval(code,millisec);</p>
<h4 id="清除定时器">4.4.3 清除定时器</h4>
<p>clearTimeout()<br />
clearInterval()</p>
<pre><code>var test1 = setTimeout(&#39;refresh()&#39;,5000);  
clearTimeout(test1);  </code></pre>
<h3 id="综合示例">4.5 综合示例</h3>
<div class="sourceCode" id="cb11"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">longestWord</span>( strings ) &#123;  </span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">var</span> longest <span class="op">=</span> strings[<span class="dv">0</span>]<span class="op">;</span>  </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>( i <span class="op">=</span> <span class="dv">1</span><span class="op">;</span> i <span class="op">&lt;</span> strings<span class="op">.</span><span class="at">length</span><span class="op">;</span> i<span class="op">++</span> ) &#123;  </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> ( strings[i]<span class="op">.</span><span class="at">length</span> <span class="op">&gt;</span> longest<span class="op">.</span><span class="at">length</span> ) &#123;  </span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>            longest <span class="op">=</span> strings[i]<span class="op">;</span>      </span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>        &#125;  </span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    &#125;  </span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> longest<span class="op">;</span>  </span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>&#125;  </span></code></pre></div>
<p>按钮点击时获取按钮属性值</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;button</span> <span class="er">onclick</span><span class="ot">=</span><span class="st">&quot;edit(this)&quot;</span> <span class="er">value</span><span class="ot">=</span><span class="st">&quot;abcdefg&quot;</span><span class="kw">&gt;</span>编<span class="kw">&lt;/button&gt;</span>  </span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;script&gt;</span>  </span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">function</span> <span class="fu">edit</span>(element) &#123;  </span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>        value <span class="op">=</span> element<span class="op">.</span><span class="fu">getAttribute</span>(<span class="st">&#39;value&#39;</span>)  </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>        <span class="fu">alert</span>(<span class="st">&quot;edit&quot;</span><span class="op">+</span>value)<span class="op">;</span>  </span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    &#125;<span class="op">;</span>  </span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/script&gt;</span>  </span></code></pre></div>
<h2 id="书写位置">5 书写位置</h2>
<h3 id="写在行内">5.1 写在行内</h3>
<div class="sourceCode" id="cb13"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>input type<span class="op">=</span><span class="st">&quot;button&quot;</span> value<span class="op">=</span><span class="st">&quot;按钮&quot;</span> onclick<span class="op">=</span><span class="st">&quot;alert(&#39;Hello World&#39;)&quot;</span> <span class="op">/&gt;</span>  </span></code></pre></div>
<h3 id="写在script标签中">5.2 写在script标签中</h3>
<div class="sourceCode" id="cb14"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>script<span class="op">&gt;</span>  </span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">alert</span>(<span class="st">&#39;Hello,world!&#39;</span>)<span class="op">;</span>  </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;/</span>script<span class="op">&gt;</span>  </span></code></pre></div>
<p>理论上可以放在html的任意位置，但一般放在head中，或者在body的最后，更建议写在body最后，这样运行速度快，且JS码较长时不影响阅读；如果其中涉及显示效果，建议放在head中。</p>
<h3 id="写在html以外的js代码中">5.3 写在html以外的js代码中</h3>
<div class="sourceCode" id="cb15"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>script src<span class="op">=</span><span class="st">&quot;my_script.js&quot;</span><span class="op">&gt;&lt;/</span>script<span class="op">&gt;</span>  </span></code></pre></div>
<p>（该js可供多个html使用）</p>
<h2 id="存储">6 存储</h2>
<h3 id="js全局变量">6.1 JS全局变量</h3>
<h4 id="方法">6.1.1 方法</h4>
<ul>
<li>window.aa = 'xxx'<br />
</li>
<li>在函数以外用var声明变量<br />
</li>
<li>在函数内部不使用var声明的变量</li>
</ul>
<h4 id="参考">6.1.2 参考</h4>
<p><a
href="https://blog.csdn.net/qq_27261333/article/details/69486540">JS
声明全局变量的三种方式</a></p>
<h3 id="本地存储">6.2 本地存储</h3>
<h4 id="全局变量与window.localstorage区别">6.2.1
全局变量与window.localstorage区别</h4>
<p>localStorage，有5M的限制，不受刷新页面的控制，长久保存。<br />
如果刷新页面后仍想保留用localstorage，否则用全局变量即可。</p>
<h4 id="注意">6.2.2 注意</h4>
<p>注意localStorage只能存字符串，如果想保存字典等结构，最好用JSON.stringify转成json，再保存；使用时再用JSON.parse转回来。</p>
<h4 id="参考-1">6.2.3 参考</h4>
<p><a
href="https://www.cnblogs.com/st-leslie/p/5617130.html">localStorage使用总结</a></p>
<h2 id="调试">7 调试</h2>
<h3 id="debug方法">7.1 Debug方法</h3>
<ul>
<li>弹框<br />
</li>
</ul>
<div class="sourceCode" id="cb16"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">alert</span>(<span class="st">&quot;xxxx&quot;</span>)  </span></code></pre></div>
<ul>
<li>在浏览器控制台显示信息（F12+控制台）<br />
</li>
</ul>
<div class="sourceCode" id="cb17"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="bu">console</span><span class="op">.</span><span class="fu">log</span>(<span class="st">&quot;xxxx&quot;</span>)  </span></code></pre></div>
<h3 id="测试代码块的错误">7.2 测试代码块的错误</h3>
<p>try {<br />
//可能会导致错误的代码<br />
} catch (error) {<br />
//在错误发生时怎么处理<br />
}</p>
<h2 id="程序结构设计">8 程序结构设计</h2>
<h3 id="js与html分离">8.1 js与html分离</h3>
<h4 id="原则">8.1.1 原则</h4>
<ul>
<li>如果只有少量js不需要分离<br />
</li>
<li>js上百行，整个html大几百行后，就可以考虑分离<br />
</li>
<li>分离时，除了head中包含.js文件的引用，以及在合适的地方添加类似window.onload的关联手段触发JavaScript代码的执行之外，其他形式的JavaScript混入HTML应该都可以避免。<br />
</li>
<li>引出后js文件方便复用<br />
</li>
<li>如果内容较多，可以分成多个js；也可以从逻辑方面，把相关内容整理成一个js<br />
</li>
<li>需要注意引用时有依赖关系的都需要引进来<br />
</li>
<li>再进一步，最好能把功能函数和界面元素完全分开</li>
</ul>
<h4 id="js文件写法">8.1.2 JS文件写法</h4>
<ul>
<li>把js代码从html移入js文件，去掉script 标签，直接写函数<br />
</li>
<li>在html的header中引入形如：<br />
</li>
</ul>
<div class="sourceCode" id="cb18"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;script</span> <span class="er">src</span><span class="ot">=</span><span class="st">&quot;xxx.js&quot;</span><span class="kw">&gt;&lt;/script&gt;</span>  </span></code></pre></div>
<ul>
<li>代码可完全不变，模板等也可以js中继续使用</li>
</ul>
<h3 id="模块化">8.2 模块化</h3>
<p>文件太长，或者实现多个组件时，常常把每个组件写成一个js，即模块，用export导出模块，其它js文件用到它时用import导入模块。<br />
例如：</p>
<div class="sourceCode" id="cb19"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">// 导出 export.js  </span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">export</span> <span class="kw">function</span> <span class="fu">square</span>(x) &#123;  </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x <span class="op">*</span> x<span class="op">;</span>  </span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>&#125;  </span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co">// 引用  </span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> &#123; square &#125; <span class="im">from</span> <span class="st">&#39;./export&#39;</span><span class="op">;</span>  </span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="bu">console</span><span class="op">.</span><span class="fu">log</span>(<span class="fu">square</span>(<span class="dv">11</span>))<span class="op">;</span> <span class="co">// 121  </span></span></code></pre></div>
<h2 id="问题与解答">9 问题与解答</h2>
<h3 id="问题一">9.1 问题一</h3>
<ul>
<li>问题：
<ul>
<li>script中 ‘$' 开头的函数没见在哪儿调用<br />
</li>
</ul></li>
<li>解答：
<ul>
<li>在程序开始运行时调用</li>
</ul></li>
</ul>
<h3 id="问题二">9.2 问题二</h3>
<ul>
<li>问题：
<ul>
<li>ES6是什么?<br />
</li>
</ul></li>
<li>解答：
<ul>
<li>ES6：ECMAScript6，是新版本JavaScript语言的标准,它的目标是使得JavaScript语言可以用来编写复杂的大型应用程序,成为企业级开发语言。</li>
</ul></li>
</ul>
<h3 id="问题三">9.3 问题三</h3>
<ul>
<li>问题：
<ul>
<li>=&gt;怎么用？<br />
</li>
</ul></li>
<li>解答：
<ul>
<li>ES6中新增的箭头操作符=&gt;
简化了函数的书写。操作符左边为输入的参数，而右边则是进行的操作以及返回的值，<br />
``` javascript<br />
</li>
</ul></li>
</ul>
<ol type="a">
<li>=&gt; {alert(a)}<br />
// 相当于<br />
function(a) {<br />
alert(a)<br />
}<br />
</li>
</ol>
<pre><code>  
  

### 9.4 问题四  
* 问题：  
    * 如何用map方式访问字典  
* 解答：  
``` javascript  
Object.entries(mydic).map(([key, value]) =&gt; (  
    console.log(key);  
    console.log(value);     
))  </code></pre>
<h3 id="问题五">9.5 问题五</h3>
<ul>
<li>问题：
<ul>
<li>如何对数组移位<br />
</li>
</ul></li>
<li>解答
<ul>
<li><a
href="http://www.manongjc.com/article/67847.html">JavaScript用一行代码对数组元素进行移位</a></li>
</ul></li>
</ul>
<h3 id="问题六">9.6 问题六</h3>
<ul>
<li>问题
<ul>
<li>如何在 javascript 中使用 import 引入其它 js<br />
</li>
</ul></li>
<li>解答
<ul>
<li>方法一：在html文件中使用link方式引入js文件<br />
</li>
<li>方法二：包含js程序段时加type='module'。这样js程序被认为是一个模块，从而可以在程序段中引入其它模块。</li>
</ul></li>
</ul>
<h3 id="问题七">9.7 问题七</h3>
<ul>
<li>问题
<ul>
<li>如何引入css文件<br />
</li>
</ul></li>
<li>解答
<ul>
<li>可利用模块的相对路径<br />
</li>
</ul>
<pre><code>import &#39;bootstrap/dist/css/bootstrap.min.css&#39;;  </code></pre></li>
</ul>
<h3 id="问题八">9.8 问题八</h3>
<ul>
<li>问题
<ul>
<li>如何跳转到其它<br />
</li>
</ul></li>
<li>解答
<ul>
<li>window.open('地址')</li>
</ul></li>
</ul>
<h2 id="参考-2">10 参考</h2>
<p><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript">MSN
Web DOCS</a><br />
<a
href="https://blog.csdn.net/u011781521/article/details/72780622">select
onChange事件</a><br />
<a
href="https://www.cnblogs.com/jifeng/archive/2010/04/08/1707528.html">javascript操作SELECT中option大全</a><br />
<a
href="https://www.cnblogs.com/deepalley/p/12919280.html">页面加载时自动执行（加载）js的几种方法</a><br />
<a href="https://www.w3school.com.cn/js/js_operators.asp">JavaScript
运算符</a></p>
]]></content>
      <tags>
        <tag>前端</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title>04_JQuery和Ajax</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%89%8D%E7%AB%AF%E5%85%A5%E9%97%A8/04_JQuery%E5%92%8CAjax/</url>
    <content><![CDATA[<h1 id="jquery和ajax">JQuery和Ajax</h1>
<p>#前端</p>
<h2 id="原理">1 原理</h2>
<ul>
<li>Ajax（阿甲克斯）提供了异步更新的机制，使用客户端与服务器间交换数据而非整个页面文档，实现页面的局部更新。<br />
</li>
<li>jQuery是一个框架（可以当成一个库），封装了一些常用方法，使得JS与Ajax更方便使用。</li>
</ul>
<h2 id="jquery">2 JQuery</h2>
<p>JQuery是一个非常常用的JS库，可以直接使用网上的js，也可以下载到自己的服务端。</p>
<h4 id="直接下载">2.1.1 直接下载</h4>
<p>下载地址：<a
href="https://jquery.com/download/">https://jquery.com/download/</a><br />
点开不压缩版本，即可看到其具体实现，将js文件保存到本地，然后在网页中引入即可</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;script</span> <span class="er">src</span><span class="ot">=</span><span class="st">&quot;pathtoyourjs/jquery-3.2.1.min.js&quot;</span><span class="kw">&gt;&lt;/script&gt;</span>  </span></code></pre></div>
<h4 id="下载源码可切换到历史版本">2.1.2
下载源码（可切换到历史版本）</h4>
<p>或者从git下载</p>
<pre><code>$ git clone https://github.com/jquery/jquery.git  </code></pre>
<h3 id="ajax">2.2 AJAX</h3>
<p>AJAX是JQuery工具集中的一个工具，用于远程请求，以实现局部刷新。</p>
<h2 id="示例">3 示例</h2>
<h3 id="示例一">3.1 示例一</h3>
<div class="sourceCode" id="cb3"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;!DOCTYPE </span>html<span class="dt">&gt;</span>  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;html&gt;</span>  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;head&gt;</span>  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;script</span> <span class="er">src</span><span class="ot">=</span><span class="st">&quot;https://cdn.staticfile.org/jquery/1.10.2/jquery.min.js&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;/script&gt;</span>  </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;script&gt;</span>  </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">$</span>(<span class="bu">document</span>)<span class="op">.</span><span class="fu">ready</span>(<span class="kw">function</span>()&#123;  </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span class="fu">$</span>(<span class="st">&quot;button&quot;</span>)<span class="op">.</span><span class="fu">click</span>(<span class="kw">function</span>()&#123;  </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>            $<span class="op">.</span><span class="fu">ajax</span>(&#123;<span class="dt">url</span><span class="op">:</span><span class="st">&quot;demo_test.html&quot;</span><span class="op">,</span>  </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>                    <span class="dt">data</span><span class="op">:</span> &#123; <span class="dt">name</span><span class="op">:</span> <span class="st">&quot;John&quot;</span><span class="op">,</span> <span class="dt">time</span><span class="op">:</span> <span class="st">&quot;2pm&quot;</span> &#125;<span class="op">,</span>  </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>                    <span class="dt">success</span><span class="op">:</span><span class="kw">function</span>(result)&#123;  </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>                <span class="fu">$</span>(<span class="st">&quot;#div1&quot;</span>)<span class="op">.</span><span class="fu">html</span>(result)<span class="op">;</span>  </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>            &#125;&#125;)<span class="op">;</span>  </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        &#125;)<span class="op">;</span>  </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    &#125;)<span class="op">;</span>  </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;/script&gt;</span>  </span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/head&gt;</span>  </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;body&gt;</span>  </span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;div</span> <span class="er">id</span><span class="ot">=</span><span class="st">&quot;div1&quot;</span><span class="kw">&gt;&lt;h2&gt;</span>使用 jQuery AJAX 修改文本内容<span class="kw">&lt;/h2&gt;&lt;/div&gt;</span>  </span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;button&gt;</span>获取其他内容<span class="kw">&lt;/button&gt;</span>  </span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/body&gt;</span>  </span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/html&gt;</span>  </span></code></pre></div>
<h2 id="常用方法">4 常用方法</h2>
<ul>
<li>javascrippt中$(function()
<ul>
<li>这是JQuery语法，$表示JQuery对象。$(function()
表示当页面加载完毕时执行这个函数。</li>
</ul></li>
</ul>
<h2 id="参考">5 参考</h2>
<p><a
href="https://blog.csdn.net/qq_42247220/article/details/85837494">JavaScript，jQuery与Ajax的关系</a><br />
<a href="https://www.runoob.com/jquery/ajax-ajax.html">jQuery ajax()
方法</a><br />
<a
href="https://www.w3school.com.cn/jquery/jquery_ajax_get_post.asp">jQuery
- AJAX get() 和 post() 方法</a></p>
]]></content>
      <tags>
        <tag>前端</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title>05_CSS</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%89%8D%E7%AB%AF%E5%85%A5%E9%97%A8/05_CSS/</url>
    <content><![CDATA[<p>#前端</p>
<h2 id="简介">1 简介</h2>
<h4 id="什么是css">1.1.1 什么是CSS</h4>
<ul>
<li>用途：设置显示风格<br />
</li>
<li>英文：Cascading Style Sheets (CSS)<br />
</li>
<li>语法：它有自身的语法</li>
</ul>
<h4 id="优点">1.1.2 优点</h4>
<ul>
<li>准确：更准确地控制显示<br />
</li>
<li>省事：一个设置多处使用<br />
</li>
<li>适配：在不修改HTML的情况下适配不同显示设备</li>
</ul>
<p>同样内容，不同风格，看起来有多么不同：<br />
<img src="/attachments_2022/Pasted%20image%2020220111171119.png"
alt="Pasted%20image%2020220111171119.png" /></p>
<h3 id="基本概念">1.2 基本概念</h3>
<ul>
<li>继承：子控件继承父控制属性<br />
</li>
<li>冲突：当设置发生冲突时，优先使用权重更大的设置
<ul>
<li>一般用中括号定义形如：<br />
</li>
</ul>
<pre><code>p &#123; line-height: 1.2em; &#125;  [0] [0] [1]  </code></pre></li>
</ul>
<h4 id="基本语法">1.2.1 基本语法</h4>
<p>CSS每一条由两部分组成：<br />
* 第一部分是 selector<br />
* 定义需要被设置的元素。<br />
* 此处可设置多个元素，用逗号分隔<br />
* selector可支持三种类型：<br />
* 选择符（如p），<br />
* 元素的类名（以点开头）<br />
* 元素的 id（以井号开头）<br />
* 用星号定义其它所有情况<br />
* 第二部分是 declaration<br />
* 定义设置的具体规则<br />
* 使用大括号定义<br />
* 每一部分由键值对成，各部分之间使用分号分隔<br />
* 可包含换行</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode css"><code class="sourceCode css"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>h1 &#123; <span class="kw">color</span>: <span class="cn">green</span><span class="op">;</span> &#125;  </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>li em &#123; <span class="kw">color</span>: <span class="cn">red</span><span class="op">;</span> &#125;  <span class="er">// 其中li是em的父控件  </span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="pp">#sleestak</span> &#123; <span class="kw">color</span>: <span class="cn">olive</span><span class="op">;</span> &#125;   </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">.abc</span> &#123; <span class="kw">color</span>: <span class="cn">olive</span><span class="op">;</span> &#125;  </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>p<span class="op">,</span> ul<span class="op">,</span> td<span class="op">,</span> th &#123; <span class="kw">color</span>: <span class="cn">navy</span><span class="op">;</span> &#125;  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>p  &#123; <span class="kw">font-size</span>: <span class="dv">large</span><span class="op">;</span> <span class="kw">font-family</span>: <span class="dv">sans-serif</span><span class="op">;</span> &#125;  </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="op">*</span> &#123; <span class="kw">border</span>: <span class="dv">1</span><span class="dt">px</span> <span class="dv">solid</span> <span class="cn">gray</span><span class="op">;</span> &#125;  </span></code></pre></div>
<h4 id="设置风格的三种方法">1.2.2 设置风格的三种方法</h4>
<h6 id="方法一-推荐">方法一 （推荐）</h6>
<p>定义在css文件中，被html引用，形如：</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;link</span> <span class="er">rel</span><span class="ot">=</span><span class="st">&quot;stylesheet&quot;</span> <span class="er">type</span><span class="ot">=</span><span class="st">&quot;text/css&quot;</span> <span class="er">href</span><span class="ot">=</span><span class="st">&quot;</span><span class="er">&lt;</span><span class="st">!--swig￼0--&gt;&quot;</span><span class="kw">/&gt;</span>  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>或:  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;style&gt;</span>      </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="im">@import</span> <span class="fu">url(</span><span class="st">external.css</span><span class="fu">)</span><span class="op">;</span>  </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/style&gt;</span>  </span></code></pre></div>
<h6 id="方法二">方法二</h6>
<p>定义在style标签中，放在html的head里。</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;head&gt;</span>  </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;style&gt;</span>  </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        <span class="co">/* style rules go here */</span>     </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;/style&gt;</span>  </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/head&gt;</span>  </span></code></pre></div>
<h6 id="方法三不推荐">方法三（不推荐）</h6>
<p>定义为标签的style属性。</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;h1</span> <span class="er">style</span><span class="ot">=</span><span class="st">&quot;color: red&quot;</span><span class="kw">&gt;</span>Introduction<span class="kw">&lt;/h1&gt;</span>  </span></code></pre></div>
<h4 id="如何查询使用方法">1.2.3 如何查询使用方法</h4>
<p>那本书的第三部分每一章都详述了一组控件对应的风格，可通过关键字在书中速查。</p>
<h2 id="我想了解的">2 我想了解的</h2>
<h4 id="它能做什么">2.1.1 它能做什么</h4>
<h4 id="如何使用">2.1.2 如何使用</h4>
<h4 id="其它问题">2.1.3 其它问题</h4>
<h6 id="是否需要编译怎么编译">是否需要编译，怎么编译</h6>
<h6 id="如何调试">如何调试</h6>
<h2 id="参考">3 参考</h2>
<p><a
href="https://www.cnblogs.com/Roc-Atlantis/p/9462326.html">css常用属性整理</a></p>
]]></content>
      <tags>
        <tag>前端</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title>06_bootstrap</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%89%8D%E7%AB%AF%E5%85%A5%E9%97%A8/06_bootstrap/</url>
    <content><![CDATA[<h2 id="需求">1 需求</h2>
<ul>
<li>代码简单<br />
</li>
<li>界面不丑<br />
</li>
<li>学习成本低</li>
</ul>
<h2 id="简介">2 简介</h2>
<p>Bootstrap_是Twitter推出的前端开发的开源工具包。<br />
具体控件长什么样，全靠设class。<br />
bootstrap都是基于jquery的。<br />
bootstrap主要需要引用css和js两个文件。</p>
<h2 id="具体用法">3 具体用法</h2>
<h3 id="blog博客">3.1 Blog博客</h3>
<h3 id="chart画图">3.2 Chart画图</h3>
<p><a
href="https://chartjs.bootcss.com/docs/">https://chartjs.bootcss.com/docs/</a></p>
<h3 id="table表">3.3 Table表</h3>
<p><a
href="https://getbootstrap.com/docs/5.1/content/tables/">https://getbootstrap.com/docs/5.1/content/tables/</a></p>
<h3 id="slidebar侧栏">3.4 SlideBar侧栏</h3>
<h3 id="model弹框">3.5 Model弹框</h3>
<p>关键字Modal</p>
<p>模态框（Modal）是覆盖在父窗体上的子窗体。</p>
<p>引例程为bootstrap5，请注意与js版本匹配<br />
具体方法：https://www.runoob.com/bootstrap5/bootstrap5-modal.htmll</p>
<p>需要在调出它的控件中设置形如</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;button</span> <span class="er">type</span><span class="ot">=</span><span class="st">&quot;button&quot;</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;btn btn-primary&quot;</span> <span class="er">data-bs-toggle</span><span class="ot">=</span><span class="st">&quot;modal&quot;</span> <span class="er">data-bs-target</span><span class="ot">=</span><span class="st">&quot;#myModal&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>xxx  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/button&gt;</span>  </span></code></pre></div>
<p>框中内容形如：</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;div</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;modal&quot;</span> <span class="er">id</span><span class="ot">=</span><span class="st">&quot;myModal&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;div</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;modal-dialog&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        <span class="kw">&lt;div</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;modal-content&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>            <span class="co">&lt;!-- 模态框头部 --&gt;</span>  </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>            <span class="kw">&lt;div</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;modal-header&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>                <span class="kw">&lt;h4</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;modal-title&quot;</span><span class="kw">&gt;</span>模态框标题<span class="kw">&lt;/h4&gt;</span>  </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>                <span class="kw">&lt;button</span> <span class="er">type</span><span class="ot">=</span><span class="st">&quot;button&quot;</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;btn-close&quot;</span> <span class="er">data-bs-dismiss</span><span class="ot">=</span><span class="st">&quot;modal&quot;</span><span class="kw">&gt;&lt;/button&gt;</span>  </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>            <span class="kw">&lt;/div&gt;</span>  </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>            <span class="co">&lt;!-- 模态框内容 --&gt;</span>  </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>            <span class="kw">&lt;div</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;modal-body&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>                模态框内容..  </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>            <span class="kw">&lt;/div&gt;</span>  </span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>            <span class="co">&lt;!-- 模态框底部 --&gt;</span>  </span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>            <span class="kw">&lt;div</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;modal-footer&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>                <span class="kw">&lt;button</span> <span class="er">type</span><span class="ot">=</span><span class="st">&quot;button&quot;</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;btn btn-danger&quot;</span> <span class="er">data-bs-dismiss</span><span class="ot">=</span><span class="st">&quot;modal&quot;</span><span class="kw">&gt;</span>关闭<span class="kw">&lt;/button&gt;</span>  </span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>            <span class="kw">&lt;/div&gt;</span>  </span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        <span class="kw">&lt;/div&gt;</span>  </span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;/div&gt;</span>  </span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/div&gt;</span>  </span></code></pre></div>
<p>注意要将class设置为模态框modal<br />
关模态框</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>$(&#39;#myModal&#39;).modal(&#39;hide&#39;)；  </span></code></pre></div>
<p>显示框</p>
<pre><code>$(&#39;#myModal&#39;).modal(&#39;show&#39;);  </code></pre>
<h3 id="bootstrap-table">3.6 bootstrap-table</h3>
<p>官方文档：
[https://bootstrap-table.com/][https://bootstrap-table.com/]<br />
它之所以要从url取数据是因为，在分页的情况下，每次只取其中N条数据</p>
<ul>
<li>table 带参<a
href="https://www.jb51.net/article/102131.htm">bootstrap
table配置参数例子</a><br />
Table用法<br />
</li>
</ul>
<div class="sourceCode" id="cb5"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;!doctype </span>html<span class="dt">&gt;</span>  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;html</span> <span class="er">lang</span><span class="ot">=</span><span class="st">&quot;en&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;head&gt;</span>  </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;meta</span> <span class="er">name</span><span class="ot">=</span><span class="st">&quot;viewport&quot;</span> <span class="er">content</span><span class="ot">=</span><span class="st">&quot;width=device-width&quot;</span> <span class="kw">/&gt;</span>  </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;title&gt;</span>BootStrap Table使用<span class="kw">&lt;/title&gt;</span>  </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--    @*1、Jquery组件引用*@--&gt;</span>  </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;script</span> <span class="er">src</span><span class="ot">=</span><span class="st">&quot;https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js&quot;</span><span class="kw">&gt;&lt;/script&gt;</span>  </span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--    @*2、bootstrap组件引用*@--&gt;</span>  </span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;link</span> <span class="er">rel</span><span class="ot">=</span><span class="st">&quot;stylesheet&quot;</span> <span class="er">href</span><span class="ot">=</span><span class="st">&quot;https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap.min.css&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;script</span> <span class="er">src</span><span class="ot">=</span><span class="st">&quot;https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/js/bootstrap.min.js&quot;</span><span class="kw">&gt;&lt;/script&gt;</span>  </span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--    @*3、bootstrap table组件以及中文包的引用*@--&gt;</span>  </span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;link</span> <span class="er">rel</span><span class="ot">=</span><span class="st">&quot;stylesheet&quot;</span> <span class="er">href</span><span class="ot">=</span><span class="st">&quot;https://unpkg.com/bootstrap-table@1.15.3/dist/bootstrap-table.min.css&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;script</span> <span class="er">src</span><span class="ot">=</span><span class="st">&quot;https://unpkg.com/bootstrap-table@1.15.3/dist/bootstrap-table.min.js&quot;</span><span class="kw">&gt;&lt;/script&gt;</span>  </span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;script</span> <span class="er">src</span><span class="ot">=</span><span class="st">&quot;https://unpkg.com/bootstrap-table@1.15.3/dist/locale/bootstrap-table-zh-CN.min.js&quot;</span><span class="kw">&gt;&lt;/script&gt;</span>  </span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/head&gt;</span>  </span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;body&gt;</span>  </span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--&lt;!</span><span class="er">--</span><span class="co">swig￼0--&gt;</span>--&gt;  </span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;div</span> <span class="er">style</span><span class="ot">=</span><span class="st">&quot;width: 80%;margin: 0 auto&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;table</span> <span class="er">id</span><span class="ot">=</span><span class="st">&quot;table&quot;</span> <span class="kw">&gt;&lt;/table&gt;</span>  </span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/div&gt;</span>  </span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--&lt;!</span><span class="er">--</span><span class="co">swig￼1--&gt;</span>--&gt;  </span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--&lt;!</span><span class="er">--</span><span class="co">swig￼2--&gt;</span>--&gt;  </span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;script</span><span class="ot"> type=</span><span class="st">&quot;text/javascript&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    <span class="fu">$</span>(<span class="kw">function</span> () &#123;  </span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>        <span class="fu">$</span>(<span class="st">&#39;#table&#39;</span>)<span class="op">.</span><span class="fu">bootstrapTable</span>(&#123;  </span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>            <span class="dt">url</span><span class="op">:</span> <span class="st">&#39;/jsondata&#39;</span><span class="op">,</span>  <span class="co">// 请求数据源的路由  </span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>            <span class="dt">dataType</span><span class="op">:</span> <span class="st">&quot;json&quot;</span><span class="op">,</span>  </span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>            <span class="dt">pagination</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span> <span class="co">//前端处理分页  </span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>            <span class="dt">singleSelect</span><span class="op">:</span> <span class="kw">false</span><span class="op">,</span><span class="co">//是否只能单选  </span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>            <span class="dt">search</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span> <span class="co">//显示搜索框，此搜索是客户端搜索，不会进服务端，所以，个人感觉意义不大  </span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>            <span class="dt">toolbar</span><span class="op">:</span> <span class="st">&#39;#toolbar&#39;</span><span class="op">,</span> <span class="co">//工具按钮用哪个容器  </span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>            <span class="dt">striped</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span> <span class="co">//是否显示行间隔色  </span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>            <span class="dt">cache</span><span class="op">:</span> <span class="kw">false</span><span class="op">,</span> <span class="co">//是否使用缓存，默认为true，所以一般情况下需要设置一下这个属性（*）  </span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>            <span class="dt">pageNumber</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span> <span class="co">//初始化加载第10页，默认第一页  </span></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>            <span class="dt">pageSize</span><span class="op">:</span> <span class="dv">10</span><span class="op">,</span> <span class="co">//每页的记录行数（*）  </span></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>            <span class="dt">pageList</span><span class="op">:</span> [<span class="dv">10</span><span class="op">,</span> <span class="dv">20</span><span class="op">,</span> <span class="dv">50</span><span class="op">,</span> <span class="dv">100</span>]<span class="op">,</span> <span class="co">//可供选择的每页的行数（*）  </span></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>            <span class="dt">strictSearch</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span><span class="co">//设置为 true启用 全匹配搜索，false为模糊搜索  </span></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>            <span class="dt">showColumns</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span> <span class="co">//显示内容列下拉框  </span></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>            <span class="dt">showRefresh</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span> <span class="co">//显示刷新按钮  </span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>            <span class="dt">minimumCountColumns</span><span class="op">:</span> <span class="dv">2</span><span class="op">,</span> <span class="co">//当列数小于此值时，将隐藏内容列下拉框  </span></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>            <span class="dt">clickToSelect</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span> <span class="co">//设置true， 将在点击某行时，自动勾选rediobox 和 checkbox  </span></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>            <span class="dt">height</span><span class="op">:</span> <span class="dv">500</span><span class="op">,</span> <span class="co">//表格高度，如果没有设置height属性，表格自动根据记录条数决定表格高度#&#125;  </span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>            <span class="dt">uniqueId</span><span class="op">:</span> <span class="st">&quot;id&quot;</span><span class="op">,</span> <span class="co">//每一行的唯一标识，一般为主键列  </span></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>            <span class="dt">showToggle</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span> <span class="co">//是否显示详细视图和列表视图的切换按钮  </span></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>            <span class="dt">cardView</span><span class="op">:</span> <span class="kw">false</span><span class="op">,</span> <span class="co">//是否显示详细视图  </span></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>            <span class="dt">detailView</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span> <span class="co">//是否显示父子表，设置为 true 可以显示详细页面模式,在每行最前边显示+号#&#125;  </span></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>            <span class="dt">sidePagination</span><span class="op">:</span> <span class="st">&quot;server&quot;</span><span class="op">,</span> <span class="co">//分页方式：client客户端分页，server服务端分页（*）  </span></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>            <span class="dt">columns</span><span class="op">:</span> [&#123;  <span class="co">//定义表头,这个表头必须定义,下边field后边跟的字段名字必须与后端传递的字段名字相同.如:id、name、price  </span></span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a><span class="co">// 　　　　　　　　　　　　　　　　跟后端的字段名id  name price是完全一样的.  </span></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>                <span class="dt">field</span><span class="op">:</span> <span class="st">&#39;id&#39;</span><span class="op">,</span>  </span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>                <span class="dt">title</span><span class="op">:</span> <span class="st">&#39;序号&#39;</span><span class="op">,</span>  </span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>                <span class="dt">align</span><span class="op">:</span> <span class="st">&#39;center&#39;</span><span class="op">,</span>  <span class="co">//对齐方式，居中  </span></span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>                <span class="dt">width</span><span class="op">:</span> <span class="st">&#39;200px&#39;</span>  <span class="co">// 可以写各种样式#&#125;  </span></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>            &#125;<span class="op">,</span> &#123;  </span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>                <span class="dt">field</span><span class="op">:</span> <span class="st">&#39;name&#39;</span><span class="op">,</span>  </span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>                <span class="dt">title</span><span class="op">:</span> <span class="st">&#39;名称&#39;</span><span class="op">,</span>  </span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>                <span class="dt">align</span><span class="op">:</span> <span class="st">&#39;center&#39;</span>  </span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>            &#125;<span class="op">,</span> &#123;  </span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>                <span class="dt">field</span><span class="op">:</span> <span class="st">&#39;price&#39;</span><span class="op">,</span>  </span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>                <span class="dt">title</span><span class="op">:</span> <span class="st">&#39;价格&#39;</span><span class="op">,</span>  </span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>                <span class="dt">align</span><span class="op">:</span> <span class="st">&#39;center&#39;</span><span class="op">,</span>  </span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>            &#125;<span class="op">,</span> &#123;  </span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>                <span class="dt">title</span><span class="op">:</span> <span class="st">&#39;操作&#39;</span><span class="op">,</span>  </span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>                <span class="dt">field</span><span class="op">:</span> <span class="st">&#39;id&#39;</span><span class="op">,</span>  </span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>                <span class="dt">align</span><span class="op">:</span> <span class="st">&#39;center&#39;</span><span class="op">,</span>  </span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>                <span class="dt">formatter</span><span class="op">:</span> <span class="kw">function</span> (value<span class="op">,</span> row<span class="op">,</span> index) &#123;  </span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>                    <span class="kw">var</span> e <span class="op">=</span> <span class="st">&#39;&lt;a href=&quot;#&quot; mce_href=&quot;#&quot; onclick=&quot;edit(</span><span class="sc">\&#39;</span><span class="st">&#39;</span> <span class="op">+</span> row<span class="op">.</span><span class="at">id</span> <span class="op">+</span> <span class="st">&#39;</span><span class="sc">\&#39;</span><span class="st">)&quot;&gt;编辑&lt;/a&gt; &#39;</span><span class="op">;</span>  <span class="co">//row.id为每行的id  </span></span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>                    <span class="kw">var</span> d <span class="op">=</span> <span class="st">&#39;&lt;a href=&quot;#&quot; mce_href=&quot;#&quot; onclick=&quot;del(</span><span class="sc">\&#39;</span><span class="st">&#39;</span> <span class="op">+</span> row<span class="op">.</span><span class="at">id</span> <span class="op">+</span> <span class="st">&#39;</span><span class="sc">\&#39;</span><span class="st">)&quot;&gt;删除&lt;/a&gt; &#39;</span><span class="op">;</span>  </span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">return</span> e <span class="op">+</span> d<span class="op">;</span>  </span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>                &#125;  </span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>            &#125;  </span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>            ]<span class="op">,</span>  </span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>        &#125;)<span class="op">;</span>  </span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a>    &#125;)<span class="op">;</span>  </span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/script&gt;</span>  </span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/body&gt;</span>  </span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/html&gt;</span>  </span></code></pre></div>
<p>还可以通过以下方法再加参数（它与"url:"平级）：</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>                    queryParams<span class="op">:</span> <span class="kw">function</span> (params) &#123;  </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>                         params<span class="op">.</span><span class="at">search</span> <span class="op">=</span> <span class="bu">document</span><span class="op">.</span><span class="fu">getElementById</span>(<span class="st">&#39;dept_text&#39;</span>)<span class="op">.</span><span class="at">value</span><span class="op">;</span>  </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>                         params<span class="op">.</span><span class="at">test</span> <span class="op">=</span> <span class="st">&#39;888&#39;</span>  </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>                         <span class="cf">return</span> params<span class="op">;</span>  </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>                    &#125;<span class="op">,</span>  </span></code></pre></div>
<h2 id="示例">4 示例</h2>
<p>https://getbootstrap.com/docs/5.1/examples/</p>
<h2 id="风格">5 风格</h2>
<p>https://themes.getbootstrap.com/<br />
一般都卖49$</p>
<h3 id="加一个看着差不多的边框">5.1 加一个看着差不多的边框</h3>
<div class="sourceCode" id="cb7"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;div</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;container mt-3&quot;</span><span class="kw">&gt;</span>  </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>内容  </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;div&gt;</span>  </span></code></pre></div>
<h2 id="边框">6 边框</h2>
<p>影响元素之间的间距是可以通过style的margin或padding属性来实现，在bootstrap中使用
m-x 和 p-x 来设置：</p>
<table>
<thead>
<tr class="header">
<th>class名</th>
<th>等价的style</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>m-0</td>
<td>等价于{margin:0 !important}</td>
</tr>
<tr class="even">
<td>m-1</td>
<td>等价于{margin:0.25rem !important}</td>
</tr>
<tr class="odd">
<td>m-2</td>
<td>等价于{margin:0.5rem !important}</td>
</tr>
<tr class="even">
<td>m-3</td>
<td>等价于{margin:1rem !important}</td>
</tr>
<tr class="odd">
<td>m-4</td>
<td>等价于{margin:1.5rem !important}</td>
</tr>
<tr class="even">
<td>m-5</td>
<td>等价于{margin:3rem !important}</td>
</tr>
<tr class="odd">
<td>m-auto</td>
<td>等价于{margin:auto !important}</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th>class名</th>
<th>等价的style</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>p-0</td>
<td>等价于{padding:0 !important}</td>
</tr>
<tr class="even">
<td>p-1</td>
<td>等价于{padding:0.25rem !important}</td>
</tr>
<tr class="odd">
<td>p-2</td>
<td>等价于{padding:0.5rem !important}</td>
</tr>
<tr class="even">
<td>p-3</td>
<td>等价于{padding:1rem !important}</td>
</tr>
<tr class="odd">
<td>p-4</td>
<td>等价于{padding:1.5rem !important}</td>
</tr>
<tr class="even">
<td>p-5</td>
<td>等价于{padding:3rem !important}</td>
</tr>
<tr class="odd">
<td>p-auto</td>
<td>等价于{padding:auto !important}</td>
</tr>
</tbody>
</table>
<p>如需要调整具体的上下左右，可使用mt-n,mb-n,mr-n,ml-n，padding同理。</p>
<h2 id="栅栏布局">7 栅栏布局</h2>
<table>
<thead>
<tr class="header">
<th>class名</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>.col-xs-*</td>
<td>超小屏幕 手机 (&lt;768px)</td>
</tr>
<tr class="even">
<td>.col-sm-*</td>
<td>小屏幕 平板 (≥768px)</td>
</tr>
<tr class="odd">
<td>.col-md-*</td>
<td>中等屏幕 桌面显示器 (≥992px)</td>
</tr>
<tr class="even">
<td>.col-lg-*</td>
<td>大屏幕 大桌面显示器 (≥1200px)</td>
</tr>
</tbody>
</table>
<h2 id="bootstrap的flex布局">8 BootStrap的Flex布局</h2>
<p>一般不直接设定style，而使用class方法设置。它的名称和style名字很类似。<br />
https://www.runoob.com/bootstrap4/bootstrap4-flex.html</p>
<h2 id="其它说明">9 其它说明</h2>
<ul>
<li>Bootstrap 插件全部依赖 jQuery<br />
</li>
<li>Grunt用于编译</li>
</ul>
<h2 id="问题与解答">10 问题与解答</h2>
<h3 id="问题一">10.1 问题一</h3>
<ul>
<li>问题：
<ul>
<li>bootstrap皮肤是买的么<br />
</li>
</ul></li>
<li>解答：
<ul>
<li><strong><em>??</em></strong></li>
</ul></li>
</ul>
<h2 id="参考">11 参考</h2>
<ul>
<li><a
href="https://www.runoob.com/bootstrap/bootstrap-glyphicons.html">bootstrap用法</a><br />
</li>
<li><a href="https://m.runoob.com/bootstrap5/">bootstrap5</a></li>
</ul>
]]></content>
      <tags>
        <tag>前端</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title>07_React</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%89%8D%E7%AB%AF%E5%85%A5%E9%97%A8/07_React/</url>
    <content><![CDATA[<h2 id="相关术语">1 相关术语</h2>
<ul>
<li>React: 用于构建用户界面的 JavaScript 库<br />
</li>
<li>node: 通过JavaScript语言开发web服务端<br />
</li>
<li>npm：相当于python的pip工具，pip用于安装python相关的各种工具，npm用于Node.JS相关的各种工具<br />
</li>
<li>jsx：JSX是一种 JavaScript
的语法扩展，用于react中，既不是字符串也不是
HTML，有点像模板，形如：<br />
</li>
</ul>
<div class="sourceCode" id="cb1"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>div<span class="op">&gt;</span>&#123;arr&#125;<span class="op">&lt;/</span>div<span class="op">&gt;</span>  </span></code></pre></div>
<h2 id="react与只有js的区别">2 react与只有JS的区别</h2>
<p>单纯的JS是直接操作和构造html。<br />
react是数据驱动界面，它通过虚拟的html生成标签。<br />
react的基础逻辑是数据由上向下单向流动。<br />
虚拟的html有点类似于模板，html中其中可嵌入变量和程序段。</p>
<p>举个例子，之前提交表单时将表单中每个元素取值转给server，也就是从html中取值；使用react后，当按下按钮时，一般调用某个react函数，由函数内部通过数据构造请求，以及处理请求的结果，再进一步渲染控件，而非整个刷新整个界面。</p>
<h2 id="基本概念">3 基本概念</h2>
<h3 id="组件">3.1 组件</h3>
<p>组件component是react的核心概念，一般功能都通过组件实现。<br />
组件名首字符必须大写，否则被认为是标签。<br />
react中有两种组件：函数组件（Functional Components) 和类组件（Class
Components）。</p>
<h4 id="函数组件">3.1.1 函数组件</h4>
<div class="sourceCode" id="cb2"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> React <span class="im">from</span> <span class="st">&#39;react&#39;</span><span class="op">;</span>  </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ReactDOM <span class="im">from</span> <span class="st">&#39;react-dom&#39;</span><span class="op">;</span>  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">MyFuncComp</span>() &#123;  </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="op">&lt;</span>h1<span class="op">&gt;</span>组件内容<span class="op">&lt;/</span>h1<span class="op">&gt;</span>  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>&#125;  </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>ReactDOM<span class="op">.</span><span class="fu">render</span>(  </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="op">&lt;</span>div<span class="op">&gt;</span>  </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="op">&lt;</span>MyFuncComp<span class="op">/&gt;</span>  </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  <span class="op">&lt;/</span>div<span class="op">&gt;,</span>   </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="bu">document</span><span class="op">.</span><span class="fu">getElementById</span>(<span class="st">&quot;root&quot;</span>)  </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>)<span class="op">;</span>  </span></code></pre></div>
<h4 id="类组件">3.1.2 类组件</h4>
<p>继承自Component，且至少实现render函数；constructor为其构造函数，参数props用于接收外部传来的属性。</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> React<span class="op">,</span> &#123; Component &#125; <span class="im">from</span> <span class="st">&#39;react&#39;</span>  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">export</span> <span class="im">default</span> <span class="kw">class</span> MyClassComp <span class="kw">extends</span> Component &#123;  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">constructor</span>(props) &#123;  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">super</span>(props)  </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">console</span><span class="op">.</span><span class="fu">log</span>(props)  </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">this</span><span class="op">.</span><span class="at">state</span> <span class="op">=</span> &#123;  </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">initData</span><span class="op">:</span> <span class="kw">this</span><span class="op">.</span><span class="at">props</span><span class="op">.</span><span class="at">time</span>  </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    &#125;  </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  &#125;  </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">render</span>() &#123;  </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">&lt;</span>h1<span class="op">&gt;</span>组件内容<span class="op">&lt;/</span>h1<span class="op">&gt;</span>  </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  &#125;  </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>&#125;  </span></code></pre></div>
<h4 id="组件状态">3.1.3 组件状态</h4>
<p>组件可以维护自己的数据，可将状态看作组件的属性。<br />
具体实现，如上例中的 this.state={xxx}。<br />
不能直接改变state，否则无法引发界面刷新，需要使用setState函数：</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">this</span><span class="op">.</span><span class="fu">setState</span>(&#123;  </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>        <span class="dt">initData</span><span class="op">:</span> <span class="kw">this</span><span class="op">.</span><span class="at">state</span><span class="op">.</span><span class="at">initData</span> <span class="op">-</span> <span class="dv">1</span>  </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>      &#125;)<span class="op">;</span>  </span></code></pre></div>
<h4 id="bind函数">3.1.4 Bind函数</h4>
<p>ES5之前，函数自动bind，而在ES6之后，需要手动bind函数，比如：回调函数需要在构造里bind，形如：</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>  <span class="fu">render</span>() &#123;  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (  </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>      <span class="op">&lt;</span>input type<span class="op">=</span><span class="st">&quot;button&quot;</span> value<span class="op">=</span><span class="st">&quot;Log&quot;</span> onClick<span class="op">=</span>&#123;<span class="kw">this</span><span class="op">.</span><span class="at">logMessage</span><span class="op">.</span><span class="fu">bind</span>(<span class="kw">this</span>)&#125; <span class="op">/&gt;</span>  </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    )<span class="op">;</span>  </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  &#125;  </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">//或者用箭头方式bind  </span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">//&lt;input type=&quot;button&quot; value=&quot;Log&quot; onClick=&#123;() =&gt; this.logMessage()&#125; /&gt;  </span></span></code></pre></div>
<h4 id="控件的key">3.1.5 控件的Key</h4>
<p>key 可以帮助 React
高效识别哪些元素发生了改变，哪些元素没有发生改变。最好给每个控件指定key，比如：</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">render</span> () &#123;  </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (  </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="op">&lt;</span>ul<span class="op">&gt;</span>  </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>      &#123;<span class="kw">this</span><span class="op">.</span><span class="at">state</span><span class="op">.</span><span class="at">todoItems</span><span class="op">.</span><span class="fu">map</span>((&#123;task<span class="op">,</span> uid&#125;) <span class="kw">=&gt;</span> &#123;  </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="op">&lt;</span>li key<span class="op">=</span>&#123;uid&#125;<span class="op">&gt;</span>&#123;task&#125;<span class="op">&lt;/</span>li<span class="op">&gt;</span>  </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>      &#125;)&#125;  </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">&lt;/</span>ul<span class="op">&gt;</span>  </span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  )  </span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>&#125;  </span></code></pre></div>
<p>这使得每个控件得以区分，控制刷新，提升效率……</p>
<h4 id="组件之间通讯">3.1.6 组件之间通讯</h4>
<p>react主导思想是数据只能从父控件向子控件流动，兄弟组件间不能通讯；数据只能被组件内部及其子组件使用。父子组间通讯，常使用方法。<br />
* 通过设置属性props把父组件数据传给子组件<br />
*
通过设置属性props把父组件句柄传给子组件，使子组件可调父组件中的方法（使用时注意bind）</p>
<h2 id="生命周期">4 生命周期</h2>
<p>详见<a
href="https://1lib.domains/?redirectUrl=/">详解React生命周期(包括react16最新版)</a></p>
<h2 id="第一个程序">5 第一个程序</h2>
<h3 id="新建一个项目">5.1 新建一个项目</h3>
<pre class="shell"><code>$ create-react-app frontend  
$ cd frontend  </code></pre>
<h3 id="写代码">5.2 写代码</h3>
<h4 id="react简单示例">5.2.1 react简单示例</h4>
<p>删除src/下所有文件，并编辑src/index.js如下:</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> React <span class="im">from</span> <span class="st">&#39;react&#39;</span>  </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ReactDOM <span class="im">from</span> <span class="st">&#39;react-dom&#39;</span>  </span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> App <span class="kw">extends</span> React<span class="op">.</span><span class="at">Component</span> &#123;  </span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">render</span>() &#123;  </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (  </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>            <span class="op">&lt;</span>div className<span class="op">=</span><span class="st">&quot;container&quot;</span><span class="op">&gt;</span>  </span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>                <span class="op">&lt;</span>h1 className<span class="op">=</span><span class="st">&quot;center-align&quot;</span><span class="op">&gt;</span>  </span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>                    盒装一流弊<span class="op">&lt;</span>br<span class="op">/&gt;</span>  </span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>                    <span class="op">&lt;</span>span className<span class="op">=</span><span class="st">&quot;waves-effect waves-light btn&quot;</span><span class="op">&gt;</span>  </span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>                        <span class="op">&lt;</span>i className<span class="op">=</span><span class="st">&quot;material-icons right&quot;</span><span class="op">&gt;</span>cloud<span class="op">&lt;/</span>i<span class="op">&gt;</span>您说的都对  </span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>                    <span class="op">&lt;/</span>span<span class="op">&gt;</span>  </span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>                <span class="op">&lt;/</span>h1<span class="op">&gt;</span>  </span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>            <span class="op">&lt;/</span>div<span class="op">&gt;</span>  </span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        )<span class="op">;</span>  </span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    &#125;     </span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>&#125;  </span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>ReactDOM<span class="op">.</span><span class="fu">render</span>(<span class="op">&lt;</span>App <span class="op">/&gt;,</span> <span class="bu">document</span><span class="op">.</span><span class="fu">getElementById</span>(<span class="st">&#39;root&#39;</span>))  </span></code></pre></div>
<h4 id="react-bootstrap示例">5.2.2 react-bootstrap示例</h4>
<div class="sourceCode" id="cb9"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> React <span class="im">from</span> <span class="st">&#39;react&#39;</span><span class="op">;</span>  </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ReactDOM <span class="im">from</span> <span class="st">&#39;react-dom&#39;</span>  </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> &#123;Button<span class="op">,</span>Form&#125; <span class="im">from</span> <span class="st">&#39;react-bootstrap&#39;</span>  </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FormInstance <span class="kw">extends</span> React<span class="op">.</span><span class="at">Component</span> &#123;  </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">render</span>() &#123;  </span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span>(  </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>            <span class="op">&lt;</span>html<span class="op">&gt;</span>  </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>            <span class="op">&lt;</span>Form<span class="op">.</span><span class="at">Group</span> className<span class="op">=</span><span class="st">&quot;mb-3&quot;</span> controlId<span class="op">=</span><span class="st">&quot;formBasicEmail&quot;</span><span class="op">&gt;</span>  </span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>                <span class="op">&lt;</span>Form<span class="op">.</span><span class="at">Label</span><span class="op">&gt;</span>Email address<span class="op">&lt;/</span>Form<span class="op">.</span><span class="at">Label</span><span class="op">&gt;</span>  </span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>                <span class="op">&lt;</span>Form<span class="op">.</span><span class="at">Control</span> type<span class="op">=</span><span class="st">&quot;email&quot;</span> placeholder<span class="op">=</span><span class="st">&quot;Enter email&quot;</span> <span class="op">/&gt;</span>  </span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>                <span class="op">&lt;</span>Form<span class="op">.</span><span class="at">Text</span> className<span class="op">=</span><span class="st">&quot;text-muted&quot;</span><span class="op">&gt;</span>  </span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>                We<span class="st">&#39;ll never share your email with anyone else.  </span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>                <span class="op">&lt;/</span>Form<span class="op">.</span><span class="at">Text</span><span class="op">&gt;</span>  </span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>            <span class="op">&lt;/</span>Form<span class="op">.</span><span class="at">Group</span><span class="op">&gt;</span>  </span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>            <span class="op">&lt;</span>Form<span class="op">.</span><span class="at">Group</span> className<span class="op">=</span><span class="st">&quot;mb-3&quot;</span> controlId<span class="op">=</span><span class="st">&quot;formBasicPassword&quot;</span><span class="op">&gt;</span>  </span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>                <span class="op">&lt;</span>Form<span class="op">.</span><span class="at">Label</span><span class="op">&gt;</span>Password<span class="op">&lt;/</span>Form<span class="op">.</span><span class="at">Label</span><span class="op">&gt;</span>  </span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>                <span class="op">&lt;</span>Form<span class="op">.</span><span class="at">Control</span> type<span class="op">=</span><span class="st">&quot;password&quot;</span> placeholder<span class="op">=</span><span class="st">&quot;Password&quot;</span> <span class="op">/&gt;</span>  </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>            <span class="op">&lt;/</span>Form<span class="op">.</span><span class="at">Group</span><span class="op">&gt;</span>  </span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>            <span class="op">&lt;</span>Form<span class="op">.</span><span class="at">Group</span> className<span class="op">=</span><span class="st">&quot;mb-3&quot;</span> controlId<span class="op">=</span><span class="st">&quot;formBasicCheckbox&quot;</span><span class="op">&gt;</span>  </span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>                <span class="op">&lt;</span>Form<span class="op">.</span><span class="at">Check</span> type<span class="op">=</span><span class="st">&quot;checkbox&quot;</span> label<span class="op">=</span><span class="st">&quot;Check me out&quot;</span> <span class="op">/&gt;</span>  </span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>            <span class="op">&lt;/</span>Form<span class="op">.</span><span class="at">Group</span><span class="op">&gt;</span>  </span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>            <span class="op">&lt;</span>Button variant<span class="op">=</span><span class="st">&quot;primary&quot;</span> type<span class="op">=</span><span class="st">&quot;submit&quot;</span><span class="op">&gt;</span>  </span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>                Submit  </span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>            <span class="op">&lt;/</span>Button<span class="op">&gt;</span>  </span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>            <span class="op">&lt;/</span>html<span class="op">&gt;</span>  </span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>        )  </span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>    &#125;  </span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>&#125;<span class="op">;</span>  </span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>ReactDOM<span class="op">.</span><span class="fu">render</span>(<span class="op">&lt;</span>FormInstance <span class="op">/&gt;,</span> <span class="bu">document</span><span class="op">.</span><span class="fu">getElementById</span>(<span class="st">&#39;root&#39;</span>))  </span></code></pre></div>
<h3 id="在浏览器中运行">5.3 在浏览器中运行</h3>
<p>启动浏览器看运行效果</p>
<pre class="shell"><code>$ sudo npm start  </code></pre>
<h3 id="编译">5.4 编译</h3>
<pre class="shell"><code>$ npm run build  </code></pre>
<p>此时build目录下生成index.html及static/js/，把它们复制到你的flask项目里，调用index.html即可看到用react生成的网页。</p>
<h2 id="使用-vscode-调试-react-应用">6 使用 VSCode 调试 React 应用</h2>
<ul>
<li>安装Debugger for Chrome插件<br />
</li>
<li>从vscode左侧调出运行与调式面板<br />
</li>
<li>设置配置launch.js，将端口改为3000<br />
</li>
<li>在终端输入npm start，即可运行调试<br />
</li>
<li>此时在浏览器中可看到界面，修改界面不需要再次运行，即可在浏览器中同步看到效果</li>
</ul>
<h2 id="reactbootstrap">7 react+bootstrap</h2>
<pre><code>$ sudo npm install react-bootstrap bootstrap@3.3.7  </code></pre>
<p>安装好后，就可以在react中直接使用了，如：</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> &#123; Navbar<span class="op">,</span> Jumbotron<span class="op">,</span> Button &#125; <span class="im">from</span> <span class="st">&#39;react-bootstrap&#39;</span><span class="op">;</span>  </span></code></pre></div>
<h2 id="简单范例">8 简单范例</h2>
<pre><code>$ git clone https://github.com/lingjiawen/react_bootstrap_demo.git  
$ cd react_bootstrap_demo  
$ npm install  
$ npm run dev  </code></pre>
<p>此时，可以在浏览器打开localhost:8080，看到示例</p>
<h2 id="编译前端代码">9 编译前端代码</h2>
<h4 id="为什么编译">9.1.1 为什么编译</h4>
<p>即使用babel这样的库可以在运行时编译html，但会遇到以下问题：<br />
* 在js中引入文件，如“import xxx from
yyy”时，如果yyy是编译过的xxx可能找不到。<br />
* yyy往往是多个js文件的集合，无法单独使用<br />
* 自己的js中可能使用了多个库，都放进项目里占空间大且乱</p>
<h4 id="如何编译">9.1.2 如何编译</h4>
<pre><code>$ npm run build  </code></pre>
<p>编译后在build目录下生成html和js文件</p>
<h2 id="问题与解决">10 问题与解决</h2>
<h3 id="问题一">10.1 问题一</h3>
<ul>
<li>问题：npm start时报错：code: 'MODULE_NOT_FOUND'<br />
</li>
<li>分析：这是由于npm和node版本不一致引起的<br />
</li>
<li>解决方法：升级npm<br />
</li>
</ul>
<pre class="shell"><code>$ sudo n 6.3 # 降级node版本  
$ sudo npm install npm -g # 升级npm版本  </code></pre>
<h3 id="问题二">10.2 问题二</h3>
<ul>
<li>问题：npm升级了多个软件包后由于版本不匹配而无法工作<br />
</li>
<li>分析：冲突异致，由于npm安装了很多软件，导致使用apt
remove删除npm后，冲突依然存在；当npm不能正常运行时，也无法管理被它安装的软件包。<br />
</li>
<li>解决方法：删除npm以及所有的缓存和相关安装包，它们的位置如下：<br />
</li>
</ul>
<pre><code>HOME/.npm/*  
/usr/local/lib/node_modules/  
/usr/local/bin/npm  
/usr/local/bin/node  </code></pre>
<h3 id="问题三">10.3 问题三</h3>
<ul>
<li>问题：console.log() 在哪显示<br />
</li>
<li>解决：在浏览器F12，控制台里显示</li>
</ul>
<h3 id="问题四">10.4 问题四</h3>
<ul>
<li>问题：访问本机提供服务的端口时报错：No
'Access-Control-Allow-Origin'跨域问题<br />
</li>
<li>分析：跨域问题<br />
</li>
<li>解决方法：在flask里设置一下CORS，形如：<br />
</li>
</ul>
<div class="sourceCode" id="cb18"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> flask_cors <span class="im">import</span> CORS  </span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>app <span class="op">=</span> <span class="fu">Flask</span>(__name__)  </span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="fu">CORS</span>(app)  </span></code></pre></div>
<h3 id="问题五">10.5 问题五</h3>
<ul>
<li>问题：什么是脚手架<br />
</li>
<li>回答：一个工作，用于快速地构建开发环境</li>
</ul>
<h3 id="问题六">10.6 问题六</h3>
<ul>
<li>问题：如何一次渲染多个组件<br />
</li>
<li>回答：<br />
</li>
</ul>
<div class="sourceCode" id="cb19"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">render</span>() &#123;  </span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="op">&lt;</span>div<span class="op">&gt;</span>  </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>        <span class="op">&lt;</span>MyComponent1 <span class="op">/&gt;</span>  </span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>        <span class="op">&lt;</span>MyComponent2  <span class="op">/&gt;</span>  </span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>        <span class="op">&lt;</span>MyComponent3 <span class="op">/&gt;</span>   </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">&lt;/</span>div<span class="op">&gt;</span>  </span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>&#125;  </span></code></pre></div>
<h3 id="问题七">10.7 问题七</h3>
<ul>
<li>问题：如何调试JSX<br />
</li>
<li>回答：JSX中可通过{}加入简单代码段</li>
</ul>
<h3 id="问题八">10.8 问题八</h3>
<ul>
<li>问题：用 create-react-app 创建的项目太大，无法保存<br />
</li>
<li>回答：去掉node-modules目录，只保存其它即可</li>
</ul>
<h3 id="问题九">10.9 问题九</h3>
<ul>
<li>问题: js文件不能立即更新<br />
</li>
<li>回答: 浏览器-&gt;F12-&gt;网络面板-&gt;停用缓存</li>
</ul>
<h3 id="问题十">10.10 问题十</h3>
<p>问题：不编译是否可以使用react<br />
回答：在网站中加入少量react代码时，可使用bebel工具，直接在js中使用jsx语法，引入以下包：</p>
<pre><code>&lt;script src=&quot;https://unpkg.com/babel-standalone@6/babel.min.js&quot;&gt;&lt;/script&gt;  </code></pre>
<p>详见：<a
href="https://react.docschina.org/docs/add-react-to-a-website.html">在网站中添加
React</a></p>
<h3 id="问题十一">10.11 问题十一</h3>
<p>问题：如何实现同时使用jsx和import<br />
回答：script type只能设置一个值，用以下方法同时作为module和bebal</p>
<pre><code>&lt;script data-plugins=&quot;transform-es2015-modules-umd&quot; type=&quot;text/babel&quot;&gt;  </code></pre>
<h2 id="参考">11 参考</h2>
<p><a href="https://zhuanlan.zhihu.com/p/30583784">使用 VSCode 调试
React 应用</a><br />
<a href="https://react-bootstrap.github.io/">React
Bootstrap官网</a><br />
<a href="https://www.jianshu.com/p/ae482813b791">React
简单介绍</a><br />
<a href="https://react-bootstrap.github.io/forms/overview/">React
Bootstrap Get Start</a><br />
<a
href="https://blog.csdn.net/nxcniuxiangchen/article/details/122014958">详解React组件生命周期</a></p>
<h2 id="发现">12 发现</h2>
<p>它可以用不同的class描绘不同的控件<br />
setstate会触发渲染<br />
控制台会打出错误信息</p>
<h2 id="访问远程数据">13 访问远程数据</h2>
<pre><code>$ npm isntall axios --save  </code></pre>
<h2 id="复杂示例">14 复杂示例</h2>
<p><a
href="https://blog.csdn.net/qq_32766999/article/details/82855600">react
利用select编写省市级三级联动</a></p>
]]></content>
      <tags>
        <tag>前端</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title>比特币挖矿——入门</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%8C%BA%E5%9D%97%E9%93%BE/%E6%AF%94%E7%89%B9%E5%B8%81%E6%8C%96%E7%9F%BF%E2%80%94%E2%80%94%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h1 id="比特币挖矿入门">比特币挖矿——入门</h1>
<p>#区块链</p>
<p>说比特币之前，先来说说虚拟货币，以及虚拟币的价值。比如说，百度文库文下载章需要付点数，自己上传文件被别人下载可以得到点数，点数就是虚拟货币，如果没有点数，又能想下文档，可以用钱兑换，这就是虚拟货币与真实货币的关系。至于一个点数研究值多少钱，又怎么给一篇文档定价，一般会借鉴类似资源的定价，使用的人多了，虚拟货币的价值也逐渐趋于稳定。</p>
<p>比特币是最流行的虚拟货币，它是基于P2P的数字货币，在互联网的某处，每10分钟产生13个币，至于新产生的币归谁，就看谁挖到了（也就是挖矿，具体算法后面说明）。一般大家最大的疑问是：算法产生的一串数就能对应真金白银吗？来看看货币的价值：钱是一张纸，印这张纸花多少钱是它的自然属性，它能当多少钱花是它的社会属性，我们更关注它能当多少钱花。钱的使用价值是以发行方的信用作担保的，也就是说有国家在，就不用担心你的钱明天变成废纸。那谁给比特币谁作担保呢？上学的时候学：说一个事物，要么是主观的，要么是客观的，现在说，介于主观和客观之间叫互为主体(intersubjective)，即：相信的人多了，它就存在了。随着比特币越来越多的被用在交易中，互联网上东西以它估值，它的价值也越来越稳定，它就有了价值。比特币的思想是去中心化，它基于算法产生，因此也并不随着发行它的组织灭亡而灭亡。</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-3f319956035e027f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>比特币是2009年中本聪发明。根据算法，每210,000个区块，比特币的区块奖励就会减半。简单的说，前段两年10分钟产生25个比特币，现在10分钟产生13个。它的总量是递增的，但递增的速度是逐步减小的，到2140年就不再增长了，还有100多年。那这每分钟产生的13个币归谁所有呢？比特币其实就是一堆算法所生成方程的特解。特解是指方程组所能得到无限个（其实比特币是有限个）解中的一组。而每一个特解都能解开方程并且是唯一的。挖矿的过程就是通过庞大的计算量不断的去寻求这个方程组的特解，这个方程组被设计成了只有
2100 万个特解，所以比特币的上限就是 2100
万。这里的计算就是所谓挖矿。</p>
<p>一开始没人认同它的价值，也没那么多人挖。但随着它的发展，8年涨了221万倍。越来越多人加入挖矿的行列。开始用PC挖，后来拿显卡的GPU挖，一个机器挂十几个显卡，现在用专业矿机，减低了功耗，又提升了性能。狼越来越多，肉越来越少。计算也越来越复杂，你的机器还没算出来呢，10分钟已经过去了，于是又有人发明了组团挖，把运算量拆成小块，分配到各个机器，于是众多机器组成了矿池。如能挖到，则按算力分成。现在能挖到的，要么是组织一帮散户挖，要么是自己的矿机集群。再拿PC挖，基本是不可能了。<br />
下面我们就来看看矿池。</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-3e13826e1325dc6c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<ol type="1">
<li>比特币体系：<br />
是由无数个节点矿池组成，这些节点矿池是单独存在的，同时是相互连接的，所有数据都是同步的。<br />
</li>
<li>矿池：<br />
一般的矿池由多台服务器组成，负责分配任务，集成结果，由矿主配置。并与控制板交互。<br />
</li>
<li>控制板：<br />
控制板与矿池服务器相连通过网线连接，控制多台矿机，需要矿工配置（在设置界面中输入服务器地址，用户名等）。据说一个树莓派加一个USB-HUB可以控制20-60台矿机。控制板上的程序也是预先写好的，与指定矿机匹配，无需矿工修改程序。<br />
</li>
<li>矿机：<br />
以运算为主，本身系统简单，矿工无需关注。</li>
</ol>
<p>如果有少量机器的话，就做矿工，参加别人的矿池，拿分成。如果有大量机器则自营矿厂，矿厂也分大小，小规模的矿场可以与其它矿厂共享任务，大的矿厂自成体系。后面文章会讲到实现的具体方法。</p>
<p>现在，区块链是个热闹技术，还被联系到自由平等，很高大上的样子，先看看为什么说区块链经济带来新的商业文明？比如说我们要买一个东西，可能将原来买东西的经验做为参考；如果之前没买过此类东西，可能向周围的人咨询；如果周围的人也不知道，可能会根据品牌选择。一个产品一家公司一般会用比较长的时间和投入来构建大家对它的信任。区块链中的信任是基于算法和无法被篡改的性质，它根据历史数据构造信任网络（历史数据是大家都能看到的，且不能被篡改的），从而减小了大小机构构造的商业信任的能力差距。这有点像淘宝的或者脉脉的评价系统，只要达到一定体量，恶意数据将被淹没在更大量的真实数据之中。从这个角度讲，它的确是重新构建了信任体系：从权威专制变成了群众投票。</p>
<p>它的主要优点是透明和去中心化。比如淘宝的评价在淘宝服务器上，其实是有可能被管理员或者黑客修改的。但区块链的数据存储在每个P2P的节点上（去中心化），不可能全给改了。因而增加了信息的透明度和真实性。像卖东西，做公证，都开始实验性地使用该技术。另外，比特币还增进了交易的全球化；区块链技术本身也给交易提供了保障，减少了运营成本。还可以提高公共事业的透明度等等。</p>
<p>它的缺点是，在效率上低于中心化的实现方式。因此，中心化已经做得很的领域，就无需改为去中心化；它的应用场合可能正是那些不那么权威，却有众多群众可以举手的领域。</p>
<p>2017年9月4日下午,央行等七部门联合发布公告,正式叫停包括ICO在内的“代币发行融资”。公告发布之日起,
代币发行融资应当立即停止，现有者应清退。中国的代币产业因而受到了严重的打击，不过比特币现在的价钱也不低，因此仍有很多人在挖。另外，区块链技术也可能是之后一个重要的技术。</p>
]]></content>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title>比特币挖矿——区块链技术</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%8C%BA%E5%9D%97%E9%93%BE/%E6%AF%94%E7%89%B9%E5%B8%81%E6%8C%96%E7%9F%BF%E2%80%94%E2%80%94%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<h1 id="比特币挖矿区块链技术">比特币挖矿——区块链技术</h1>
<p>#区块链</p>
<h2 id="说明">1. 说明</h2>
<p>区块链具有数据运行公开、不可篡改、可溯源、跨国际、去中心化的特点。因此越来越多地被应用在各个领域。区块链主要技术包括：分布式数据存储、点对点传输、共识机制、加密算法，将在下面一一介绍。</p>
<h2 id="点对点传输">2. 点对点传输</h2>
<p>点对点技术（peer-to-peer，
简称P2P）又称对等互联网络技术，它依赖网络中参与者的计算能力和带宽，而不是把依赖都聚集在较少的几台服务器上。最典型的应用就是电驴。在这里它提供了最底层的去中心化支持。</p>
<h2 id="分布式数据存储">3. 分布式数据存储</h2>
<p>先看看对区块链最直观的感觉：当第一次运行比特币钱包时，会下载很多数据，2017年10月有150G左右，且还在不断增加。数据存储在data/blocks目录下，blk*.dat这就是区块block。<br />
第一个问题是：为什么建矿池需要下载这么多数据？区块链本质上是一个去中心化的数据库，我们下载的是比特币所有数据所组成的数据库，因此很大。去中心化的数据库，数据并不是保存在某一个服务器上，而且在P2P的每个节点上都需要保存一份。对于中心化的数据库，数据库可能被宿主或者黑客篡改，因而可靠性变差。而去中心化数据库就像一个公共帐本，所有人都能查看，但没人能私自修改以往数据，因为它不可能修改分散在其他人机器上的数据库。在某个数据与其它数据库不一致时，则以大多数一致的为准，这就是所谓的“共识机制”。<br />
随着交易增加，钱包还会不断变大。太大之后，会用到硬分叉技术。也就是启用一个全新的网络并让所有的用户大规模迁移。</p>
<h2 id="区块链blockchain">4. 区块链（blockchain）</h2>
<p>区块链是一串使用密码学方法相关联产生的数据块，每一个数据块（block）中包含了一次比特币网络交易的信息，用于验证其信息的有效性和生成下一个区块（根据一个生成下一生，构成链chain）。<br />
所谓挖矿就是计算出一个满足规则的随机数，从而获得本次记帐权，发出本轮需要记录的数据，然后向全网广播，每个节点都会将收到交易信息，并记录到一个区块中，然后链接到现有的区块链上。</p>
<h2 id="算法">5. 算法</h2>
<p>哈希算法是一个字符串到一个（有限位数的）数的映射。<br />
Block的算法是根据上一个block的hash值，寻找满足某些hash结果的字符串，简单的说就是不停地拼凑字符串，计算SHA256哈希值（碰撞哈希值），直到找到产生合适的哈希的字符串，这个字符串就是解。具体公式如下：<br />
SHA256(SHA256(version + prev_hash + merkle_root + ntime + nbits + x ))
&lt; TARGET<br />
挖矿就是求解上述方程中的x。<br />
其中，version是block的版本，prev_hash是上一个block的hash值，merkle_root是需要写入的交易记录的merkle树的值（merkle树被应用在了交易的存储上，其基本原理就是将叶子节点（每笔交易的hash）两两配对做哈希运算生成父节点，不断迭代这一过程最终生成唯一的根节点merkle
root），ntime是更新时间，nbits是当前难度，TARGET根据当前难度求出。x的范围是0~2^32，这就是个求解x的问题，一旦你找到了x，你就可以广播一个新的block。<br />
TARGET越小，解出x的难度就越大，每产生2016个block(约14天)，网络会根据这段时间产生新block的平均间隔调整之后的TARGET，以保证每10分钟产生一次的速度。因此，随着网上算力的不断增加，计算难度会越来越大，矿也越来越难挖了。<br />
如果两人同时挖到，block
chain会出现分叉，客户端在众多分支中找到符合当前难度且最长的。</p>
<h2 id="安全机制">6. 安全机制</h2>
<h4 id="私钥">1) 私钥</h4>
<p>私钥是形式如下的一段字符串：<br />
5KYZdUEo39z3FPrtuX2QbbwGnNP5zTd7yyr2SC1j299sBCnWjss。只要是正确支持比特币协议的应用都可以把这段字符串识别为私钥，转换成公钥，再转换为地址，如果对应的地址上面有比特币，就可以使用这个私钥花费上面的比特币。一般被盗指的都是私钥被盗。</p>
<h4 id="公私">2) 公私</h4>
<p>公钥是由私钥生成的，一个私钥经过椭圆曲线变换之后会生成一个65个byte的数组，一般我们会看到这样形式的一个公钥：04a34b99f22c790c4e36b2b3c2c35a36db06226e41c692fc82b8b56ac1c540c5bd5b8dec5235a0fa8722476c7709c02559e3aa73aa03918ba2d492eea75abea235<br />
操作是用私钥签名的，只有对应的公钥才能解开，地址也是从公钥生成的，这样就可以验证操作是不是属于这个地址的。</p>
<h4 id="地址">3) 地址</h4>
<p>地址是由公钥产生的，生成的过程是，先对公钥做一次SHA256，对得到的结果做一次RIPEMD160,再从结果中取20个byte的数组，这个得到的数组就是得到的hash160，形如：9a1c78a507689f6f54b847ad1cef1e614ee23f1e</p>
<h4 id="流程">4) 流程</h4>
<p>从你这里发出的数据都是由私钥加密的（包括挖到矿的广播，转帐等等），传数据的时候也会传一个公钥，通过这个公钥解密。如果公/私钥能对上，就可以证明你的身份。公钥是大家可见的，而私钥被盗，那么别人就可以用你的身份交易了。具体加解密和密钥导入导出方法请见后续“钱包”篇。</p>
<h2 id="挖矿与深度学习">7. 挖矿与深度学习</h2>
<h4 id="组织算力">1) 组织算力</h4>
<p>挖矿和深度学习都需要组织算力。在运算量大时都需要构建集群，拆分计算，集成结果等等。</p>
<h4 id="硬件基础">2) 硬件基础</h4>
<p>挖矿和深度学习都是数学模型计算，它们对于大规模学习的解决方案都是：显卡，FPGA，ASIC。当然功能并不完全相同，深度学习需要矩阵乘法，卷积等基本运算，而挖矿主要是hash碰撞。都需要并行性、多线程和高内存带宽等特性，虽然功能相近，但硬件还是有不少的差别。硬件说明详见后续“控制器与矿机”篇。</p>
]]></content>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title>比特币挖矿——建立Kafka&amp;ZooKeeper集群</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%8C%BA%E5%9D%97%E9%93%BE/%E6%AF%94%E7%89%B9%E5%B8%81%E6%8C%96%E7%9F%BF%E2%80%94%E2%80%94%E5%BB%BA%E7%AB%8BKafka&amp;ZooKeeper%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<h1
id="比特币挖矿建立kafkazookeeper集群">比特币挖矿——建立Kafka&amp;ZooKeeper集群</h1>
<p>#区块链</p>
<h2 id="介绍">1. 介绍</h2>
<p>采用ZooKeeper+Kafka的方式建立集群，主要支持了消息传递和负载均衡，常见的一些文档，有的是概念较多，没有实际操作；有的只有命令，不知其原理。这里就结合集群矿池来说说它的具体应用场景，原理，以及具体实现。</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-4757f714e2ad8c0c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<h2 id="举例">2. 举例</h2>
<p>先举个例子，比如一个理发店：<br />
一开始只有一个理发师，洗剪吹都由他一个人负责，那么只能一个客人做完全套（同一台机器上操作各个步骤），再给下一个客人服务。<br />
之后,
又来了几个理发师，每个人负责接待一个客人（多台服务器，每台负责单个流程）。<br />
再后来理发店又扩大，人多了（多台不同用途的机器），老板发现如果把工作细分为：洗(A)剪(B)吹(C)三部分，这三部分的工作量和难度都不同，可以安排专人专职，以节约人力成本。三个模块工作量不同，需要的人数也不同，如上图所示，洗2人(2台机器)，剪3人(3台机器)，吹2人(2台机器)。Data为库房(数据服务器)，每个人都可能去库房存取工具。<br />
显然，A与B并不是一一对应的关系。洗发之后，应该分配剪发员执行下一步骤。让洗发员找每个剪发员查询状态显然不是明智的作法，而且，此时可能每个剪发员都不空闲，A还有接下来的工作，也不能一接等在那儿。<br />
于是就引入了另一个角色：接待员broker，当某个A的工作做完全后，则向broker的topic发一个消息，告诉它本层已完成，需要下一层处理，此时A是发送者producer，中介是broker（它也位于一台机器上，这里没用方框画出来），如果某个B空闲时，也会连接到topic，等待下一个工作（如上图所示），此时B是接受者customer。B和C的通讯也是一样，不过它们间通讯时B是producer，C是customer。<br />
Broker是Kafka的一个实例，broker按功能不同又可建立多个topic，topic里又可包含多个partition，每个partition都可保证先入先出，但partition之间不保证顺序。多个broker又可以做成Kafka群组。综上，Kafka是传送消息的工具，或者说是一套机制，它实现了消息创建，存取等工作。</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-7034f4aead21f267.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>在producer，customer，broker的背后又有着ZooKeeper的支持，它就好像理发店的排班员，在这里主要负责负载均衡，将工作平均分配给customer，避免产生闲的闲死忙的忙死这种问题。ZooKeeper也可以有多个，即使某一个死掉，整个系统仍可正常运转。<br />
从此处可见Kafka和Zookeeper上跑的不是执行具体工作的程序（洗剪吹），它们的角色是提供通讯和负载均衡的协调者。具体洗剪吹运行在哪个服务器上是另外的工作．</p>
<h2 id="配置过程">3. 配置过程</h2>
<h4 id="配置zookeeper">1) 配置ZooKeeper</h4>
<p>在一台或几台机器上配置和运行ZooKeeper服务。</p>
<h4 id="配置kafka">2) 配置Kafka</h4>
<p>配置Kafka的 broker<br />
创建topic及partition。</p>
<h4 id="修改程序">3) 修改程序</h4>
<p>在程序中分别加入对producer和consumer的调用，以传递信息。</p>
<h4 id="说明">4) 说明</h4>
<p>通过以上步骤，程序就可以在不同的机器通过简单地调用函数传递消息了。上述的ZooKeeper，Kafka，程序可以运行在同一台机器上，可以分别在运行在不同机器上。</p>
<h2 id="zookeeper">4. ZooKeeper</h2>
<h4 id="介绍-1">1) 介绍</h4>
<p>ZooKeeper是一个快速、高可靠、容错、分布式的协调服务。</p>
<h4 id="配置">2) 配置</h4>
<pre><code>$ cp conf/zoo_sample.cfg conf/zoo.cfg  
$ vi conf/zoo.cfg #修改配置文件  </code></pre>
<p>配置文件中server*是zookeeper服务器之间交互用的，它使得一台服务器死机时，另外一台，能快速转换为主zookeeper服务器<br />
dataDir是数据目录，clientPort为ZooKepper端口号，一般不用改</p>
<pre><code>$ ./startserver.sh start # 启动zooKeeper服务  </code></pre>
<h3 id="调试工具">3) 调试工具</h3>
<pre><code>$ bin/zkCli.sh -server 127.0.0.1:2181 #client端连上看一下  
$ jps #查看进程, 其中QuorumPeerMain是zooKeeper的主进程  
$ netstat -nap|grep 2181 # 查看配置文件中设置的端口是否打开  </code></pre>
<p>正常显示为：</p>
<pre><code>tcp  0   0   0.0.0.0:2181   0.0.0.0:*   LISTEN   10737/java  </code></pre>
<h2 id="kafka">5. Kafka</h2>
<h4 id="介绍-2">1) 介绍</h4>
<p>Kafka是一个分布式的流数据处理平台。</p>
<h4 id="配置文件">2) 配置文件</h4>
<pre><code>$ vi config/server.properties  
这是默认的配置文件，以下几项比较重要  
broker.id=1 # broker的标识，具有唯一性  
port=9092 # kafka服务的端口号  
log.dirs=/tmp/kafka-logs # 存储log的目录，交互的信息就存在该目录下  
zookeeper.connect=127.0.0.1:2181 # zookeeper服务器的IP和端口,多个用逗号分开  
host.name=127.0.0.1 # 运行本程序机器的IP地址，在btcpool的cfg中指定  
delete.topic.enable=true #建议加这句，否则删topic时候特别麻烦  
message.max.bytes=20000000 # 支持大数据msg，否则传输时将丢弃大数据块  
replica.fetch.max.bytes=30000000 # 同上     </code></pre>
<h4 id="启动服务">3) 启动服务</h4>
<pre><code>$ bin/kafka-server-start.sh config/server.properties  </code></pre>
<h4 id="创建供btcpool使用的topic">4) 创建供btcpool使用的topic</h4>
<p>需要先启后台服务，再创建topic，我这里使用了一个本机的zookeeper，如果有多个，请使用逗号分隔。</p>
<pre><code>$ ./bin/kafka-topics.sh --create --topic test --zookeeper 127.0.0.1:2181 --replication-factor 1 --partitions 1  </code></pre>
<h4 id="相关工具">5) 相关工具</h4>
<ol type="i">
<li>查看topic<br />
</li>
</ol>
<pre><code>$ ./bin/kafka-topics.sh --describe --zookeeper 127.0.0.1:2181 #查看topic  </code></pre>
<ol start="2" type="i">
<li>查看kafka服务<br />
</li>
</ol>
<pre><code>$ netstat -nap|grep 9092  </code></pre>
<p>正常运行时返回</p>
<pre><code>tcp  0   0 127.0.0.1:9092   0.0.0.0:*   LISTEN   24961/java  </code></pre>
<h4 id="删除topic">6) 删除topic</h4>
<p>先删除kafka存储目录（server.properties文件log.dirs配置，默认为"/tmp/kafka-logs"）相关topic目录。注意partition的数据都存在这个目录中。</p>
<pre><code>./bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --topic test -delete  </code></pre>
<p>如果在server.properties中未指定delete.topic.enable=true，则只会做一个删除标记，不会真正删除，删除需要在zookeeper服务器上，通过zkCli.sh连进去删除。</p>
<h4 id="常出现的错误">7) 常出现的错误</h4>
<ol type="i">
<li>kafka-server-start.sh报错找不到主机，然后直接退出<br />
解决方法，在配置文件中设置主机<br />
host.name=主机名<br />
主机名通过命令hostname查看<br />
</li>
<li>kafka-server-start.sh虽不退出，但不停报错java.lang.NoClassDefFoundError:
Could not initialize class kafka.network.RequestChannel$<br />
这也是主机名相关的问题，在/etc/hosts的最后填加一句<br />
127.0.0.1 主机名<br />
主机名通过命令hostname查看</li>
</ol>
<h4 id="测试kafka">8) 测试kafka</h4>
<p>正常情况下，producer上发的，consumer都应该能收到<br />
i. 创建</p>
<pre><code>bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test  </code></pre>
<ol start="2" type="i">
<li>接收<br />
</li>
</ol>
<pre><code>bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning  </code></pre>
<ol start="3" type="i">
<li>发送<br />
</li>
</ol>
<pre><code>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test  </code></pre>
<p>如果topic没建立，producer会自动建立top，但参数可能与你想要的不同．</p>
<h2 id="c程序调用kafka发消息">6. C程序调用kafka发消息</h2>
<p>一般使用librdkafka库，下载库源码编译，其中example目录中的程序也可以用于测试。</p>
<h2 id="参考">7. 参考</h2>
<h4 id="apache-kafka-分布式消息队列中间件安装与配置">1) Apache Kafka
分布式消息队列中间件安装与配置</h4>
<p>http://blog.csdn.net/wangjia184/article/details/37921183</p>
<h4 id="kafkazookeeper原理与应用场景介绍">2)
Kafka&amp;Zookeeper原理与应用场景介绍</h4>
<p>https://wenku.baidu.com/view/a47389116ad97f192279168884868762caaebbd4.html</p>
]]></content>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title>比特币挖矿——控制器与矿机</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%8C%BA%E5%9D%97%E9%93%BE/%E6%AF%94%E7%89%B9%E5%B8%81%E6%8C%96%E7%9F%BF%E2%80%94%E2%80%94%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B8%8E%E7%9F%BF%E6%9C%BA/</url>
    <content><![CDATA[<h1 id="比特币挖矿控制器与矿机">比特币挖矿——控制器与矿机</h1>
<p>#区块链</p>
<h2 id="介绍">1. 介绍</h2>
<p>只要把矿机插电、插网,
开启电源,它就可以24小时源源不断的生产虚拟货币。听起来热血沸腾吧！下面就来看看矿机怎么连网和挖矿的．矿机有很多种，有的集成很多显卡．有的看起来像台电脑，有的像个Ｕ盘．</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-9398ede5d6d578df.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>无论哪种矿机，至少都包含连网和计算两个部分．连网部分负责收发计算数据和证明挖矿者身份，计算部分负责具体的挖矿．这里我们来考虑最常见的一个控制板带多个矿机，连接他人矿池的情况．矿工只在设置的时候需要电脑或者手机连接到控制器的web界面，其余时候只要启动控制板和矿机即可挖矿（有些矿机和控制板是一体的）。当然这里指的是连他人的矿池，如果自己做矿池，矿池也是需要机器的．</p>
<h2 id="控制器与网络相连部分">2. 控制器（与网络相连部分）</h2>
<p>下面以树莓派控制板为例分析，控制内部如何运作，以及如何与上下层交互。一般树莓派都自带再dhcp客户端，连上网线就能自动获取IP地址，其上运行一个WebServer，外加miner-web工具，即可支持矿机的Web设置界面。矿工通过路由器看找到分给控制器的IP地址，然后用http连接的方式来设置它，此时需要设置矿池的具体信息，以及钱包的地址，地址从矿池得到。通过usb连接的矿机(可通过hub连多台)，直接映射成/dev下的设备，树莓派上运行的挖矿程序miner控制设备完成具体计算，miner的参数通过web设置得到。如果没有控制器，用电脑也可以完成上述工作，只是像树莓派这种微型电脑功耗低，出售者又已把挖矿等相关功能做好，相对省时，省力，省电．控制器的核心就是miner程序，也可以在电脑上运行minerd控制矿机，如果还没买矿机，也可以用电脑上的CPU／GPU挖，只是算力有限挖不出来。不过用该方法，在搭建矿池时，就可以用一台机器来模拟矿池整个运行逻辑。下面介绍几种常用的挖矿工具：</p>
<h4 id="cpuminer可以云端模拟不需要gpu矿机等设备">1)
cpuminer（可以云端模拟，不需要gpu，矿机等设备）</h4>
<pre><code>$ git clone https://github.com/pooler/cpuminer.git  
$ cd cpuminer/  
$ ./autogen.sh  
$ ./configure  
$ make;make install  
$ minerd --url=矿池地址 --user=用户名 --pass=密码  </code></pre>
<h4 id="cpugpuminer需要矿机无法在云端测试">2)
cpu/gpuminer（需要矿机，无法在云端测试）</h4>
<pre><code>$ apt-get install cgminer  
$ cgminer -o 矿坑地址 -u 用户名 -p 密码  </code></pre>
<h4 id="bfgminer需要矿机无法在云端测试">3)
bfgminer（需要矿机，无法在云端测试）</h4>
<pre><code>$ apt-get install bfgminer  
$ bfgminer  </code></pre>
<p>不指定参数，也可以找到本机上开启的矿池，并搜索与本机相连的矿机硬件．</p>
<h2 id="矿机计算部分">3. 矿机（计算部分）</h2>
<p>早期使用电脑挖矿，现在都是专用矿机：显卡，FPGA（现场可编程门阵列）、ASIC（专用集成电路）矿机的面世，使算力级别大幅提升、计算时间减小。</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-0b164bfe58cb4354.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<h4 id="显卡">1) 显卡</h4>
<p>显卡的组件模块是乘法器、加法器。可并行计算，但是功耗大。</p>
<h4 id="fpga矿机">2) FPGA矿机</h4>
<p>FPGA(Field-Programmable Gate
Array)现场可编程门阵列。它是一系列通过可编程互连的可编程模块。FPGA犹如乐高，其灵活性高，可根据实际应用的需求，构建所需的硬件组件。但是乐高本身就是一种浪费：其功耗性能比，可变布线资源、多余的逻辑资源，其实都是浪费。虽然比显卡省电，但效果不如显卡，只是过渡时期的产品。</p>
<h4 id="asic矿机">3) ASIC矿机</h4>
<p>ASIC（ApplicationSpecific Integrated
Circuits）是为专门目的而设计的集成电路．它不能修改，所以前期开发周期长，成本高。像蚂蚁矿机，烤猫矿机都是ASIC矿机。ASIC的能效也是最高的，现在卖的矿机基本都是这种．</p>
]]></content>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title>比特币挖矿——钱包</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%8C%BA%E5%9D%97%E9%93%BE/%E6%AF%94%E7%89%B9%E5%B8%81%E6%8C%96%E7%9F%BF%E2%80%94%E2%80%94%E9%92%B1%E5%8C%85/</url>
    <content><![CDATA[<h1 id="比特币挖矿钱包">比特币挖矿——钱包</h1>
<p>#区块链</p>
<h2 id="bitcoin钱包">1. BitCoin钱包</h2>
<p>BitCoin是钱包的一种，目前它需要下载上百G的数据，且之后还会不断增加，其它钱包也有数据比较少的，但是做矿池一般用bitcoin，可以把它看成实时更新的矿池数据库。<br />
如果想做矿池的话，必须把钱包数据下到本地，而且后台进程要一直开着更新数据。还需要给钱包加密。</p>
<h2 id="安装配置钱包">2. 安装配置钱包</h2>
<h4 id="安装">1) 安装</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ apt-get install bitcoind  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 2)	修改配置文件  </span><br><span class="line">```  </span><br><span class="line">$ vi bitcoin.conf # 内容如下  </span><br><span class="line">rpcuser=abc  </span><br><span class="line">rpcpassword=123  </span><br><span class="line">server=1  </span><br><span class="line">rpcallowip=127.0.0.1  </span><br><span class="line">addnode=14.111.41.235  </span><br><span class="line">addnode=180.109.106.68  </span><br><span class="line">addnode=119.129.41.15  </span><br><span class="line">```  </span><br><span class="line">注意，这里的user和password是RPC的用户名密码，它和钱包地址没关系，随便设什么都可以，只要和挖矿服务（如：p2pool或btcpool）设的一致即可。  </span><br><span class="line"></span><br><span class="line">#### 3)	运行  </span><br><span class="line"></span><br><span class="line">###### i.	本机上执行  </span><br><span class="line">```  </span><br><span class="line">$ bitcoin-qt  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">###### ii.	服务端执行（远程机器，用ssh连接，看不到图形界面）  </span><br><span class="line">```  </span><br><span class="line">$ bitcoind --datadir=数据目录 -conf=配置文件 -daemon  </span><br><span class="line">```  </span><br><span class="line">运行bitcoind即可以下载数据，下载时间较长。  </span><br><span class="line">默认的配置文件路径是：$USER/.bitcoin/bitcoin.conf  </span><br><span class="line"></span><br><span class="line">###### iii.	查看当前状态  </span><br><span class="line">```  </span><br><span class="line">$ bitcoin-cli -getinfo  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">###### iv.	查看端口  </span><br><span class="line">```  </span><br><span class="line">$ netstat -nap|grep 8332  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">## 3.	加密  </span><br><span class="line">比特币钱包地址和真正的银行卡不同，它不是实名制的。系统又是分布式的，没有一个中心机构来维护，因此它只认密钥不认人，所以一定要保护好你的私钥。  </span><br><span class="line">对于bitcoin-qt客户端来说，比特币私钥一般储存在客户端的wallet.dat文件中。对于Blockchain这样的在线钱包用户来说，比特币私钥是储存在在线钱包的网络服务器上，用户也可以将私钥下载到本地。对于bitcoin，加密相关命令如下，通过bitcoin-cli运行。  </span><br><span class="line"></span><br><span class="line">#### 1)	导出私钥  </span><br><span class="line">```  </span><br><span class="line">$ walletpassphrase 密码 解锁持续时间(秒) #解锁  </span><br><span class="line">$ dumpprivkey 地址  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 2)	导入私钥  </span><br><span class="line">```  </span><br><span class="line">$ walletpassphrase 密码 解锁持续时间(秒) #解锁  </span><br><span class="line">$ importprivkey 私钥  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 3)	加密钱包  </span><br><span class="line">```  </span><br><span class="line">$ encryptwallet 密码  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 4)	查询列表地址（返回钱包上所有地址信息：地址，余额，所属帐户）  </span><br><span class="line">```  </span><br><span class="line">$ listaddressgroupings  </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title>比特币挖矿——集群矿池btcpool</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%8C%BA%E5%9D%97%E9%93%BE/%E6%AF%94%E7%89%B9%E5%B8%81%E6%8C%96%E7%9F%BF%E2%80%94%E2%80%94%E9%9B%86%E7%BE%A4%E7%9F%BF%E6%B1%A0btcpool/</url>
    <content><![CDATA[<h1 id="比特币挖矿集群矿池btcpool">比特币挖矿——集群矿池btcpool</h1>
<p>#区块链</p>
<h2 id="介绍">1. 介绍</h2>
<p>btcpool一个集群的解决方案，它使用了mysql数据库，web服务，kafka，zooKeeper，据说可以控制100000矿机。代码中逻辑和安装说明都比较完整，但还需要一些编写一些web界面做UI支持。配好之后就和其它大矿池差不多了。<br />
挖矿的哈希碰撞需要大量计算，由矿机实现。而拆分集成运算量，分配任务，在矿机多的情况下也需要大量的算力支持。Btcpool是一个去中心化集群的解决方案（矿池内部去中心，对外自成体系）。N个矿机连一个控制板，控制板接入网络，通过端口连服务器，服务器再把拆分运算量的工作分担给矿池内的多台服务器同时计算。<br />
它的主旨就是整套系统切分成功能块，块与块之间用使用kafka传递数据和信息，后台由zooKeeper负载均衡，从而使不同的功能块运行在不同的服务器上。像钱包和mysql这种频率使用的公用数据放在另外的服务器上，各功能块通过rpc，zmp等方式访问它们。<br />
其中最核心的程序是sserver，矿机控制板连接的就是该程序。它支持Stratum协议。现在一般的比特币矿池都支持两种协议:getwork、stratum。getwork比较方便也非常好理解，直接连接到矿池挖矿。stratum协议是一个挖矿代理，先通过电脑稳定连接矿池，然后挖矿机连接到电脑上，通过电脑中转挖矿结果和接收新的block，因为有电脑作为中转，相对来说挖矿过程比较稳定。</p>
<h2 id="btcpool核心工具">2. btcpool（核心工具）</h2>
<h4 id="下载">1) 下载</h4>
<pre><code>https://github.com/btccom/btcpool  </code></pre>
<h4 id="安装">2) 安装</h4>
<p>btcpool源码里，虽然没有什么文档，但是README和INSTALL里面写得很清楚。</p>
<pre><code>$ su  #install脚本里，指定了/root等绝对路径，最好切换成root安装  
$ unzip btcpool-master.zip  
$ cd btcpool-master/install  
$ . install_btcpool.sh #第一次安装，有些辅助软件从git下载（一次连不上可多连几次），这样有效地保证了版本匹配，数据下载和安装在/root/sources和/work/中，具体说明见 INSTALL.md。  
$ cd /work/btcpool/build  
$ bash ../install/init_folders.sh  </code></pre>
<h4 id="注意事项">3) 注意事项</h4>
<ol type="i">
<li>/work/btcpool/build/run_xxx/xxx.cfg文件必须根据具体信息修改，先安装好支持软件，最后修改配置文件。<br />
</li>
<li>集群的搭建方法必须按btcpool/docs/INSTALL*.md来操作，因为有一些重要参数，比如broker.id，max.size等等需要调整，如按一般方法安装，调试起来非常麻烦。<br />
</li>
<li>尽量不要变更目录，很多路径都是写死的<br />
</li>
<li>核心算法在src/bitcoin目录下，它编出来的是一个静态库，其它的可执行程序调用它。</li>
</ol>
<h2 id="zookeeper依赖工具">3. ZooKeeper（依赖工具）</h2>
<p>主要负责负载均衡。安装Kafka的说明书在/work/btcpool/docs/ INSTALL-
ZooKeeper.md中，最好按它的步骤配置，否则调试可能很麻烦。ZooKeeper原理及调试方法见上篇《比特币挖矿——建立Kafka&amp;Zookeeper集群》</p>
<h2 id="kafka依赖工具">4. Kafka（依赖工具）</h2>
<p>主要负责消息传送。安装Kafka的说明书在/work/btcpool/docs/
INSTALL-Kafka.md中，一定要按它的要求修改配置文件，如果一开始配置错误，后对调试很麻烦。具体原理及调试方法见上篇《比特币挖矿——建立Kafka&amp;Zookeeper集群》<br />
建topic操作见INSTALL.md脚本</p>
<h2 id="mysql数据库依赖工具">5. Mysql数据库（依赖工具）</h2>
<ol type="1">
<li>安装<br />
</li>
</ol>
<pre><code>$ apt-get install mysql-client  
$ apt-get install mysql-server  </code></pre>
<ol start="2" type="1">
<li>建库<br />
</li>
</ol>
<pre><code>$ mysql  
&gt; CREATE DATABASE bpool_local_db; # 这两个库在.cfg中设置  
&gt; CREATE DATABASE bpool_local_stats_db;  
&gt; exit  </code></pre>
<p>其它操作见INSTALL.md脚本</p>
<h2 id="http服务器apache2依赖工具">6. http服务器Apache2（依赖工具）</h2>
<ol type="1">
<li>安装<br />
</li>
</ol>
<pre><code>$ apt install apache2  </code></pre>
<ol start="2" type="1">
<li>需要写一个php，能输入如下内容<br />
</li>
</ol>
<pre><code>&#123;&quot;err_no&quot;:0,&quot;err_msg&quot;:null,&quot;data&quot;:&#123;&quot;jack&quot;:1,&quot;terry&quot;:2&#125;&#125;  </code></pre>
<p>它与矿工连上来的用户名对应。</p>
<h2 id="zeromq辅助工具">7. zeromq（辅助工具）</h2>
<p>ZeroMQ看起来像一个可嵌入的网络库,
但其作用就像是一个并发框架。它提供了各种传输工具, 如进程内, 进程间,
TCP和组播中进行原子消息传递的套接字。<br />
在install.sh脚本里下载到/root/sources/下，并安装，无需手动再安了。<br />
在gbtmaker.cfg中的默认设置为使用zeromq通讯，
需要bitcoin钱包也支持zeromq，如果不想用它，在gbtmaker.cfg里将zmq相关的设为false，它将改为调用rpc通讯。</p>
<h2 id="supervisor依赖工具">8. supervisor（依赖工具）</h2>
<h4 id="说明">1) 说明</h4>
<p>它负责管理后台进程，服务一般要长时间运行，它负责监测进程状态，在死掉时重启服务等等，其中的配置文件conf用于指定具体的程序及参数。</p>
<h4 id="安装-1">2) 安装</h4>
<pre><code>$ apt-get install supervisor # 这是后台进程管理用的  </code></pre>
<p>将需要启动的服务配置写成conf文件复制到/etc/supervisor/conf.d下即可，其它操作见INSTALL.md脚本</p>
<h4 id="常用命令">3) 常用命令</h4>
<pre><code>$ supervisorctl  
&gt; reread  
&gt; update  
&gt; status # 查看状态  
&gt; restart xxxx # 可选择重启某一个  
其它  
$ supervisorctl start xxx  
$ supervisorctl stop xxx  </code></pre>
<h2 id="测试">9. 测试</h2>
<h4 id="自带的测试工具simulator">1) 自带的测试工具simulator</h4>
<pre><code>$ cd /work/btcpool/build/run_simulator  
$ ./simulator -c simulator.cfg -l /tmp/log  </code></pre>
<h4 id="模拟矿机连接">2) 模拟矿机连接</h4>
<pre><code>minerd -o stratum+tcp://127.0.0.1:3333 -O jack:1  </code></pre>
<p>注意这里的用户名要和http服务上的匹配</p>
<h2 id="集成说明">10. 集成说明</h2>
<h4 id="一般调试过程如下">1) 一般调试过程如下：</h4>
<ol type="i">
<li>所有程序正常运行，不退出，不报错，不卡往。<br />
</li>
<li>矿机能连上矿池，能分配到工作，开始计算。<br />
</li>
<li>数据库中出现用户登录的记录。<br />
</li>
<li>数据库中的各项数据都显示正常。<br />
</li>
<li>程序员做一些监控统计的工具，供一般用户使用。</li>
</ol>
<h4 id="调试说明">2) 调试说明：</h4>
<ol type="i">
<li>首先要根据具体情况修改各个.cfg文件<br />
</li>
<li>调试时，可以先不使用supervisorctl，直接调用/work/btcpool/build/run*中的程序，具体参数见对应的conf程序<br />
</li>
<li>建议从核心程序开始一个一个调试。默认有很多log文件，里面显示了具体程序出错的位置。调试的顺序是blkmaker-&gt;gbtmaker-&gt;jobmaker-&gt;sserver-&gt;其它<br />
</li>
<li>集成最重要的是配置文件和软件版本，配完后最好对其进行记录和备份<br />
</li>
<li>综上，Btcpool提供了一个工作框架，真正用起来还需要做很多工作。</li>
</ol>
]]></content>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title>少儿Python编程_第二讲：开发环境</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%B0%91%E5%84%BF%E7%BC%96%E7%A8%8B/02_%E5%B0%91%E5%84%BFPython%E7%BC%96%E7%A8%8B_%E7%AC%AC%E4%BA%8C%E8%AE%B2%EF%BC%9A%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<p>#少儿编程 #Python</p>
<h1
id="少儿python编程_第二讲开发环境">少儿Python编程_第二讲：开发环境</h1>
<p>在开始编写程序之前，首先要搭建开发环境。Python是一种跨平台的编程语言，它可以在Window、Linux、MacOS等操作系统上运行，为简化操作，本书以Windows系统作为开发平台，以Anaconda套件作为开发工具。</p>
<h2 id="python语言">2.1 Python语言</h2>
<p>在讨论如何选择编程语言之前，先看看什么是编程。现在很多工作都离不开计算机，比如：使用各种办公软件，做图，编辑视频，开发网站，微信和手机应用，统计分析，机器人，人工智能……应该学习什么？对于非专业人员，针对青少年的知识和能力，能学什么？</p>
<p>希望本次学习的成果能在后续的学习和工作中发挥作用，那么就需要学习“编写真正的程序”，而不仅仅是展示某种“有趣的成果”。</p>
<p>图书馆里有很多十几年前的计算机工具书籍都已经不再使用，IT行业日新月异，即使今天学习了一门最流行的编程语言，等十几年后，可能也已经过时了。</p>
<p>因此，最好能学习一门相对简单的编程语言，不要把时间都花在语言的细节和技巧上，Python语言就非常合适，它可烦可简。Python入门简单，从8岁到80岁都可以学习；同时功能强大，在人工智能领域，它几乎是使用率最高的编程语言。小学生和博士生都在使用。利用这门简单的语言，编程者可以把更多的精力放在目标和流程上，像搭建积木一样，Python语言和它强大的三方库负责解决具体问题。</p>
<h2 id="安装软件">2.2 安装软件</h2>
<p>无论是否编写程序，安装软件都是使用计算机的必备技能之一。本节将通过安装Python开发环境，向读者介绍从网上下载、安装和使用软件的步骤和方法。</p>
<h3 id="anaconda开发环境">2.2.1 Anaconda开发环境</h3>
<p>Python可在多个操作系统中运行，也有多种安装方法，本书将Windows系统作为基础系统，使用Anaconda套件作为开发环境，Anaconda是一个免费开源的Python发行版本，支持多个操作系统，除了基本的Python环境，它还包括科学、工程、绘图等多种Python三方库，以及Spyder和Jupyter等Python编辑器。非常适合初学者使用，省去了后续装库的麻烦。</p>
<p>一般下载软件的方法是：用浏览器打开“百度”搜索软件相关的关键字，如图2.1所示：</p>
<p><img
src="https://pic2.zhimg.com/80/v2-e31a0090fdc64535cb05d436d6deac61_1440w.jpg" /></p>
<p>图2.1 搜索待安装软件</p>
<p>图2.1中搜索出的第一项即Anacoda的主页，点击它进入下载界面：<a
href="https://link.zhihu.com/?target=https%3A//www.anaconda.com/distribution/">https://www.anaconda.com/distribution/</a>，如图2.2所示：</p>
<p><img
src="https://pic1.zhimg.com/80/v2-8dd225572ef86f9a23b98643db1a91bc_1440w.jpg" /></p>
<p>图2.2 Anaconda下载界面</p>
<p>可以看到下载页提供了Windows、macOS、Linux三个平台对应的软件，这里选择Windows平台的Python
3.7版本，其中包括32位和64位两种软件版本，需要根据自己计算机的情况下载不同版本，在计算机的桌面上右键点击“计算机”，选“属性”，即可从系统类型中查看计算机是32位系统还是64位系统。在浏览器中点击对应版本，下载完成后即可安装。</p>
<p><em>注意：Anaconda是英文软件，在下载和安装的过程中，低年龄儿童可能遇到大量生词，建议家长先帮助孩子下载“金山词霸”或其它翻译软件，以克服语言障碍，或者在家长的帮助下完成第一次软件安装。</em></p>
<h3 id="安装软件-1">2.2.2 安装软件</h3>
<p>下载Anaconda后安装步骤如图2.3所示，按提示点击下一步（Next），同意（I
Agree），安装（Install），完成（Finish）即可。</p>
<p><img
src="https://pic1.zhimg.com/80/v2-ffa0f92565cdf53d2827d0892195279c_1440w.jpg" /></p>
<p><img
src="https://pic1.zhimg.com/80/v2-948d298b0e3d3ef51fd2ff90be582a7c_1440w.jpg" /></p>
<p><img
src="https://pic1.zhimg.com/80/v2-0b0bf217b6f48c8db49b725ab06b4fec_1440w.jpg" /></p>
<p><img
src="https://pic2.zhimg.com/80/v2-0b1a83338a422cf55cbc1a3ddab9ce29_1440w.jpg" /></p>
<p>图2.3 安装Anaconda</p>
<p>安装完成之后，在开始菜单-&gt;所有程序-&gt;Anaconda3文件夹下可以看到Python相关的应用程序，如图2.4所示：</p>
<p><img
src="https://pic3.zhimg.com/80/v2-3aa6038c45549b70b8563c3110125cc2_1440w.jpg" /></p>
<p>图2.4 Python相关应用程序</p>
<p>其中Anaconda
Navigator是导航工具，使用它可以操作Anaconda安装的软件；Anaconda
Powershell Prompt和Anaconda
Prompt是命令行模式，可以在此处管理和安装Python软件；Spyder和Jupyter
Notebook是程序编辑器，后续将使用它们编写Python程序，后续章节将具体介绍。</p>
<h3 id="卸载软件">2.2.3 卸载软件</h3>
<p>与安装软件对应的是从系统中删除软件，即卸载软件。具体方法是：点击桌面上的“计算机”图标，选择其窗口上方的“打开控制面板”-&gt;程序-&gt;卸载程序，即可打开“程序和功能界面”，如图2.5所示，从列表中选择要更改或者卸载的应用程序。</p>
<p><img
src="https://pic3.zhimg.com/80/v2-108da627379f689303f2aff214c45f32_1440w.jpg" /></p>
<p>图2.5 程序和功能界面</p>
<p><strong>课后练习：</strong>（练习答案见本讲最后的小结部分）</p>
<p>练习一：安装软件Firefox浏览器。</p>
<h2 id="使用python开发环境">2.3 使用Python开发环境</h2>
<p>可用于Python开发的环境非常多，本节将讲解其中最常用的几种环境。</p>
<h3 id="python命令行">2.3.1 Python命令行</h3>
<p>首先，打开命令行界面：开始菜单-&gt;所有程序-&gt;Anaconda-&gt;Anaconda
Prompt。并输入“python”，进入Python命令行模式，如图2.6所示。</p>
<p><img
src="https://pic1.zhimg.com/80/v2-45463760e9ff1cd4ea62cf1ec139fd30_1440w.jpg" /></p>
<p>图2.6 Python命令行界面</p>
<p>看到提示符“&gt;&gt;&gt;”，可输入python命令</p>
<pre class="text"><code> 01 print(&quot;aaaa&quot;)  </code></pre>
<p>print用于显示输出，回车后该程序被运行，显示“aaaa”，之后使用exit()退出Python命令行模式。</p>
<h3 id="ipython命令行">2.3.2 IPython命令行</h3>
<p>IPython命令行是Python命令行的加强版，它的使用方法是先打开命令行界面：开始菜单-&gt;所有程序-&gt;Anaconda-&gt;Anaconda
Prompt。然后输入ipython进入交互命令行模式。如图2.7所示。</p>
<p><img
src="https://pic4.zhimg.com/80/v2-68a0353dc2988762be3f3e9965fd45eb_1440w.jpg" /></p>
<p>图2.7 IPython界面</p>
<p>可以看到，IPython的提示符与Python不同，它用颜色标出了不同类型的程序和数据，在输入命令的过程中，可以通过按“Tab”键补全命令，还支持按“上”键，调出以往输入的命令。相对于Python命令行方便很多。</p>
<h3 id="spyder">2.3.3 Spyder</h3>
<p>Spyder是Python作者开发的一个简单的Python集成开发环境，开发者可以在Spyder中编写和运行程序。</p>
<p>首先，打开Spyder程序：开始菜单-&gt;所有程序-&gt;Anaconda-&gt;Spyder，打开的Spyder界面如图2.8所示：</p>
<p><img
src="https://pic1.zhimg.com/80/v2-f689ff13cb4a3d8d9c3636f0a19f614c_1440w.jpg" /></p>
<p>图2.8 Spyder界面</p>
<p>Spyder界面主要包含三部分，左边是程序编辑区，开发者在左侧编写程序；右侧上部是对象变量文件浏览区，右侧下部是命令窗口区，它提供ipython的交互界面，开发者在此处以交互模式输入Python代码，此处同时显示左侧程序运行结果。</p>
<p>下面来编写第一个Python程序，在左侧区域加入代码：</p>
<pre class="python3"><code> 01 print(&quot;aaa&quot;)  </code></pre>
<p>输入代码后，点击上方快捷菜单中的绿色箭头运行这段程序，在右下的交互界面中显示了程序的运行结果“aaa”。</p>
<h3 id="jupyter-notebook">2.3.4 Jupyter Notebook</h3>
<p>Jupyter Notebook开始叫IPython
Notebook，它是一个交互式的编程界面，初期只支持Python，后来逐渐发展，现已支持四十多种编程语言。</p>
<p>Jupyter在后台开启服务，开发者通过浏览器与服务连接，可在浏览器中编写程序和查看运行结果。它的优点是可以在某一台机器上安装Python环境，而在同一网络的任意一台机器上都可以通过IP地址和端口连接该环境，编写Python程序，而无需在每一台开发机器上安装Python环境。</p>
<p>相对其它编程工具，Jupyter
Notebook界面看起来简洁大方，且启动速度快。其中间的主要区域用于编写程序，运行结果显示在程序下方。本教程中后续的例程都使用Jupyter
Notebook编写。</p>
<p>Jupyter
Notebook与其它Python程序开发软件不同的是，一般Python程序扩展名为“.py”，而Notebook中Python程序默认的格式是“.ipynb”。这种格式不只支持python代码，还能加入格式丰富的文字、图片、以及记录程序运行结果。同时它也支持导出纯代码格式的“.py”文件。</p>
<p>需要注意的是：有些浏览器不支持Jupyter
Notebook，建议使用Firefox浏览器开发，并将Firefox设置成默认浏览器。</p>
<p>打开Jupyter
Notebook程序：开始菜单-&gt;所有程序-&gt;Anaconda-&gt;Jupyter
Notebook，此时跳出后台服务框的同时，默认浏览器也被开启。Jupyter有两种界面，一种是列表界面，一种是程序编辑界面。列表界面如图2.9所示。</p>
<p><img
src="https://pic3.zhimg.com/80/v2-f2704ef7ad16bbaaf7261ebc583b2b12_1440w.jpg" /></p>
<p>图2.9 Jupyter Notebook列表界面</p>
<p>浏览器中显示了文件目录列表，第一次使用时可以用右上边的Upload上传代码文件，或者使用New-&gt;Python
3创建程序文件，本例中创建了一个Python程序，程序编辑界面如图2.10所示。</p>
<p><img
src="https://pic4.zhimg.com/80/v2-f46e3d725b93ee003b66ab29afccdfc7_1440w.jpg" /></p>
<p>图2.10 Jupyter Notebook程序编辑界面</p>
<p>编程界面上菜单支持的功能很多，不能一一列举。几个最常用的功能在图2.10中用绿色字符标出。</p>
<p>一般编程工具都有颜色提示，比如在Jupyter
Notebook中Python提供的关键字（像while,
import）用绿色，符号为粉色，字符串为红色，通过颜色可识别打字引起的错误。当光标停在一个括号上时，括号的另一半颜色也随之改变，这样可以查看括号是否成对出现。Jupyter还支持代码自动补全功能，按Tab键即可使用。</p>
<p>图2.10中的每个灰色方格都是Cell单元，它是Notebook中的基本元素。通过Insert菜单可添加新的单元。单元分为两种：Markdown单元（标记语言）和代码单元。</p>
<p>Markdown单元：一般用于编写注释和说明信息，文本格式、插入链接、图片甚至数学公式等数据，一般使用Markdown
的语法编写，纯文本也可正常显示。</p>
<p>代码单元：代码单元左边有“In [
]:”的序列标记，方便查看代码的执行次序。其运行结果显示在该单元下方。</p>
<p>单元有编辑模式和命令模式，命令模式时单元左侧显示蓝线，编辑模式时左侧显示绿线。按Enter键切换到编辑模式，按Esc键切换到命令模式。编辑模式一般用于修改单元内容，命令模式用于对整个单元进行操作，如添加单元、删除单元等，比如用Shift+L快捷键控制是否显示行号，用Shift+Enter执行当前单元中的代码。</p>
<p><strong>课后练习：</strong></p>
<p>练习二：用Jupyter编写程序，显示字符串“aaaa”。</p>
<h2 id="思维训练">2.4 思维训练</h2>
<p>我们常说“学完之后，都还给老师了”。这也是学习中最常见的问题：当时的确学会了，过一段时间记得好像学过，却忘记了具体内容。它可能受到以下几种因素影响：</p>
<p><strong>理论脱离实际</strong></p>
<p>大学理工科都需要学微积分，同学说“这有什么用？我买菜还积个分吗？”的确后来很少有人在生活中用到高等数学。越是抽象，离生活越远，越难理解，更难被记住。原因可能是难度大，也可能因为使用得太少了。</p>
<p>学习编程也是一样，很多课程中，老师搭建好环境，学生主要在编程工具中操作，学习偏重于基础和理论，可以拿它“玩”、“做展示”，却没有渗透进日常生活之中。开发程序是一项综合技能，涉及查资料、安装软件、制作图片、编写界面，配置环境，分析数据，调试程序，以及将结果呈现给他人，以及综合使用知识的能力，后面课程也会逐步讲解。</p>
<p>本讲中的安装软件、查资料等技能在日常生活中也很常用，比如养成用手机或者电脑查资料的习惯：游泳、养鱼、做饭都可以在网上学习，天天使用想忘记都很困难。</p>
<p>读者在学习的过程中一定要边学边用，无论是配置环境的例程还是程序例程都要跟着做一遍，并且尽量使用它解决生活中的问题。</p>
<p><strong>复习</strong></p>
<p>日常生活中可能遇到非常多的知识和技能，全记住需要大量的存储空间，查找也将非常耗时。大脑一般会记住那些重要的，而忽略不太重要的。</p>
<p>在学习时，知识进入了短时记忆，可以存储几分钟到几天的时间，而只有少部分短时记忆被转存在长时记忆之中，这部分通常是反复使用的。对于日常能用到的知识和技能，每用一次都会加深印象。还有一些，比如背单词，没有可用的语言环境反复训练，就需要利用复习的方法反复刺激，才能形成长时记忆。</p>
<p><strong>提炼</strong></p>
<p>提炼又可以分成简化、归纳、总结规律等等。</p>
<ul>
<li>简化<br />
简化问题是把重要部分从千头万绪中清理出来。比如读文章时，不可能记住每一个字；学习相对复杂内容和新内容时，读完之后大脑往往一片空白。建议一边看一边划重点，并总结每一段的大意。阅读文章时需要划重点，做数学应用题时也一样，概括之后脑中记忆的都是关键点，查找起来更加迅速，同时也保留了大量空间用于联想和思考。<br />
</li>
<li>归纳<br />
经过层层简化后，梳理关键点之间的关系，形成树型或网状的知识结构，这也是总结和建构知识体系的过程。大段的文字如果被整理成1.2.3,(1)(2)(3)带顺序和层次的简化版本，往往更容易被记忆以及联想。<br />
就像整理衣橱一样，把知识放到适当的位置，再打上标签，之后使用时就能方便地找到。同时也与类似的问题建立连接，与已有知识建立连接，使新知识更容易被联想，提供多种方式被调出。<br />
</li>
<li>找规律<br />
在解决复杂问题时，难免“卡壳”，解决了问题之后，需要反思，在会与不会之间，到底被“卡”在了哪个点。然后总结规律，并将规律用在其它的问题之中。只有会用才是真的学会了。</li>
</ul>
<p>有时候我们把学习当成打卡，做完就完，多一眼都不看。实际上我们的角色不仅是学习者，同时也是检查员。一个人做两个人的工作也有难度，也需要用一段时间培养习惯。因此，从本讲开始，每一课都请读者总结本讲学习的内容，并列举其用途。</p>
<p><strong>课后练习：</strong></p>
<p>练习三：总结本讲学习的内容，并列举三种用途。</p>
<h2 id="本课小结">2.5 本课小结</h2>
<p>本课的学习重点除了熟悉Windows操作系统，安装软件之外，还包括学习使用浏览器搜索，学习这项技能后，如果遇到无法解决的问题，可以通过百度搜索在网上寻找答案。</p>
<h3 id="单词">2.5.1 单词</h3>
<p>对于小读者来说，在下载安装软件时遇到的最大问题是：不熟悉计算机操作相关的英文单词及它们在计算机领域的意思，最好能在学习过程中背下来，本讲需要掌握的英文单词如表2.1所示。</p>
<p><img
src="https://pic3.zhimg.com/80/v2-6998da08815ac4f52010e88340754d2e_1440w.jpg" /></p>
<p>表2.1本讲需要掌握的英文单词</p>
<h3 id="习题答案">2.5.2 习题答案</h3>
<ol type="1">
<li>练习一：安装软件Firefox浏览器。</li>
</ol>
<ul>
<li>第一步、查看本机是否已安装Firefox浏览器：点击桌面上的“计算机”图标，选择其窗口上方的“打开控制面板”-&gt;程序-&gt;卸载程序，即可打开“程序和功能界面”，查看是否有名为“Firefox的程序”，如果已经存在，则不需要安装。如果想尝试安装过程，可以先卸载再安装。<br />
</li>
<li>第二步、用浏览器打开百度：<a
href="https://link.zhihu.com/?target=http%3A//www.baidu.com/">www.baidu.com</a><br />
</li>
<li>第三步、在输入框中输入关键字：“Firefox
下载”，注意：把需要搜索的内容切分成词，词间用空格分隔；点击右侧的“百度一下”开始搜索。<br />
</li>
<li>第四步：点击搜索返回的网址列表，在网页中点击其中的“下载Firefox”，并在文件下载框中点选择“运行”。<br />
</li>
<li>第五步：按提示安装，直到FireFox浏览器安装成功并正常启动。</li>
</ul>
<ol start="2" type="1">
<li>练习二：用Jupyter编写程序，显示字符串“aaaa”。</li>
</ol>
<p><img
src="https://pic1.zhimg.com/80/v2-cbf1baa8afa1c66f91ccb543481247e8_1440w.jpg" /></p>
<p>图2.11 显示字符串</p>
<ol start="3" type="1">
<li>练习三：总结本讲学习的内容，并列举三种用途。</li>
</ol>
<p>本题答案比较灵活，主要目标是养成梳理问题的习惯，只有包括主要元素，怎么组织都可以。下图为小李同学用xmind绘制的思维导图，笔者认为安装部分过于细化，但为保留小李同学作业的完整性，未做修改。</p>
<p><img
src="https://pic3.zhimg.com/80/v2-4144a7e8e09881b1638736a6e60eea82_1440w.jpg" /></p>
<p>图2.12 本课内容总结</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>少儿编程</tag>
      </tags>
  </entry>
  <entry>
    <title>少儿Python编程_第十六讲：图形界面开发</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%B0%91%E5%84%BF%E7%BC%96%E7%A8%8B/16_%E5%B0%91%E5%84%BFPython%E7%BC%96%E7%A8%8B_%E7%AC%AC%E5%8D%81%E5%85%AD%E8%AE%B2%EF%BC%9A%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A2%E5%BC%80%E5%8F%91/</url>
    <content><![CDATA[<p>#少儿编程 #Python</p>
<h1
id="少儿python编程_第十六讲图形界面开发">少儿Python编程_第十六讲：图形界面开发</h1>
<p>运行在计算机上的程序一般分为命令行程序和图形界面程序，例如：安装Python三方模块的pip命令，软件版本管理的git命令等都属于命令行程序；而大多数软件使用图形界面，例如Windows的Word，Excel，画图等等软件都是图形化用户界面，简称GUI。</p>
<p>在图形化用户界面中，用户可以用鼠标操作菜单、按钮等图形化组件，并从对话框等图型化组件中获取信息。实现图形化界面的方法与制作游戏界面的流程相似：在初始化工具之后，进入主循环接收用户事件，并且进行显示、反馈等处理，直到程序退出，才结束主循环。与绘制游戏界面不同的是，游戏界面中的绘图、处理鼠标事件都需要开发者写程序自行处理，而图形用户界面内部已经实现了按钮、文本框的绘制和响应事件，使用时调用这些控件即可，减少了编写程序的工作量。</p>
<p>图形界面在任何编程语言中原理都一样，本讲通过Python图形界面编程，介绍图形界面中的基本概念和简单用法：常用控件、布局方法、事件处理。</p>
<h2 id="图形界面入门">16.1 图形界面入门</h2>
<p>Python的图形用户界面常使用Tkinter开发，Tcl
是“工具控制语言”的缩写。Tk是Tcl“图形工具箱”的扩展，而Tkinter是Tk
interface的缩写，意思是TK界面。</p>
<p>在Windows系统中Tkinter已由Anaconda安装，可以直接使用，在Linux下则需要使用apt安装python3-tk软件包。</p>
<h3 id="基本概念">16.1.1 基本概念</h3>
<p>在学习具体编程之前，先了解一些基本概念。</p>
<p><strong>1．控件</strong></p>
<p>控件也叫组件，是图形用户界面中最基本的组成部分，常用的控件有：按钮、文本框、标签、表格等等。</p>
<p><strong>2．容器</strong></p>
<p>容器是一种特殊的控件，它能容纳其它控件，如窗口、对话框都属于容器。</p>
<p><strong>3．布局</strong></p>
<p>布局是控制控件在容器中的大小和位置的方法。</p>
<p><strong>4．事件处理</strong></p>
<p>事件是可以被程序识别的操作，如：按下按钮，选择某个单选按钮或者复选框，关闭程序等等，开发者往往需要对事件做出处理，响应某个事件的函数就是事件处理程序，也被称为回调函数。</p>
<h3 id="程序示例">16.1.2程序示例</h3>
<p>下例是一个简单的图形界面程序，它创建窗口。并在窗口中显示两行文字“test1”和“test2”。</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> <span class="im">import</span> tkinter  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">2</span>    </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">3</span> win <span class="op">=</span> tkinter.Tk()  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">4</span> win.geometry(<span class="st">&quot;320x240+200+50&quot;</span>)  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">5</span> tx1 <span class="op">=</span> tkinter.Label(win, text<span class="op">=</span><span class="st">&quot;test1&quot;</span>)  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">6</span> tx1.pack()  </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">7</span> tx2 <span class="op">=</span> tkinter.Label(win, text<span class="op">=</span><span class="st">&quot;test2&quot;</span>)  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">8</span> tx2.pack()  </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">9</span> win.mainloop()  </span></code></pre></div>
<p>第01行引入tkinter模块。<br />
第03行创建一个实例，用于显示窗口。<br />
第04行设置窗口大小为：宽度320，高度240，位置在屏幕横坐标200，纵坐标50。<br />
第05行创建标签控件tx1用于显示文字，Label函数有两个参数，第一个参数指定控件所在的容器，第二个参数text指定标签上显示的文字。<br />
第06行将控件放置在容器之中，pack是布局的一种方法，将在之后的“布局”部分详细介绍。<br />
第07-08行创建和放置了第二个标签tx2。<br />
第09行开启主循环，在窗口关闭时主循环退出，程序结束。</p>
<p>程序运行结果如图16.1所示：</p>
<p><img
src="https://pic2.zhimg.com/80/v2-615ed3d48cd01a0e34497a087da1172d_1440w.jpg" /></p>
<p>16.1 简单的图形用户界面</p>
<h2 id="布局">16.2 布局</h2>
<p>布局是把控件放置到容器之中，并且指定放在哪里，以及如何放置。Tkinter有3种基本布局管理器：pack、grid和place，还提供容器Frame支持复杂的嵌套布局。</p>
<h3 id="常用布局方法">16.2.1 常用布局方法</h3>
<p><strong>1. pack布局</strong></p>
<p>pack是最常用的布局方法——顺序布局，用于按顺序添加各个控件，上例中使用pack分别添加了两个文字标签，可以看到控件按添加的顺序依次显示在窗口中。图16.2分别展示了横向和纵向顺序布局的方法。</p>
<p><img
src="https://pic4.zhimg.com/80/v2-d01b095c18743e8aa315c3e1dc360a17_1440w.jpg" /></p>
<p>图16.2 pack布局示意图</p>
<p>其基本语法如下：</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> 控件名.pack(可选参数)  </span></code></pre></div>
<p>布局的可选参数如表16.1所示：</p>
<p><img
src="https://pic4.zhimg.com/80/v2-8b98fbd0ba83e8163b869e961eb4b4d7_1440w.jpg" /></p>
<p>表16.1 布局参数表</p>
<p><strong>2．grid布局</strong></p>
<p>grid按网格摆放控件，如图16.3所示，其中每个控件的位置都由行索引row和列索引colomn两个值确定，索引号从0开始（不是1），如左上角的控件1行列为0,0；控件2行列为0,1，以此类推。</p>
<p><img
src="https://pic4.zhimg.com/80/v2-2addeffab7c970578b8d2d4d12edd993_1440w.jpg" /></p>
<p>图16.3 grid布局示意图</p>
<p>其基本语法如下，该函数也支持表16.1中的参数。</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> 控件名.grid(row<span class="op">=</span>行索引, column<span class="op">=</span>列索引,可选参数)  </span></code></pre></div>
<p><strong>3．place布局</strong></p>
<p>place按具体坐标摆放控件。如图16.4所示，用x1,y1设置控件1左上角的位置。</p>
<p><img
src="https://pic1.zhimg.com/80/v2-993da8a240e09f71ac1d09c72978db44_1440w.jpg" /></p>
<p>图16.4 place布局示意图</p>
<p>其基本用法如下，该函数也支持表16.1中的参数。</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> 控件名.place(x<span class="op">=</span>横坐标, y<span class="op">=</span>纵坐标,可选参数)  </span></code></pre></div>
<h3 id="容器布局">16.2.2 容器布局</h3>
<p>当界面设计比较复杂时，一般使用Frame容器实现布局。Frame译为框架，它是一种容器，容器是可以包含其它控件的特殊控件。图16.5在同一窗口中加入了11个控件，包含顺序和网格两种布局方法，实现此界面，需要建立两个frame容器，一个容器为深色背景，用于存放控件1和控件2，另一个容器为浅灰色背景，用于存放其它网络布局的控件。Frame本身也是控件，两个frame控件也使用了顺序布局。</p>
<p><img
src="https://pic4.zhimg.com/80/v2-6c39d832c6d687a504c105d0843eb457_1440w.jpg" /></p>
<p>图16.5 frame容器示意图</p>
<p>其基本语法如下。</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> f<span class="op">=</span> Frame(父容器,可选参数)  </span></code></pre></div>
<p>以上程序创建了容器f，之后可以将其它控件加入该容器。“父/子”用于描述容器和控件之间的关系，通常将包含其它控件的容器称为“父”，而被包含的控件被称为“子”。</p>
<h3 id="综合实例">16.2.3 综合实例</h3>
<p>本例中使用了pack、grid、place、frame多种方法布局界面。</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> <span class="im">import</span> tkinter  </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">2</span>    </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">3</span> win <span class="op">=</span> tkinter.Tk()  </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">4</span> win.geometry(<span class="st">&quot;320x240+200+50&quot;</span>)  </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">5</span>    </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">6</span> f1 <span class="op">=</span> tkinter.Frame(win)  </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">7</span> f1.pack()  </span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">8</span> f2 <span class="op">=</span> tkinter.Frame(win)  </span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">9</span> f2.pack()  </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="dv">10</span>    </span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="dv">11</span> tx1 <span class="op">=</span> tkinter.Label(f1, text<span class="op">=</span><span class="st">&quot;test1&quot;</span>)  </span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="dv">12</span> tx1.grid(row<span class="op">=</span><span class="dv">0</span>,column<span class="op">=</span><span class="dv">0</span>)  </span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="dv">13</span> tx2 <span class="op">=</span> tkinter.Label(f1, text<span class="op">=</span><span class="st">&quot;test2&quot;</span>)  </span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="dv">14</span> tx2.grid(row<span class="op">=</span><span class="dv">1</span>,column<span class="op">=</span><span class="dv">1</span>)  </span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="dv">15</span> tx3 <span class="op">=</span> tkinter.Label(f2, text<span class="op">=</span><span class="st">&quot;test3&quot;</span>)  </span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="dv">16</span> tx3.pack()  </span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="dv">17</span> tx4 <span class="op">=</span> tkinter.Label(win, text<span class="op">=</span><span class="st">&quot;test4&quot;</span>)  </span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="dv">18</span> tx4.place(x<span class="op">=</span><span class="dv">10</span>,y<span class="op">=</span><span class="dv">10</span>)  </span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="dv">19</span>    </span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="dv">20</span> win.mainloop()  </span></code></pre></div>
<p>第01-04行用于引入模块和创建窗口。<br />
第06行创建容器f1，并指定其父容器为窗口。<br />
第07行用pack方法将容器以顺序方式布局。<br />
第08-09行建立并加入了第二个容器f2。<br />
第11行创建标签控件tx1，设置其父容器为f1。<br />
第12行用网格方式布局tx1显示在网格的第0行0列。<br />
第13-14行创建标签控件tx2，并以网格方式布局tx2显示在网格的第1行1列。<br />
第15行创建标签tx3，设置其父容器为f2。<br />
第16行用顺序方式将控件tx3布局到其父容器中。<br />
第17行创建标签tx4，设置其父容器为窗口win。<br />
第18行用指定具体位置的方式将控件布局到窗口的坐标为(10,10)位置上。<br />
第20行开启主循环，在窗口关闭时主循环退出，程序结束。</p>
<p>程序运行结果如图16.7所示，其中深灰色部分为容器f2，浅灰色部分为容器f1，它们大小不同是由于容器大小等于其子控件大小。f1中子控件更多，因此区域更大。</p>
<p><img
src="https://pic1.zhimg.com/80/v2-00717956490f98a0fe98c0056fab5164_1440w.jpg" /></p>
<p>图16.6 布局综合实例运行结果</p>
<h2 id="控件">16.3 控件</h2>
<p>Tkinter除了标签控件Label，还支持很多其它控件，本节将介绍最为常用的：按钮、输入框、选择框、以及显示图片的控件。</p>
<h3 id="常用控件">16.3.1 常用控件</h3>
<p><strong>1．标签</strong></p>
<p>标签控件用于显示文字或者图片，定义方法如下：</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> tkinter.Label(父容器, [可选参数])  </span></code></pre></div>
<p>控件常用的可选参数如表16.2所示：</p>
<p><img
src="https://pic2.zhimg.com/80/v2-9b2846796468fac1e5b8862ac91a68e1_1440w.jpg" /></p>
<p>表16.2 控件常用参数</p>
<p><strong>2．按钮</strong></p>
<p>按钮控件是最常用的控件，例如对话框中的“确定”、“取消”都用按钮控件实现。定义方法如下：</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> tkinter.Button(父容器, [可选参数])  </span></code></pre></div>
<p><strong>3．输入框</strong></p>
<p>输入框显示为矩形框，供用户输入信息使用。定义方法如下：</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> tkinter.Entry(父容器, [可选参数])  </span></code></pre></div>
<p><strong>4．选择框</strong></p>
<p>一般情况下，选择框前面是一个矩形方框，后面跟随说明文字，例如：让用户选择“婚否”，结婚则在矩形方框中打钩，否则留空。定义方法如下：</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> tkinter.Checkbutton(父容器, [可选参数])  </span></code></pre></div>
<p><strong>5．图片</strong></p>
<p>图片不直接作为控件使用，而是作为标签或者其它控件的背景，如果不设置标签文字，只设置其背景图片，则该标签是一个图片标签。图片的加载方法如下：</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> tkinter.PhotoImage(<span class="bu">file</span><span class="op">=</span>图片路径)  </span></code></pre></div>
<p>图片加载后，可放在控件的可选参数image中使用。</p>
<h3 id="获取和设置控件的属性">16.3.2 获取和设置控件的属性</h3>
<p>属性指的是控件的性质，一般在创建控件时指定，如：控件的宽度width，高度height等，查看控件的属性方法类似于访问字典，具体方法如下：</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> 控件变量名[属性名]  </span></code></pre></div>
<p>使用configure方法可以重新设置控件属性值，使用方法如下：</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> 控件变量名.configure(属性名<span class="op">=</span>属性值)  </span></code></pre></div>
<p>下例是操作属性的实际应用：</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> x <span class="op">=</span> tkinter.Label(win, text<span class="op">=</span>”abcd”)  </span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">2</span> <span class="bu">print</span>(x[‘text’])  </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">3</span> x.configure(text<span class="op">=</span>’efg’)  </span></code></pre></div>
<p>第01行建立了标签控件，并设置标签显示的文字：text属性为“abcd”。<br />
第02行显示出控件变量x的text属性。<br />
第03行修改控件变量x的text属性为“efg”。</p>
<h3 id="综合实例-1">16.3.3 综合实例</h3>
<p>下面通过综合实例，进一步巩固本节中介绍的各个控件的用法。</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> <span class="im">import</span> tkinter  </span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">2</span>    </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">3</span> win <span class="op">=</span> tkinter.Tk()  </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">4</span> label <span class="op">=</span> tkinter.Label(win,text<span class="op">=</span><span class="st">&quot;请填表&quot;</span>) <span class="co"># 创建文字标签控件  </span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">5</span> label.pack()  </span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">6</span> img <span class="op">=</span> tkinter.PhotoImage(<span class="va">None</span>) <span class="co"># 加载图片  </span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">7</span> label_img <span class="op">=</span> tkinter.Label(win,image<span class="op">=</span>img) <span class="co"># 创建图片标签控件  </span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">8</span> label_img.pack()  </span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">9</span> entry <span class="op">=</span> tkinter.Entry(win) <span class="co"># 创建输入框控件  </span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="dv">10</span> entry.pack()  </span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="dv">11</span> check <span class="op">=</span> tkinter.Checkbutton(win,text<span class="op">=</span><span class="st">&quot;婚否&quot;</span>) <span class="co"># 创建选择框控件  </span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="dv">12</span> check.pack(anchor<span class="op">=</span><span class="st">&#39;w&#39;</span>)  </span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="dv">13</span> button <span class="op">=</span> tkinter.Button(win, text<span class="op">=</span><span class="st">&quot;退出&quot;</span>) <span class="co"># 创建按钮控件  </span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="dv">14</span> button.pack()  </span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="dv">15</span> win.mainloop()  </span></code></pre></div>
<p>程序运行结果如图16.7所示：</p>
<p><img
src="https://pic4.zhimg.com/80/v2-8e17dc674442b4e0cbcc49e9e03fae3b_1440w.png" /></p>
<p>16.7 控件综合实例运行结果</p>
<p><strong>课后练习：</strong>（练习答案见本讲最后的小结部分）</p>
<p>练习一：绘制如图16.8所示的计算器界面，其中上方用Label显示输入数值和计算结果，下方提供12个按钮用于输入数字和符号。</p>
<p><img
src="https://pic1.zhimg.com/80/v2-6ddccd7c82183a535ccb4416eb052404_1440w.png" /></p>
<p>图16.8 计算器效果图</p>
<h2 id="事件处理">16.4 事件处理</h2>
<p>程序需要接收用户操作，并进行反馈。用户操作和系统发来的信息统称事件，事件又分为两种，一种是与整个窗口相关的事件，比如关闭窗口，另一种是与单个控件相关的事件，比如按下按钮Button产生的事件。</p>
<h3 id="控件事件处理">16.4.1 控件事件处理</h3>
<p>在创建按钮时，可通过command参数设置当按钮按下时调用的函数，即事件响应函数，用法如下例所示：</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> <span class="kw">def</span> do_1():  </span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">2</span>     <span class="bu">print</span>(<span class="st">&quot;按下1&quot;</span>)  </span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">3</span>    </span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">4</span> bt<span class="op">=</span>tkinter.Button(win, text<span class="op">=</span><span class="st">&#39;1&#39;</span>,command<span class="op">=</span>do_1)  </span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">5</span> bt.pack()  </span></code></pre></div>
<p>第01-02行定义了事件的响应函数do_1，并在函数中显示字符串“按下1”。<br />
第04行创建按钮控件，并指定按下按钮时调用函数do_1（注意：本行do_1函数并未被调用）。</p>
<h3 id="窗口事件处理">16.4.2 窗口事件处理</h3>
<p>在创建按钮时，可通过protocol设置窗口相关事件的响应函数。下例为设置窗口关闭事件，在窗口关闭时自动调用fun1函数。</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span> <span class="im">import</span> tkinter  </span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">2</span>    </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">3</span> <span class="kw">def</span> func1():  </span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">4</span>     <span class="bu">print</span>(<span class="st">&quot;关闭窗口&quot;</span>)  </span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">5</span>     win.destroy()  </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">6</span>       </span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">7</span> win <span class="op">=</span> tkinter.Tk()  </span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">8</span> win.geometry(<span class="st">&quot;400x400+200+50&quot;</span>)  </span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">9</span> win.protocol(<span class="st">&quot;WM_DELETE_WINDOW&quot;</span>,func1)  </span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="dv">10</span>    </span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="dv">11</span> win.mainloop()  </span></code></pre></div>
<p>第03行定义事件响应函数fun1。<br />
第04行显示字符串＂关闭窗口＂。<br />
第05行调用窗口的destroy方法销毁窗口。<br />
第09行设置在窗口关闭时调用自定义函数fun1，即关联事件和响应函数。</p>
<p><strong>课后练习：</strong></p>
<p>练习二：继续完成上题中计算器程序，响应用户按下各个按钮的事件，更新Label显示算式，在用户按下”=”按钮时，计算算式结果。</p>
<p>（提示：Python的eval函数用于执行字符串表达式，例如eval(“1+2”)的结果为3；十二个按钮功能类似，建议先将其中一两个按钮调试正常后，用复制粘贴的方法实现其它按钮，以免在调试过程中反复修改）。</p>
<h2 id="思维训练">16.5 思维训练</h2>
<h3 id="眼中的世界">16.5.1 眼中的世界</h3>
<p>人们对客观事物比如什么是一、二、三、花、草、树木有着类似的理解，有了这些共识，可以通过语言来沟通；这也让我们误认为，每个人眼中的世界都是相同的。</p>
<p>然而，“一千个读者眼里有一千个哈姆雷特”，不仅是故事，人们对单个文字的理解也不尽相同。对于什么是“爱”，什么是“道德”，这些并非具体可见的事物，由于文化和经历不同，大家的理解也不尽相同，越是不能用语言描述的感觉，差异可能越大。</p>
<p>为什么有些笑话，只有大人才觉得有趣，因为孩子并不知道很多语言的二义性以及背后的引申含义，艺术家激活了大家拥有的共同体验，它们又往往是不可言喻的。引领着读者的思维在具体文字图像和感觉之间跳跃。</p>
<p>语言是一种抽象的符号，是人们交流的工具，却不是现实或思维本身。任何事物或者词汇的意义都取决于它与其它事物的关系，从而形成了脑中复杂的关系网络，而不是简单的字典上的定义。</p>
<h3 id="用语言思考">16.5.2 用语言思考</h3>
<p>在表达的过程中，思维本身也在变化，表达过程中可能创造出一些新的想法，这就是“用语言思考”。对于复杂的内容，无法用语言描述它的所有细节，在表达的过程中，必然经过提炼和简化，这也重构了思维状态。因此，有时候向别人提问的过程中，自己就找到了答案。</p>
<p>语言的结构以链式为主，而思维内部一般是网状连接，描述过程是将一团相互纠缠的细网拆解成为一条主链。当一个人用语言的标号代替一套复杂的结构，就可能建立和处理更加复杂的内容。想要利用语言在他人脑中重建自己脑中的思维结构，必须掌握网状和链状结构相互转换的能力，同时还要了解大家头脑中的“共识”。</p>
<p>比如写一部小说或者电影的观后感就是一种总结和梳理，从文章的内容和结构上也能看到写作者的思路和关注点。练习作文或者写程序，不只是掌握语言本身，也是锻炼总结、抽象的能力。这种能力必须通过不断地书写、修改、总结来增强。</p>
<p>虽然很多思维与语言无关，比如触觉、味觉、情绪，不一定能用语言精确地表达出来，但我们仍然常用语言来思考问题，比如常常听到小孩自言自语，成人思考问题，有时也像在脑中独白或者与人对话，这都是语言赋予我们的思考方式。</p>
<h3 id="语言以外的表达方式">16.5.3 语言以外的表达方式</h3>
<p>语言是一种链式的表达方式，除了简单，它还有利于推导，归因……但是，脑中的结构往往更加复杂，比如下图中的关系，虽然可以用语言描述，但是非常麻烦。除了各个部件之间的关系，描述时还需要考虑如何遣词造句，这就把问题变得更加复杂。</p>
<p><img
src="https://pic4.zhimg.com/80/v2-41cfffd9fc715b2d0b5f57b6296e664b_1440w.jpg" /></p>
<p>图16.9 关系图</p>
<p>流程图，思维导图，公式，程序，它们不仅与自然语言的语法不同，结构也不同。在不同情况下，可采用不同的表达方式，如果做数学应用题的时候也用画图的方法，换一种角度表达，可能描述本身就是问题的答案。</p>
<h3 id="学习语言">16.5.4 学习语言</h3>
<p>霍金曾说：多写一个公式就会吓跑一半读者，英国一项研究证明：数学公式不但会吓跑普通读者，科学家也会被公式吓跑。这主要由于日常生活中并不经常使用公式。学习语言需要大量时间。自然语言是这样，公式和程序语言也一样，需要反复学习和使用才能记忆。</p>
<p>脑中没有大量的存储空间用于记忆，即使空间足够，从海量信息之中查找也需要大量时间。因此，只有反复使用的内容才能被记住。也只有掌握了语言，才可能利用它思考和解决问题。学任何一门非母语的语言都有很大难度，甚至大多数人对母语掌握得也没有想象中那么好，比如很少有人能驾驭小说、新闻等不同风格的文章写作。</p>
<p>写作的人将脑中的思维框架转换成文字，并试图在读者脑中构建起类似的结构，其中包括着大量的常识和背景知识，比如通过故事发生的时间、地点、氛围、故事风格，激活读者脑中的某种场景，这些都是文字之外的信息。思维中故事的框架是多层次的网络，而机器所识别的文字只是相对扁平的结构。</p>
<p>通过前几讲的学习可以看到，目前机器学习模仿写武侠小说的能力已经非常强大，而小说的风格明显不适合写新闻。如果想训练机器写所有类型文章，则需要使用非常大量的数据训练模型，让它拥有基本写作能力。然后再根据要生成的不同文章类型，定向训练。机器有海量的存储和算力，但不是每个人都有时间和条件作大规模的训练。</p>
<p>学习自然语言也一样，如果希望读懂新闻，对话，科技论文，就需要非常大量的训练，不如想看论文，就主要读论文，当然，练习“阅读论文”对“对话水平”提高有限。</p>
<h2 id="小结">16.6 小结</h2>
<h3 id="单词">16.6.1单词</h3>
<p>本讲需要掌握的英文单词如表16.3所示。</p>
<p><img
src="https://pic1.zhimg.com/80/v2-e2c9e19b0038ae7a4eed54b034c17980_1440w.jpg" /></p>
<p>表16.3本讲需要掌握的英文单词</p>
<h3 id="习题答案">16.6.2习题答案</h3>
<p>1．练习一：绘制如图16.8所示的计算器界面，其中上方用Label显示输入数值和计算结果，下方提供12个按钮用于输入数字和符号。</p>
<p>2．练习二：继续完成上题中计算器程序，响应用户按下各个按钮的事件，更新Label显示算式，在用户按下”=”按钮时，计算算式结果。</p>
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">1</span>   <span class="im">import</span> tkinter  </span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">2</span>     </span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">3</span>   win<span class="op">=</span>tkinter.Tk()  </span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">4</span>     </span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">5</span>   f1<span class="op">=</span>tkinter.Frame(win)  </span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">6</span>   f1.pack()  </span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">7</span>   f2<span class="op">=</span>tkinter.Frame(win)  </span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">8</span>   f2.pack()  </span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="er">9</span>     </span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="dv">10</span>   label<span class="op">=</span>tkinter.Label(f1,text<span class="op">=</span><span class="st">&quot;&quot;</span>)  </span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="dv">11</span>   label.grid(row<span class="op">=</span><span class="dv">0</span>,column<span class="op">=</span><span class="dv">0</span>)  </span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="dv">12</span>   <span class="kw">def</span> do_1():  </span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="dv">13</span>       y<span class="op">=</span>label[<span class="st">&#39;text&#39;</span>]  </span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="dv">14</span>       x<span class="op">=</span><span class="bu">str</span>(<span class="dv">1</span>)  </span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="dv">15</span>       s<span class="op">=</span>y<span class="op">+</span>x  </span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="dv">16</span>       label.configure(text<span class="op">=</span>s)  </span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="dv">17</span>         </span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="dv">18</span>   bt1<span class="op">=</span>tkinter.Button(f2,text<span class="op">=</span><span class="st">&#39;1&#39;</span>,command<span class="op">=</span>do_1)  </span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="dv">19</span>   bt1.grid(row<span class="op">=</span><span class="dv">1</span>,column<span class="op">=</span><span class="dv">0</span>)  </span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="dv">20</span>   <span class="kw">def</span> do_2():  </span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="dv">21</span>       y<span class="op">=</span>label[<span class="st">&#39;text&#39;</span>]  </span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="dv">22</span>       x<span class="op">=</span><span class="bu">str</span>(<span class="dv">2</span>)  </span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="dv">23</span>       s<span class="op">=</span>y<span class="op">+</span>x  </span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="dv">24</span>       label.configure(text<span class="op">=</span>s)  </span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="dv">25</span>     </span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="dv">26</span>   bt1<span class="op">=</span>tkinter.Button(f2,text<span class="op">=</span><span class="st">&#39;2&#39;</span>,command<span class="op">=</span>do_2)  </span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="dv">27</span>   bt1.grid(row<span class="op">=</span><span class="dv">1</span>,column<span class="op">=</span><span class="dv">1</span>)  </span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="dv">28</span>   <span class="kw">def</span> do_3():  </span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a><span class="dv">29</span>       y<span class="op">=</span>label[<span class="st">&#39;text&#39;</span>]  </span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="dv">30</span>       x<span class="op">=</span><span class="bu">str</span>(<span class="dv">3</span>)  </span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="dv">31</span>       s<span class="op">=</span>y<span class="op">+</span>x  </span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a><span class="dv">32</span>       label.configure(text<span class="op">=</span>s)  </span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>…   <span class="co"># 此处省略其它数字  </span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a><span class="dv">90</span>   btjia<span class="op">=</span>tkinter.Button(f2,text<span class="op">=</span><span class="st">&#39;+&#39;</span>,command<span class="op">=</span>do_jiahao)  </span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a><span class="dv">92</span>   btjia.grid(row<span class="op">=</span><span class="dv">4</span>,column<span class="op">=</span><span class="dv">1</span>)  </span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a><span class="dv">93</span>   <span class="kw">def</span> do_dengyu():  </span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a><span class="dv">94</span>       y<span class="op">=</span>label[<span class="st">&#39;text&#39;</span>]  </span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a><span class="dv">95</span>       t<span class="op">=</span><span class="bu">str</span>(<span class="bu">eval</span>(y))  </span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a><span class="dv">96</span>       label.configure(text<span class="op">=</span>t)  </span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a><span class="dv">97</span>         </span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a><span class="dv">98</span>   btd<span class="op">=</span>tkinter.Button(f2,text<span class="op">=</span><span class="st">&#39;=&#39;</span>,command<span class="op">=</span>do_dengyu)  </span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a><span class="dv">99</span>   btd.grid(row<span class="op">=</span><span class="dv">4</span>,column<span class="op">=</span><span class="dv">2</span>)  </span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a><span class="dv">100</span>  <span class="kw">def</span> do_jianhao():  </span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a><span class="dv">101</span>      y<span class="op">=</span>label[<span class="st">&#39;text&#39;</span>]  </span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a><span class="dv">102</span>      x<span class="op">=</span><span class="bu">str</span>(<span class="st">&#39;-&#39;</span>)  </span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a><span class="dv">103</span>      s<span class="op">=</span>y<span class="op">+</span>x  </span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a><span class="dv">104</span>      label.configure(text<span class="op">=</span>s)  </span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>…    <span class="co"># 此处省略乘除运算  </span></span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a><span class="dv">132</span>  win.mainloop()  </span></code></pre></div>
<p>3．练习三：总结常见错误信息及其原因。</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>少儿编程</tag>
      </tags>
  </entry>
  <entry>
    <title>少儿Python编程_第十八：讲搭建网站</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%B0%91%E5%84%BF%E7%BC%96%E7%A8%8B/18_%E5%B0%91%E5%84%BFPython%E7%BC%96%E7%A8%8B_%E7%AC%AC%E5%8D%81%E5%85%AB%E8%AE%B2%EF%BC%9A%E6%90%AD%E5%BB%BA%E7%BD%91%E7%AB%99/</url>
    <content><![CDATA[<p>#少儿编程 #Python</p>
<h1
id="少儿python编程_第十八讲搭建网站">少儿Python编程_第十八讲：搭建网站</h1>
<p>上一讲学习了编写网页代码的方法，到目前为止，创建的网页文件只能用浏览器打开。如果需要用同一网络中的其它电脑或者手机访问该页面，则需要搭建HTTP服务。</p>
<p>普通电脑上也可以搭建HTTP服务，成为小型的HTTP服务器，使用Python搭建HTTP服务非常简单，不需要额外安装软件，只要安装Python的三方模块Flask即可实现。</p>
<p>使用Python开发网站，只需要加入少量代码，就可以将Python的工作成果快速地展示给用户。</p>
<h2 id="简单例程">18.1 简单例程</h2>
<p>Flask是一个轻量级的Web应用框架，占用资源少，使用简单。本节将学习如何用Flask创建一个最简单的网站。</p>
<p>在Anaconda安装时已经安装了Flask，因此可以直接使用，程序代码如下：</p>
<pre><code>01 from flask import Flask  
02    
03 app = Flask(__name__)  
04    
05 @app.route(&#39;/test.html&#39;)  
06 def hello_world():  
07     return &#39;&lt;h1&gt;Hello World! &lt;/h1&gt;&#39;  
08    
09   app.run(host=&#39;0.0.0.0&#39;, port=8088)  
  </code></pre>
第01行引入了flask三方模块的Flask类。<br />
第03行创建一个flask对象，并赋值给app，传入的参数 <strong>name</strong>
（注意：前后都是两条下划线）是当前模块的名字。<br />
第05行用于指定在访问网址的路径“/test.html”时调用的函数。<br />
第06-07行定义访问路径对应的函数hello_word()，函数返回的字符串”
<h1>
Hello<br />
World!
</h1>
<p>”是html风格的简单网页数据，其作用是将字符串“Hello
World!”作为标题显示。<br />
此处是本节的重点，程序定义了hello_word函数，但并没有看到调用它的代码，这是由于第05行将其下面定义的函数关联到该网站的“/test.html”路径下，也就是说当用户访问该网址时，hello_world()函数被调用，其返回值被返回给浏览器显示。<br />
第09行用run函数开启了Web服务的主循环，它将一直运行，直到程序退出，参数将主机host设置为IP地址’0.0.0.0’，启动程序的端口为8088。’0.0.0.0’是一个特殊的IP地址，设置之后，网络上的其它设备才能访问该服务，否则只有本机可以访问。</p>
<p>在Jupyter<br />
Notebook中运行服务后，程序将一直处于运行状态，如果想停止该服务，需要点击Jupyter界面上的“中断服务”（“运行”图标右边的黑色矩形图标），<br />
<strong>重启服务时也需要先中断，再开启，这点非常重要。</strong>
否则修改可能不起作用。</p>
<p>程序只使用了不到10行代码，在本机的8088端口启动了HTTP服务，此时用浏览器打开网址：http://127.0.0.1:<br />
8088/test.html，即可看到本机启动的网络服务。其中127.0.0.1
是一个特殊的IP地址，它代表当前计算机。</p>
<p>利用本机对外的IP地址，可以让同一网络上的其他计算机或者手机访问当前的HTTP服务，方法如下，先打开Windows命令行：开始菜单-<br />
&gt;所有程序-&gt;附件-&gt;命令提示符，在其中输入ipconfig命令，其结果中显示的IPv4地址（如：192.168.1.107），即本机的IP地址。</p>
<p>通过手机浏览器打开当前HTTP服务的效果如图18.1所示：</p>
<figure>
<img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81MzU3ODkzLWQwZGY1OGUzZDk5YmNiOTQucG5n?x-oss-%20process=image/format,png"
alt="图18.1 手机打开Web服务效果" />
<figcaption aria-hidden="true">图18.1<br />
手机打开Web服务效果</figcaption>
</figure>
<p>图18.1 手机打开Web服务效果</p>
<h2 id="地址和端口">18.2 地址和端口</h2>
<h3 id="地址">18.2.1 地址</h3>
<p>网页是使用上一讲介绍的工具制作的HTML文件，可通过浏览器解析成图文格式。网站指的是互联网上特定内容相关网页的集合。</p>
<p>浏览网页时，在浏览器上方的地址栏输入网址，一般用英文字母表示。此处的网址指的是URL统一资源定位符，一般由三部分组成：第一部分是协议（如HTTP）；第二部分是存有该资源的主机地址，有时也包括端口号；第三部分是主机资源的具体路径。例如：</p>
<p><a
href="https://blog.csdn.net/xieyan0811">https://blog.csdn.net/xieyan0811</a><br />
其中https是协议， <a href="http://blog.csdn.net">blog.csdn.net</a><br />
是主机地址，xieyan0811是主机资源的具体路径。</p>
<p>主机地址可以用IP地址表示，例如192.168.0.1，为了方便记忆，采用域名来代替IP地址标识站点地址，如blog.csdn.net，域名一般由有意义的字符串表示。域名解析就是域名到IP地址的转换过程。域名的解析工作由DNS服务器完成。DNS服务器一般是由运营商负责维护的，它也是互联网的重要组成部分。</p>
<p>打开Windows命令行：开始菜单-&gt;所有程序-&gt;附件-&gt;命令提示符，在其中输入ipconfig命令，其结果中显示的IPv4地址，即本机的IP地址。</p>
<h3 id="端口号">18.2.2 端口号</h3>
<p>客户端可以通过ip地址或者域名找到对应的服务器，服务器端则可以提供一种或者多种服务，比如Web服务、文件传输服务、邮件服务等等，不同的服务使用端口号区分，例如：邮件服务常用110端口，文件传输常用21端口，HTTP常用80端口等等。端口号的取值范围是1-65535，1-1023为系统端口，其中大多数端口号已经定义了对应的功能，如上面列出的常用端口；1024-5000为临时端口，5001-65535用于自定义端口，开发者开发的服务一般使用这一端口范围。</p>
<p>上例中使用Flask建立的Web服务默认启动在5000端口，而程序用port参数指定了8088为服务启动的端口号。在浏览器的地址栏中输入网址时，用冒号分隔IP地址和端口号，形如<br />
<a
href="http://192.168.1.107:8088/test.html">http://192.168.1.107:8088/test.html</a>
。</p>
<h3 id="url命名规则">18.2.3 URL命名规则</h3>
<p>URL请求允许使用小写字母，数字，部分特殊符号（非制表符）组成。其中的中文空格等特殊字符需要转码成特殊字符。因此，请尽量减少使用中文以及特殊符号，以使用字母、数字下划线为主。</p>
<h2 id="动态网页">18.3 动态网页</h2>
<h3 id="网页模板">18.3.1 网页模板</h3>
<p>上例中服务端返回的简单网页是由程序生成的，网页内容被写在Python代码文件之中，当网页内容较多时，一般存储在单独的文件之中。</p>
<p>网页常常是由较多的静态内容和较少的动态内容共同构成的，使用模板用于组合静态内容和动态内容。</p>
<p>模板是一个包含响应文本的文件，它通常是html文件，该文件中允许包含“占位变量”来表示动态的内容，"占位变量"在程序中被真实的值所替换。Flask内部使用<br />
Jinja2
模板引擎实现模板功能。从模板文件中读出数据，用真实数据替代占位变量，并将文件中的数据转换成Python字符串，这一过程称为渲染render。</p>
<p>Flask中的模板文件保存在templates目录下，该目录与源码存储在同一目录之中。</p>
<p>模板中的“占位变量”用两个大括号{ {占位变量名}}表示，例如：</p>
<pre><code>01 用户名：&#123;&#123;name&#125;&#125;  
  </code></pre>
<p>其中的name将在渲染时被程序中的真实值代替。</p>
<h3 id="生成动态网页">18.3.2 生成动态网页</h3>
<p>本例用于生成一个动态网页，网页中的大部分数据保存在templates目录下，名为demo.html的HTML文件中。以Jupyter<br />
Notebook编辑器为例。</p>
<p>首先，创建目录templates：在文件列表界面的右上点击：New-&gt;Folder创建目录，选中该目录（在目录名前的方框中打勾），点左上角的rename将目录名改为templates。</p>
<p>然后，创建网页文件：进入templates目录，点击右上：New-&gt;Text<br />
File创建文本文件，写入以下HTML格式文本，然后在列表界面，选中该文件，点左上角的rename将文件改名为demo.html。在Jupyter中，HTML文件不能像Python其它文件那样通过点击直接打开，需要先选中该文件，然后点击上方的编辑铵钮Edit，才能修改，直接点击HTML文件，会在浏览器中显示该网页效果。将demo.html修改成以下内容：</p>
<pre><code>01 &lt;html&gt;  
02     &lt;body&gt;  
03 用户名：&#123;&#123;name&#125;&#125;  
04         &lt;/br&gt;  
05 密码：&#123;&#123;password&#125;&#125;  
06     &lt;/body&gt;  
07 &lt;/html&gt;  
  </code></pre>
<p>第03和05行，分别使用了两个占位变量，用于插入动态数据。</p>
<p>在与templates目录平级的位置（不在templates目录之中）创建Python代码文件，输入以下代码：</p>
<pre><code>01 from flask import Flask  
02 from flask import render_template  
03    
04 app = Flask(__name__)  
05    
06 @app.route(&#39;/show.html&#39;)  
07 def page2():  
08 return render_template(&#39;demo.html&#39;, name=&quot;张三&quot;, password=&quot;123456&quot;)  
09    
10 app.run(host=&#39;0.0.0.0&#39;, port=8088)  
  </code></pre>
<p>第02行导入了用于渲染网页的三方库render_template。<br />
第06行指定在访问网站的show.html路径时，调用page2函数。<br />
第07-08行实现了page2函数，使用render_template渲染上面编辑的网页demo.html（程序在templates目录下读取文件），然后设置了文件中的两个占位变量name和password。此处涉及的文件目录较为复杂，请读者在计算机上完成以上实验。</p>
<p>程序运行结果如图18.2所示，可以看到网页中的占位变量被程序中设置的参数所代替。</p>
<figure>
<img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81MzU3ODkzLTI0Yzg4ZWI5OTBmMzZmZmIucG5n?x-oss-process=image/format,png"
alt="图18.2利用模板生成网页效果" />
<figcaption aria-hidden="true">图18.2利用模板生成网页效果</figcaption>
</figure>
<p>图18.2 利用模板生成网页效果</p>
<p><strong>课后练习：</strong> （练习答案见本讲最后的小结部分）<br />
练习一：将本节中的动态网页示例程序输入计算机，保证程序正常运行。<br />
（练习中涉及的内容较多，实现过程中需要不断在网页编辑界面、程序界面、浏览器测试效果的界面之间切换，它锻炼了切分问题，以及分步解决问题的能力。）</p>
<h2 id="表单">18.4 表单</h2>
<p>表单form是一种网页的形式，一般用于收集用户信息，例如：网站的用户注册页面一般需要输入用户名、密码、联系方式、真实姓名等信息，此类网页一般由表单实现。</p>
<h3 id="post与get方式">18.4.1 POST与GET方式</h3>
<p>POST和GET是HTTP请求的两种方式，上面学习的例程都是GET方式，且客户端没有向服务端传送参数。POST请求和GET请求都支持客户端向服务端传送数据，但格式不同。</p>
<p><strong>1．GET方式</strong></p>
<p>GET方式传递参数时，名/值对是在GET请求的URL中发送的，例如：</p>
<pre><code>01 http://192.168.1.104/login.html?user=a&amp;passwd=123  
  </code></pre>
<p>其中问号之后是客户端向服务端传递的参数，本例中共有两个参数，参数之间用“<br />
&amp;”符号分隔，参数是名/值对，如第一个参数的参数名是user，值是a，名值之间用“=”连接。</p>
<p><strong>2．POST方式</strong></p>
<p>POST方式传递参数时，名/值对是在HTTP的消息体中发送的，从URL中无法得知，POST请求更加安全，例如用POST方式传送的密码不会被显示在网页地址栏中，有更好的保密性。下面介绍的表单主要使用POST方式传输数据。</p>
<h3 id="表单-1">18.4.2 表单</h3>
<p>表单是客户端提交给服务器端的一组数据，与之前学习过的软件界面一样，它可以包含输入框、单选框、密码框等等控件供用户输入，一般包含提交和重置两个按钮，当用户点击提交按钮时，浏览器将向服务端发起请求，将表单中用户输入的数据发送给服务器。因此使用表单一方面需要在HTML文件中添加表单，另一方面需要在服务端的程序中处理由表单传来的数据。</p>
<p>首先，使用以下程序在模板目录下创建含有表单的HTML文件login_base.html：</p>
<pre><code>01 &lt;html&gt;  
02     &lt;body&gt;  
03         &lt;form action=&quot;show.html&quot; method=&quot;post&quot;&gt;  
04             用户名：&lt;input type=&quot;text&quot; name=&quot;name&quot; value=&quot;zhangsan&quot;/&gt;  
05             密码：&lt;input type=&quot;password&quot; name=&quot;passwd&quot; /&gt;  
06             &lt;input type=&quot;submit&quot; value=&quot;登录&quot;/&gt;  
07         &lt;/form&gt;  
08     &lt;/body&gt;  
09 &lt;/html&gt;  
  </code></pre>
第03行标记了表单form元素的开始，并使用action属性设置当用户点击提交时，跳转到网站的show.html路径，处理方式是POST。<br />
第04行显示了文字“用户名”和普通输入框，表单中的元素由input标签定义，标签的具体类型由其type属性指定，普通输入框的类型是“text”，name设置了被提交数据的名字“name”，以便于服务端的程序读取不同的用户输入内容，属性value指定了输入框的默认值为“zhangsan”。<br />
第05行显示了文字“密码”和密码输入框，它的类型为password，密码输入框中输入的任何字符都显示成“*”以便于保密，name设置了提交数据的名字“passwd”，供服务器读出数据时使用。<br />
第06行加入提交按钮，它的类型为submit，意思是提交，value指定了铵钮上显示的文字是“登录”。<br />
第07行的
</form>
<p>标签标记了表单结束。</p>
<p>然后，编写Python程序，该程序包含两个界面，一个是提供给用户输入用户名和密码的登录界面login.html，另一个是显示用户是否登录成功的提示界面show.html。</p>
<pre><code>01 from flask import Flask,request  
02 from flask import render_template  
03    
04 app = Flask(__name__)  
05    
06 @app.route(&quot;/login.html&quot;)  
07 def page1():  
08     return render_template(&#39;login_base.html&#39;)  
09                              
10 @app.route(&#39;/show.html&#39;,methods=[&quot;POST&quot;])  
11 def page2():  
12     if request.method==&#39;POST&#39;:  
13         u=request.form[&#39;name&#39;]  
14         p=request.form[&#39;passwd&#39;]  
15         if u == &#39;zhangsan&#39; and p == &#39;123456&#39;:  
16             return render_template(&#39;demo.html&#39;, name=u, password=p)  
17         else:  
18             return &quot;用户名或密码错误&quot;  
19     else:  
20         return &quot;请求错误&quot;  
21    
22 app.run(host=&#39;0.0.0.0&#39;, port=8088)  
  </code></pre>
<p>第01行引入了flask三方模块的Flask和request，其中request用于接收客户端传来的参数。<br />
第06行关联了login.html与page1函数，当用户在浏览器打开网络路径login.html时调用page1函数，route译为路由，它的含义是寻找从源地址到目标地址的最佳路径。<br />
第07-08行实现了page1函数，它从templates模板目录下加载了login_base.html文件，并将其转换成字符串类型，作为page1函数的返回值。</p>
<p>第10行关联了show.html与page2函数，并用参数methods指出接收POST请求发来的数据。<br />
第11-18行实现了page2函数。<br />
第12行判断用户请求是否为POST请求，如果不是POST请求，则跳转到19-20行返回请求错误。<br />
第13行从post请求中取出名为“name”的数据并将该数据赋值给变量u，关键字“name”在HTML文件中定义。<br />
第14行从post请求中取出名为“passwd”的数据并将该数据赋值给变量p。<br />
第15行判断用户名和密码，如果是zhangsan和123456则执行16行，否则返回“用户名密码错误”。<br />
第16行读取之前创建的模板文件demo.html，并用真实的用户名和密码替换HTML文件中的占位变量。</p>
<p>程序运行结果如图18.3所示：</p>
<figure>
<img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81MzU3ODkzLTA0YzMzNDg2ZDczMGZhZTQucG5n?x-oss-process=image/format,png"
alt="图18.3登录界面效果图" />
<figcaption aria-hidden="true">图18.3登录界面效果图</figcaption>
</figure>
<p>图18.3 登录界面效果图</p>
<p><strong>课后练习：</strong></p>
<p>练习二：在7777端口打开HTTP服务，实现用户注册界面，用户输入：姓名、用户名、密码、年龄，按确认后，显示注册成功界面其中包含用户注册信息。</p>
<h2 id="思维训练">18.5 思维训练</h2>
<h3 id="建立框架">18.5.1 建立框架</h3>
<p>建立处理问题的统一框架，类似于前几讲提到过的抽象的处理问题，它几乎是最重要的学习方法，通过一次或几次学习，总结出处理一类问题的解决方法。以后再遇到类似问题，不需要重新学习具体处理方法，直接代入框架，即可解决问题。人工智能中的“训练机器学习模型”就是建立框架的过程；在程序中使用函数，也用到建立框架的思路，具体方法是：</p>
<p>第一步：切分，将整体功能切分成小块。<br />
第二步：实现，将具体实现功能的代码封装到函数之中，建立最基本的结构，确定框架中的不变部分和可变部分。<br />
第三步：定义使用场景，在什么情况下可以使用，以及如何使用。<br />
第四步：包容，扩展其功能，增加适用范围，让该框架不仅可用于当前情况，之后还可以在更多的情况下使用。</p>
<h3 id="积累">18.5.2 积累</h3>
<p>如果找不到规律生成统一框架，就需要记忆具体实例，即积累。但是使用这些未经处理的数据代价很大，需要大量的记忆空间。此时可以考虑简化和分解。</p>
<p>简化时需要区分和保留实例中的重要特征，去掉不重要的，以及常识性的知识。</p>
<p>而分解则是化整为零。写程序也同样有一些约定俗成的要求，比如一个函数中的代码长度最好不要超过一屏，单个代码文件也不要太长，这并不是由于机器无法运行，而是让程序员阅读起来更加方便。因此，有时候即使多次调用，也会把大段代码拆成函数。</p>
<p>积累的另一个使用场景是保存统一框架以外的特例。如果建立处理所有情况的统一框架，规律将非常复杂。此时，可积累一些特例作为统一框架的补充。需要注意的也是保持积累数据的简洁。</p>
<h3 id="重构">18.5.3 重构</h3>
<p>建立框架和积累实例是最常用的方法，如果试用了已有的框架和积累的实例仍无法解决问题，可以尝试重构，重构的核心是使用新的角度把简化问题，而不是改进具体的方法。重构的方法有很多，如：</p>
<ul>
<li><p>从思考问题的结构转为思考问题的功能，如果目标是出一本校刊，又实在无法画好其中的插画，是否可以使用其它途径，比如从网上下载模板……</p></li>
<li><p>把问题划分成小块，然后区分其中重要和次要的成份。重组重要特征，尝试不同的划分方法，不同的边界可能预示着不同解决方法。</p></li>
<li><p>调整看问题角度，从整体到部分，比如可以把大问题拆分成多个小问题，再逐一寻找解法；或者把问题放入一个更大的框架。</p></li>
<li><p>使用类比，并借鉴类似问题的解决方法，比如将学习语文的方法代入英语学习之中，虽然细节有所不同，但其中一些技巧仍可以正常工作。</p></li>
<li><p>头脑风暴，和小组的其他成员在不受任何限制的气氛中讨论、座谈，打破常规，积极思考，畅所欲言，充分发表看法，拼接扩展思路。</p></li>
</ul>
<h2 id="小结">18.6 小结</h2>
<h3 id="单词">18.6.1单词</h3>
<p>本讲需要掌握的英文单词如表18.1所示。</p>
<figure>
<img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81MzU3ODkzLTcxYmQ0MWM1MDlmNDE2NDEucG5n?x-oss-%20process=image/format,png"
alt="表18.1本讲需要掌握的英文单词" />
<figcaption aria-hidden="true">表18.1本讲需要掌握的英文单词</figcaption>
</figure>
<p>表18.1本讲需要掌握的英文单词</p>
<h3 id="习题答案">18.6.2 习题答案</h3>
<ol type="1">
<li><p>练习一：将本节中的动态网页示例程序输入计算机，保证程序正常运行。</p></li>
<li><p>练习二：在7777端口打开HTTP服务，实现用户注册界面，用户输入：姓名、用户名、密码、年龄，按确认后，显示注册成功界面其中包含用户注册信息。</p></li>
</ol>
<pre><code>01 from flask import Flask,request  
02 from flask import render_template  
03    
04 app=Flask(__name__)  
05    
06 @app.route(&quot;/login.html&quot;)  
07 def page1():  
08     return render_template(&#39;login.html&#39;)  
09    
10 @app.route(&#39;/show.html&#39;,methods=[&quot;POST&quot;])  
11 def page2():  
12     if request.method==&#39;POST&#39;:  
13         u=request.form[&#39;name1&#39;]  
14         p=request.form[&#39;mima&#39;]  
15         l=request.form[&#39;name2&#39;]  
16         w=request.form[&#39;old&#39;]  
17         iiii=&quot;注册成功，用户名：&quot;+u+&quot;，密码：&quot;+p+&quot;, 姓名：&quot;+l+&quot;, 年龄：&quot;+w  
18         return iiii  
19     else:  
20         return &quot;不是post, 需要post&quot;  
21           
22 app.run(host=&#39;0.0.0.0&#39;,port=7777)</code></pre>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>少儿编程</tag>
      </tags>
  </entry>
  <entry>
    <title>少儿Python编程_第二十讲：编程技巧</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%B0%91%E5%84%BF%E7%BC%96%E7%A8%8B/20_%E5%B0%91%E5%84%BFPython%E7%BC%96%E7%A8%8B_%E7%AC%AC%E4%BA%8C%E5%8D%81%E8%AE%B2%20%EF%BC%9A%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/</url>
    <content><![CDATA[<p>#少儿编程 #Python</p>
<h1
id="少儿python编程_第二十讲编程技巧">少儿Python编程_第二十讲：编程技巧</h1>
<p>在学习编程的过程中，起初新手开发者对程序没有什么概念，先讲解习惯和注意事项，不但没什么效果，注意事项太多，反而提高了编程的难度；往往在自己遇到问题后，经过思考，印象更加深刻。之前在每一讲课后练习中，也加入了一些技巧说明，但比较分散。本讲将总结编写程序过程中遇到的各种问题和编程习惯。</p>
<h2 id="编程习惯">20.1 编程习惯</h2>
<p>写程序最重要的是实现功能，在实现功能的基础上，好的编程习惯，让代码更清晰，更容易理解，无论是过一段时间自己再看，还是给别人使用都能节约大量时间；同时，好的编程习惯让代码在不同运行环境和操作系统中也能稳定地运行。</p>
<h3 id="缩进">20.1.1 缩进</h3>
<p>缩进指代码与边界之间的距离，Python使用缩进组织代码块，一般用冒号和缩进区分代码之间的层次。代码块缩进常出现在：函数体、循环体、以及判断语句之后。</p>
<p>对Python编程来说，缩进是必不可少的；其它编程语言，也大都包括缩进，但有的不是必须缩进，比如C语言用大括号括住循环体内容，但一般程序员也会使用空格缩进，这样更容易看到代码的层次：直观地看到循环从哪里开始，到哪里结束，缩进也是一种良好的编程习惯。</p>
<p><strong>1．缩进相关错误</strong><br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;pre style=&quot;tab-stops:21.75pt 91.6pt 137.4pt 183.2pt 229.0pt 274.8pt 320.6pt 366.4pt 412.2pt 458.0pt 503.8pt 549.6pt 595.4pt 641.2pt 687.0pt 732.8pt&quot;&gt;    </span><br><span class="line">```  </span><br><span class="line">缩进的英文是Indentation，在报错信息中看到相关的单词，如“unexpected indent”，就需要注意，可能是缩进错误。&lt;/pre&gt;  </span><br><span class="line">```  </span><br><span class="line">&lt;pre style=&quot;tab-stops:21.75pt 91.6pt 137.4pt 183.2pt 229.0pt 274.8pt 320.6pt 366.4pt 412.2pt 458.0pt 503.8pt 549.6pt 595.4pt 641.2pt 687.0pt 732.8pt&quot;&gt;    </span><br><span class="line">```  </span><br><span class="line">有一种常见的错误是：缩进中间断开，如下例所示：&lt;/pre&gt;  </span><br><span class="line">```  </span><br><span class="line">01 if x&gt;0:  </span><br><span class="line">02     print(&quot;x&gt;0&quot;)  </span><br><span class="line">03 print(x)  </span><br><span class="line">04     print(&quot;ok&quot;)  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">编写这段语句的本意是：需要在x大于0时打印02和04句，无论什么情况都打印第03句。但使用以上写法，第三句没有缩进，表示if条件对应的代码块在02句之后已经结束，第04句的缩进出错。  </span><br><span class="line">  </span><br><span class="line">冒号表示一个新代码块的开始，行尾的冒号和新增的缩进一一对应，只有冒号没有新的缩进，或者没有冒号但有新的缩进都是错误的，代码块中间不能断开。  </span><br><span class="line">  </span><br><span class="line">正确的方法是调换第03句和04句的位置。    </span><br><span class="line">  </span><br><span class="line">**2．缩进的空格数**  </span><br><span class="line">  </span><br><span class="line">缩进使用的空格数是可变的，一般情况下，使用四格缩进，但也有人习惯两空格缩进或八空格缩进。在同一程序中必须使用一致的缩进规则，建议使用默认的四格缩进。  </span><br><span class="line">  </span><br><span class="line"> **3．Tab键生成缩进和空格生成缩进**  </span><br><span class="line">  </span><br><span class="line">Tab键输入制表符，用于文本对齐，制表符在不同软件中被显示成四个或者八个空格。在Jupyter Notebook或者Spyder等编程工具中，使用Tab键生成的制表符都被转换成了对应的空格，因此可以使用Tab键生成缩进。但使用Windows记事本这类纯文本编辑器时，不自动转换成空格，如果混用Tab键输入的制表符和空格，程序运行时就会报错，由于制表符和空格看起来差不多，这种错误很难通过观察发现。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 20.1.2 命名  </span><br><span class="line">  </span><br><span class="line">无论是编写程序还是使用文件都会遇到命名问题，比如函数名、类名、变量名、文件名、路径名、网址、数据库的字段名等等。计算机上的命名规则也大同小异。一般都支持英文字母、数字、下划线，有的命名也支持中文、特殊符号、空格等等，虽然有些命名规则支持上百个字符的命名长度，但习惯上一般都在20字符以内，不应太长。    </span><br><span class="line">  </span><br><span class="line">**1．有意义的命名**  </span><br><span class="line">  </span><br><span class="line">命名最重要的是有意义，让自己和他人通过名字可以了解变量或者文件的作用。尽量不要使用a、b这样的命名，很难查找，时间长了自己也会忘记用途。    </span><br><span class="line">  </span><br><span class="line">**2．中文和特殊符号**  </span><br><span class="line">  </span><br><span class="line">Python 3之后的版本，支持用中文命名变量，Windows也支持用中文命名文件和目录。由于在计算机中支持多种中文编码，使用不同软件或者系统打开文件时，默认的编码方式如果不同，则可能出现乱码；另外，有些系统区分大小写字母，有的则视大小写为同一字母。  </span><br><span class="line">  </span><br><span class="line">在编写程序时，尽量使用小写英文字母数字和下划线命名，最好使用有意义的英文单词，其次是使用拼音，尽量少使用中文命名变量、函数和类，除了下划线“_”，命名时也尽量少使用其它的特殊符号和空格，如果想用一个以上的词命名变量，建议使用下划线分隔词，例如“get_width”相比“getwidth”更加直观。  </span><br><span class="line">  </span><br><span class="line">另外，还需要注意区分下划线“_”和减号“-”；中英文标点符号不同；一些字符看起来比较像，比如大写的i（I）和小写的L（l），英文字母O和数字0比较容易混淆等等。    </span><br><span class="line">  </span><br><span class="line">**3．命名习惯**  </span><br><span class="line">  </span><br><span class="line">注意根据用途命名，例如：主要给老师、同学、家长（中国人）看的文件名、目录名可以用中文命名；给程序员看的代码文件名、代码中的内容、数据库字段使用英文字母命名；提供给别人调用的文件或者函数命名要有意义，只供自己使用的内部变量可相对随意一些。  </span><br><span class="line">  </span><br><span class="line">另外，还有一些约定俗成的用法，比如：一般使用字母i，j表示循环中的记数变量。对于一些不变的值，通常使用大写字母命名，比如窗口的长宽常使用WIDTH和HEIGHT命名。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 20.1.3 注释  </span><br><span class="line">  </span><br><span class="line">**1．用途**  </span><br><span class="line">  </span><br><span class="line">注释是对代码的解释和说明，它的目的是让人能够更加轻松地理解代码。虽然使用有意义的命名可以描述程序文件、函数、变量的功能，但命名不能太长，一般通过注释进行更加详细的说明。注释有以下几种使用场景：  </span><br><span class="line">  </span><br><span class="line">* 在程序文件的开头介绍该程序的功能和用法。  </span><br><span class="line">* 在函数之前介绍函数的功能和用法。  </span><br><span class="line">* 在难以理解的语句前后，说明语句的功能。  </span><br><span class="line">* 将暂时不用的代码注释掉。  </span><br><span class="line">  </span><br><span class="line">注释要尽量写得简洁而清楚，如果不熟悉英文，就用中文写，内容比形式更重要。不光自己看得懂，也要让别人能看懂。    </span><br><span class="line">  </span><br><span class="line">**2．用法**  </span><br><span class="line">  </span><br><span class="line">Python使用井号“#”实现单行注释，当前行中井号之后的内容都视为注释。使用三引号实现多行注释，形如：  </span><br><span class="line">```  </span><br><span class="line">01 print(&#x27;aaa&#x27;) # 打印信息  </span><br><span class="line">02 &quot;&quot;&quot;  </span><br><span class="line">03 注释第一行  </span><br><span class="line">04 注释第二行  </span><br><span class="line">05 &quot;&quot;&quot;  </span><br><span class="line">```  </span><br><span class="line">三引号用于定义包含回车换行的字符串，可以是三个单引号，也可以是三个双引号。在程序中的字符串，不操作、不赋值，也不影响程序的运行，因此，常作为包含多行的注释使用。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">## 20.2 调试程序  </span><br><span class="line">  </span><br><span class="line">学习自然语言时，除了记住词义以外，还要能组合成句子文章，才能正常使用。编程语言也是一种语言，学习时不仅要记住所学知识点，还要学习程序整体的构造和调试。在每一讲后面的习题可供读者练习编写各种程序。尤其是从第十五章之后，不再对课程中实例的简单修改，而是用完全不同的代码构造新的功能。  </span><br><span class="line">  </span><br><span class="line">如果读者按要求完成了练习，在练习过程中一定遇到了很多的程序错误，也从中学习了解决问题的方法。  </span><br><span class="line">  </span><br><span class="line">本小节将总结常见的问题和解法，并介绍简单有效的程序调试方法。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 20.2.1 常见问题  </span><br><span class="line">  </span><br><span class="line">无论是使用命令行还是Python集成开发环境，程序运行出错时都会显示错误提示。提示信息中最重要的是行号信息，开发者通过行号可以确定错误的大概位置。    </span><br><span class="line">  </span><br><span class="line">**1．语法错误**  </span><br><span class="line">  </span><br><span class="line">![图20.1 语法错误示例](https://upload-images.jianshu.io/upload_images/5357893-ddb4ab8e61e6e953.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line">图20.1是一种常见的错误，“invalid syntax”意思是语法错误，提示错误出现在第二行（line 2），实际上，错误的原因是第一行少了右括号，程序一直在等待右括号，而在第02行却出现了print语句，所以提示为第02行错误。由此可见，也有少量错误行提示，可能是由之前行的错误引起的。但至少可以通过行号确认大概位置。    </span><br><span class="line">  </span><br><span class="line">**2．缩进错误**  </span><br><span class="line">  </span><br><span class="line">图20.2是缩进错误，“unexpected indent”意思是意外的缩进，它由第2行多了一个空格引起，也是常见的输入引起的错误。  </span><br><span class="line">  </span><br><span class="line">![图20.2 缩进错误](https://upload-images.jianshu.io/upload_images/5357893-ab6a3a7eabeb7eaa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line"> **3．名字未定义错误**  </span><br><span class="line">  </span><br><span class="line">图20.3示例了未定义错误，程序在使用y之前，没有定义y，因此提示“name ‘y’ is not defined”（名字’y’没有被定义）。有时候，并不是使用变量或者函数前没有定义，也可能是没有引入函数所在的三方库、或者是输入时拼写错误引起的，比如：混淆字母O和数字0，逗号看成句号，冒号和分号写错等等。像大写I(i)和小写l(L)混淆的错误很难被观察到，这时，可以使用查找功能，比如在Jupyter Notebook中用Ctrl+f查找报错中提示的名字。  </span><br><span class="line">  </span><br><span class="line">![图20.3未定义错误](https://upload-images.jianshu.io/upload_images/5357893-cc5b06c00587736e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line">**4．下标越界错误**  </span><br><span class="line">  </span><br><span class="line">图20.4示例了下标越界错误，报错为“list index out of range”（列表索引号超出范围），程序在第1行定义了含有三个元素的列表arr，在第2行试图访问数组的第4个元素（索引号为3），数组元素索引号从0开始，范围是0,1,2，本例中访问的索引号超过了列表的最大索引号。  </span><br><span class="line">  </span><br><span class="line">![图20.4 下标越界错误](https://upload-images.jianshu.io/upload_images/5357893-24e2114463bb4d68.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line">**5．其它问题**  </span><br><span class="line">  </span><br><span class="line">程序可能出现的错误非常多，无法一一列举，而报错信息一般都是英文的，建议使用以下步骤查找错误原因：  </span><br><span class="line">  </span><br><span class="line">首先，查看错误提示中的行号，以及行号之前的程序，看是否能发现代码错误。  </span><br><span class="line">  </span><br><span class="line">如果未找到原因，查看是否为以上几种错误类型。  </span><br><span class="line">  </span><br><span class="line">如果不是以上问题，用翻译工具翻译错误提示，以定位问题。  </span><br><span class="line">  </span><br><span class="line">如果仍不能找到问题，在搜索引擎（如百度）中搜索错误提示，查看他人解决此类问题的方法。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 20.2.2 调试方法  </span><br><span class="line">  </span><br><span class="line">在程序中间加入断点和打印信息都是标准的程序调试方法，特别是在运行他人编写的代码时，用这种方法可以了解每个阶段做了什么。  </span><br><span class="line">  </span><br><span class="line">我们写的程序都相对简单，类和函数并不多，当运行别人代码时，梳理互相调用关系很重要，最好能画出简单的调用关系图。    </span><br><span class="line">  </span><br><span class="line">**1．print 函数**  </span><br><span class="line">  </span><br><span class="line">Python中的print函数用于打印输出，它虽然不是专用的程序调试工具，但是如果养成使用print跟踪程序运行的习惯，至少一半的问题都可以解决。  </span><br><span class="line">  </span><br><span class="line">学习使用print调试程序不是学习函数的使用方法，而是在编写程序的过程中，要理解程序每一行做了什么工作，每一行程序执行之后当前环境中各个变量的状态是什么，尤其是在循环这样较为复杂的结构中，需要了解每一次循环中数据的变化。而使用print语句则是在开发者不太清楚当前状态的情况下，用程序输出所关注的变量或者数据。  </span><br><span class="line">  </span><br><span class="line">比如加载数据表文件之后，可以用print语句显示加载后的内容以及数据格式，又如跟踪循环中数据的变化情况。如下例所示。  </span><br><span class="line">```  </span><br><span class="line">01 s = 0  </span><br><span class="line">02 for i in [1,2,3]:  </span><br><span class="line">03     s = s + i * 7  </span><br><span class="line">04     print(s, i)  </span><br><span class="line">```  </span><br><span class="line">其中第四行用于显示每一次循环中的s值和i值。当程序并未报错，但输出结果与想象中不同时，可以使用print方法跟踪程序中数据的变化，以定位出错的位置。  </span><br><span class="line">  </span><br><span class="line">还有一种常用的调试方法是注释掉可能错误的程序段，然后运行程序，如果运行仍不正常，说明不是被注释掉语句的问题，继续注释更多的语句；如果注释后运行正常，则说明是该段问题，然后尝试注释掉较少的语句，直到定位到具体出错的行。    </span><br><span class="line">  </span><br><span class="line">**2\. 调试工具pdb**  </span><br><span class="line">  </span><br><span class="line">pdb是Python的调试工具，由于pdb使用方法比较复杂，此处讲解pdb只作为知识扩展，不要求读者掌握。  </span><br><span class="line">  </span><br><span class="line">在Jupyter中加入魔法命令%pdb，即可在程序出错时调用pdb，以便调试出错时的具体代码。例如，运行以下程序：  </span><br><span class="line">```  </span><br><span class="line">01 %pdb  </span><br><span class="line">02 arr = [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;]  </span><br><span class="line">03 print(arr[3])  </span><br><span class="line">```  </span><br><span class="line">程序运行到第三行时，会报错，但并未退出，界面上将出现可交互的输入框，开发者可以在输入框中输入程序如：print(arr)，来进一步运行程序。请注意：调试完成之后需要在输入框中输入exit退出调试模式。  </span><br><span class="line">  </span><br><span class="line">使用pdb的另一种方法是在程序中加入断点，当程序运行到该行，会跳出可交互的输入框，开发者可以通过pdb命令查看当前状态，或者逐步执行断点之后的程序。  </span><br><span class="line">  </span><br><span class="line">设置断点的方法是，在程序中加入pdb.set_trace()，如以下程序所示：  </span><br><span class="line">```  </span><br><span class="line">01 import pdb  </span><br><span class="line">02 arr = [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;]  </span><br><span class="line">03 pdb.set_trace()  </span><br><span class="line">04 print(arr[3])  </span><br><span class="line">```  </span><br><span class="line">pdb常用的调式命令如下：  </span><br><span class="line">  </span><br><span class="line">* 单步调试（进入函数）：s(tep)。  </span><br><span class="line">* 单步调试（不进入函数）：n(ext)。  </span><br><span class="line">* 继续往后执行，直到下个断点：c(ont(inue))。  </span><br><span class="line">* 运行到函数结束：r(eturn)。  </span><br><span class="line">* 运行到当前循环结束：unt(il)。  </span><br><span class="line">* 设置断点：b(reak) 文件名:行号（或行号，或函数名）。  </span><br><span class="line">* 显示当前调用关系：w(here)。  </span><br><span class="line">* 显示当前代码段：l(ist)。  </span><br><span class="line">* 显示变量：p(rint) 变量名。  </span><br><span class="line">* 显示当前函数的参数：a(rgs)。  </span><br><span class="line">* 显示帮助信息：h(elp)。  </span><br><span class="line">* 退出：q(uit)。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 20.2.3 错误处理  </span><br><span class="line">  </span><br><span class="line">程序有时可能出现一些难以预料的错误，比如写客户端程序与服务器端交互，就可能遇到很多问题，如网络未连接，对三方库调用方法不对，与服务器数据交互格式不对，或者以前能正常运行，后来服务端修改了端口，找不到对应功能等等。  </span><br><span class="line">  </span><br><span class="line">这种情况下，程序员，尤其是写程序供他人调用的程序员，需要识别出程序中可能出现的错误，进行错误处理后，保证程序正常运行，而不会意外退出。  </span><br><span class="line">  </span><br><span class="line">当程序运行出错时会抛出异常，如果不做处理，则程序会异常退出，Python用try/except方式捕获异常，其语法规则如下：  </span><br><span class="line">```  </span><br><span class="line">01 try:  </span><br><span class="line">02     程序代码  </span><br><span class="line">03 except &lt;异常类&gt; as &lt;变量&gt;:  </span><br><span class="line">04 异常处理代码  </span><br><span class="line">05 else:  </span><br><span class="line">06     异常以外其它情况处理  </span><br><span class="line">07 finally：  </span><br><span class="line">08     无论是否异常，最终都要执行的代码  </span><br><span class="line">```  </span><br><span class="line">简单实例如下：以读方式打开文件test.txt，该文件不存在时将抛出异常，例程中捕获异常，并显示出具体的异常信息。  </span><br><span class="line">```  </span><br><span class="line">01 try:  </span><br><span class="line">02     f = open(&#x27;test.txt&#x27;, &#x27;r&#x27;)  </span><br><span class="line">03 except Exception as e:  </span><br><span class="line">04     print(&#x27;error&#x27;, e)  </span><br><span class="line">05 print(&#x27;aaaa&#x27;)  </span><br><span class="line">06 # 返回结果：  </span><br><span class="line">07 # error [Errno 2] No such file or directory: &#x27;test.txt&#x27;  </span><br><span class="line">08 # aaaa  </span><br><span class="line">```  </span><br><span class="line">从返回结果可以看到，捕捉到异常信息后，程序正常执行了之后的打印信息操作，而并未因为异常而崩溃。  </span><br><span class="line">  </span><br><span class="line">**课后练习：**（练习答案见本讲最后的小结部分）  </span><br><span class="line">  </span><br><span class="line">练习一：尝试捕获越界的错误。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">## 20.3 思维训练  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 20.3.1 学习编程的好处  </span><br><span class="line">  </span><br><span class="line">  如果读者从头到尾学习了所有例程，并做完了所有习题，可能发现以下变化：  </span><br><span class="line">  </span><br><span class="line">* 熟悉了程序、界面、网络、数据库、数据分析等概念。  </span><br><span class="line">* 熟练使用Python编程环境。  </span><br><span class="line">* 对大多数问题都能定位到关键点。  </span><br><span class="line">* 写程序从修改变成了构建。  </span><br><span class="line">* 不再抵触较长的程序段。  </span><br><span class="line">* 变量命名更有章法。  </span><br><span class="line">* 更喜欢使用工具和快捷键。  </span><br><span class="line">* 能解决大多数语法方面的问题，至少有了解决思路。  </span><br><span class="line">……  </span><br><span class="line">  </span><br><span class="line">12岁以下的学生，对于文中绝大多数的概念都是第一次接触，即使当时学会了，过一段时间也会淡忘，因此推荐整体看三遍以上，最终目标是能自如地编写练习中的每一个程序，并且能够将程序用于日常的数据处理。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 20.3.2 防患于未然  </span><br><span class="line">  </span><br><span class="line">之前提到学习常常分为两部分：一部分从经验中学习，即构建框架；另一部分从教训中学习。经验可以通过实践或者学习规则构造，而教训更多往往是自己犯了错误印象才深。  </span><br><span class="line">  </span><br><span class="line">教训又可再细分成两种情况：改正错误和防患于未然。发现问题及时改正可能导致处理过程的暂停和回退；而防患于未然则更多地源于之前的积累，它们在错误的行为之前就进行了阻止，而从表面看来，似乎非常平稳，未经波折。实际上是经验在毫无意识的情况下就发生了作用。比如我们不会在公共场景提到禁忌话题。  </span><br><span class="line">  </span><br><span class="line">因此，很多时候看起来运气比较好或者天生的灵感，实际上下意识的行为是源于之前的积累。对于一个严谨的人，很多思路在没有外显时可能就已经被过滤掉了，往往也显得没有幽默感，缺少想象力。严谨或者随意可能取决于个人经历和环境，也可能是遗传或者性格所致。  </span><br><span class="line">  </span><br><span class="line">人们不能要求小孩子对陌生人又友好，又有戒心，但是有些成年人却可以做到。我们在成长过程中不断打磨，逐渐学会了在两极之间取折中的方案，在不同的情况下使用不同的框架。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 20.3.3  注意事项  </span><br><span class="line">  </span><br><span class="line">最后，整理了一些学习编程中的注意事项，与大家共同学习：  </span><br><span class="line">  </span><br><span class="line">* 任何老师都不可能列出所有可能出现的问题，要学会在试错中进步。  </span><br><span class="line">* 基础知识非常重要，无论文科理科记和背都是必须的，对常用知识构建条件反射，才能有更多的脑力用于后续的学习和思考。  </span><br><span class="line">* 完成功能后整理代码：从变量命名到代码顺序，都请严格要求自己。  </span><br><span class="line">* 量的问题积累太多，就变成了质的问题：一个小问题，努力一下也许能解决，但是十个小问题堆叠起来，脑子就直接转不动了。  </span><br><span class="line">* 代码重构比代码填空难度大得多，尽量多练习构建整体代码逻辑。  </span><br><span class="line">* 分类和对比非常重要，如果不能直接找到答案，可以寻找类似的情况及处理方法。  </span><br><span class="line">* 代码需要逐行读懂，长代码，很可能读到后面忘了前面，建议边读边记，最好能绘制流程图，有时候也需要反复阅读。  </span><br><span class="line">* 初学者对例程往往知其然，不知其所以然，在看他人代码时尽量动手跟踪调试程序。  </span><br><span class="line">* 写程序像弹琴一样需要不断练习，即使学一遍就会，后边不用也会很快忘记。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">## 20.4 小结  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 20.4.1 单词  </span><br><span class="line">  </span><br><span class="line">本讲需要掌握的英文单词如表20.1所示。  </span><br><span class="line">  </span><br><span class="line">![表20.1本讲需要掌握的英文单词](https://upload-images.jianshu.io/upload_images/5357893-a8881357a4a57246.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 20.4.2 习题答案  </span><br><span class="line">  </span><br><span class="line">1. 练习一：尝试捕获越界的错误。  </span><br><span class="line">```  </span><br><span class="line">01 try:  </span><br><span class="line">02     arr=[&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;]  </span><br><span class="line">03     print(arr[3])  </span><br><span class="line">04 except Exception as e:  </span><br><span class="line">05     print(&#x27;error&#x27;,e)  </span><br><span class="line">06 print(&#x27;aaaa&#x27;)  </span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>少儿编程</tag>
      </tags>
  </entry>
  <entry>
    <title>MYSQL数据库大太的解决方案</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E6%95%B0%E6%8D%AE%E5%BA%93/MYSQL_%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%A7%E5%A4%AA%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[<h1 id="mysql-数据库大太的解决方案">MYSQL 数据库大太的解决方案</h1>
<p>#数据库/MYSQL</p>
<h2 id="面对问题">面对问题</h2>
<p>插入查询慢、且需要时效性比较强的情况</p>
<h2 id="原因">原因</h2>
<p>MYSQL 容量上千万条以上就会很慢。</p>
<h2 id="解决方法">解决方法</h2>
<h3 id="分区">分区</h3>
<p>对应用透明，相对操作比较简单。<br />
对主键有要求：所有主键里必须包含分区主键，如果又想用id查，又想用年份查就比较难。<br />
查询会受一些影响：批量查时快不了多少，插入可以提速。</p>
<h3 id="分库">分库</h3>
<p>比如不同年份可以放在不同主机上，以加快速度。</p>
<h3 id="分表">分表</h3>
<p>一般都使用分表策略。<br />
需要看按什么分，比如按用户id分，或者按年份分表。<br />
按时间分：热表（当前一年数据）、冷表（往年数据），最后一个年份的冷表可能看需要看是否保存最新数据；需要确定冷热表是否重叠，如果重叠。<br />
如按年份分表，注意按业务时间而不是编辑时间（这个时间可能变化）</p>
<h2 id="迁移场景">迁移场景</h2>
<p>需要定义迁移规则：比如每个月迁一次（新表、本年表、前一年表），对时间字段建索引<br />
*
历史数据迁移：如果表巨大，则不使用查询，从第一条开始向其它表里分流；选改表，再改其上应用。<br />
*
新表间迁移：假设每月迁一次，每月把这个月数据从热表里迁出来（同样是分流）；也可以双写，即每次写入冷表和热表，定期删热表最后的数据。<br />
* 补采数据：在修修补补的情况下（补采数据），又写可能更合适。<br />
* 数据表结构修改：不分表时操作一次，分表后需要同一操作，执行多次。<br />
* 注意一：单批次迁移每次1000-10000条，不要太大。<br />
* 注意二：在复杂的场景下，双写最好。</p>
<h2 id="注意事项">注意事项</h2>
<ul>
<li>索引<br />
对于在巨大表中可能查询的数据一定要建索引<br />
</li>
<li>表碎片清理<br />
热表不断地写入删除，需要定期清理，方法如下：<br />
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">alter table 表名 engine=innodb;</span>  </span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>少儿Python编程_第十九讲 数据分析网站</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E5%B0%91%E5%84%BF%E7%BC%96%E7%A8%8B/19_%E5%B0%91%E5%84%BFPython%E7%BC%96%E7%A8%8B_%E7%AC%AC%E5%8D%81%E4%B9%9D%E8%AE%B2%EF%BC%9A%20%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E7%BD%91%E7%AB%99/</url>
    <content><![CDATA[<p>#少儿编程 #Python</p>
<h1
id="少儿python编程_第十九讲数据分析网站">少儿Python编程_第十九讲：数据分析网站</h1>
<p>本讲是一个综合实例，结合了数据分析和构建网站技术，提供用户通过浏览器上传文件，在服务端实现分析上传的数据，并生成动态统计表格，回传给用户端。其中用到表单上传文件、读取Excel数据表文件、统计图表、生成动态网页等技术。</p>
<h2 id="上传文件">19.1 上传文件</h2>
<p>让用户上传文件，处理后再把结果返回给用户，是一个很常用的操作，比如用户上传一张相片，服务器端经过美颜或者换背景处理后显示在网页上；又如用户上传一个Excel数据表文件，数据统计分析后把统计结果显示给用户。开发者提供前端和后端服务。用户使用网络中任意一台计算机或者手机，只需要用浏览器即可实现需要的功能，无需安装任何软件。</p>
<p>上传文件功能也可通过表单实现。本例展示了上传文件的方法。为简化代码逻辑，将HTML模板也写入了Python代码。<br />
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">01 <span class="keyword">from</span> flask <span class="keyword">import</span> Flask,request,redirect,url_for  </span><br><span class="line">02 <span class="keyword">import</span> os  </span><br><span class="line">03    </span><br><span class="line">04 UPLOAD_DIR = <span class="string">&quot;files&quot;</span>  </span><br><span class="line">05    </span><br><span class="line">06 app=Flask(__name__)  </span><br><span class="line">07    </span><br><span class="line">08 @app.route(<span class="string">&quot;/upload.html&quot;</span>)  </span><br><span class="line">09 <span class="keyword">def</span> <span class="title function_">page1</span>():  </span><br><span class="line"><span class="number">10</span>     <span class="keyword">return</span> <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">11 &lt;html&gt;  </span></span><br><span class="line"><span class="string">12     &lt;h1&gt;请上传文件&lt;/h1&gt;  </span></span><br><span class="line"><span class="string">13     &lt;form action=&quot;show.html&quot; method=post enctype=multipart/form-data&gt;  </span></span><br><span class="line"><span class="string">14         &lt;input type=file name=upload_file&gt;  </span></span><br><span class="line"><span class="string">15         &lt;input type=submit value=&#x27;上传&#x27;&gt;  </span></span><br><span class="line"><span class="string">16     &lt;/form&gt;  </span></span><br><span class="line"><span class="string">17 &lt;html&gt;  </span></span><br><span class="line"><span class="string">18     &quot;&quot;&quot;</span>  </span><br><span class="line"><span class="number">19</span>    </span><br><span class="line"><span class="number">20</span> @app.route(<span class="string">&quot;/show.html&quot;</span>, methods=[<span class="string">&quot;POST&quot;</span>,<span class="string">&quot;GET&quot;</span>])  </span><br><span class="line"><span class="number">21</span> <span class="keyword">def</span> <span class="title function_">page2</span>():  </span><br><span class="line"><span class="number">22</span>     <span class="keyword">if</span> request.method==<span class="string">&quot;POST&quot;</span>:  </span><br><span class="line"><span class="number">23</span>         file = request.files[<span class="string">&#x27;upload_file&#x27;</span>]  </span><br><span class="line"><span class="number">24</span>         <span class="keyword">if</span> file:  </span><br><span class="line"><span class="number">25</span>             <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(UPLOAD_DIR):  </span><br><span class="line"><span class="number">26</span>                 os.mkdir(UPLOAD_DIR)  </span><br><span class="line"><span class="number">27</span>             file.save(os.path.join(UPLOAD_DIR, file.filename))  </span><br><span class="line"><span class="number">28</span>             <span class="keyword">return</span> <span class="string">&quot;上传成功&quot;</span>  </span><br><span class="line"><span class="number">29</span>     <span class="keyword">return</span> redirect(url_for(<span class="string">&#x27;page1&#x27;</span>))  </span><br><span class="line"><span class="number">30</span>    </span><br><span class="line"><span class="number">31</span> app.run(host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="string">&quot;8088&quot;</span>)  </span><br><span class="line">```  </span><br><span class="line">第01行引入flask模块中的几种方法：Flask用于建立服务，request用于接收用户传来的数据，redirect用于网页跳转，url_for用于查找函数名对应的路径。  </span><br><span class="line">第04行定义了存储上传文件的目录。  </span><br><span class="line">第08-<span class="number">18</span>行定义了函数用于提供用户选择文件和上传文件的界面。  </span><br><span class="line">第08-09行关联了网址中的路径与函数，当用户在浏览器中打开“/upload.html”时调用函数page1。  </span><br><span class="line">第<span class="number">10</span>-<span class="number">18</span>行描述了返回的HTML文件，使用三个双引号可定义带有回车的字符串。读者也可以将这段代码写成文件，放在templates目录下，在程序中用render_template函数加载。  </span><br><span class="line">第<span class="number">13</span>-<span class="number">15</span>行定义了表单，表单提交时以POST方式访问路径“show.html”。  </span><br><span class="line">第<span class="number">14</span>行添加了选择上传文件的控件，并将该控件命名为upload_file，以便程序读取。  </span><br><span class="line">第<span class="number">20</span>-<span class="number">29</span>行定义了用户上传文件后的响应界面。  </span><br><span class="line">第<span class="number">22</span>行判断是否为“POST”请求。  </span><br><span class="line">第<span class="number">23</span>行获取上传的文件，赋值给变量file。  </span><br><span class="line">第<span class="number">24</span>行判断file变量是否正常。  </span><br><span class="line">第<span class="number">25</span>-<span class="number">26</span>行判断保存文件的目录是否存在，如果不存在，则创建该目录。  </span><br><span class="line">第<span class="number">27</span>行使用文件保存路径加文件名，构造文件在服务端的存储路径。  </span><br><span class="line">第<span class="number">28</span>行向客户端返回“上传成功”字符串。  </span><br><span class="line">第<span class="number">29</span>行用于处理在非“POST”请求的情况下，跳转到page1对应的地址upload.html继续显示上传文件界面。  </span><br><span class="line">  </span><br><span class="line">程序运行结果如图<span class="number">19.1</span>所示：  </span><br><span class="line">  </span><br><span class="line">![图<span class="number">19.1</span>文件上传界面](https://upload-images.jianshu.io/upload_images/<span class="number">5357893</span>-eb69b8d944ee3843.png?imageMogr2/auto-orient/strip%7CimageView2/<span class="number">2</span>/w/<span class="number">1240</span>)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 19.2 PyEcharts  </span></span><br><span class="line">  </span><br><span class="line">探索性数据分析简称**EDA**，它是通过图表方式探索数据的结构和规律的一种数据分析方法。常用的方法有直方图、箱线图、变量分析等等。  </span><br><span class="line">  </span><br><span class="line">Echarts是一个用Javascript实现的商业级数据图表工具，它可以流畅的运行在计算机和手机设备上，兼容当前绝大部分浏览器。Pyecharts是Python版本的Echarts，它的使用方法类似前面讲过的matplotlib，虽然它主要用于网页显示，但可以在Jupyter Notebook中调试，并且生成HTML文件。调试的显示效果和HTML页面效果完全一样。与其它EDA工具相比，它使用更方便，配色方案也更加考究。  </span><br><span class="line">  </span><br><span class="line">之前学习了使用Matplotlib绘制图表，Matplotlib虽然能实现绝大多数的图表绘制，但默认字体和配色效果都不太美观，如果想做出高级的图表，需要设置大量的参数，虽然它也能将图表保存成图片，但只支持静态图片，且嵌入网页操作比较复杂。  </span><br><span class="line">  </span><br><span class="line">PyEcharts解决了以上问题，它可以生成与用户交互的动态网页，有完美的字体和配色方案，用简单方法绘制复杂图片，并且可以方便地与Flask框架配合使用。  </span><br><span class="line">  </span><br><span class="line">本节将介绍PyEcharts的使用方法。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">### 19.2.1 准备环境  </span></span><br><span class="line">  </span><br><span class="line">**<span class="number">1</span>．安装软件**  </span><br><span class="line">  </span><br><span class="line">在使用PyEcharts之前需要用以下命令安装模块，PyEcharts不同版本使用方法不同，本例中使用了当前的默认版本<span class="number">1.4</span><span class="number">.0</span>。在Windows中打开：开始-&gt;所有程序-&gt;Anaconda <span class="number">3</span>-&gt;Anaconda Prompt，在终端输入：  </span><br><span class="line">```  </span><br><span class="line">01 $ pip install pyecharts  </span><br><span class="line">```  </span><br><span class="line">**<span class="number">2</span>．数据准备**  </span><br><span class="line">  </span><br><span class="line">将表<span class="number">19.1</span>中的数据存入Excel数据表test.xlsx，作为数据分析的素材。表中共有<span class="number">9</span>条记录，<span class="number">8</span>个字段，包括字符型（姓名）、类别型（性别、类型、年龄、出场频率），数值型（智力、体力、颜值）。  </span><br><span class="line">  </span><br><span class="line">![表<span class="number">19.1</span> 待分析的数据表](https://upload-images.jianshu.io/upload_images/<span class="number">5357893</span>-67ea55ff7abce7a2.png?imageMogr2/auto-orient/strip%7CimageView2/<span class="number">2</span>/w/<span class="number">1240</span>)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">### 19.2.2 绘制柱状图  </span></span><br><span class="line">  </span><br><span class="line">柱状图非常实用，本例展示了在同一张图中显示多柱对比效果的方法，对比了智力和体力两个特征，将每个人的智力和体力用不同颜色的柱表示：  </span><br><span class="line">``` python  </span><br><span class="line">01 <span class="keyword">import</span> pandas <span class="keyword">as</span> pd  </span><br><span class="line">02 <span class="keyword">from</span> pyecharts <span class="keyword">import</span> charts  </span><br><span class="line">03 <span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts  </span><br><span class="line">04    </span><br><span class="line">05 df = pd.read_excel(<span class="string">&#x27;test.xlsx&#x27;</span>)  </span><br><span class="line">06    </span><br><span class="line">07 bar = charts.Bar()  </span><br><span class="line">08 bar.add_xaxis(df[<span class="string">&#x27;姓名&#x27;</span>].tolist())  </span><br><span class="line">09 bar.add_yaxis(<span class="string">&quot;智力&quot;</span>, df[<span class="string">&#x27;智力&#x27;</span>].tolist())  </span><br><span class="line"><span class="number">10</span> bar.add_yaxis(<span class="string">&quot;体力&quot;</span>, df[<span class="string">&#x27;体力&#x27;</span>].tolist())  </span><br><span class="line"><span class="number">11</span> bar.set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">&quot;喜羊羊与灰太狼&quot;</span>))  </span><br><span class="line"><span class="number">12</span> bar.render(<span class="string">&#x27;test.html&#x27;</span>)  </span><br><span class="line"><span class="number">13</span> bar.render_notebook()  </span><br><span class="line">```  </span><br><span class="line">第01行引入了数据表支持模块Pandas，并将其重命名为pd。  </span><br><span class="line">第02行引入了绘图模块PyEcharts的子模块charts用于绘制图表。  </span><br><span class="line">第03行引入了绘图模块PyEcharts的子模块options并重命名为opts用于设置参数。  </span><br><span class="line">第05行读入数据表文件test.xlsx，并将其内容赋值给变量df，注意将数据文件放在与程序相同的目录中。  </span><br><span class="line">第07行创建了Bar对象用于绘制柱图。  </span><br><span class="line">第08行设置了柱图的横坐标数据为姓名字段的内容，设置前将数据格式转换为列表。  </span><br><span class="line">第09行设置了柱图的纵坐标数据，第一个参数为显示的文字，第二个参数为柱的高度,本行设置了智力字段的内容。  </span><br><span class="line">第<span class="number">10</span>行设置了柱图的纵坐标数据为体力字段的内容，工具用不同颜色区分不同的数据。  </span><br><span class="line">第<span class="number">11</span>行将标题设置为“喜羊羊与灰太狼”，其中用到了opt模块的标题参数工具TitleOpts。  </span><br><span class="line">第<span class="number">12</span>行将图表数据渲染后保存到test.html文件中，此时当前目录下产生了新文件 test.html，如果test.html已经存在，程序将替换文件内容。  </span><br><span class="line">第<span class="number">13</span>行将图表内容显示在Jupyter Notebook窗口之中。  </span><br><span class="line">  </span><br><span class="line">程序运行结果如图<span class="number">19.2</span>所示：  </span><br><span class="line">  </span><br><span class="line">![图<span class="number">19.2</span> 柱图效果](https://upload-images.jianshu.io/upload_images/<span class="number">5357893</span>-6495d17c54068c16.png?imageMogr2/auto-orient/strip%7CimageView2/<span class="number">2</span>/w/<span class="number">1240</span>)  </span><br><span class="line">  </span><br><span class="line">在Jupyter Notebook中，可以显示图表的动态效果：将鼠标放在柱上，可以反馈当前柱对应的数据。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">### 19.2.3 绘制饼图  </span></span><br><span class="line">  </span><br><span class="line">饼图使用的数据和其它图表不同，需要指定每个区域显示的文字以及对应的数量。  </span><br><span class="line">``` python  </span><br><span class="line">01 pie = charts.Pie()  </span><br><span class="line">02 m = <span class="built_in">len</span>(df[df[<span class="string">&#x27;性别&#x27;</span>]==<span class="string">&#x27;男&#x27;</span>])  </span><br><span class="line">03 f = <span class="built_in">len</span>(df[df[<span class="string">&#x27;性别&#x27;</span>]==<span class="string">&#x27;女&#x27;</span>])  </span><br><span class="line">04 data = [[<span class="string">&#x27;男&#x27;</span>,m],[<span class="string">&#x27;女&#x27;</span>,f]]  </span><br><span class="line">05 pie.add(<span class="string">&quot;&quot;</span>, data, radius=[<span class="number">60</span>, <span class="number">150</span>],)  </span><br><span class="line">06 pie.render(<span class="string">&#x27;test.html&#x27;</span>)  </span><br><span class="line">07 pie.render_notebook()  </span><br><span class="line">```  </span><br><span class="line">第01行创建了Pie对象用于绘制柱图。  </span><br><span class="line">第02行统计了性别为男的实例数量，本例中为<span class="number">6</span>个。  </span><br><span class="line">第03行统计了性别为女的实例数量，本例中为<span class="number">3</span>个。  </span><br><span class="line">第04行构建了两层列表，外层对应饼图中划分的不同区域，内层的两个值分别是：显示的文字及对应的大小。  </span><br><span class="line">第05行将数据加入饼图，其中radius参数指定了饼图内圈和外圈半径。  </span><br><span class="line">  </span><br><span class="line">程序运行结果如图<span class="number">19.3</span>所示：  </span><br><span class="line">  </span><br><span class="line">![图<span class="number">19.3</span> 饼图效果](https://upload-images.jianshu.io/upload_images/<span class="number">5357893</span>-c3e6bfeff71d7150.png?imageMogr2/auto-orient/strip%7CimageView2/<span class="number">2</span>/w/<span class="number">1240</span>)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">### 19.2.4 绘制折线图  </span></span><br><span class="line">  </span><br><span class="line">折线图的绘制方法类似柱图，本例中除了绘制基本的折线图，还加入了图中最大值、最小值、以及平均值虚线的显示。  </span><br><span class="line">``` python  </span><br><span class="line">01 bar = charts.Line()  </span><br><span class="line">02 bar.add_xaxis(df[<span class="string">&#x27;姓名&#x27;</span>].tolist())  </span><br><span class="line">03 bar.add_yaxis(<span class="string">&quot;智力&quot;</span>, df[<span class="string">&#x27;智力&#x27;</span>].tolist(),  </span><br><span class="line">04          markline_opts=opts.MarkLineOpts(data=[opts.MarkLineItem(type_=<span class="string">&quot;average&quot;</span>)]),  </span><br><span class="line">05          markpoint_opts=opts.MarkPointOpts(data=[opts.MarkPointItem(type_=<span class="string">&quot;max&quot;</span>)]))  </span><br><span class="line">06 bar.add_yaxis(<span class="string">&quot;体力&quot;</span>, df[<span class="string">&#x27;体力&#x27;</span>].tolist(),  </span><br><span class="line">07          markline_opts=opts.MarkLineOpts(data=[opts.MarkLineItem(type_=<span class="string">&quot;average&quot;</span>)]),  </span><br><span class="line">08          markpoint_opts=opts.MarkPointOpts(data=[opts.MarkPointItem(type_=<span class="string">&quot;min&quot;</span>)]))  </span><br><span class="line">09 bar.set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">&quot;喜羊羊与灰太狼&quot;</span>))  </span><br><span class="line"><span class="number">10</span> bar.render(<span class="string">&#x27;test.html&#x27;</span>)  </span><br><span class="line"><span class="number">11</span> bar.render_notebook()  </span><br><span class="line">```  </span><br><span class="line">第01行创建了Pie对象用于绘制柱图。  </span><br><span class="line">第03-05行设置了柱图的纵坐标数据智力，第一个参数为显示的文字，第二个参数为柱的高度，参数markline_opts用于设置标志线，这里用标志线显示了均值average，参数markline_opts用于设置标志点，此处将显示最大值<span class="built_in">max</span>点为标志点。  </span><br><span class="line">第06-08行设置了柱图的纵坐标数据体力，标签线设置为均值average，标志点设置为最小值点。  </span><br><span class="line">  </span><br><span class="line">程序运行结果如图<span class="number">19.4</span>所示：  </span><br><span class="line">  </span><br><span class="line">![图<span class="number">19.4</span>折线图效果](https://upload-images.jianshu.io/upload_images/<span class="number">5357893</span>-0ca2fe6f67cf171a.png?imageMogr2/auto-orient/strip%7CimageView2/<span class="number">2</span>/w/<span class="number">1240</span>)  </span><br><span class="line">  </span><br><span class="line">本节介绍了三种常用图表，Pyecharts还支持更多的图表，不同版本的Pyecharts的函数调用方法也有差异，因此想自如地使用该模块，需要学会从三方模块自带的例程中学习使用方法，更多实例请参考：https://github.com/pyecharts/pyecharts的example目录下的例程。  </span><br><span class="line">  </span><br><span class="line">课后练习：（练习答案见本讲最后的小结部分）  </span><br><span class="line">  </span><br><span class="line">练习一：从git的pyecharts示例代码中学习一种之前没学过的图表，在Jupyter Notebook中正常运行，并讲述每行程序的作用。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 19.3 显示图表网页  </span></span><br><span class="line">  </span><br><span class="line">以上几个实例中用render方法将动态网页保存成HTML格式的文件，只要在Flask框架中需要显示图表处返回该网页的内容就可以在客户端的浏览器中正常显示图表。  </span><br><span class="line">  </span><br><span class="line">以下实例结合了本讲学习的上传文件和制作图表功能，根据用户上传的Excel文件生成图表，并将结果反馈给浏览器显示图表。  </span><br><span class="line">``` python  </span><br><span class="line">01 <span class="keyword">from</span> flask <span class="keyword">import</span> Flask,request,redirect,url_for,render_template  </span><br><span class="line">02 <span class="keyword">import</span> os  </span><br><span class="line">03 <span class="keyword">import</span> pandas <span class="keyword">as</span> pd  </span><br><span class="line">04 <span class="keyword">from</span> pyecharts <span class="keyword">import</span> charts  </span><br><span class="line">05    </span><br><span class="line">06 UPLOAD_DIR = <span class="string">&quot;files&quot;</span>  </span><br><span class="line">07 app = Flask(__name__)  </span><br><span class="line">08    </span><br><span class="line">09 @app.route(<span class="string">&quot;/upload.html&quot;</span>)  </span><br><span class="line"><span class="number">10</span> <span class="keyword">def</span> <span class="title function_">page1</span>():  </span><br><span class="line"><span class="number">11</span>     <span class="keyword">return</span> <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">12 &lt;html&gt;  </span></span><br><span class="line"><span class="string">13     &lt;h1&gt;请上传文件&lt;/h1&gt;  </span></span><br><span class="line"><span class="string">14     &lt;form action=&quot;show.html&quot; method=post enctype=multipart/form-data&gt;  </span></span><br><span class="line"><span class="string">15         &lt;input type=file name=upload_file&gt;  </span></span><br><span class="line"><span class="string">16         &lt;input type=submit value=&#x27;上传&#x27;&gt;  </span></span><br><span class="line"><span class="string">17     &lt;/form&gt;  </span></span><br><span class="line"><span class="string">18 &lt;html&gt;  </span></span><br><span class="line"><span class="string">19     &quot;&quot;&quot;</span>  </span><br><span class="line"><span class="number">20</span>    </span><br><span class="line"><span class="number">21</span> @app.route(<span class="string">&quot;/show.html&quot;</span>, methods=[<span class="string">&quot;POST&quot;</span>,<span class="string">&quot;GET&quot;</span>])  </span><br><span class="line"><span class="number">22</span> <span class="keyword">def</span> <span class="title function_">page2</span>():  </span><br><span class="line"><span class="number">23</span>     <span class="keyword">if</span> request.method==<span class="string">&quot;POST&quot;</span>:  </span><br><span class="line"><span class="number">24</span>         file = request.files[<span class="string">&#x27;upload_file&#x27;</span>]  </span><br><span class="line"><span class="number">25</span>         <span class="keyword">if</span> file:  </span><br><span class="line"><span class="number">26</span>             <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(UPLOAD_DIR):  </span><br><span class="line"><span class="number">27</span>                 os.mkdir(UPLOAD_DIR)  </span><br><span class="line"><span class="number">28</span>             filename = os.path.join(UPLOAD_DIR, file.filename)  </span><br><span class="line"><span class="number">29</span>             file.save(filename)  </span><br><span class="line"><span class="number">30</span>             df = pd.read_excel(filename)  </span><br><span class="line"><span class="number">31</span>             bar = charts.Bar()  </span><br><span class="line"><span class="number">32</span>             bar.add_xaxis(df[<span class="string">&#x27;姓名&#x27;</span>].tolist())  </span><br><span class="line"><span class="number">33</span>             bar.add_yaxis(<span class="string">&quot;智力&quot;</span>, df[<span class="string">&#x27;智力&#x27;</span>].tolist())  </span><br><span class="line"><span class="number">34</span>             bar.add_yaxis(<span class="string">&quot;体力&quot;</span>, df[<span class="string">&#x27;体力&#x27;</span>].tolist())  </span><br><span class="line"><span class="number">35</span>             bar.render(<span class="string">&#x27;templates/test.html&#x27;</span>)  </span><br><span class="line"><span class="number">36</span>             <span class="keyword">return</span> render_template(<span class="string">&#x27;test.html&#x27;</span>)             </span><br><span class="line"><span class="number">37</span>     <span class="keyword">return</span> redirect(url_for(<span class="string">&#x27;page1&#x27;</span>))  </span><br><span class="line"><span class="number">38</span>    </span><br><span class="line"><span class="number">39</span> app.run(host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="string">&quot;8088&quot;</span>)  </span><br><span class="line">```  </span><br><span class="line">    </span><br><span class="line">  本例中的大部分代码来自前面例程，因此不再逐行讲解，只介绍特殊部分。  </span><br><span class="line">  第01-<span class="number">20</span>行代码引入头文件，并实现上传文件界面。  </span><br><span class="line">  第<span class="number">21</span>-<span class="number">37</span>行对上传的文件数据分析做图，将其结果返回给客户端。  </span><br><span class="line">  第<span class="number">29</span>行将上传的文件存储在服务器端的文件之中。  </span><br><span class="line">  第<span class="number">30</span>行打开保存的数据表文件。  </span><br><span class="line">  第<span class="number">31</span>-<span class="number">35</span>行绘制图表，并将图表存储在<span class="string">&#x27;templates/test.html&#x27;</span>文件中。  </span><br><span class="line">  第<span class="number">36</span>行将test.html文件内容返回给客户端，需要注意的是第<span class="number">35</span>和<span class="number">36</span>行中的test.html是同一文件，由于调用方式不同，第<span class="number">35</span>行用pyecharts保存时指定了全路径。而<span class="number">36</span>默认从模板目录读取文件，因此不加入模板目录名。  </span><br><span class="line">  </span><br><span class="line">课后练习：  </span><br><span class="line">  </span><br><span class="line">练习二：用Excel数据表创建一个小学生从一年级到六年级<span class="number">12</span>个学期语文、数学、英语各科成绩的数据表，使用浏览器上传到服务器，服务器用折线图绘制其各科成绩的曲线，并在图中标出语文的平均分、最高分、最低分。做饼图分析英语成绩为“优秀”的比例（大于等于<span class="number">90</span>分认为优秀）。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 19.4 思维训练  </span></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">### 19.4.1学方法和学知识  </span></span><br><span class="line">  </span><br><span class="line">有一次，我让某位小朋友查一查“红果酱”怎么做，于是她去百度搜索到一个“一斤红果加一斤糖”的做法，我隐约觉得糖是不是放太多了？于是我也用类似方法搜索，找到三种排名靠前的三种不同做法，最终将红果和糖的比例确定为<span class="number">5</span>:<span class="number">3</span>，并按照多数帖子中描述的步骤进行了操作。当面对同一个陌生的问题，不同人有不同的处理方法。  </span><br><span class="line">  </span><br><span class="line">在这个过程中，成人的常识起到了一定作用，成人能估计出一斤糖的甜度。而对比多种教程则是一种通过“数据”训练“模型”的方法，把脆弱的单一方法，扩展成实现目标的多条路径，以便处理更多的突发状况。另外，还有一些小技巧，比如查看美食攻略的排名、点赞数等等。可以说，这不仅是儿童和成人的区别，而是学习方法的区别。  </span><br><span class="line">  </span><br><span class="line">在这个信息爆炸的时代，学习一门技能不再需要报班、买书，网络上有大量唾手可得的教程、视频，水平也良莠不齐（培训班也存在同样问题）。学习对大多数人来说，学习已经不仅是努力、认真、听老师的话；更高阶的技能是辨别学习资料的品质、合理安排时间和强度，寻找最优的途径，以及能客观地认识自己和评价外界的信息。  </span><br><span class="line">  </span><br><span class="line">时代不同了，我们拥有了更多选择，判断力也比以往更加重要。如何培养判断力？判断一个教程和买一件衣服的规则不同，而货比三家、以及强大的常识系统是所有判断的基础。常识系统来自于行千里路读万卷书，尝试更多新鲜事物，而学习和思维的方法则源于通过有目标的训练培养出的良好习惯。  </span><br><span class="line">  </span><br><span class="line">来看看机器人是如何学习的。Toyota正在开发一款厨房机器人，首先，让机器人拥有了视觉、触觉、运动，以及与人交流的基本能力，然后训练做具体工作的能力：比如通过多次训练机器人从架子上拿东西，以适应于不同环境，不同的架子，不同的光线，处理意外情况……同样也是先构建基本技能和学习方法，然后学习各种具体的技能。这种模仿式的学习，不再需要海量的数据训练，使机器人可以通过少量学习即可掌握各种家务技能，相比另一个只具有精准抓取技能的机器人，虽然没那么准确，但适用于更多场合。  </span><br><span class="line">  </span><br><span class="line">人也是一样，把一项技能训练得再精准，也没有机器精准。从工厂的蓝领，到实验室的白领，谁又能保证你的技能有一天不会被机器人取代。学霸学方法，学渣学知识。而拥有学习的技能，长远看，可以用短时间培养出新技能，永不过时；近期看，也省了不少报补习班的费用。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">### 19.4.2 规则与练习  </span></span><br><span class="line">  </span><br><span class="line">除了数学或者神学这些人造领域，现实中基本没有用之四海皆准的方法，拥有的方法越多能力越强。最重要的两种学习方法是：在练习中领悟和直接学习规则，它们各有利弊。如果需要快速提高，学习规则肯定是捷径，使用同样的时间和精力，的确能让人暂时领先；从素质教育的角度看，如果有足够时间，建议多做练习，毕竟练习具体技术的过程也是对比、总结、提炼，泛化，建立内部框架的过程。  </span><br><span class="line">  </span><br><span class="line">在反复练习一项技能，尤其在寻找一个问题多个解法的过程中，一些子模块会反复出现，并且可以重用。比如练字过程中，虽然常用字有几千个，但是基本笔划只有几种，每种笔划写法也有限，随着练习越来越多，即使没人告诉你“捺”的几种写法，也能训练成一种习惯。与此相对的是学习一些前人总结好的规则，比如永字八法，代入已有的规则，也能让人在短时间内快速提高水平。  </span><br><span class="line">  </span><br><span class="line">规则往往是使用语言描述的链式结构，而通过练习得到的是交叉连结的网状结构。使用语言表达时，由于只能提取主干，看起来没什么区别。但是链式结构非常脆弱，只要其中一个环节断开，整个链条就会完全失效，而网状结构中通向终点的路径不只一条，具有足够的健壮性。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">### 19.4.3 复习和复用  </span></span><br><span class="line">  </span><br><span class="line">学习也没有捷径，再好的方法离不开反复训练。复习可以加强记忆，大多数情况下，只有被反复使用的技能才能记住；另外，在多次做同一件事的时候，内部便开启了“优化”过程：解决一个问题可能涉及很多因素，其中哪些重要，哪些只是偶然发生？如果只做一次，可能永远都无法了解。  </span><br><span class="line">  </span><br><span class="line">另一个技巧是学习一些类似的技能，网状结构中很多区域都可以被复用。当你学习了素描、色彩、书法、漫画，共性的部分被一次次激发，相对于单一的链条，将更能找出其重点，并且融会贯通。尤其是对于无法用语言描述的技能，练习一段时间画画之后再练习书法，就感觉上手很快，练习书法的过程中，绘画水平也有所提高。  </span><br><span class="line">  </span><br><span class="line">学习每一种技能都需要花很多的时间和精力，这并不容易，如果钢琴已经学有小成，就更愿意继续学习钢琴，而不是从头再学小提琴。然而大多数人学习钢琴的目标都不是成为音乐家，少年儿童成长阶段主要以培养能力为主，建议做更多尝试。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 19.5 小结  </span></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">### 19.5.1单词  </span></span><br><span class="line">  </span><br><span class="line">本讲需要掌握的英文单词如表<span class="number">19.2</span>所示。  </span><br><span class="line">  </span><br><span class="line">![表<span class="number">19.2</span>本讲需要掌握的英文单词](https://upload-images.jianshu.io/upload_images/<span class="number">5357893</span>-721e8d07f426439b.png?imageMogr2/auto-orient/strip%7CimageView2/<span class="number">2</span>/w/<span class="number">1240</span>)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">### 19.5.2 习题答案  </span></span><br><span class="line">  </span><br><span class="line"><span class="number">1</span>．练习一：从git的pyecharts示例代码中学习一种之前没学过的图表，在Jupyter Notebook中正常运行，并讲述每行程序的作用。  </span><br><span class="line">  </span><br><span class="line">  第一步：打开网址https://github.com/pyecharts/pyecharts。  </span><br><span class="line">  第二步：在网页下方的Demo中找一个感兴趣的图表，记住名字。  </span><br><span class="line">  第三步：打开代码的examples目录，找到名字对应的示例代码。  </span><br><span class="line">  第四步：将示例代码复制到自己的Jupyter Notebook文件中。  </span><br><span class="line">  第五步：把程序中的render改成render_notebook，然后运行程序。  </span><br><span class="line">  第六步：分析程序时注意：创建需要的控件，用add函数加入待分析的数据，用opt设置需要显示的特征属性。  </span><br><span class="line">  </span><br><span class="line"><span class="number">2</span>\. 练习二：用Excel数据表创建一个小学生从一年级到六年级<span class="number">12</span>个学期语文、数学、英语各科成绩的数据表，使用浏览器上传到服务器，服务器用折线图绘制其各科成绩的曲线，并在图中标出语文的平均分、最高分、最低分。做饼图分析英语成绩为“优秀”的比例（大于等于<span class="number">90</span>分认为优秀）。  </span><br><span class="line">  </span><br><span class="line">设计数据如表<span class="number">19.3</span>所示：  </span><br><span class="line">  </span><br><span class="line">![表<span class="number">19.3</span> 学习成绩数据](https://upload-images.jianshu.io/upload_images/<span class="number">5357893</span>-a687cf615d44a560.png?imageMogr2/auto-orient/strip%7CimageView2/<span class="number">2</span>/w/<span class="number">1240</span>)  </span><br><span class="line">``` python  </span><br><span class="line">01 <span class="keyword">from</span> flask <span class="keyword">import</span> Flask,request,redirect,url_for,render_template  </span><br><span class="line">02 <span class="keyword">import</span> os  </span><br><span class="line">03 <span class="keyword">import</span> pandas <span class="keyword">as</span> pd  </span><br><span class="line">04 <span class="keyword">from</span> pyecharts <span class="keyword">import</span> charts  </span><br><span class="line">05 <span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts  </span><br><span class="line">06    </span><br><span class="line">07 UPLOAD_DIR = <span class="string">&quot;files&quot;</span>  </span><br><span class="line">08      </span><br><span class="line">09 app=Flask(__name__)  </span><br><span class="line"><span class="number">10</span>      </span><br><span class="line"><span class="number">11</span> @app.route(<span class="string">&quot;/upload.html&quot;</span>)  </span><br><span class="line"><span class="number">12</span> <span class="keyword">def</span> <span class="title function_">page1</span>():  </span><br><span class="line"><span class="number">13</span>     <span class="keyword">return</span> <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">14 &lt;html&gt;  </span></span><br><span class="line"><span class="string">15     &lt;h1&gt;请上传文件&lt;/h1&gt;  </span></span><br><span class="line"><span class="string">16     &lt;form action=&quot;show.html&quot; method=post enctype=multipart/form-data&gt;  </span></span><br><span class="line"><span class="string">17          &lt;input type=file name=upload_file&gt;  </span></span><br><span class="line"><span class="string">18          &lt;input type=submit value=&#x27;上传&#x27;&gt;  </span></span><br><span class="line"><span class="string">19     &lt;/form&gt;  </span></span><br><span class="line"><span class="string">20 &lt;/html&gt;  </span></span><br><span class="line"><span class="string">21 &quot;&quot;&quot;</span>  </span><br><span class="line"><span class="number">22</span>    </span><br><span class="line"><span class="number">23</span> @app.route(<span class="string">&quot;/show.html&quot;</span>, methods=[<span class="string">&quot;POST&quot;</span>,<span class="string">&quot;GET&quot;</span>])  </span><br><span class="line"><span class="number">24</span> <span class="keyword">def</span> <span class="title function_">page2</span>():  </span><br><span class="line"><span class="number">25</span>     <span class="keyword">if</span> request.method==<span class="string">&quot;POST&quot;</span>:  </span><br><span class="line"><span class="number">26</span>         file = request.files[<span class="string">&#x27;upload_file&#x27;</span>]  </span><br><span class="line"><span class="number">27</span>         <span class="keyword">if</span> file:  </span><br><span class="line"><span class="number">28</span>             <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(UPLOAD_DIR):  </span><br><span class="line"><span class="number">29</span>                 os.mkdir(UPLOAD_DIR)  </span><br><span class="line"><span class="number">30</span>             filename = os.path.join(UPLOAD_DIR, file.filename)  </span><br><span class="line"><span class="number">31</span>             file.save(filename)  </span><br><span class="line"><span class="number">32</span>             df = pd.read_excel(filename)  </span><br><span class="line"><span class="number">33</span>             pie = charts.Pie()  </span><br><span class="line"><span class="number">34</span>             m = <span class="built_in">len</span>(df[df[<span class="string">&#x27;英语&#x27;</span>]&gt;=<span class="number">90</span>])  </span><br><span class="line"><span class="number">35</span>             f = <span class="built_in">len</span>(df[df[<span class="string">&#x27;英语&#x27;</span>]&lt;=<span class="number">89</span>])  </span><br><span class="line"><span class="number">36</span>             data = [[<span class="string">&#x27;90&#x27;</span>,m],[<span class="string">&#x27;89&#x27;</span>,f]]  </span><br><span class="line"><span class="number">37</span>             pie.add(<span class="string">&quot;&quot;</span>, data, radius=[<span class="number">60</span>, <span class="number">150</span>],)  </span><br><span class="line"><span class="number">38</span>             pie.render(<span class="string">&#x27;templates/happy.html&#x27;</span>)  </span><br><span class="line"><span class="number">39</span>             a=render_template(<span class="string">&#x27;happy.html&#x27;</span>)  </span><br><span class="line"><span class="number">40</span>           </span><br><span class="line"><span class="number">41</span>             bar = charts.Line()  </span><br><span class="line"><span class="number">42</span>             bar.add_xaxis(df[<span class="string">&#x27;学期&#x27;</span>].tolist())  </span><br><span class="line"><span class="number">43</span>             bar.add_yaxis(<span class="string">&quot;语文&quot;</span>, df[<span class="string">&#x27;语文&#x27;</span>].tolist(),  </span><br><span class="line"><span class="number">44</span> markline_opts=opts.MarkLineOpts(data=[opts.MarkLineItem(type_=<span class="string">&quot;average&quot;</span>)]),  </span><br><span class="line"><span class="number">45</span>    markpoint_opts=opts.MarkPointOpts(data=[opts.MarkPointItem(type_=<span class="string">&quot;max&quot;</span>),  </span><br><span class="line"><span class="number">46</span>                                          opts.MarkPointItem(type_=<span class="string">&quot;min&quot;</span>)]))  </span><br><span class="line"><span class="number">47</span>             bar.add_yaxis(<span class="string">&quot;数学&quot;</span>, df[<span class="string">&#x27;数学&#x27;</span>].tolist())  </span><br><span class="line"><span class="number">48</span>             bar.add_yaxis(<span class="string">&quot;英语&quot;</span>, df[<span class="string">&#x27;英语&#x27;</span>].tolist())  </span><br><span class="line"><span class="number">49</span>             bar.render(<span class="string">&#x27;templates/happy1.html&#x27;</span>)  </span><br><span class="line"><span class="number">50</span>             b=render_template(<span class="string">&#x27;happy1.html&#x27;</span>)  </span><br><span class="line"><span class="number">51</span>             <span class="keyword">return</span> a + b  </span><br><span class="line"><span class="number">52</span>     <span class="keyword">return</span> redirect(url_for(<span class="string">&#x27;page1&#x27;</span>))  </span><br><span class="line"><span class="number">53</span>    </span><br><span class="line"><span class="number">54</span> app.run(host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="string">&quot;8088&quot;</span>)  </span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>少儿编程</tag>
      </tags>
  </entry>
  <entry>
    <title>MYSQL入门之一_数据库常用命令</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E6%95%B0%E6%8D%AE%E5%BA%93/MYSQL%E5%85%A5%E9%97%A8%E4%B9%8B%E4%B8%80_%E6%95%B0%E6%8D%AE%E5%BA%93%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h1 id="mysql入门之一_数据库常用命令">MYSQL入门之一_数据库常用命令</h1>
<p>#大数据 #数据库/MYSQL</p>
<p>1. 登录<br />
** $ mysql--user=root --password=xxxxxx **</p>
<p>2. 数据库操作<br />
列出所有数据库<br />
** mysql &gt; show databases; **<br />
创建数据库<br />
** mysql &gt; create database x123; **<br />
删除数据库<br />
** mysql &gt; drop database x123; **<br />
连接使用数据库<br />
** mysql &gt; use x123; **</p>
<p>3. 数据表操作<br />
显示数据表<br />
** mysql &gt; show tables; **<br />
创建数据表<br />
** mysql &gt; create table mytable (name VARCHAR(20),sex CHAR(1), birth
DATE);<br />
**<br />
显示表头<br />
** mysql &gt; describe mytable; **<br />
向表中插入数据<br />
** mysql &gt; insert into mytable values('xieyan','f','1980-01-01');
**<br />
具体条件查找<br />
** mysql &gt; select * from mytable where sex ="f"; **<br />
模糊条件查找<br />
** mysql &gt; select * from mytable where name like"%xie%"; **<br />
删除数据表<br />
** mysql &gt; drop table mytable; **<br />
从TXT文件中读取插入数据，SAE不支持load data命令<br />
（TXT文件格式：字段间使用空格分隔，记录间使用换行分隔）<br />
** mysql &gt; load data local infile"testme.txt" into table mytable;
**</p>
]]></content>
      <tags>
        <tag>大数据</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>MYSQL入门之三_将本地MySQL数据导入SAE数据库</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E6%95%B0%E6%8D%AE%E5%BA%93/MYSQL%E5%85%A5%E9%97%A8%E4%B9%8B%E4%B8%89_%E5%B0%86%E6%9C%AC%E5%9C%B0MySQL%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5SAE%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    <content><![CDATA[<h1
id="mysql入门之三_将本地mysql数据导入sae数据库">MYSQL入门之三_将本地MySQL数据导入SAE数据库</h1>
<p>#网站 #数据库/MYSQL</p>
<p>1. MySQL字符集<br />
MySQL的默认字符集是latin1，将本地MySQL库导出成sql，再导入到SAE的MySQL时中文字符出现乱码，解决方法是将本地mysql默认字符集也设成utf8<br />
查看当前MySQL字符集<br />
** mysql &gt; show variables like 'character_set_%'; **<br />
更改MySQL默认字符集<br />
$ vi /etc/mysql/my.cnf<br />
在client和mysqld中加参数<br />
** [client]<br />
default-character-set=utf8<br />
[mysqld]<br />
character-set-server=utf8<br />
init_connect='SET NAMES utf8'<br />
** 重启MySQL后台服务<br />
** $ service mysqld restart **</p>
<p>2. 导入/导出数据<br />
一般导入导出数据通过sql文件进行，sql文件包括一系列sql命令，包含建表，插入数据等等</p>
<p>3. 从MySQL导出数据<br />
** $ mysqldump -h localhost -u root -p 库名 表名 &gt; /tmp/tmp.sql
**</p>
<p>4. 向SAE数据库中导入数据<br />
SAE-&gt;我的应用-&gt;服务管理-&gt;MySQL-&gt;管理MySQL-&gt;导入，选择/tmp/tmp.sql,文件字符集utf8，SQL兼容模式MYSQL40，导入<br />
导入之后可以在管理MySQL界面中看到新导入的数据表</p>
<p>5. 错误处理<br />
如果SAE导入时提示LOCK出错，则在/tmp/tmp.sql中删除所有LOCK,
UNLOCK相关语句即可</p>
<p>6 参考实例</p>
<p>http://oatmental123.sinaapp.com/slim/index.php</p>
]]></content>
      <tags>
        <tag>网站</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>MYSQL入门之二_PHP操作MYSQL</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E6%95%B0%E6%8D%AE%E5%BA%93/MYSQL%E5%85%A5%E9%97%A8%E4%B9%8B%E4%BA%8C_PHP%E6%93%8D%E4%BD%9CMYSQL/</url>
    <content><![CDATA[<h1 id="mysql入门之二_php操作mysql">MYSQL入门之二_PHP操作MYSQL</h1>
<p>#网站 #数据库/MYSQL</p>
<p>1. 本地连接MySQL</p>
<p>** $con= mysql_connect("localhost", "root", "xxxxxx"); **</p>
<p>** if(!$con) { **</p>
<p>** die('Could not connect: ' .mysql_error()); **</p>
<p>** }else { **</p>
<p>** echo"Connect success <br/>"; **</p>
<p>** } **</p>
<p>2. SAE连接MySQL</p>
<p>** $con =mysql_connect(SAE_MYSQL_HOST_M.':'.SAE_MYSQL_PORT, **</p>
<p>** SAE_MYSQL_USER,SAE_MYSQL_PASS); **</p>
<p>** if (!$con) { **</p>
<p>** die('Could not connect: ' .mysql_error()); **</p>
<p>** } else { **</p>
<p>** echo"Connect success <br/>"; **</p>
<p>** } **</p>
<p>** mysql_select_db(SAE_MYSQL_DB,$con); **</p>
<p>3. 断开MySQL</p>
<p>** mysql_close($con); **</p>
<p>4. 建立数据库</p>
<p>** $sql = "CREATE DATABASE IFNOT EXISTS $DATABASE_NAME"; **</p>
<p>** if(mysql_query($sql, $con)) { **</p>
<p>** echo "Database create success <br/>"; **</p>
<p>** }else { **</p>
<p>** echo"Error creating database: " . mysql_error() ." <br/>"; **</p>
<p>** } **</p>
<p>5. 连接使用数据库</p>
<p>** mysql_select_db(<span
class="math inline">\(DATABASE_NAME,\)</span>con); **</p>
<p>6. 建立数据表</p>
<p>** $sql ="CREATE TABLE $TABLE_NAME ( **</p>
<p>** namevarchar(80), **</p>
<p>** ageint **</p>
<p>** )ENGINE=MyISAM DEFAULT CHARSET=utf8"; **</p>
<p>** if(mysql_query(<span class="math inline">\(sql,\)</span>con)) {
**</p>
<p>** echo "Table create success <br/>"; **</p>
<p>** }else { **</p>
<p>** echo"Error creating table: " . mysql_error() . " <br/>"; **</p>
<p>** } **</p>
<p>7. 查找数据</p>
<p>** $sql= "SELECT * FROM <span class="math inline">\(TABLE_NAME where
name like \&quot;%\)</span>INPUT%""; **</p>
<p>** <span class="math inline">\(result=
mysql_query(\)</span>sql,$con); **</p>
<p>** while(<span class="math inline">\(row
=mysql_fetch_array(\)</span>result)) { **</p>
<p>** echo$row['name'] . " " . $row['age']; **</p>
<p>** echo" <br/>"; **</p>
<p>** } **</p>
<p>8. 设置字符集（设置之后的sql操作基于utf8字符集）<br />
** mysql_query("SET NAMES 'utf8'");<br />
mysql_query("SET CHARACTER_SET_CLIENT=utf8");<br />
mysql_query("SET CHARACTER_SET_RESULTS=utf8"); **</p>
]]></content>
      <tags>
        <tag>网站</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>PGSQL使用方法</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E6%95%B0%E6%8D%AE%E5%BA%93/PGSQL%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>#光伏项目 #数据库</p>
<h2 id="相关概念">1 相关概念</h2>
<h4 id="schema">1.1.1 schema</h4>
<p>在 PostgreSQL 中，schema
是一个命名空间，它可以包含数据库对象的名称，如表、视图、索引、数据类型、函数以及运算符。在一个数据库中可以存在多个
schema，它们都有各自的命名空间。这使得多个用户可以在同一个数据库中使用相同的表名，因为它们在不同的
schema 中。</p>
<p>相关SQL命令：<br />
* CREATE SCHEMA：创建一个新的 schema，<br />
* DROP SCHEMA：删除一个 schema<br />
* ALTER SCHEMA：更改一个已存在的 schema 的属性</p>
<h2 id="建立服务器环境">2 建立服务器环境</h2>
<pre class="shell"><code>$ docker pull postgres:11.0  
$ mkdir /exports/project/pv/data/ -p  
$ docker run --rm --name pv_postgres -v /exports/project/pv/data/:/var/lib/postgresql/data -e POSTGRES_PASSWORD=123456 -p 5432:5432 -d postgres:11.0  </code></pre>
<p>此后即可操作：<br />
* 使用 Navicat 连接；<br />
* 创建数据库（注意：字符集按 sql 中的设置）<br />
* 创建 schema<br />
* 用sql导入数据</p>
<h2 id="用命令行连接服务">3 用命令行连接服务</h2>
<pre><code>$ psql -h ip -p 5432 -U username  </code></pre>
<h2 id="常用-sql-命令">4 常用 sql 命令</h2>
<h4 id="查看数据库">4.1.1 查看数据库</h4>
<pre><code>\l  </code></pre>
<h4 id="连接数据库">4.1.2 连接数据库</h4>
<pre><code>\c 数据库名;  </code></pre>
<h4 id="查看当前库中的数据表">4.1.3 查看当前库中的数据表</h4>
<pre><code>\dt  </code></pre>
<h4 id="查看表结构">4.1.4 查看表结构</h4>
<pre><code>\d 表名;  </code></pre>
<h4 id="退出">4.1.5 退出</h4>
<pre><code>\q  </code></pre>
<h4 id="查看-schema-命名空间">4.1.6 查看 SCHEMA 命名空间</h4>
<pre><code>\dn  </code></pre>
<h4 id="查看所有表">4.1.7 查看所有表</h4>
<p>即使使用最高权限的 postgres 用户，命令行连接也可能看不到某些 schema
对应的表，使用以下命令可以看到命名空间中的表。</p>
<pre><code>select * from pg_tables;  </code></pre>
<h4 id="访问表">4.1.8 访问表</h4>
<pre><code>select * from SCHEMA名.表名;  </code></pre>
<h2 id="使用-sqlalchemy-连接-pgsql">5 使用 sqlalchemy 连接 pgsql</h2>
<h3 id="安装">5.1 安装</h3>
<pre class="shell"><code>$ pip install sqlalchemy  
$ pip install psycopg2  </code></pre>
<h3 id="代码">5.2 代码</h3>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sqlalchemy <span class="im">import</span> create_engine, text  </span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sqlalchemy.orm <span class="im">import</span> sessionmaker  </span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>db_url <span class="op">=</span> <span class="st">&quot;postgresql://postgres:123456@192.168.10.106:5432/data&quot;</span>  </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>engine <span class="op">=</span> create_engine(db_url)  </span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>Session <span class="op">=</span> sessionmaker(bind<span class="op">=</span>engine)  </span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>session <span class="op">=</span> Session()  </span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> session.execute(text(<span class="st">&quot;select * from pg_type;&quot;</span>))  </span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> row <span class="kw">in</span> result:  </span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(row)  </span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>session.commit()  </span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>session.close()  </span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>engine.dispose()  </span></code></pre></div>
<h2 id="参考">6 参考</h2>
<p><a
href="https://www.xjx100.cn/news/449047.html?action=onClick">postgresql数据库中多个Schemas互相访问</a><br />
<a
href="https://blog.csdn.net/liu320yj/article/details/132524596">PostgreSQL命令行工具psql常用命令</a><br />
<a href="https://www.modb.pro/db/610658">psql基本命令</a></p>
]]></content>
  </entry>
  <entry>
    <title>半小时搞定Hadoop+Mysql+Hive</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%8D%8A%E5%B0%8F%E6%97%B6%E6%90%9E%E5%AE%9AHadoop+Mysql+Hive+Python/</url>
    <content><![CDATA[<h1 id="半小时搞定hadoopmysqlhive">半小时搞定Hadoop+Mysql+Hive</h1>
<p>#Linux #数据库/MYSQL</p>
<h3 id="说明">1. 说明</h3>
<p> 搭建过Hadoop集群的小伙伴一定知道，如果不用docker，半小时配好Hadoop+Mysql+Hive（后简称Hive）肯定是胡吹，有了Docker镜像，没有说明文档，配好了也不一定会用。本文将介绍如何在半小时内，让Hive在你的Linux系统上运行起来，并且可以通过
Python程序访问其中数据。</p>
<h3 id="使用集群">2. 使用集群</h3>
<p> Hadoop需要安装Java虚拟机，创建Hadoop用户，下载安装Hadoop软件，修改多个配置文件，启动服务等，有时由于操作系统不同还需要重编Hadoop源码。没亲亲自搭建过可以参考这篇<a
href="https://www.jianshu.com/p/7e43e8cd12ba">Python海量数据处理之_Hadoop（一）集群搭建</a>。整个Hadoop系统就非常复杂，涉及各种类型Node的概念及原理。本文主要介绍对HIVE的使用方法，只需要Hadoop可用，因此使用了Hadoop，MySQL及Hive都正常安装和配置好的dokcer
image.</p>
<p> 首先，查找可用的Hive的docker镜像<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker search hive  </span><br><span class="line">```  </span><br><span class="line">&amp;emsp;将teradatalabs/cdh5-hive镜像拉到本地，该镜像约1.78G  </span><br><span class="line">```  </span><br><span class="line">$ docker pull teradatalabs/cdh5-hive  </span><br><span class="line">```  </span><br><span class="line">&amp;emsp;运行docker镜像，请注意这里使用了参数-P，它将docker中开启的所有端口映射到宿主机，端口号与docker内部不同，用docker ps可查看映射的端口号，用浏览器打开50070所映射的宿主机端口，可查看hadoop状态。  </span><br><span class="line">```  </span><br><span class="line">$ docker run --rm -d --name hadoop-master -P -h hadoop-master teradatalabs/cdh5-hive  </span><br><span class="line">$ docker ps  </span><br><span class="line">```  </span><br><span class="line">&amp;emsp;进入已启动的docker容器  </span><br><span class="line">```  </span><br><span class="line">$ docker exec -it hadoop-master bash  </span><br><span class="line">```  </span><br><span class="line">&amp;emsp;进入docker容器之后，先用hadoop命令查看数据存储情况  </span><br><span class="line">```  </span><br><span class="line">&gt; hadoop fs -ls /  </span><br><span class="line">```  </span><br><span class="line">&amp;emsp;试连接mysql数据库，默认密码是root  </span><br><span class="line">```  </span><br><span class="line">&gt; mysql -uroot -proot  </span><br><span class="line">```  </span><br><span class="line">&amp;emsp;进入hive  </span><br><span class="line">```  </span><br><span class="line">&gt; hive  </span><br><span class="line">```  </span><br><span class="line">&amp;emsp;用HSQL建立数据库，并查看当前数据库列表，并退出的hive。其它的操作与mysql类似，此处不再重复。  </span><br><span class="line">```  </span><br><span class="line">&gt; create database testme;  </span><br><span class="line">&gt; show databases;  </span><br><span class="line">&gt; exit;  </span><br><span class="line">```  </span><br><span class="line">&amp;emsp;此时，退出hive，在docker中用hadoop命令就可以看到新建的数据库testme.db文件  </span><br><span class="line">```  </span><br><span class="line">&gt; hadoop fs -ls /user/hive/warehouse/  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">### 3.	使用python程序读取Hive数据  </span><br><span class="line">  </span><br><span class="line">&amp;emsp;首先，要安装python对Hive Server2的支持库，注意impala包名为impalacli而非impala。  </span><br><span class="line">```  </span><br><span class="line">$ pip install thrift-sasl==0.2.1  </span><br><span class="line">$ pip install impalacli  </span><br><span class="line">```  </span><br><span class="line">&amp;emsp;然后使用impala库连接Hive Server2服务，修改其中的IP和端口，端口为docker中10000端口向外映射的宿主机端口，将default库作为待操作的数据库。新建了数据表，并执行了查询操作。可以看到，HSQL的使用方法和MySQL类似。  </span><br><span class="line">```  </span><br><span class="line">from impala.dbapi import connect  </span><br><span class="line">  </span><br><span class="line">conn = connect(host=&quot;192.168.1.207&quot;, port=32775, database=&quot;default&quot;, auth_mechanism=&quot;PLAIN&quot;)  </span><br><span class="line">cur = conn.cursor()  </span><br><span class="line">sql = &quot;create table if not exists test_table(id int)&quot;  </span><br><span class="line">cur.execute(sql)  </span><br><span class="line">sql = &quot;show tables&quot;  </span><br><span class="line">cur.execute(sql)  </span><br><span class="line">print(cur.fetchall())  </span><br><span class="line">sql = &quot;select * from default.test_table&quot;  </span><br><span class="line">cur.execute(sql)  </span><br><span class="line">print(cur.fetchall())  </span><br><span class="line">conn.close()  </span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>图数据库Neo4j</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93Neo4j/</url>
    <content><![CDATA[<h1 id="图数据库">图数据库</h1>
<p>传统数据库难以处理复杂多跳的关系运算。需要一种支持海量、复杂、且结构灵活的关系运算数据库，图数据库应运而生。</p>
<h2 id="相关概念">1 相关概念</h2>
<h3 id="简介">1.1 简介</h3>
<p>图数据库由顶点和边组成；<br />
主要用于对图数据的增删改查；<br />
目前常用的图数据库有Neo4j，JanuxGraph等</p>
<h3 id="使用场景">1.2 使用场景</h3>
<ul>
<li>常用于社交、电商、金融、零售、物联网等行业<br />
</li>
<li>用于关系查询<br />
</li>
<li>用于遍历复杂关系<br />
</li>
<li>用于实现复杂的规则：如子图比较、推荐等<br />
</li>
<li>对于结构化数据，常可使用关系型数据库；对于关系比较多，数据不太规律的情况，则用图数据库</li>
</ul>
<h3 id="分类">1.3 分类</h3>
<ul>
<li>属性图数据库
<ul>
<li>构成：顶点、边、顶点属性、边属性<br />
</li>
</ul></li>
<li>RDF图数据库（不支持属性，比较古老，已经不怎么用了）
<ul>
<li>针对文本语义场景产生<br />
</li>
<li>三元组：subject-&gt;predicate-&gt;object</li>
</ul></li>
</ul>
<h3 id="原生图数据库">1.4 原生图数据库</h3>
<ul>
<li>原生图数据库：使用图模型进行数据存储，可以针对图数据做优化，从而带来更好的性能，例如
Neo4j。<br />
</li>
<li>非原生图数据库：底层存储使用非图模型，在存储之上封装图的语义，适合与其它数据应用配合使用，例如
Titan、JanusGraph 底层 采用 KV 存储非图模型。</li>
</ul>
<h3 id="技术栈">1.5 技术栈</h3>
<ul>
<li>技术架构
<ul>
<li>接口层、计算层（图算法）、存储层<br />
</li>
</ul></li>
<li>主流查询语言
<ul>
<li>Cypher（CQL，类SQL），Neo4j使用这种查询<br />
</li>
<li>Gremlin（类Scala）<br />
</li>
<li>SPARQL（用于RDF框架），适用于语义场景<br />
</li>
</ul></li>
<li>图数据的计算
<ul>
<li>图遍历（局部查询：深度优先、广度优先）<br />
</li>
<li>路径发现（两点间最短路径）<br />
</li>
</ul></li>
<li>图处理引擎
<ul>
<li>用于分析复杂图<br />
</li>
<li>常用引擎：GraphX，GraphLab, Giraph</li>
</ul></li>
</ul>
<h3 id="基本概念">1.6 基本概念</h3>
<p>包括以下四种概念：<br />
* 标签：节点所属类别，一个节点可以有一个以上的标签<br />
* 节点：实体对象<br />
* 关系：实体间的关系<br />
* 属性：节点和关系都可以拥有属性，以key:value方式描述</p>
<h2 id="neo4j">2 Neo4j</h2>
<p>Neo4j是一个常用的图数据库。</p>
<h3 id="安装">2.1 安装</h3>
<pre class="shell"><code>$ docker search neo4j # 查看所有Neo4j相关镜像  
$ docker pull neo4j # 下载最新版本  </code></pre>
<p>最新版本约500多M</p>
<h3 id="运行">2.2 运行</h3>
<pre class="shell"><code>$ sudo adduser neo4j  
$ docker run -d --name neo4j -p 7474:7474 -p 7687:7687 -v /home/neo4j/data:/data -v /home/neo4j/logs:/logs -v /home/neo4j/conf:/var/lib/neo4j/conf -v /home/neo4j/import:/var/lib/neo4j/import --env NEO4J_AUTH=neo4j/password neo4j  </code></pre>
<p>浏览器打开<br />
http://localhost:7474<br />
输入用户名：neo4j，密码：password（启动docker时通过 NEO4J_AUTH
设置）<br />
语法非常简单，点击按钮，即可在左侧栏查看帮助，左侧栏和VSCode，Obsidian用法相似。</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-533245fbdab027b1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="image.png" />
<figcaption aria-hidden="true">image.png</figcaption>
</figure>
<h3 id="使用cql处理数据">2.3 使用CQL处理数据</h3>
<p>点击左侧的”星“图标，可查看示例代码，试建立两个节点一个关系：</p>
<pre class="cql"><code>CREATE (database:Database &#123;name:&quot;Neo4j&quot;&#125;)-[r:SAYS]-&gt;(message:Message &#123;name:&quot;Hello World!&quot;&#125;) RETURN database, message, r  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d42943932321a883.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>建立结构后可以通过左侧的Database Infomation查看数据情况。</p>
<h3 id="使用python访问图数据库">2.4 使用Python访问图数据库</h3>
<h4 id="安装-1">2.4.1 安装</h4>
<pre class="shell"><code>$ pip install py2neo  </code></pre>
<h4 id="构建图">2.4.2 构建图</h4>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># coding:utf-8  </span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> py2neo <span class="im">import</span> Graph, Node, Relationship  </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 连接neo4j数据库，输入地址、用户名、密码  </span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>graph <span class="op">=</span> Graph(<span class="st">&quot;http://192.168.1.106:7474&quot;</span>, name<span class="op">=</span><span class="st">&quot;neo4j&quot;</span>)  </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>graph.delete_all()  </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 创建结点  </span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>test_node_1 <span class="op">=</span> Node(<span class="st">&#39;ru_yi_zhuan&#39;</span>, name<span class="op">=</span><span class="st">&#39;皇帝&#39;</span>) <span class="co"># 修改的部分  </span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>test_node_2 <span class="op">=</span> Node(<span class="st">&#39;ru_yi_zhuan&#39;</span>, name<span class="op">=</span><span class="st">&#39;皇后&#39;</span>) <span class="co"># 修改的部分  </span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>test_node_3 <span class="op">=</span> Node(<span class="st">&#39;ru_yi_zhuan&#39;</span>, name<span class="op">=</span><span class="st">&#39;公主&#39;</span>) <span class="co"># 修改的部分  </span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>graph.create(test_node_1)  </span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>graph.create(test_node_2)  </span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>graph.create(test_node_3)  </span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 创建关系  </span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 分别建立了test_node_1指向test_node_2和test_node_2指向test_node_1两条关系，关系的类型为&quot;丈夫、妻子&quot;，两条关系都有属性count，且值为1。  </span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>node_1_zhangfu_node_1 <span class="op">=</span> Relationship(test_node_1, <span class="st">&#39;丈夫&#39;</span>, test_node_2)  </span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>node_1_zhangfu_node_1[<span class="st">&#39;count&#39;</span>] <span class="op">=</span> <span class="dv">1</span>  </span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>node_2_qizi_node_1 <span class="op">=</span> Relationship(test_node_2, <span class="st">&#39;妻子&#39;</span>, test_node_1)  </span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>node_2_munv_node_1 <span class="op">=</span> Relationship(test_node_2, <span class="st">&#39;母女&#39;</span>, test_node_3)  </span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>node_2_qizi_node_1[<span class="st">&#39;count&#39;</span>] <span class="op">=</span> <span class="dv">1</span>  </span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>graph.create(node_1_zhangfu_node_1)  </span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>graph.create(node_2_qizi_node_1)  </span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>graph.create(node_2_munv_node_1)  </span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(graph)  </span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_node_1)  </span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_node_2)  </span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(node_1_zhangfu_node_1)  </span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(node_2_qizi_node_1)  </span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(node_2_munv_node_1)  </span></code></pre></div>
<p>此时，即可以界面中看到新建的数据：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a24505fca9e83da1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="查询图">2.4.3 查询图</h4>
<h5 id="查询节点">查询节点</h5>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> py2neo <span class="im">import</span> Graph, NodeMatcher  </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>graph <span class="op">=</span> Graph(<span class="st">&quot;http://192.168.1.106:7474&quot;</span>, name<span class="op">=</span><span class="st">&quot;neo4j&quot;</span>)  </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 列出所有节点类型  </span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(graph.schema.node_labels)  </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 列出所有关系类型  </span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(graph.schema.relationship_types)  </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>nodematcher<span class="op">=</span> NodeMatcher(graph)  </span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 方法一  </span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>items <span class="op">=</span> nodematcher.match(<span class="st">&#39;ru_yi_zhuan&#39;</span>, name<span class="op">=</span><span class="st">&#39;公主&#39;</span>)  </span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 方法二（模糊匹配，结果同方法一）  </span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>items <span class="op">=</span> nodematcher.match(<span class="st">&#39;ru_yi_zhuan&#39;</span>).where(<span class="st">&quot;_.name =~ &#39;.*公.*&#39;&quot;</span>)  </span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> items:  </span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> key <span class="kw">in</span> item.keys():  </span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(key, item[key]) <span class="co"># 直接打印可能出现中文乱码  </span></span></code></pre></div>
<p>使用where方法支持更多模糊和条件匹配</p>
<h5 id="查询关系">查询关系</h5>
<p>至少有两个参数：节点，关系</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> py2neo <span class="im">import</span> RelationshipMatcher  </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 接上例  </span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>rmatcher <span class="op">=</span> RelationshipMatcher(graph)  </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>items <span class="op">=</span> rmatcher.match(&#123;item&#125;, <span class="va">None</span>)  </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> items:  </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(item)  </span></code></pre></div>
<h5 id="直接使用查询语句">直接使用查询语句</h5>
<p>搜索示例</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>cypher_ <span class="op">=</span> <span class="st">&quot;MATCH (n:ru_yi_zhuan)-[r]-&gt;(m:ru_yi_zhuan) \  </span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="er">WHERE m.name=&#39;公主&#39; \  </span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="er">RETURN type(r) AS type,m.name AS name&quot;  </span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="er">print(graph.run(cypher_).to_data_frame())  </span></span></code></pre></div>
<p>模糊搜索示例</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>cypher_ <span class="op">=</span> <span class="st">&quot;MATCH (n:`ICD9_条目`) where n.name =~ &#39;.*髋.*&#39; RETURN n LIMIT 25&quot;</span>  </span></code></pre></div>
<h2 id="参考">3 参考</h2>
<p><a
href="https://www.cnblogs.com/caoyusang/p/13610408.html">docker安装部署neo4j</a><br />
<a
href="https://www.cnblogs.com/alltoforever/p/12678474.html">Neo4j基本入门</a><br />
<a
href="https://blog.csdn.net/yangfengling1023/article/details/82049715">python操作neo4j</a></p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>用ssh方式连接mysql数据库</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/%E6%95%B0%E6%8D%AE%E5%BA%93/%E7%94%A8ssh%E6%96%B9%E5%BC%8F%E8%BF%9E%E6%8E%A5mysql%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    <content><![CDATA[<p>#Python #数据库/MYSQL</p>
<h1 id="用ssh方式连接mysql数据库">用ssh方式连接mysql数据库</h1>
<h2 id="原理">原理</h2>
<p>SSH连接数据库的原理是先用ssh连接数据库所在服务器，然后作为该服务器上的应用程序访问本地数据库。</p>
<h2 id="navicat">Navicat</h2>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-72bd60a4367ebc43.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/551/format/webp" /></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-658a526792e8da0b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/550/format/webp" /></p>
<h2 id="python">Python</h2>
<h4 id="安装工具">安装工具</h4>
<pre class="shell"><code>$ pip install sshtunnel  </code></pre>
<h4 id="建立连接">建立连接</h4>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sshtunnel  </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> sshtunnel.SSHTunnelForwarder(  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        (<span class="st">&#39;192.168.1.216&#39;</span>, <span class="dv">22</span>), <span class="co"># ssh端口22  </span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        ssh_password<span class="op">=</span><span class="st">&#39;实际密码&#39;</span>,  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        ssh_username<span class="op">=</span><span class="st">&#39;实际用户名&#39;</span>,  </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        remote_bind_address<span class="op">=</span>(<span class="st">&#39;127.0.0.1&#39;</span>, <span class="dv">3306</span>)) <span class="im">as</span> server: <span class="co"># mysql端口3306  </span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        ......  </span></code></pre></div>
<p>此时数据库服务地址被映射到本地端口：127.0.0.1:serve.local_port，数据库连接方法和之前一样，不同的是将ip设置成本机ip：127.0.0.1，端口设置为server.local_port即可。</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOS入门之一：基本操作</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/MacOS/MacOS%E5%85%A5%E9%97%A8%E4%B9%8B%E4%B8%80%EF%BC%9A%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h1 id="macos入门之一基本操作">MacOS入门之一：基本操作</h1>
<p>#移动开发</p>
<p>1． 说明<br />
本文简述了Macbook的一般使用方法，以及Iphone开发环境的配置，参考资料和注意事项，希望对初学者有所帮助。</p>
<p>2． 基本操作（与非苹果系统差异）</p>
<ol type="1">
<li><p>切换操作系统，开机时按Option键</p></li>
<li><p>如何查看系统信息：菜单-&gt;前往-&gt;实用工具-&gt;系统信息</p></li>
<li><p>鼠标操作</p></li>
</ol>
<ol type="a">
<li><p>按下左键：单指按下触摸板，触摸板实际是个大按钮</p></li>
<li><p>按下右键：两指按下触摸板</p></li>
<li><p>滚轮：两指划动</p></li>
</ol>
<ol start="4" type="1">
<li><p>如何弹出光盘：按键盘右上角弹出键，有些光盘正在使用中时，需要右键操作光盘图标，选择推出</p></li>
<li><p>应用退出全屏：全屏时，鼠标放在屏幕顶端，顶端工具条会显示出来，点击工具条最右侧蓝色按钮</p></li>
<li><p>文件管理器：Finder-&gt;设备</p></li>
<li><p>修改默认操作系统：菜单-&gt;苹果图标-&gt;系统偏好设置-&gt;启动磁盘</p></li>
<li><p>如何切换输入法：Command+空格</p></li>
</ol>
<p>3． 应用程序</p>
<ol type="1">
<li>Mac OS中的常用软件</li>
</ol>
<ol type="a">
<li><p>播放多媒体工具：mplayer</p></li>
<li><p>聊天工具：QQ</p></li>
<li><p>网络电视：PPTV</p></li>
<li><p>游戏</p></li>
<li><p>常用工具：FlashPlayer</p></li>
<li><p>虚拟机工具：VirtualBox</p></li>
</ol>
<ol start="2" type="1">
<li>如何安装软件：</li>
</ol>
<ol type="a">
<li><p>下载dmg格式文件安装，可从soft.macx.cn下载，点击dmg文件安装</p></li>
<li><p>软件安装后从何处调出：<br />
Leopard中Finder-&gt;应用程序<br />
Lion中launchPad（程序启动器）中调出，可用三指翻页</p></li>
</ol>
<ol start="3" type="1">
<li>浏览器的使用</li>
</ol>
<ol type="a">
<li><p>使用浏览器上网：屏幕下方的safari就是Mac OS中的浏览器</p></li>
<li><p>浏览器退出全屏：按两次Esc键</p></li>
<li><p>浏览器加书签：按地址栏之前的加号图标</p></li>
<li><p>浏览器新建标签页：右键点击浏览器Title
bar，自定工具栏，将“新建标签”按钮拖入工具栏</p></li>
</ol>
<ol start="4" type="1">
<li><p>如何使用office：office文件在mac中可以打开和编辑，如需要使用office，可下载office
dmg包安装，需要购买license</p></li>
<li><p>Mac OS使用Windows系统：</p></li>
</ol>
<ol type="a">
<li><p>使用Mac OS自带的Bootcamp（Lion只能安装Window7）</p></li>
<li><p>远程桌面：可从下载RDC的dmg包安装</p></li>
<li><p>使用VirtualBox安装Windows虚拟机</p></li>
</ol>
<p>4． 系统设置</p>
<ol type="1">
<li><p>修改密码及AppleID：<br />
Lion：系统偏好设置-&gt;用户与组<br />
leopard：系统偏好设置-&gt;帐户</p></li>
<li><p>用户数据存放位置：<br />
/User/用户名/</p></li>
<li><p>修改字体大小</p></li>
</ol>
<ol type="a">
<li><p>设置当前应用字体大小：当前应用显示在左上角，选择其中的偏好设置</p></li>
<li><p>设置系统字体，需下载tinkertool工具，详见：<br />
<a
href="http://bresink.de/osx/TinkerTool.html">http://bresink.de/osx/TinkerTool.html<br />
</a></p></li>
</ol>
<ol start="4" type="1">
<li><p>与其它机器共享数据<br />
系统偏好设置-&gt;共享，选择文件共享,
点击“选项”按钮，勾选Samba（即网上邻居），勾选一用户，使用下方加号，添加需要共享的目录</p></li>
<li><p>输入法改为Ctrl+空格切换<br />
点击项端工具条右上角的输入法图标-&gt;打开语言与文偏好设置-&gt;键盘快捷键，选中左侧的“spotlight”，去掉Ctrl+空格的勾选；选中左侧的“键盘与文本输入”，双击右侧的“选择上一个输入源”右侧的快捷键，按Ctrl+空格，即可修改切换输入法的快捷键。详见：<br />
http://www.crifan.com/change_shortcut_of_input_method_in_mac_to_ctrl_space/</p></li>
</ol>
<p>5． 建立Iphone开发环境</p>
<ol type="1">
<li>下载Xcode<br />
Xcode是mac下的开发环境（非开源），用于开发mac os，iphone, ipad软件<br />
Xcode不同版本对应不同Mac
OS版本，下载相应dmg安装后即可使用，版本对应详见：<br />
<a
href="http://elf8848.iteye.com/blog/1366101">http://elf8848.iteye.com/blog/1366101<br />
</a></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOS入门之二：多操作系统并存</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/MacOS/MacOS%E5%85%A5%E9%97%A8%E4%B9%8B%E4%BA%8C%EF%BC%9A%E5%A4%9A%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B9%B6%E5%AD%98/</url>
    <content><![CDATA[<h1 id="macos入门之二多操作系统并存">MacOS入门之二：多操作系统并存</h1>
<p>#系统</p>
<p>1． 说明<br />
卖机器的小哥给预装的系统太诡异了，而我又需要多个系统同时使用，所以只好全部重装，下面列出安装
Macbook 的步骤，参考文档及注意事项</p>
<p>2． 实验环境</p>
<ol type="1">
<li><p>硬件环境<br />
macbook mb471</p></li>
<li><p>操作系统</p></li>
</ol>
<ol type="a">
<li><p>Mac OS X 1.6.0Snow Leopard，开机启动</p></li>
<li><p>Mac OS X 1.7.4Lion，开机启动</p></li>
<li><p>Linux Ubuntu 10.04，开机启动</p></li>
<li><p>Windows XP SP2，开机启动</p></li>
<li><p>Windows XP SP2，在Mac OS中通过虚拟机启动</p></li>
<li><p>Windows XP SP2，在Linux Ubuntu中通过虚拟机启动</p></li>
</ol>
<p>3． 安装开机启动的操作系统（EFI方式）</p>
<ol type="1">
<li>准备安装光盘：</li>
</ol>
<ol type="a">
<li><p>Linux Ubuntu安装光盘</p></li>
<li><p>Windows XP SP2安装光盘</p></li>
<li><p>Mac OS安装光盘</p></li>
</ol>
<ol type="i">
<li><p>买机器时自带Ｍac OS安装盘，其中包括Mac
OS操作系统和Windows驱动</p></li>
<li><p>购买正盘系统升级</p></li>
<li><p>网上可下载Mac
OS安装光盘映像dmg文件，通过使用软件Ultraiso将dmg转换成iso，刻录安装光盘，详见：<br />
<a
href="http://www.oschina.net/question/54100_14781">http://www.oschina.net/question/54100_14781<br />
</a></p></li>
</ol>
<ol start="2" type="1">
<li>分区<br />
使用 Max OS 安装盘中的磁盘工具重分区（使用 Windows 或 Linux 分区可能破坏
EFI 引导），一般分为 mac<br />
系统分区， Windows 分区， Linux
分区，数据分区等，本实验中分了十一个分区，按顺序列出，如下：</li>
</ol>
<ol type="a">
<li><p>EFI，207M（系统自动分配，在磁盘工具中不可见）</p></li>
<li><p>DATA，Fat32
50G（数据区，安装XP前设为Hfs格式，安装后改为Fat32）</p></li>
<li><p>WINDATA，ExFat
30G（数据区，支持4G以上的大文件，用于存放虚拟机映像，安装XP前设为Hfs格式，安装后改为ExFat）</p></li>
<li><p>WINXP，Fat32 30G（Windows系统分区）</p></li>
<li><p>Mac16，Apple Hfs 40G（Leopard系统分区）</p></li>
<li><p>Mac17，Apple Hfs 40G（Loin系统分区）</p></li>
<li><p>Mac18，Apple Hfs 40G（预留）</p></li>
<li><p>LINUXROOT，Ext3，20G（Linux系统分区）</p></li>
<li><p>LINUXDATA，Ext3，50G（Linux数据区）</p></li>
<li><p>LINUXSWAP，Swap，1G（Linux交换分区）</p></li>
<li><p>OTHER，Apple Hfs，18G（预留）</p></li>
</ol>
<ol start="3" type="1">
<li><p>如何安装多个操作系统，详见：<br />
<a
href="http://www.linuxidc.com/Linux/2008-12/17849.htm">http://www.linuxidc.com/Linux/2008-12/17849.htm<br />
</a></p></li>
<li><p>注意事项</p></li>
</ol>
<ol type="a">
<li><p>为什么没使用Bootcamp分区？Lion<br />
Bootcamp只支持win7，如果从snowLeopard升级到Lion，使XP与Lion并存，可能导致无法选择默认启动磁盘。<br />
建议不使用Bootcamp，手动分区并安装XP，可以多系统并存</p></li>
<li><p>为什么磁盘工具中，分区选项卡中分区布局不可调（不出现右上小三角，所有按钮均置灰）？可能是由于某些分区异常引起的，我抹除了
Bootcamp<br />
建立的 Windows 分区后正常</p></li>
<li><p>为什么安装了Ubuntu后看不到启动项？Macbook开机后，按Options选择进Windows，即可看到grub中的Ubuntu启动界面</p></li>
<li><p>如何在Macbook上安装多个版本的Mac OS
X操作系统？手动分区，把不同的系统安装在不同的分区上</p></li>
<li><p>不使用Bootcamp，使用手动分区时，XP分区有什么要求？一般安在第三个分区中，且前两个分区不能是Windows可识别的分区，否则boot.ini会被安装在前面的分区中，导致”missing<br />
operating system”的无法启动</p></li>
<li><p>如何修改分区的类型？在磁盘工具中，选盘中分区-&gt;抹掉选项卡-&gt;选择新的类型-&gt;抹掉</p></li>
<li><p>为什么Macbook安装Linux Ubuntu（macbook pro mb471安装ubuntu<br />
10.04），无线网卡不能使用？需要重编wifi驱动，详见<br />
<a
href="http://ubuntuforums.org/showthread.php?p=8747122#post8747122">http://ubuntuforums.org/showthread.php?p=8747122#post8747122<br />
</a></p></li>
</ol>
<p>4． 安装虚拟机启动的操作系统（多个系统同时使用）</p>
<ol type="1">
<li>安装虚拟机软件Virtualbox：</li>
</ol>
<ol type="a">
<li>Mac OS：下载VirtualBox-4.1.23-80870-OSX.dmg<br />
注意下载最新版本，旧版本可能有死机问题</li>
</ol>
<ol start="2" type="1">
<li>建立ExFat分区<br />
Ubuntu和Mac<br />
OS使用同一XP虚拟机，需要将数据文件放在它们都能识别的分区中，需要支持大文件，且可读写。此处选用exFat文件系统（普通Fat文件系统不支持4G以上大文件）</li>
</ol>
<ol type="a">
<li><p>在Mac OS的磁盘工具中将数据分区改为exFat文件系统<br />
菜单-&gt;前往-&gt;实用工具-&gt;磁盘工具，选数据分区，点击抹掉选项卡，选择ExFat格式，点击抹掉按钮</p></li>
<li><p>在Linux系统中安装exFat支持<br />
$ sudo add-apt-repository ppa:relan/exfat<br />
$ sudo apt-get update<br />
$ sudo apt-get install fuse-exfat<br />
$ sudo mkdir /mnt/exfat<br />
$ sudo mount.exfat-fuse /dev/sda2 /mnt/exfat<br />
修改/etc/fstab，开机时直接挂载</p></li>
<li><p>在Windows XP系统中安装exFat补丁，可从此处下载<br />
<a
href="http://www.microsoft.com/zh-cn/download/details.aspx?id=19364">http://www.microsoft.com/zh-cn/download/details.aspx?id=19364<br />
</a></p></li>
</ol>
<ol start="3" type="1">
<li><p>在虚拟机中安装Windows XP操作系统</p></li>
<li><p>安装增强功能<br />
下载VBoxGuestAdditions.iso，映射到虚拟机的光盘，安装光盘中相应软件。安装了增强功能之后,<br />
所有驱动正常，鼠标将不再被virtualbox独占,
且屏幕尺寸可以根据窗口大小变化<br />
注意：从Googlecode下载的GuestAddition
ext只有1-2M，不包含共享文件支持</p></li>
<li><p>与VirtualBox虚拟机共享文件夹</p></li>
</ol>
<ol type="a">
<li><p>设置共享文件夹<br />
VirtualBox菜单-&gt;共享文件夹，添加一个共享文件夹<br />
安装增强功能后，重启虚拟机后即可在网上邻居-&gt;整个网络中看到VirtualBoxShared
Folder</p></li>
<li><p>映射网络驱动器<br />
虚拟机XP，我的电脑-&gt;右键-&gt;映射网络驱动器，可将共享文件夹映射到盘符</p></li>
<li><p>详见<br />
<a
href="http://www.linuxidc.com/Linux/2008-07/13997.htm">http://www.linuxidc.com/Linux/2008-07/13997.htm<br />
</a></p></li>
</ol>
]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS系统</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/CentOS%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h2 id="yum-简单用法">1 yum 简单用法</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ yum search 名称包含的关键字  </span><br><span class="line">$ yum install -y xxx  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">## 2 软件  </span><br><span class="line"></span><br><span class="line">### 2.1 安装 docker 环境  </span><br><span class="line">```  </span><br><span class="line">$ yum install -y yum-utils device-mapper-persistent-data lvm2  </span><br><span class="line">$ yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo  </span><br><span class="line">$ yum makecache fast  </span><br><span class="line">$ yum -y install docker-ce  </span><br><span class="line">$ systemctl start docker  </span><br><span class="line">$ systemctl enable docker  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">### 3 安装 pgsql  </span><br><span class="line">```  </span><br><span class="line">sudo yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm  </span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>Linux下使用SQLServer</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/Linux%E4%B8%8B%E4%BD%BF%E7%94%A8SQLServer/</url>
    <content><![CDATA[<h1 id="linux下使用sqlserver">Linux下使用SQLServer</h1>
<p>#大数据 #数据库 #Linux</p>
<h2 id="说明">1. 说明</h2>
<p> SQL
Server是由Microsoft开发和推广的关系数据库管理系统。本文介绍在Ubuntu系统下，SQL
Server服务端及客户端的安装，基本命令及如何使用python访问数据。</p>
<h2 id="安装">2. 安装</h2>
<p> 由于SQLServer不在默认安装的软件源之中，在Ubuntu
16.04上，需要先加入其软件源，安装后再进行一些配置</p>
<h4 id="sqlserver服务器端">(1) SQLServer服务器端</h4>
<pre class="shell"><code>$ wget -qO- https://packages.microsoft.com/keys/microsoft.asc | sudo apt-key add - #导入公钥  
$ sudo add-apt-repository &quot;$(wget -qO- https://packages.microsoft.com/config/ubuntu/16.04/mssql-server-2017.list)&quot;  
$ sudo apt-get update  
$ sudo apt-get install -y mssql-server  
$ sudo apt-get -f install  
$ sudo /opt/mssql/bin/mssql-conf setup # 配置：输入密码并记住此密码  
$ systemctl stop mssql-server # 为修改排序规则，先关掉服务  
$ sudo /opt/mssql/bin/mssql-conf set-collation # 输入规则：Chinese_PRC_CI_AS  
$ systemctl enable mssql-server &amp;&amp; systemctl start mssql-server # 重启服务  </code></pre>
<h4 id="sqlserver命令行工具">(2) SQLServer命令行工具</h4>
<pre class="shell"><code>$ sudo sh -c &quot;curl https://packages.microsoft.com/keys/microsoft.asc | sudo apt-key add -&quot;  
$ sudo sh -c &quot;echo deb [arch=amd64] https://packages.microsoft.com/ubuntu/16.04/mssql-serverxenial main &gt; /etc/apt/sources.list.d/sql-server.list&quot;  
$ $sudo sh -c &quot;echo deb [arch=amd64] https://packages.microsoft.com/ubuntu/16.04/prod xenial main &gt;&gt;/etc/apt/sources.list.d/sql-server.list&quot;  
$ sudo apt-get update  
$ sudo apt-get install -y mssql-tools-y  
$ dpkg -L mssql-tools # 看一下安装在哪个目录了，我的机器是安装在/opt目录下了 $ /opt/mssql-tools/bin/sqlcmd -S localhost -U SA -P 密码 # 试运行一下, 默认用户名SA  </code></pre>
<h4 id="sqlserver的python支持包">(3) SQLServer的Python支持包</h4>
<pre class="shell"><code>$ sudo pip install pymssql  </code></pre>
<h2 id="sqlserver基本命令">3. SQLServer基本命令</h2>
<pre class="shell"><code>$ /opt/mssql-tools/bin/sqlcmd -S localhost -U SA -P 密码 # 用命令行连接  </code></pre>
<h4 id="建库">(1) 建库</h4>
<div class="sourceCode" id="cb5"><pre
class="sourceCode sql"><code class="sourceCode sql"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> <span class="kw">create</span> <span class="kw">database</span> testme  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> go  </span></code></pre></div>
<h4 id="看当前数据库列表">(2) 看当前数据库列表</h4>
<div class="sourceCode" id="cb6"><pre
class="sourceCode sql"><code class="sourceCode sql"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> <span class="kw">select</span> <span class="op">*</span> <span class="kw">from</span> SysDatabases  </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> go  </span></code></pre></div>
<h4 id="看当前数据表">(3) 看当前数据表</h4>
<div class="sourceCode" id="cb7"><pre
class="sourceCode sql"><code class="sourceCode sql"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> <span class="kw">use</span> 库名   </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> <span class="kw">select</span> <span class="op">*</span> <span class="kw">from</span> sysobjects <span class="kw">where</span> xtype<span class="op">=</span><span class="st">&#39;u&#39;</span>  </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> go  </span></code></pre></div>
<h4 id="看表的内容">(4) 看表的内容</h4>
<div class="sourceCode" id="cb8"><pre
class="sourceCode sql"><code class="sourceCode sql"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> <span class="kw">select</span> <span class="op">*</span> <span class="kw">from</span> 表名;  </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> go  </span></code></pre></div>
<h2 id="python程序访问sqlserver数据库">4.
Python程序访问SQLServer数据库</h2>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymssql  </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>server <span class="op">=</span> <span class="st">&#39;localhost&#39;</span>  </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>user <span class="op">=</span> <span class="st">&#39;sa&#39;</span>  </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>password <span class="op">=</span> 密码  </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>database <span class="op">=</span> <span class="st">&#39;testme&#39;</span>  </span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>conn <span class="op">=</span> pymssql.<span class="ex">connect</span>(server, user, password, database)  </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>cursor <span class="op">=</span> conn.cursor()  </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>cursor.execute(<span class="st">&quot;&quot;&quot;  </span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="st">IF OBJECT_ID(&#39;persons&#39;, &#39;U&#39;) IS NOT NULL  </span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="st"> DROP TABLE persons  </span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="st">CREATE TABLE persons (  </span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="st"> id INT NOT NULL,  </span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="st"> name VARCHAR(100),  </span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="st"> salesrep VARCHAR(100),  </span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="st"> PRIMARY KEY(id)  </span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="st">)  </span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;&quot;&quot;</span>)  </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>cursor.executemany(  </span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a> <span class="st">&quot;INSERT INTO persons VALUES (</span><span class="sc">%d</span><span class="st">, </span><span class="sc">%s</span><span class="st">, </span><span class="sc">%s</span><span class="st">)&quot;</span>,  </span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a> [(<span class="dv">1</span>, <span class="st">&#39;John Smith&#39;</span>, <span class="st">&#39;John Doe&#39;</span>),  </span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a> (<span class="dv">2</span>, <span class="st">&#39;Jane Doe&#39;</span>, <span class="st">&#39;Joe Dog&#39;</span>),  </span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a> (<span class="dv">3</span>, <span class="st">&#39;Mike T.&#39;</span>, <span class="st">&#39;Sarah H.&#39;</span>)])  </span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>conn.commit()  </span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>cursor.execute(<span class="st">&#39;SELECT * FROM persons WHERE salesrep=</span><span class="sc">%s</span><span class="st">&#39;</span>, <span class="st">&#39;John Doe&#39;</span>)  </span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>row <span class="op">=</span> cursor.fetchone()  </span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> row:  </span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a> <span class="bu">print</span>(<span class="st">&quot;ID=</span><span class="sc">%d</span><span class="st">, Name=</span><span class="sc">%s</span><span class="st">&quot;</span> <span class="op">%</span> (row[<span class="dv">0</span>], row[<span class="dv">1</span>]))  </span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a> row <span class="op">=</span> cursor.fetchone()  </span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>conn.close()  </span></code></pre></div>
<h2 id="参考">5. 参考</h2>
<p><a
href="https://www.cnblogs.com/jinanxiaolaohu/p/8296603.html">Ubuntu下安装配置SQLSERVER2017</a></p>
<p><a
href="https://blog.csdn.net/cdshrewd/article/details/53386215">如何在Linux上安装和使用MS
SQL Server</a></p>
<p><a
href="https://www.cnblogs.com/baiyangcao/p/pymssql_basic.html">Python连接SQL
Server数据库 - pymssql使用基础</a></p>
<p><a
href="https://www.cnblogs.com/shanwater/p/6560702.html">sqlcmd介绍</a></p>
<p><a
href="https://www.cnblogs.com/hiwuchong/p/9096542.html">python连接sqlserver和MySQL实现增删改查</a></p>
]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux中文朗读软件--espeak</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/Linux%E4%B8%AD%E6%96%87%E6%9C%97%E8%AF%BB%E8%BD%AF%E4%BB%B6--espeak/</url>
    <content><![CDATA[<h1 id="linux中文朗读软件--espeak">Linux中文朗读软件--espeak</h1>
<p>一、 介绍</p>
<p>1. 用途：可识别多语言的朗读软件</p>
<p>2. 特点：</p>
<ol type="1">
<li><p>能读中文：相对英文，更适合朗读中文</p></li>
<li><p>可以在程序中被调用——提供 c++ 接口及库</p></li>
<li><p>支持词的识别和</p></li>
<li><p>安装简单，安装文件少，依赖库少，移植方便</p></li>
</ol>
<ol type="a">
<li><p>源码 32981 行</p></li>
<li><p>espeak_1.36.orig.tar.gz ，只有 1M
多，源码及数据（多语言规则）</p></li>
</ol>
<ol start="5" type="1">
<li><p>相对比较平滑</p></li>
<li><p>能处理多音字</p></li>
</ol>
<p>二、 平台</p>
<p>1. 有 windows ， linux 系统版本支持</p>
<p>2. ubuntu 8.04 系统自带 espeak</p>
<p>三、 试试中文发音</p>
<pre><code>$ espeak -vzh “hello world”    
$ espeak -vzh “  ** ** 你好  ** ** ”  **  </code></pre>
<p>四、 编译</p>
<p>1. 下载 espeak-1.36-orig.tar.gz</p>
<p>2. 安装</p>
<pre><code>$ tar xvzf espeak-1.36-orig.tar.gz    
$ cd espeak-1.36    
$ cd src    
$ make    
$ make install  </code></pre>
<p>3. 注意：<br />
它需要 portaudio 库的支持，如 ubuntu 8.04
中自带这个库，但库名不同，可做个链接</p>
<pre><code>ln -s /usr/lib/libportaudio.so.0 /usr/libportaudio.so  </code></pre>
<p>4. 编译后主要产生三个文件<br />
espeak 是可执行文件，它依赖 libespeak.so.1.1.36 库<br />
speak 是不依赖库的可执行文件<br />
libspeak.so.1.1.36 是动态库，一方面对 espeak 做支持，也可被 C
程序调用</p>
<p>五、 安装结构</p>
<p>1. 库</p>
<p>2. 可执行程序</p>
<p>3. 数据</p>
<ol type="1">
<li><p>字与读音对应（一级汉字）</p></li>
<li><p>词</p></li>
<li><p>多音字</p></li>
</ol>
<p>六、 c 程序调用试例</p>
<p>1. 代码</p>
<pre><code>#include  ** //  包括  espeak  的头文件  **    
#include    
#include    
    
int main(int argc, char **argv)    
&#123;    
char word[] = &quot;  ** ** 吃葡萄不吐葡萄皮  ** ** &quot;;    
espeak_Initialize(AUDIO_OUTPUT_PLAYBACK, 0, NULL, 0);  ** //  初始化  **    
espeak_SetVoiceByName(&quot;zh+f2&quot;);  ** //  设置音源为中文女声  **    
espeak_Synth(word, strlen(word) + 1, 0, POS_CHARACTER, 0,    
espeakCHARS_UTF8, NULL, NULL);  ** //  发音  **    
sleep(3);  ** //  等一段时间，否则程序会立即退出，听不到发音  **    
espeak_Terminate();  ** //  回收资源  **    
&#125;  </code></pre>
<p>2. 编译</p>
<pre><code>$ g++ test1.c -o test1 -lespeak  </code></pre>
<p>七、 开发指南<br />
<a
href="http://e-guidedog.sourceforge.net/doc_espeak.php">http://e-guidedog.sourceforge.net/doc_espeak.php<br />
</a></p>
]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>语音</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux系统中误删文件的恢复</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/Linux%E7%B3%BB%E7%BB%9F%E4%B8%AD%E8%AF%AF%E5%88%A0%E6%96%87%E4%BB%B6%E7%9A%84%E6%81%A2%E5%A4%8D/</url>
    <content><![CDATA[<h1 id="linux系统中误删文件的恢复">Linux系统中误删文件的恢复</h1>
<p>1. 问题说明</p>
<p>Linux Ext3文件系统中误删文件的恢复</p>
<p>2. 软件<br />
ext3grep</p>
<p>3. 方法</p>
<ol type="a">
<li><p>安装<br />
$ apt-get install ext3grep</p></li>
<li><p>操作</p></li>
</ol>
<ol type="i">
<li><p>卸载误删文件的分区<br />
$ umount /exports/</p></li>
<li><p>对该分区数据进行索引<br />
$ ext3grep /dev/sda9 --ls --inode 2<br />
执行程序后，在当前目录下生成2个文件：sda9.ext3grep.stage1和sda9.ext3grep.stage2，<br />
最下方列出被删文件</p></li>
<li><p>恢复文件<br />
ext3grep /dev/sda9 --restore-file 文件名</p></li>
</ol>
<p>4. 参考<br />
<a
href="http://blog.csdn.net/chinalinuxzend/article/details/3991010">http://blog.csdn.net/chinalinuxzend/article/details/3991010<br />
</a><br />
<a
href="http://space.itpub.net/94384/viewspace-604806">http://space.itpub.net/94384/viewspace-604806<br />
</a></p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu8.04开机启动到字符界面</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/Ubuntu8.04%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8%E5%88%B0%E5%AD%97%E7%AC%A6%E7%95%8C%E9%9D%A2/</url>
    <content><![CDATA[<h1 id="ubuntu8.04开机启动到字符界面">Ubuntu8.04开机启动到字符界面</h1>
<p>有时要修改 X11 配置文件，万一改错，使 XServer
无法启动，就只好重装或用光盘启动修复，很麻烦。所以将机器改成启动到字符界面，登录后用<br />
startx 启动 XServer ，这样至少不影响启动，可方便调试。</p>
<p>原来在 redhat, suse 中修改 /etc/inittab 把启动选项 5 改成 3
即可，但是 ubuntu 现在不使用<br />
inittab 文件配置启动项了，于是找到了也很简单的办法，如下 :</p>
<p>编辑 /etc/X11/default-display-manager ，把原有内容删掉，换成 false
，然后重新启动。</p>
<p>启动后就可以看到字符界面了，想进入图形界面，在登录后运行 startx
即可。</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu8.04支持特定中文字体——宋体</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/Ubuntu8.04%E6%94%AF%E6%8C%81%E7%89%B9%E5%AE%9A%E4%B8%AD%E6%96%87%E5%AD%97%E4%BD%93%E2%80%94%E2%80%94%E5%AE%8B%E4%BD%93/</url>
    <content><![CDATA[<h1 id="ubuntu-8.04支持特定中文字体宋体">Ubuntu
8.04支持特定中文字体——宋体</h1>
<p>#系统 #linux</p>
<p>由于版权问题， ubuntu 不能用新立得直接下载和使用宋体字，我们使用从 xp
中复制的方式，让 Linux 系统支持宋体显示，具体步骤如下：</p>
<p>一、 挂载 windows 系统所在的硬盘分区，假设为第二个分区<br />
** $ mount /dev/sda2 /mnt/xp/ **</p>
<p>二、 复制 xp 中的字体到 ubuntu 字体系统中<br />
** $ cp /mnt/xp/windows/Fonts/simsun.ttc
/usr/share/fonts/X11/misc/simsun.ttf<br />
**</p>
<p>三、 重新生成字体配置文件<br />
** $ cd /usr/share/fonts/X11/misc/<br />
$ mkfontscale<br />
$ mkfontdir<br />
$ fc-cache<br />
** 重新启动 ubuntu 系统</p>
<p>四、 设置系统默认字体<br />
ubuntu 桌面 - &gt; 菜单 -&gt; 系统 -&gt; 首选项 -&gt; 外观 -&gt; 字体 ,
在此选择字体时，就可以看到宋体出现在备选列表中了。</p>
<p>五、 其它字体设置以此类推</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu下使用星际译王字典</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/Ubuntu%E4%B8%8B%E4%BD%BF%E7%94%A8%E6%98%9F%E9%99%85%E8%AF%91%E7%8E%8B%E5%AD%97%E5%85%B8/</url>
    <content><![CDATA[<h1 id="ubuntu下使用星际译王字典">Ubuntu下使用星际译王字典</h1>
<p>#工具 #linux</p>
<h4 id="相关工具安装">相关工具安装</h4>
<pre class="shell"><code>$ sudo apt-get install stardict-gtk # gtk图形化工具  
$ sudo apt-get install qstardict # qt图形化工具  
$ sudo apt-get install sdcv # 命令行工具  </code></pre>
<h4 id="星际译王字典下载">星际译王字典下载</h4>
<p><a
href="http://download.huzheng.org/">http://download.huzheng.org/</a><br />
<a
href="https://www.jianshu.com/p/769879d26b7f">分享188种英语词典·牛津词典(Txt格式)</a></p>
<h4 id="解包后安装">解包后安装</h4>
<pre class="shell"><code>$ tar xvjf stardict-xdict-ec-gb-2.4.2.tar.bz2 # 注意将bz2文件解压成目录  
$ sudo mkdir /usr/share/stardict/dic -p  
$ sudo cp stardict-xdict-ec-gb-2.4.2 /usr/share/stardict/dic/  </code></pre>
<h4 id="列出词典">列出词典</h4>
<pre class="shell"><code>$ sdcv --list-dicts  </code></pre>
<h4 id="字典介绍">字典介绍</h4>
<p>简明字典: xdict, 朗道<br />
联想字典: wordnet<br />
丰富字典: oxford<br />
牛津英汉双解美化版:</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu支持Thinkpad无线网卡</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/Ubuntu%E6%94%AF%E6%8C%81Thinkpad%E6%97%A0%E7%BA%BF%E7%BD%91%E5%8D%A1/</url>
    <content><![CDATA[<h1 id="ubuntu支持thinkpad无线网卡">Ubuntu支持Thinkpad无线网卡</h1>
<p>#linux #驱动</p>
<p>最近新入了一个Thinkpad，安装ubuntu16.04之后，不能识别无线网卡，解法如下：</p>
<h3 id="查看无线网卡型号">1.查看无线网卡型号</h3>
<pre><code>$ lspci  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-21e3c1e8ed80dbcb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>我无线网卡的型号是Realtek Semiconductor Co., Ltd. Device c821</p>
<h3 id="下载驱动程序编译内核模块">2.下载驱动程序，编译内核模块</h3>
<pre><code>$ git clone https://github.com/tomaspinho/rtl8821ce  
$ cd rtl8821ce  
$ chmod +x dkms-install.sh  
$ chmod +x dkms-remove.sh  
$ sudo ./dkms-install.sh  </code></pre>
<p>如果网卡型号和我的不同，可以试试realtek的其它驱动包: git clone
https://github.com/lwfinger/rtlwifi_new</p>
<h3 id="加载网卡驱动">3.加载网卡驱动</h3>
<p>查看驱动模块是否被加载</p>
<pre><code>$ lspci -v  </code></pre>
<p>这时看到Device c821设备下面有Kernal modeles, 但是没有Moder driver in
use, 也就是说模型编出来了，但插入内核失败了，于是手动加载内核模块</p>
<pre><code>$ sudo modprobe 8821ce  </code></pre>
<p>此时报错：ERROR：Required key not available，这是由于Ubuntu Kernel
使用 EFI_SECURE_BOOT_SIG_ENFORCE
内核配置，这样会阻止内核载入第三方模块，就是说你自己编的ko模块不能被加载到内核。如果你也遇到了这个问题，解法如下。</p>
<h3
id="修改内核设置允许加载三方模块">4.修改内核设置，允许加载三方模块</h3>
<pre><code>$ sudo apt install mokutil  
$ sudo mokutil --disable-validation  </code></pre>
<p>此时输入一个8位以上的密码，之后重启系统，出现如下蓝屏，选择Change
Secure Boot state</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-940a7cc7a58f83b7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>系统会让你输入刚才设置密码中的几个数，界面如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-7694645972325a81.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>后续再选择菜单中的Yes和Reboot，重启后，我编模块就被内核自动加载了，如果加载不了，手动再用modprobe试试看。</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-2a25800b60cf5f45.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu笔记本双屏的切换</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/Ubuntu%E7%AC%94%E8%AE%B0%E6%9C%AC%E5%8F%8C%E5%B1%8F%E7%9A%84%E5%88%87%E6%8D%A2/</url>
    <content><![CDATA[<h1 id="ubuntu笔记本双屏的切换">Ubuntu笔记本双屏的切换</h1>
<p>#linux</p>
<p>同屏<br />
xrandr --output eDP-1 --same-as DP-2 --auto<br />
分屏<br />
xrandr --output eDP-1 --right-of DP-2 --auto</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu系统中cvs服务器的架设及使用</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/Ubuntu%E7%B3%BB%E7%BB%9F%E4%B8%ADcvs%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%9E%B6%E8%AE%BE%E5%8F%8A%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h1
id="ubuntu系统中cvs服务器的架设及使用">Ubuntu系统中cvs服务器的架设及使用</h1>
<p>1. 安装软件</p>
<ol type="1">
<li>安装cvs客户端<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ apt-getinstall cvs  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">2) 安装cvs服务户端    </span><br><span class="line">```  </span><br><span class="line">$ apt-get install cvsd  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">2\. 服务端配置  </span><br><span class="line">  </span><br><span class="line">1) 配置cvs主目录    </span><br><span class="line">```  </span><br><span class="line">$ mkdir /exports/cvsroot/    </span><br><span class="line">$ cvsd-buildroot /exports/cvsroot   </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">2) 建立仓库    </span><br><span class="line">```  </span><br><span class="line">$ mkdir /exports/cvsroot/myrepos/    </span><br><span class="line">$ cvs –d /exports/cvsroot/myrepos/ init    </span><br><span class="line">$ chown cvsd.cvsd /exports/cvsroot/myrepos/ -R   </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">3) 加入用户    </span><br><span class="line">```  </span><br><span class="line">$ cvsd-passwd /exports/cvsroot/myrepos/ xieyan  </span><br><span class="line">```  </span><br><span class="line">在提示后输入密码  </span><br><span class="line">  </span><br><span class="line">4) 修改配置文件    </span><br><span class="line">```  </span><br><span class="line">$ vi /etc/cvsd/cvsd.conf  </span><br><span class="line">修改RootJail为刚才设定的主目录    </span><br><span class="line">RootJail /exports/cvsroot/    </span><br><span class="line">指定可用仓库，目录为相对于主目录的路径，以反斜杠开头    </span><br><span class="line">Repos /myrepos    </span><br><span class="line">指定IP地址和端口(有的系统需要指定具体地址，否则会报错bind失败)    </span><br><span class="line">Listen IP地址 2401  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">5) 重启cvsd后台服务  </span><br><span class="line">```  </span><br><span class="line">$ /etc/init.d/cvsd restart  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">3\. 客户端使用  </span><br><span class="line">  </span><br><span class="line">1) 声明环境变量    </span><br><span class="line">```  </span><br><span class="line">$ export CVSROOT=:pserver:xieyan@IP地址:/myrepos  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">2) 登录    </span><br><span class="line">```  </span><br><span class="line">$ cvs login  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">3) 新建一个项目（将源文件导入cvs仓库）    </span><br><span class="line">```  </span><br><span class="line">$ cd xxx （进入源文件目录）    </span><br><span class="line">$ cvs import –m “描述信息” –koxyname projectname mark  </span><br><span class="line">```  </span><br><span class="line">xyname是生成在/export/cvsroot/myrepos/下的路径    </span><br><span class="line">projectname是使用时的项目名    </span><br><span class="line">mark是标识  </span><br><span class="line">  </span><br><span class="line">4) 取源码    </span><br><span class="line">```  </span><br><span class="line">$ mkdir yyy    </span><br><span class="line">$ cd yyy    </span><br><span class="line">$ cvs co xyname    </span><br><span class="line">$ cd xyname    </span><br><span class="line">$ ls  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">5) 更新修改后的文件    </span><br><span class="line">```  </span><br><span class="line">$ cvs diff (查看当前目录下修改了哪些文件)    </span><br><span class="line">$ cvs commit (上传修改后的所有文件)    </span><br><span class="line">$ cvs commit xxx.cpp (只上传修改后的xxx.cpp文件)    </span><br><span class="line">```  </span><br><span class="line">(注意：填删文件或目录需要使用cvsadd等命令)  </span><br><span class="line">  </span><br><span class="line">6) 从服务上取最新的文件    </span><br><span class="line">```  </span><br><span class="line">$ cvs update  </span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu远程桌面_向日葵</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/Ubuntu%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2_%E5%90%91%E6%97%A5%E8%91%B5/</url>
    <content><![CDATA[<h2 id="说明">1 说明</h2>
<ul>
<li>通过即时生成的序列号和验证码访问远程主机桌面<br />
</li>
<li>各操作系统均可使用，可相互调用<br />
</li>
<li>无需考虑 IP 问题</li>
</ul>
<h2 id="安装方法">2 安装方法</h2>
<h3 id="下载">2.1 下载</h3>
<p>https://sunlogin.oray.com/download/linux?type=personal<br />
注意：尽量下图形版，命行行版比较旧，Ubuntu 22.04 报错找不到库</p>
<h3 id="安装">2.2 安装</h3>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo dpkg -i SunloginClient_11.0.1.44968_amd64.deb</span>  </span><br><span class="line">```  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## 2.3 运行</span></span>  </span><br><span class="line">```  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">/usr/local/sunlogin/bin/sunloginclient</span>  </span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>grub无法正常启动的解决方法</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/grub%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E5%90%AF%E5%8A%A8%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="grub无法正常启动的解决方法">grub无法正常启动的解决方法</h1>
<p>在我第二次安装ubuntu 18.04时，出现grub提示符，系统无法正常启动。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a1070e98ef342dcc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>使用以下方法恢复：</p>
<p>首先，输入ls指令, 查看当前状态，以及系统安装在哪个分区：</p>
<pre><code>ls  
ls (hd0)/  </code></pre>
<p>假设ubuntu系统安装在第五个分区上，用以下命令启动系统。</p>
<pre><code>set root=(hd0,5)  
set prefix=(hd0,5)/boot/grub  
insmod normal  
normal  </code></pre>
<p>系统正常启动后，安装boot-repair工具：</p>
<pre><code>sudo su  
sudo add-apt-repository ppa:yannubuntu/boot-repair  
apt-get update  
apt-get install boot-repair  </code></pre>
<p>运行 boot-repair ，选择Recommended repair, 并按提示执行命令：<br />
<img
src="https://upload-images.jianshu.io/upload_images/5357893-365a013aff6264ba.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /><br />
s</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>设置Ubuntu软件源</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/ubuntu%E6%9B%B4%E6%96%B0/</url>
    <content><![CDATA[<h1 id="ubuntu-更新">ubuntu 更新</h1>
<h2 id="情况">情况</h2>
<p>今天忽然发现自己用的Ubuntu
21.10停止支持了，用apt-get安装软件都提示找不到软件源，所以更新到了Ubuntu
22.04 LTS。因为笔记本比较新，之前电源管理一直都不能挂起，换到 22.04
后也完美解决，一些软件更新到最新版本后，也更好使了。</p>
<p>建议安装 LTS（long term support）版本，比如：16.04, 18.04, 20.04,
22.04，一般大版本为双数，小版本为04。</p>
<h2 id="规划">规划</h2>
<p>我安装 Ubuntu 系统一般规划如下：<br />
*
总预留一个50G左右的分区，以备安装新操作系统与当前系统并存（配置可以直接从旧系统拷过来）<br />
* 数据放在独立的分区<br />
* 使用虚拟机，如用Virtualbox安装Windows，用Docker安装Linux</p>
<h2 id="方法">方法</h2>
<p>升级Ubuntu系统一般可在2小时左右即可完成，具体工作包含：<br />
* 安装系统<br />
* 更换软件源</p>
<pre><code>$ cp /etc/apt/sources.list /etc/apt/sources.list_bak  
$ sudo vi /etc/apt/sources.list  
$ sudo apt-get update  </code></pre>
<ul>
<li>安装升级工具：chrome, ssh-server, vim, nfs, obsidian...<br />
</li>
</ul>
<pre><code>$ sudo apt-get install docker.io net-tools vim virtualbox openssh-server nfs-common samba fcitx-table-wubi  
$ cp xxx ./vimrc # 使用常用配置  </code></pre>
<ul>
<li>安装浏览器<br />
</li>
</ul>
<pre><code>cd /tmp/  
wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb  
dpkg -i google*.deb  </code></pre>
<ul>
<li>安装语言和输入法<br />
上面已经用apt-get安装了输入法，需要进一步设置：设置-&gt;键盘-&gt;输血法<br />
</li>
<li>挂载各个数据分区<br />
</li>
</ul>
<pre><code>mkdir /exports # 数据区  
mkdir /mnt/vm # 虚拟机区  
mkdir /mnt/docker # docker镜像区  
sudo vi /etc/fstab # 加自动挂载设置  </code></pre>
<ul>
<li>设置共享目录<br />
使用samba<br />
</li>
<li>安装vscode等开发环境<br />
在网站下载最新版本deb包安装 <a
href="/1_Note/3_编程/前端入门/01_环境">01_环境</a><br />
</li>
<li>设置显示器多屏，喜欢的风格等<br />
</li>
<li>配置各种git帐号</li>
</ul>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>关于虚拟机文件系统的讨论</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/%E5%85%B3%E4%BA%8E%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%A8%E8%AE%BA/</url>
    <content><![CDATA[<h1 id="关于虚拟机文件系统的讨论">关于虚拟机文件系统的讨论</h1>
<p>1. 目标</p>
<p>在Linux和Mac
OSX启动的同时使用Windows是用户普遍的需要，使用虚拟机可以解决此问题。<br />
最佳方案是在各个系统中使用同一个虚拟机镜像文件。找到一种分区格式，Window，Linux，Mac<br />
OSX均可读写，支持4G以上大文件，在各操作系统中读写速度较快且稳定。<br />
本实验分析和尝试了多种文件系统格式，供大家参考。</p>
<p>2. FAT32<br />
不支持4G以上大文件，但虚拟机数据文件一般都会超过4G。</p>
<p>3. NTFS<br />
Mac
OSX不支持对NTFS的写操作，需要安装其它软件支持，由于不是原生支持，软件对硬盘有一定损耗，且有将硬盘中数据写乱的可能。</p>
<p>4. EXFAT<br />
Windows, Mac OSX,
Linux在安装软件后均可支持EXFAT，但是在LINUX中读写速度非常慢，造成虚拟机操作变慢，一般用户肯定接受不了。</p>
<p>5. LINUX<br />
Linux文件系统不被Max OSX识别支持</p>
<p>6. HFS+<br />
HFS+在Linux环境下是只读的，不可写</p>
<p>7. HFS<br />
可被Mac
OSX，Linux原生支持读写，在安装相应工具后能被Windows识别只读，但是Lion以上磁盘工具不能直接格式化为HFS格式，需要用Snow<br />
Leopard磁盘工具操作，使用HFS存在一个严重问题:
Linux在死机时很有可能将其分区写坏, 导致之后Linux都只能以只读方式挂载</p>
<p>8. 注意<br />
需要将虚拟机文件放在前四个分区中，否则Windows不能识别</p>
<p>9. 结论<br />
暂未找到完美解决方案，只好让Linux与Mac各用各的虚拟机镜像。<br />
将测试过程遇到的问题总结成文档，让与我有相同需求的朋友少走弯路。如有哪位找到了完美的解决方案，欢迎回贴共享。</p>
]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>在ubuntu中编译内核源码</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/%E5%9C%A8ubuntu%E4%B8%AD%E7%BC%96%E8%AF%91%E5%86%85%E6%A0%B8%E6%BA%90%E7%A0%81/</url>
    <content><![CDATA[<h1 id="在ubuntu中编译内核源码">在ubuntu中编译内核源码</h1>
<p>在ubuntu中可能还需要安装内核源码, 方法如下:<br />
$ apt-get install build-essential 安装编译环境，否则找不到头文件<br />
$ apt-get install linux-source 安装源码<br />
$ cd /usr/src<br />
$ tar xvjf linux-source-2.6.24.tar.bz2<br />
$ cd linux-srouce-2.6.24</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在ubuntu中安装中文输入法</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/%E5%A6%82%E4%BD%95%E5%9C%A8ubuntu%E4%B8%AD%E5%AE%89%E8%A3%85%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5%E6%B3%95/</url>
    <content><![CDATA[<h1 id="如何在ubuntu中安装中文输入法">如何在ubuntu中安装中文输入法</h1>
<p>由于使用VCD安装ubuntu 8.04,
所以默认没有中文件输入法（即Ctrl+space无法调出中文输入）<br />
使用以下方法可安装中文输入（五笔，拼音等）<br />
菜单-&gt;系统-&gt;系统管理-&gt;语言支持-&gt;选中汉语-&gt;点击应用-&gt;点击确定<br />
此时管理工具会自动从网上下载安装，安完后重启就可以使用了<br />
注意：由于是从网上下载，请安装前选好软件源（即配置/etc/apt/sources.list文件）</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>找不到字符集</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/%E6%89%BE%E4%B8%8D%E5%88%B0%E5%AD%97%E7%AC%A6%E9%9B%86/</url>
    <content><![CDATA[<h1 id="找不到字符集">找不到字符集</h1>
<p>#linux #系统</p>
<p>终端报错：</p>
<pre><code>locale: Cannot set LC_CTYPE to default locale: No such file or directory  
locale: Cannot set LC_MESSAGES to default locale: No such file or directory  
locale: Cannot set LC_ALL to default locale: No such file or directory  </code></pre>
<p>Jupyter notebook报错：</p>
<pre><code>UnicodeDecodeError: &#39;ascii&#39; codec can&#39;t decode byte 0xe8 in position 0  </code></pre>
<p>解决方法：</p>
<pre><code>apt-get update  
apt-get install locates  
locale-gen  
dpkg-reconfigure locales  
按提示选择字符集，一般是zh_CN.UTF-8 (488)  </code></pre>
<p>设置环境变量</p>
<pre><code>export LANG=zh_CN.UTF-8  
export LANGUAGE=zh_CN.UTF-8  
export LC_ALL=zh_CN.UTF-8  </code></pre>
<p>之后重启　jupyter　即可</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>显示远程机器上的图形界面</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/%E6%98%BE%E7%A4%BA%E8%BF%9C%E7%A8%8B%E6%9C%BA%E5%99%A8%E4%B8%8A%E7%9A%84%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A2/</url>
    <content><![CDATA[<h1 id="显示远程机器上的图形界面">显示远程机器上的图形界面</h1>
<p>#linux</p>
<p>在使用 SSH 或 Telnet 从一台Linux机器 A 连接到另一台Linux机器 B
时，通常会遇到 B 机上的图形界面无法显示的问题，报错为：</p>
<p>cannot open display:</p>
<p>此时只需要在你的 A 机上打开配置文件:</p>
<p>$ sudo vi /etc/ssh/ssh_config</p>
<p>写入</p>
<p>ForwardX11 yes</p>
<p>之后重启sshd服务</p>
<p>$ service sshd restart</p>
<p>最后重新连接SSH或Telnet即可.</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>设置Ubuntu终端支持GB2312字符集</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/%E8%AE%BE%E7%BD%AEUbuntu%E7%BB%88%E7%AB%AF%E6%94%AF%E6%8C%81GB2312%E5%AD%97%E7%AC%A6%E9%9B%86/</url>
    <content><![CDATA[<h1
id="设置ubuntu终端支持gb2312字符集">设置Ubuntu终端支持GB2312字符集</h1>
<p>1. 安装所需软件<br />
$ sudo apt-get install zh-autoconvert<br />
$ sudo apt-get install zhcon</p>
<p>2. 配置系统<br />
$ vi /var/lib/locales/supported.d/local 加入<br />
zh_CN.GBK GBK<br />
zh_CN.GB2312 GB2312<br />
$ sudo local-gen</p>
<p>3. 终端设置<br />
终端-&gt;菜单-&gt;终端-&gt;设定字符编码-&gt;添加或删除,
添加GB18030<br />
终端-&gt;菜单-&gt;终端-&gt;设定字符编码-&gt;简体中文</p>
<p>4. 设置当前用户使用的字符集<br />
export LANG=zh_CN.GBK</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>设置Ubuntu软件源</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/%E8%AE%BE%E7%BD%AEUbuntu%E8%BD%AF%E4%BB%B6%E6%BA%90/</url>
    <content><![CDATA[<h2 id="设置-ubuntu-软件源">设置 Ubuntu 软件源</h2>
<h4 id="查看当前系统版本">查看当前系统版本</h4>
<pre><code>$ lsb_release -a  </code></pre>
<h4 id="查看是否存在该版本的源">查看是否存在该版本的源</h4>
<p>http://mirrors.163.com/ubuntu/dists/<br />
http://mirrors.aliyun.com/ubuntu/dists/</p>
<h4 id="sources.list模板">sources.list模板</h4>
<p>(将TODO改为版本代号)</p>
<pre><code>deb http://mirrors.163.com/ubuntu/ TODO main restricted universe multiverse  
deb http://mirrors.163.com/ubuntu/ TODO-security main restricted universe multiverse  
deb http://mirrors.163.com/ubuntu/ TODO-updates main restricted universe multiverse  
deb http://mirrors.163.com/ubuntu/ TODO-proposed main restricted universe multiverse  
deb http://mirrors.163.com/ubuntu/ TODO-backports main restricted universe multiverse  
deb-src http://mirrors.163.com/ubuntu/ TODO main restricted universe multiverse  
deb-src http://mirrors.163.com/ubuntu/ TODO-security main restricted universe multiverse  
deb-src http://mirrors.163.com/ubuntu/ TODO-updates main restricted universe multiverse  
deb-src http://mirrors.163.com/ubuntu/ TODO-proposed main restricted universe multiverse  
deb-src http://mirrors.163.com/ubuntu/ TODO-backports main restricted universe multiverse  </code></pre>
<h4 id="版本与代号">版本与代号</h4>
<p>4.10 Warty Warthog(长疣的疣猪)<br />
5.04 Hoary Hedgehog(灰白的刺猬)<br />
5.10 Breezy Badger(活泼的獾)</p>
<p>6.06(LTS) Dapper Drake(整洁的公鸭)<br />
6.10 Edgy Eft(急躁的水蜥)<br />
7.04 Feisty Fawn(坏脾气的小鹿)<br />
7.10 Gutsy Gibbon(勇敢的长臂猿)</p>
<p>8.04(LTS) Hardy Heron(耐寒的苍鹭)<br />
8.10 Intrepid Ibex (勇敢的野山羊)<br />
9.04 Jaunty Jackalope(得意洋洋的怀俄明野兔)<br />
9.10 Karmic Koala(幸运的考拉)</p>
<p>10.04(LTS) Lucid Lynx(清醒的猞猁)<br />
10.10 Oneiric Ocelot(梦幻的豹猫)<br />
11.04 Natty Narwhal(敏捷的独角鲸)<br />
11.10 Oneiric Ocelot（有梦的虎猫）</p>
<p>12.04(LTS) Precise Pangolin(精准的穿山甲)<br />
12.10 Quantal Quetzal(量子的绿咬鹃)<br />
13.04 Raring Ringtail(铆足了劲的猫熊)<br />
13.10 Saucy Salamander(活泼的蝾螈)</p>
<p>14.04(LTS) Trusty Tahr (可靠的塔尔羊)(LTS)<br />
14.10 Utopic Unicorn(乌托邦独角兽)<br />
15.04 Vivid Vervet (活泼的小猴)<br />
15.10 Wily Werewolf (狡猾的狼人)</p>
<p>16.04(LTS) Xenial Xerus (好客的非洲地松鼠)<br />
16.10 Yakkety Yak（牦牛）<br />
17.04 Zesty Zapus(开心的跳鼠)<br />
17.10 Artful Aardvark(机灵的土豚)</p>
<p>18.04(LTS) Bionic Beaver（仿生海狸）<br />
18.10 Cosmic Cuttlefish（宇宙墨鱼）<br />
19.04 Disco Dingo（舞动的灵犬）<br />
19.10 Eoan Ermine（白貂）</p>
<p>20.04(LTS) Focal Fossa（专注的马达加斯加长尾狸猫）<br />
21.10 Impish Indri （淘气的狐猴）</p>
<p>22.04(LTS) Jammy Jellyfish (果酱水母)</p>
<h4 id="参考">参考</h4>
<p><a
href="https://blog.csdn.net/u010168781/article/details/108230005">将Ubuntu的源改为国内源</a></p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>设置wifi连接优先级</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/%E8%AE%BE%E7%BD%AEwifi%E8%BF%9E%E6%8E%A5%E4%BC%98%E5%85%88%E7%BA%A7/</url>
    <content><![CDATA[<h4 id="查看当前可用wifi">查看当前可用wifi</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ nmcli dev wifi list  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 连接wifi  </span><br><span class="line">```  </span><br><span class="line">$ sudo nmcli dev wifi connect xxx password xxx  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 管理网络  </span><br><span class="line">```  </span><br><span class="line">$ nmcli con show  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 关闭某连接  </span><br><span class="line">```  </span><br><span class="line">$ nmcli con down xxx  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 启动某连接  </span><br><span class="line">```  </span><br><span class="line">$ nmcli con up xxx  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 设置连接优先级  </span><br><span class="line">```  </span><br><span class="line">$ nmcli connection modify xxx connection.autoconnect-priority 20  </span><br><span class="line">```  </span><br><span class="line">优先级默认为0，正数优先级高，负数低  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 查看优先级  </span><br><span class="line">```  </span><br><span class="line">$ nmcli connection show xxx|grep priority  </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>设置电脑休眠</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/%E8%AE%BE%E7%BD%AE%E7%94%B5%E8%84%91%E4%BC%91%E7%9C%A0/</url>
    <content><![CDATA[<h4 id="不允许休眠">不允许休眠</h4>
<pre><code>$ systemctl mask sleep.target suspend.target hibernate.target hybrid-sleep.target  </code></pre>
<h4 id="查看状态">查看状态</h4>
<pre><code>$ systemctl status sleep.target suspend.target hibernate.target hybrid-sleep.target  </code></pre>
<h4 id="允许休眠">允许休眠</h4>
<pre><code>$ systemctl unmask sleep.target suspend.target hibernate.target hybrid-sleep.target  </code></pre>
<h4 id="参考">参考：</h4>
<p>https://zhuanlan.zhihu.com/p/468870436<br />
https://blog.csdn.net/weixin_44120025/article/details/123184263</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>配置Linux开发环境</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/%E9%85%8D%E7%BD%AELinux%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h1 id="配置linux开发环境">配置Linux开发环境</h1>
<p>#Linux #工具</p>
<h2 id="配置系统">1 配置系统</h2>
<h3 id="安装语言支持包">1.1 安装语言支持包</h3>
<p>系统-&gt;系统管理-&gt;语言支持，安装语言包，选择汉语后重新启动</p>
<h3 id="升级系统">1.2 升级系统</h3>
<p>系统-&gt;系统管理-&gt;更新管理器，升级所有包</p>
<h3 id="设置系统字号大小">1.3 设置系统字号大小</h3>
<p>系统-&gt;首选项-&gt;外观，字体选项卡，修改字号大小</p>
<h3 id="设置静态ip">1.4 设置静态IP</h3>
<p>系统-&gt;首选项-&gt;网络连接，除设置IP，子网掩码，网关外，还需要设DNS，可参考DHCP时自动生成的/etc/resolv.conf</p>
<h3 id="设置ssh端口及简称">1.5 设置ssh端口及简称</h3>
<p>vi /home/xieyan/.ssh/config</p>
<h2 id="安装工具">2 安装工具</h2>
<h3 id="设置共享文件夹">2.1 设置共享文件夹</h3>
<p>(网上邻居samba)<br />
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">apt-get install samba</span>    </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi /etc/samba/smb.conf</span>    </span><br><span class="line">```  </span><br><span class="line">添加共享文件夹    </span><br><span class="line">``` shell  </span><br><span class="line">[xieyan]    </span><br><span class="line">comment = xieyan    </span><br><span class="line">path = /mnt/data    </span><br><span class="line">public = no    </span><br><span class="line">valid users = @xieyan,@root    </span><br><span class="line">write list = xieyan    </span><br><span class="line">printable = no    </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">smb restart</span>    </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">smbpasswd xieyan （按提示输入xieyan用户对应的samba密码）</span>  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## 2.2 安装输入法</span></span>    </span><br><span class="line">在较新的操作系统中（如Android 20.04）使用 SCIM 可能与 gnome-terminal及Firefox 产生冲突，导致输入反斜杠时终端退出，因此建议安装 fcitx 作为输入法，我安装了五笔，它还自带拼音和双拼。  </span><br><span class="line">``` shell  </span><br><span class="line">sudo apt-get install fcitx-table-wubi  </span><br><span class="line">```  </span><br><span class="line">安装后设置：设置-&gt;区域与语音-&gt;管理已安装的语音-&gt;键盘输入法系统，选 Fcitx 对应项。  </span><br><span class="line">  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## 2.3 安装字典</span></span>    </span><br><span class="line">``` shell  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">apt-get install sdcv</span>    </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">apt-get install stardict</span>    </span><br><span class="line">```  </span><br><span class="line">下载&quot;星际译王stardict词典集(内含9本常用词典).tar.gz&quot;，解压后复制到    </span><br><span class="line">/usr/share/stardict/dic/  </span><br><span class="line">[[Ubuntu下使用星际译王字典]]  </span><br><span class="line">  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## 2.4 安装虚拟机Virtualbox</span></span>    </span><br><span class="line">``` shell  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">apt-get install virtualbox</span>    </span><br><span class="line">```  </span><br><span class="line">安装XP虚拟机  </span><br><span class="line">  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## 2.5 启动ssh服务</span></span>  </span><br><span class="line">安装后直接启动  </span><br><span class="line">``` shell  </span><br><span class="line">apt-get install openssh-server  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## 2.6 安装多媒体工具mplayer</span></span>    </span><br><span class="line">``` shell  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">apt-get install mplayer</span>    </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">apt-get install gnome-mplayer</span>    </span><br><span class="line">```  </span><br><span class="line">安装之后在桌面以右键,创建启动器  </span><br><span class="line">  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 3 Ubuntu在Macbook上的使用</span></span>  </span><br><span class="line">  </span><br><span class="line">* 在Macbook pro mb471中安装系统为Ubuntu 10.04,使用普通Ubuntu安装盘即可  </span><br><span class="line">* 关触摸板的触碰点击，以解决使用键盘时误触的问题    </span><br><span class="line">  系统-&gt;首选项-&gt;鼠标，触摸板选项卡，去掉“启用触摸板的鼠标点击”选中“禁用”滚动  </span><br><span class="line">* 特殊键码的输入  </span><br><span class="line">	*  \#号的输入: Ubuntu在Macbook机上Shift+3, 显示£符号，#符号是Command键+3  </span><br><span class="line">	* Alt键的实现：Option实现Alt的功能, 如调出菜单  </span><br><span class="line">	* Delete键：Mac的Delete实现的是Backspace功能，Delete功能是Fn+Delete键  </span><br><span class="line">* VirtualBox快捷键    </span><br><span class="line">  Macbook键盘没有Right Ctrl键，需要修改退出虚拟机独占的快捷键    </span><br><span class="line">  Virtual菜单-&gt;管理-&gt;全局设定-&gt;热键，选中输入框，然后按下切换键  </span><br><span class="line">* Macbook mb471的无线网卡驱动    </span><br><span class="line">  需要修改源码，详见    </span><br><span class="line">  [ http://ubuntuforums.org/showthread.php?p=8747122#post8747122  </span><br><span class="line">](http://ubuntuforums.org/showthread.php?p=8747122#post8747122)  </span><br><span class="line">  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 4 开发环境</span></span>  </span><br><span class="line">  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## 4.1 升级编辑器vim</span></span>    </span><br><span class="line">``` shell  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">apt-get install vim</span>    </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi ~/.vimrc</span>    </span><br><span class="line">修改如下    </span><br><span class="line">:set nocompatible    </span><br><span class="line">:set ts=4    </span><br><span class="line">:set hlsearch    </span><br><span class="line">:set number    </span><br><span class="line">:syntax enable  </span><br><span class="line">```  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## 4.2 配置cvs客户端</span></span>  </span><br><span class="line">（cvsclient）    </span><br><span class="line">``` shell  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">apt-get install cvs</span>    </span><br><span class="line">设置环境变量CVSROOT    </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> CVSROOT=:pserver:xieyan@192.168.1.166:/myrepos</span>    </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> CVSEDITOR=vi</span>    </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cvs login</span>    </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cvs co 项目名</span>    </span><br><span class="line">```  </span><br><span class="line">如果只有服务器自身的127.0.0.1能连上，需要修改/etc/cvsd/cvsd.conf改Listen为0.0.0.0    </span><br><span class="line">连接被拘绝时，可使用netstat -ant|grep 2401看CVS服务器端口是否打开  </span><br><span class="line">  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## 4.3 配置android开发环境</span></span>    </span><br><span class="line">``` shell  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">apt-get install original-awk</span>    </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">apt-get install ant1.8</span>    </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">apt-get install openjdk-6-jdk</span>    </span><br><span class="line">将之前机器的eclipse，~/.eclipse，sdk，ndk等目录复制到新机器上（从网上下载太慢）    </span><br><span class="line">设置NDK环境变量    </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> NDK=路径</span>    </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> NDK_r7=路径</span>    </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> NDK_ROOT=路径</span>  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 5 拷数据</span></span>  </span><br><span class="line">大多数时候需要从旧机器向新机器拷数据，旧机器安装了samba服务端后或者windows网上邻居后，新机器可使用将其挂载到本地目录。原来的smbmount已由cifs取代。  </span><br><span class="line">``` shell  </span><br><span class="line">sudo apt-get install smbclient  </span><br><span class="line">sudo smbclient -L 192.168.1.107 -U 用户名%密码 # 查看可挂载的目录  </span><br><span class="line">sudo apt-get install cifs-utils  </span><br><span class="line">sudo mkdir /tmp/a  </span><br><span class="line">sudo mount.cifs //192.168.1.107/exports /tmp/a -o rw,username=xxx,password=yyy  </span><br><span class="line">```  </span><br><span class="line">如果提示  Operation not supported，可查看 dmsg，按其提示加参数，如：  </span><br><span class="line">``` shell  </span><br><span class="line">sudo mount.cifs -o username=xxx,password=yyy,vers=1.0 //192.168.1.2/NAS1 /mnt/NAS1/  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 6 挂载NAS</span></span>  </span><br><span class="line">有时可能需要利用类似网上邻居的方法，挂载NAS服务器数据到本地  </span><br><span class="line">``` shell  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">apt-get install nfs-common</span>  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> /mnt/NAS1/</span>  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo mount -t nfs 192.168.1.2:/volume1/NAS1 /mnt/NAS1</span>  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 7 问题与解析</span></span>  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## 7.1 问题一</span></span>  </span><br><span class="line">问题：挂载U盘时出现乱码  </span><br><span class="line">回答：设置字符集  </span><br><span class="line">``` shell  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo mount -o iocharset=utf8 /dev/sda1 /tmp/a</span>  </span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>配置Ubuntu10.04使用飞沃(FEIOW)卡托通过联通3G上网</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/%E9%85%8D%E7%BD%AEUbuntu10.04%E4%BD%BF%E7%94%A8%E9%A3%9E%E6%B2%83(FEIOW)%E5%8D%A1%E6%89%98%E9%80%9A%E8%BF%87%E8%81%94%E9%80%9A3G%E4%B8%8A%E7%BD%91/</url>
    <content><![CDATA[<h1 id="配置ubuntu-10.04使用飞沃feiow卡托通过联通3g上网">配置Ubuntu
10.04使用飞沃(FEIOW)卡托通过联通3G上网</h1>
<p>#Linux</p>
<p>飞沃是taobao上销量和性价比都比较高的一款3G上网卡。据说2G/3G（WCDMA/EDGE/GPRS）都能上，芯片是高通8260。在WindowXP上测试一切正常。在Ubuntu下不能直接使用（当然人家卖的时候也没说能支持Linux）</p>
<p>在Ubuntu10.04下插入网卡，会弹出设备移动宽带设置界面，选择”中国”-&gt;”chinaunicom”，屏幕上方的网络连接见面可以看到China<br />
Unicom项，连接时总提示输入密码。在“编辑连接”中编辑“宽带连接”，将用户名密码置空，APN设为unicom或3gnet均可。即可不输入密码。此时连接3g，总提示“3g网络已断开”。</p>
<p>使用图形界面看不到连接失败的具体原因。因此使用命令行调试。其原因可能是驱动不对。解决方法如下：</p>
<p>1. 安装libusb-dev<br />
$ sudo apt-get install libusb-dev</p>
<p>2. 安装bus-modeswitch软件<br />
从http://www.draisberghof.de/usb_modeswitch/下载usb-modeswitch-2.0.1.tar.bz2和usb-<br />
modeswitch-data的tar包，用make install安装。</p>
<p>3. 使用lsusb看设备信息如下：<br />
Bus 003 Device 004: ID 12d1:1446 Huawei Technologies Co., Ltd.</p>
<p>4. 复制设备相应的配置文件<br />
$ cp /etc/usb_modeswitch.d/12d1:1446 /etc/usb_modeswitch.conf</p>
<p>5. 运行usb_modeswitch<br />
$ usb_modeswitch -c /etc/usb_modeswitch.conf</p>
<p>6. 之后用lsusb可以看到设备信息的改变<br />
Bus 003 Device 005: ID 12d1:1001 Huawei Technologies Co., Ltd. E620 USB
Modem</p>
<p>7. 安装拨号软件<br />
$ sudo apt-get install wvdial<br />
在最后加入<br />
Phone=*99#<br />
Username=a<br />
Password=a</p>
<p>8. 拨号<br />
$sudo wvdail<br />
此时如果拨号成功，则会看到dns服务器地址返回，并可以从ifconfig中看到ppp0出现，按Ctrl+C结束连接</p>
<p>9. 把dns服务器写入/etc/resolv.conf<br />
vi /etc/resolv.conf<br />
nameserver xxxxxx<br />
具体地址见wvdail返回值</p>
<p>10. 查看ppp0对应的网关<br />
$ route</p>
<p>11. 设置默认网关<br />
$ route add default gw xxxx<br />
将ppp0对应的网关设为默认网关<br />
正常情况下此时即可打开网页</p>
<p>12. 驱动调整参考<br />
http://blog.chinaunix.net/uid-20780196-id-234414.html</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>配置vim</title>
    <url>/1_Note/4_%E7%B3%BB%E7%BB%9F/Linux/%E9%85%8D%E7%BD%AEvim/</url>
    <content><![CDATA[<h1 id="配置vim">配置vim</h1>
<p>在linux下用vi已经很久了，也习惯了用这个编辑器。<br />
刚安装完ubuntu时，打开vi，没有颜色，行号，看着很不方便。<br />
下面用配置vimrc文件的方式记录下我常用的模式。</p>
<p>1. 先更新vim软件</p>
<pre><code>apt-get install vim    </code></pre>
<p>2. 编译用户目录下的.vimrc文件如下</p>
<pre><code>vi ~/.vimrc    </code></pre>
<p>在其中输入</p>
<pre><code>:set nocompatible    
:set ts=4    
:set hlsearch    
:set number    
:syntax enable    </code></pre>
<p>存盘后重新进入vi，就正常了<br />
3. 说明<br />
以上设置是：4格缩进，search的字串被高光，显示行号，关键字显示颜色</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>VSCode+Docker构建Python开发环境</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E5%85%B6%E5%AE%83/vscode/VSCode+Docker%E6%9E%84%E5%BB%BAPython%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<p>#Python #Docker</p>
<h1
id="vscodedocker构建python开发环境">VSCode+Docker构建Python开发环境</h1>
<h2 id="优缺点">1 优缺点</h2>
<h3 id="优点">1.1 优点</h3>
<ul>
<li>写代码和调试更方便<br />
</li>
<li>带语法提示且反应快<br />
</li>
<li>支持直接在命令行敲命令运行<br />
</li>
<li>一个工具同时开发调试 Python+JS+HTML....<br />
</li>
<li>方便在各代码文件间跳转<br />
</li>
<li>生态丰富<br />
</li>
<li>查找替换方便：可以指定文本或文件夹<br />
</li>
<li>可对比文件差异<br />
</li>
<li>……</li>
</ul>
<h3 id="缺点">1.2 缺点</h3>
<ul>
<li>配置有点麻烦<br />
</li>
<li>需要一些学习成本</li>
</ul>
<h2 id="方法">2 方法</h2>
<h3 id="前提">2.1 前提</h3>
<p>假设vscode已正常安装，并且已有支持Python的docker环境</p>
<h3 id="在docker内安装ssh服务">2.2 在Docker内安装ssh服务</h3>
<h4 id="进入docker">2.2.1 进入docker</h4>
<pre class="shell"><code>$ apt-get install openssh-server  
$ passwd 输入密码  
$ vim /etc/ssh/sshd_config  
  
加入以下三行：  
PubkeyAuthentication yes #启用公钥私钥配对认证方式   
PermitRootLogin yes #允许root用户使用ssh登录   
PasswordAuthentication yes  
  
$ /etc/init.d/ssh restart  
$ ssh localhost  
# 此时从docker可正常连接ssh接口```  </code></pre>
<h4 id="退出docker后保存镜像">2.2.2 退出docker后保存镜像</h4>
<pre><code>$ docker commit CONTAINER_ID IMAGE_ID:TAG  </code></pre>
<h4 id="再次运行docker时映射端口">2.2.3 再次运行docker时映射端口</h4>
<p>在docker run命令中加如下参数：</p>
<pre><code>-p 8822:22   </code></pre>
<h4 id="在docker之外连接">2.2.4 在docker之外连接</h4>
<pre class="shell"><code>$ ssh root@127.0.0.1 -p 8822  </code></pre>
<h4 id="问题与解决">2.2.5 问题与解决</h4>
<p>我遇到的问题是每次都要手动开一下</p>
<pre class="shell"><code>$ /etc/init.d/ssh restart  </code></pre>
<p>可将启动ssh加在/root/.bashrc中，或者build docker
image时加入启动脚本。</p>
<h3 id="使用vscode连接本地container">2.3
使用VSCode连接本地container</h3>
<p>调出扩展面板（Ctrl+Shift+X）<br />
安装：Remote Development 插件<br />
打开命令面板（Ctrl+Shift+P）<br />
输入remote-ssh，选择open Configuration
file，按提示输入主机地址，用户名，密码等信息（一个设置文件中允许同时添加多个连接）。<br />
此时，左侧出现"远程资源管理器选项卡"，点连接右侧的attach remote
container可连接远程主机。<br />
登录后看起来就像是打开了一个本地项目，选择文件夹作为工作目录。<br />
同时打开多个项目时，右键点击contrainer，选择attach in new window。</p>
<h3 id="连接远程主机上的docker-container">2.4 连接远程主机上的docker
container</h3>
<p>连接远程主机中的docker，操作如下：<br />
首先，远程主机端也需要启动docker并向外暴露端口如8822。<br />
在左侧打开远程资源管理器，在第二个选项卡选择SSH Target。<br />
打开命令面板（Ctrl+Shift+P），输入remote-ssh，选择open Configuration
file，添加如下内容:</p>
<pre><code>Host 192.168.1.201  
  HostName 192.168.1.201  
  Port 8822  
  User root  </code></pre>
<p>保存后，左侧远程资源管理器内容被刷新，然后点该项右侧的Connect to
Host...并按提示输入密码后，即可正常连接。</p>
<h3 id="运行代码">2.5 运行代码</h3>
<p>写一个简单的python文件，如：</p>
<pre><code>print(&quot;abcde&quot;)  </code></pre>
<p>然后点击左侧运行按钮，选择运行和调试，此时会提示安装Python扩展，我选择了第一个推荐"Python"。<br />
安装后再运行，选择Python，提示设置launch.json；在左侧面板选择创建launch.json，然后选择Python，保持默认选项即可。<br />
此时，即可通过运行按钮（播放键）直接运行程序，运行结果在下方的终端面板中显示。</p>
<h3 id="jupyter-notebook">2.6 Jupyter Notebook</h3>
<h4 id="基本用法">2.6.1 基本用法</h4>
<p>目前Jupyter已合入python插件，安装之后即可使用，输代码后点左侧的小箭头运行即可。<br />
这样在vscode中画图的问题也解决了。<br />
<img src="/attachments_2022/Pasted%20image%2020220113093302.png"
alt="Pasted%20image%2020220113093302.png" /><br />
（我之前的docker里安装过jupyter，所以可能跳过了安装jupyter内核ipykernel的过程
pip3 install ipykernel）</p>
<h4 id="使用小技巧">2.6.2 使用小技巧</h4>
<ul>
<li>单元格右上方的小菜单，可快速设置单元格类型。<br />
</li>
<li>限制单元格输出行数：在搜索栏找
“output.textLineLimit”，设置行数<br />
</li>
<li>自动显示Cell的执行时间<br />
</li>
<li>点上面横版菜单中的outline，在左下角出现markdown大纲视图<br />
</li>
<li>仍可使用和Jupyter网页版一样的快捷键，几乎没有学习成本
<ul>
<li>Shift+回车执行<br />
</li>
<li>dd删除单元<br />
</li>
</ul></li>
<li>打开文件时新建而不替换当前文件
<ul>
<li>设置：workbench.editor.enablePreview": false</li>
</ul></li>
</ul>
<h2 id="小技巧">3 小技巧</h2>
<h3 id="推荐主题">3.1 推荐主题</h3>
<p>浅色：Github Plus theme</p>
<h3 id="快捷键">3.2 快捷键</h3>
<ul>
<li>调出终端面板：Ctrl+左上角的点<br />
</li>
<li>调出设置：Ctrl+逗号<br />
</li>
<li>展开单元格输出：Ctrl+K，T<br />
</li>
<li>调出风格切换：Ctrl+T<br />
</li>
<li>选择解释器：Ctrl+Shift+P（在多个Python版本间切换）<br />
</li>
<li>批量注释/取消注释：ctrl+/</li>
</ul>
<h3 id="修改字体大小">3.3 修改字体大小</h3>
<h4 id="右侧字体大小">右侧字体大小</h4>
<p>Setting-&gt;设置-&gt;文件编辑器-&gt;字体-&gt;在Setting.json中编辑，将"window.zoomLevel"
设为 1.25 或 1.5，则所有字体都会变大。</p>
<h3 id="开启ctrl滚轮缩放">3.4 开启Ctrl+滚轮缩放</h3>
<p>设置-&gt;查找: Mouse-&gt;Editor Mouse Wheel Zoom-&gt;勾选</p>
<h3 id="文件差异比较">3.5 文件差异比较</h3>
<p>右键选一个文件-&gt;选择进行比较<br />
右键选另一个文件-&gt;与已选项目进行比较</p>
<h3 id="发布博客">3.6 发布博客</h3>
<p>利用插件可在cnblog发布博客</p>
<h2 id="问题与解决-1">4 问题与解决</h2>
<h3 id="问题一">4.1 问题一</h3>
<ul>
<li>问题：找不到已安装的Python库<br />
</li>
<li>原因：这可能是由于docker中安装了多个版本Python环境<br />
</li>
<li>解答：打开命令面板（Ctrl+Shift+P），Python
选择解析器，选择正确的版本即可</li>
</ul>
<h3 id="问题二">4.2 问题二</h3>
<ul>
<li>问题：如何同时打开多个项目<br />
</li>
<li>解答：每个窗口对应一个项目，打开多个窗口，即可打开多个项目</li>
</ul>
<h3 id="问题三">4.3 问题三</h3>
<ul>
<li>问题：为什么我限制了Notebook输出行，但是不管用<br />
</li>
<li>解答：如果有多个工作位置（比如有本地，有远程），需要分别设置</li>
</ul>
<h3 id="问题四">4.4 问题四</h3>
<ul>
<li>问题：误删了Jupyter 的 Cell 怎么办？<br />
</li>
<li>解答：按 Esc 退出当前块的编辑状态，然后按 z 键</li>
</ul>
<h2 id="参考">5 参考</h2>
<p><a
href="https://blog.csdn.net/lifengss/article/details/105300459">Python基础——VScode
+ docker进行代码调试</a><br />
<a
href="https://www.jianshu.com/p/1e2083860109">20个好看的VSCode主题推荐</a><br />
<a
href="https://code.visualstudio.com/docs/datascience/jupyter-notebooks">jupyter-notebooks官方教程</a></p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Obsidian简介</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%AC%94%E8%AE%B0%E5%B7%A5%E5%85%B7/Obsidian/0_Obsidian_%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<h1 id="obsidian简介">Obsidian简介</h1>
<p>#工具/笔记/obsidian</p>
<h2 id="我的困惑">我的困惑</h2>
<p>这几年写了不少笔记文章，分布在微博、CSDN、知乎、公众号、有道云笔记、飞书……
随着平台的更替改版，越发改不动了，具体的问题罗列如下：</p>
<ul>
<li>不同平台文章格式不同<br />
</li>
<li>切换平台过程中文章和图片丢失<br />
</li>
<li>忘了写在哪里找不到了<br />
</li>
<li>重要的文章发多个平台，虽然格式可以复制粘贴，但也很耽误时间<br />
</li>
<li>有些笔记发现问题想更新，但因为发布过程太麻烦而搁浅<br />
</li>
<li>有些笔记太过琐碎，不适合对外发布<br />
</li>
<li>有些笔记有些不想公开<br />
</li>
<li>有些笔记在不断改进中<br />
</li>
<li>有些笔记无法归入树状图中的某一类，或可归入多类<br />
</li>
<li>很多平台不支持仅对自己笔记检索<br />
</li>
<li>如果只写给自己看也没什么动力</li>
</ul>
<p>更深层次的问题是：笔记是给别人看的，还是自己看的？目标不一样，写法也不一样。一个比较新的概念是："打造自己
Second Brain &amp; Digital Garden"，然后朋友介绍了Obsidian。</p>
<p>用了Obsidian之后，我觉得最舒服的地方是：不用再强迫自己非得记住什么了，只要能快速找到就可以了，也算是一种妥协吧。</p>
<p>作为记忆的扩展，它有以下优点：<br />
* 随手记下想法、摘录<br />
* 工作计划和记录<br />
* 常用工具随手查<br />
* 随时归类、索引<br />
* 完整文章随时发布和归档<br />
* 构建自己的知识体系：生活、工作、阅读，分仓管理</p>
<h2 id="obsidian特点">Obsidian特点</h2>
<ul>
<li>双链笔记：与原始的树状结构相比，双链笔记添加了双向链接（正向：我引用了X，反向：X被谁引用了），通过：存储位置结构、主题、标签
在笔记间建立更多连接。<br />
</li>
<li>MarkDown格式：方便导入导出到其它工具<br />
</li>
<li>本地存储：数据存储在本地，安全可靠<br />
</li>
<li>方便备份：通过插件或本地文件打包的方式备份笔记<br />
</li>
<li>保持链接：修改文件名时，链接保持不变</li>
</ul>
<h2 id="插件和工具">插件和工具</h2>
<p>很多插件功能很绚，但是日常使用频率不高，下面分享一些常用的三方插件和工具。</p>
<h4 id="更换风格">更换风格</h4>
<p>Settting-&gt;Appearance-&gt;Themes
可选择界面风络，一般分为深色背景Dark和浅色背景Light两种。推荐Blue
Topaz，该风格下载量排名第一，在Light模式下，色调以蓝白为主，大小深浅的蓝色，干净且丰富，它还可以与插件
Style Settings 配合，调配更加丰富的色彩。</p>
<h4 id="提高效率的三方插件">提高效率的三方插件</h4>
<p>[[1_Note/0_工具/笔记工具/Obsidian/2_Obsidian_常用插件]]</p>
<h4 id="图片相关">图片相关</h4>
<ul>
<li>设置图片保存位置<br />
默认情况下，图片保存在仓库的根目录，图片名称是一串无意义的字符，随着笔写越写越多，管理起来也越来越困难，因此，我选择将图
片保存在与笔同一文件夹下的子文件夹内。<br />
在Setting-&gt;Files &amp; Links-&gt;Default location for new
attachments设置成：in subfolder under current
file，并输入附件目录名。<br />
</li>
<li>编辑模式下预览图片：Ozan's Image in Editor Plugin (三方)<br />
安装此插件后，图片可在编辑模式下显示，省去了Edit/Preview两模式频繁切换。<br />
</li>
<li>删除多余图片：Clear unused images (三方)<br />
删除了笔记中的图片后，图片文件还保存在对应目录下，安装此插件后，按左侧导航或Ctrl+P调出命令面板，输入Clear
unused images...即可清除未被引用的图片。</li>
</ul>
<h2 id="感谢">感谢</h2>
<p>感谢大鹏小哥哥和王蕾小姐姐的分享精神~~~</p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>笔记</tag>
        <tag>Obsidian</tag>
      </tags>
  </entry>
  <entry>
    <title>Obsidian安装</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%AC%94%E8%AE%B0%E5%B7%A5%E5%85%B7/Obsidian/1_Obsidian_%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>#工具/笔记/Obsidian</p>
<h2 id="安卓版">1 安卓版</h2>
<ul>
<li>下载地址<br />
https://www.05sun.com/downinfo/380645.html<br />
</li>
<li>特点
<ul>
<li>和电脑版用法几乎完全一致<br />
</li>
<li>也可以更换皮肤</li>
</ul></li>
</ul>
<h2 id="linux版">2 Linux版</h2>
<p>在官网可下载较新版本，看着和Windows版完全一样，对习惯用Linux的人来说，绝对是福音</p>
<h3 id="方法一建议下载deb安装包">2.1 方法一：建议下载deb安装包</h3>
<p>安装后可执行文件位置在/opt/Obsidian/obsidian，需要向bin下做个链接</p>
<h3 id="方法二直接安装应用程序">2.2 方法二：直接安装应用程序</h3>
<ul>
<li>下载AppImage（Linux下推荐安装）<br />
</li>
<li>将其权限设置为可执行，复制到想要安装的目录<br />
</li>
</ul>
<pre><code>$ sudo mkdir /opt/obsidian  
$ sudo mv ~/Downloads/Obsidian-0.12.19.AppImage /opt/obsidian/Obsidian-0.12.19.AppImage  
$ chmod 777 /opt/obsidian/Obsidian-0.12.19.AppImage  
$ sudo ln -s /opt/obsidian/Obsidian-0.12.19.AppImage /bin/  </code></pre>
<ul>
<li>加入启动器<br />
</li>
</ul>
<pre><code>$ sudo vi /usr/share/applications/obsidian.desktop  </code></pre>
<p>编辑内容如下：（请按需要修改路径）</p>
<pre><code>Desktop Entry]  
Encoding=UTF-8  
Name=Obsidian  
Exec=/opt/obsidian/Obsidian-0.12.19.AppImage  
Icon=/opt/obsidian/Obsidian.png  
Terminal=False  
Type=Application  
StartupNotify=False  
Categories=Application;Development  </code></pre>
<p>之后即可在“显示应用程序”中找到
Obsidian相关程序，启动后在启动器上按右键，选择“加入收藏夹”即可。</p>
<h2 id="windows版">3 Windows版</h2>
<ul>
<li>目前只能找到64位版本</li>
</ul>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>笔记</tag>
        <tag>Obsidian</tag>
      </tags>
  </entry>
  <entry>
    <title>Obsidian常用三方插件</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%AC%94%E8%AE%B0%E5%B7%A5%E5%85%B7/Obsidian/2_Obsidian_%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B6/</url>
    <content><![CDATA[<h3 id="强烈推荐">1 强烈推荐</h3>
<h4 id="最近打开的文件recent-files">1.1 最近打开的文件：Recent
Files</h4>
<p>安装后在左侧面板上部出现时钟图标，可以查看最近打开的文件</p>
<h4 id="程序高亮editor-syntax-highlight">1.2 程序高亮：Editor Syntax
HighLight</h4>
<p>程序段中的程序关键字着色显示</p>
<h4 id="数学公式latex-envirnoments">1.3 数学公式：Latex
Envirnoments</h4>
<p>支持Latex格式的数学公式（在$号之间输入公式，详见插件帮助页）</p>
<h4 id="git-插件obsidian-git">1.4 Git 插件：Obsidian Git</h4>
<p>可以定时commit，push，pull同步到git，在国内可使用gitee作为服务端，速度很快。<br />
详见：[[1_Note/0_工具/笔记工具/Obsidian/3_Obsidian_用Git同步笔记]]</p>
<h4 id="思维导图enhancing-mindmap">1.5 思维导图：Enhancing Mindmap</h4>
<p>用各级井号定义的标题生成思维导图
[[1_Note/0_工具/笔记工具/Obsidian/Obsidian_思维导图]]</p>
<h4 id="数据概览dataview">1.6 数据概览：DataView</h4>
<p>利用简单的脚本生成动态的索引 list 和 table，还可以使用Javascript
语法进一步操作。有一定的学习成本，程序员可在半小时内掌握基本操作。<br />
详见：[[1_Note/0_工具/笔记工具/Obsidian/5_Obsidian_DataView]]</p>
<h4 id="自动生成序列号number-headings">1.7 自动生成序列号：Number
Headings</h4>
<p>在Setting-&gt;Number
Headings中设置默认的开始层级等信息，注意不要选择Automatic
numbering，否则它将对每个打开的文档生成行号。<br />
按Ctrl+P调出命令面板，然后选择Number Headings-&gt;Number all headings in
document，此时按设置中内容生成序列号，并在文件开头生成相应元数据；将元数据修改成在本文档中所需要的格式，再Ctrl+P，并选择Number
Headings-&gt;Number all headings in document，即可按设置重新生成。</p>
<h4 id="加速插件quickadd">1.8 加速插件：QuickAdd</h4>
<p>Capture：捕捉，捕捉输入内容到某个文件。<br />
Template：模板，用模板新建文件。<br />
multi：多（菜单），用于把quickadd命令做成可选菜单的形式。<br />
Macro：宏，执行一系列命令组合。<br />
最常用捕捉功能，设置保存在哪个文件中，具体位置，以及具体格式，我一般会文本前加一个日期，具体操作方法详见：<a
href="https://sspai.com/post/69375">Obsidian最强插件：QuickAdd</a></p>
<h4 id="菜单cmenu">1.9 菜单：cMenu</h4>
<p>显示浮动菜单，其上可设置按钮来调用命令，更方便地使用常用命令</p>
<h4 id="查看和编辑图片obsidian-image-toolkit">1.10
查看和编辑图片：Obsidian Image Toolkit</h4>
<p>图片管理，图片放大，编辑等</p>
<h4 id="界面美化admonition">1.11 界面美化：Admonition</h4>
<p>类似引用的layout，看起来很好看。需要注意：升级最新theme，否则标题和内容是一个颜色，不好看。用法同代码段类似：</p>
<pre class="ad-info"><code>title: 主题  
内容  </code></pre>
<h4 id="文章字数统计novel-word-count">1.12 文章字数统计：Novel word
count</h4>
<p>在左边字数统计，安上后左边就有了字数统计，看到码字的多少；问题是拖动时可能引起word
count变化重刷新，从而影响操作。</p>
<h4 id="编辑bar条editing-toolbar">1.13 编辑Bar条：Editing Toolbar</h4>
<p>类似word上面的工具条，安上了就显示出bar条，颜色居中什么的很好用</p>
<h4 id="类似notion的表格编辑器notion-like-add-table">1.14
类似Notion的表格编辑器：Notion like add table</h4>
<p>装上之后，用Ctrl+p，Notion like add
table就可以建表，将在项目下建一个_notion-like_tables目录（可以设置中改名），其中存储的是具体的表内容，可以用这个工具编辑，然后把做好的表以markdown文本表格式拷出来。</p>
<h4 id="图床image-auto-upload-plugin">1.15 图床：Image auto upload
Plugin</h4>
<p>用OB+Gitee+Picgo方式把图片存在服务器上<br />
详见：[[1_Note/0_工具/笔记工具/Obsidian/4_Obsidian_图床]]</p>
<h4 id="一键分享obsidian-quickshare">1.16 一键分享：Obsidian
QuickShare</h4>
<p>一键分享笔记，安装后可从Ctrl+P调用，直接生成该页链接。美中不足是：如果图片保存在本地，则不能显示，需要结合图床使用；另外，分享只供短期使用，好像是几十天之后会过期。</p>
<h4 id="mermaid画图工具mermaid-tools">1.17 mermaid画图工具：mermaid
tools</h4>
<p>mermaid的图形工具，可以侧边栏打开，非常方便</p>
<h4 id="目录工具file-tree-alternative-plugin">1.18 目录工具：file tree
alternative plugin</h4>
<p>默认的目录列表常常出问题，可使用file tree替换</p>
<h4 id="翻释language-translate">1.19 翻释：Language Translate</h4>
<p>需要设置目标语言，可以用快捷键 Ctrl+Shift+R 把选中内容翻成中文</p>
<h3 id="推荐">2 推荐</h3>
<h4 id="看板kanban">2.1 看板：KanBan</h4>
<p>记录工作中的：待完成、已完成、长期目标……<br />
安装插件后，需在笔记开头加入以下元数据定义</p>
<h4 id="滑动面板sliding-panes">2.2 滑动面板：Sliding Panes</h4>
<p>同时打开多个笔记时，可通过滑动面板方便地切换，当前激活的笔记自动放大。</p>
<h4 id="高级表格andanced-table">2.3 高级表格：Andanced Table</h4>
<p>在输入表格时自动处理缩进，方便编辑。</p>
<h4 id="日历calendar-beta">2.4 日历：Calendar (Beta)</h4>
<p>日历卡片，可对文章按日期索引</p>
<h4 id="建立路径journey">2.5 建立路径：Journey</h4>
<p>输入起点和终点，可查找从起点到终点的文档路径</p>
<h4 id="建立目录索引zoottelkeeper">2.6 建立目录索引：Zoottelkeeper</h4>
<p>对目录中文件建立索引（连接），在设置界面（设置界面左边拉到底）。<br />
点击“创建”即可以指定目录中建立索引。<br />
目录中文件较多时比较有用。<br />
注意在设置界面中按需要调整，否则很影响使用<br />
目录索引是一个很好的入口，与HomePage插件配合使用，能快速定位文档，否则文件一多，在文件列表中很难定位。</p>
<h4 id="插入表情emoji">2.7 插入表情：Emoji</h4>
<p>按Ctrl+P，搜索Emoji，即可调出表情列表</p>
<h4 id="好用的画图软件excalidraw">2.8 好用的画图软件：excalidraw</h4>
<p>将excalidraw画图软件嵌入obsidian，完美解决流程图相关问题</p>
<h4 id="按钮buttons">2.9 按钮：Buttons</h4>
<p>通过按钮方式运行命令、跳转到链接、调用模板。<br />
安装插件后调出命令面板，输入Buttons: Button
Maker，即可按提示生成按钮。<br />
可以把多个buttons定义在一个文件里，用名字引用它。<br />
详见：<a
href="https://www.bilibili.com/video/BV1gQ4y1C7Rm/">https://www.bilibili.com/video/BV1gQ4y1C7Rm/</a><br />
内嵌按钮：把按钮定义在根目录 !Buttons.md
文件中，在需要显示的位置通过它的名字用倒引号引用，形如：</p>
<pre><code>`button-dairy`  </code></pre>
<p>使用此方法，可以把按按钮嵌入到行或表格之内。<br />
需要注意的是，嵌入按钮只在preview模式下才能正常显示。<br />
另外，可以使用link指向本地Obsidian文档及工作区，建立与Advanced
URI配合使用。</p>
<h4 id="工作区workspace">2.10 工作区：Workspace</h4>
<p>workspace是一个自带插件（非三方），开启后在左边栏出现Manage
workspace，也可通过命令行操作。<br />
可以保存当前工作区和load之前保存的工作区（布局/内容等 ）。</p>
<h4 id="主页homepage">2.11 主页：HomePage</h4>
<p>功能简单，但非常有效，它是一个主入口/锚点，可通过它实现快速定位文档<br />
在Buttons文件中定义按钮，以inline方式插入homepage，然后发现每次切换到homepage时需要转到preview模型才能正常显示，此时在homepage的设置中选homepage
view-&gt;reading view即可解决此问题，切过来就是preview模式。</p>
<h4 id="高级uriadvanced-uri">2.12 高级URI：Advanced URI</h4>
<p>如果用AppImage方式在Linux下安装Obsidian，同时想利用"obsidian://"方式跳转，需要先将AppImage解包，然后使用AppRun脚本启动应用，在AppRun中设置软件解包路径，并修改desktop文件，具体方法请见：详见Obsidian
Help项目下的 Installing Obsidian URI。</p>
<h4 id="画图表obsidian-charts">2.13 画图表：Obsidian Charts</h4>
<p>画线图、饼图、箱图，简单好看，用法详见插件介绍。</p>
<h4 id="mermaid-画图">2.14 Mermaid 画图</h4>
<p>mermaid是markdown支持的语法，无需安装插件即可使用，很方便地画流程图、时序图、甘特图、类图、状态图等。<br />
常见用法：<a
href="https://blog.csdn.net/weixin_36483061/article/details/112285101">mermaid流程图工具_mermaid
给你的文档加层滤镜</a><br />
时序图画法：<a
href="https://blog.csdn.net/u011315681/article/details/120179395">Mermaid知识点总结5
- Sequence diagram 1</a></p>
<h4 id="嵌入网页convert-url-to-previewiframe">2.15 嵌入网页：Convert url
to preview(iframe)</h4>
<p>选中URI，然后点击：Alt+i，即可在当前页面生成网页嵌入。<br />
与 <a href="https://tableconvert.com/">https://tableconvert.com/</a>
相结合，可方便地编辑excel。</p>
<h4 id="日程管理day-planner">2.16 日程管理：Day Planner</h4>
<p>以图的形式显示当天日程。<br />
详见：[[1_Note/0_工具/笔记工具/Obsidian/6_Obsidian_日程管理工具]]</p>
<h4 id="悬浮显示大纲">2.17 悬浮显示大纲</h4>
<p>floating-toc</p>
<h4 id="在上方目录跳转">2.18 在上方目录跳转</h4>
<p>quick explorer</p>
<h4 id="隐藏文件夹">2.19 隐藏文件夹</h4>
<p>hidden folder</p>
<h2 id="尝试中">尝试中</h2>
<h4 id="把obsidian内容导入notionobsidian-to-notion">2.20
把Obsidian内容导入Notion：Obsidian to Notion</h4>
<p>Notion地址：https://www.notion.so/</p>
<h4 id="利用obsidian中的素材做网站quartz">2.21
利用Obsidian中的素材做网站：quartz</h4>
<p>用obsidian做网站</p>
<h3 id="下载">3 下载</h3>
<p><a href="https://ob.pory.app/">OB插件搜索</a><br />
<a
href="https://gitee.com/whghcyx/obsidian-plugin/tree/master/.obsidian%5Cplugins">插件下载</a><br />
<a
href="https://gitee.com/whghcyx/obsidian-plugin/tree/master/plugin">插件介绍</a></p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>笔记</tag>
        <tag>Obsidian</tag>
      </tags>
  </entry>
  <entry>
    <title>Obsidian用Git同步笔记</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%AC%94%E8%AE%B0%E5%B7%A5%E5%85%B7/Obsidian/3_Obsidian_%E7%94%A8Git%E5%90%8C%E6%AD%A5%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>#工具/笔记/Obsidian</p>
<h2 id="问题">问题</h2>
<p>Obsidian需要家里和单位电脑同步，以及定时备份，之前试过使用百度网盘和Github备份数据。百度网盘提供了一些API上传和下载数据，搭配Linux的crontab定时任务，能实现基本备份功能，但速度太慢。Github效果不错，但是常常连不通。</p>
<p>这次选择了 Obsidian
的三方插件+Gitee结合的方式，设置半小时备份一次，比较完美地解决了备份问题。</p>
<h2 id="原理">原理</h2>
<p>Obsidian中的插件只是简单地执行git
pull/commit/pull等命令，需要先在本机配置好git环境，然后与Obsidian的定时任务配合实现push和pull功能。</p>
<p>Gitee是国内的Git服务器，用法和Github基本相同，速度比较快，私有数据也免费。</p>
<h2 id="方法">方法</h2>
<h4 id="配置git环境">配置git环境</h4>
<ul>
<li>注册gitee，并创建自己的私有仓库<br />
<a href="%5Bhttps://gitee.com/%5D">https://gitee.com/</a><br />
</li>
<li>生成公钥：<br />
</li>
</ul>
<pre><code>$ ssh-keygen -t rsa -C &quot;xxx@xxx.com&quot;  </code></pre>
<p>按提示输入地址为
$HOME/.ssh/id_rsa_gitee，以免和github混了，其它选择一路回车（我用Linux系统）。<br />
查看公钥，并将其复制到gitee设置界面的公钥位置。</p>
<pre><code>$ cat /home/xieyan/.ssh/id_rsa_gitee.pub  </code></pre>
<p>其原理是告诉服务器这个客户端是值得信赖的，所以无需用户名密码也可以正常使用。<br />
此后用ssh方式克隆代码（注意http方式仍需输密码），如果不输入用户名密码，可以直接下载，则说明设置成功</p>
<pre><code>$ git clone git@gitee.com:xxx/yyy.git  </code></pre>
<h4 id="使用obsidian访问git">使用obsidian访问git</h4>
<ul>
<li>安装obsidian插件：Obsidian Git<br />
</li>
<li>用Ctrl+p命令行Git pull/push操作git<br />
注意需要先commit，再push<br />
</li>
<li>设置定时更新：<br />
Setting-&gt;Obsidian Git-&gt;设置自动更新，建议30min更新一次<br />
</li>
<li>设置后重启Obsidian生效</li>
</ul>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>笔记</tag>
        <tag>Obsidian</tag>
      </tags>
  </entry>
  <entry>
    <title>Obsidian用Gitee做图床</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%AC%94%E8%AE%B0%E5%B7%A5%E5%85%B7/Obsidian/4_Obsidian_%E5%9B%BE%E5%BA%8A/</url>
    <content><![CDATA[<h2 id="目标">1 目标</h2>
<p>Obsidian文档可以本地存储，文档主要由markdown和图片组成。markdown是纯文本，格式简单占空间也小，在存储和分享的过程中，插在文档中的图片就比较麻烦。所以希望把文本和图片分开存储，并且能简单快速地分享给别人，比如发布博客时，不用一张一张贴图。</p>
<p>图床是一个比较简单的解决方案，它是一种在线图片存储服务，可以用来上传、存储、管理和分享图片。通常，图床会提供图片的URL地址，可以在网页、博客、社交媒体等平台中使用。一般使用腾讯云、阿里云的存储服务实现，也可以使用Github，Gitee代码托管服务实现。主要看图多不多，访问量大不大。</p>
<p>本文将介绍在Ubuntu系统下，用 Obsidian+PicGo+Gitee
的方式做个免费图床，适用于图片不多，访问量不大的场景，同时讨论了扩展性。</p>
<h2 id="原理">2 原理</h2>
<h3 id="obsidian">2.1 Obsidian</h3>
<p>离线的文档管理工具，可以通过 Obsidian QuickShare, Obsidian to
Notion等插件进行网页共享，个人觉得通过图床，把文档和图片分开更加方便。</p>
<h3 id="picgo">2.2 PicGo</h3>
<p>PicGo是一款用于上传、管理和分享图片的工具。它支持多种图床服务，可以方便地将图片上传到图床并生成图片链接，可以在网页、博客、社交媒体等平台中使用。<br />
常见有PicgoApp和Picgo-core两种使用方式，PicgoApp是在本机端口启动一个本地服务，本地应用通过http访问使用它；Picgo-core则比较简单，可以通过命令行调用，无需后台守护进程，占用资源少，但是没有图形界面，操作起来比较困难。（本文使用了Picgo-core方式）</p>
<h3 id="gitee">2.3 Gitee</h3>
<p>Gitee类似Github，是一个代码托管服务，也可以存储图片，并给图片提供外链。它是国内服务，所以比Github速度更快。与收费服务相比，它提供的空间比较小，如果外链访问量太大，有被Gitee官方关停项目的风险。</p>
<h3 id="工具整合">2.4 工具整合</h3>
<p>PicGo支持多种服务，比如Gitee,
Github，七牛云，阿里云等，通过对它的配置，可以轻松切换图床，而不影响上层应用，以方便图床切换。Obsidian可以通过插件方式调用PicGo，把本地图片切换为图床存储。另外，我的系统是Ubuntu
22.04，使用这些工具组合，几乎看不到CPU和内存使用率（文中方法不限于Linux）。</p>
<h2 id="方法">3 方法</h2>
<h3 id="配置gitee">3.1 配置Gitee</h3>
<ul>
<li>建一个公开项目作为图床（只有公开项目，图片链接才能供所有人访问）<br />
</li>
<li>生成令牌：项目界面-&gt;右上角-&gt;设置-&gt;私人令牌-&gt;生成新令牌，权限只选projects</li>
</ul>
<h3 id="配置picgo">3.2 配置PicGo</h3>
<h4 id="搭建nodejs环境">3.2.1 搭建nodejs环境</h4>
<p>nodejs是一个开源、跨平台的 JavaScript
运行环境。下最新版本：https://nodejs.org/dist/v12.18.3/node-v12.18.3-linux-x64.tar.xz<br />
压缩包，并将其解压。</p>
<pre><code>sudo apt-get remove nodejs # 删除旧版本  
sudo sudo cp -r node-v12.18.3-linux-x64 /usr/local/lib/nodejs  
export PATH=/usr/local/lib/nodejs/bin:$PATH  
echo &quot;export PATH=/usr/local/lib/nodejs/bin:$PATH&quot; &gt;&gt; ~/.bashrc  </code></pre>
<p>此后时，node, npm 程序可正常执行。</p>
<h4 id="安装picgo">3.2.2 安装picgo</h4>
<p>安装</p>
<pre><code>npm config set registry https://registry.npm.taobao.org # 设置国内源  
npm install -g cnpm  
npm install picgo -g  
picgo install gitee-uploader # 安装gitee支持插件  </code></pre>
<p>配置</p>
<pre><code>picgo set uploader  
# 选gitee（用上下键和回车）  
# repo：输入gitee项目名（英文名）  
# token: 设置成gitee的令牌  
# 其它选项保持默认即可  
picgo use uploader  
# 选gitee  </code></pre>
<p>此时生成~/.picgo/config.json，pico配置完成，内容大致如下：</p>
<pre><code>&#123;  
  &quot;picBed&quot;: &#123;  
    &quot;uploader&quot;: &quot;gitee&quot;,  
    &quot;current&quot;: &quot;gitee&quot;,  
    &quot;gitee&quot;: &#123;  
      &quot;repo&quot;: &quot;我的项目名&quot;,  
      &quot;branch&quot;: &quot;master&quot;,  
      &quot;token&quot;: &quot;我的token&quot;,  
      &quot;path&quot;: &quot;picgo&quot;,  
      &quot;customPath&quot;: &quot;default&quot;,  
      &quot;customUrl&quot;: &quot;&quot;  
    &#125;,  
    &quot;transformer&quot;: &quot;path&quot;  
  &#125;,  
  &quot;picgoPlugins&quot;: &#123;  
    &quot;picgo-plugin-gitee-uploader&quot;: true  
  &#125;,  
  &quot;picgo-plugin-gitee-uploader&quot;: &#123;  
    &quot;lastSync&quot;: &quot;2023-01-15 09:52:14&quot;  
  &#125;  
&#125;  </code></pre>
<p>测试上传一张图片：</p>
<pre><code>picgo upload xxx.png  </code></pre>
<p>如果命令行提示成功，则已打通picgo和gitee。</p>
<h3 id="配置obsidian">3.3 配置Obsidian</h3>
<p>安装插件：设置-&gt;第三方插件-&gt;浏览-&gt;搜索“Image auto upload
Plugin”-&gt;安装<br />
在插件设置界面将 Default uploader 设为 picgo-core<br />
将 pico core path设为：</p>
<pre><code>/usr/local/lib/nodejs/bin/node /usr/local/lib/nodejs/bin/picgo  </code></pre>
<p>（之前不填也行，最近不知为什么不行了）</p>
<p>理论上，安装后，再Obsidian中贴图时，图片就自动上传了图床。<br />
如果有wl-clipboard报错，可尝试以下方法：</p>
<pre><code>sudo apt -y install wl-clipboard  
npm install clipboard  </code></pre>
<p>可能是基于命令行的picgo
core只能支持图片文件上传，而剪切板并没把图片存在文件里，所以上传失败；如果直接把图片文件拖进OB，则可以正常上传。<br />
问题分析详见<a
href="https://www.cnblogs.com/crstyl/p/16665649.html">超详细配置Marktext的Picgo-Core图片上传到七牛云图床</a>，这个问题在Windows下可以通过安装ShareX补救，但在Linux下，可使用Print
Screen抓屏，然后点“显示文件”，再把文件拖到OB内，即可实现粘贴。</p>
<h3 id="实现效果">3.4 实现效果</h3>
<p>最终我没使用贴图时自动上传（Auto Pasted
upload）。因为如果粘贴了不需要的文件，无法在图床删除。所以只在需要上传单个文档中的图片时，通过Ctrl+p调出命令行，选
"Upload all
images"，操作完之后，界面中的图就替换成了图床地址。相对的，使用“Download
all images”，则图片下载到本地，本地图片地址替换了网页地址。</p>
<h2 id="其它方案">4 其它方案</h2>
<h3 id="安装-picgoapp-版本">4.1 安装 PicgoApp 版本</h3>
<p>我是Ubuntu 22.04，所以下了AppImage版本<br />
国内下载：<br />
https://mirrors.sdu.edu.cn/github-release/Molunerfinn_PicGo/v2.3.1/</p>
<pre><code>chmod 777 PicGo-2.3.1.AppImage # 加权限  
./PicGo-2.3.1.AppImage # 运行，此时右上角出现picgo图标  </code></pre>
<ul>
<li>打开主窗口<br />
</li>
<li>在插件设置中，安装gitee-uploader插件<br />
</li>
<li>在图床设置的giee中设置项目地址和token<br />
</li>
<li>在工作区中设置上传图片</li>
</ul>
<h2 id="参考">5 参考</h2>
<p><a
href="https://picgo.github.io/PicGo-Core-Doc/zh/guide/commands.html#use">PicGo-Core介绍</a></p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>笔记</tag>
        <tag>Obsidian</tag>
      </tags>
  </entry>
  <entry>
    <title>ObsidianDataView插件的简单用法</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%AC%94%E8%AE%B0%E5%B7%A5%E5%85%B7/Obsidian/5_Obsidian_DataView/</url>
    <content><![CDATA[<h1 id="obsidian-dataview-插件的简单用法">Obsidian DataView
插件的简单用法</h1>
<p>#工具/笔记/obsidian</p>
<p>使用DrawView三方插件可生成动态索引</p>
<h4 id="列出当前笔记中的所有标签">列出当前笔记中的所有标签</h4>
<pre><code>`= this.file.tags`  </code></pre>
<h4 id="根据文件生成索引列表">根据文件生成索引列表</h4>
<p>将”目录名“文件夹（含子文件夹）下所有名字包含‘2021’的文件生成索引列表，并按时间排序。</p>
<pre><code>\```dataview  
list from &quot;目录名&quot;  
where contains(file.name,&quot;2021&quot;)  
sort file.ctime  
\```  </code></pre>
<h4 id="根据标签生成索引列表">根据标签生成索引列表</h4>
<pre class="dataview"><code>list   
from #标签名  </code></pre>
<h4 id="yml格式">YML格式</h4>
<p>如需使用dataview进一步管理和显示笔记相关属性，需要在笔记开头用YML格式描述笔记相关属性作为元数据（Metadata），可将YML看作是简单的配置文件
，笔记文件将开头位置六个横杠之间的内容识别为YML，形如：</p>
<pre><code>---  
题目: xxx  
作者: yyy  
tags: \[]  
---  </code></pre>
<p>注意冒号后面的空格</p>
<h4 id="按属性生成索引表">按属性生成索引表</h4>
<pre><code>\```dataview  
list   
from &quot;&quot;  
where contains(作者,&quot;yyy&quot;)  
\```  </code></pre>
<p><strong>注意关键字使用双引号括起来</strong></p>
<h4 id="生成数据表">生成数据表</h4>
<p>将读书笔记目录下的所有文件生成table表，该表包含索引文件名、作者、tags三列，并根据tags排序</p>
<pre class="dataview"><code>table 作者,tags  
from &quot;读书笔记&quot;  
sort tags  </code></pre>
<p>其中author, tags在笔记开头的YML中定义</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020211204164623.png"
alt="Pasted%20image%2020211204164623.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020211204164623.png</figcaption>
</figure>
<h4 id="参考">参考</h4>
<p><a
href="https://zhuanlan.zhihu.com/p/409253101">obsidian插件之dataview入门</a></p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>笔记</tag>
        <tag>Obsidian</tag>
      </tags>
  </entry>
  <entry>
    <title>Obsidian日程管理工具</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%AC%94%E8%AE%B0%E5%B7%A5%E5%85%B7/Obsidian/6_Obsidian_%E6%97%A5%E7%A8%8B%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<p>#工具/笔记/obsidian</p>
<h2 id="简介">简介</h2>
<p>原来一直觉得对每个小时日程做记录实在太卷了，但是近来常常遇到的问题是：计划都没完成，时间就没了，所以决定记录一下看看每天都做了什么。<br />
Obsidian 的 Day Planner
插件就实现了这一功能，且可以以图的形式显示当天日程。</p>
<h2 id="优点">优点</h2>
<ul>
<li>很直观的看到当前处于什么位置<br />
</li>
<li>明显看到时间流浙<br />
</li>
<li>哪项工作delay<br />
</li>
<li>哪些工作安排冲突<br />
</li>
<li>尽管没完成计划，但也并没闲着<br />
</li>
<li>进一步优化时间表，更有掌控感</li>
</ul>
<h2 id="使用方法">使用方法</h2>
<ul>
<li>安装三方插件Day Planner
<ul>
<li>Setting-&gt;Community plugins-&gt;Day Planner<br />
</li>
<li>这也是一款下载量非常大的插件<br />
</li>
</ul></li>
<li>设置插件
<ul>
<li>Setting-&gt;Day Planner<br />
</li>
<li>建议在 Day Planner mode 中选 Command mode，如果使用File
mode会建立一个文件夹专门存放Day Planner文件，如果使用Command
mode则可通过命令面板在任意文件中插入Day Planner块<br />
</li>
<li>建议选中Mermaid Gantt，可以在笔记中自动建立横版的进度图，形如：</li>
</ul></li>
</ul>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-9f32b0635b6e173a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/721/format/webp" /></p>
<pre class="undefined"><code>* 建议把Timeline Zoom Level设置成1或2，这样右侧的竖版图显示比较紧凑  </code></pre>
<ul>
<li>添加Day Planner
<ul>
<li>Ctrl+P调出命令面板<br />
</li>
<li>输入Day Planner，找到与它相关的所有命令<br />
</li>
<li>选 Add a Day Planner...... 在当前笔记中加入基本模板<br />
</li>
<li>再选 Show the Day Planer
timeline，此时在右侧面板上显示竖版进度图<br />
</li>
<li>如果显示“No plan data”，使用命令面板上的 Link today's Day planner to
the current note，即可正常显示</li>
</ul></li>
</ul>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-dc0ee4021dab0a9f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/432/format/webp" /></p>
<ul>
<li>关键字
<ul>
<li>注意关键字 “BREAK”
为休息时段，在横图上它与其它状态以不同颜色显示</li>
</ul></li>
</ul>
<h2 id="tips">Tips</h2>
<ul>
<li>可以把"Kanban"和"Day
Planner"放在同一个文件里，个人感觉，这样用也挺不错</li>
</ul>
<h2 id="参考">参考</h2>
<ul>
<li><a
href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Flynchjames%2Fobsidian-day-planner">git说明文档</a><br />
</li>
<li><a
href="https://links.jianshu.com/go?to=https%3A%2F%2Fwww.zhihu.com%2Fcolumn%2Fc_1413472005866266624">玩转Obsidian的保姆级教程</a></li>
</ul>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>笔记</tag>
        <tag>Obsidian</tag>
      </tags>
  </entry>
  <entry>
    <title>7_Obsidian_用腾讯云同步笔记</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%AC%94%E8%AE%B0%E5%B7%A5%E5%85%B7/Obsidian/7_Obsidian_%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BA%91%E5%90%8C%E6%AD%A5%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="介绍">1 介绍</h2>
<p>之前用gitee同步OB笔记，同时做图床。但由于git系产品设置起来相对复杂，且后续可能有外链过审等问题。周五被同事小姐姐安利了用腾讯云COS，试了一下，果然不错。其主要优点如下：<br />
* 设置简单，学习成本低，手机端也可方便设置<br />
*
价格也可接受，如果仅存笔记，一年也就十几-几十块钱吧（当然也看存储访问量）<br />
* 想存啥存啥，不用担心哪天被人家关了</p>
<h2 id="开通腾讯云存储">2 开通腾讯云存储</h2>
<ul>
<li>先用价格计算器看一下价钱<br />
<a
href="https://cloud.tencent.com/product/cos?cps_key=07262ceff2ebf6a221b67638c3953235&amp;from=console">腾讯云存储</a><br />
</li>
<li>注册并开通COS服务<br />
<a href="https://console.cloud.tencent.com/cos">登录</a><br />
</li>
<li>创建笔记存储桶<br />
起名（后面不能改），设成私有读写，其它使用默认设置<br />
</li>
<li>创建图床存储桶<br />
起名（后面不能改），设成公有读私有写，其它使用默认设置<br />
</li>
<li>创建密钥<br />
<a href="https://console.cloud.tencent.com/cam/capi">网页入口</a></li>
</ul>
<h2 id="设置同步ob笔记">3 设置同步OB笔记</h2>
<ul>
<li>安装插件<br />
Remotely Save<br />
此后，左侧出现一个小圆圈的图标，需要同步时按这个图标即可。<br />
</li>
<li>填写以下五项设置，其它可使用默认<br />
（20230218当前版本插件，填写设置中的五个输入框）<br />
其中第一二五项内容填写获取方式：COS网页-&gt;存储桶列表-&gt;点新建桶右侧的配置管理，根据其访问域名填写；第三四项内容根据上面创建的密钥填写<br />
<img
src="https://obimage-1316917304.cos.ap-beijing.myqcloud.com/picgo/image-image-image-Pasted%20image%2020230218231807.png"
alt="图-1" /></li>
</ul>
<h2 id="设置图床">4 设置图床</h2>
<p>图床基本操作见：<a
href="/1_Note/0_工具/笔记工具/Obsidian/4_Obsidian_图床">4_Obsidian_图床</a><br />
设置具体信息：<code></code><br />
picgo set uploader # 选tcyun</p>
<pre><code>具体请参考如下设置：  
![图-2](https://obimage-1316917304.cos.ap-beijing.myqcloud.com/picgo/image-image-image-Pasted%20image%2020230218233847.png)  
设置服务器  </code></pre>
<p>picgo use uploader # 选tcyun<br />
```</p>
<h2 id="其它">5 其它</h2>
<ul>
<li>设置中有自动同步频率等，需要手术设置<br />
</li>
<li>OB同步应有主次
<ul>
<li>主端自动定时push，开启时pull（一般在修改频率的PC端设置）<br />
</li>
<li>从端手动同步和更新（有时在后台不能确定其是否更新，可能引起错误的覆盖）</li>
</ul></li>
</ul>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>笔记</tag>
        <tag>Obsidian</tag>
      </tags>
  </entry>
  <entry>
    <title>Obsidian_从豆瓣收集图书_电影_电视剧信息</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%AC%94%E8%AE%B0%E5%B7%A5%E5%85%B7/Obsidian/8_Obsidian_%E4%BB%8E%E8%B1%86%E7%93%A3%E6%94%B6%E9%9B%86%E4%BF%A1%E6%81%AF/</url>
    <content><![CDATA[<h3 id="功能">功能</h3>
<p>从豆瓣收集图书_电影_电视剧信息，插入Obsidian笔记。</p>
<h3 id="原理">原理</h3>
<p>用JS抓取网站内容填入模板，插入笔记，通过插件之间的配合实现强大功能。</p>
<h3 id="设置">设置</h3>
<ul>
<li>安装 QuickAdd 插件<br />
</li>
<li>把js文件复制到 templates/script/目录下<br />
</li>
<li>把模板复制到 templates/目录下<br />
</li>
<li>在左下角设置界面调出QuickAdd的设置界面<br />
<img src="/attachments_2023/Pasted%20image%2020230319221121.png"
alt="|400" /><br />
</li>
<li>加Micro
<ul>
<li>点Manage Micros-&gt;起个名-&gt;Add Micro<br />
</li>
<li>加好Macro后点其对应的Configure设置<br />
</li>
<li>加JS脚本
<ul>
<li>在User Scripts中选刚才拷到script下的脚本，然后点其后的Add<br />
</li>
</ul></li>
<li>点Template按钮，加上一个模板后，设置其内容
<ul>
<li>在Template Path中设置刚才拷进的模板<br />
</li>
<li>勾选File Name Format<br />
</li>
<li>在File Name中输入：<code>&#123;&#123;VALUE:name&#125;&#125;</code><br />
</li>
<li>双击顶部的模板名，设置成自定义名称<br />
</li>
<li>点右上的叉退出，自动保存<br />
</li>
</ul></li>
</ul></li>
<li>连接显示名称和Macro
<ul>
<li>进入最顶层的QuickAdd Setting界面（上图所示界面）<br />
</li>
<li>起一个最终显示的名字，选Macro，点Add Choice<br />
</li>
<li>设置刚生成项目，将其与前面设置的Macro连接<br />
</li>
</ul></li>
<li>点亮对应的 Add Command for xxx（打雷图标）</li>
</ul>
<h3 id="添加豆瓣">添加豆瓣</h3>
<ul>
<li>Ctrl+P调出菜单<br />
</li>
<li>选择QuickAdd新建的功能</li>
</ul>
<h2 id="其它">其它</h2>
<ul>
<li>稍微改一下js脚本，支持IMDb，就可以支持收集电影电视剧信息。<br />
</li>
<li>对于唯一标识，书是采用的是ISBN；电影是IMDb；音乐国外是条形码，国内是ISRC。<br />
</li>
<li>如果还想收集综艺，就把那个网页地址填入输入框。</li>
</ul>
<h2 id="代码">代码</h2>
<p>方法主要参考"参考"部分的代码和视频，我加了少量简化和修改</p>
<h3 id="我的模板">我的模板</h3>
<pre><code>---  
title: &#123;&#123;VALUE:title&#125;&#125;  
author: &#123;&#123;VALUE:author&#125;&#125;  
transAuthor: &#123;&#123;VALUE:transAuthor&#125;&#125;  
rating: &#123;&#123;VALUE:rating&#125;&#125;  
tags: &#123;&#123;VALUE:tags&#125;&#125;  
ISBN: &#123;&#123;VALUE:isbn&#125;&#125;  
type: ReadNote  
link: &#123;&#123;VALUE:link&#125;&#125;  
cover: &#123;&#123;VALUE:coverUrl&#125;&#125;  
pages: &#123;&#123;VALUE:pages&#125;&#125;  
BeginDate: &#123;&#123;VALUE:today&#125;&#125;  
---  
  
# &#123;&#123;VALUE:name&#125;&#125;  
  
![&#123;&#123;VALUE:name&#125;&#125;|300](&#123;&#123;VALUE:coverUrl&#125;&#125;)  
  

## 简介  

### 书籍简介  
  
&#123;&#123;VALUE:intro&#125;&#125;  
  

### 作者简介  
  
&#123;&#123;VALUE:authorIntro&#125;&#125;  </code></pre>
<p>另外，修改js，兼容了综艺和电影和直接输入http地址，只简单加了一个，没做太多解释：</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode js"><code class="sourceCode javascript"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">// Author: @Lumos  </span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co">// Url: https://github.com/LumosLovegood  </span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="kw">const</span> headers <span class="op">=</span> &#123;  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Content-Type&quot;</span><span class="op">:</span> <span class="st">&quot;text/html; charset=utf-8&quot;</span><span class="op">,</span>  </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Connection&#39;</span><span class="op">:</span> <span class="st">&#39;keep-alive&#39;</span><span class="op">,</span>  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Upgrade-Insecure-Requests&#39;</span><span class="op">:</span> <span class="st">&#39;1&#39;</span><span class="op">,</span>  </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;User-Agent&#39;</span><span class="op">:</span> <span class="st">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36&#39;</span><span class="op">,</span>  </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Accept&#39;</span><span class="op">:</span> <span class="st">&#39;text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9&#39;</span><span class="op">,</span>  </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;sec-ch-ua&#39;</span><span class="op">:</span> <span class="st">&#39;&quot; Not A;Brand&quot;;v=&quot;99&quot;, &quot;Chromium&quot;;v=&quot;98&quot;, &quot;Google Chrome&quot;;v=&quot;98&quot;&#39;</span><span class="op">,</span>  </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;sec-ch-ua-mobile&#39;</span><span class="op">:</span> <span class="st">&#39;?0&#39;</span><span class="op">,</span>  </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;sec-ch-ua-platform&#39;</span><span class="op">:</span> <span class="st">&#39;&quot;Windows&quot;&#39;</span><span class="op">,</span>  </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Sec-Fetch-Site&#39;</span><span class="op">:</span> <span class="st">&#39;same-site&#39;</span><span class="op">,</span>  </span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Sec-Fetch-Mode&#39;</span><span class="op">:</span> <span class="st">&#39;navigate&#39;</span><span class="op">,</span>  </span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Sec-Fetch-User&#39;</span><span class="op">:</span> <span class="st">&#39;?1&#39;</span><span class="op">,</span>  </span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Sec-Fetch-Dest&#39;</span><span class="op">:</span> <span class="st">&#39;document&#39;</span><span class="op">,</span>  </span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Referer&#39;</span><span class="op">:</span> <span class="st">&#39;https://m.douban.com/&#39;</span><span class="op">,</span>  </span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Accept-Language&#39;</span><span class="op">:</span> <span class="st">&#39;en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7&#39;</span><span class="op">,</span>  </span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    &#125;  </span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="kw">async</span> <span class="kw">function</span> <span class="fu">douban</span>(QuickAdd)&#123;  </span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> user_input <span class="op">=</span> <span class="cf">await</span> QuickAdd<span class="op">.</span><span class="at">quickAddApi</span><span class="op">.</span><span class="fu">inputPrompt</span>(  </span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;请输入书籍背后的13位ISBN码/10位IMDb/网页地址：&quot;</span>  </span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    )<span class="op">;</span>  </span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> simpleInfo<span class="op">=</span>&#123;&#125;<span class="op">;</span>  </span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(user_input<span class="op">.</span><span class="fu">substring</span>(<span class="dv">0</span><span class="op">,</span><span class="dv">4</span>)<span class="op">!=</span><span class="st">&#39;http&#39;</span>) &#123;  </span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(user_input<span class="op">.</span><span class="at">length</span><span class="op">!=</span><span class="dv">13</span> <span class="op">&amp;&amp;</span> user_input<span class="op">.</span><span class="at">length</span><span class="op">!=</span><span class="dv">10</span> <span class="op">&amp;&amp;</span> user_input<span class="op">.</span><span class="fu">substring</span>(<span class="dv">0</span><span class="op">,</span><span class="dv">4</span>)<span class="op">!=</span><span class="st">&#39;http&#39;</span>)&#123;  </span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>            <span class="kw">new</span> <span class="fu">Notice</span>(<span class="st">&quot;输入错误&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">throw</span> <span class="kw">new</span> <span class="bu">Error</span>(<span class="st">&quot;输入错误&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>        &#125;  </span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>        simpleInfo <span class="op">=</span><span class="cf">await</span> <span class="fu">getBookUrl</span>(user_input)<span class="op">;</span>  </span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(<span class="op">!</span>simpleInfo)&#123;  </span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>            <span class="kw">new</span> <span class="fu">Notice</span>(<span class="st">&quot;无法识别此ISBN码&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>            <span class="cf">throw</span> <span class="kw">new</span> <span class="bu">Error</span>(<span class="st">&quot;无法识别此ISBN码&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>        &#125;  </span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>    &#125; <span class="cf">else</span> &#123;  </span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>        simpleInfo<span class="op">.</span><span class="at">title</span><span class="op">=</span><span class="st">&#39;数据&#39;</span><span class="op">;</span>  </span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>        simpleInfo<span class="op">.</span><span class="at">url</span> <span class="op">=</span> user_input<span class="op">;</span>  </span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    &#125;      </span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> url <span class="op">=</span> simpleInfo<span class="op">.</span><span class="at">url</span><span class="op">;</span>  </span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>    <span class="kw">new</span> <span class="fu">Notice</span>(<span class="st">&quot;准备获取《&quot;</span><span class="op">+</span>simpleInfo<span class="op">.</span><span class="at">title</span><span class="op">+</span><span class="st">&quot;》的内容信息&quot;</span><span class="op">,</span><span class="dv">1000</span>)  </span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> bookInfo <span class="op">=</span> <span class="cf">await</span> <span class="fu">getDetailInfo</span>(url)  </span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(<span class="op">!</span>bookInfo)&#123;  </span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>        <span class="kw">new</span> <span class="fu">Notice</span>(<span class="st">&quot;获取内容失败&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">throw</span> <span class="kw">new</span> <span class="bu">Error</span>(<span class="st">&quot;获取内容失败&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>    &#125;  </span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>    <span class="kw">new</span> <span class="fu">Notice</span>(<span class="st">&quot;笔记已生成！&quot;</span><span class="op">,</span><span class="dv">500</span>)<span class="op">;</span>  </span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 获取今日日期  </span></span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> date <span class="op">=</span> <span class="bu">window</span><span class="op">.</span><span class="fu">moment</span>()<span class="op">.</span><span class="fu">format</span>(<span class="st">&quot;gggg-MM-DD&quot;</span>)  </span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>    bookInfo<span class="op">.</span><span class="at">today</span> <span class="op">=</span> date<span class="op">;</span>  </span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>    QuickAdd<span class="op">.</span><span class="at">variables</span> <span class="op">=</span> &#123;  </span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>        <span class="op">...</span>bookInfo  </span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>    &#125;<span class="op">;</span>  </span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>&#125;  </span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a><span class="kw">async</span> <span class="kw">function</span> <span class="fu">getBookUrl</span>(isbn)&#123;  </span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>    url <span class="op">=</span> <span class="st">&quot;https://m.douban.com/search/?query=&quot;</span><span class="op">+</span>isbn<span class="op">;</span>  </span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> searchUrl <span class="op">=</span> <span class="kw">new</span> <span class="fu">URL</span>(url)<span class="op">;</span>  </span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> res <span class="op">=</span> <span class="cf">await</span> <span class="fu">request</span>(&#123;  </span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>      <span class="dt">url</span><span class="op">:</span> searchUrl<span class="op">.</span><span class="at">href</span><span class="op">,</span>  </span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>      <span class="dt">method</span><span class="op">:</span> <span class="st">&quot;GET&quot;</span><span class="op">,</span>  </span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>      <span class="dt">cache</span><span class="op">:</span> <span class="st">&quot;no-cache&quot;</span><span class="op">,</span>  </span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a>      <span class="dt">headers</span><span class="op">:</span> &#123;  </span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;Content-Type&quot;</span><span class="op">:</span> <span class="st">&quot;text/html; charset=utf-8&quot;</span><span class="op">,</span>  </span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;sec-ch-ua&#39;</span><span class="op">:</span> <span class="st">&#39;&quot; Not A;Brand&quot;;v=&quot;99&quot;, &quot;Chromium&quot;;v=&quot;98&quot;, &quot;Google Chrome&quot;;v=&quot;98&quot;&#39;</span><span class="op">,</span>  </span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;sec-ch-ua-mobile&#39;</span><span class="op">:</span> <span class="st">&#39;?0&#39;</span><span class="op">,</span>  </span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;sec-ch-ua-platform&#39;</span><span class="op">:</span> <span class="st">&#39;&quot;Windows&quot;&#39;</span><span class="op">,</span>  </span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;Upgrade-Insecure-Requests&#39;</span><span class="op">:</span> <span class="st">&#39;1&#39;</span><span class="op">,</span>  </span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;User-Agent&#39;</span><span class="op">:</span> <span class="st">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36&#39;</span>  </span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a>      &#125;  </span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>    &#125;)<span class="op">;</span>  </span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(<span class="op">!</span>res)&#123;  </span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="kw">null</span><span class="op">;</span>  </span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a>    &#125;  </span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> p <span class="op">=</span> <span class="kw">new</span> <span class="fu">DOMParser</span>()<span class="op">;</span>  </span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> doc <span class="op">=</span> p<span class="op">.</span><span class="fu">parseFromString</span>(res<span class="op">,</span> <span class="st">&quot;text/html&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> title <span class="op">=</span> doc<span class="op">.</span><span class="fu">querySelector</span>(<span class="st">&quot;div.subject-info span&quot;</span>)<span class="op">.</span><span class="at">textContent</span><span class="op">;</span>  </span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> detailUrl <span class="op">=</span> <span class="bu">String</span>(doc<span class="op">.</span><span class="fu">querySelector</span>(<span class="st">&quot;ul li a&quot;</span>)<span class="op">.</span><span class="at">href</span>)<span class="op">.</span><span class="fu">replace</span>(None)<span class="op">;</span>  </span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="op">!</span>detailUrl)&#123;  </span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="kw">null</span><span class="op">;</span>  </span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a>    &#125;  </span>
<span id="cb2-85"><a href="#cb2-85" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> simpleInfo<span class="op">=</span>&#123;&#125;<span class="op">;</span>  </span>
<span id="cb2-86"><a href="#cb2-86" aria-hidden="true" tabindex="-1"></a>    simpleInfo<span class="op">.</span><span class="at">title</span><span class="op">=</span>title<span class="op">;</span>  </span>
<span id="cb2-87"><a href="#cb2-87" aria-hidden="true" tabindex="-1"></a>    simpleInfo<span class="op">.</span><span class="at">url</span> <span class="op">=</span> detailUrl<span class="op">;</span>  </span>
<span id="cb2-88"><a href="#cb2-88" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> simpleInfo<span class="op">;</span>  </span>
<span id="cb2-89"><a href="#cb2-89" aria-hidden="true" tabindex="-1"></a>&#125;  </span>
<span id="cb2-90"><a href="#cb2-90" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-91"><a href="#cb2-91" aria-hidden="true" tabindex="-1"></a><span class="kw">async</span> <span class="kw">function</span> <span class="fu">getDetailInfo</span>(url)&#123;  </span>
<span id="cb2-92"><a href="#cb2-92" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> bookUrl <span class="op">=</span> <span class="kw">new</span> <span class="fu">URL</span>(url)<span class="op">;</span>  </span>
<span id="cb2-93"><a href="#cb2-93" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> res <span class="op">=</span> <span class="cf">await</span> <span class="fu">request</span>(&#123;  </span>
<span id="cb2-94"><a href="#cb2-94" aria-hidden="true" tabindex="-1"></a>        <span class="dt">url</span><span class="op">:</span> bookUrl<span class="op">.</span><span class="at">href</span><span class="op">,</span>  </span>
<span id="cb2-95"><a href="#cb2-95" aria-hidden="true" tabindex="-1"></a>        <span class="dt">method</span><span class="op">:</span> <span class="st">&quot;GET&quot;</span><span class="op">,</span>  </span>
<span id="cb2-96"><a href="#cb2-96" aria-hidden="true" tabindex="-1"></a>        <span class="dt">cache</span><span class="op">:</span> <span class="st">&quot;no-cache&quot;</span><span class="op">,</span>  </span>
<span id="cb2-97"><a href="#cb2-97" aria-hidden="true" tabindex="-1"></a>        <span class="dt">headers</span><span class="op">:</span> headers  </span>
<span id="cb2-98"><a href="#cb2-98" aria-hidden="true" tabindex="-1"></a>    &#125;)<span class="op">;</span>  </span>
<span id="cb2-99"><a href="#cb2-99" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> p <span class="op">=</span> <span class="kw">new</span> <span class="fu">DOMParser</span>()<span class="op">;</span>  </span>
<span id="cb2-100"><a href="#cb2-100" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> doc <span class="op">=</span> p<span class="op">.</span><span class="fu">parseFromString</span>(res<span class="op">,</span> <span class="st">&quot;text/html&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-101"><a href="#cb2-101" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> $ <span class="op">=</span> s <span class="kw">=&gt;</span> doc<span class="op">.</span><span class="fu">querySelector</span>(s)<span class="op">;</span>  </span>
<span id="cb2-102"><a href="#cb2-102" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> $2 <span class="op">=</span> z <span class="kw">=&gt;</span> doc<span class="op">.</span><span class="fu">querySelectorAll</span>(z)<span class="op">;</span>  </span>
<span id="cb2-103"><a href="#cb2-103" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-104"><a href="#cb2-104" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> bookInfo <span class="op">=</span> &#123;&#125;<span class="op">;</span>   </span>
<span id="cb2-105"><a href="#cb2-105" aria-hidden="true" tabindex="-1"></a>    <span class="co">//书名、作者、ISBN、封面  </span></span>
<span id="cb2-106"><a href="#cb2-106" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> name <span class="op">=</span> <span class="fu">$</span>(<span class="st">&quot;meta[property=&#39;og:title&#39;]&quot;</span>)<span class="op">?.</span><span class="at">content</span><span class="op">;</span>  </span>
<span id="cb2-107"><a href="#cb2-107" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> title <span class="op">=</span> <span class="st">&quot;</span><span class="sc">\&quot;</span><span class="st">&quot;</span><span class="op">+</span>name<span class="op">+</span><span class="st">&quot;</span><span class="sc">\&quot;</span><span class="st">&quot;</span><span class="op">;</span> <span class="co">//用于放到front matter里，加引号避免因为包含特殊字符导致ymal解析错误  </span></span>
<span id="cb2-108"><a href="#cb2-108" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> author <span class="op">=</span> <span class="st">&quot;</span><span class="sc">\&quot;</span><span class="st">&quot;</span><span class="op">+</span><span class="fu">$</span>(<span class="st">&quot;meta[property=&#39;book:author&#39;]&quot;</span>)<span class="op">?.</span><span class="at">content</span><span class="op">.</span><span class="fu">replace</span>(<span class="ss">/</span><span class="sc">[\[\]\(\)（）]</span><span class="ss">/g</span><span class="op">,</span><span class="st">&quot;&quot;</span>)<span class="op">+</span><span class="st">&quot;</span><span class="sc">\&quot;</span><span class="st">&quot;</span><span class="op">;</span>  </span>
<span id="cb2-109"><a href="#cb2-109" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> isbn <span class="op">=</span> <span class="fu">$</span>(<span class="st">&quot;meta[property=&#39;book:isbn&#39;]&quot;</span>)<span class="op">?.</span><span class="at">content</span><span class="op">;</span>  </span>
<span id="cb2-110"><a href="#cb2-110" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> cover <span class="op">=</span> <span class="fu">$</span>(<span class="st">&quot;meta[property=&#39;og:image&#39;]&quot;</span>)<span class="op">?.</span><span class="at">content</span><span class="op">;</span>  </span>
<span id="cb2-111"><a href="#cb2-111" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb2-112"><a href="#cb2-112" aria-hidden="true" tabindex="-1"></a>    <span class="co">//其他信息(译者、原作名、页数)  </span></span>
<span id="cb2-113"><a href="#cb2-113" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> text <span class="op">=</span> <span class="fu">$</span>(<span class="st">&quot;#info&quot;</span>)<span class="op">?.</span><span class="at">textContent</span><span class="op">.</span><span class="fu">replace</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">,</span><span class="st">&quot;&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-114"><a href="#cb2-114" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> transAuthor <span class="op">=</span> text<span class="op">.</span><span class="fu">match</span>(<span class="ss">/</span><span class="sc">(?</span><span class="ss">&lt;=译者:</span><span class="sc">\s*)\S+\s?\S+</span><span class="ss">/g</span>)<span class="op">?</span>text<span class="op">.</span><span class="fu">match</span>(<span class="ss">/</span><span class="sc">(?</span><span class="ss">&lt;=译者:</span><span class="sc">\s*)\S+\s?\S+</span><span class="ss">/g</span>)[<span class="dv">0</span>]<span class="op">.</span><span class="fu">trim</span>()<span class="op">:</span><span class="st">&quot;&quot;</span><span class="op">;</span>  </span>
<span id="cb2-115"><a href="#cb2-115" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> originalName <span class="op">=</span> text<span class="op">.</span><span class="fu">match</span>(<span class="ss">/</span><span class="sc">(?</span><span class="ss">&lt;=原作名:</span><span class="sc">\s*)[\S ]+</span><span class="ss">/g</span>)<span class="op">?</span>(<span class="st">&quot;</span><span class="sc">\&quot;</span><span class="st">&quot;</span><span class="op">+</span>text<span class="op">.</span><span class="fu">match</span>(<span class="ss">/</span><span class="sc">(?</span><span class="ss">&lt;=原作名:</span><span class="sc">\s*)[\S ]+</span><span class="ss">/g</span>)[<span class="dv">0</span>]<span class="op">.</span><span class="fu">trim</span>()<span class="op">+</span><span class="st">&quot;</span><span class="sc">\&quot;</span><span class="st">&quot;</span>)<span class="op">:</span><span class="st">&quot;&quot;</span><span class="op">;</span>  </span>
<span id="cb2-116"><a href="#cb2-116" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> pages <span class="op">=</span> text<span class="op">.</span><span class="fu">match</span>(<span class="ss">/</span><span class="sc">(?</span><span class="ss">&lt;=页数:</span><span class="sc">\s*)[\S ]+</span><span class="ss">/g</span>)<span class="op">?</span>text<span class="op">.</span><span class="fu">match</span>(<span class="ss">/</span><span class="sc">(?</span><span class="ss">&lt;=页数:</span><span class="sc">\s*)[\S ]+</span><span class="ss">/g</span>)[<span class="dv">0</span>]<span class="op">.</span><span class="fu">trim</span>()<span class="op">:</span><span class="st">&quot;&quot;</span><span class="op">;</span>  </span>
<span id="cb2-117"><a href="#cb2-117" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> publisher <span class="op">=</span> text<span class="op">.</span><span class="fu">match</span>(<span class="ss">/</span><span class="sc">(?</span><span class="ss">&lt;=出版社:</span><span class="sc">\s*)\S+\s?\S+</span><span class="ss">/g</span>)<span class="op">?</span>text<span class="op">.</span><span class="fu">match</span>(<span class="ss">/</span><span class="sc">(?</span><span class="ss">&lt;=出版社:</span><span class="sc">\s*)\S+\s?\S+</span><span class="ss">/g</span>)[<span class="dv">0</span>]<span class="op">.</span><span class="fu">trim</span>()<span class="op">:</span><span class="st">&quot;&quot;</span><span class="op">;</span>  </span>
<span id="cb2-118"><a href="#cb2-118" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-119"><a href="#cb2-119" aria-hidden="true" tabindex="-1"></a>    <span class="co">//豆瓣评分  </span></span>
<span id="cb2-120"><a href="#cb2-120" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> rating <span class="op">=</span> <span class="fu">$</span>(<span class="st">&quot;div#interest_sectl div div strong&quot;</span>)<span class="op">?.</span><span class="at">textContent</span><span class="op">.</span><span class="fu">replace</span>(<span class="ss">/</span><span class="sc">\s</span><span class="ss">/g</span><span class="op">,</span><span class="st">&quot;&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-121"><a href="#cb2-121" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-122"><a href="#cb2-122" aria-hidden="true" tabindex="-1"></a>    <span class="co">//书籍和作者简介，这一块儿不同类型的书对应的网页结构都不太一样，尽力做兼容了，还有问题我也没办法 \摊手  </span></span>
<span id="cb2-123"><a href="#cb2-123" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> intro <span class="op">=</span> <span class="st">&quot;&quot;</span><span class="op">;</span>  </span>
<span id="cb2-124"><a href="#cb2-124" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> authorIntro <span class="op">=</span> <span class="st">&quot;&quot;</span><span class="op">;</span>  </span>
<span id="cb2-125"><a href="#cb2-125" aria-hidden="true" tabindex="-1"></a>    <span class="kw">var</span> temp1 <span class="op">=</span> <span class="fu">$</span>(<span class="st">&quot;h2&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-126"><a href="#cb2-126" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(temp1<span class="op">.</span><span class="at">innerText</span><span class="op">.</span><span class="fu">includes</span>(<span class="st">&quot;内容简介&quot;</span>))&#123;  </span>
<span id="cb2-127"><a href="#cb2-127" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> temp2 <span class="op">=</span> temp1<span class="op">.</span><span class="at">nextElementSibling</span><span class="op">.</span><span class="fu">querySelectorAll</span>(<span class="st">&quot;div.intro&quot;</span>)  </span>
<span id="cb2-128"><a href="#cb2-128" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> temp3 <span class="op">=</span> temp2[temp2<span class="op">.</span><span class="at">length</span><span class="op">-</span><span class="dv">1</span>]<span class="op">.</span><span class="fu">querySelectorAll</span>(<span class="st">&quot;p&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-129"><a href="#cb2-129" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span>(<span class="kw">var</span> i<span class="op">=</span><span class="dv">0</span><span class="op">;</span>i<span class="op">&lt;</span>temp3<span class="op">.</span><span class="at">length</span><span class="op">;</span>i<span class="op">++</span>)&#123;  </span>
<span id="cb2-130"><a href="#cb2-130" aria-hidden="true" tabindex="-1"></a>            intro <span class="op">=</span> intro<span class="op">+</span>temp3[i]<span class="op">.</span><span class="at">textContent</span><span class="op">+</span><span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">;</span>  </span>
<span id="cb2-131"><a href="#cb2-131" aria-hidden="true" tabindex="-1"></a>        &#125;  </span>
<span id="cb2-132"><a href="#cb2-132" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>&#123;  </span>
<span id="cb2-133"><a href="#cb2-133" aria-hidden="true" tabindex="-1"></a>            temp2 <span class="op">=</span> <span class="fu">$2</span>(<span class="st">&quot;h2&quot;</span>)[<span class="dv">1</span>]<span class="op">.</span><span class="at">nextElementSibling</span><span class="op">.</span><span class="fu">querySelectorAll</span>(<span class="st">&quot;div.intro&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-134"><a href="#cb2-134" aria-hidden="true" tabindex="-1"></a>            temp3 <span class="op">=</span> temp2[temp2<span class="op">.</span><span class="at">length</span><span class="op">-</span><span class="dv">1</span>]<span class="op">.</span><span class="fu">querySelectorAll</span>(<span class="st">&quot;p&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-135"><a href="#cb2-135" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span>(<span class="kw">var</span> i<span class="op">=</span><span class="dv">0</span><span class="op">;</span>i<span class="op">&lt;</span>temp3<span class="op">.</span><span class="at">length</span><span class="op">;</span>i<span class="op">++</span>)&#123;  </span>
<span id="cb2-136"><a href="#cb2-136" aria-hidden="true" tabindex="-1"></a>                authorIntro <span class="op">=</span> authorIntro<span class="op">+</span>temp3[i]<span class="op">.</span><span class="at">textContent</span><span class="op">+</span><span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">;</span>  </span>
<span id="cb2-137"><a href="#cb2-137" aria-hidden="true" tabindex="-1"></a>            &#125;  </span>
<span id="cb2-138"><a href="#cb2-138" aria-hidden="true" tabindex="-1"></a>        &#125;<span class="cf">catch</span>(e)&#123;  </span>
<span id="cb2-139"><a href="#cb2-139" aria-hidden="true" tabindex="-1"></a>            <span class="kw">new</span> <span class="fu">Notice</span>(<span class="st">&quot;没有简介&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-140"><a href="#cb2-140" aria-hidden="true" tabindex="-1"></a>        &#125;          </span>
<span id="cb2-141"><a href="#cb2-141" aria-hidden="true" tabindex="-1"></a>    &#125;<span class="cf">else</span> <span class="cf">if</span>(temp1<span class="op">.</span><span class="at">innerText</span><span class="op">.</span><span class="fu">includes</span>(<span class="st">&quot;作者简介&quot;</span>))&#123;  </span>
<span id="cb2-142"><a href="#cb2-142" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> temp2 <span class="op">=</span> temp1<span class="op">.</span><span class="at">nextElementSibling</span><span class="op">.</span><span class="fu">querySelectorAll</span>(<span class="st">&quot;div.intro&quot;</span>)  </span>
<span id="cb2-143"><a href="#cb2-143" aria-hidden="true" tabindex="-1"></a>        <span class="kw">var</span> temp3 <span class="op">=</span> temp2[temp2<span class="op">.</span><span class="at">length</span><span class="op">-</span><span class="dv">1</span>]<span class="op">.</span><span class="fu">querySelectorAll</span>(<span class="st">&quot;p&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-144"><a href="#cb2-144" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span>(<span class="kw">var</span> i<span class="op">=</span><span class="dv">0</span><span class="op">;</span>i<span class="op">&lt;</span>temp3<span class="op">.</span><span class="at">length</span><span class="op">;</span>i<span class="op">++</span>)&#123;  </span>
<span id="cb2-145"><a href="#cb2-145" aria-hidden="true" tabindex="-1"></a>            authorIntro <span class="op">=</span> authorIntro<span class="op">+</span>temp3[i]<span class="op">.</span><span class="at">textContent</span><span class="op">+</span><span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">;</span>  </span>
<span id="cb2-146"><a href="#cb2-146" aria-hidden="true" tabindex="-1"></a>        &#125;  </span>
<span id="cb2-147"><a href="#cb2-147" aria-hidden="true" tabindex="-1"></a>    &#125;  </span>
<span id="cb2-148"><a href="#cb2-148" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-149"><a href="#cb2-149" aria-hidden="true" tabindex="-1"></a>    <span class="co">//豆瓣常用标签，记得之前这一块儿网页元素里是有的，后来找不到了，但是尝试性源代码全文搜索的时候 在Script标签里找到了，但是感觉随时会改。  </span></span>
<span id="cb2-150"><a href="#cb2-150" aria-hidden="true" tabindex="-1"></a>    <span class="kw">var</span> temp <span class="op">=</span> <span class="fu">$2</span>(<span class="st">&quot;script&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-151"><a href="#cb2-151" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> tags <span class="op">=</span> temp[temp<span class="op">.</span><span class="at">length</span><span class="op">-</span><span class="dv">3</span>]<span class="op">.</span><span class="at">textContent</span><span class="op">.</span><span class="fu">match</span>(<span class="ss">/</span><span class="sc">(?</span><span class="ss">&lt;=:</span><span class="sc">)[\u4e00-\u9fa5·]+</span><span class="ss">/g</span>)<span class="op">;</span>  </span>
<span id="cb2-152"><a href="#cb2-152" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (tags <span class="op">===</span> <span class="kw">null</span>) &#123;  </span>
<span id="cb2-153"><a href="#cb2-153" aria-hidden="true" tabindex="-1"></a>        tags <span class="op">=</span> []<span class="op">;</span>  </span>
<span id="cb2-154"><a href="#cb2-154" aria-hidden="true" tabindex="-1"></a>    &#125; <span class="cf">else</span> &#123;  </span>
<span id="cb2-155"><a href="#cb2-155" aria-hidden="true" tabindex="-1"></a>        tags<span class="op">.</span><span class="fu">push</span>(<span class="st">&quot;book&quot;</span>)<span class="op">;</span>  </span>
<span id="cb2-156"><a href="#cb2-156" aria-hidden="true" tabindex="-1"></a>    &#125;  </span>
<span id="cb2-157"><a href="#cb2-157" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-158"><a href="#cb2-158" aria-hidden="true" tabindex="-1"></a>    bookInfo<span class="op">.</span><span class="at">name</span> <span class="op">=</span> name<span class="op">;</span>  </span>
<span id="cb2-159"><a href="#cb2-159" aria-hidden="true" tabindex="-1"></a>    bookInfo<span class="op">.</span><span class="at">title</span><span class="op">=</span>title<span class="op">;</span>  </span>
<span id="cb2-160"><a href="#cb2-160" aria-hidden="true" tabindex="-1"></a>    bookInfo<span class="op">.</span><span class="at">author</span><span class="op">=</span>author<span class="op">;</span>  </span>
<span id="cb2-161"><a href="#cb2-161" aria-hidden="true" tabindex="-1"></a>    bookInfo<span class="op">.</span><span class="at">transAuthor</span><span class="op">=</span>transAuthor<span class="op">;</span>  </span>
<span id="cb2-162"><a href="#cb2-162" aria-hidden="true" tabindex="-1"></a>    bookInfo<span class="op">.</span><span class="at">coverUrl</span><span class="op">=</span>cover<span class="op">;</span>  </span>
<span id="cb2-163"><a href="#cb2-163" aria-hidden="true" tabindex="-1"></a>    bookInfo<span class="op">.</span><span class="at">originalName</span><span class="op">=</span>originalName<span class="op">;</span>  </span>
<span id="cb2-164"><a href="#cb2-164" aria-hidden="true" tabindex="-1"></a>    bookInfo<span class="op">.</span><span class="at">pages</span><span class="op">=</span>pages<span class="op">;</span>  </span>
<span id="cb2-165"><a href="#cb2-165" aria-hidden="true" tabindex="-1"></a>    bookInfo<span class="op">.</span><span class="at">publisher</span><span class="op">=</span>publisher<span class="op">;</span>  </span>
<span id="cb2-166"><a href="#cb2-166" aria-hidden="true" tabindex="-1"></a>    bookInfo<span class="op">.</span><span class="at">intro</span><span class="op">=</span>intro<span class="op">;</span>  </span>
<span id="cb2-167"><a href="#cb2-167" aria-hidden="true" tabindex="-1"></a>    bookInfo<span class="op">.</span><span class="at">isbn</span><span class="op">=</span>isbn<span class="op">;</span>  </span>
<span id="cb2-168"><a href="#cb2-168" aria-hidden="true" tabindex="-1"></a>    bookInfo<span class="op">.</span><span class="at">rating</span><span class="op">=</span>rating<span class="op">;</span>  </span>
<span id="cb2-169"><a href="#cb2-169" aria-hidden="true" tabindex="-1"></a>    bookInfo<span class="op">.</span><span class="at">authorIntro</span> <span class="op">=</span>authorIntro<span class="op">;</span>  </span>
<span id="cb2-170"><a href="#cb2-170" aria-hidden="true" tabindex="-1"></a>    bookInfo<span class="op">.</span><span class="at">tags</span><span class="op">=</span>tags<span class="op">;</span>  </span>
<span id="cb2-171"><a href="#cb2-171" aria-hidden="true" tabindex="-1"></a>    bookInfo<span class="op">.</span><span class="at">link</span> <span class="op">=</span> url<span class="op">;</span>  </span>
<span id="cb2-172"><a href="#cb2-172" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-173"><a href="#cb2-173" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 如果为空的话，quickadd会出现提示框让自己填，太麻烦了，所以先填一个默认空值  </span></span>
<span id="cb2-174"><a href="#cb2-174" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(<span class="kw">var</span> i <span class="kw">in</span> bookInfo)&#123;  </span>
<span id="cb2-175"><a href="#cb2-175" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(bookInfo[i]<span class="op">==</span><span class="st">&quot;&quot;</span>)&#123;  </span>
<span id="cb2-176"><a href="#cb2-176" aria-hidden="true" tabindex="-1"></a>            bookInfo[i]<span class="op">=</span><span class="st">&quot;Not Found.&quot;</span><span class="op">;</span>  </span>
<span id="cb2-177"><a href="#cb2-177" aria-hidden="true" tabindex="-1"></a>        &#125;  </span>
<span id="cb2-178"><a href="#cb2-178" aria-hidden="true" tabindex="-1"></a>    &#125;  </span>
<span id="cb2-179"><a href="#cb2-179" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-180"><a href="#cb2-180" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> bookInfo<span class="op">;</span>  </span>
<span id="cb2-181"><a href="#cb2-181" aria-hidden="true" tabindex="-1"></a>&#125;  </span>
<span id="cb2-182"><a href="#cb2-182" aria-hidden="true" tabindex="-1"></a>module<span class="op">.</span><span class="at">exports</span> <span class="op">=</span>  douban  </span></code></pre></div>
<h2 id="参考">参考</h2>
<p><a
href="https://github.com/LumosLovegood/myScripts/tree/main/CreateReadNote">代码</a><br />
<a
href="https://www.bilibili.com/video/BV1NT4y1U7P3/?from=seopage">视频</a></p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>笔记</tag>
        <tag>Obsidian</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo问题及解决</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%AC%94%E8%AE%B0%E5%B7%A5%E5%85%B7/hexo/hexo%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3/</url>
    <content><![CDATA[<h2 id="推荐主题">1 推荐主题</h2>
<p>butterfly 的默认 layout 很好，尤其对于内容比较多的
blog，安装方法如下：</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>npm install hexo<span class="op">-</span>renderer<span class="op">-</span>pug hexo<span class="op">-</span>renderer<span class="op">-</span>stylus <span class="op">--</span>save  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>npm install hexo<span class="op">-</span>theme<span class="op">-</span>butterfly  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>cp node_modules<span class="op">/</span>hexo<span class="op">-</span>theme<span class="op">-</span>butterfly<span class="op">/</span>_config.yml _config.butterfly.yml  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>vi _config.yml <span class="co"># 修改 theme: butterfly  </span></span></code></pre></div>
<h2 id="正常显示-latex-公式">2 正常显示 Latex 公式</h2>
<h3 id="切换渲染器">2.1 切换渲染器</h3>
<p>切成root权限，安装 pandoc:</p>
<pre><code>apk add pandoc  </code></pre>
<h3 id="安装插件">2.2 安装插件</h3>
<p>这个插件能支持 <code>$</code> 号模式的 Latex 公式：</p>
<pre><code>npm install hexo-filter-mathjax  </code></pre>
<h3 id="配置文件">2.3 配置文件</h3>
<p>修改_config文件如下：<br />
(我直接把插件 github 说明中的配置文件拷过来了)</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode yml"><code class="sourceCode yaml"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mathjax</span><span class="kw">:</span><span class="at">                                                    </span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">tags</span><span class="kw">:</span><span class="at"> none  </span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">single_dollars</span><span class="kw">:</span><span class="at"> </span><span class="ch">true</span><span class="at">  </span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">cjk_width</span><span class="kw">:</span><span class="at"> </span><span class="fl">0.9</span><span class="at">  </span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">normal_width</span><span class="kw">:</span><span class="at"> </span><span class="fl">0.6</span><span class="at">  </span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">append_css</span><span class="kw">:</span><span class="at"> true                                             every_page: false  </span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">packages</span><span class="kw">:</span><span class="at">   </span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">extension_options</span><span class="kw">:</span><span class="at"> </span><span class="kw">&#123;&#125;</span><span class="at">  </span></span></code></pre></div>
<ul>
<li>修改主题配置文件_config.butterfly.yml：<br />
</li>
</ul>
<div class="sourceCode" id="cb5"><pre
class="sourceCode yml"><code class="sourceCode yaml"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MathJax                                           </span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mathjax</span><span class="kw">:</span><span class="at">                </span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">enable</span><span class="kw">:</span><span class="at"> </span><span class="ch">true</span><span class="at">                        </span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">per_page</span><span class="kw">:</span><span class="at"> </span><span class="ch">true</span><span class="at">    </span></span></code></pre></div>
<h2 id="使用-pandoc-渲染器">3 使用 pandoc 渲染器</h2>
<p>切换 hexo-renderer-pandoc
后，公式倒是能正常显示，但是图片，文本格式需要按 pandoc 的 markdown
格式修改，因此，做了批量调整：<br />
* 换行前加两个空格。<br />
* 图片使用绝对路径。<br />
* 标题前两个回车。<br />
* 把本地图片地址变为绝对路径。</p>
<h2 id="构建标签和分类界面">4 构建标签和分类界面</h2>
<h3 id="标签界面">4.1 标签界面</h3>
<pre><code>$ hexo new page &quot;tags&quot;  
$ vi ~/.hexo/source/tags/index.md  
加如下内容  
---  
type: &quot;tags&quot;  
layout: &quot;tags&quot;  
comments: false  
---  </code></pre>
<h3 id="分类界面">4.2 分类界面</h3>
<pre><code>$ hexo new page &quot;categories&quot;  
$ vi ~/.hexo/source/categories/index.md  
加如下内容  
---  
type: categories  
---  </code></pre>
<h3 id="自动生成分类">4.3 自动生成分类</h3>
<p>一般分类在md的文件头中设置，形如：</p>
<pre><code>categories:  
  - web  
  - framework  </code></pre>
<p>也可以使用自动分类功能，按目录结构生成分类：<br />
安装插件：</p>
<pre><code>npm install hexo-auto-category --save  </code></pre>
<p>修改配置文件_config.yml</p>
<pre><code>auto_category:  
 enable: true  
 depth:  </code></pre>
<h2 id="添加搜索功能">5 添加搜索功能</h2>
<h3 id="安装插件-1">5.1 安装插件</h3>
<pre><code>npm install hexo-generator-searchdb --save  </code></pre>
<h3 id="修改配置文件">5.2 修改配置文件</h3>
<p>改_config.yml</p>
<pre><code>search:  
  path: search.xml  
  field: post  
  format: html  
  limit: 10000  </code></pre>
<p>修改主题的配置文件_config.butterfly.yml：</p>
<pre><code>local_search:  
  enable: true  </code></pre>
<h2 id="显示外链图片">6 显示外链图片</h2>
<p>需要在生成网页的 head 中加：</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode html"><code class="sourceCode html"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;meta</span> <span class="er">name</span><span class="ot">=</span><span class="st">&quot;referrer&quot;</span> <span class="er">content</span><span class="ot">=</span><span class="st">&quot;no-referrer&quot;</span><span class="kw">/&gt;</span>  </span></code></pre></div>
<p>我使用 butterfly
主题，只需要在主题配置文件_config.butterfly.yml中修改：</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode yml"><code class="sourceCode yaml"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 插入代码到头部 &lt;/head&gt; 之前 和 底部 &lt;/body&gt; 之前  </span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">inject</span><span class="kw">:</span><span class="at">  </span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">head</span><span class="kw">:</span><span class="at">  </span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="at">    &lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;/&gt;  </span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">bottom</span><span class="kw">:</span><span class="at">  </span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co">    # - &lt;script src=&quot;xxxx&quot;&gt;&lt;/script&gt;  </span></span></code></pre></div>
<h2 id="内链跳转">7 内链跳转</h2>
<p>首先，让 hexo 生成的 html 目录结构与 markdown
存储的结构一致，在_config.yml中设置：</p>
<pre><code>permalink: :title/  </code></pre>
<p>详见：<a
href="https://www.cnblogs.com/baiqiantao/p/10538926.html#%E9%93%BE%E6%8E%A5-permalink">permalink写法</a><br />
然后写了程序，批量在 markdown 内链的位置把扩展名 .md
去掉，再把路前面加一个"/"变成绝对路径即可使用。</p>
<h2 id="添加字数和阅读时间统计">8 添加字数和阅读时间统计</h2>
<p>安装插件</p>
<pre><code>npm install hexo-symbols-count-time --save  </code></pre>
<p>修改_config.yml，添加：</p>
<pre><code>symbols_count_time:  
  symbols: true  
  time: true  
  total_symbols: true  
  total_time: true  </code></pre>
<p>修改_config.butterfly.yml，打开 enable：</p>
<pre><code>wordcount:  
  enable: true  </code></pre>
<ul>
<li>需要支持两个中括号的图片/链接</li>
</ul>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>构建个人博客_Obsidian_github</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%AC%94%E8%AE%B0%E5%B7%A5%E5%85%B7/hexo/%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2_Obsidian_github.io_hexo/</url>
    <content><![CDATA[<h2 id="初衷">1 初衷</h2>
<p>很早就开始分享文档，以技术类的为主，一开始是
MSN，博客，随着平台的更替，后来又用了 CSDN，知乎，简书…… 再后来是
Obsidian，飞书，Notion，常常有以下困扰：</p>
<h3 id="问题">1.1 问题</h3>
<ul>
<li>各平台格式不同，审核规则不同，需要花很多时间上传多个平台，文档更新成本也高。<br />
</li>
<li>分类太简单，搜索困难，不能满足要求。<br />
</li>
<li>虽然积累了一些积分和关注，但是平台更替，被黑，不可控。<br />
</li>
<li>想表达的东西很多：技术文，书评，旅行，画画，其它作品，日常感受；长文与短文，文献与田野的不同风格；每个平台调性，受众不同，全放一起，显得很不专业。</li>
</ul>
<h3 id="优势">1.2 优势</h3>
<p>这么看来，自建平台相对来说更自由，更方便：<br />
* 租个每年几百块钱的服务器，或者先用个免费平台。<br />
*
从内容到数据迁移更自由，可利用工具切换平台，减少时间成本，一键分享/更新。<br />
*
构造一种介于“给自己看”和“给别人看”之间的状态，打通公/私分享内容。<br />
* 在自己的 blog 和 其它内容之间建立深度链接。<br />
*
设计自己的逻辑，做自己喜欢的分类和屏蔽规则，让不同类型的内容互不干扰。</p>
<h3 id="劣势">1.3 劣势</h3>
<p>但也存在一些问题：<br />
* 学习成本：虽然入门成本不高，但想做到自己满意，需要花很多时间。<br />
*
内容过多：当文章上千，待分享的内容大几百的情况下，有很多类别时，Layout很难做得好看，会引入整理和设计的时间成本。<br />
*
让更多人看到：写在公共网站上，写得好会被推荐，平台的属性和分类也会吸引更多读者；而自己做的网站相对难推，且有的免费站被百度搜索屏蔽掉了，只能申请自己的域名。<br />
* 建站成本：除了买域名，还需要做网站公安备案，也是费时费力。</p>
<p>总之，选择自建平台/公共平台，主要视情况而定，不过艺不压身，多学点东西，有更多选择总是没错的。</p>
<h2 id="设计思路">2 设计思路</h2>
<h3 id="选平台">2.1 选平台</h3>
<p>最终的目标是可以省时省力，随时切换到各种服务器和平台。具体步骤如下：<br />
* 先找个免费的平台<br />
这里选用了 github.io，用法类似于 github
普通项目，可方便切换到任何历史版本。<br />
* 设计方便的切换方法<br />
为后期可方便地切换到一般的 Linux服务器，主要基于：Docker环境 + Python
后端工具 + JS 前端工具的架构。<br />
* Docker：便于切换平台；<br />
* Python：我对 Python 用着比较顺手，后面还可以加一些有意思的功能；<br />
* 前端：前端先期选用 Hexo，基于以下原因：<br />
* 既可以自己启动服务，也可以生成静态网页自动部署到已有的 Web
服务。<br />
* 无缝对接之前的 markdown 写作风格。<br />
* 插件多，且有很多网络 Theme 可选。</p>
<h3 id="打通私人笔记和分享笔记">2.2 打通私人笔记和分享笔记</h3>
<p>之前笔记写在 Obsidian中，主要使用 markdown
格式，只是文件头写得并不规范，导致转成 Html
后列表卡片显示不正常。这里使用简单的 Python
代码编辑所有文档的文件头。以保证文档正常显示。（非常简单，正在整理，后面会上传到
github 项目，或者做得更通用一些）</p>
<h3 id="降低分享成本">2.3 降低分享成本</h3>
<ul>
<li>设计分享规则<br />
将笔记分为：分享、不分享
两个类别；不分享的包含一些还没写完的文档，模板，测试，以及某些不足为外人道的内容。如果大部分都可以分享，hexo
自带排除功能。所以只要用目录区分就可以了。如果有更进一步的要求，则需要一些程序或插件实现。<br />
</li>
<li>快速部署到服务器<br />
Hexo支持部署功能，通过配置文件和一些简单脚本，即可实现：一键将 markdown
笔记分享/更新到博客。</li>
</ul>
<h3 id="设计展示">2.4 设计展示</h3>
<ul>
<li>Hexo 默认 Theme
将展示分为：按标签分类、按日期分类、最近的文章。先实现基本功能，后期再通过插件扩展。<br />
</li>
<li>选择喜欢的展示风格 Theme。</li>
</ul>
<p>总之，前期架构使用了 Docker + github.io + Hexo
的组合，成本低扩展性高，具体方法下面逐一介绍。</p>
<h2 id="github.io-建站">3 github.io 建站</h2>
<h3 id="建立仓库">3.1 建立仓库</h3>
<p>https://github.com/new</p>
<p><img src="/attachments_2023/Pasted%20image%2020230825215422.png"
alt="|300" /><br />
注意：repo name 需要填写：“用户名.github.io”
格式，只能使用你的用户名，也就是说每个 github 帐户只能建一个 github.io
的主页。</p>
<h3 id="创建静态网页">3.2 创建静态网页</h3>
<pre><code>$ git clone git@github.com:用户名/用户名.github.io.git  
$ cd 用户名.github.io.git  
$ echo &#39;hello world !!!&#39; &gt; index.html  
$ git add index.html  
$ git commit -m &#39;init&#39;  
$ git push origin master  </code></pre>
<p>提交后需要等一会儿，才能访问：https://用户名.github.io/，我大概等了两分钟。</p>
<h2 id="hexo-框架">4 Hexo 框架</h2>
<p>Hexo 是一个简单、快速、强大的博客发布工具，支持 Markdown
格式，有众多优秀插件和主题。我一般使用Markdown语法编写文章，通过 Hexo
命令行工具生成静态网页，并通过 Hexo 部署到网站。</p>
<h3 id="配置环境">4.1 配置环境</h3>
<p>安装 Hexo 之前先要安装 javascript 开发环境，因为怕麻烦，就直接使用了
Hexo 的 docker image 现成环境。具体版本用了轻量级且稳定的系统 alpine
版，整个镜像只有几十兆，其中还包含简单的 vi 编辑器。我的宿主机系统是
Ubuntu 22.04，具体操作如下：</p>
<pre><code>$ docker pull taskbjorn/hexo:alpine-latest  
$ sudo mkdir /exports/hexo_data -p # 数据存放在 docker 之外  
$ sudo chmod 777 /exports/hexo_data  
$ docker run -it --rm --name my_hexo_container --privileged=true -p 4000:4000 -v /exports/hexo_data:/home/hexo/.hexo taskbjorn/hexo:alpine-latest # 启动镜像  </code></pre>
<p>第一次运行时，数据安装到/home/hexo/.hexo目录，比较慢，再启就快了。<br />
正常启动后，使用 localhost:4000
即可在本机访问博客，生成新内容时自动更新，无需重启服务。</p>
<p>从另一个终端进入 docker container，以使用命令操作 Hexo：</p>
<pre><code>$ docker exec -it my_hexo_container sh  </code></pre>
<p>进入 docker 内部可以看到，当前用户为
hexo，在当前目录下已经建立好了项目文件。<br />
其中包安装在 node_modules 目录下，markdown 等源数据在 source
目录下，生成的文件在 public 目录下，主要配置文件是_config.yml。</p>
<h3 id="配置文件">4.2 配置文件</h3>
<p><code>_config.yml</code> 是最基本的配置文件，至少需要设置其 site
部分：</p>
<pre><code>title: &#39;标题&#39;  
subtitle: &#39;副标题&#39;  
description: &#39;网站描述&#39;  
author: 作者  
language: zh-Hans  
timezone: &#39;Asia/Shanghai&#39;  </code></pre>
<h3 id="基本操作">4.3 基本操作</h3>
<pre><code>$ hexo cl # hexo clean 清除缓存  
$ hexo g # hexo generate 生成静态网页  
$ hexo d # hexo deploy 部署  
$ hexo s # hexo server 启动服务预览，由于docker已经启动了服务，无需此操作  </code></pre>
<h3 id="markdown规范">4.4 Markdown规范</h3>
<p>通过 markdown
生成的网页，如果不设置文件头，则列表中只能显示文件创建日期：<br />
<img
src="/attachments_2023/Pasted%20image%2020230826093720.png" /><br />
因此，至少需要设置 title 才能正常显示，一般设置 title, author, date,
tags，Obsidian 的 hexo 模板如下：</p>
<pre><code>---  
title: &lt;% tp.file.title %&gt;  
author: xieyan0811  
date: &lt;% tp.file.creation_date() %&gt;  
updated: &lt;% tp.file.last_modified_date() %&gt;  
tags:  
---  </code></pre>
<h3 id="部署博客到-github.io">4.5 部署博客到 github.io</h3>
<h4 id="配置-github-免密环境">4.5.1 配置 github 免密环境</h4>
<pre><code>$ git config --global user.email 你的邮箱  
$ git config --global user.name 你的用户名  
$ ssh-keygen -t rsa -C 你的邮箱 # 一路回车  </code></pre>
<p>如果提示找不到 ssh-keygen，可能是 docker
环境中未安装该软件，由于安装的是 alpine 环境，需要用 root
权限登入，才能安装软件（建议另起一终端操作）：</p>
<pre><code>$ docker exec -u=root -it my_hexo_container sh # 以root方式登入  
# apk add openssh # 安装 openssh 工具集  </code></pre>
<p>将 /home/hexo/.ssh/id_rsa.pub 内容加入 github，具体方法是：<br />
https://github.com/settings/keys add ssh key</p>
<p>设置好后，查看能否正常使用：</p>
<pre><code>$ ssh git@github.com  # 正常结果形如: You&#39;ve successfully authenticated  </code></pre>
<p>为保留 docker 中的内容，建议设置后 commit 一下：</p>
<pre><code>docker commit my_hexo_container taskbjorn/hexo:alpine-mine_230828  </code></pre>
<h4 id="配置文件-1">4.5.2 配置文件</h4>
<p>修改配置文件_config.yml，设置部署服务</p>
<pre><code>deploy:  
  type: &#39;git&#39;  
  repo: git@github.com:用户名/用户名.github.io # 注意这里不是http地址   
  branch: master  </code></pre>
<h4 id="部署">4.5.3 部署</h4>
<pre><code>$ npm install hexo-deployer-git # 安装 hexo 的 git 插件  
$ hexo g # 生成静态网页  
$ hexo d # 部署到 github.io   </code></pre>
<p>正常执行后，可以看到 public 目录内容被更新到 github.io
主页，内容也不多，只有 demo 时不到1M。</p>
<h3 id="显示图片">4.6 显示图片</h3>
<p>Hexo
支持多种显示图片的方法，比如图床，上传图片等，这里介绍最简单的方法：</p>
<h4 id="安装插件">4.6.1 安装插件</h4>
<pre><code>$ npm install hexo-asset-image  
$ npm install hexo-renderer-marked  </code></pre>
<h4 id="配置文件-2">4.6.2 配置文件</h4>
<p>保持_config.yml配置文件 中 post_asset_folder: false 不变，加入 marked
设置：</p>
<pre><code>post_asset_folder: false  
marked:  
  prependRoot: true  
  postAsset: true  </code></pre>
<ul>
<li>我在 Obsidian 中的图片都放在 attachments/ 目录下，将此目录复制到
Hexo 项目的 source 目录中，即：source/attachments/xx.png<br />
</li>
<li>hexo g 重新生成后，图片正常显示<br />
</li>
<li>注意图片较少时，建议使用该方法，图片很多时，github项目也变得很“重”，建议使用图床。</li>
</ul>
<h3 id="更换主题">4.7 更换主题</h3>
<p>建议设置一个常用的主题，比如next，遇到问题也好查资料。<br />
官网主题见：https://hexo.io/themes/</p>
<ul>
<li>安装主题<br />
</li>
</ul>
<pre><code>npm install hexo-theme-next # 安装在node_modules/ 目录下  
cp node_modules/hexo-theme-next/_config.yml _config.next.yml # 复制主题配置文件  </code></pre>
<ul>
<li>修改配置：在_config.yml中， 修改：theme: next<br />
</li>
<li>重新生成后，即可看到新主题</li>
</ul>
<h3 id="调试">4.8 调试</h3>
<ul>
<li>查看软件版本<br />
</li>
</ul>
<pre><code>hexo -v  </code></pre>
<ul>
<li>查看详细 debug 信息<br />
</li>
</ul>
<pre><code>hexo g --debug # 加 --debug 参数  </code></pre>
<ul>
<li>忽略一些文章<br />
修改_config.yml，修改后注意先清缓存再生成，否则设置可能不生效。<br />
</li>
</ul>
<pre><code>skip_render: [&#39;in_progress/**/*&#39;]  </code></pre>
<h2 id="参考">5 参考</h2>
<p><a
href="https://blog.esunr.xyz/2022/07/e9b42b453d9f.html#1-%E5%89%8D%E8%A8%80">Hexo
+ Obsidian + Git 完美的博客部署与编辑方案</a><br />
<a href="https://zhuanlan.zhihu.com/p/514982831">搭建个人博客 —
Hexo+Markdown+Github Pages</a><br />
<a
href="https://www.cnblogs.com/lfri/p/12219608.html">如何让Hexo不渲染某些文件</a><br />
<a
href="https://www.cnblogs.com/mlzrq/p/16099460.html">hexo相对路径图片显示</a><br />
<a
href="https://www.cnblogs.com/bzsheng/p/13802829.html">hexo博客如何插入图片</a><br />
<a href="https://www.ngui.cc/el/1611711.html?action=onClick">搭建自己的
github.io 博客</a><br />
<a
href="https://blog.csdn.net/wangsidadehao/article/details/78540724">在github.io上写博客</a></p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>前端</tag>
        <tag>笔记</tag>
        <tag>Obsidian</tag>
      </tags>
  </entry>
  <entry>
    <title>markdown_LaTeX</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%AC%94%E8%AE%B0%E5%B7%A5%E5%85%B7/markdown/markdown_LaTeX/</url>
    <content><![CDATA[<p>#工具/笔记/Obsidian</p>
<h2 id="希腊字母">1 希腊字母</h2>
<table>
<thead>
<tr class="header">
<th>字母</th>
<th>LaTex</th>
<th>字母</th>
<th>LaTex</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\alpha\)</span></td>
<td></td>
<td><span class="math inline">\(\xi\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\beta\)</span></td>
<td></td>
<td><span class="math inline">\(\pi\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\gamma\)</span></td>
<td></td>
<td><span class="math inline">\(\rho\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\delta\)</span></td>
<td></td>
<td><span class="math inline">\(\sigma\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\epsilon\)</span></td>
<td></td>
<td><span class="math inline">\(\tau\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\zeta\)</span></td>
<td></td>
<td><span class="math inline">\(\upsilon\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\eta\)</span></td>
<td></td>
<td><span class="math inline">\(\phi\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\theta\)</span></td>
<td></td>
<td><span class="math inline">\(\chi\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\iota\)</span></td>
<td></td>
<td><span class="math inline">\(\psi\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\kappa\)</span></td>
<td></td>
<td><span class="math inline">\(\omega\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\lambda\)</span></td>
<td></td>
<td><span class="math inline">\(\nu\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mu\)</span></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\Gamma\)</span></td>
<td></td>
<td><span class="math inline">\(\Sigma\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\Delta\)</span></td>
<td></td>
<td><span class="math inline">\(\Upsilon\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\Theta\)</span></td>
<td></td>
<td><span class="math inline">\(\Phi\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\Lambda\)</span></td>
<td></td>
<td><span class="math inline">\(\Psi\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\Xi\)</span></td>
<td></td>
<td><span class="math inline">\(\Omega\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\Pi\)</span></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="常用符号">2 常用符号</h2>
<h3 id="关系表达式">2.1 关系表达式</h3>
<table>
<thead>
<tr class="header">
<th>符号</th>
<th>LaTex</th>
<th>符号</th>
<th>LaTex</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\notin\)</span></td>
<td></td>
<td><span class="math inline">\(\ne\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\in\)</span></td>
<td></td>
<td><span class="math inline">\(\approx\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\sim\)</span></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\le\)</span></td>
<td></td>
<td><span class="math inline">\(\ge\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\subset\)</span></td>
<td></td>
<td><span class="math inline">\(\supset\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\subseteq\)</span></td>
<td></td>
<td><span class="math inline">\(\supseteq\)</span></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="运算符">2.2 运算符</h3>
<table>
<thead>
<tr class="header">
<th>符号</th>
<th>LaTex</th>
<th>符号</th>
<th>LaTex</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\cdot\)</span></td>
<td></td>
<td><span class="math inline">\(\div\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\times\)</span></td>
<td></td>
<td><span class="math inline">\(\setminus\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\cup\)</span></td>
<td></td>
<td><span class="math inline">\(\cap\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\vee\)</span></td>
<td></td>
<td><span class="math inline">\(\wedge\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\oplus\)</span></td>
<td></td>
<td><span class="math inline">\(\ominus\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\odot\)</span></td>
<td></td>
<td><span class="math inline">\(\pm\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\star\)</span></td>
<td></td>
<td><span class="math inline">\(\bullet\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\ast\)</span></td>
<td></td>
<td><span class="math inline">\(\diamond\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\circ\)</span></td>
<td></td>
<td><span class="math inline">\(\to\)</span></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="空格">2.3 空格</h3>
<table>
<thead>
<tr class="header">
<th>方法</th>
<th>LaTex</th>
<th>效果</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>两个quad空格</td>
<td>a b</td>
<td><span class="math inline">\(a \qquad b\)</span></td>
</tr>
<tr class="even">
<td>quad空格</td>
<td>a b</td>
<td><span class="math inline">\(a \quad b\)</span></td>
</tr>
<tr class="odd">
<td>大空格</td>
<td>a b</td>
<td><span class="math inline">\(a\ b\)</span></td>
</tr>
<tr class="even">
<td>中空格</td>
<td>a;b</td>
<td><span class="math inline">\(a\;b\)</span></td>
</tr>
<tr class="odd">
<td>小空格</td>
<td>a,b</td>
<td><span class="math inline">\(a\,b\)</span></td>
</tr>
<tr class="even">
<td>紧贴</td>
<td>a!b</td>
<td><span class="math inline">\(a\!b\)</span></td>
</tr>
</tbody>
</table>
<h3 id="其它符号">2.4 其它符号</h3>
<table>
<colgroup>
<col style="width: 35%" />
<col style="width: 30%" />
<col style="width: 19%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr class="header">
<th>符号</th>
<th>LaTex</th>
<th>符号</th>
<th>LaTex</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\hat{a}\)</span></td>
<td></td>
<td><span class="math inline">\(\infty\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\overline{a}\)</span></td>
<td></td>
<td><span class="math inline">\(\propto\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\widetilde{a}\)</span></td>
<td></td>
<td><span class="math inline">\(\intercal\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\vec{a}\)</span></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="常用格式">3 常用格式</h2>
<table>
<thead>
<tr class="header">
<th>方法</th>
<th>LaTex</th>
<th>效果</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>上标</td>
<td>{abc}^{2}</td>
<td><span class="math inline">\({abc}^{2}\)</span></td>
</tr>
<tr class="even">
<td>下标</td>
<td>{abc}_1</td>
<td><span class="math inline">\({abc}_1\)</span></td>
</tr>
<tr class="odd">
<td>分数</td>
<td></td>
<td><span class="math inline">\(\frac{x}{y}\)</span></td>
</tr>
<tr class="even">
<td>开根号</td>
<td>[y]{x}</td>
<td><span class="math inline">\(\sqrt[y]{x}\)</span></td>
</tr>
<tr class="odd">
<td>省略号1</td>
<td></td>
<td><span class="math inline">\(\ldots\)</span></td>
</tr>
<tr class="even">
<td>省略号2</td>
<td></td>
<td><span class="math inline">\(\cdots\)</span></td>
</tr>
<tr class="odd">
<td>偏导</td>
<td></td>
<td><span class="math inline">\(\partial\)</span></td>
</tr>
<tr class="even">
<td>组合</td>
<td>{zn }</td>
<td><span class="math inline">\({n \choose 2}\)</span></td>
</tr>
</tbody>
</table>
<h2 id="复杂格式">4 复杂格式</h2>
<h3 id="求和">4.1 求和</h3>
<pre><code>$$\sum_&#123;k=1&#125;^nk$$  </code></pre>
<p><span class="math display">\[\sum_{k=1}^nk\]</span></p>
<h3 id="连乘">4.2 连乘</h3>
<pre><code>$$\prod_&#123;k=1&#125;^nk$$  </code></pre>
<p><span class="math display">\[\prod_{k=1}^nk\]</span></p>
<h3 id="积分">4.3 积分</h3>
<pre><code>$$\int_0^&#123;+\infty&#125;x$$  </code></pre>
<p><span class="math display">\[\int_0^{+\infty}x\]</span></p>
<h3 id="极限">4.4 极限</h3>
<pre><code>$$\lim_&#123;x \to 0&#125;$$  </code></pre>
<p><span class="math display">\[\lim_{x \to 0}\]</span></p>
<h2 id="多行">5 多行</h2>
<p>begin/end/双斜线换行</p>
<h3 id="对齐">5.1 对齐</h3>
<pre><code>$$  
\begin&#123;align&#125;   
    a &amp; = b + c    
    \ \\  
    &amp; = d + e    
\end&#123;align&#125;  
$$  </code></pre>
<p><span class="math display">\[  
\begin{align}   
    a &amp; = b + c    
    \ \\  
    &amp; = d + e    
\end{align}  
\]</span></p>
<h3 id="矩阵和行列式">5.2 矩阵和行列式</h3>
<pre><code>$$  
A=\left[ \begin&#123;matrix&#125;  
   a &amp; b   \\  
   c &amp; d   \\  
\end&#123;matrix&#125; \right]  
$$  </code></pre>
<p><span class="math display">\[  
A=\left[ \begin{matrix}  
   a &amp; b   \\  
   c &amp; d   \\  
\end{matrix} \right]  
\]</span></p>
<h3 id="左对齐">5.3 左对齐</h3>
<p>使用aligned实现对齐，使用&amp;符号设定对齐位置</p>
<pre><code>$$ \begin&#123;aligned&#125;  
&amp; y_2 = 2x^2-1 \\  
&amp; y_3 = 4x^3-3x \\  
&amp; ... \\  
&amp; y_n = 2x*y_&#123;n-1&#125;-y_&#123;n-2&#125;  
\end&#123;aligned&#125;  
$$  </code></pre>
<p><span class="math display">\[ \begin{aligned}  
&amp; y_2 = 2x^2-1 \\  
&amp; y_3 = 4x^3-3x \\  
&amp; ... \\  
&amp; y_n = 2x*y_{n-1}-y_{n-2}  
\end{aligned}  
\]</span></p>
<h2 id="参考">6 参考</h2>
<p><a
href="https://banxian-w.com/article/2021/9/12/1891.html">王半仙笔记:LaTex快速入门</a><br />
<a
href="https://jingyan.baidu.com/article/4b52d702df537efc5c774bc9.html">Latex常用数学符号输入方法</a><br />
<a
href="https://github.com/raineszm/obsidian-latex-environments/">插件github地址</a></p>
]]></content>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>markdown_页面中跳转</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%AC%94%E8%AE%B0%E5%B7%A5%E5%85%B7/markdown/markdown_%E9%A1%B5%E9%9D%A2%E4%B8%AD%E8%B7%B3%E8%BD%AC/</url>
    <content><![CDATA[<p>#工具/笔记/markdown</p>
<h2 id="标题跳转">1 标题跳转</h2>
<h3 id="页内跳转">1.1 页内跳转</h3>
<pre><code>[[#本页标题名]]  </code></pre>
<h3 id="页间跳转">1.2 页间跳转</h3>
<pre><code>[[文档名#标题名]]  </code></pre>
<h3 id="跳转时显示特定文本">1.3 跳转时显示特定文本</h3>
<pre><code>[显示的内容](#标题标号-标题文本)  </code></pre>
<h3 id="注意">1.4 注意</h3>
<p><code>()</code>小括号内部声明跳转目标标题，以<code>#</code>开头(无论几级标题，都只要一个井号)，标题题号如果包含<code>.、</code>下划线直接忽略掉，标题文本中如果有空格，使用<code>-</code>横杠符号替代，标题文本中的大写字母转换成小写。</p>
<h2 id="块跳转">2 块跳转</h2>
<p>Obsidian支持块跳转功能，Help中有详细说明，简要概括如下：</p>
<p>使用^号定义块</p>
<pre><code>正文 ^dcf64c  </code></pre>
<p>跳转</p>
<pre><code> [[#^dcf64c]]   </code></pre>
<p>在文档中嵌入块内容</p>
<pre><code>![[#^dcf64c]]  </code></pre>
<p>形如:<br />
<img src="/attachments_2022/Pasted%20image%2020220102231907.png"
alt="Pasted%20image%2020220102231907.png" /></p>
<h2 id="脚注">3 脚注</h2>
<p>调用脚注写法：</p>
<pre><code>点击跳到脚注 [^aa]  </code></pre>
<p>脚注本身写法：</p>
<pre><code>[^aa]:我是脚注本身（点击右测可返回调用处）  </code></pre>
<h2 id="参考">4 参考</h2>
<p><a href="https://blog.csdn.net/yingaizhu/article/details/82458437">#
Markdown实用语法之实现页面内跳转</a></p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>笔记</tag>
        <tag>Obsidian</tag>
      </tags>
  </entry>
  <entry>
    <title>文献工具_Zotero</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E7%AC%94%E8%AE%B0%E5%B7%A5%E5%85%B7/zotero/%E6%96%87%E7%8C%AE%E5%B7%A5%E5%85%B7_Zotero/</url>
    <content><![CDATA[<p>之前一直用在线的readpaper看论文，可是文献一多，就觉得分类功能比较弱，也不太好找，另外没办法做整篇笔记，也不能和笔记工具连起来，有点难受。<br />
昨天同事推荐了Zotero和Endnote，看了几篇文章都说Zotero比Endnote好用，另外，它还能导出Obsidian
Note，在O和Z之间互相跳转，以及和Chrome结合。</p>
<h2 id="简介">1 简介</h2>
<p>Zotero用于收集、组织、引用、分享各类资料，支持网页版，注册账号之后在多端自动同步以及使用浏览器插件。</p>
<h2 id="用后感">2 用后感</h2>
<p>安上后发现除了论文还支持书籍文献等等功能。感觉Zotero覆盖了之前使用软件的所有功能，软件版本也更稳定，翻译也很流畅。</p>
<h2 id="安装linux版本">3 安装Linux版本</h2>
<h3 id="下载">3.1 下载</h3>
<p>https://www.zotero.org/</p>
<h3 id="安装">3.2 安装</h3>
<pre class="shell"><code>tar xvjf Zotero-6.0.19_linux-x86_64.tar.bz2  
mv Zotero_linux-x86_64/ /opt/  
cd /opt/Zotero_linux-x86_64/  
chmod 777 zotero  
chmod 777 zotero-bin  
sudo ./set_launcher_icon  
./zotero # 运行  
将zotero.desktop中的Exec改为：/opt/Zotero_linux-x86_64/zotero  
cp zotero.desktop /用户目录/桌面/  
即可以桌面上点击使用  </code></pre>
<h2 id="安装浏览器扩展">4 安装浏览器扩展</h2>
<p>https://www.zotero.org/download/connectors<br />
与浏览器Chrome结合，直接安装插件需要科学上网</p>
<h2 id="导入文章">5 导入文章</h2>
<ul>
<li>点上界面上方“通过标识符添加条目”，然后输入论文的DOI，找到后在文件上点右键选"查找可用的PDF"<br />
</li>
<li>把下载好的PDF从文件管理器里拖到Zotero中即可完成本地文件导入</li>
</ul>
<h2 id="安装翻译插件">6 安装翻译插件</h2>
<ul>
<li>在github搜：zotero translate，点开推荐最高的 zotero pdf
translate，我下了最新版本的 release, xpi文件<br />
</li>
<li>在zotero界面中点：菜单-&gt;工具-&gt;添加组件-&gt;Setting图标-&gt;Install
Add-on from file，然后选择xpi文件<br />
</li>
<li>按提示重启后，选中文字后自动出翻译<br />
</li>
<li>打开右侧边栏可对翻译进行设置</li>
</ul>
<h2 id="常用插件">7 常用插件</h2>
<ul>
<li>Zotero PDF Translate 翻译软件<br />
</li>
<li>Sci-Hub Plugin for Zetero 从sci-hub下载<br />
</li>
<li>zotero-better-bibtex 导出bib格式<br />
</li>
<li>zotero-markdb-connect 与obsidian联动<br />
[[1_Note/0_工具/笔记工具/Obsidian/打通Obsidian和Zotero]]<br />
</li>
<li>zotero reference 显示文献引用的详情</li>
</ul>
<h2 id="设置字体大小">8 设置字体大小</h2>
<ul>
<li>菜单-&gt;编辑-&gt;首选项-&gt;高级-&gt;编辑器<br />
</li>
<li>搜索 fontSize 相关选项并调整（主要调整右测面板和翻译字体大小）</li>
</ul>
<h2 id="显示中文标题">9 显示中文标题</h2>
<ul>
<li>选一篇或多篇文章-&gt;右键-&gt;标题翻译<br />
</li>
<li>在列面上方键-&gt;勾选标题翻译</li>
</ul>
<h2 id="参考">10 参考</h2>
<p><a
href="https://baijiahao.baidu.com/s?id=1746343170787887758&amp;wfr=spider&amp;for=pc">傻瓜式操作｜Zotero与Obsidian自动双链笔记设置及Onedrive同步</a><br />
<a
href="https://www.yangzhiping.com/tech/zotero5.html">Zotero（5）：电子文献管理攻略</a><br />
也推荐 Zotero(1-4)，文中有链接。</p>
]]></content>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>查找论文</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E8%AE%BA%E6%96%87/0_%E6%96%B9%E6%B3%95/%E6%9F%A5%E6%89%BE%E8%AE%BA%E6%96%87/</url>
    <content><![CDATA[<p>#论文阅读 #工具</p>
<h2 id="sci是什么">SCI是什么</h2>
<p>美国《科学引文索引》（Science Citation Index, 简称 SCI
）是由美国科学信息研究所1961
年创办出版的引文数据库。相对于EI工程索引，SCI要求论文更规范，系统，完整，创新性更高。</p>
<h2 id="论文分区">论文分区</h2>
<p>SCI有两个分区规则：JCR分区和中科院分区。
JCR分区根据某一学科的所有期刊都按照上一年的影响因子降序排列，然后平均4等分(各25%)，分别是Q1，Q2，Q3，Q4。
中科院分区按各类期刊三年平均影响因子排序，前5%为一区（国际顶级期刊），前20%为二区，前50%为三区，剩下的为四区。</p>
<h2 id="影响因子">影响因子</h2>
<p>SCI期刊的影响因子IF（Impact
Factor）值是衡量期刊水平的标准，它的计算方法为：前两年文章引用数/前两年文章收录数（一般IF＞1表示引用率较高）。最低分值是0~1分，高的到几十分。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-c5e86013d091af8b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>用以下方法查看影响因子：</p>
<ul>
<li><p>打开<a
href="http://www.letpub.com.cn/">http://www.letpub.com.cn/</a></p></li>
<li><p>点击SCI IF（影响因子）查询</p></li>
<li><p>输入期刊名搜索（也可以按分类查找）
如：输入JAMA，列出了JAMA的多个子刊，从列表中可以看到中科院分区</p></li>
</ul>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-0686dc91a88b8b06.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>点击查看IF可看到其具体分值，根据每年的影响力，其分值也会做相应调整，网站还提供一些同类著名期刊的推荐，审稿周期，录用比例等等。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-e06a37d614199970.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="论文查询">论文查询</h2>
<p>除了一些非常著名的论文，有时候查找相关领域知识，希望读到一些技术含量更高的论文。除了论文出处，还需查看它被引用的次数和更多细节。国内可以通过访问谷歌学术的镜像网站查找论文。比如：<br />
<a href="https://ac.scmor.com/">https://ac.scmor.com/</a><br />
<a
href="https://xueshu.lanfanshu.cn/">https://xueshu.lanfanshu.cn/</a></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-268df8c4230c267d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="arxiv">arXiv</h2>
<p>为了防止自己的idea在论文被收录前被别人剽窃，作者常将预稿上传到arvix作为预收录，用于证明论文原创性（上传时间戳）的文档收录网站。网站收集了物理学、数学、计算机科学与生物学论文预印本。
一般计算机科学类的论文在这里都能找到原文。推荐查找arxiv论文的工具：http://www.arxiv-sanity.com/,
查找关键字相关的论文，并按时间远近排序，列表中显示了简介。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-9f8a718aa204afff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>show similar可查找与之类似的论文。</p>
<h2 id="web-of-science">Web of Science</h2>
<p>Web of Science数据库是国际公认的反映科学研究水准的数据库。<br />
https://www.webofscience.com/wos/woscc/basic-search<br />
用法详见：<br />
https://zhuanlan.zhihu.com/p/414252078?utm_id=0</p>
<h2 id="医学顶级期刊介绍">医学顶级期刊介绍</h2>
<p><a
href="http://www.sci666.com.cn/57704.html">http://www.sci666.com.cn/57704.html</a></p>
<p><a
href="https://blog.csdn.net/ivy_reny/article/details/54844841">计算机顶级会议和期刊影响因子介绍</a></p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>论文检索</title>
    <url>/1_Note/0_%E5%B7%A5%E5%85%B7/%E8%AE%BA%E6%96%87/0_%E6%96%B9%E6%B3%95/%E8%AE%BA%E6%96%87%E6%A3%80%E7%B4%A2/</url>
    <content><![CDATA[<h1 id="论文检索">论文检索</h1>
<p>#工具 #论文阅读</p>
<p>科学文献数据库：http://arxiv.org</p>
<p>查找arxiv上论文的工具： <a
href="http://www.arxiv-sanity.com/">http://www.arxiv-sanity.com/</a><br />
,
可查找关键字相关的论文，并按时间远近排序，列表中也显示了introduce。</p>
<p><img
src="https://img-blog.csdnimg.cn/20200323101240784.png?x-oss-%20process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpZXlhbjA4MTE=,size_16,color_FFFFFF,t_70" /></p>
<p>show similar可查找与之类似的论文（内部使用tf/idf方法实现）</p>
]]></content>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_BERT知识蒸馏</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/11_%E4%BC%98%E5%8C%96/%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_BERT%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/</url>
    <content><![CDATA[<p>英文题目：Distilling Task-Specific Knowledge from BERT into Simple
Neural Networks<br />
中文题目：从BERT中蒸馏指定任务知识到简单网络<br />
论文地址：https://arxiv.org/pdf/1903.12136.pdf<br />
领域：自然语言，深度学习<br />
发表时间：2019<br />
作者：Raphael Tang, 滑铁卢大学<br />
被引量：226<br />
代码和数据：https://github.com/qiangsiwei/bert_distill<br />
阅读时间：2022.09.11</p>
<h2 id="读后感">读后感</h2>
<p>第一次对大型自然语言模型的蒸馏：将BERT模型蒸馏成BiLSTM模型。</p>
<h2 id="介绍">介绍</h2>
<p>在自然语言处理方面，随着BERT,GPT等大规模预训练模型的发展，浅层的深度学习模型似乎已经过时了。但由于资源的限制，又需要使用小而快的模型。</p>
<p>文章的动机是讨论：<strong>浅层模型是否真的不具备对文本的表示能力</strong>？并展示了针对于具体的任务，将BERT蒸馏成单层BiLSTM模型的方法和效果。也通过大模型（起初训练的复杂的模型，后称Teacher/T）和小模型（蒸馏后的模型，后称Student/S）完全不同的模型结构展示了蒸馏与模型结构无关。另外，<strong>之前蒸馏模型主要应用于图片建模</strong>
，论文讨论了它在自然语言领域的使用方法。</p>
<h2 id="方法">方法</h2>
<p>核心方法包含两部分：增加了logit回归目标；重建蒸馏训练数据集使训练更为有效。</p>
<h3 id="模型结构">模型结构</h3>
<p>将BERT作为教师模型，使用单层的 BiLSTM
作为学习模型的非线性分类器，针对每一种<strong>下游任务使用不同模型</strong>。如图-1是对单句分类任务设计的学生模型。<br />
<img src="/attachments_2022/Pasted%20image%2020220912140516.png"
alt="Pasted%20image%2020220912140516.png" /><br />
图-2展示了用于预测句子匹配度的模型，它们的编码层共享同一BiLSTM模型。<br />
<img src="/attachments_2022/Pasted%20image%2020220912140643.png"
alt="Pasted%20image%2020220912140643.png" /><br />
为了更好地对比效果，在学生模型中，未使用注意力归一化等更多技巧。</p>
<h3 id="蒸馏目标">蒸馏目标</h3>
<p>学生模型的目标是在所有数据上，模拟老师模型的行为。除了最终的标签，老师模型预测出的概率也很重要
。比如在情绪分类问题中，一些实例有很强的正面情绪，有一些情绪可能比较中性，所以除了是否，也需要预测程度。</p>
<p>一般预测标签的方法是：<br />
<img src="/attachments_2022/Pasted%20image%2020220912141318.png"
alt="Pasted%20image%2020220912141318.png" /><br />
文中使用了logit的优化方法，构造了蒸馏目标：用MSE来惩罚师生模型间的差异：<br />
<img src="/attachments_2022/Pasted%20image%2020220912141655.png"
alt="Pasted%20image%2020220912141655.png" /><br />
其中z(B)指的是老师模型BERT，z(S)指学生模型，在初步实验中，MSE比软目标效果更好。</p>
<p>在实际训练时，也使用了传统的交叉熵（对真正目标的预测）和蒸馏损失相结合的方式，最终损失函数如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220912142437.png"
alt="Pasted%20image%2020220912142437.png" /><br />
当使用有标签数据训练时，t是实例的标签；使用无标签数据训练时，使用老师模型打标签。</p>
<h3 id="蒸馏的数据增强">蒸馏的数据增强</h3>
<p>在蒸馏过程中，使用小的数据集不足以让老师模型展示出其所有知识，因此，使用了无标签数据扩充训练数据集，用老师模型对其打标签。</p>
<p><strong>增强NLP数据比增强图像数据难度大</strong>，没办法使用扭曲等方法，做出的句子可能不够流畅。文中提出了几种数据增强方法：<br />
* 遮蔽：使用类似BERT的方法，这种方法能反应句中每个词对标签的贡献。<br />
*
基于词性的词替换：在词袋里找同一词性的词作替换，以保持原始数据的分布。<br />
* n-gram采样：根据概率，随机采样n个连续的词，它是遮蔽方法的增强版。</p>
<h2 id="实验">实验</h2>
<p>使用的是BERT_LARGE作为老师模型，针对特定任务精调，预测时获取预测的logit值，学生模型使用300维的word2vec作为词嵌入。主实验效果如表-1所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220912144737.png"
alt="Pasted%20image%2020220912144737.png" /><br />
可以看到同样是使用BiLSTM方法，文中方法相较于其它方法有显著提升。</p>
<p>从表-2可以看到预测速度也有很大提升：<br />
<img src="/attachments_2022/Pasted%20image%2020220912144810.png"
alt="Pasted%20image%2020220912144810.png" /></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>知识蒸馏</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_中文医疗模型_ eHealth</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/11_%E4%BC%98%E5%8C%96/%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E4%B8%AD%E6%96%87NLP%E7%B2%BE%E5%87%8F%E6%A8%A1%E5%9E%8BELECTRA/</url>
    <content><![CDATA[<ul>
<li>介绍：ELECTRA由Manning联合谷歌发布，后来哈工大讯飞联合实验室训练了相应的中文模型。精减后的模型效果和BERT差不太多，而模型大小只有BERT的1/10，ELECTRA-small
只有46M。<br />
</li>
<li>代码&amp;模型下载&amp;详细说明：https://github.com/ymcui/Chinese-ELECTRA<br />
</li>
<li>使用：LTP使用它为基础模型。<br />
</li>
<li>原理：使用生成对抗网络训练自然语言模型，时间短，参数少。模型分为两部分：生成器和判别器，生成实现MLM，判别器用于识别每一个单词是否为模型生成。<br />
</li>
<li>效果：以中文阅读理解为例，其效果对比如下，其它实验详见github<br />
<img src="/attachments_2022/Pasted%20image%2020220620181324.png"
alt="Pasted%20image%2020220620181324.png" /></li>
</ul>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_模型蒸馏_TinyBERT</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/11_%E4%BC%98%E5%8C%96/%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F_TinyBERT/</url>
    <content><![CDATA[<p>英文题目：TINYBERT: DISTILLING BERT FOR NATURAL LAN-GUAGE
UNDERSTANDING<br />
中文题目：TinyBERT: 提炼BERT的自然语言理解能力<br />
论文地址：https://arxiv.org/pdf/1909.10351.pdf<br />
领域：NLP，知识蒸馏<br />
发表时间：2020<br />
作者：Xiaoqi Jiao, 华中科技大学<br />
出处：ICLR<br />
被引量：67<br />
代码和数据：<br />
*
https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/TinyBERT<br />
* https://github.com/Lisennlp/TinyBert<br />
* https://github.com/qiangsiwei/bert_distill （数据是中文的）<br />
阅读时间：22.09.16</p>
<h2 id="读后感">读后感</h2>
<p>对BERT模型进行蒸馏，老师模型和学生模型都使用<strong>Transformer</strong>架构，但是层数和每层的输出维度可以不同，从而实现对模型的精减。</p>
<h2 id="介绍">介绍</h2>
<p>预训练的大模型难以应用到资源受限的系统中，文中提出针对Transformer模型的蒸馏方法，将BERT模型作为老师模型，将知识蒸馏到学生模型TinyBERT中。同时在预训练和精调的场景中进行蒸馏，它可以达到其老师模型96%的准确率，比老师模型小7.5倍
，快9.4倍。</p>
<p>实现的具体方法是根据BERT层设计了多种损失函数。与现有模型的差异如表-1所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220916162634.png"
alt="Pasted%20image%2020220916162634.png" /></p>
<p><strong>文章贡献</strong><br />
* 优化了基于Transformer框架的蒸馏方法<br />
* 支持预训练和精调两个场景的蒸馏<br />
* 实验证明TinyBERT的效果</p>
<h2 id="方法">方法</h2>
<h3 id="蒸馏">蒸馏</h3>
<p>蒸馏方法的如公式-5所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220916164508.png"
alt="Pasted%20image%2020220916164508.png" /><br />
将fs定义为学生模型，将ft定义为老师模型，把实例代入模型，计算预测结果，L()为损失函数，评价师生的差异，目标是尽量让老师与学生结果一致。</p>
<h3 id="transformer蒸馏">Transformer蒸馏</h3>
<p>蒸馏方法允许老师和学生是完全不同的模型，TinyBERT设计过程中将老师和学生模型都设计使用Transformer结构。</p>
<h4 id="符号定义">符号定义</h4>
<p>设学生模型有M个Transformer层，老师模型有N个Transformer层，在二者之间建立一个映射函数
n=g(m)，学生的第m层从老师的第g(m)层学习。将嵌入层定义为第0层，预测层定义为M+1层。根据经验选择g()映射函数。其整体损失函数定义如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220916165607.png"
alt="Pasted%20image%2020220916165607.png" /></p>
<p>公式-6与公式-5类似，它针对学习的m个层优化，λm为超参数，指定每层的重要程度。</p>
<h4 id="transformer层蒸馏">Transformer层蒸馏</h4>
<p>Transformer层蒸馏包含对注意力的蒸馏和对隐藏状态的蒸馏，如图-2所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220916211804.png"
alt="Pasted%20image%2020220916211804.png" /><br />
注意力层的蒸馏致力于学习BERT捕捉的丰富语言学知识，学生模型首先拟合老师模型的多头注意力，损失函数如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220916212121.png"
alt="Pasted%20image%2020220916212121.png" /><br />
其中h是头数，A为注意力矩阵，MSE为均方误差损失。这里直接使用Attention，而未使用归一化的softmax，是由于实验证明直接使用效果更好。</p>
<p>除了Attention，还对transformer层的输出进行了拟合：<br />
<img src="/attachments_2022/Pasted%20image%2020220916212451.png"
alt="Pasted%20image%2020220916212451.png" /><br />
这里的HS和HT分别是学生和老师模型的隐藏层，学生模型隐藏层的维度往往小于老师层的维度，使用W参数在两个维度间进行转换。</p>
<h4 id="嵌入层蒸馏">嵌入层蒸馏</h4>
<p>嵌入层的蒸馏与上述隐藏层处理方法类似，也可使用不同维度，通过W进行映射，本文中使用了相同维度。<br />
<img src="/attachments_2022/Pasted%20image%2020220916212925.png"
alt="Pasted%20image%2020220916212925.png" /></p>
<h4 id="预测层蒸馏">预测层蒸馏</h4>
<p>另外，还对最后一层的预测层进行了蒸馏，具体使用了软的交叉熵作为损失函数，这是为了从老师模型中除了最终结果类别，还能学到每一个类别的匹配度。<br />
<img src="/attachments_2022/Pasted%20image%2020220916213402.png"
alt="Pasted%20image%2020220916213402.png" /><br />
其中zS和zT分别对学生和老师预测的向量进行指数运算，t是温度系数，本文实验中t=1时表现最好。</p>
<p>综上，对不同层使用不同的损失函数：<br />
<img src="/attachments_2022/Pasted%20image%2020220916213712.png"
alt="Pasted%20image%2020220916213712.png" /></p>
<h3 id="tinybert学习">TinyBERT学习</h3>
<p>一般训练BERT模型包含<strong>两个场景</strong>：预训练和精调。对预训练模型的蒸馏将丰富的语言学知识转换到小模型中，提升小模型的泛化性能。流程如图-1所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220916214140.png"
alt="Pasted%20image%2020220916214140.png" /><br />
另外，还支持进一步针对具体任务的蒸馏。</p>
<h4 id="通用蒸馏">通用蒸馏</h4>
<p>使用普通的BERT作为老师模型，并利用大规模数据集来蒸馏，生成的TinyBERT可用于进一步训练下游任务。此处训练出的TinyBERT是一个中间模型，效果比BERT差。</p>
<h4 id="针对任务蒸馏">针对任务蒸馏</h4>
<p>由于大模型的众多参数不一定都能通过精调优化，精调质量不一定很高，所以蒸馏模型有可能达到与普通的调优模型类似的效果。此处，用附加的针对任务的数据调优模型。将针对任务调优的BERT模型作为老师，使用数据增强方法来扩展训练数据，以提升学生模型的泛化能力。</p>
<h4 id="数据增强">数据增强</h4>
<p>使用预训练的BERT和GloVE词嵌入实现词级别替换来增强数据。<br />
用BERT来找到单个词替换，用Glove词嵌入来检索最相似的词组替换，通过概率p来决定是否替换当前词。算法-1展示了数据加强的方法。预训练的蒸馏模型为针对任务的模型提供初始模型参数。<br />
<img src="/attachments_2022/Pasted%20image%2020220916215432.png"
alt="Pasted%20image%2020220916215432.png" /></p>
<h2 id="实验">实验</h2>
<p>主实验结果如表-1所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220916220413.png"
alt="Pasted%20image%2020220916220413.png" /><br />
可以看到，TinyBERT
在参数少且速度快的情况下，相对于其它小模型效果更好，基本于MobileBERT持平。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>知识蒸馏</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_知识蒸馏_Meta-KD</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/11_%E4%BC%98%E5%8C%96/%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F_Meta-KD/</url>
    <content><![CDATA[<p>英文题目：Meta-KD: A Meta Knowledge Distillation Framework for
Language Model Compression across Domains<br />
中文题目：Meta-KD:跨领域语言模型压缩的元知识蒸馏框架<br />
论文地址：http://export.arxiv.org/pdf/2012.01266v1.pdf<br />
领域：自然语言处理, 知识蒸馏<br />
发表时间：2020.12<br />
作者：Haojie Pan，阿里团队<br />
出处：ACL<br />
被引量：1<br />
代码和数据：https://github.com/alibaba/EasyNLP（集成于EasyNLP）<br />
阅读时间：2022-09-17</p>
<h2 id="读后感">读后感</h2>
<p>结合元学习和蒸馏学习：元学习使得模型获取调整超参数的能力，使其可以在已有知识的基础上快速学习新任务。</p>
<h2 id="介绍">介绍</h2>
<p>预训练的自然语言模型虽然效果好，但占空间大，预测时间长，使模型不能应用于实时预测任务。典型的方法是使用基于老师/学生模型的知识蒸馏。而模型一般面向单一领域，忽略了不同领域知识的知识转移。本文提出元蒸馏算法，致力于基于元学习的理论，让老师模型具有更大的转移能力，尤其对few-shot和zero-shot任务效果更好。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a7a29b81f1f37627.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>如图-1所示，一个学物理的学生如果跟数学老师学习了数学方程知识，可能有助于他更好地理解物理方程。相近领域的数据可能提升模型的能力，但其它领域模型也可能转移一些无关的知识，从而影响性能。另外，当前研究证明：使用多任务精调也未必能提升所有任务的性能。由此，文中提出需要让老师模型消化不同领域的知识，并可针对具体领域，将知识转移到学生模型。在图-1(c)中，如果有万能的科学老师（元学习），它既会数学也会物理，则可以更好地教导学生。</p>
<p>如图-2所示，模型包含两部分：元老师和元蒸馏：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d1715667c25e497b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>首先利用多领域数据集训练元老师，通过引入破坏域损失来获取跨域知识，然后针对具体领域，用领域相关数据集引导元老师，以提升学生的蒸馏能力。</p>
<p><strong>文章贡献</strong><br />
* 第一次提出基于元学习的预训练自然语言模型压缩算法。<br />
* 提出Meta-KD框架训练跨领域的老师模型，包含元老师和元蒸馏两部分<br />
* 实验证明模型的有效性</p>
<h2 id="方法">方法</h2>
<h3 id="概览">概览</h3>
<p>定义：设有K个领域的K个数据集参与训练，D为数据集，M为大模型，S为蒸馏后的学习模型。<br />
模型训练分为两个场景：<br />
*
训练一个学习了K个领域知识的元老师模型M，模型消化了各领域知识且有针对不同领域很好的泛化能力。<br />
* 在元蒸馏过程中，利用领域数据集DK和元模型M，训练学生模型SK。<br />
如果某一个领域的实例很少，如few-shot或zero-shot问题，通过知识转移训练该领域模型。</p>
<h3 id="元老师学习">元老师学习</h3>
<p>将BERT模型作为基础模型。</p>
<p><strong>基于原型实例加权</strong><br />
学习过程中对每个实例X计算原型得分t，假设处理分类问题，共m个类别，计算所有第K领域中实例属于每个类别的概率均值（请参考图-3左侧的实心多边形）：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-323909ff5edb207c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>计算原型得分如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-f91f5322c26486a5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>此处cos用于计算相似度，α是超参数，公式的前半部分计算了该实体与它所在的领域的关系（在嵌入空间与同类实体的一致性），后半部分计算了与其它领域的关系。这样模型就同时学习了同一领域的知识和其它领域的知识。</p>
<p><strong>域破坏</strong><br />
除了交叉熵损失，还加入了域破坏损失以提升元老师转移学习的能力。对于每个实例，学习一个与h维度相同的域嵌入，记作ED(epsilon
D)。</p>
<p>在BERT以外，又加入了一个子网络，对网络输出进一步处理：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-f2ac659a3db3be37.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>针对域破坏的损失函数定义为：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-8197dca46dc5ebff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中σ(sigma)表示域类别，它是一个指示函数，只有0/1两个取值，这里最大化元教师对域标签做出错误预测的可能性。</p>
<p>我理解，这里的损失函数是让实例最终能识别它所在的域类别k。</p>
<p><strong>损失函数</strong><br />
最终的损失定义为：使用得分t加权针对所有领域的交叉损失；同时，加入了域破坏损失作为辅助，以训练模型转移知识的能力。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-06044efa1f57abbd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>这里的γ1(gamma)是超参数，用于设定域破坏损失的贡献。</p>
<h3 id="元蒸馏">元蒸馏</h3>
<p>使用小型的BERT作为学生模型，蒸馏网络结构如图-3所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5862f32714cf7ee8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>目标由五个部分组成：输入嵌入Lembd，隐藏层状态Lhidn，注意力矩阵Lattn，输出ligit和知识转移。其中Lembd，Lhidn，Lattn的蒸馏方法与TinyBERT一样。又加入了Lpred对输出层使用软交叉熵损失。<br />
另外，考虑到特定领域的知识转移，下面公式又加入了域相关的损失：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ca9278d3bd9f8403.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>以此鼓励学生模型学习更多的该领域相关知识。我理解这里的hM是指对该领域的老师模型获得的编码。</p>
<p>又引入λk参数，它是领域相关的权重：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-9d4cfdbc4ce58bec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中y^是预测的类别标签，当预测准确，或者t比较大时，λ值也相应变大，它反应的是老师在特定任务上监督学生的能力。</p>
<p>整体蒸馏损失计算方法如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-abe3ae576cb95d8f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="实验">实验</h2>
<p>使用自然语言推理（MNLI）和情绪分析（Amazon
Reviews）两个任务评价模型。<br />
表-2和3展示了主实验结果：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-33df72a98e3418f8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>得出三个结论：<br />
* Meta-KD模型优于之前模型，它比基线模型小7.5倍，效果仅差0.5%<br />
*
Meta-teacher模型效果很好，这表明元老师有能力学习更多可转移的知识来帮助学生。<br />
* 一般情况下，Meta-KD对小数据集数据效果更明显。</p>
<p>图-4也说明在few-shot情况下，实例越少，Meta-KD效果越明显：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-aacfcae147932447.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
]]></content>
      <tags>
        <tag>知识蒸馏</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_知识蒸馏_MobileBERT</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/11_%E4%BC%98%E5%8C%96/%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F_MobileBERT/</url>
    <content><![CDATA[<p>英文题目：MobileBERT: a Compact Task-Agnostic BERT for
Resource-Limited Devices<br />
中文题目：MobileBERT：面向资源有限设备的任务无关的压缩模型<br />
论文地址：https://arxiv.org/pdf/2004.02984<br />
领域：自然语言处理，模型蒸馏<br />
发表时间：2020<br />
作者：Zhiqing Sun，卡内基梅隆大学，谷歌<br />
出处：ACL<br />
被引量：162<br />
代码和数据：https://github.com/google-research/google-research/tree/master/mobilebert<br />
阅读时间：22.06.16</p>
<h2 id="读后感">读后感</h2>
<p>使用了瓶颈结构，同时微调模型实现加速，最终实现了任务无关的蒸馏BERT模型。</p>
<h2 id="介绍">介绍</h2>
<p>大模型效果好，但受资源限制。文中提出了MobileBERT模型对BERT模型进行压缩和加速，它和原始BERT一样，是任务无关的，可以<strong>泛化到不同下游任务</strong>。MobileBERT是对BERT
LARGE的优化，使用瓶颈结构。具体实现分两步：先训练一个倒瓶颈的特殊的老师模型，然后再将知识转移到学生模型MobileBERT。它比BERT
BASE模型小4.3倍，快5.5倍，在GLUE数据集上达到与BASE BASE类似的效果。</p>
<p>文中提出的MobileBERT模型与BERT
LARGE的深度相同，用瓶颈结构使每一层更窄，如图-1所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220916225337.png"
alt="Pasted%20image%2020220916225337.png" /></p>
<p>与之前的模型相比，文中模型只在预训练阶段使用知识转移，在<strong>下游任务中不需要微调教师模型和数据增强；另外，它不修改模型层数，只改变了每层的宽度</strong>。</p>
<h2 id="方法">方法</h2>
<p>图-1展示了模型参数的具体大小：<br />
<img src="/attachments_2022/Pasted%20image%2020220916230754.png"
alt="Pasted%20image%2020220916230754.png" /></p>
<h3 id="瓶颈和逆瓶颈">瓶颈和逆瓶颈</h3>
<p>从表-1中可以看到，每块维度仅为128，另外，将全流程的层输入输出都调整为更窄的512。<br />
在训练过程中，首先训练老师模型 IB-BERT
，再将知识转移到学生模型MobileBERT。老师模型设计如图-1(b)所示，它是一个逆瓶颈结构，师生模型的Feature
map大小均为512，这样可以直接对比层输出。同时使用瓶颈和逆瓶颈使老师模型保持性能，学生模型足够紧凑。</p>
<h3 id="多层前馈网络">多层前馈网络</h3>
<p>注意力层和前馈网络功能不同：前者连接了不同空间数据，后者提升了模型的非线性表达能力。一般BERT的注意力层和前馈网络参数比例为1:2，而由于MobileBERT模型比较窄，注意力参数相对更多，为解决此问题，设计了<strong>多个叠加的前馈层</strong>，如图-1(c)所示。</p>
<h3 id="操作优化">操作优化</h3>
<p>通过延迟分析发现，归一化层和 gelu
激活函数占延迟的很大比例，因此对其进行优化。<br />
* 去掉归一化层：用针对元素的线性变换替换n通道的隐藏层归一化。<br />
<img src="/attachments_2022/Pasted%20image%2020220917154943.png"
alt="Pasted%20image%2020220917154943.png" /><br />
* 使用relu代替glue</p>
<h3 id="嵌入分解">嵌入分解</h3>
<p>嵌入词表占了模型的很大比例，如表-1所示，MobileBERT将嵌入词表压缩到128维，再用核为3的卷积层将其扩展到512维。</p>
<h3 id="训练目标">训练目标</h3>
<p>转移目标包含：feature map转移和注意力转移。</p>
<p><strong>Feature map转移</strong><br />
BERT中每层的输出是下层的输入，因此，需要让学生的层输出尽量与老师结果一致。这里使用MSE作为损失函数。<br />
<img src="/attachments_2022/Pasted%20image%2020220917155843.png"
alt="Pasted%20image%2020220917155843.png" /><br />
公式中l为层索引，T为序列长度，N为feature map大小。</p>
<p><strong>注意力转移</strong><br />
注意力提升了BERT模型的语言识别能力，因此也通过学习注意力层将知识更好地转移到MobileBERT模型。使用KL散度来计算注意力层的差异，作为损失函数：<br />
<img src="/attachments_2022/Pasted%20image%2020220917160241.png"
alt="Pasted%20image%2020220917160241.png" /></p>
<p><strong>预训练蒸馏</strong><br />
除了针对各Transformer层的转移，在预训练时，还使用了蒸馏的loss函数，最终损失函数由三部分组成：遮蔽的损失(MLM)，下一句预测的损失(NSP)和针对MLM的蒸馏损失：<br />
<img src="/attachments_2022/Pasted%20image%2020220917160758.png"
alt="Pasted%20image%2020220917160758.png" /></p>
<h3 id="训练策略">训练策略</h3>
<p>下面讨论三种训练策略，如图-2所示：</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220917161034.png"
alt="Pasted%20image%2020220917161034.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220917161034.png</figcaption>
</figure>
<p><strong>辅助知识转移（AKT）</strong><br />
将中间层的知识转移作为知识蒸馏的辅助任务。损失函数是所有层的知识转移损失和预测蒸馏损失的线性组合。</p>
<p><strong>联合知识转移（JKT）</strong><br />
将训练分成两步：先训练中间层知识转移，然后训练预训练的知识蒸馏。</p>
<p><strong>递进知识转移（PKT）</strong><br />
下层的错误可能影响到上层的学习，因此设计了先训练下层，再训练上层的知识转移方法。一般在训练上层时冻结下层参数，也可以使用软化方法，训练上层时对下层参数使用较小的学习率。实验证明该方法效果最好。</p>
<h2 id="实验">实验</h2>
<p>表-2展示了在SQuAD数据集上，使用不同参数大小的蒸馏结果：<br />
<img src="/attachments_2022/Pasted%20image%2020220917162235.png"
alt="Pasted%20image%2020220917162235.png" /></p>
<p>图-3展示了堆叠前馈层的效果：</p>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220922120955.png"
alt="Pasted%20image%2020220922120955.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220922120955.png</figcaption>
</figure>
<p>精调下游任务的方法与普通BERT一致，略有不同的是MobileBERT常需要更大的学习率和更多次迭代。主实验结果如表-8所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220917163418.png"
alt="Pasted%20image%2020220917163418.png" /><br />
可以看到，由于是对BERT LARGE的蒸馏，MobileBERT与BERT
BASE模型效果类似，而大小比BERT小4.3倍，速度是BERT的5.5倍。</p>
<p>表-8对比了三种不同策略的训练方法，可以看到递进训练效果更好。<br />
<img src="/attachments_2022/Pasted%20image%2020220917163018.png"
alt="Pasted%20image%2020220917163018.png" /><br />
文中用的每个优化技术都在实验中做了效果比较，这里只罗列了最重要的部分，其它详见论文正文。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>知识蒸馏</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_模型鲁棒性的量化指标</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/11_%E4%BC%98%E5%8C%96/%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E6%A8%A1%E5%9E%8B%E9%B2%81%E6%A3%92%E6%80%A7%E7%9A%84%E9%87%8F%E5%8C%96%E6%8C%87%E6%A0%87/</url>
    <content><![CDATA[<h2 id="读后感">读后感</h2>
<p>建立一个框架，用于计算和量化模型鲁棒性。使用者应根据情境，风险偏好，以及分布等角度选择不同的衡量方法。更抽象地讲，它是对不确定性的决策原则。选择不同鲁棒性评价方法会影响决策，尽量使用多个指标结合的方式。</p>
<h2 id="介绍">介绍</h2>
<p>根据经济学中的不确定型决策原则。在深度不确定性下，存在多种不确定因素共同影响决策的后果。在这样的系统中，系统性能通常使用鲁棒性指标来衡量。</p>
<h2 id="具体方法介绍">具体方法介绍</h2>
<h3 id="maximin">Maximin</h3>
<p>悲观原则：有若干种结果，选择每个系列中最坏结果中的最好结果<br />
<span class="math display">\[Maximin = max(min_1, min_2, ...,
min_n)\]</span></p>
<h3 id="maximax">Maximax</h3>
<p>乐观原则：有若干种结果，选择每个系列中最好结果中的最好结果<br />
<span class="math display">\[ Maximax = max(max_1, max_2, ..., max_n)
\]</span></p>
<h3 id="hurwicz-optimism-pessimism-rule">Hurwicz optimism-pessimism
rule</h3>
<p>折衷原则：按比例结合乐观和悲观原则<br />
<span class="math display">\[ HOR = αMaxmin + (1 − α)Maximax
\]</span></p>
<h3 id="laplaces-principle-of-insufficient-reason">Laplace's principle
of insufficient reason</h3>
<p>不充分理由原则：对所有结果取平均<br />
<span class="math display">\[LPIR=1 / n\sum_{i}^{n} real \]</span></p>
<h3 id="minimax-regret">Minimax regret</h3>
<p>后悔最小原则：最优-实际，也是一种相对悲观的方法<br />
<span class="math display">\[ regret_i = max − real_i\]</span><br />
<span class="math display">\[MinimaxRegret = min(regret_1, regret_2,
..., regret_n)\]</span></p>
<h3 id="th-percentile-minimax-regret">90th percentile minimax
regret</h3>
<p>与 Minimax regret 相似，只是取后悔的90分位数</p>
<h3 id="mean-vaiance">Mean-vaiance</h3>
<p>均值方差模型：类似不充分理由模型，通过频率采样，计算分布，估计打分</p>
<h3 id="undesirable-deviations">Undesirable deviations</h3>
<p>不良偏差：将偏差的中位数作为打分</p>
<h3 id="percentile-base-skewness">Percentile-base skewness</h3>
<p>正态分布偏度：描述不对称程度，有左偏和右偏两种，它是对分布的评价（pandas可提供该统计值）</p>
<h3 id="percentile-base-skewness-1">Percentile-base skewness</h3>
<p>正态分布峰度：描述某个分布相⽐于正态分布的峰值⾼低的程度，它是对分布的评价</p>
<h3 id="starrs-domain-criterion">Starr's domain criterion</h3>
<p>斯塔尔阈准则：计算性能与决策者选择的基准进⾏⽐较，并打分,
1为通过，0为不通过，计算打分的平均值，得分最高的鲁棒性高。</p>
<p>乐观程度排名如下图所示：<br />
<img src="/attachments_2023/Pasted%20image%2020230203171411.png" /></p>
<h2 id="框架">框架</h2>
<p>框架由三部分组成：方案(Decision alternatives)，条件（Plausible future
conditions），度量方法（Performance
metric）。代入机器学习的场景中，如下：<br />
*
方案-&gt;模型算法，解决一个问题可能有多个算法，x1,x2...xm，每次评价其中一种的鲁棒性<br />
*
条件-&gt;数据，不同情况下的数据，可视为不同场景，S={s1,s1...sn}，比如不同环境下产生的数据，每个算法xi需要代入不同场景的数据<br />
*
度量方法-&gt;评价方法，将各个场景数据S代入模型xi，f(xi,S)评价模型在各场景下的效果。<br />
<img
src="/attachments_2023/Pasted%20image%2020230203232605.png" /><br />
<img
src="/attachments_2023/Pasted%20image%2020230203233909.png" /><br />
计算其整体鲁棒性可分为以下三步：<br />
*
T1：将对模型的评价方法f改为f'，比如在后悔最小模型中，把对模型的打分改为最好值与实际值的差。<br />
*
T2：选择场景子集，有的方法不需要所有子集参与，比如乐观原则只需要选择效果最好的场景子集。<br />
*
T3：融合各个场景子集的结果，比如不充分理由原则会对所有子集的结果取均值。</p>
<p>具体方法对应的步骤如下：<br />
<img src="/attachments_2023/Pasted%20image%2020230203235001.png" /></p>
<h2 id="如何选择鲁棒性度量方法">如何选择鲁棒性度量方法</h2>
<ul>
<li>在T1步中，可选择使用相对指标还是绝对指标，以及考虑客户满意度<br />
</li>
<li>在T2步中，可选择使用单个场景，多个场景，所有场景，以及风险偏好<br />
</li>
<li>在T3步中，需要考虑使用什么方法结合多场景的结果，如均值，方差，峰度等。</li>
</ul>
<p>下表列出了不同方法T1,T2,T3步骤的差异以及风险偏好。<br />
<img
src="/attachments_2023/Pasted%20image%2020230203235619.png" /><br />
不同鲁棒性度量方法可能产生不一致结果。</p>
<hr />
<h2 id="扩展">扩展</h2>
<h3 id="对抗鲁棒性">对抗鲁棒性</h3>
<p>具体应用时，如果没有多场景的数据，可以使用对抗攻击方式产生不同场景数据，然后用其评测模型鲁棒性。</p>
<h3 id="工具介绍">工具介绍</h3>
<p>对抗攻击工具箱<br />
<a
href="https://github.com/Trusted-AI/adversarial-robustness-toolbox">adversarial-robustness-toolbox</a><br />
其readme.md中的Classifies展示了对分类器的攻击，其中包含针对不同种类模型攻击的工具。<br />
具体使用逻辑是：先用数据训练一个模型（任意黑盒模型），然后用将模型和数据代入API，生成具有攻击性的数据，并用其评测模型被攻击后的效果。</p>
<h2 id="zotero地址">Zotero地址</h2>
<p><a href="http://zotero.org/users/10876188/items/KNSA7X5H">Robustness
Metrics: How Are They Calculated, When Should They Be Used and Why Do
They Give Different Results?</a><br />
zotero id: KNSA7X5H</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Bland-Altman图</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/3_%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83/Bland-Altman%E5%9B%BE/</url>
    <content><![CDATA[<h3 id="介绍">介绍</h3>
<p>Bland-Altman图是一种<strong>一致性</strong>评价测量方法，简称BA，常用于医学实验和数据分析。<br />
可使用它检测两组数据的一致性，比如对比新旧两种方法，对比一组实际值和预测值等。相对于校准曲线，它能更好地对比两组数据中每个数据对的一致性。</p>
<h3 id="如何看图">如何看图</h3>
<p><img
src="/attachments_2023/Pasted%20image%2020230217111256.png" /><br />
图中每个点代表一个实例，其横轴是预测值和实际值的均值，纵轴是其预测值与实际的差值。两条红线分别表示mean±1.96std的范围。若大部分样本点落在此范围内，则说明两种方法的测量一致性较好。如上图中最右侧的点，假设它的预测值是1，实际值是0.93，则其均值是0.965（即横坐标），其差值是0.07（即纵坐标）。</p>
<p>通过看图可以得到一些结论，如：<br />
* 可以从图中点看出数据的分布；<br />
* 如果图中点均分布在0附近，则说明一致性高；<br />
* 如果左边密集，右边分散，则说明值越小误差越小；<br />
* 从Y轴可以看出，数据是往上偏还是往下偏。</p>
<h3 id="实现">实现</h3>
<p>Python 的 pingouin 和 pyCompare 包都提供 BA
作图工具，也可以使用matplotlib直接画图，详见：<br />
<a href="https://www.jianshu.com/p/477d93a64991">Bland-Altman
Plots(一致性评价)在python中的实现</a></p>
]]></content>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>从正态分布到T检验</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/3_%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83/%E4%BB%8E%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%E5%88%B0T%E6%A3%80%E9%AA%8C/</url>
    <content><![CDATA[<h1 id="从正态分布到t检验">从正态分布到T检验</h1>
<h3 id="说明">1． 说明</h3>
<p> 接上次的<a
href="https://blog.csdn.net/xiaocong1990/article/details/83039083">《几种常见的数学分布》</a>。这次说说T分布和T检验，用词不够严谨，大家就领会精神为主吧~</p>
<h3 id="什么是抽样">2． 什么是抽样</h3>
<p> 如果整体样本可以一个一个判断叫普查，如果整体样本太多，没法一个一个判断，只能取一部分代表整体，叫抽样。</p>
<p> 比如说，一个班有20个人，我们可以把所有人的身高加一起，除以人数，计算均值，如果有2000000人，就无法把所有人身高都统计一遍再除以总数，一般情况下，就是取其中一部分，计算其均值，认为他们能代表全部。</p>
<h3 id="正态分布">3． 正态分布</h3>
<p> 先复习一下正态分布，比如说女人的身高一般在160左右，150,
170的比较少，140,180的更少，把身高当做横轴，人数作为纵轴画图，就可看到一个中间高两边低的钟形曲线，也就是正态分布。</p>
<p> 那什么不是正态分布呢？比如人的空腹血糖一般在4-6之间，而血糖高的7,8,9的很多，而低到3,2,1的就很少，不样一边多一边少的，就不是正态分布。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ed5629198986890c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="正态分布和t分布">4． 正态分布和T分布</h3>
<p>如果只有20个人画一下算一下，就是正态分布；如果有2000000人，从中随机取出20个，画一图也就钟形，就叫T分布。<br />
它俩的不同就在于，一个是抽样的，一个是全体的。规律都是中间高两边低对称的样子。当取样趋于无穷大时，T分布就是正态分布，但一般都没法取太多。</p>
<h3 id="假设检验">5． 假设检验</h3>
<p> 如果有2000000个女的，你认为她们的身高是正态分布，均值160（称理论值或标准值μ0），然后从中随机选了20个人，平均身高161（μ），标准差为5（上下浮动），那她们是否适合你所定义的正态分布均值160的规律呢？</p>
<p> 由样本信息对相应总体的特征进行推断称为统计推断。若对所估计的总体首先提出一个假设（平均身高160），然后通过样本数据（20个人）去推断是否拒绝这一假设，称为假设检验，如果符合这个假设就是H0（无效假设null
hypothesis），如果不符合就是H1（备择假设alternative hypothesis）。</p>
<h3 id="t检验">6． T检验</h3>
<p> 以T分布为基础的检验叫T检验。这里主要是判断一组样本是否符合我们设定的“统计推断”。
将上例中的值代入公式，如果这20人的平均身高为161，求t值。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-82aadd9809f532d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 如果这20人的平均身高为164<br />
<img
src="https://upload-images.jianshu.io/upload_images/5357893-5e55fb119420a9ca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /><br />
 可以看出t值的大小与抽样的均值161，标准差5，样本数20，以及统计推断160相关。</p>
<h3 id="如何查表">7． 如何查表</h3>
<p> H0成立时t服从自由度v=n-1=19的t分布，查表如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d0a881c23d125a52.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 上面的0.05和0.025又是什么呢？是p值（p-value），p=0.05意味着样本统计有95%的信心拒绝原假设，就是说p越小，原假设越可能被拒绝，一般p设成0.05，自由度19时，它对应的t值为2.093。</p>
<p> 当采样的20人平均身高为161时，t=0.894&lt;2.093，即H0成立（抽样符合假设），当平均身高为164时，t=3.578&gt;2.093，则H1成立（即这组抽样不符合假设）。</p>
<p> 就是说t差得越多，t是因为误差造成的可能性p越小，既然不是因为误差，那就是因为本质不同，所以不符合假设。</p>
<h3 id="单侧和双侧检验">8． 单侧和双侧检验</h3>
<p> 那上边为什么还有0.05和0.1的差别呢？它分别对应单侧和双侧检验。
理论值μ0（160），抽样均值μ（161）。</p>
<p>双测检验值：<br />
μ≠μ0 （μ &gt;μ0或μ&lt;μ0）<br />
单测检验值：<br />
μ&gt;μ0 （根据专业角度，μ不可能小于μ0）<br />
μ&lt;μ0 （根据专业角度，μ不可能大于μ0）</p>
<p> 通常我们用的都是双侧t检验，上例中用的也是双边的p值0.05对应的t值。</p>
<h3 id="t检验的应用条件">9． T检验的应用条件</h3>
<p> 要符合t检验的条件，才能计算t检验的统计值</p>
<p><strong>(1) 必须是随机样本且相互独立</strong></p>
<p> 比如抽得出自一个家庭，就只能统计这一家的，不能代表全国的。</p>
<p><strong>(2) 来自正态分布的总体</strong></p>
<p> 正态分布是一种特殊的T分布，判断正态分布的方法有很多，比如Shapiro-
Wilk
(W检验)用于3-50个的小样本，Kolmogorov-Smirnov检验(D检验)用于小于5000的样本量，大于2000可做直方图，观察是否正态分布。</p>
<p><strong>(3)方差齐性</strong></p>
<p> 均数比较时，要求两总体方差相等</p>
]]></content>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>几种常见的数学分布</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/3_%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83/%E5%87%A0%E7%A7%8D%E5%B8%B8%E8%A7%81%E7%9A%84%E6%95%B0%E5%AD%A6%E5%88%86%E5%B8%83/</url>
    <content><![CDATA[<h1 id="几种常见的数学分布">几种常见的数学分布</h1>
<p>#数学</p>
<h4 id="什么是数学期望">1. 什么是数学期望</h4>
<p> 举个例子：某城市有10万个家庭，没有孩子的家庭有1000个，有一个孩子的家庭有9万个，有两个孩子的家庭有6000个，有3个孩子的家庭有3000个<br />
(0 * 1000 + 1 * 90000 + 2 * 6000 + 3 * 3000) / 100000 = 1.11<br />
 数学期望(mean)（或均值，亦简称期望）是试验中每次可能结果的概率乘以其结果的总和<br />
0 * 0.01 + 1 * 0.9 + 2 * 0.06 + 3 * 0.03 = 1.11</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-45a7ba44d25d459c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="概率密度与累积分布">2. 概率密度与累积分布</h4>
<p> 概率密度一般的写法是：P(X=a) = …，即X等于某个值a的可能性<br />
 累积分布一般的写法是：P(X&lt;=a) =
…，即X小于等于某个值a的所有可能性累加之和<br />
 这二者千万别弄混，否则就会被各种公式绕晕。下图是增量分布的概率密度图（橙色）和累积分布图（蓝色）。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-8735207d64755298.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="常见的分布">3. 常见的分布</h4>
<p><strong>(1) 离散分布：</strong><br />
伯努利分布（零一分布，两点分布），二项分布，几何分布，泊松分布（Poisson分布）</p>
<p><strong>(2) 连续分布：</strong><br />
指数分布，正态分布（高斯分布），均匀分布</p>
<p><strong>(3) 抽样分布：</strong><br />
卡方分布（X<sup>2</sup>分布），F分布，T分布</p>
<p><strong>(4) 其它分布：</strong><br />
多项分布，Beta分布，Dirichlet分布</p>
<h4 id="伯努利分布">4. 伯努利分布</h4>
<p><strong>(1) 应用场景</strong><br />
 应用于两种实验结果。要么成功，要么失败，一定程度上是二元的性质。比如：一个硬币抛一次人结果。</p>
<p><strong>(2) 描述</strong><br />
 进行一次事件试验，该事件发生的概率为p，不发生的概率为1-p，任何一个只有两种结果的随机现象都服从0-1分布。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5e44c09944e1f50d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="二项分布">5. 二项分布</h4>
<p><strong>(1) 应用场景</strong><br />
 在独立n次实验中成功次数，比如：一个硬币抛n次，k次正面朝上。</p>
<p><strong>(2) 描述</strong></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-3fae236919680eb1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-3ceac5f6d5cbf0e9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 上图是n=100, p=0.5（抛硬100次,
每一枚硬币正面朝上的概率为0.5），图中横轴为正面朝上的次数，纵轴为概率，可以看出正面朝上50次的可能性最大，为0.08左右。</p>
<h4 id="泊松分布">6. 泊松分布</h4>
<p><strong>(1) 应用场景</strong><br />
 某一区间内发生随机事件次数的概率分布，比如：每小时出生3个婴儿，某网站平均每分钟有2次访问。</p>
<p><strong>(2) 描述</strong><br />
 一个离散型随机变量X 满足：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-0f4c85b0d515efbe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 这样看起来就很抽象了，推荐看一看参考中的《如何通俗理解泊松分布》，简单地说一下上述公式怎么用，以出生婴儿为例，λ是每小时出生的婴儿的平均数，k是3个婴儿，P(X=3)是每小时出生3个婴儿的概率。从λ中我们就能看出单位时间和发生事件的大概关系。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-37d96edfb70dbc58.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 上图是λ=2时（平均每小时出生2个婴儿），出生0个的概率为0.14，出生1个的概率为0.27…</p>
<h4 id="几何分布">7. 几何分布</h4>
<p><strong>(1) 应用场景</strong><br />
 第一次成功所进行的试验次数，比如：考几次能通过，抛几次硬币能出现正面。</p>
<p><strong>(2) 描述</strong><br />
 几何分布由n次伯努利分布构成，随机变量X表示第一次成功所进行试验的次数</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-bbc85aa1a74ba343.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 从公式中很容易看出，经历了k-1次不中，和一次命中，以抛硬币为例，P(X=3)是抛三次能抛到一次正面向上概率，前两次都是背面朝上，第三次正面朝上。如果单个硬币正面朝上的概率为0.5，那么期望是2次。
与二项分布相比，二项分布是抛n次硬币，有几次正面朝上，几何分布是抛几次出现第一次正布朝上。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-8c85287b674b7684.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 上图是p=0.5时的几何分布，横轴是次数，可见抛一次就中的可能性最大为0.5，两次中的可能性为0.25…，次数越多，概率越小，整体平均下来基本是两次左右，因此，期望为2。从期望就可以看出，抛第几次能出正面，主要还是取决于硬币本身正面朝上的概率。</p>
<h4 id="指数分布">8. 指数分布</h4>
<p><strong>(1) 应用场景</strong><br />
 两次随机事件发生时间间隔的概率分布，比如：婴儿出生的时间间隔，网站访问的时间间隔。</p>
<p><strong>(2) 描述</strong><br />
 指数分布满足以下概率密度函数公式</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-dfb09e6376aa5bf4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> λ&gt; 0是分布的一个参数，常被称为率参数（rate
parameter）。即每单位时间内发生某事件的次数，还是生小孩为例，公式中的x是生两个孩子的时间间隔。<br />
 假设平均每一小时出生两个婴儿，则单位时间1小时出生2个婴儿，λ=2，期望e=0.5（平均间隔0.5小时），如左图所示。</p>
<p> 假设平均每两小时出生一个婴儿，则单位时间1小时出生0.5个婴儿，λ=0.5，期望E=2（平均间隔2小时），如右图所示。
λ越大，曲线下降越快，可见，指数分布是几何分布的加强版。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5736e77b2cf8f7da.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 上图中x轴是时间间隔，y轴是概率，不是说概率之和为1吗？为什么间隔为0的概率大于1呢？因为这是连续分布，某一点概率大于1（但它所在区域很窄），也不影响函数线下面积之和为1。</p>
<h4 id="正态分布">9. 正态分布</h4>
<p><strong>(1) 应用场景</strong><br />
 连续型数据或者数据离散性小，数据基本符合正态分布特点。比如：群体的身高，智商，考试分数（中间多两边少）。</p>
<p><strong>(2) 描述</strong><br />
 若随机变量X服从一个数学期望为μ、方差o^2 为的高斯分布，记为N(μ，o^2)</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a2a5492b6333e833.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-4164cb97d1009cd2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 上图是μ=1,
o=2.0的正态分布，简单地说，就是基本都分布在以μ为中心，分散在o范围之内，比如：全班平均分80分，考100的也少，不及格的也少。</p>
<h4 id="抽样分布">10. 抽样分布</h4>
<p><strong>(1) 一些概率</strong></p>
<ol type="i">
<li><p>抽样<br />
 如果整体样本可以一个一个判断叫普查，如果整体样本太多，没法一个一个判断，只能取一部分代表整体，叫抽样。</p></li>
<li><p>统计量<br />
 统计量是根据样本数据计算出来的一个量，他是样本的函数，通常我们所关心的样本统计量有品均数、样本标准差等等。</p></li>
<li><p>抽样分布<br />
 抽样分布也称统计量分布，以样本平均数为例，它是总体平均数的一个估计量，如果按照相同的样本容量，相同的抽样方式，反复地抽取样本，每次可以计算一个平均数，所有可能样本的平均数所形成的分布，就是样本平均数的抽样分布。卡方分布，T分布，F分布都是抽样分布。</p></li>
</ol>
<p><strong>(2) 卡方分布</strong><br />
 设 X1,X2,......Xn相互独立, 都服从标准正态分布N(0,1),
则称随机变量χ<sup>2=X1</sup>2+X2<sup>2+......+Xn</sup>2所服从的分布为自由度为
n 的χ2分布.</p>
<p><strong>(3) T分布</strong><br />
 设X1服从标准正态分布N(0,1)，X2服从自由度为n的χ2分布，且X1、X2相互独立，则称变量t=X1/((X2/n)^(1/2))
所服从的分布为自由度为n的t分布。</p>
<p><strong>(4) F分布</strong></p>
<p> 设X1服从自由度为m的χ2分布,X2服从自由度为n的χ2分布，且X1、X2相互独立，则称变量F=(X1/m)/(X2/n)所服从的分布为F分布，其中第一自由度为m,第二自由度为n
。</p>
<h4 id="参考">11. 参考</h4>
<p><strong>(1) 几种常见的分布</strong><br />
<a
href="https://wenku.baidu.com/view/dc16311a777f5acfa1c7aa00b52acfc789eb9f04.html">https://wenku.baidu.com/view/dc16311a777f5acfa1c7aa00b52acfc789eb9f04.html</a></p>
<p><strong>(2) 如何通俗理解泊松分布</strong><br />
<a
href="https://blog.csdn.net/ccnt_2012/article/details/81114920">https://blog.csdn.net/ccnt_2012/article/details/81114920</a></p>
]]></content>
  </entry>
  <entry>
    <title>熵_相对熵_散度</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/3_%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83/%E7%86%B5_%E7%9B%B8%E5%AF%B9%E7%86%B5_%E6%95%A3%E5%BA%A6/</url>
    <content><![CDATA[<h2 id="信息量">1 信息量</h2>
<p>意外越大，越不可能发生，概率就越小，信息量也就越大，也就是信息越多。比如说“今天肯定会天黑”，实现概率100%，说了和没说差不多，信息量就是0。<br />
详见：<a href="None">2. 信息量</a></p>
<h3 id="公式">1.1 公式</h3>
<p><span class="math display">\[I(x)=-logP(x)\]</span><br />
概率P(x)越小，信息量越大，可以简单理解为最小编码长度，比如概率0.125，log(1/0.125)，如果以2为底做log，则需要3位二进制数描述。</p>
<h2 id="熵">2 熵</h2>
<p>熵用于描述不确定性，越不确定，熵越高。熵是事件所属的整个分布的不确定性总量量化。可以说：熵越小，越容易被预测。</p>
<h3 id="公式-1">2.1 公式</h3>
<p><span class="math display">\[H(\mathrm{x})=\mathbb{E}_{\mathbf{x}
\sim P}[I(x)]=-\mathbb{E}_{\mathbf{x} \sim P}[\log P(x)]=-\sum_{x} P(x)
\log P(x)\]</span><br />
这里乘了概率P(x)，等于计算了平均最小编码长度。</p>
<h3 id="特性">2.2 特性</h3>
<ul>
<li>接近均匀分布的概率分布具有较高的熵<br />
</li>
<li>接近确定性的分布 (输出几乎可以确定) 具有较低的熵</li>
</ul>
<h3 id="实例">2.3 实例</h3>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>arr <span class="op">=</span> [<span class="dv">1</span>,<span class="dv">10</span>,<span class="dv">100</span>,<span class="dv">1000</span>]  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> <span class="dv">0</span>  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> arr:  </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> x<span class="op">/</span><span class="bu">sum</span>(arr)  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">&#123;</span>x<span class="sc">&#125;</span><span class="ss">, </span><span class="sc">&#123;</span><span class="bu">round</span>(p,<span class="dv">5</span>)<span class="sc">&#125;</span><span class="ss"> * </span><span class="sc">&#123;</span><span class="bu">round</span>(math.log(p),<span class="dv">5</span>)<span class="sc">&#125;</span><span class="ss"> = </span><span class="sc">&#123;</span><span class="bu">round</span>(p<span class="op">*</span>math.log(p),<span class="dv">5</span>)<span class="sc">&#125;</span><span class="ss">&quot;</span>)  </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    e <span class="op">+=</span> p<span class="op">*</span>math.log(p)  </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="op">-</span>e)  </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(scipy.stats.entropy(arr))  </span></code></pre></div>
<p>运行结果</p>
<pre><code>1, 0.0009 * -7.01302 = -0.00631  
10, 0.009 * -4.71043 = -0.0424  
100, 0.09001 * -2.40785 = -0.21673  
1000, 0.90009 * -0.10526 = -0.09474  
0.3601821726181299  
0.3601821726181299  </code></pre>
<ul>
<li>首先要注意的是：数组里存放的是每个类别中元素的个数，而不是元素的具体值，本例中共1111个元素，分为四类。<br />
</li>
<li>p是每个类别出现的频率，取值在0-1之间，因此log(p)为负，频率p离1越近，log(p)离0越近。<br />
</li>
<li>就每一类而言，有以下几种可能：
<ul>
<li>a.该类占整体比例越大，p越大，log(p)离0越近，相乘后，对整体熵（混乱程度）的贡献比较小<br />
</li>
<li>b.该类占整体比例越小，p越小，log(p)离0越远，相乘后，对整体熵（混乱程度）的贡献比较小<br />
</li>
<li>c.该类占整体比例适中，p值中等，log(p)也中等，相乘后，对整体熵（混乱程度）的贡献反而比较大<br />
</li>
</ul></li>
<li>其背后的逻辑是：
<ul>
<li>a.有一个类别可能性非常大（如a），绝大多数属于该类，就“蒙”这一类<br />
</li>
<li>b.有一个类别可能性非常小（如b），绝大多数不属于该类，“不蒙”这一类<br />
</li>
<li>c.如果数据被平均分成少数几个类别（c中的一种情况），那就很难“蒙对”了，这也是最不确定的情况</li>
</ul></li>
</ul>
<h2 id="相对熵">3 相对熵</h2>
<p>相对熵可以用来衡量两个分布之间的差异程度。两者差异越小，KL散度越小。</p>
<h3 id="kl散度">3.1 KL散度</h3>
<p>KL散度，KL距离，又叫相对熵(relative
entropy)，衡量两个概率分布之间的不同程度。<br />
*
KL散度被称为：相对熵、互熵、鉴别信息、Kullback熵、Kullback-Leible散度(即KL散度的简写)。<br />
* KL散度常在损失函数中用于限制函数变化。<br />
*
在机器学习、深度学习领域中，KL散度被广泛运用于变分自编码器中(Variational
AutoEncoder,简称VAE)、EM算法、GAN网络中。<br />
* KL散度是非对称的，如需考虑双向散度，请见JS散度。<br />
*
KL散度结果为0-正无穷，很难给出一个绝对的阈值，但可以使用比较的方法计算相对的大小。</p>
<h4 id="定义">3.1.1 定义</h4>
<p>一个离散随机变量X的可能取值为X=x1,x2,...xn，对应的概率pi=p(X=xi)。</p>
<h4 id="离散公式">3.1.2 离散公式</h4>
<p><span class="math display">\[D_{K L}(p \| q)=\sum_{i=1}^{n} p(x) \log
\frac{p(x)}{q(x)}\]</span><br />
上述公式描述的是p相对于q的散度，针对每个x，计算不同分布中概率p(x)与q(x)的比值，当无差异时，其值为1，log(1)为0（见下方log函数图），此x项对应项则为0，否则根据其概率p(x)与差异的大小的乘积累加。当两个分布一致时，其KL散度为0。</p>
<h4 id="连续公式">3.1.3 连续公式</h4>
<p><span class="math display">\[D_{KL}(p \| q)=\int_x p(x) \log
\frac{p(x)}{q(x)} d x\]</span><br />
与离散公式类似，差异是将离散x变为连续值计算积分，其目标也是让x取值范围中所有值p(x)与q(x)一致。</p>
<h4 id="用途">3.1.4 用途</h4>
<ul>
<li>用户画像<br />
使用KL散度去计算同一类型商品不同用户群体之间的金额（或其余指标）的KL散度，如果都很接近，说明这个类型商品不是不同用户群体之间的差异点，可以进行剔除，只保留有差异性的商品类型(KL散度较大)。</li>
</ul>
<h3 id="js散度">3.2 JS散度</h3>
<h4 id="定义-1">3.2.1 定义</h4>
<p>JS散度是基于KL散度的变体，解决了KL散度非对称的问题，同样是二者越相似，JS散度越小。</p>
<h4 id="特性-1">3.2.2 特性</h4>
<p>JS散度的取值范围在0-1之间，完全相同时为0。</p>
<h4 id="公式-2">3.2.3 公式</h4>
<p><span
class="math display">\[J_S(P_1||P_2)=\frac{1}{2}KL(P_1||\frac{P_1+P_2}{2})+\frac{1}{2}KL(P_2||\frac{P_1+P_2}{2})\]</span><br />
把数据1和数据2放一块作为一个整体，再用数据1和数据2分别和整体比。</p>
<h2 id="交叉熵">4 交叉熵</h2>
<h3 id="公式-3">4.1 公式</h3>
<p>交叉熵常作为损失函数使用，用于评价离散值的预测：<br />
<span class="math display">\[\mathrm{H}(\mathrm{p}, \mathrm{q})=\sum_{x}
p(x) \cdot \log \left(\frac{1}{q(x)}\right)\]</span><br />
p表示真实标签的分布，q则为训练后的模型的预测标签分布，交叉熵损失函数可以衡量p与q的相似性。如果把q换成p，则计算的是数据的熵。</p>
<h3 id="交叉熵损失函数">4.2 交叉熵损失函数</h3>
<p>交叉熵作为分类的损失函数时，由于实际上每个实例只属于一个分类，则只有一个p(x)为1，其它p(x)都为0，那么只需要考虑模型预测为该类别的概率q(x)。展开式示例如下：<br />
<span class="math display">\[  
\begin{array}{c}  
H\left(P_{1}, Q_{1}\right)=-\sum_{i} P_{1}(i) \log _{2} Q_{1}(i) \\  
=-(1 \log 0.4+0 \log 0.3+0 \log 0.05+0 \log 0.05+0 \log 0.2) \approx
0.916  
\end{array}  
\]</span><br />
当预测完全正确，q(x)=1，log(1/q(x))=0，p(x)=1，H(p,q)=0。<br />
当预测概率为40%，q(x)=0.4，log(1/0.4)=0.916，p(x)=1，H(p,q)=0.916，预测不准，loss大。<br />
当预测概率为90%，q(x)=0.9，log(1/0.9)=0.105，p(x)=1，H(p,q)=0.105，预测较准，loss小。<br />
如果说第一项是“狗”，实际也真是狗，第一项的P(x)=1，也希望预测的q(x)接近1（它是个概率取值在0-1之间）；它离1越远(近0)，越要惩罚它。</p>
<h2 id="参考">5 参考</h2>
<h3 id="log曲线">5.1 log曲线</h3>
<p><img
src="/attachments_2023/Pasted%20image%2020230304081642.png" /></p>
]]></content>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>Python对网页内容作词云图分析</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/3_%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/Python%E5%AF%B9%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9%E4%BD%9C%E8%AF%8D%E4%BA%91%E5%9B%BE%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="python对网页内容作词云图分析">Python对网页内容作词云图分析</h1>
<p>#自然语言处理 #Python</p>
<h3 id="在线生成词云图">在线生成词云图</h3>
<ul>
<li>WordArt<br />
定制性比较强，支持中文，但是图中的词需要手动输入。<br />
https://wordart.com/</li>
</ul>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d5d3ec03f588e85b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<ul>
<li>图悦<br />
支持分析大段文字并生成词云图，但是功能相对比较简单。<br />
http://www.picdata.cn/picdata/index.php</li>
</ul>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5118e83c5ab4940b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="python生成词云图">Python生成词云图</h3>
<p>本文介绍使用Python程序生成词云图，它依赖的三方库wordcloud需要编译C++库，在Windows搭建环境比较复杂，建议在Linux系统中安装使用。</p>
<p>下例中使用了urllib库从抓取网页内容，jieba库用于分词，wordcould库用于生成词云，代码如下：</p>
<pre><code>import matplotlib.pyplot as plt  
import jieba  
from wordcloud import WordCloud  
import urllib.request   
import html2text  
%matplotlib inline  
  
#url = &#39;https://mp.weixin.qq.com/s/Pr04533M2chdA3pVA8idNA&#39;  
url = &#39;http://baijiahao.baidu.com/s?id=1645663163087703799&amp;wfr=spider&amp;for=pc&#39;  
page = urllib.request.urlopen(url)  
contents = page.read().decode()  
h = html2text.HTML2Text()  
h.ignore_links=True # 去掉超链接  
text = h.handle(contents)  
text = text.replace(&#39; &#39;, &#39;&#39;)  
text = text.replace(&#39;*&#39;, &#39;&#39;)  
text = text.replace(&#39;\n&#39;, &#39; &#39;)  
cut_text = jieba.cut(text) # 分词  
result = &quot; &quot;.join(cut_text)  
print(result)  
wc = WordCloud(  
    font_path=&#39;simhei.ttf&#39;,  
    background_color=&#39;white&#39;,  
    width=1000,  
    height=600,  
    max_font_size=50,  
    min_font_size=10,  
    max_words=200,  
    mask=plt.imread(None)  #mask图片  
)  
wc.generate(result)  
wc.to_file(None)  #图片保存  
plt.imshow(wc) # 显示图片  
plt.axis(&#39;off&#39;) #关闭坐标  
plt.show()  </code></pre>
<p>读者替换网址后，重新运行即可生成词云图。其中的mask图片用于设置词云的形状，本例中使用了背景为白色，前景为黑色的图片star.jpg（注意使用jpg格式图片），效果如下图所示（左侧为mask，右侧为生成的词云图）：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-528d78ef74d33734.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python数据分析常用工具</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/3_%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/Python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<h1 id="python数据分析常用工具">Python数据分析常用工具</h1>
<p>#大数据 #Python</p>
<h2 id="numpy">1． Numpy：</h2>
<p>科学计算基础包, 提供矩阵数据类型、矢量处理，以及精密的运算库。<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ pip install numpy  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">## 2．	Pandas：  </span><br><span class="line">基于Numpy，最初被作为金融数据分析工具而开发出来，一般用于处理结构化数据。  </span><br><span class="line">```  </span><br><span class="line">$ pip install pandas  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">## 3．	Matplotlib：  </span><br><span class="line">绘制数据图表  </span><br><span class="line">```  </span><br><span class="line">$ pip install matplotlib  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">## 4．	Seaborn：  </span><br><span class="line">在 Matplotlib的基础上进行了更高级的API封装，从而使得作图更加容易。  </span><br><span class="line">```  </span><br><span class="line">$ pip install seaborn  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">## 5．	IPython：  </span><br><span class="line">Python 的交互式 shell，比默认的python shell 好用，支持变量自动补全，自动缩进，支持 bash shell 命令，内置了许多很有用的功能和函数。  </span><br><span class="line">```  </span><br><span class="line">$ sudo apt-get install ipython  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">## 6．	Scipy：  </span><br><span class="line">科学计算中标准问题，包括统计，优化，整合，线性代数模块，傅里叶变换，信号和图像处理，常微分方程求解器等等.  </span><br><span class="line">```  </span><br><span class="line">$ pip install scipy  </span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Stata中常用的数据分析命令</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/3_%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/Stata%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h1 id="stata中常用的数据分析命令">Stata中常用的数据分析命令</h1>
<p>#大数据 #数据分析</p>
<h3 id="常用的数据分析工具">1. 常用的数据分析工具</h3>
<p> Stata、SPSS、SAS、R、Python，甚至Excel都可以做数据分析工作。R和Python是程序员的首选，可以通过编写程序实现成整体的数据清洗、分析、挖掘，还可以增加扩展支持，把一套代码应用于类似的数据分析场景中。对于专业人士（如生物、医疗领域）来说，掌握编程语言的学习成本太高，他们更关注通过工具，方便快捷地得到分析结果，SPSS和Stata主要是图形界面的软件操作，相对来说更为合适。很多专业领域，发论文时都使用了Stata和SPSS软件的分析结果，久而久之，也使该软件成为了该领域的数据分析标准工具。</p>
<p>###2 . Stata安装和运行<br />
 我下载的是Stata 15.1 Linux
版本，下载到本地解包后，可看到工具stata和xstata，它们分别是命令行版本和图形界面版本，图形界面中也可以使用命令，运行xstata：<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ./xstata  </span><br><span class="line">```  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/5357893-ae5ee6a0caa49f94.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line">&amp;emsp; 可在其下方的框内输入Stata命令回车运行，该软件中最常用的三个菜单是：Data（数据处理）、Graphic（画图）和Statistic（统计）。功能非常丰富，包括很多二级三级子菜单，下文将介绍一些最常用的功能。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 3. Stata数据导入   </span><br><span class="line">&amp;emsp;Stata数据导入主要有两种方式，一种是从文件导入，另一种是手动编辑内容。用文件菜单中的Open打开文件，支持Stata定义的数据’*.dta’，图表’*.gph’等文件类型（Python的Pandas支持导出Stata文件类型，但默认不支持中文字段名），还可通过文件菜单中的Import导入Excel、csv、dbf等常用格式数据。另外，也可以通过界面上方的New Do-file Editer或Data Editer手动创建新的数据，以及编辑现有数据，编辑界面支持复制粘贴功能。  可以看到，每次通过菜单操作后，界面中间的窗口中都显示出操作对应的命令，我们可以把常用的命令记录下来，以便后期通过命令行方式快速调用。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 4. Stata常用数据分析命令  </span><br><span class="line">**(1) 变量相关**  </span><br><span class="line">生成新变量   </span><br><span class="line">```  </span><br><span class="line">. gen a=3   </span><br><span class="line">```  </span><br><span class="line">改变量名   </span><br><span class="line">```  </span><br><span class="line">. rename a b   </span><br><span class="line">```  </span><br><span class="line">改变量值   </span><br><span class="line">```  </span><br><span class="line">. replace b=5  </span><br><span class="line">```  </span><br><span class="line">删除变量  </span><br><span class="line">```  </span><br><span class="line">. drop b   </span><br><span class="line">```  </span><br><span class="line">计算器   </span><br><span class="line">```  </span><br><span class="line">. display 2+3  </span><br><span class="line">```  </span><br><span class="line">**(2) 文件目录相关**  </span><br><span class="line">切换目录  </span><br><span class="line">```  </span><br><span class="line">. cd /tmp/   </span><br><span class="line">```  </span><br><span class="line">查看目录下文件   </span><br><span class="line">```  </span><br><span class="line">. ls   </span><br><span class="line">```  </span><br><span class="line">打开数据文件   </span><br><span class="line">```  </span><br><span class="line">. use xxx.dta   </span><br><span class="line">```  </span><br><span class="line">导入excel文件中名为“首页”的sheet页   </span><br><span class="line">```  </span><br><span class="line">. import excel &quot;/tmp/xxx.xlsx&quot;, sheet(&quot;首页&quot;)   </span><br><span class="line">```  </span><br><span class="line">保存文件   </span><br><span class="line">```  </span><br><span class="line">. save /tmp/a.dta   </span><br><span class="line">```  </span><br><span class="line">退出   </span><br><span class="line">```  </span><br><span class="line">. exit  </span><br><span class="line">```  </span><br><span class="line">**(3) 数据表相关**    </span><br><span class="line">展示当前数据表内容   </span><br><span class="line">```  </span><br><span class="line">. list  </span><br><span class="line">```   </span><br><span class="line">看当前数据格式  </span><br><span class="line">```  </span><br><span class="line">. describe  </span><br><span class="line">```  </span><br><span class="line">查看统计数据，包含：例数(Obs)、变量的平均值(Mean)、标准差、最小值和最大值   </span><br><span class="line">```  </span><br><span class="line">. sum  </span><br><span class="line">```   </span><br><span class="line">计算尔尔森系数  </span><br><span class="line">```  </span><br><span class="line">. pwcorr y x,sig   </span><br><span class="line">```  </span><br><span class="line">计算斯皮尔曼系数   </span><br><span class="line">```  </span><br><span class="line">. spearman y x   </span><br><span class="line">```  </span><br><span class="line">计算kwallis检验值   </span><br><span class="line">```  </span><br><span class="line">. kwallis y,by(x)  </span><br><span class="line">```  </span><br><span class="line">计算F检验值   </span><br><span class="line">```  </span><br><span class="line">. oneway y x   </span><br><span class="line">```  </span><br><span class="line">多元线性回归   </span><br><span class="line">```  </span><br><span class="line">. regress y x1 x2 x3…  </span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>数据分析</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>TableOne数据分析工具</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/3_%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/TableOne%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<h1 id="tableone数据分析工具">TableOne数据分析工具</h1>
<p>#大数据 #Python #数据分析</p>
<p>前面学习了统计描述和统计假设的Python方法，分析数据表时，需要先确定因变量Y，然后对自变量X逐一分析，最后将结果组织成数据表作为输出，还是比较麻烦，使用TableOne工具可以简化这一过程。</p>
<p>TableOne是生成统计表的工具，常用于生成论文中的表格，TableOne底层也基于scipy和statsmodels模块实现，其代码主要实现了根据数据类型调用不同统计工具，以及组织统计结果的功能。它支持Python和R两种语言，可使用以下方法安装:<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ pip install tableone  </span><br><span class="line">```  </span><br><span class="line">TableOne的核心代码只有800多行，建议下载其源码，阅读核心代码文件tableone.py，以了解其全部功能和工作流程，并从中借鉴统计分析的具体方法。  </span><br><span class="line">```  </span><br><span class="line">git clone https://github.com/tompollard/tableone  </span><br><span class="line">```  </span><br><span class="line">下例中分析了96年美国大选数据，用groupby参数指定了其因变量，categorical参数指定了自变量中的分类型变量，使用pval=True指定了需要计算假设检验结果，程序最后将结果保存到excel文件中。  </span><br><span class="line">```  </span><br><span class="line">import statsmodels as sm  </span><br><span class="line">import tableone   </span><br><span class="line">  </span><br><span class="line">data = sm.datasets.anes96.load_pandas().data  </span><br><span class="line">categorical = [&#x27;TVnews&#x27;, &#x27;selfLR&#x27;, &#x27;ClinLR&#x27;, &#x27;educ&#x27;, &#x27;income&#x27;]   </span><br><span class="line">groupby = &#x27;vote&#x27;  </span><br><span class="line">mytable = tableone.TableOne(data, categorical=categorical,   </span><br><span class="line">                            groupby=groupby, pval=True)  </span><br><span class="line">mytable.to_excel(&quot;a.xlsx&quot;)  </span><br><span class="line"># from xieyan jianshu blog  </span><br><span class="line">```  </span><br><span class="line">表列出了程序的部分输出结果，对于连续变量popul，在统计检验中，用两样本T检验方法计算出p值，在统计描述中，计算出popul的均值和标准差；对于分类变量TWnews，使用卡方检验计算出其p值，并统计出其各分类的例数及占比；表中还展示出对于因变量各类别的记数，空值个数，离群点，以及非正态变量的统计结果。  </span><br><span class="line">  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/5357893-337f060edf464263.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line">对于分类型因变量，使用groupby指定其变量名，对于连续型因变量，一般不指定groupby值，TableOne只进行统计描述。  </span><br><span class="line">  </span><br><span class="line">作为小工具，TableOne也有它的局限性，比如它只能对分类型的因变量Y做统计假设，又如它只能按数据类型自动匹配检验方法，不能手动指定具体的假设检验方法，不支持多变量分析等等，可能解决不了所有数据统计问题。但它使用方便，大大简化了分析流程，能在分析初期展示出数据的概况，尤其对于不太熟悉数据分析方法的编程者给出了较好的统计结果。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 技巧  </span><br><span class="line">table.cont_table用于连续变量--&gt;读取DataFrame格式  </span><br><span class="line">table.cat_table 用于离散变量--&gt;读取DataFrame格式  </span><br><span class="line">table.tableone  用于整体输出--&gt;读取DataFrame格式  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 选取P值小于0.05的  </span><br><span class="line">```  </span><br><span class="line">def conv(x):  </span><br><span class="line">    if isinstance(x, str) and x[0] == &#x27;&lt;&#x27;:  </span><br><span class="line">        x = x[1:]  </span><br><span class="line">    try:  </span><br><span class="line">        return float(x)  </span><br><span class="line">    except Exception as err:  </span><br><span class="line">        print(x)  </span><br><span class="line">          </span><br><span class="line">df_result = mytable.tableone[&#x27;标题xxx&#x27;]  </span><br><span class="line">df_result[&#x27;P-Value&#x27;] = df_result[&#x27;P-Value&#x27;].apply(lambda x: conv(x))  </span><br><span class="line">df_result = df_result[df_result[&#x27;P-Value&#x27;]&lt;0.05]  </span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>数据分析</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>python数据统计分析</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/3_%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/python%E6%95%B0%E6%8D%AE%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="python数据统计分析">python数据统计分析</h1>
<p>#大数据 #数据分析 #Python</p>
<h4 id="常用函数库">1. 常用函数库</h4>
<p> 
scipy包中的stats模块和statsmodels包是python常用的数据分析工具，scipy.stats以前有一个models子模块，后来被移除了。这个模块被重写并成为了现在独立的statsmodels包。</p>
<p> scipy的stats包含一些比较基本的工具，比如：t检验，正态性检验，卡方检验之类，statsmodels提供了更为系统的统计模型，包括线性模型，时序分析，还包含数据集，做图工具等等。</p>
<h3 id="小样本数据的正态性检验">2. 小样本数据的正态性检验</h3>
<p><strong>(1) 用途</strong></p>
<p> 夏皮罗维尔克检验法 (Shapiro-Wilk)
用于检验参数提供的一组小样本数据线是否符合正态分布，统计量越大则表示数据越符合正态分布，但是在非正态分布的小样本数据中也经常会出现较大的W值。需要查表来估计其概率。由于原假设是其符合正态分布，所以当P值小于指定显著水平时表示其不符合正态分布。</p>
<p> 正态性检验是数据分析的第一步，数据是否符合正态性决定了后续使用不同的分析和预测方法，当数据不符合正态性分布时，我们可以通过不同的转换方法把非正太态数据转换成正态分布后再使用相应的统计方法进行下一步操作。</p>
<p><strong>(2) 示例</strong></p>
<pre><code>from scipy import stats  
import numpy as np  
  
np.random.seed(12345678)  
x = stats.norm.rvs(loc=5, scale=10, size=80) # loc为均值，scale为方差  
print(stats.shapiro(x))  
# 运行结果：(0.9654011726379395, 0.029035290703177452)  </code></pre>
<p><strong>(3) 结果分析</strong></p>
<p> 返回结果
p-value=0.029035290703177452，比指定的显著水平（一般为5%）小，则拒绝假设：x不服从正态分布。</p>
<h3 id="检验样本是否服务某一分布">3. 检验样本是否服务某一分布</h3>
<p><strong>(1) 用途</strong></p>
<p> 科尔莫戈罗夫检验(Kolmogorov-Smirnov
test)，检验样本数据是否服从某一分布，仅适用于连续分布的检验。下例中用它检验正态分布。</p>
<p><strong>(2) 示例</strong></p>
<pre><code>from scipy import stats  
import numpy as np  
  
np.random.seed(12345678)  
x = stats.norm.rvs(loc=0, scale=1, size=300)  
print(stats.kstest(x,&#39;norm&#39;))  
# 运行结果：KstestResult(statistic=0.0315638260778347, pvalue=0.9260909172362317)  </code></pre>
<p><strong>(3) 结果分析</strong></p>
<p> 生成300个服从N(0,1)标准正态分布的随机数，在使用k-s检验该数据是否服从正态分布，提出假设：x从正态分布。最终返回的结果，p-value=0.9260909172362317，比指定的显著水平（一般为5%）大，则我们不能拒绝假设：x服从正态分布。这并不是说x服从正态分布一定是正确的，而是说没有充分的证据证明x不服从正态分布。因此我们的假设被接受，认为x服从正态分布。如果p-value小于我们指定的显著性水平，则我们可以肯定的拒绝提出的假设，认为x肯定不服从正态分布，这个拒绝是绝对正确的。</p>
<h3 id="方差齐性检验">4.方差齐性检验</h3>
<p><strong>(1) 用途</strong></p>
<p> 方差反映了一组数据与其平均值的偏离程度，方差齐性检验用以检验两组或多组数据与其均值偏离程度是否存在差异，也是很多检验和算法的先决条件。</p>
<p><strong>(2) 示例</strong></p>
<pre><code>from scipy import stats  
import numpy as np  
  
np.random.seed(12345678)  
rvs1 = stats.norm.rvs(loc=5,scale=10,size=500)    
rvs2 = stats.norm.rvs(loc=25,scale=9,size=500)  
print(stats.levene(rvs1, rvs2))  
# 运行结果：LeveneResult(statistic=1.6939963163060798, pvalue=0.19337536323599344)  </code></pre>
<p><strong>(3) 结果分析</strong></p>
<p> 返回结果 p-value=0.19337536323599344,
比指定的显著水平（假设为5%）大，认为两组数据具有方差齐性。</p>
<h3 id="图形描述相关性">5. 图形描述相关性</h3>
<p><strong>(1) 用途</strong></p>
<p> 最常用的两变量相关性分析，是用作图描述相关性，图的横轴是一个变量，纵轴是另一变量，画散点图，从图中可以直观地看到相关性的方向和强弱，线性正相关一般形成由左下到右上的图形；负相关则是从左上到右下的图形，还有一些非线性相关也能从图中观察到。</p>
<p><strong>(2) 示例</strong></p>
<pre><code>import statsmodels.api as sm  
import matplotlib.pyplot as plt  
data = sm.datasets.ccard.load_pandas().data  
plt.scatter(data[&#39;INCOMESQ&#39;], data[&#39;INCOME&#39;])  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ae99017b07924d6e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><strong>(3) 结果分析</strong></p>
<p> 从图中可以看到明显的正相关趋势。</p>
<h3 id="正态资料的相关分析">6. 正态资料的相关分析</h3>
<p><strong>(1) 用途</strong></p>
<p> 皮尔森相关系数（Pearson correlation
coefficient）是反应俩变量之间线性相关程度的统计量，用它来分析正态分布的两个连续型变量之间的相关性。常用于分析自变量之间，以及自变量和因变量之间的相关性。</p>
<p><strong>(2) 示例</strong></p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">12345678</span>)  </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> np.random.normal(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>)  </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.random.normal(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">100</span>)  </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stats.pearsonr(a, b))  </span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 运行结果：(-0.034173596625908326, 0.73571128614545933)  </span></span></code></pre></div>
<p><strong>(3) 结果分析</strong></p>
<p> 返回结果的第一个值为相关系数表示线性相关程度，其取值范围在[-1,1]，绝对值越接近1，说明两个变量的相关性越强，绝对值越接近0说明两个变量的相关性越差。当两个变量完全不相关时相关系数为0。第二个值为p-value，统计学上，一般当p-value&lt;0.05时，可以认为两变量存在相关性。</p>
<h3 id="非正态资料的相关分析">7. 非正态资料的相关分析</h3>
<p><strong>(1) 用途</strong></p>
<p> 斯皮尔曼等级相关系数(Spearman’s correlation coefficient for ranked
data
)，它主要用于评价顺序变量间的线性相关关系，在计算过程中，只考虑变量值的顺序（rank,
秩或称等级），而不考虑变量值的大小。常用于计算类型变量的相关性。</p>
<p><strong>(2) 示例</strong></p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats  </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stats.spearmanr([<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>], [<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">7</span>]))  </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 运行结果：SpearmanrResult(correlation=0.82078268166812329, pvalue=0.088587005313543812)  </span></span></code></pre></div>
<p><strong>(3) 结果分析</strong></p>
<p> 返回结果的第一个值为相关系数表示线性相关程度，本例中correlation趋近于1表示正相关。第二个值为p-value，p-value越小，表示相关程度越显著。</p>
<h3 id="单样本t检验">8. 单样本T检验</h3>
<p><strong>(1) 用途</strong></p>
<p> 单样本T检验，用于检验数据是否来自一致均值的总体，T检验主要是以均值为核心的检验。注意以下几种T检验都是双侧T检验。</p>
<p><strong>(2) 示例</strong></p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats  </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">12345678</span>)  </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>rvs <span class="op">=</span> stats.norm.rvs(loc<span class="op">=</span><span class="dv">5</span>, scale<span class="op">=</span><span class="dv">10</span>, size<span class="op">=</span>(<span class="dv">100</span>,<span class="dv">2</span>))  </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stats.ttest_1samp(rvs, [<span class="dv">1</span>, <span class="dv">5</span>]))  </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 运行结果：Ttest_1sampResult(statistic=array([ 5.12435977,  1.07927393]), pvalue=array([  1.47820719e-06,   2.83088106e-01]))  </span></span></code></pre></div>
<p><strong>(3) 结果分析</strong></p>
<p> 本例中生成了2列100行的数组，ttest_1samp的第二个参数是分别对两列估计的均值，p-value返回结果，第一列1.47820719e-06比指定的显著水平（一般为5%）小，认为差异显著，拒绝假设；第二列2.83088106e-01大于指定显著水平，不能拒绝假设：服从正态分布。</p>
<h3 id="两独立样本t检验">9. 两独立样本T检验</h3>
<p><strong>(1) 用途</strong></p>
<p> 有于比较两组数据是否来自于同一正态分布的总体。注意：如果要比较的两组数据不满足方差齐性，
需要在ttest_ind()函数中添加参数equal_var = False。</p>
<p><strong>(2) 示例</strong></p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats  </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">12345678</span>)  </span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>rvs1 <span class="op">=</span> stats.norm.rvs(loc<span class="op">=</span><span class="dv">5</span>,scale<span class="op">=</span><span class="dv">10</span>,size<span class="op">=</span><span class="dv">500</span>)    </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>rvs2 <span class="op">=</span> stats.norm.rvs(loc<span class="op">=</span><span class="dv">6</span>,scale<span class="op">=</span><span class="dv">10</span>,size<span class="op">=</span><span class="dv">500</span>)  </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stats.ttest_ind(rvs1,rvs2))  </span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 运行结果：Ttest_indResult(statistic=-1.3022440006355476, pvalue=0.19313343989106416)  </span></span></code></pre></div>
<p><strong>(3) 结果分析</strong></p>
<p> 返回结果的第一个值为统计量，第二个值为p-value，pvalue=0.19313343989106416，比指定的显著水平（一般为5%）大，不能拒绝假设，两组数据来自于同一总结，两组数据之间无差异。</p>
<h3 id="配对样本t检验">10. 配对样本T检验</h3>
<p><strong>(1) 用途</strong></p>
<p> 配对样本T检验可视为单样本T检验的扩展，检验的对象由一群来自正态分布独立样本更改为二群配对样本观测值之差。它常用于比较同一受试对象处理的前后差异，或者按照某一条件进行两两配对分别给与不同处理的受试对象之间是否存在差异。</p>
<p><strong>(2) 示例</strong></p>
<pre><code>from scipy import stats  
import numpy as np  
  
np.random.seed(12345678)  
rvs1 = stats.norm.rvs(loc=5,scale=10,size=500)   
rvs2 = (stats.norm.rvs(loc=5,scale=10,size=500) + stats.norm.rvs(scale=0.2,size=500))   
print(stats.ttest_rel(rvs1,rvs2))  
运行结果：Ttest_relResult(statistic=0.24101764965300979, pvalue=0.80964043445811551)  </code></pre>
<p><strong>(3) 结果分析</strong></p>
<p> 返回结果的第一个值为统计量，第二个值为p-value，pvalue=0.80964043445811551，比指定的显著水平（一般为5%）大，不能拒绝假设。</p>
<h3 id="单因素方差分析">11. 单因素方差分析</h3>
<p><strong>(1) 用途</strong></p>
<p> 方差分析(Analysis of
Variance，简称ANOVA)，又称F检验，用于两个及两个以上样本均数差别的显著性检验。方差分析主要是考虑各组之间的均数差别。</p>
<p> 单因素方差分析（One-wayAnova），是检验由单一因素影响的多组样本某因变量的均值是否有显著差异。</p>
<p> 当因变量Y是数值型，自变量X是分类值，通常的做法是按X的类别把实例成分几组，分析Y值在X的不同分组中是否存在差异。</p>
<p><strong>(2) 示例</strong></p>
<pre><code>from scipy import stats  
a = [47,56,46,56,48,48,57,56,45,57]  # 分组1  
b = [87,85,99,85,79,81,82,78,85,91]  # 分组2  
c = [29,31,36,27,29,30,29,36,36,33]  # 分组3  
print(stats.f_oneway(a,b,c))  
# 运行结果：F_onewayResult(statistic=287.74898314933193, pvalue=6.2231520821576832e-19)  </code></pre>
<p><strong>(3) 结果分析</strong></p>
<p> 返回结果的第一个值为统计量，它由组间差异除以组间差异得到，上例中组间差异很大，第二个返回值p-value=6.2231520821576832e-19小于边界值（一般为0.05）,拒绝原假设,
即认为以上三组数据存在统计学差异，并不能判断是哪两组之间存在差异
。只有两组数据时，效果同 stats.levene 一样。</p>
<h3 id="多因素方差分析">12. 多因素方差分析</h3>
<p><strong>(1) 用途</strong></p>
<p> 当有两个或者两个以上自变量对因变量产生影响时，可以用多因素方差分析的方法来进行分析。它不仅要考虑每个因素的主效应，还要考虑因素之间的交互效应。</p>
<p><strong>(2) 示例</strong></p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.formula.api <span class="im">import</span> ols  </span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.stats.anova <span class="im">import</span> anova_lm  </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>X1 <span class="op">=</span> [<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>]   </span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>X2 <span class="op">=</span> [<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>]  </span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>Y  <span class="op">=</span> [<span class="dv">76</span>,<span class="dv">78</span>,<span class="dv">76</span>,<span class="dv">76</span>,<span class="dv">76</span>,<span class="dv">74</span>,<span class="dv">74</span>,<span class="dv">76</span>,<span class="dv">76</span>,<span class="dv">55</span>,<span class="dv">65</span>,<span class="dv">90</span>,<span class="dv">65</span>,<span class="dv">90</span>,<span class="dv">65</span>,<span class="dv">90</span>,<span class="dv">90</span>,<span class="dv">79</span>,<span class="dv">70</span>,<span class="dv">90</span>, <span class="dv">88</span>,<span class="dv">76</span>,<span class="dv">76</span>,<span class="dv">76</span>,<span class="dv">56</span>,<span class="dv">76</span>,<span class="dv">76</span>,<span class="dv">98</span>,<span class="dv">88</span>,<span class="dv">78</span>,<span class="dv">65</span>,<span class="dv">67</span>,<span class="dv">67</span>,<span class="dv">87</span>,<span class="dv">78</span>,<span class="dv">56</span>,<span class="dv">54</span>,<span class="dv">56</span>,<span class="dv">54</span>,<span class="dv">56</span>]   </span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> &#123;<span class="st">&#39;T&#39;</span>:X1, <span class="st">&#39;G&#39;</span>:X2, <span class="st">&#39;L&#39;</span>:Y&#125;  </span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)  </span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>formula <span class="op">=</span> <span class="st">&#39;L~T+G+T:G&#39;</span> <span class="co"># 公式                                          </span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ols(formula,df).fit()  </span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(anova_lm(model))  </span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;  </span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co">运行结果：  </span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="co">            df    sum_sq      mean_sq         F    PR(&gt;F)  </span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co">T          1.0   265.225   265.225000  2.444407  0.126693  </span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="co">G          1.0   207.025   207.025000  1.908016  0.175698  </span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co">T:G        1.0  1050.625  1050.625000  9.682932  0.003631  </span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co">Residual  36.0  3906.100   108.502778       NaN       NaN  </span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;</span>  </span></code></pre></div>
<p><strong>(3) 结果分析</strong></p>
<p> 上述程序定义了公式，公式中，"~"用于隔离因变量和自变量，”+“用于分隔各个自变量，
":"表示两个自变量交互影响。从返回结果的P值可以看出，X1和X2的值组间差异不大，而组合后的T:G的组间有明显差异。</p>
<h3 id="卡方检验">13. 卡方检验</h3>
<p><strong>(1) 用途</strong></p>
<p> 上面介绍的T检验是参数检验，卡方检验是一种非参数检验方法。相对来说，非参数检验对数据分布的要求比较宽松，并且也不要求太大数据量。卡方检验是一种对计数资料的假设检验方法，主要是比较理论频数和实际频数的吻合程度。常用于特征选择，比如，检验男人和女人在是否患有高血压上有无区别，如果有区别，则说明性别与是否患有高血压有关，在后续分析时就需要把性别这个分类变量放入模型训练。</p>
<p> 基本数据有R行C列, 故通称RC列联表(contingency table),
简称RC表，它是观测数据按两个或更多属性（定性变量）分类时所列出的频数表。</p>
<p><strong>(2) 示例</strong></p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> chi2_contingency  </span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">12345678</span>)  </span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.random.randint(<span class="dv">2</span>, size<span class="op">=</span>(<span class="dv">40</span>, <span class="dv">3</span>)) <span class="co"># 2个分类，50个实例，3个特征  </span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame(data, columns<span class="op">=</span>[<span class="st">&#39;A&#39;</span>, <span class="st">&#39;B&#39;</span>, <span class="st">&#39;C&#39;</span>])  </span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>contingency <span class="op">=</span> pd.crosstab(data[<span class="st">&#39;A&#39;</span>], data[<span class="st">&#39;B&#39;</span>]) <span class="co"># 建立列联表  </span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(chi2_contingency(contingency)) <span class="co"># 卡方检验  </span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;  </span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co">运行结果：  </span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co">(0.36556036556036503, 0.54543425102570975, 1,   </span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co">array([[ 10.45,   8.55],  </span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="co">       [ 11.55,   9.45]]))&#39;&#39;&#39;</span>  </span></code></pre></div>
<p><strong>(3) 结果分析</strong></p>
<p> 卡方检验函数的参数是列联表中的频数，返回结果第一个值为统计量值，第二个结果为p-value值，p-value=0.54543425102570975，比指定的显著水平（一般5%）大，不能拒绝原假设，即相关性不显著。第三个结果是自由度，第四个结果的数组是列联表的期望值分布。</p>
<h3 id="单变量统计分析">14. 单变量统计分析</h3>
<p><strong>(1) 用途</strong></p>
<p> 单变量统计描述是数据分析中最简单的形式，其中被分析的数据只包含一个变量，不处理原因或关系。单变量分析的主要目的是通过对数据的统计描述了解当前数据的基本情况，并找出数据的分布模型。</p>
<p> 单变量数据统计描述从集中趋势上看，指标有：均值，中位数，分位数，众数；从离散程度上看，指标有：极差、四分位数、方差、标准差、协方差、变异系数，从分布上看，有偏度，峰度等。需要考虑的还有极大值，极小值（数值型变量）和频数，构成比（分类或等级变量）。</p>
<p> 此外，还可以用统计图直观展示数据分布特征，如：柱状图、正方图、箱式图、频率多边形和饼状图。</p>
<h3 id="多元线性回归">15. 多元线性回归</h3>
<p><strong>(1) 用途</strong></p>
<p> 多元线性回归模型（multivariable linear regression model
），因变量Y（计量资料）往往受到多个变量X的影响，多元线性回归模型用于计算各个自变量对因变量的影响程度，可以认为是对多维空间中的点做线性拟合。</p>
<p><strong>(2) 示例</strong></p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm   </span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> sm.datasets.ccard.load_pandas().data  </span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(endog <span class="op">=</span> data[<span class="st">&#39;AVGEXP&#39;</span>], exog <span class="op">=</span> data[[<span class="st">&#39;AGE&#39;</span>,<span class="st">&#39;INCOME&#39;</span>,<span class="st">&#39;INCOMESQ&#39;</span>,<span class="st">&#39;OWNRENT&#39;</span>]]).fit()  </span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.summary())  </span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;  </span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co">运行结果：  </span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co">                            OLS Regression Results                              </span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co">==============================================================================  </span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co">Dep. Variable:                 AVGEXP   R-squared:                       0.543  </span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co">Model:                            OLS   Adj. R-squared:                  0.516  </span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co">Method:                 Least Squares   F-statistic:                     20.22  </span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co">Date:                Thu, 31 Jan 2019   Prob (F-statistic):           5.24e-11  </span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co">Time:                        15:11:29   Log-Likelihood:                -507.24  </span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co">No. Observations:                  72   AIC:                             1022.  </span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co">Df Residuals:                      68   BIC:                             1032.  </span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co">Df Model:                           4                                           </span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="co">Covariance Type:            nonrobust                                           </span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="co">==============================================================================  </span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="co">                 coef    std err          t      P&gt;|t|      [0.025      0.975]  </span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="co">------------------------------------------------------------------------------  </span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="co">AGE           -6.8112      4.551     -1.497      0.139     -15.892       2.270  </span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="co">INCOME       175.8245     63.743      2.758      0.007      48.628     303.021  </span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="co">INCOMESQ      -9.7235      6.030     -1.613      0.111     -21.756       2.309  </span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="co">OWNRENT       54.7496     80.044      0.684      0.496    -104.977     214.476  </span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="co">==============================================================================  </span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="co">Omnibus:                       76.325   Durbin-Watson:                   1.692  </span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="co">Prob(Omnibus):                  0.000   Jarque-Bera (JB):              649.447  </span></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a><span class="co">Skew:                           3.194   Prob(JB):                    9.42e-142  </span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="co">Kurtosis:                      16.255   Cond. No.                         87.5  </span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a><span class="co">==============================================================================  </span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;&#39;&#39;</span>  </span></code></pre></div>
<p><strong>(3) 结果分析</strong></p>
<p> 直接通过返回结果中各变量的P值与0.05比较，来判定对应的解释变量的显著性，P&lt;0.05则认为自变量具有统计学意义，从上例中可以看到收入INCOME最有显著性。</p>
<h3 id="逻辑回归">16. 逻辑回归</h3>
<p><strong>(1) 用途</strong></p>
<p> 当因变量Y为2分类变量（或多分类变量时）可以用相应的logistic回归分析各个自变量对因变量的影响程度。</p>
<p><strong>(2) 示例</strong></p>
<pre><code>import statsmodels.api as sm  
data = sm.datasets.ccard.load_pandas().data  
data[&#39;OWNRENT&#39;] = data[&#39;OWNRENT&#39;].astype(int)  
model = sm.Logit(endog = data[&#39;OWNRENT&#39;], exog = data[[&#39;AVGEXP&#39;,&#39;AGE&#39;,&#39;INCOME&#39;,&#39;INCOMESQ&#39;]]).fit()  
print(model.summary())  
&#39;&#39;&#39;  
运行结果：  
Optimization terminated successfully.  
         Current function value: 0.504920  
         Iterations 8  
                           Logit Regression Results                             
==============================================================================  
Dep. Variable:                OWNRENT   No. Observations:                   72  
Model:                          Logit   Df Residuals:                       68  
Method:                           MLE   Df Model:                            3  
Date:                Fri, 01 Feb 2019   Pseudo R-squ.:                  0.2368  
Time:                        17:05:47   Log-Likelihood:                -36.354  
converged:                       True   LL-Null:                       -47.633  
                                        LLR p-value:                 4.995e-05  
==============================================================================  
                 coef    std err          z      P&gt;|z|      [0.025      0.975]  
------------------------------------------------------------------------------  
AVGEXP         0.0002      0.001      0.228      0.820      -0.002       0.002  
AGE            0.0853      0.042      2.021      0.043       0.003       0.168  
INCOME        -2.5798      0.822     -3.137      0.002      -4.191      -0.968  
INCOMESQ       0.4243      0.126      3.381      0.001       0.178       0.670  
==============================================================================  
&#39;&#39;&#39;  </code></pre>
<p><strong>(3) 结果分析</strong></p>
<p> 直接通过返回结果中各变量的P值与0.05比较，来判定对应的解释变量的显著性，P&lt;0.05则认为自变量具有统计学意义。</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>数据分析</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析_列线图工具_Nomogram</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/3_%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E5%88%97%E7%BA%BF%E5%9B%BE%E5%B7%A5%E5%85%B7_Nomogram/</url>
    <content><![CDATA[<h3 id="定义">定义</h3>
<p>列线图是一种相对传统的分析方法，用于展示自变量和因变量的线性关系，及其特征的重要程度。<br />
现在用SHAP，和机器学习库中的 Feature importance
工具可以实现类似甚至更好效果。不过很多传统的研究领域比较认这种方法。<br />
列线图工具建立在多因素回归分析的基础上，将多个预测指标进行整合，然后采用带有刻度的线段，按照一定的比例绘制在同一平面上，从而用以表达预测模型中各个变量之间的相互关系。</p>
<h3 id="原理">原理</h3>
<p>先使用多因素回归（逻辑回归，Cox回归）得出的结果，然后根据回归系数算出Nomogram及画图。</p>
<h3 id="处理流程">处理流程</h3>
<p>主要操作流程如下：<br />
* 数据处理：<br />
* 去掉共线性特征（VIF判断多重共线性）<br />
* 去掉单因素分析中不显著的特征<br />
* 去掉加了和不加对模型没什么影响的特征（LASSO回归）<br />
* 做多因素回归<br />
* 用回归结果做Nomogram，将结果图形化</p>
<h3 id="怎么看图">怎么看图</h3>
<p><img
src="/attachments_2023/Pasted%20image%2020230211162419.png" /><br />
Points： 第一行是标尺<br />
前几行是特征重要性<br />
Total Points: 所有指标加在一起的得分<br />
Risk：对应风险值</p>
<h3 id="工具">工具</h3>
<p>R语言实现方法，详见：<a
href="http://www.360doc.com/content/20/0616/17/37126131_918827972.shtml">Nomogram图不会画?看了这篇,小白也能轻松看懂搞定</a><br />
Python没有Nomogram相关工具包，需要自己实现，详见：<br />
<a
href="https://blog.csdn.net/qq_40985985/article/details/119738620">使用Python，matplotlib绘制Nomogram列线图</a></p>
<h3 id="注意事项">注意事项</h3>
<ul>
<li>如果是数值型变量，乘了系数后影响可能比0/1项大很多<br />
</li>
<li>可将数据值数据通过分界点转成0/1，分界点的选择方法：可用单变量做回归后代入模型，找到AUC最佳点（Youden
index）；或者仅用单变量做一个二分类树，让模型自动选分界点。</li>
</ul>
]]></content>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析工具_SuperSet</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/3_%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7_SuperSet/</url>
    <content><![CDATA[<h2 id="介绍">介绍</h2>
<p>SuperSet是一款开源可视化BI（商业智能）Web应用程序。它通过创建和分享dashboard，为数据分析提供了轻量级的数据查询和可视化方案。其优点如下：<br />
* 不需要自己去搭服务，写前端页面，直接生成分析图<br />
* 可接入多种数据源<br />
* 安装方便，学习成本较低</p>
<h2 id="安装">安装</h2>
<p>使用docker安装启动方法如下：</p>
<pre><code>docker search superset  
docker pull amancevice/superset # 星最多，最新版的  
mkdir -p /opt/module/docker/superset/conf   
mkdir -p /opt/module/docker/superset/data  
# 启动  
docker run --name superset -u 0 -d -p 8088:8088 -v /opt/module/docker/superset/conf:/etc/superset -v /opt/module/docker/superset/data:/var/lib/superset amancevice/superset  
# 进入docker  
docker exec -it superset bash  
&gt; superset db upgrade  
&gt; superset fab create-admin  
&gt; superset fab create-admin # 设用户名密码，我都设了admin  
&gt; superset init  
&gt; superset run --with-threads --reload --debugger # 启动  </code></pre>
<p>此时在本机的8088端口启动了该服务，通过用户名密码即可访问。<br />
之后可用以下命令启动此镜像：</p>
<pre><code>docker start superset  </code></pre>
<h2 id="使用">使用</h2>
<ul>
<li>增加库<br />
上方菜单-&gt;Data-&gt;Databases-&gt;右上add
DATABASE，此时可加入MySQL等各种数据库作为数据源，输入信息后可显示在列表中。<br />
</li>
<li>增加表<br />
上方菜单-&gt;Data-&gt;Datasets-&gt;右上角add
DATASET，选库中的表即可即可显示在列表中。<br />
</li>
<li>建立dashboard仪表盘
<ul>
<li>上方菜单-&gt;Dashboard-&gt;右上角add DASHBOARD<br />
</li>
<li>按提示建一个Chart，在该界面选一个表作为数据源，然后选数据表类型，点下方的CREATE
NEW CHART<br />
</li>
<li>选择想要展示的列（Query-&gt;METRICS），可通过写SQL或者选列的方式设置在图中显示的具体内容<br />
</li>
<li>点击下方CREATE_CHART，即可在右侧看到图表<br />
</li>
<li>点击右上方保存，即可将其保存到CHART及DASHBOARD中</li>
</ul></li>
</ul>
<h2 id="参考">参考</h2>
<p>使用方法详见：<a
href="https://blog.csdn.net/m0_37606374/article/details/120386913">Superset
使用手册 -- 从入门到精通 （基本使用+权限管理+可视化实时刷新）
爆肝七天力作</a></p>
]]></content>
      <tags>
        <tag>工具</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析软件SPSS及数据挖掘软件WEKA使用</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/3_%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%BD%AF%E4%BB%B6SPSS%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E8%BD%AF%E4%BB%B6WEKA%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h1
id="数据分析软件spss及数据挖掘软件weka使用">数据分析软件SPSS及数据挖掘软件WEKA使用</h1>
<p>#数据分析</p>
<p>1. 说明<br />
从数据表中读入数据，用 SPSS 进行数据处理，然后用 WEKA 进行数据分析。</p>
<p>2. EXCEL</p>
<ol type="1">
<li><p>目的<br />
用 java 将其它数据写入 EXCEL</p></li>
<li><p>读写 excel 的 jar 包 jexcelapi 从此处下载<br />
<a
href="http://www.andykhan.com/jexcelapi/download.html">http://www.andykhan.com/jexcelapi/download.html<br />
</a></p></li>
<li><p>java 读写 excel 例程示例<br />
<a
href="http://www.javaeye.com/topic/55844">http://www.javaeye.com/topic/55844</a><br />
<a
href="http://mengqingyu.javaeye.com/blog/440358">http://mengqingyu.javaeye.com/blog/440358<br />
</a></p></li>
</ol>
<p>3. 数据分析软件 SPSS （占据 90% 市场分额）</p>
<ol type="1">
<li><p>目的<br />
整理数据，分析数据，结果展示</p></li>
<li><p>读入数据</p></li>
</ol>
<ol type="a">
<li><p>方法一：从 excel 中复制单元格，粘贴在 SPSS 中</p></li>
<li><p>直接打开 excel 文件 (*.xls) ，注意因为版本原因，用 java 写的 xls
有的需要再用 excel<br />
转存一下才能供 SPSS 使用</p></li>
</ol>
<ol start="3" type="1">
<li>操作数据</li>
</ol>
<ol type="a">
<li>数据处理</li>
</ol>
<ol type="i">
<li><p>修改字段类型<br />
从 SPSS 左下角的进入 Variable View 选项卡，可改变字段的类型值<br />
Meature 数据量度 : Scale( 数值 ), Ordinal( 可排序 ), Nominal( 离散
)</p></li>
<li><p>计算新变量<br />
菜单 Transform-&gt;Compute varliable ，将根据现有列计算出新列</p></li>
<li><p>排序<br />
菜单 Transform-&gt;Rank cases 生成新列，新列中是排序号</p></li>
<li><p>修改内容<br />
菜单 Transform-&gt;Record into xxx
，根据某列数据通过某种算法产生新数据</p></li>
<li><p>文件操作<br />
菜单 Data-&gt;Merge File</p></li>
<li><p>数据整理：<br />
菜单 Data-&gt;Select Cases ，数据选择<br />
菜单 Data-&gt;Weight Cases ，数据加权</p></li>
</ol>
<ol start="2" type="a">
<li>数据分析</li>
</ol>
<ol type="i">
<li><p>生成关系矩阵<br />
菜单 Analyze-&gt;Correlate-&gt;Bivariate
，生成矩阵，数越大，相关性越大</p></li>
<li><p>生成 K 均值聚簇<br />
菜单 Analyze-&gt;Classify-&gt;K-Means cluster ，将需计算的数据放入
Variables ，说明列放入 Label<br />
Cases by ，在 Iterate 中设置迭代次数， Number of clusters
中输入簇数，选中 Save<br />
中项，以生成列（记录属于哪个簇，与簇心的距离）</p></li>
</ol>
<ol start="3" type="a">
<li><p>数据描述，结果展示：<br />
菜单 Graphs</p></li>
<li><p>注意：开始使用时，数据最好转成 int 型，以便于计算</p></li>
</ol>
<ol start="4" type="1">
<li>菜单说明<br />
Data 菜单：操作行<br />
Transform 菜单：操作列<br />
Analyze 菜单：数据分析，主要是聚类和分类方法</li>
</ol>
<p>4. 数据挖掘软件 WEKA</p>
<ol type="1">
<li><p>目的<br />
数据分析</p></li>
<li><p>读入数据</p></li>
</ol>
<ol type="a">
<li><p>使用 SPSS 和 Excel 保存为 csv 文件 ( 文本格式的数据文件
)</p></li>
<li><p>在预处理选项卡中用 Open file 打开 csv 文件，注意 csv
中不能含有特殊字符</p></li>
<li><p>WEKA 中默认的文本格式为 arff
，也是一种文本格式的数据文件</p></li>
</ol>
<ol start="3" type="1">
<li>操作数据</li>
</ol>
<ol type="a">
<li><p>分类<br />
选项卡 Classify 选择 Choose-&gt;trees-&gt;J48 或 ID3 (ID3 只能处理离散值
) ，生成决策树</p></li>
<li><p>关联<br />
选项卡 Associate 选择 Choose-&gt;apriori ，在按钮右侧通过点击设置支持度
(lowerBoundMinSuport)<br />
，可信度 (upperBoundMinSupport) ， apriori 需要离散化数据</p></li>
</ol>
<p>5. 参考</p>
<ol type="1">
<li>《 spss 数据统计分析与实践》 pdf 文档</li>
</ol>
]]></content>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据挖掘之_后处理</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/3_%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B9%8B_%E5%90%8E%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<h1 id="数据挖掘之_后处理">数据挖掘之_后处理</h1>
<p>#机器学习 #特征工程</p>
<p> 常常听说数据预处理，后处理相对少见，本篇来说说何时需要后处理，以及后处理的一些简单方法。</p>
<p> 数据挖掘的流程一般是：输入数据-&gt;特征工程-&gt;模型训练/预测-&gt;导出结果。后处理是将模型预测的结果进一步处理后，再导出。</p>
<p> 先看一个例子：比如我们网购小包装的咖啡，一般的购买习惯是，在少量购买时，需要多少买多少：一包，两包，三包；买的较多的时候，可能是六包，八包，十包；买得更多的情况下，可能是十包，十五包，二十包；再往上是三十包，四十包，五十包，一百包……以此类推。</p>
<p> 也就是说：数量大的时候，我们可能更倾向于取整，双数，五的倍数，十的倍数等等。如果不是针对人数买的话，一般不会出现7,
19,
113这样的购买数量。如下图示意：横轴代表购买数量，纵轴代表该数量出现的次数。蓝色为实际购买数据，橙色为预测数据。注意本图是结果y的分布图。　</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-b14b7ecc9324ebf2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 想在模型和预测处理中优化比较困难，因为对于测试集，并不知道预测的结果是多少，于是也无法将它是否靠近2,5,10的倍数作为特征代入模型。<br />
此时可使用后处理，让橙线靠近蓝线，最简单的方法是手写判断语句，例如：如果大于12.5则预测为15等等。但相对比较麻烦，很多边界值需要手动调节，换了数据之后，还需要重新调节。</p>
<p> 我想到一种自动处理的方法，还算简单有效，在此分享一下。假设我们预测出购买量是13.5红色点（因为是回归，有可能是非整数）。一般情况下我们会四取五入，得到结果14。下面来看看怎么用算法优化。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-71ca9d0ec064e700.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 先找到它前后的两个点13和14，确定它在图中的位置，即红色的点，然后再从该点到它前后的距离N以内的高点连线（黄色区域限定距离），取其中斜率最大的线所对应的高点，这样兼顾了高度和距离。用此方法，我们将12.5取15。</p>
<p> 有时候，我们还要考虑给红点左右的线段分配不同的权重，比如说：如果一共37个人，人手一个，可能会考虑破损，意外，留出余量买到40个，而不会故意少买成35个，导致不够分。在此情况下，只要比较斜率时给右侧线多乘一些权重即可。</p>
<p> 还有一种常见情况：有时候做回归，预测不出很大或很少值，所有数值都集中在中部区域，比如之前糖尿病预测的初赛，大家都使用GBDT类模型，很多人都预测不出血糖大于10的，几乎所有结果都在5-8之间。这是由于这种迭代模型，追求的是整体误差最小化，为了保证绝大多数预测正确，就牺牲了人少但血糖高的部分。但实际场景中，如果不能预测高血糖，模型就没用了。后来也有人用了一些后处理方法，即把偏离正常范围值的乘一个系数，手动拉宽预测范围。其实也可以使用类似上述方法的思路解决。</p>
<p> 在二分类问题中，一般能得到的是0-1之间的概率值，此时把界限从0.5上移或者下移即可实现后处理。方法很多，这里只是抛砖引玉吧，如果各位有更好的方法，欢迎给我留言。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
      </tags>
  </entry>
  <entry>
    <title>特征工程之_筛选</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/3_%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E4%B9%8B_%E7%AD%9B%E9%80%89/</url>
    <content><![CDATA[<h1 id="特征工程之_筛选">特征工程之_筛选</h1>
<p>#机器学习 #特征工程</p>
<h2 id="说明">1. 说明</h2>
<p> 本文并非介绍某个成熟算法或者工具，只是个人的一点感悟，写得可能不正确，不全面，希望能给大家带来一些启发，也欢迎各位回复讨论。</p>
<h2 id="特征工程">2. 特征工程</h2>
<p> 大数据相关的工作可简要地归纳为：模型部分和数据部分，在模型部分，目前大家的做法主要是拿现成的模型来用，对其做内部修改或重写的很少，主要工作在选型和调参。<br />
 相对来说，对数据部分做的工作更多，在比赛中数据都是固定的，且很多时候数据已脱敏，特征工程能做的不太多，而真实场景中，往往能从复杂数据中提取更多信息，因此如期何提取以及筛选信息就变得尤为重要。</p>
<h2 id="筛选">3. 筛选</h2>
<p> 筛选分为筛选实例和筛选特征，如果把整体数据看成一张表，就是删行或者删列。<br />
 在实际应用时，常遇到的一个难题是：怎么把人的经验和算法结合起来，特征工程是一个重要的入口，一方面我们可以用经验构造更多特征，另一方面，也可以通过经验选择合理的实例代入模型，以及分配权重。</p>
<h2 id="特征筛选">4. 特征筛选</h2>
<h4 id="为什么筛选">(1) 为什么筛选</h4>
<p> 对特征的筛选主要是去掉无关特征，无关特征一般有两种影响：在数据量大的情况下，影响训练速度，在数据量少的情况下，带来更多误差。像天池的汽车上牌赛和糖尿病预测赛，前几名介绍经验，有的最终砍掉了多一半特征。在去掉无关特征的同时，也突显了主要特征，对进一步提取因果关系，以及解释模型也有很大作用。</p>
<h4 id="如何筛选">(2) 如何筛选</h4>
<p> 有一些特征，明显没啥用，比如缺失值特别多的；和其它特征重复的；某特征的取值对结果不构成任何影响的；另外一些，并不容易察觉，比如某特征对结果有影响，却是一种噪声数据，把模型给带偏了，这种特征一般只能在训练模型的过程中发现。</p>
<h2 id="实例筛选">5. 实例筛选</h2>
<h4 id="为什么选筛">(1) 为什么选筛</h4>
<ol type="i">
<li><p>数据量大<br />
数据并不是越多越好，如果数据量非常大，比如电商中的购买记录，是海量数据，训练起来，任何一个模型都无法承受，此时，可以随机选取一部分数据训练。选取时，尽量均匀采样，可以采取一些规则优先提取更有规律的数据。</p></li>
<li><p>有噪数据<br />
 数据中常有一些显而易见的错误，比如：“身高为162米”，这种单位错误，还有一些缺失数据多或者缺失关键特征的实例。这种错误非常明显，一般是由于操作人员的失误，或者前后版本格式不一致造成的，发现后删除或修改（如果能修正，还可以继续使用），见招拆招就可以了。</p></li>
<li><p>数据不合理<br />
 这种情况非常重要，又常被忽略，人的经验往往能在此处发挥巨大作用。主要的情况有：实例的因果关系不合逻辑；同样的条件引发不同的结果。<br />
 比如某君只得了脚气，结果死了，能不能得出结论说：一定是脚气致死的。也许这个人本身有其它病症（比如心脏病），但在当前的特征中并未提取到。<br />
 也就是说根据已知条件，不能形成任何有效推论，或者形成的推论违背常理，下次遇到了此情况，不能由此因推出此果。与留着这种规则在这儿搅和，不如把它删掉。</p></li>
<li><p>可预测与不可预测――不可避免的黑天鹅事件<br />
 事件的发生，有一部分是可控的，一部分是随机的，像海啸地震，它们是可能发生又无法预期的。我们可以从结果中分析出原因，却无法事先提取“因”作为特征，比如我们知道地震会影响旅游业，却不知何时地震。这样的实例，即使做出了模型，也用不上。对于这种意外事件，也建议去掉。</p></li>
</ol>
<h4 id="如何筛选-1">(2) 如何筛选</h4>
<p> 在一开始统计和分析数据的过程有一些特殊的实例和特征可以被发现。我们也可以选择少量实例，进行人工数据分析。<br />
 在实例和特征都很多，不可能一一过目，且我们也希望让模型自己发现一些规律的情况下，可以尝试：先用所有数据训练一个模型，把数据都代入模型并预测，然后分析主要特征，并把预测结果不正确筛出来分析原因，或者只用正确的单独训练模型。</p>
<h2 id="筛选之后怎么处理">(3) 筛选之后怎么处理</h2>
<p> 特殊数据处理起来相对复杂。它往往取决于数据的质和数据的量。<br />
 比如训练集一共十万条数据，筛完后就剩一万条了，此时模型就变成了一个只适合特殊情况的“小众”逻辑。如果按同样的分布，预测集中也有九成都是不可预测的，此时，就需要先想想那九成不能代入模型的，应该怎么处理？比如实在无法使用模型，用一些统计值（如均值、中值），也不失为一种方法。<br />
 另一种方法是保留大部分数据，但为不同的实例分配不同权重。如果模型支持，可为典型的事例赋予更大的权重，如模型不支持权重设置，简单的方法是构造更多的典型实例代入模型。<br />
 需要注意的是：我们对实例的任何处理，都可能引入误差。是增是删还是改的权衡往往反应的是开发者对数据和业务逻辑的理解。</p>
<h2 id="写在最后">6. 写在最后</h2>
<p> 我们常常觉得某些意外情况发性的概率不大，在海量数据中往往可以忽略不计，因而无需额外处理。但忽略不计的前提是其它大量数据都是有规律可循的；在整体规律不太明显的情况下，还是需要额外处理一下。<br />
 做模型就像养孩子，虽然人类的基因决定，可以通过历练打磨，自我学习，他能从现实中学习出很多的关系和规则，但我们更愿意把“确定是对的”东西直接教给他，这样可以少走很多弯路。<br />
 另外，预测的背后有一个重要因素：不确定性——并不是所有情况都可以被预测，如果我们能把需要预测的问题分为模型“可预测的”和“不可预测”的，比如在操作股票的情况下，只对可预测的情况“作为”，也不失为一种选择。<br />
 实际场景中，我们不只是模型的实现者，作为服务的设计者，能做的更多。比如说提示，由于信息太少，或者缺少关键信息，而无法预测，也好过勉强给出一个瞎蒙的预测结果。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
      </tags>
  </entry>
  <entry>
    <title>特征筛选工具</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/3_%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E7%89%B9%E5%BE%81%E7%AD%9B%E9%80%89%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<h1 id="特征筛选工具">特征筛选工具</h1>
<p>#机器学习 #特征工程</p>
<p>做模型时常常是特征越多模型准确率越高（至少在训练集上）。但过多的特征又增加了数据收集、处理、存储的工作量，以及模型的复杂度。</p>
<p>在保证模型质量的前提下，我们希望尽量少地使用特征，这样也间接地加强了模型的可解释性。一般来说，为避免过拟合，特征尽量控制在实例个数的1/20以下，比如有3000个实例，则特征最好控制在150以下。</p>
<p>除了特征的具体个数，特征工程中也经常遇到某些特征严重缺失，特征相关性强，一些特征不但无法给模型带来贡献，反而带来噪声等问题。</p>
<p>本篇介绍特征筛选工具feature-selector，在github上有1.8K星，它使用少量的代码解决了特征筛选中的常见问题，用法简单，便于扩展；同时也提供了作图方法，以更好地呈现特征效果。</p>
<h4 id="下载地址">下载地址</h4>
<p><a
href="https://github.com/WillKoehrsen/feature-selector">https://github.com/WillKoehrsen/feature-selector</a></p>
<h4 id="核心代码">核心代码</h4>
<p>其核心代码文件只有feature_selector/feature_selector.py（600多行代码），所有方法都定义在FeatureSelector类中，因此，不用安装，只需要将该文件复制你的项目中即可使用。</p>
<h4 id="功能点">功能点</h4>
<ul>
<li>寻找缺失严重的特征<br />
</li>
<li>寻找仅有单值的特征<br />
</li>
<li>寻找相关性强的特征（皮尔森相关系数，默认只考虑数值型）<br />
</li>
<li>寻找特征重要性为0的特征（根据gbm模型）<br />
</li>
<li>寻找特征重要性低的特征（根据gbm模型）</li>
</ul>
<h4 id="示例代码">示例代码</h4>
<p>示例及效果见：Feature Selector Usage.ipynb</p>
<p>代码中使用Kaggle比赛中信用风险预测的数据，为分类问题。</p>
<p>其中包含10000条数据，122个特征；将其TARGET字段作为标签，其它字段作为预测特征。</p>
<p>首先用训练数据建立类的实例：</p>
<p>fs = FeatureSelector(data = train, labels = train_labels)</p>
<p>后面逐一列出了各个函数的用法，此处不再一一列举。</p>
<h4 id="图示">图示</h4>
<p>工具提供plot_xxx等方法具象地展示了数据情况：</p>
<ul>
<li>数据缺失图<br />
该图横坐标为缺失比例，纵坐标为特征个数，例如第一列为缺失比例在0-0.1之间的特征约60多个。</li>
</ul>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-3cd1c79261857b84.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<ul>
<li>特征取值图<br />
该图横坐标为特征取值个数，纵轴为特征个数，例如第一个柱表示将近100个特征取值的个数在1-1000之间，最后一柱表示有几个特征有上万种取值。</li>
</ul>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-2692e2c0966d8506.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<ul>
<li>特征相关性<br />
下图中列出了相关系数大于0.98的特征（未列出所有特征），同时还提供fs.record_collinear()方法列出各个特征对及其相关系数。</li>
</ul>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-67fb6acb5a1976cd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<ul>
<li>特征重要性<br />
工具默认使用lightgbm模型计算特征重要性，在调用方法时需要指定损失函数，以及使用分类方法还是回归方法，迭代次数等等。工具可显示其前N个重要特征。另外，还可以参考下图，查看模型特征个数与模型效果的关系，下图显示：将模型参数简化为122个后，模型准确率几乎不变。</li>
</ul>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-fe12f312fcef68ca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
      </tags>
  </entry>
  <entry>
    <title>EasyNLP</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7/EasyNLP/</url>
    <content><![CDATA[<h2 id="easynlp中文nlp算法框架">EasyNLP中文NLP算法框架</h2>
<ul>
<li>作者：PAI（阿里云人工智能平台）算法团队<br />
</li>
<li>平台：基于PyTorch<br />
</li>
<li>优势：中文预训练模型<br />
</li>
<li>提供：AppZoo和预训练ModelZoo，ModelZoo有很多预训练模型，EasyNLP可以无缝接入huggingface/transformers的模型；AppZoo支持文本分类，文本匹配，序列标注等任务。<br />
</li>
<li>工具：
<ul>
<li>支持小样本训练：Contrastive Prompt Tuning。<br />
</li>
<li>大模型知识蒸馏技术：让跨领域典型性的样本在学习阶段有更大的权重。<br />
</li>
</ul></li>
<li>数据：DataHub还支持一些中文训练数据<br />
</li>
<li>项目开源地址：https://github.com/alibaba/EasyNLP<br />
</li>
<li>蒸馏算法实现：EasyNLP/examples/knowledge_distillation/metakd</li>
</ul>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>初始化网络参数</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7/%E5%88%9D%E5%A7%8B%E5%8C%96%E7%BD%91%E7%BB%9C%E5%8F%82%E6%95%B0/</url>
    <content><![CDATA[<h1 id="初始化网络参数">初始化网络参数</h1>
<p>#深度学习</p>
<h3 id="为什么要给网络参数赋初值">为什么要给网络参数赋初值</h3>
<p>既然网络参数通过训练得到，那么其初值是否重要？设置初值不佳是否只影响收敛速度而不影响模型结果？网络参数是否可以设置为全0或者全1？</p>
<p>假设网络的参数Ｗ初值都是０，如下图所示，无论输入任何Ｘ，第一层的输出Ａ将都为０，再向前传递到y也是0，使用误差函数调参时，每一层的梯度只与该层的输入和输出有关，由于a1,a2值相等，计算出的梯度调整的值，以及调整后的梯度也相等；第二次迭代也同理，由于a1,a2相等，w<sup>[2]</sup>中各单元的值也相等。因此该层有100个单元与1个单元没有差异，该问题被称为“对称性”问题。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-4ed28160008502dc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>试想将w设置成全1，则有a1=x1+x2，a2=x1+x2，a1与a2值仍然相同，对称性问题依然存在。由此，一般将参数设置为随机值。</p>
<p>设置成随机值还不够，还需要设置成较小的随机值，试想如果w的均值在0.5附近，某一层的输入输出都为500个元素，那么经过该层乘和加的运算，输出约是输入值的250倍；如果存在多层，250x250x…，很快就爆炸了。如果在层后使用Sigmoid函数，将值映射到较小的空间，又会发生非线性激活函数的饱和问题，使收敛变慢。</p>
<p>因此，简单的方法是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">W = np.random.randn(o_dim, i_dim) * 0.01     </span><br><span class="line">np.zeros((o_dim, 1))  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">bias不导致对称性，一般设置为0。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 常用的初值化方法  </span><br><span class="line">  </span><br><span class="line">全0或全1的初始化方法不能使用，而随机初始化也存在一些问题，由于各层的输入和输出元素个数不同，这使得每一层输出数据的方差也不同，比如层输入500个元素和5个元素，同等大小的w，输出的大小可能差出百倍。不同层的调参将受到影响。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### Xavier初始化  </span><br><span class="line">  </span><br><span class="line">假设层的输入有三个元素x1,x2,x3，输入为y，权重分别是w1,w2,w3，  </span><br><span class="line">  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/5357893-c891c6d7d120f30f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line">则y值为：  </span><br><span class="line">  </span><br><span class="line">y=w1x1+w2x2+w3x3，在计算参数w的初值时考虑到输入该层元素的个数n：于是出现了Xavier方法。  </span><br><span class="line">  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/5357893-63155b3c50502f1f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### Kaiming初始化  </span><br><span class="line">  </span><br><span class="line">Xavier的问题是，它没有考虑到激活函数对输出数据分布的影响，它会带偏当前广泛使用的ReLU激活函数的结果，于是He Kaiming提取了针对ReLU激活函数的Kaiming初始化（有时也叫作He初始化）。  </span><br><span class="line">  </span><br><span class="line">其原理是：由于ReLU过滤掉了0以下的输入值，因此，激活函数输出的均值将大于0，为解决这和问题，Kaiming方法修改了生成随机数时的标准差。  </span><br><span class="line">  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/5357893-97c4b963899a17d3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line">ReLU过滤掉了一半数据，因此分子乘2，分母是上一层的输出元素个数，即本层的输入元素个数。推导过程请见论文：《Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification》的Section 2.2。  </span><br><span class="line">  </span><br><span class="line">尽管Kaiming初始化一开始主要针对ReLU激活函数优化，但是目前主流库中的Kaiming函数已经支持sigmoid等多种激活函数，可放心调用。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 归一化层  </span><br><span class="line">  </span><br><span class="line">Kaiming的目标也是保证各个层输入和输出数据的方差不变。由于后来归一化层被广泛使用，有效地缓解了均值和方差稳定的问题。因此，在使用归一化层的情况下，使用随机数始初化参数即可。  </span><br><span class="line">  </span><br><span class="line">另外，在有些情况下无法使用归一化层，比如最常用的BN（Batch Normalization）在Batch中数据较少时效果不好，这种情况下就需要选用参数初始化。  </span><br><span class="line">  </span><br><span class="line">在预训练/调优的场景中，一般使用预训练的参数作为模型的初值。  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### Python参数初始化  </span><br><span class="line">  </span><br><span class="line">在使用Pytorch构建网络时，torch.nn中提供了各种常用初始化方法，直接调用即可。下面列出用于初始化网络的某一层或某几层的常用代码。  </span><br><span class="line">    </span><br><span class="line">```  </span><br><span class="line">def init_network_params(model, method=&#x27;xavier&#x27;, keywords, seed=123, debug=False):    </span><br><span class="line">    for name, w in model.named_parameters():    </span><br><span class="line">        init = False    </span><br><span class="line">        for key in keywords:    </span><br><span class="line">            if key in name:    </span><br><span class="line">                init = True    </span><br><span class="line">        if init:    </span><br><span class="line">            if debug:    </span><br><span class="line">                print(&#x27;init layer params&#x27;, name)    </span><br><span class="line">            if &#x27;weight&#x27; in name:    </span><br><span class="line">                if method == &#x27;xavier&#x27;:    </span><br><span class="line">                    nn.init.xavier_normal_(w)    </span><br><span class="line">                elif method == &#x27;kaiming&#x27;:    </span><br><span class="line">                    nn.init.kaiming_normal_(w)    </span><br><span class="line">                else:    </span><br><span class="line">                    nn.init.normal_(w)    </span><br><span class="line">            elif &#x27;bias&#x27; in name:    </span><br><span class="line">                nn.init.constant_(w, 0)    </span><br><span class="line">            else:    </span><br><span class="line">                pass  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">Pytorch中如果不额外设置，线性层的初值设为：（详见torch.nn.modules.linear）：  </span><br><span class="line">  </span><br><span class="line">```  </span><br><span class="line">kaiming_uniform_(self.weight, a=math.sqrt(5))  </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>归一化</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7/%E5%BD%92%E4%B8%80%E5%8C%96/</url>
    <content><![CDATA[<h1 id="归一化">归一化</h1>
<p>#深度学习</p>
<h3 id="为什么使用归一化">为什么使用归一化</h3>
<p>如果输入有多个feature，且它们的数值范围有很大差异，这样训练时学习率就不能设置得太大，以免大幅调参引发越界。反之，如果各个feature有相同的均值和方差，则可使用更高的学习率，使<strong>收敛更快</strong>。归一化解决了梯度爆炸和梯度消失的问题，使构建<strong>更深层的网络</strong>成为可能，还避免了<strong>梯度爆炸和梯度消失</strong>。</p>
<p>使用模型时需要保证训练数据和测试数据同分布。在机器学习中往往对输入数据进行归一化处理，在深度学习中则常对网络的每一层都做归一化处理，以保证每次处理的数据分布一致。这也使得层与层之间更加独立，依赖更小。Batch-Normalize（BN）论文中描述：加入BN方法后，模型训练提速14倍，且精度也有所提升。</p>
<h3 id="convariate-shift漂移问题">Convariate shift（漂移）问题</h3>
<p>从原理上看，归一化缓解了内部协变量的移位问题，即漂移问题。深度神经网络中每一层输入都依赖之前层的输出，在训练的不同阶段，前层输出的分布也不相同。调参幅度越大越可能使分布变化，因此，只能使用较小的学习率，这样又使得收敛变慢。</p>
<p>由调参引发的内部数据分布变化的问题叫做内部协变量的移位问题，也被称作漂移问题。归一化方法可以有效地缓解该问题，它将特定特征的数据表示为均值为０，标准差为１的数据。其物理意义是把数据集映射到原点周围，除了缩放（除标准差）和平移（减均值），一般工具库提供的归一化函数包括affine参数实现仿射变换。其公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-05c486f321097295.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中x为归一化层的输入，y为归一化层的输出，E[x]是均值，Var[x]是方差，weight(γ)和bias(β)是模型的参数，通过训练求得，用于实现仿射变换。ε(eps)是个很小的数用于防止分母为0。在γ为标准差，β为均值的情况下，上述公式未对x进行变换，而这两个参数通过训练求得，可以说在多大程度上进行归一化由模型训练决定。</p>
<h3 id="常用的归一化方法">常用的归一化方法</h3>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-b85b85511d95d607.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><strong>Batch-Normalize（BN）</strong></p>
<p>Batch-Normalize最早提出，也是最常用的归一化方法，其原理已经在前面介绍。在图像处理时，它在batch上，对NHW做归一化。它的缺陷是在batch
size较小的情况下效果不好，而目标检测或者在图片分辨率较大的情况下，又只能使用较小的batch
size。</p>
<p>理论上，上述公式应该对整个训练集计算均值和方差，而实际操作中，每一次只对一个batch中的数据计算统计量（均值/方差），由此引起了噪声，这种噪声类似于Dropout，因此有时BN也能部分实现Dropout的功能，降低模型对某些连接的依赖性，提高模型的泛化能力。但是当batch
size很小时，归一化引入了太多的噪声，导致模型效果变差。为解决这一问题，开发者在BN基础上提出了更多的归一化算法。</p>
<p><strong>Layer-Normalize（LN）</strong></p>
<p>基于BN，在通道方向上，对CHW归一化。常用于RNN任务，但在机器视觉方面达不到BN的精度。</p>
<p><strong>Instance-Normalize（IN）</strong></p>
<p>基于BN，在图像像素上，对HW做归一化，常用于迁移学习，风格转换，在机器视觉方面达不到BN的精度。</p>
<p><strong>Group-Normalize（GN）</strong></p>
<p>基于BN，GroupNorm将channel分组，计算每一组数据的统计值做归一化处理，解决了BN在
batchSize较小的情况下引入大量噪声的问题。</p>
<p><strong>Switchable-Normalize（SN）</strong></p>
<p>将BN、LN、IN结合，赋予权重，让网络自己去学习归一化层应该使用什么方法。</p>
<p>SN结合了BN、LN、IN几种方法，可用于不同任务及不同场景，SN计算了BN，LN，IN三种统计量，然后对统计量加权（权值通过softmax计算），最终计算出归一化值。通过训练动态调节权值，使模型具有更强的鲁棒性，以适应各种场景。</p>
<h3 id="测试阶段的归一化">测试阶段的归一化</h3>
<p>需要注意的是训练集和测试集需要使用同样的归一化方法。以BN为例，训练时，用当前batch中的所有数据计算均值和方差（一般包含32,64,128个样本）。在预测时，如果只对单个样本做预测，只计算单个样本的统计值会产生偏差。可使用如下几种解决方法：</p>
<ul>
<li>使用整个训练集的数据计算统计值。<br />
</li>
<li>从训练集中随机抽取一批数据计算统计值。<br />
</li>
<li>记录训练阶段计算的统计值，使用指数加权平均法计算训练阶段的统计值。</li>
</ul>
<p>一般深度学习框架（如Pytorch）都提供默认的处理方法，如无特殊情况，不用自己写程序实现。</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>浅析梯度迭代算法</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7/%E6%B5%85%E6%9E%90%E6%A2%AF%E5%BA%A6%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h1 id="浅析梯度迭代算法">浅析梯度迭代算法</h1>
<p>#深度学习</p>
<p>梯度迭代类算法已成为目前各种领域的主流算法。各种现实中的问题分解抽象成机器可以处理的形式之后，基本都可归类为图像、自然语言处理、决策、时序、强化学习这几种类型，而当今解决这些问题的顶尖算法中，梯度迭代（梯度上升或梯度下降）都占据主流地位，比如决策类问题的比赛中，梯度下降决策树GBDT类算法是完全的主流，使用深度学习网络处理图片自然语言问题更毋庸置疑。</p>
<p>那么，梯度迭代算法究竟是什么？简单地说，就是代入数据，预测结果，如果结果偏大就调小参数，结果偏小就调大参数。举一个简单的例子，分为三个小问题：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-4654f10dfc126951.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><strong>问题一</strong></p>
<p>假设父亲的智商影响儿子的智商，设父亲的智商为ｘ，儿子的智商为ｙ，y=wx，训练一个参数w学习二者之间的关系。目前有多个父子智商数据对，其中第一个数据：父亲智商x=100，儿子智商w=110，将w初值设为w=1.0；学习率设为0.00001，计算平均误差。</p>
<p>如下程序用于学习w。</p>
<pre><code>import torch    
import matplotlib.pyplot as plt    
%matplotlib inline    
    
x = torch.tensor([100.]) # 只做训练不求梯度    
y = torch.tensor([110.])    
w = torch.tensor([1.], requires_grad=True) # 模拟网络参数    
lr = 0.00001 # 学习率    
arr = []    
        
for i in range(10):    
    pred = x * w    
    loss = (pred-y)*(pred-y) # 平方误差    
    loss.backward() # 计算梯度    
    print(&quot;real&quot;, y.item(), &quot;pred&quot;, pred.item(), &quot;loss&quot;, loss.item())    
    print(&quot;w.data&quot;, w.data.item(), &quot;w.grad&quot;, w.grad.item())    
    w.data = w.data - lr * w.grad # 按学习率调参    
    w.grad.zero_() # 梯度清 0，否则梯度会不断累加    
    arr.append(loss.item())    
    
plt.plot(arr)    </code></pre>
<p>程序中使用了torch的基本数据结构Tensor及其自动计算梯度的功能，模型、优化器、误差函数全部写代码实现。其误差等于实际的y值减预测值的平方，在第一次迭代中计算结果如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-becf1645618da3b3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>求误差函数对参数w的偏导数，用以调节w，具体使用链式法则：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-802f743f8a27e9bb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>然后使用梯度修改参数w，每次修改一个很小的步幅，即学习率。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a3bb4f37bf0645f4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>每次w都变好一点，经过多次迭代，参数w逐渐逼近其真实值，误差也逐渐下降，如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-754950465a0782bd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>此时再代入值x=100，即可得到正确的预测y=110。上述是最简单的情况，为简化操作只训练了一个实例，如果有10000个实例代入训练，反复迭代20次，最终将通过微调的方法得到最为合理的参数ｗ。</p>
<p>使用Pytorch提供的线性层、误差函数和优化器，功能与上面的程序一致，代码更加简单：</p>
<pre><code>import torch    
    
x = torch.tensor([100.]) # 只做训练不求梯度    
y = torch.tensor([110.])    
lr = 0.00001 # 学习率    
    
model = torch.nn.Linear(1, 1, bias=False)    
model.weight.data.fill_(1.0) # 初始化参数    
optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0) # 优化器    
lossfunc = torch.nn.MSELoss() # 平方根损失    
    
for i in range(10):    
    pred = model(x)    
    loss = lossfunc(pred, y)    
    loss.backward() # 计算梯度    
    optimizer.step()    
    optimizer.zero_grad()    </code></pre>
<p><strong>问题二</strong></p>
<p>如果孩子的智商由父母双方决定，那么每一实例的ｘ将提供父母双方的智商值x1,x2，学到的参数w也是两个：y=x1w1+x2w2，每次调节参数时误差函数分别对w1,w2求偏导。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-c636dc2c813b0d72.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>（码字不易，转载请注明出处：谢彦的技术博客）</p>
<p><strong>问题三</strong></p>
<p>如果孩子的智商由父亲决定，父亲的智商由奶奶决定，此时网络的输入是奶奶的智商x，输出是孩子的智商y，父亲的智商成为中间变量。因此有：y=x<em>w1</em>w2，其中w1是奶奶对父亲的影响，w2是父亲对儿子的影响。（示例仅用于描述多层网络，实际上这样的双层网络与单层网络效果无异w3=w2*w1）。</p>
<pre><code>import torch    
    
x = torch.tensor([100.]) # 只做训练不求梯度    
y = torch.tensor([110.])    
lr = 0.00001 # 学习率    
    
model1 = torch.nn.Linear(1, 1, bias=False)    
model2 = torch.nn.Linear(1, 1, bias=False)    
params = [&#123;&#39;params&#39;:model1.parameters()&#125;,     
          &#123;&#39;params&#39;:model2.parameters()&#125;] # 同时优化两组参数    
optimizer = torch.optim.SGD(params, lr=lr, momentum=0) # 优化器    
lossfunc = torch.nn.MSELoss() # 平方根损失    
    
for i in range(10):    
    pred = model2(model1(x))    
    loss = lossfunc(pred, y)    
    loss.backward() # 计算梯度    
    optimizer.step()    
    print(&quot;real&quot;, y.item(), &quot;pred&quot;, pred.item(), &quot;loss&quot;, loss.item())    
    print(&quot;w1.data&quot;, model1.weight.data.item(), &quot;w1.grad&quot;, model1.weight.grad.item())    
    print(&quot;w2.data&quot;, model2.weight.data.item(), &quot;w2.grad&quot;, model2.weight.grad.item())    
    optimizer.zero_grad()  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5bf7ca14623169e4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>（码字不易，转载请注明出处：谢彦的技术博客）</p>
<p>###梯度爆炸和梯度消失</p>
<p>梯度爆炸和梯度消失指的是梯度太陡或者梯度太平，引发的调参问题，该问题由连乘引发，假设一个n层网络，每一次都有参数w,b，试想比较简单的情况b=0，于是有如下的前向传播：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-9fea583b9891a34a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>当所有的W都大于1，且网络非常深时，最终的Y将非常大甚至越界，反之，当所有W都小于1，且网络非常深时，最终的Y将趋于0。如果网络的后几层的输入和输出都是0，则梯度也必然是“平”的，导致无法正常调参。</p>
<p>一般用下列方法缓解梯度爆炸和消失问题：</p>
<ul>
<li>用归一化方法处理模型输入x。<br />
</li>
<li>控制模型初值参数ｗ。<br />
</li>
<li>使用较小的学习率。<br />
</li>
<li>对模型中的数据流做一些限制。<br />
</li>
<li>使用残差网络，在前向传播过程中累加X值，使得W小于1时，Y也不再趋于0，从而解决梯度消失问题。</li>
</ul>
<p>当模型参数无法如设想中的调整时，除上述方法还可以尝试：</p>
<ul>
<li>冻结一些层，调整另一些层。<br />
</li>
<li>不能收敛时，或波动太大时，可考虑缩小学习率。<br />
</li>
<li>跟踪backward之后参数梯度的均值和方差，查看有无异常。<br />
</li>
<li>如果手动实现模型，需要验证梯度计算是否正确（计算双边误差）。<br />
</li>
<li>调试时需去掉Dropout，以保持稳定。<br />
</li>
<li>注意正则化项对代价函数的影响。<br />
</li>
<li>W和B一般在训练过程中逐渐变大，有些问题可能只在W,B较大时才出现。<br />
</li>
<li>使用BatchNormal时，mini-batch size不能太小。</li>
</ul>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习_BP神经网络</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_BP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h1 id="深度学习_bp神经网络">深度学习_BP神经网络</h1>
<p>#深度学习</p>
<h2 id="说明">1. 说明</h2>
<p>现在使用深度学习算法都以调库为主，但在使用库之前，先用python写一个最基本的神经网络的程序，也非常必要，它让我们对一些关键参数：学习率，批尺寸，激活函数，代价函数的功能和用法有一个直观的了解。</p>
<h2 id="原理">2. 原理</h2>
<h4 id="bp神经网络">1) BP神经网络</h4>
<p>BP神经网络是一种按照误差逆向传播算法训练的多层前馈神经网络．这又前馈又逆向的把人绕晕了．先看看什么是前馈神经网络，回顾一下《深度学习_简介》中的图示：</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-2ad9048016c956ad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>这是一个典型的前馈神经网络，数据按箭头方向数据从输入层经过隐藏层流入输出层，因此叫做前馈．前馈网络在模型的输出和模型之间没有反馈，如果也包含反馈，则是循环神经网络，将在后续的RNN部分介绍．<br />
前向网络和循环网络的用途不同，举个例子，比如做玩具狗，前馈是用不同材料和规格训练Ｎ次，各次训练之间都没什么关系，只是随着训练，工人越来越熟练．而循环网络中，要求每次做出来的狗都是前次的加强版，因此前次的结果也作为一种输入参与到本次的训练之中．可把循环网络理解成前馈网络的升级版．本篇讲到的BP神经网络，以及处理图像常用的卷积神经网络都是前馈网络，而处理自然语言常用的RNN则是循环网络．<br />
误差逆向传播是指通过工人做出的狗（预测结果）与玩具狗规格（实际结果）的误差来调整各个工人的操作（权重w），这个例子具体见前篇《简介》，¬由于误差的传播的顺序是：输出层-&gt;隐藏层2-&gt;隐藏层1，所以叫逆向传播．<br />
综上，前馈指的是数据流向，逆向指的是误差流向．</p>
<h4 id="训练过程">2) 训练过程</h4>
<p>简单回忆一下（详见《简介》篇）训练过程：对于每个训练样本，BP算法先将输入样例提供给给输入神经元，然后逐层将信号向前传播，直到产生输出层的结果，然后对照实际结果计算输出层的误差，再将误差逆向传播到隐层神经元，然后根据神经元的误差来对连接权值和与偏置进行调整优化。向前传数据很简单，只包含加法乘法和激活函数（具体计算见代码），相对的难点在于逆向传误差，当得到了输出层的误差后，调整w3中各个w的具体方法是什么呢？这里用到了梯度下降算法．此处也是代码中的最理解的部分．<br />
下面先看一下代码，梯度下降算法见之后的＂关键概念＂部分．</p>
<h2 id="代码分析">3. 代码分析</h2>
<h4 id="程序说明">1) 程序说明</h4>
<p>程序实现了通过MNIST数据集中60000个实例训练对手写数字的识别，使用一个输入层，一个隐藏层，一个输出层的方式构建BP神经网络．<br />
因代码较长，把它分成两块：算法实现和处部调用（运行程序时把它们粘在一起即可）。注释有点多哈:ｐ</p>
<h4 id="算法实现">2) 算法实现</h4>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -*- coding: utf-8 -*-  </span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, struct  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> array <span class="im">import</span> array <span class="im">as</span> pyarray  </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> append, array, int8, uint8, zeros  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.datasets <span class="im">import</span> mnist  </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NeuralNet(<span class="bu">object</span>):  </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 初始化神经网络，sizes包含了神经网络的层数和每层神经元个数  </span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, sizes):  </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sizes_ <span class="op">=</span> sizes  </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_layers_ <span class="op">=</span> <span class="bu">len</span>(sizes)  <span class="co"># 三层：输入层，一个隐藏层(8个节点), 输出层  </span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># zip 函数同时遍历两个等长数组的方法  </span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.w_ <span class="op">=</span> [np.random.randn(y, x) <span class="cf">for</span> x, y <span class="kw">in</span> <span class="bu">zip</span>(sizes[:<span class="op">-</span><span class="dv">1</span>], sizes[<span class="dv">1</span>:])]  <span class="co"># w_、b_初始化为随机数  </span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b_ <span class="op">=</span> [np.random.randn(y, <span class="dv">1</span>) <span class="cf">for</span> y <span class="kw">in</span> sizes[<span class="dv">1</span>:]]  </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># w_是二维数组，w_[0].shape=(8,784), w_[1].shape=(10, 8),权值, 供矩阵乘  </span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># b_是二维数组，b_[0].shape=(8, 1), b_[1].shape=(10, 1),偏移, 每层间转换的偏移  </span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sigmoid函数，激活函数的一种, 把正负无穷间的值映射到0-1之间  </span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> sigmoid(<span class="va">self</span>, z):  </span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">1.0</span><span class="op">/</span>(<span class="fl">1.0</span><span class="op">+</span>np.exp(<span class="op">-</span>z))  </span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sigmoid函数的导函数, 不同激活函数导函数不同  </span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> sigmoid_prime(<span class="va">self</span>, z):  </span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.sigmoid(z)<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="va">self</span>.sigmoid(z))  </span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 向前传播：已知input，根据w,b算output，用于预测  </span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> feedforward(<span class="va">self</span>, x):  </span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> b, w <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.b_, <span class="va">self</span>.w_):  </span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> <span class="va">self</span>.sigmoid(np.dot(w, x)<span class="op">+</span>b)  </span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x <span class="co"># 此处的x是0-9每个数字的可能性  </span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 单次训练函数，x是本次训练的输入，y是本次训练的实际输出  </span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 返回的是需调整的w,b值  </span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backprop(<span class="va">self</span>, x, y):  </span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 存放待调整的w,b值，nabla是微分算符  </span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>        nabla_b <span class="op">=</span> [np.zeros(b.shape) <span class="cf">for</span> b <span class="kw">in</span> <span class="va">self</span>.b_] <span class="co"># 与b_大小一样，初值为0  </span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>        nabla_w <span class="op">=</span> [np.zeros(w.shape) <span class="cf">for</span> w <span class="kw">in</span> <span class="va">self</span>.w_] <span class="co"># 与w_大小一样，初值为0  </span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>        activation <span class="op">=</span> x <span class="co"># 存放层的具体值,　供下层计算   </span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>        activations <span class="op">=</span> [x] <span class="co"># 存储每层激活函数之后的值  </span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>        zs <span class="op">=</span> [] <span class="co"># 存放每层激活函数之前的值  </span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> b, w <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.b_, <span class="va">self</span>.w_):  </span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>            z <span class="op">=</span> np.dot(w, activation)<span class="op">+</span>b <span class="co"># dot是矩阵乘法, w是权值，b是偏移  </span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>            zs.append(z)  </span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>            activation <span class="op">=</span> <span class="va">self</span>.sigmoid(z) <span class="co"># 激活函数  </span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>            activations.append(activation)  </span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 计算输出层的误差，cost_derivative为代价函数的导数  </span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>        delta <span class="op">=</span> <span class="va">self</span>.cost_derivative(activations[<span class="op">-</span><span class="dv">1</span>], y) <span class="op">*</span> \  </span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.sigmoid_prime(zs[<span class="op">-</span><span class="dv">1</span>]) <span class="co">#原理见梯度下降部分  </span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>        nabla_b[<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> delta   </span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>        nabla_w[<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> np.dot(delta, activations[<span class="op">-</span><span class="dv">2</span>].transpose())  </span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 计算隐藏层的误差  </span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="va">self</span>.num_layers_):  </span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>            z <span class="op">=</span> zs[<span class="op">-</span>l]  </span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>            sp <span class="op">=</span> <span class="va">self</span>.sigmoid_prime(z)  </span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>            delta <span class="op">=</span> np.dot(<span class="va">self</span>.w_[<span class="op">-</span>l<span class="op">+</span><span class="dv">1</span>].transpose(), delta) <span class="op">*</span> sp  </span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>            nabla_b[<span class="op">-</span>l] <span class="op">=</span> delta  </span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>            nabla_w[<span class="op">-</span>l] <span class="op">=</span> np.dot(delta, activations[<span class="op">-</span>l<span class="op">-</span><span class="dv">1</span>].transpose())  </span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (nabla_b, nabla_w)  </span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 对每批中的len(mini_batch)个实例，按学习率eta调整一次w,b  </span></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update_mini_batch(<span class="va">self</span>, mini_batch, eta):  </span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 累计调整值  </span></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>        nabla_b <span class="op">=</span> [np.zeros(b.shape) <span class="cf">for</span> b <span class="kw">in</span> <span class="va">self</span>.b_] <span class="co"># 与b_大小一样，值为0  </span></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>        nabla_w <span class="op">=</span> [np.zeros(w.shape) <span class="cf">for</span> w <span class="kw">in</span> <span class="va">self</span>.w_] <span class="co"># 与w_大小一样，值为0  </span></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> x, y <span class="kw">in</span> mini_batch: <span class="co"># 100个值,分别训练  </span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>            delta_nabla_b, delta_nabla_w <span class="op">=</span> <span class="va">self</span>.backprop(x, y)  </span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>            nabla_b <span class="op">=</span> [nb<span class="op">+</span>dnb <span class="cf">for</span> nb, dnb <span class="kw">in</span> <span class="bu">zip</span>(nabla_b, delta_nabla_b)]  </span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>            nabla_w <span class="op">=</span> [nw<span class="op">+</span>dnw <span class="cf">for</span> nw, dnw <span class="kw">in</span> <span class="bu">zip</span>(nabla_w, delta_nabla_w)]  </span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>        <span class="co"># eta是预设的学习率(learning rate),用来调节学习的速度. eta越大，调整越大  </span></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 用新计算出的nable_w调整旧的w_, b_同理  </span></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.w_ <span class="op">=</span> [w<span class="op">-</span>(eta<span class="op">/</span><span class="bu">len</span>(mini_batch))<span class="op">*</span>nw <span class="cf">for</span> w, nw <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.w_, nabla_w)]  </span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b_ <span class="op">=</span> [b<span class="op">-</span>(eta<span class="op">/</span><span class="bu">len</span>(mini_batch))<span class="op">*</span>nb <span class="cf">for</span> b, nb <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.b_, nabla_b)]  </span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 训练的接口函数  </span></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>    <span class="co"># training_data是训练数据(x, y);epochs是训练次数;  </span></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># mini_batch_size是每次训练样本数; eta是学习率learning rate  </span></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> SGD(<span class="va">self</span>, training_data, epochs, mini_batch_size, eta, test_data<span class="op">=</span><span class="va">None</span>):  </span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> test_data:  </span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>            n_test <span class="op">=</span> <span class="bu">len</span>(test_data)  </span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>        n <span class="op">=</span> <span class="bu">len</span>(training_data)  </span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(epochs): <span class="co"># 用同样数据，训练多次  </span></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>            random.shuffle(training_data) <span class="co"># 打乱顺序  </span></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>            mini_batches <span class="op">=</span> [training_data[k:k<span class="op">+</span>mini_batch_size] <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, n, mini_batch_size)]  </span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 把所有训练数据60000个分成每100个/组(mini_batch_size=100)  </span></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> mini_batch <span class="kw">in</span> mini_batches:  </span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.update_mini_batch(mini_batch, eta) <span class="co"># 分批训练  </span></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> test_data:  </span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&quot;Epoch </span><span class="sc">&#123;0&#125;</span><span class="st">: </span><span class="sc">&#123;1&#125;</span><span class="st"> / </span><span class="sc">&#123;2&#125;</span><span class="st">&quot;</span>.<span class="bu">format</span>(j, <span class="va">self</span>.evaluate(test_data), n_test))  </span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:  </span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&quot;Epoch </span><span class="sc">&#123;0&#125;</span><span class="st"> complete&quot;</span>.<span class="bu">format</span>(j))  </span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 计算预测的正确率  </span></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> evaluate(<span class="va">self</span>, test_data):  </span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>        <span class="co"># argmax(f(x))是使得 f(x)取得最大值所对应的变量x  </span></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>        test_results <span class="op">=</span> [(np.argmax(<span class="va">self</span>.feedforward(x)), y) <span class="cf">for</span> (x, y) <span class="kw">in</span> test_data]  </span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">sum</span>(<span class="bu">int</span>(x <span class="op">==</span> y) <span class="cf">for</span> (x, y) <span class="kw">in</span> test_results)  </span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 代价函数的导数, 对比实际输出与模拟输出的差异, 此时y也是个数组  </span></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> cost_derivative(<span class="va">self</span>, output_activations, y):  </span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (output_activations<span class="op">-</span>y)  </span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 预测  </span></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, data):  </span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>        value <span class="op">=</span> <span class="va">self</span>.feedforward(data)  </span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> value.tolist().index(<span class="bu">max</span>(value))  </span></code></pre></div>
<h4 id="外部调用">3) 外部调用</h4>
<p>外部调用主要实现了主函数，load数据，以及调用神经网络的接口</p>
<pre><code># 将输入数据转换为神经网络能处理的格式  
def load_samples(image, label, dataset=&quot;training_data&quot;):  
    X = [np.reshape(x,(28*28, 1)) for x in image] # 手写图分辨率28x28  
    X = [x/255.0 for x in X]   # 灰度值范围(0-255)，转换为(0-1)  
   
    # 把y从一个值转成一个数组，对应输出层0-9每个数字出现的概率  
    # 5 -&gt; [0,0,0,0,0,1.0,0,0,0];  1 -&gt; [0,1.0,0,0,0,0,0,0,0]  
    def vectorized_Y(y):    
        e = np.zeros((10, 1))  
        e[y] = 1.0  
        return e  
   
    if dataset == &quot;training_data&quot;:  
        Y = [vectorized_Y(y) for y in label]  
        pair = list(zip(X, Y))  
        return pair  
    elif dataset == &#39;testing_data&#39;:  
        pair = list(zip(X, label))  
        return pair  
    else:  
        print(&#39;Something wrong&#39;)  
   
   
if __name__ == &#39;__main__&#39;:  
    INPUT = 28*28 # 每张图像28x28个像素  
    OUTPUT = 10 # 0-9十个分类  
    net = NeuralNet([INPUT, 8, OUTPUT])  
  
    # 从mnist提供的库中装载数据  
    (x_train, y_train), (x_test, y_test) = mnist.load_data()  
    # 格式转换  
    test_set = load_samples(x_test, y_test, dataset=&#39;testing_data&#39;)  
    train_set = load_samples(x_train, y_train, dataset=&#39;training_data&#39;)  
  
    #训练  
    net.SGD(train_set, 13, 100, 3.0, test_data=test_set)  
   
    #计算准确率  
    correct = 0;  
    for test_feature in test_set:    
        if net.predict(test_feature[0]) == test_feature[1]:    
            correct += 1    
    print(&quot;percent: &quot;, correct/len(test_set))  </code></pre>
<h2 id="关键概念">4. 关键概念</h2>
<h4 id="误差函数">1) 误差函数</h4>
<p>误差函数也叫代价函数或损失函数，它计算的是实际结果和预测结果之间的差异，误差函数记作L(Y,
f(x))．<br />
上例中代价函数用的是方差再取二分之一的方法(SSE)：(1/2)*(o-y)^2，它的导数是o-y，即output_activations-y，其中output_activations为预测结果，y为实际结果。上面没有直接写误差函数，而是给出了它的导数（cost_derivative）．<br />
误差函数还有均方误差，绝对值均差等，具体请见参考中的《目标函数objectives》。</p>
<h4 id="梯度下降">2) 梯度下降</h4>
<p>回顾一下导数的概念，假设我们有一个函数 y = f
(x)，这个函数的导数记为f’(x)
，它描述了如何改变x，能在输出获得相应的变化：<br />
f (x +ε) ≈ f (x) +ε<em>f’(x)<br />
此时我们希望f()向小的方向变化（等号左侧），则需要对f(x)加一个负数，即ε</em>f’(x)&lt;=0，那么ε与f’(x)符号不同。换言之，可以将
x 往导数的反方向移动一小步ε来减小 f
(x)。这种技术被称为梯度下降．可通过下图，获得更直观的理解．</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-bfe1c1f2491a3b47.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="(图片引自《深度学习》＂花书＂)" />
<figcaption
aria-hidden="true">(图片引自《深度学习》＂花书＂)</figcaption>
</figure>
<p>梯度下降算法在上例的backprop()部分实现，我们想知道如何改变权重w，能使误差函数Ｌ变小，于是求L对于w的导数，然后将w向导数的反方向移动一小步，即可使Ｌ变小．<br />
损失函数的计算由下式得出：<br />
L = (1/2)*(g(wx+b) –
y)^2，其中y是实际结果，g()是激活函数，wx+b是对上一步x的线性变换，对L求导用到了复合函数的链试法则，因此有程序中分别使用了激活函数的导数（sigmoid_prime），损失函数的导数（cost_derivative），再乘以上一步的x（activations）．以上就是求权重w变化的原理，偏置b同理．<br />
另外，需要注意的是这里求出的nable_w是权重的梯度，并不是具体的权重值．</p>
<h4 id="批尺寸">3) 批尺寸</h4>
<p>批尺寸是每训练多少个数据调整一次权重．上例中由mini_batch指定为每次100个实例；如果每训练一次就调整一次，不但会增加运算量，还会使w变化波动加俱，使其难以收敛；如果一次训练太多，则会占用较大内存，有时正负波相互抵消，最终使w无法改进．因此选择批尺寸时，需要在考虑内存和运算量的情况下尽量加大批尺寸．</p>
<h4 id="学习率">4) 学习率</h4>
<p>学习率也叫学习因子，简单地说，就是每次算出来的梯度对权值的影响的大小。学习率大，影响就大。学习率决定了参数移动到最优值的速度快慢。如果学习率过大，很可能会越过最优值；反而如果学习率过小，优化的效率可能过低，使得长时间算法无法收敛。<br />
学习率在上例中是eta数值．<br />
学习率的选择与误差函数相关，上例中使用SSE作为误差函数，批尺寸越大，梯度数据累加后越大，因此在计算时除以了批尺寸大小．我们可以选择一个不被训练集样本个数影响的误差函数(比如MSE)．另外，输入特征的大小也对学习率有影响，所以处理前最好先归一化．<br />
还可以在学习中动态地调整学习率，常用的有学习率有sgd，
adadelta等．具体见参考中的《各种优化方法总结比较》</p>
<h4 id="激活函数">5) 激活函数</h4>
<p>激活函数也叫激励函数，它的功能是将线性变换转成非线性变换，以提供非线性问题的解决方法．<br />
上例中使用了sigmoid函数作为激活函数．常用的激活函数还有tanh，RelU等．其中ReLU是当前流行的激活函数y=max(0,x)，它将大于0的值留下，否则一律为0。常用于处理大多数元素为0的稀疏矩阵。具体请见参考中的《神经网络之激活函数》</p>
<h2 id="参考">5. 参考</h2>
<ol type="1">
<li>神经网络入门之bp算法，梯度下降<br />
http://blog.csdn.net/u013230651/article/details/75909596<br />
</li>
<li>使用Python实现神经网络<br />
http://blog.csdn.net/u014365862/article/details/53868414<br />
</li>
<li>目标函数objectives<br />
http://keras-cn.readthedocs.io/en/latest/other/objectives/<br />
</li>
<li>各种优化方法总结比较<br />
http://blog.csdn.net/luo123n/article/details/48239963<br />
</li>
<li>机器学习中的损失函数<br />
http://blog.csdn.net/shenxiaoming77/article/details/51614601<br />
</li>
<li>Deep Learning 学习随记（七）Convolution and Pooling
--卷积和池化<br />
http://blog.csdn.net/zhoubl668/article/details/24801103<br />
</li>
<li>神经网络之激活函数(sigmoid、tanh、ReLU)<br />
http://blog.csdn.net/suixinsuiyuan33/article/details/69062894?locationNum=4&amp;fps=1</li>
</ol>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习_总结篇</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%E6%80%BB%E7%BB%93%E7%AF%87/</url>
    <content><![CDATA[<h1 id="深度学习_总结篇">深度学习_总结篇</h1>
<p>#深度学习</p>
<h1 id="深度学习_总结篇-1">深度学习_总结篇</h1>
<p>#深度学习</p>
<h2 id="前篇总结">前篇总结</h2>
<ol type="1">
<li><p>深度学习_简介及相关概念<br />
<a
href="http://blog.csdn.net/xieyan0811/article/details/78401473">http://blog.csdn.net/xieyan0811/article/details/78401473<br />
</a></p></li>
<li><p>深度学习_工具<br />
<a
href="http://blog.csdn.net/xieyan0811/article/details/78411882">http://blog.csdn.net/xieyan0811/article/details/78411882<br />
</a></p></li>
<li><p>深度学习_BP神经网络<br />
<a
href="http://blog.csdn.net/xieyan0811/article/details/78425453">http://blog.csdn.net/xieyan0811/article/details/78425453<br />
</a></p></li>
<li><p>深度学习_卷积神经网络CNN<br />
<a
href="http://blog.csdn.net/xieyan0811/article/details/78438329">http://blog.csdn.net/xieyan0811/article/details/78438329<br />
</a></p></li>
<li><p>深度学习_循环神经网络RNN与LSTM<br />
<a
href="http://blog.csdn.net/xieyan0811/article/details/78462982">http://blog.csdn.net/xieyan0811/article/details/78462982<br />
</a></p></li>
</ol>
<p>朋友反馈说，看不懂CNN和RNN篇．文章确实因为篇幅原因，有点跳步了．不过我觉得主要原因还是跳过了前面的基础部分．我们很多时候喜欢直击重点，跳过过程，但是有的过程确实跳不过去．<br />
数据挖掘，机器学习，机器视觉，语言处理这些背后有很多数学概率基础，且不止于此，它和大多数程序员之前接触的写应用，网络编程，数据库，配系统，学习编程语言，把人家的库拿来搭一搭…<br />
不一样，那些即使不懂原理，也能照猫画虎做个七八成．在这里，我们用Python/R，它们把技术细节都解决了，这里拼的不是工作量，拼的是算法，是对数据的理解．参加个比赛或者技术选型，人家用啥模型，咱也用啥模型，即使只调参，也需要理解数据和掌握数学工具．不明白原理，还是没法跟人家拼？<br />
我个人觉得，这个很难速成．对于程序员来说，唯一的捷径可能是从代码入手，在做的过程中，逐步把数学和原理补上．程序员对代码直觉相对好一点，有时候我看不懂图和公式，但我看得懂代码．</p>
<h2 id="谈谈我对深度学习的理解">谈谈我对深度学习的理解</h2>
<p>深度学习可以理解成一层一层地抽象提取隐含的特征，最后求解问题．一开始我觉得这和浅层学习中的算法集成差不多，那个也可以一层一层搭起来的．<br />
随着学习的深入，我觉得它确实有明显的优势，比如：<br />
第一：它引入的激活函数可以解决非线性问题．<br />
第二：数据从x流向y，而误差从y逐层流回x，整个网络中所有权值都在不断调整，不是某一层调完就不动了，浅层集成大多数时候是单向的，没这灵活．<br />
第三：它相对自动化，第个层间具体传输的内容，不用人手动指定和对接．</p>
<h2 id="神经网络解决的问题">神经网络解决的问题</h2>
<p>一般把有监督学习分为三种（概念引自《机器学习》Peter<br />
Flach著）：几何模型（如线性拟合），概率模型（如贝叶斯网络），逻辑模型（如决策树）．具体算法可能是其中一种或多种的结合．<br />
看看神经网络与这三种模型的关系：<br />
第一：几何模型，神经网络层与层间的连续就是线性变换，然后利用误差调整参数，这个过程就是线性拟合．<br />
第二：概率模型，神经网络本来就是个概率类模型．它网络中各个权重表示的就是它对最终结果的影响，预测出的值也可以是结果的概率．<br />
第三：逻辑模型，逻辑模型主要是：与，或，非，异或这些运算的组合，最常看到激活函数的例子就是处理异或运算．我们也常在池化中见到与或运算．因此，它也是神经网络可以实现的．<br />
还有一些无监督学习，在CNN的卷积和DropOut中也实现了一部分．<br />
那么是不是神经网络就可以代替所有算法了呢？杀鸡需要牛刀吗？异或还需要训练吗？确实很多算法都可以迂回地改用神经网络实现．但是还要考虑运算量和复杂度的问题．正如人脑处理简单问题和复杂问题也有不同的路径：有的是查表，有的是套路，有的是具体问题具体分析．神经网络也不是一种算法，而是一类算法的集合．好坏还是要看具体场景．写算法就像搭积木，你中有我，我中有你，不好讲哪块好，哪块不好．</p>
<h2 id="关于鹦鹉学舌">关于鹦鹉学舌</h2>
<p>机器学习现阶段还是以模仿为主，即人们常说的鹦鹉学舌．真正的强人工智能，自主的思考，至少需要有常识（大量地采样和组织数据），才能识别出非常态的＂特性＂，有了这些才能组合，理解，发现因果．再深入到确定目标，以及目标分解等等．这条链上缺失的东西有还是很多很多，目前以学术研究为主．想了解更多，建议阅读马文明斯基的《心智社会》．</p>
<h2 id="推荐">推荐</h2>
<p>关于深度学习的书也不太多，有一些从具体工具入手，如Caffe，TensorFlow等等．卖
得最好的是《深度学习》Ian Goodfellow,<br />
Yoshua Bengio, Aaron<br />
Courville著（＂花书＂），目前在当当的计算机网络类图书排名第一，也可见现在＂深度学习＂有多热门．虽然字不大，还很厚，不过去掉前边的数学知识，后面的附录，也还好，并且复杂的公式不多，讲得也很细，确实是良心之作．</p>
<h2 id="总结">总结</h2>
<p>机器学习只是人工智能的一部分，光靠它恐怕实现不了强人工智能．不过随着技术地进步越来越多相关技术也更多地溶入和结合起来，我们也不妨把它作为人工智能的切入点．<br />
本篇是本次深度学习系列的最后一篇，接下来的文章还会围绕机器学习展开，包括经典算法的代码实例，常用工具，Kaggle比赛介绍等等，可能会穿插地写．<br />
在这个过程中我们尽量不调库自己写算法，加入真实的应用场景，并且和原理结合起来，不过顺序可能会从兴趣出发，并非由浅入深．呵呵，我尽量写吧，欢迎继续关注…</p>
<p>技术文章定时推送<br />
请关注公众号：算法学习分享 <a
href="http://www.cnblogs.com/52machinelearning/p/5821591.html"><br />
<img src="https://img-blog.csdn.net/20171031143905808" /><br />
</a></p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习_简介及相关概念</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%E7%AE%80%E4%BB%8B%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<h1 id="深度学习_简介及相关概念">深度学习_简介及相关概念</h1>
<p>#深度学习</p>
<h2 id="传说">1. 传说</h2>
<p>传说深度神经非常神奇，把那些浅层学习都给甩出十万八千里去了！还需要什么特征工程？卷积神经网络的特征都是自动识别的！只要用正确的条件和结果训练得足够多，以后给条件就能自动出结果了，比教人还简单！它模拟的可是人类的大脑，现在的运算量已经赶上猫狗的脑了，只要运算足够大足够快，机器人分分钟就消灭人类！</p>
<p>这些只是传说，它夸大的事实的一部分，而故意忽略了另一部分．不过，树立的典型不都这样么？看2010年以来最热门的卷积神经网络（CNN）的发展，从AlexNet到RssNet，就可以看到，它主要解决了什么问题，具体怎么用，离强人工智能还有多远。</p>
<p>其实，神经网络就是机器学习的一种，机器学习又是人工智能的一种。现在一说人工智能就说深度学习，不懂这个就太out了。环境就是这样，也只好花时间来了解一下了，此专题大致分为：简介，入门工具，BP实现，CNN，RNN，技巧这几部分来介绍一下。</p>
<h2 id="引入">2. 引入</h2>
<p>简单地举个例子：有一家玩具工厂，想通过试生产的方式培养员工的生产玩具的能力．具体过程是提供3种材料（输入），和1种成品（输出），让工人们练手（此例为回归问题）．所有工人被分成三组（w1,w2,w3），如图所示，产品按箭头方向渐步生产．于是把它们分成了四层：输入层（3种材料）-&gt;隐藏层A（初级半成品）-&gt;隐藏层B（高级半成品）-&gt;输出层（1种成品）．注意：每层中的圆圈是产品（状态），而非员工（权重）．</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-1e6ead9d9a6b06e6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>当工人生产完一个玩具时，交给质检员（黄色方块），质检员将之与成品规格对比（误差函数），然后告诉第三组的工人：做得太大了，用手一比划，说下回做小点．于是第三组反馈给第二组头太大身太大…第二组反馈给第一组骨架太大填充太多…从而所有人都做相应的调整（以上只是示例，实际每层节点的含义并没这么具体）。训练就是不断地给不同材料让他们去实践（训练），并用产品规格去评价评测做出来的产品（误差函数），每个人都在不断调整自己（调整权值）。在大量的磨合之后，大家都找到了合适的工作方式（各自权重）。这时候再给一些用过的新材料，也可以根据训练出来的体系做成相对靠谱的产品。</p>
<h2 id="重要概念">3. 重要概念</h2>
<p>下面说说其中几个重要的概念</p>
<h4 id="权值">1) 权值</h4>
<p>权值就是在上例中我们所说的每个工人都知道自己怎么做，它是神经网络的训练成果．图中圈与圈之后的每条黑线都代表一个权值，一般用符号w表示．</p>
<h4 id="损失函数">2) 损失函数</h4>
<p>损失函数也叫做成本函数，代价函数，误差函数．它是图中的黄色部分，用于评测预测值f(x)与实际值Y的差异．通常使用符号L(Y,
f(x))来表示，损失函数越小，学习效果越好．</p>
<h4 id="学习率">3) 学习率</h4>
<p>学习率也叫学习因子，每训练一次权值都会被调整一次，从上例中看，当质检员说太大了，工人该怎么调整呢？是调低20%，还是50%呢？这个调整的比例就是学习率．学习率决定了参数移动到最优值的速度快慢。如果学习率过大，很可能会越过最优值；反而如果学习率过小，优化的效率可能过低，使得长时间算法无法收敛。学习率也可以动态调整．</p>
<h4 id="批尺寸">4) 批尺寸</h4>
<p>批尺寸指的就是每生产多少个玩具，调整一下权重．如果每做一个玩具就调整一次，会造成反复波动，难以收敛；如果把所有的都训练完再调整，在数据量大的情况下，会占用大量的资源，还有正负相互抵消的问题．因此数据量大时，一般分批训练。</p>
<h4 id="全连接与部分连接">5) 全连接与部分连接</h4>
<p>在上例中，每一层的节点都会用到上一层所有节点的结果，并且把自己的运算结果提供给下一层的每个节点，这就是全连接．有时候并不需要全连接，以节约资源，就是部分连接（部分连接在CNN部分再详述）．</p>
<h4 id="激活函数">6) 激活函数</h4>
<p>激活函数也叫激励函数,
是图中红色部分．它的主要作用是把线性变换转换成非线性变换．神经网络优于其它算法主要方面就是它能解决非线性问题．如果没有激活函数，则每层变换都是线性变换，线性变换多层组合还是线性变换，那样的话多个隐藏层和单个隐藏层就没区别了．因此，在每层都加了一个非线性变换，理论上这样就可以解决所有非线性问题．</p>
<h4 id="说明">7) 说明</h4>
<p>此处概念较多，最好是跟着程序一块儿看，具体后面《深度学习——BP神经网络》．</p>
<h2 id="程序员的工作">4. 程序员的工作</h2>
<p>不要以为把材料和规格扔进去就啥事儿没有了．程序设计者至少需要事先指定的有几个隐藏层，每层多少个单元，每层的激活函数，误失函数，优化率，是否全连接等等．程序员就好比工厂的管理者，他的经验知识就体现在这儿。</p>
<h2 id="深度学习">5. 深度学习</h2>
<p>算法分好多层，并且后层依赖前层的结果，所以叫深度学习，不止是神经网络，其它的算法与其自身，或者算法与算法之间，层层堆叠的也叫深度学习．</p>
<h2 id="分类">6. 分类</h2>
<p>这里我们先看看NN,DNN,CNN,RNN,GAN这些常见的概念，到底是什么关系。这里只是个大致的分类，更多时候它们是组合使用的。</p>
<h4 id="从算法上分">1) 从算法上分</h4>
<ul>
<li><p>多层感知机（MLP）<br />
感知机拥有一个输入层, 一个输出层, 一个隐藏层, 数据从输入层,
经过隐藏层变化, 然后在输出层得出分类结果. 后来发展出多层感知机,
就是有多个隐藏层,</p></li>
<li><p>神经网络（NN）<br />
神经网络是在感知机的基本上，又加入了激励函数, 模拟人脑的响应,
如上例中那样工作, 这就是所谓的神经网络NN.
后文的《深度学习——BP神经网络》描述了BP神经网络的具体实现（非调库方式）。</p></li>
<li><p>深度神经网络（DNN）<br />
随着层数的加深, 梯度消失问题变得严重, NN越来越容易隐入局部最优解,
为了克服梯度消失问题。采用了一些方法, 比如用ReLU替代sigmoid激活函数,
预训练等方法缓解了局部最优解问题, 使NN可用更多层实现,
这就是DNN。但具体使用了什么算法, 扩展到多少层叫DNN, 也没有确定的说法.
只是说DNN是NN的改进版.</p></li>
<li><p>生成式对抗网络（GAN<br />
GAN是博弈式的训练过程，生成模型的工作过程如下：生成一些图片-&gt;判别模型学习区分生成的图片和真实图片-&gt;生成模型根据判别模型改进自己，生成新的图片-&gt;….-&gt;
判别模型无法判断是生成的还是真实的-&gt;结束</p></li>
</ul>
<h4 id="从功能上分">2) 从功能上分</h4>
<ul>
<li><p>卷积神经网络（CNN）<br />
卷积神经网络一种专门用来处理具有类似网格结构的数据的神经网络，它一般指那些至少在网络的一层中使用卷积运算来替代一般的矩阵乘法运算的神经网络。它典型的应用是图像处理.</p></li>
<li><p>循环神经网络（RNN）<br />
循环神经网络是专门用于处理序列的神经网络，例如它可对时间序列上的变化建模。神经元的输出可以在下一个时间戳直接作用到自身。它典型的应用是自然语言处理.</p></li>
</ul>
<h2 id="参考">7. 参考</h2>
<p>[CNN(卷积神经网络)、RNN(循环神经网络)、DNN(深度神经网络)概念区分理解](http://blog.csdn.net/eddy_zheng/article/details/50763648)<br />
<a
href="http://www.sohu.com/a/139545215_133098">'到底什么是生成式对抗网络GAN？</a></p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习资源</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90/</url>
    <content><![CDATA[<h1 id="深度学习资源">深度学习资源</h1>
<p>#深度学习</p>
<p>深度学习成为主流是近十年的事，且涉及的知识很多，即使是资深工程师也很难在短时间内学会。学习过程中也有很多弯路，从复习大学数学开始，学习算法原理，工具和框架，看论文，参考别人写的代码，参加大数据比赛。能坚持把以上步骤认真做完已经很难得，但似乎仍然很难建立对深度学习的“直觉”，很难把这些知识融合到自己的架构和代码里，实际应用中看着都眼熟，细看全是盲点，修改结构的时候一改就错，最终成长为“调包侠”。</p>
<p>识字+读书≠会写作文，在原理、语法和代码之间似乎有一道沟；从论文、比赛、技术博客之中学到的又往往是琐碎的点，很难连成知识面。</p>
<p>推荐吴恩达老师的《Deep
Learning》线上课程，网易云课堂上有免费课程视频（带中文字幕），课程比较系统，讲解了从线性层的实现到深度学习技巧，再到视觉和自然语言处理等实际的应用。</p>
<p>这门课最大的亮点是：没有太复杂的数学，用直觉代替推导，大家都能听懂；作业难度适中，上课讲原理，下课通过编程实现各种原理，不再是只会调库。作业主要是选择题和程序填空，题量不算小，也不算容易。</p>
<p>比如第一个编程习题：自己写神经网络用于判断图片中是否包含猫，其中涉及优化、前向后向传播，数据处理。但代码不多，以程序填空的方式提供，并且可以找到参考答案。即使实在做不出来，完全抄一遍答案也有收获。慢慢地，可以从中打磨出一些经验，比如根据问题的难度估计神经网络的规模、数据量、以及训练时间、超参数等等。</p>
<p>除了建立知识体系，也适合查缺补漏，在实践过程中遇到的问题，很多都能在这里得到启发；明白别人的程序为什么会这么写。与算法开发者的想法相互印证。另外，还有很多经验性知识，比如超参数有N个，最重要的是xxx，其次是xxx，一般使用默认值是xxx；yyy原理很重要，但一般实现时常常用不到等等。不像有些书上为了完整性列出所有选项，却没有重点。另外，吴恩达老师声音很好听，有点像纪录片的配音效果，引用弹幕“引起极度舒适”。</p>
<p>课程共包括五个专题，每个专题2-4课，每课视频时间约1-2小时（有些片断需反复琢磨），作业时间约3个小时（视个人程度而定，主要基于TensorFlow1.0版本）。每周1课，约17周完成。完全Full
time学习，也需要至少半个月时间。</p>
<p><strong>下面列出课程目录</strong></p>
<ul>
<li>神经网络和深度学习<br />
深度学习概论<br />
神经网络基础<br />
浅层神经网络<br />
深层神经网络<br />
</li>
<li>改善深层神经网络：超参数调试、正则化以及优化<br />
深度学习的实用层面<br />
优化算法<br />
超参数调试、Batch正则化和程序框架<br />
</li>
<li>结构化机器学习项目<br />
机器学习策略1<br />
机器学习策略2<br />
</li>
<li>卷积神经网络<br />
卷积神经网络<br />
深度卷积网络：实例探究<br />
目标检测<br />
特殊应用：人脸识别和神经风格转换<br />
</li>
<li>序列模型<br />
循环序列模型<br />
自然语言处理与词嵌入<br />
序列模型和注意力机制</li>
</ul>
<p><strong>分享一些课程相关链接</strong></p>
<ul>
<li>coursera在线课程<br />
<a
href="https://www.coursera.org/specializations/deep-learning">https://www.coursera.org/specializations/deep-learning</a><br />
</li>
<li>网易云课堂<br />
<a
href="https://mooc.study.163.com/smartSpec/detail/1001319001.htm">https://mooc.study.163.com/smartSpec/detail/1001319001.htm</a><br />
<a
href="https://mooc.study.163.com/course/2001281003#/info">https://mooc.study.163.com/course/2001281003#/info</a><br />
</li>
<li>B站视频地址<br />
<a
href="https://www.bilibili.com/video/av87840460/">https://www.bilibili.com/video/av87840460/</a><br />
</li>
<li>中英文对照的作业及答案分析（含习题数据下载）<br />
<a
href="https://blog.csdn.net/u013733326/article/details/79827273?tdsourcetag=s_pcqq_aiomsg">https://blog.csdn.net/u013733326/article/details/79827273?tdsourcetag=s_pcqq_aiomsg</a><br />
</li>
<li>其它作业资源<br />
<a
href="https://github.com/Kulbear/deep-learning-coursera">https://github.com/Kulbear/deep-learning-coursera</a><br />
<a
href="https://github.com/greebear/deeplearning.ai-notes">https://github.com/greebear/deeplearning.ai-notes</a><br />
<a
href="https://github.com/Wasim37/deeplearning-assignment">https://github.com/Wasim37/deeplearning-assignment</a></li>
</ul>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>深度网络调参</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7/%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C%E8%B0%83%E5%8F%82/</url>
    <content><![CDATA[<h1 id="深度网络调参">深度网络调参</h1>
<p>#深度学习</p>
<h3 id="重要的超参数">重要的超参数</h3>
<p>深度学习网络有很多超参数，下面列出了一些比较重要，常常需要调节的超参数。</p>
<ul>
<li>最重要<br />
学习率<br />
</li>
<li>较重要<br />
mini-batch size<br />
hidden units<br />
网络层数<br />
动量参数<br />
学习率衰减</li>
</ul>
<h3 id="算力不同的调参">算力不同的调参</h3>
<p>算力不同、网络规模、数据量不同，也有不同的调参方法，当模型和计算量较小时，可以使用网格调参；在算力足够的情况下，使用多组参数并行训练模型；反之，如果算力不足，且模型和数据较大，可能需要手动调参，比如训练几天之后，手动下调学习率，动量等超参数，人为地逐渐推进训练过程。</p>
<h3 id="网格调参和随机调参">网格调参和随机调参</h3>
<p>机器学习中常使用网格调参，即将参数列成表格，按一定步长尝试所有组合的参数，这种方法适用于较小的网络。深度学习网络一般较大，训练时间较长，一般使用随机抽取方法，在重点区域进行更多的抽样（密度更大），这样在一开始不确定哪些超参数重要时，可以广撒网，越往后越有针对性，实现从粗到细调参，同时又兼顾各种可能性，以免陷入局部最优值，类似于蒙特卡洛方法。</p>
<h3 id="非线性轴调参">非线性轴调参</h3>
<p>非线性轴调参也是常见的调参问题，比如设置学习率常常是0.1, 0.01, 0.001,
0.0001…这样就不能用直接将取值范围平均分成n份，每次增加同样步长的方法，如:
0.01, 0.02,
0.03…这样调节效果不好。在这种情况下常使用指数调参，如Pytorch提供的ExponentialLR方法。</p>
<p>另外，还有一些类似情况，比如参数的取值范围在[0,1]之间，可能在中段并不敏感，而在0或1附近非常敏感，也需要使用类似指数或者指数加权平均的累积调参方法。</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>激活函数</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<h1 id="激活函数">激活函数</h1>
<p>#深度学习</p>
<h3 id="为什么使用激活函数">为什么使用激活函数</h3>
<p>如果没有激活函数，神经网络就变成了线性模型，输出是输入的线性组合，使用一层与使用多层没有区别。如下式所示，输入为x，经过线性层计算出a1，将a1输入下个线性层得到a2，展开后可以看出，最终得到的仍然是wx+b的线性组合，只是参数值不同。</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-0448d91717eddde8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>另外，线性层无法解决非线性问题，如在预测房价问题中，如果不使用激活函数，则房价可能计算成负值，这也与实际不符。理论上，加了激活函数后，模型可以逼近任意函数。</p>
<p>激活函数又分线性激活函数和非线性激活函数，一般使用的都是非线性激活函数，线性激活函数与线性层类似，只在输出层偶尔使用，不在此展开讨论。</p>
<h3 id="何时使用激活函数">何时使用激活函数</h3>
<p>激活函数一般放置在线性变换之后，在线性变换和激活函数之间，常常插入归一化层，用于解决饱和的非线性激活函数问题（下面Sigmoid函数部分详细说明）。</p>
<h3 id="如何选择激活函数">如何选择激活函数</h3>
<p>从一些当前流行的深度学习网络代码中，可以看到，当前使用的激活函数绝大部分是ReLU；在一些特殊情况下，也使用Sigmoid，比如二分类问题的最后一层使用Sigmoid将输出转换到0-1之间；又如使用注意力网络时，注意力加权需要使用0-1之间的权值时，也用到Sigmoid函数。作为一般的夹在线性层之间的普通激活函数，ReLU是默认选择。</p>
<h3 id="常用激活函数">常用激活函数</h3>
<p>下面介绍常用激活函数的方法、原理、梯度计算、直观图示，以及使用中可能遇到的问题。</p>
<p><strong>sigmoid激活函数</strong></p>
<p>sigmoid是较早期的激活函数，它的输入是任意的x，输出在0-1之间，实现数据映射。</p>
<p>其公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a5344f53619ed153.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其求导过程如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-069d15a3420cb451.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>Python代码实现：</p>
<pre><code>def sigmoid(x):    
    return 1. / (1 + np.exp(-x))  </code></pre>
<p>试想将值代入时，当x趋近正无穷，分母为1，计算结果为1；当x趋近负无穷，分母为无穷大，计算结果为0。当x为0时，分母为２，计算结果为0.5。</p>
<p>函数图示如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-1f6516d194663f81.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>如图所示，映射过程中将值压缩到0-1之间，它对0附近的值比较敏感，其图形接近线性，而其它部分的数值在sigmoid后绝对值缩小很多。</p>
<p>梯度是x方向上变化引起的y方向的变化，在x值较大的情况下，x的变化对y影响很小，这就是所谓的“非线性激活函数的饱和”问题。在使用梯度下降法给网络调参时，接近0的梯度使学习的速度变得非常缓慢。这一现象在调试程序时尤为明显：大不把网络参数以及输入数据设置得比较小，且不使用归一化层的情况下，使用Sigmoid函数收敛得非常慢。</p>
<p>此外，sigmoid还包括幂运算，运算量也比较大，目前除了上述比较特殊的场景，已很少使用。</p>
<p><strong>tanh激活函数</strong></p>
<p>tanh激活函数可视为sigmoid函数的改进版本，其图示如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-23eb7d9a5ed03539.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>在数学上，tanh是sigmoid的平移，它把数据范围压缩到-1~1之间，均值为0。前人证明0均值的tanh激活函数效果更好。0均值同样可应用于其它场景提高模型效果。</p>
<p>其公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-1424d0d6edd3e8a9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>Python代码实现：</p>
<pre><code>import numpy as np    
np.tanh(x)  </code></pre>
<p>尽管tanh略优于sigmoid，但它也有sigmoid同样的缺点：计算量大及饱和问题，目前也很少使用，另外，0均值也可通过归一化层实现。因此，只做简单介绍，不再展开。</p>
<p><strong>ReLU激活函数</strong></p>
<p>ReLU激活函数，原理，计算以及求导都非常简单：如果x大于0，则y=x，如果小于0，则y=0，其图示如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-769da43b47aa2823.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-cc5b5ed90032b69e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其导数是：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-4bc3bc966548fdb1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>需要注意的是，ReLU在0值不可微，但一般情况下，不会遇到太多的0值，因此将0值的梯度置为0或1都可以。</p>
<p>Python代码实现：</p>
<pre><code>def relu(x):    
    return np.maximum(0,x)  </code></pre>
<p>ReLU非常简单，运算速度非常快，收敛也快，由于它没有压缩数据，因此，也避免了由激活函数引起的梯度问题。另外，处理结果不能为负（如房价不能为负，或者避免sum累积时正负抵消）的问题时，也可以在层后添加ReLU激活函数。</p>
<p><strong>ReLU衍生的激活函数</strong></p>
<p>虽然ReLU相对于之前算法表现优异，但也存在问题，试想当梯度大幅变化时，由于ReLU在大于0的情况下，不做处理直接向后传递，则可能造成之前线性层参数的大幅变化，因此，很可能产生大量小于0的数据输入ReLU。若ReLU的输入大多是负数，则会导致大部分梯度无法向后传递，从而引起“Dead
ReLU”问题。其现象是由于某些特殊数据引发了无法继续收敛。</p>
<p>为解决这一问题，出现了一些ReLU变种，来处理小于0的数据，比如ELU，Leaky
RELU。</p>
<p>ELU公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-de45445c6ccf8327.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>做图如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-71cb0d8abb9ed7af.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>Python代码如下：</p>
<pre><code>def elu(x,a):    
    y = []    
    for i in x:    
        if i&lt;0:    
            i = a * (np.exp(i)-1)    
        y.append(i)    
    return y  </code></pre>
<p>它的均值趋近0，没有Dead
ReLU的问题，但计算量略大。更简单一点的还有Leaky ReLU，如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-cd862c5446a6fc24.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>它对于0以下的部分乘一个较小的a值，一般是0.01。另外，引入归一化层也可解决Dead
ReLU问题，因此，推荐以ReLU作为默认的激活函数。</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>设置BatchSize</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7/%E8%AE%BE%E7%BD%AEBatchSize/</url>
    <content><![CDATA[<h1 id="设置batchsize">设置BatchSize</h1>
<p>#深度学习</p>
<p>BatchSize是非常重要的超参数，它不仅影响训练速度，也影响模型精度。本篇来讨论如何选择BatchSize。</p>
<p><strong>BatchSize是否越大越好？</strong></p>
<p>BatchSize一般指同时代入训练模型的实例个数，最直接的经验是如果GPU显存不大，又设置较大的BatchSize时直接报错“cuda
runtime error(2): out of memory”。</p>
<p>是不是只要机器性能允许，就要设置尽可能大的Batch
size呢？同时训练多个实例比逐个代入单个实例训练速度又能提高多少？</p>
<p>下图为使用不同的batchSize，在LeNet上训练mnist数据的效果，使用的框架为Theano。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-62641c4c4644c23a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>可以看到，使用较大的batchSize的确可以提速，但是batchSize大到一定程度后，效果并不十分明显。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-3c567212a18d73e7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>从图中可以看到如果将所有数据全部代入一次迭代（左图），则在训练集上的代价函数下降比较平滑，如果切分成多个Batch，代价函数不一定是下降的。这是由于每一个Batch中数据的难度不同，造成了代价函数忽大忽小。</p>
<p><strong>如何选择batch大小？</strong></p>
<p>两种极端的情况是BatchSize大小为1，每次只训练一个实例，或者BatchSize大小等于所有训练集数据大小，即每次训练所有数据。但更多的时候BatchSize设置在二者之间。</p>
<p>batchSize较小时，抖动大，训练过程有很大运气的成份，可能某个实例将模型带偏了，防止被模型被带偏的方法是使用较小的学习率，这样即非并行处理，又使用较小的学习率，使得收敛变慢。</p>
<p>batchSize较大时，任务并行执行，训练速度快,
且大Batch正负样本更均衡可以有效更新BN层参数精度更高。代价函数也能相对比较稳定，平滑地下降。但是如果代入了所有数据后再调参，可能会使很多梯度相互抵消，调参也比较粗糙。如果不进行特殊处理，过大的BatchSize一将会损失模型精度。另外，较大的batchSize会使模型的泛化能力下降（generalization
gap）。</p>
<p>如果遇到较大的数据集，一般需要切分成batch分批训练，对于较少的数据，也可以使用全部数据训练。当有足够算力时，选取BatchSize为32,64,128或更小一些的batch_size。算力不够时，在效率和泛化性之间做权衡，选择更小的batchSize。</p>
<p>在训练过程中，可以将batch_size作为超参数做多次尝试。另一方面，也可以在前期使用较大的学习率和较越BatchSize粗调，后期（比如论文实验/比赛最后）将BatchSize变小精调，并使用SGD优化方法，慢慢把Error磨低。</p>
<p><strong>BatchSize是否只与速度有关？</strong></p>
<p>BatchSize不仅与速度相关，如果模型中使用了Batch
Normalization（BN）归一化方法，那么太小的BatchSize会影响模型效果，如果受算法或性能限制只能使用小的BatchSize，则建议在fine-tune时锁住BN归一化层，或者使用其它归一化方法（如Group
Normalization）。</p>
<p>另外，BN归一化时的统计值针对每一Batch计算，而非对整个训练集计算，从而引入了噪声，当噪声在合理范围以内时，它能实现类似Dropout的效果，使模型更加健壮；BatchSize太小噪声太大，则使模型效果变差；如果BatchSize太大，统计值能有效地表示整体训练数据的统计数据，则无法产生类似Dropout的正则化效果。</p>
<p><strong>BatchSize与Learning rate的关系</strong></p>
<p>Krizhevsky提出，如果BatchSize加大，可以加大学习率，当BatchSize加大k倍，则学习也加大k的开根号位数，后来发现使用线性变换调节二者关系效果更好。用这种方法将AlexNet的BatchSize从128加大到1024精度只损失1%。但是太大的学习率又会在一开始使模型训练不稳定，解决该问题的方法是学习率warm-up。</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>调节学习率</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7/%E8%B0%83%E8%8A%82%E5%AD%A6%E4%B9%A0%E7%8E%87/</url>
    <content><![CDATA[<h1 id="调节学习率">调节学习率</h1>
<p>#深度学习</p>
<p>在深度学习和其它一些循环迭代算法中，学习率都非常重要。在效率上，它几乎是与算力同等重要的因素；在效果上，它也决定着模型的准确率。如果设置太小，则收敛缓慢，也有可能收敛到局部最优解；设置太大又导致上下摆动，甚至无法收敛。</p>
<h3 id="设定学习率">设定学习率</h3>
<p>下面总结了设置学习率的一些方法：</p>
<ul>
<li><p>理论上，如果将学习率调大10倍，现在10次训练就可以达成之前100次的训练效果。</p></li>
<li><p>一般使用工具默认的学习率，如果收敛太慢，比如训练了十几个小时，在训练集和验证集上仍在收敛，则可尝试将学习率加大几倍，不要一下调成太大。</p></li>
<li><p>如果误差波动过大，无法收敛，则可考虑减小学习率，以便微调模型。</p></li>
<li><p>在测试阶段建议使用较大的学习率，在短时间内测算过拟合位置，尤其好用。</p></li>
<li><p>在预训练模型的基础上fine-tune模型时，一般使用较小的学习率；反之，如果直接训练，则使用较大的学习率。</p></li>
<li><p>对于不同层可使用不同学习率，比如可对新添加的层使用较大的学习率，或者“冻住”某些层。</p></li>
<li><p>下图展示了不同学习率的误差变化曲线。</p></li>
</ul>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-5334e5009bd03bf0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片来自网络" />
<figcaption aria-hidden="true">图片来自网络</figcaption>
</figure>
<h3 id="手动调节学习率">手动调节学习率</h3>
<p>Pytorch提供在迭代过程中修改学习率的方法。最简单的方法是手动修改学习率的值。优化器optimizer通过param_group提供对不同层使用不同的优化方法，其中每组参数保存了各自的学习率、动量等，如果只设置了一种优化方法，修改其第0组的lr即可，例如设置学习率加倍：
optimizer.param_groups[0]['lr'] *=2
在使用工具调整学习率的过程中，也可通过该值检测学习率的变化：<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">print(optimizer.state_dict()[&#x27;param_groups&#x27;][0][&#x27;lr&#x27;])  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">### 使用库函数调节  </span><br><span class="line">  </span><br><span class="line">更为简便的方法是使用torch.optim.lr_scheduler工具，它支持三种调整方法：  </span><br><span class="line">  </span><br><span class="line">* 有序调整    </span><br><span class="line">按一定规则调整，比如使用余弦退火(CosineAnnealing)，指数衰减(Exponential)，或者步长(Step)等事先定制的规则调整学习率。  </span><br><span class="line">  </span><br><span class="line">* 自适应调整    </span><br><span class="line">通过监测某个指标的变化情况(loss、accuracy)，当指标不再变好时，调整学习率 (ReduceLROnPlateau);  </span><br><span class="line">  </span><br><span class="line">* 自定义调整    </span><br><span class="line">使用自定义的lambda函数调整学习率(LambdaLR)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### 示例  </span><br><span class="line">  </span><br><span class="line">下面示例最简单的调整方法：每十次迭代，学习率减半  </span><br><span class="line">```  </span><br><span class="line">import torch  </span><br><span class="line">import torch.nn as nn  </span><br><span class="line">import matplotlib.pyplot as plt  </span><br><span class="line">%matplotlib inline  </span><br><span class="line">  </span><br><span class="line"># 构建一个简单的网络  </span><br><span class="line">class simpleNet(nn.Module):  </span><br><span class="line">    def __init__(self, in_dim, n_hidden, out_dim):  </span><br><span class="line">        super(simpleNet, self).__init__()  </span><br><span class="line">        self.layer1 = nn.Linear(in_dim, n_hidden)  </span><br><span class="line">        self.layer2 = nn.Linear(n_hidden, out_dim)  </span><br><span class="line">   def forward(self, x):  </span><br><span class="line">         x = self.layer1(x)  </span><br><span class="line">         x = self.layer2(x)  </span><br><span class="line">         return x  </span><br><span class="line">  </span><br><span class="line">model = simpleNet(5, 10, 8)  </span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=0.1) # 学习率初值0.1  </span><br><span class="line">scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5) # 每十次迭代，学习率减半  </span><br><span class="line">  </span><br><span class="line">arr = [] # 用于做图  </span><br><span class="line">for i in range(1,100):  </span><br><span class="line">    scheduler.step() # 学习率迭代次数+1  </span><br><span class="line">    arr.append(optimizer.state_dict()[&#x27;param_groups&#x27;][0][&#x27;lr&#x27;])  </span><br><span class="line">    #arr.append(scheduler.get_lr())  # 与上一句功能相同  </span><br><span class="line">plt.grid()  </span><br><span class="line">plt.plot(arr)     </span><br><span class="line">```  </span><br><span class="line">其运行结果如下图所示：  </span><br><span class="line">  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/5357893-8cc6f69fea37a301.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line">其它常用方法：  </span><br><span class="line">  </span><br><span class="line">多步长调整：在迭代到第10,30,50次时调整学习率，其它情况学习率不变。  </span><br><span class="line">```  </span><br><span class="line">scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [10,30,50], gamma=0.5)  </span><br><span class="line">```  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/5357893-337be0844a00294b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line">指数方式调整：每一次迭代，学习率呈指数方式变化lr=base_lr * (gamma**epoch)  </span><br><span class="line">```  </span><br><span class="line">scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)  </span><br><span class="line">```  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/5357893-2743f552b6c60fd5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line">余弦退火：设置每T_max次迭代后衰减到eta_min设置的最小值，然后逐渐恢复其初值，后面依此类推，往复波动：   </span><br><span class="line">```  </span><br><span class="line">scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=0.05)  </span><br><span class="line">```  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/5357893-3ac196781cad9914.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line">自适应调整：当误差或准确率达变化很小时调整学习率  </span><br><span class="line">```  </span><br><span class="line">torch.optim.lr_sheduler.ReduceLROnPlateau(optimizer, mode=&#x27;min&#x27;, factor=0.1, patience=10,  </span><br><span class="line">```  </span><br><span class="line">verbose=False, threshold=0.0001, threshold_mode=&#x27;rel&#x27;, cooldown=0, min_lr=0, eps=1e-08) （涉及环境较为复杂，此处不做示例）  自定义函数调整（最常用）：每次增加迭代次数的百分之一   </span><br><span class="line">```  </span><br><span class="line">lambdaf = lambda epoch: 0.05 + (epoch) / 100  </span><br><span class="line">scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambdaf)  </span><br><span class="line">```  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/5357893-fdf4bda220545c82.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">### Warmup  </span><br><span class="line">  </span><br><span class="line">深度学习网络往往非常庞大，有时候训练一次epoch需要数小时。学习率设置不合理会浪费大量时间。设置学习率需要确定三个问题：初始时的学习率、终止时的学习率，以及如何变化。其中的变化方法一般有直线变化，曲线变化，或者跳变，只要足够细化，使用哪种方法问题都不大；终止学习率可视学习效果设定，比如当模型在验证集上不再变好，可尝试将学习率调到更低。  </span><br><span class="line">  </span><br><span class="line">初始学习率的设置方法可借鉴论文《Cyclical Learning Rates for Training Neural Networks》。文中介绍了估计最小学习率和最大学习率的方法，比如在首次训练时（第1个epoch），先设置一个非常小的初始学习率，在每个batch之后都更新网络，同时增加学习率，统计每个batch计算出的loss，看增加到多大时，loss开始变差（很容易看到，调大到一定程度，loss变大，甚至变成nan），从而得到初始学习率。其核心在于将学习率由小变大。  </span><br><span class="line">  </span><br><span class="line">Warmup预热是一种非常流行的对学习率先升后降（三角学习率）的调整方法，就效果而言，通常情况下：三角学习率&gt; 按照auc逐步衰减&gt; 保持均值不变。  </span><br><span class="line">  </span><br><span class="line">尽管上述工具简化了调整学习率的工作，但暂时还未找到一种任何情况下都适用的方法，具体的学习率变化方法及其范围仍需要在具体数据集上实验。  </span><br><span class="line">  </span><br><span class="line">笔者的体验是在前期加了lr变大收敛往往非常快，后期变小效果又非常好。过于手调可能降低模型的泛化能力，但针对具体问题，尤其是在数据量较大的情况下（如训练一次几十个小时），一定要精调。使用指数，步长调节方法虽然看起来整整齐齐，但是限制也多，还是建立自己写lambda函数优化更到位，如果使用现成的工具，则根据其example以微调为主。  </span><br><span class="line">  </span><br><span class="line">下面展示一些warmup相关代码：  </span><br><span class="line">  </span><br><span class="line">定义warmup函数  </span><br><span class="line">```  </span><br><span class="line">def warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor):  </span><br><span class="line">    def f(x): # x是step次数  </span><br><span class="line">        if x &gt;= warmup_iters:  </span><br><span class="line">            return 1  </span><br><span class="line">        alpha = float(x) / warmup_iters # 当前进度 0-1  </span><br><span class="line">        return warmup_factor * (1 - alpha) + alpha  </span><br><span class="line">return torch.optim.lr_scheduler.LambdaLR(optimizer, f)  </span><br><span class="line">```  </span><br><span class="line">训练前设置  </span><br><span class="line">```  </span><br><span class="line">    lr_scheduler = None  </span><br><span class="line">    if warmup:  </span><br><span class="line">        warmup_factor = 1. / 1000  </span><br><span class="line">        warmup_iters = min(1000, len(train_loader) - 1)  </span><br><span class="line">        lr_scheduler = warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)  </span><br><span class="line">```  </span><br><span class="line">训练时每次优化后调用  </span><br><span class="line">```  </span><br><span class="line">            if lr_scheduler is not None:  </span><br><span class="line">                lr_scheduler.step()  </span><br><span class="line">                print(i, optimizer.state_dict()[&#x27;param_groups&#x27;][0][&#x27;lr&#x27;], np.mean(arr_loss))  </span><br><span class="line">                arr_lr.append(lr_scheduler.get_lr()[0]) # 加入数组用于后期绘图  </span><br><span class="line">                arr_loss_all.append(np.mean(arr_loss))  </span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>避免过拟合</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7/%E9%81%BF%E5%85%8D%E8%BF%87%E6%8B%9F%E5%90%88/</url>
    <content><![CDATA[<h1 id="避免过拟合">避免过拟合</h1>
<p>#深度学习</p>
<h3 id="欠拟合和过拟合">欠拟合和过拟合</h3>
<p>欠拟合是指在训练集和测试集（或验证集）上模型效果都不好，一般由于模型能力不足导致；过拟合是指模型在训练集上表现好，而在测试集上表现不好，一般由于模型过度拟合了训练集中的噪声导致。本文主要讨论解决过拟合问题的方法。</p>
<h3 id="l2正则化">L2正则化</h3>
<p>无论机器学习还是深度学习，L2正则化项都用于限制参数W过大，它被累加在代价函数之中。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-770dcf1607120a28.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>代价函数Ｊ除了计算每个实例的误差Ｌ，还加入网络中每层参数Ｗ的2范数的平方，并用λ作为参数，当λ较大时，就需要Ｗ接近０，才能得到较小的代价函数，这样一些无关紧要的参数就变成了０，从而减少了模型的复杂度，以及压缩后模型的规模。另外，较小的Ｗ也使层之间传递的数据变小，这样在使用sigmoid和tanh激活函数时，数据刚好集中在中间类似线性变换的一段，使非线性变换的结果类似线性变换。由于多个线性组合叠加相当于单个线性层，因此也倾向于简化模型。</p>
<p>如果使用L1正则化，参数矩阵将变得稀疏，根据经验，一般L2效果更好。L2正则化方法可用于简化决策，但不适用于需要复杂决策的问题。使用该方法时，需要尝试多个λ值。</p>
<h3 id="dropout方法">Dropout方法</h3>
<p>Dropout方法是扔掉网络中的一些连接,
使结果不依赖于某个特定结点，从而构成更健壮的网络。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-96b2d799e59c3357.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>具体方法是将层中一定比例的参数置为0，反向传播时也不调节这些参数。需要注意的是，在调试和预测阶段一般不使用Dropout。如果在调试时也随机去掉连接，则不能保证每次实验结果一致，导致无法比较模型修改前后的效果，预测时则需要尽可能地使用网络功能，因此也不能去掉连接。</p>
<p>另外，如果手工实现Dropout功能还需要考虑补偿系数，例如在某层将20%的参数置0，导致训练时该层的输出与预测时的分布不一致，则需要在训练时将该层输出除以0.8。</p>
<h3 id="归一化层">归一化层</h3>
<p>归一化层，也能在一定程度上缓解过拟合，它的原理与Dropout类似，都是引入噪声。比如Batch-Norm针对每个mini-batch计算均值和方差，而非对全体数据计算，相当于在训练集中加入了一些噪声，使得后面的层不过于依赖前层的某一单元。需要注意的是batch
size越大，引入的噪声越小，正则效果也越差。</p>
<h3 id="其它方法">其它方法</h3>
<p>还有一些方法也能缓解过拟合问题，如：</p>
<ul>
<li>增加训练数据，在数据不足时，加入变形后的数据（旋转、裁剪、水平翻转）。<br />
</li>
<li>Early stopping：当模型在验证集上不再下降时，停止迭代。<br />
</li>
<li>修改模型结构：训练样本过小，模型参数过多也是造成过拟合的原因，可尝试修改模型结构。</li>
</ul>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Attention注意力机制</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/Attention%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<h1 id="attention注意力机制">Attention注意力机制</h1>
<p>#深度学习</p>
<p>网上的文章总把Attention注意力机制和Transformer模型结合来讲，看起来非常复杂。实际上Attention不仅作用于自然语言处理领域，目前已是很通用的技术。本篇来看看Attention的原理，以及在各个领域的典型应用。</p>
<h3 id="原理">原理</h3>
<p>越来越多的模型用到注意力机制，它已成为与全连接，卷积，循环网络同等重要的技术。简单地说，当人观察图片时，一般先扫一眼，确定大概信息，然后聚焦在图中的重要区域，这个区域可能是某个物体，某种显著的特点，或者人脸等等。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ffc0c492e9bcc772.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>机器视觉，自然语言模型，跨模态模型都越来越多地使用到注意力技术。其核心是通过当前数据决定更关注哪一部分数据，给数据加权。</p>
<p>那么，同样是给特征加权，注意力和普通的全连接网络到底有何差异？主要差异在于是否与位置相关。全连接网络与位置强相关（比如下图中W11描述了x1到y1的映射关系，如果特征x1改变了位置，结果就会不同）。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-74c1738218515e95.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-905fa3216624c173.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>在使用Attention的过程中，我们希望聚焦于图中的动词，不管它出现在句中什么位置，希望聚焦于图中的人脸，而不管脸在图中的位置以及有几张脸……Attention计算出的也是权重，而这个权重可能是根据x1,x2,x3以及其它特征计算出来的。如：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ed252dde84e5ea34.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>此时的w不再是一个具体的权重值，而是根据x1的特征计算出来的是否需要更关注x1，比如当x1是人脸时，w1=f(x1)值较大，则给x1区域更大的权重。</p>
<p>上例是比较简单的情况，w1不仅可以使用x1的内容计算权重，还可以使用上下文数据（如在自然语言处理中使用附近的词计算某词权重，图片处理中使用周边内容给某区域加权），以及使用附加数据（如使用文字给图片某一区域加权，在翻译任务中在原文与译文之间通过注意力对齐）。</p>
<p>Attention与门控非常类似，比如LSTM中的输入门，输出门，遗忘门，都是利用当前时间步的输入x与之前激活层的状态，通过模型参数w,b以及sigmoid激活函数计算权重，用于确定对之前状态的遗忘，对当前输入的接纳，以及是否输出。与Attention一样，它们使用的都是数据加权的方法。</p>
<h3 id="使用场景">使用场景</h3>
<p>全连接网络可视为一个空间到另一空间的映射，它倾向于保持全局，只加入形变，相对地一视同仁；而Attention更关注局部特征，近似于筛选器。下面介绍使用注意力的几种典型场景。</p>
<p><strong>文字处理：划重点词</strong></p>
<p>计算词之间的关系，划出重点词是Attention的一个重要应用，无论词在句中的任何位置都能将其识别出来。比如句中有五个词，分别计算每四个词对另一个词的贡献度，然后给该词加权。此时Attention的输入是所有词特征，输出是每个词的权重。</p>
<p><strong>图片处理：重点区域</strong></p>
<p>图片注意力与文字注意力类似，通过图片各区域特征之间的关系，给某一区域，或某一通道加权也可以提升模型效果。图像处理中主要使用两种Attention，空间注意力和通道注意力。</p>
<p><strong>图文结合：用文字加强图片</strong></p>
<p>用文字给图片加权，比如可从网店下载商品图片和简单描述，通过文字描述，如“一字领”、“蕾丝花边”重点关注图片中某个区域，使图像处理更有针对性。模型的输入是文字w和图像中的区域v，通过计算它们之间的关系f(w,v)，给各个区域v加权。其中的f(w,v)一般使用全连接网络实现。</p>
<h3 id="具体方法">具体方法</h3>
<p>Attention计算的权值大小f(x)是特征x的函数，而x中的数据（如图中小区域的内容）由于代入模型的实例不同，各有差异。<strong>重点是一定要把自己的值x代进去，</strong>用文字t加强图片x时，把文字t也代入f()函数的计算。如果用t加强x时只使用y=x*f(t)，那么无论x是什么都进行同样的乘f(t)处理，忽略了x与t间的关系，这样就起不到加强局部的作用了。</p>
<p>下面看最简单的情况，x是输入，y是输出，z是用于修饰x的附加数据，a为attention值（假设attention的计算方法是一个简单的线性变换，不考虑过程中使用的激活函数）。</p>
<p>只使用全连接：</p>
<pre><code>y=w*x+b  </code></pre>
<p>使用z给x加权</p>
<pre><code>y=x*(zw+b)=x*z*w+x*b  </code></pre>
<p>使用attention</p>
<pre><code>y=xa  
a=(x+z)*w+b  
y=x*((x+z)*w+b)=x*x*w+x*z*w+x*b  </code></pre>
<p>从上面公式可以看出一阶和二阶的差异，且加入了条件z。</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>RNN循环神经网络公式总结</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AC%E5%BC%8F%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="rnn循环神经网络公式总结">RNN循环神经网络公式总结</h1>
<p>#深度学习 #时序</p>
<h3 id="rnn网络">RNN网络</h3>
<p>RNN模型计算分为两步，第一步，计算第ｔ个时间步的隐藏层ａ；第二步，计算t步的预测值ｙ。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-49e9aae8d8195041.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中Wax和Waa两组参数分别与前一层的激活a和当前数据x结合，也可将其合二为一，并与x和a的连接计算。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-4c139e0e785c818f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>在RNN网络中最常用激活函数是tanh，有时也用ReLU，一般只在最后一层使用sigmoid或softmax。</p>
<h3 id="lstm网络">LSTM网络</h3>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5cad267033a9af32.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>相对于基础的RNN，LSTM增加了c（Cell）状态单元，可将其看做在计算激活a的过程中保存的当前状态。它与a都在工作过程中一直向下一步传递。</p>
<p>公式中的Γ表示门控gate，门控使用sigmoid函数计算得出0-1之间的值，用于过滤（保留或去掉）数据。LSTM中增加的门控分别是：遗忘门f，输入门i和输出门o，它们分别控制在更新当前cell内容时，之前的cell占比，当前的cell占比，以及如何用cell生成ａ。</p>
<p>举个简单的例子：用LSTM生成文字，当输入“回车”时，说明本段已结束，之前的内容被遗忘门丢弃；当前输入是“笑脸”时，输入本身没太大意义，被输入门丢弃；如果之前输入了“本段没”，当前时间步又输入了“用”，加在一起是“本段没用”，则输出门将其丢弃。（请领会精神）。</p>
<p>一般RNN的层数不会特别多（三层就差不多了），除了层数以外，还需要按时间步向后传播，计算量也很大。门控值由前一激活层a和当前时间步的数据x计算得出，每一门控分别对应一组参数w和b，因此，参数比RNN大三倍。这与Attention注意力机制非常相似，用当前输入和当前状态计算权值，给数据流加权。</p>
<h3 id="gru网络">GRU网络</h3>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-6cc90eb12ab22784.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>GRU可视为LSTM的变体，它使用了两个门控，更新门u控制当前状态和之前状态的占比（LSTM使用输入门和遗忘门实现）；去掉了输出门，用状态值作为激活值，简化算法结构；另外加入了重置门r，用于控制当状状态对前一状态的依赖程度。</p>
<p>深度神经网络一般都面临梯度爆炸和梯度消失的问题，梯度爆炸问题可以通过加入归一化层或梯度修剪的方式解决，LSTM和GRU主要用于缓解梯度消失问题，如GRU中当更新门趋近0时，当前状态与之前状态相等，类似于用残差网络解决梯度消失问题。它使RNN网络能在更长的时间步中工作，并支持更深层次的网络。</p>
<h3 id="双向网络">双向网络</h3>
<p>双向网络在求y时，需要计算向前的激活层和向后的激活层，常用解决类似于完型填空的问题，需要考虑上下文的场景。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-9e39d54b87774c8f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>时序</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer-XL框架</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/Transformer-XL%E6%A1%86%E6%9E%B6/</url>
    <content><![CDATA[<h1 id="transformer-xl框架">Transformer-XL框架</h1>
<p>#自然语言处理</p>
<h3 id="引入">引入</h3>
<p>Transformer-XL超长上下文的注意力模型，出自CMU和Google
Brain在2019年1月发表的论文：《Transformer-XL: Attentive Language Models
Beyond a Fixed-Length Context》。其中XL是extra
long的缩写，意为额外长度。论文地址：<a
href="https://arxiv.org/pdf/1901.02860.pdf">https://arxiv.org/pdf/1901.02860.pdf</a>
先简单举例Transformer XL与Transformer 的区别。比如有以下数据：</p>
<p>“小说是以刻画人物形象为中心，通过完整的故事情节和环境描写来反映社会生活的文学体裁。”<br />
如果把序列长度设为十个字，代入模型时数据被切分为：<br />
“小说是以刻画人物形象”（序列一）<br />
“为中<strong>心</strong>，通过完整的故”（序列二）<br />
……</p>
<p>在训练第二个序列时，它的意思是不完整的，Transformer计算第二个序列中的第三字“心”时只能通过前两个字“为中”作为输入计算，而Transformer-XL可以把序列一中的十个字同时作为输入。</p>
<p>切分，尤其当英文中使用字符作为序列中的元素时，如果一个单词被切成两部分，分别位于前后两个序列中，必然影响模型效果。Transformer-XL让之前的序列也能参与到当前序列的预测中来，由此解决了长序列依赖问题，以及序列切断问题。</p>
<p>Transformer-XL既不像GPT-2一样使用海量数据训练，也没像ERNIE加入自然语言相关领域的知识，它主要通过改进模型的架构提高性能。它在字符级和词的级别上表现都很好（第一个在这两方面都超过RNN的自注意力模型），该方案不仅能应用于自然语言处理，在其它序列问题中也能发挥很好的效果。测试证明其在小数据集上也表现优异。</p>
<h3 id="原理">原理</h3>
<p>Transformer模型用Self-Attention自注意力机制替换了循环网络RNN，而Transformer-XL再次使用RNN，处理序列之间的连续性。Transformer
XL有两点重要创新：循环机制（Recurrence
Mechanism）和相对位置编码（Relative Positional Encoding）。</p>
<p><strong>循环机制</strong></p>
<p>尽管Transformer模型可以处理较长的上下文关系，但仍需要在训练时将文章切分成固定长度的序列，再代入模型。而模型学到的也是各序列内部的规律。</p>
<ul>
<li>若不切分，字串太长，尤其是以字符为单位时，计算注意力过于复杂。<br />
</li>
<li>按标点或按段切分，使程序效率下降。<br />
</li>
<li>按固定长度切分后，前后的语义被切断。</li>
</ul>
<p>Transformer
XL在输入数据的每个段上仍使用自注意力方法，并使用循环机制来学习连续段之间的依赖关系。</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-0a3f3d40682e1697.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片摘自论文" />
<figcaption aria-hidden="true">图片摘自论文</figcaption>
</figure>
<p>Transformer模型的依赖关系如上图(a)中的灰色线条所示，在每个序列中，当前层的输入取决于前一层的输出；Transformer-XL模型的依赖关系又加入了绿色连线，使当前层的输入取决于本序列和前一序列前一层的输出。具体公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-28f2b3c848f7a511.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中h为隐藏层，n为层数，r为序列数，W为模型参数。</p>
<p>式一计算当前第n-1隐藏层时，考虑了当前序列r上一个序列r-1的隐藏层值，其中SG意为stands
for
stop-gradient停止计算梯度，这样即运用了前一序列生成的数据，又不对其反向传播调参，节省了算力；中括号里的圆圈为连接两个隐藏层。</p>
<p>式二计算注意力所需的q,k,v，q用于查询当前位置，k用于提供相关位置信息，v用于提供相关位置的值。其中k和v使用了包括上个序列信息的隐藏层，而查询q只与当前序列相关。另外，第n个层是通过前一个序列和当前序列的n-1层算出来的，这和基础的循环网络RNN有所不同。</p>
<p>式三将q,k,v代入Transformer算法，计算隐藏层n。</p>
<p>上述方法在计算过程中保留了前一个序列的隐藏层输出ｈ，使得评价过程中不需要每次从头计算，也节约了算力。</p>
<p><strong>相对位置编码</strong></p>
<p>每个序列有其各自的位置编码，当使用多个序列作为输入时，则会出现位置冲突的问题。解决方法是将序列内部的绝对位置编码变为相对位置编码，并把在一开始计算位置编码，移到注意力打分时做计算。直觉上看，相对位置比绝对位置更重要，比如上例中“整”的前一个位置是“完”，一定比“整”在位置八时第七位置是“完”更合理。</p>
<p>具体方法是修改计算Attention的算法：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-371b5086d8611d2c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>上式中E表示词嵌入，U表示绝对位置信息，R为相对位置信息，W为模型参数，i是查询元素，j是相关元素。</p>
<p>式四使用绝对位置计算，先将词嵌入E和绝对位置U相加后，与参数相乘计算重要性权重，第二行将其展开。</p>
<p>式五使用相对位置计算，首先用相对位置R代替绝对位置U；由于不需要绝对位置U<sub>i</sub>,
引入了u,v参数，取代U<sub>i</sub><sup>T</sup>W<sub>q</sub><sup>T</sup>；另外将参数W<sub>k</sub>拆分成了W<sub>k,E</sub>和W<sub>k,R</sub>。式五又可分为四部分，含义分别是：</p>
<ol type="a">
<li>j的内容相对于i的影响<br />
</li>
<li>i与j的距离对于i的影响<br />
</li>
<li>j的内容相对于整体的影响<br />
</li>
<li>i与j的距离对于整体的影响</li>
</ol>
<p>相对编码和循环网络二者结合后才能提升模型效果。如果只加循环网络，则前一序列的位置编码可能与当前序列的位置编码混淆；如果只使用相对位置编码，那么无法解决句子的截断问题。</p>
<h3 id="代码">代码</h3>
<p>Git代码地址：<br />
<a
href="https://github.com/kimiyoung/transformer-xl">https://github.com/kimiyoung/transformer-xl</a></p>
<p>作者提供了Tensorflow、PyTorch两种代码实现，以Pytorch为例，其模型实现在pytorch/mem_transformer.py代码中，其模型的代码几乎是transformer代码量的两倍，但命令名规则一致。</p>
<p>层结构、注意力、位置编码与基本的Transformer模型大同小异，改进的核心在：保存之前隐藏层数据的mems和计算相对位置的Rel*LearnableMultiHeadAttn部分。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积网络CNN</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9CCNN/</url>
    <content><![CDATA[<h1 id="卷积网络cnn">卷积网络CNN</h1>
<p>#深度学习</p>
<p>卷积网络是近年来非常流行的网络结构，常用于处理图像（2维卷积）和自然语言（1维卷积）。在不明觉厉的情况下使用卷积层，往往使用别人设计的结构，凑参数往模型里塞，同复杂的原理书中的内容又有点对不上号。本篇从应用场景，具体用法入手，深入到每一个重要参数：具体用途、用法及计算方法。</p>
<h3 id="为什么使用卷积网络">为什么使用卷积网络</h3>
<p>先来看看全连接网络的参数：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a97b2d81521db39d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>网络有三个输入x1,x2,x3和两个输出y1,y2，具体计算方法是：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-06ec3f7b7468dc22.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>如果y1与x3没有什么关系，通过训练两者之间的参数w31可能趋近于0，但该连接仍然存在。对于输入为3输出为2的网络需要训练3<em>2=6个参数。图片数据非常庞大，如果训练一张1000</em>1000像素，RGB三通道的图片，则输入元素有3M个，如果第一个隐藏层有1000个元素，则需要训练1000<em>1000</em>3*1000个参数，使得网络非常庞大，同时需要非常大量的数据才能避免过拟合。</p>
<p>卷积网络的优势在于共享参数，比如一个3x3的检测物体边缘卷积核训练好后，即可用于整个图片，此时需要学习的参数只有3x3=9个，如果在一层中训练20个3x3的卷积核用于检测不同特征，也只需要训练3x3x20=60个参数。</p>
<p>需要注意的问题是使用同样一组参数（卷积核）处理层的多个输入特征时，每组输入特征需要具有共同的性质，才能被处理，比如图片中的每个小区域边缘都具有相同的性质，可使用同种方法检测；但是预测汽车价格时，各个特征都代表完全不同的含义，就无法将不同意义的特征分组后使用同样的方法处理。</p>
<h3 id="具体用法">具体用法</h3>
<p>卷积网络常用于图像处理，它常与池化层同时使用。以Pytorch为例，在模型的__init__初始化中创建层：</p>
<pre><code>self.conv=torch.nn.Conv2d(3,16,2,stride=1,padding=1)    
self.pool=torch.nn.MaxPool2d(4,4)    </code></pre>
<p>在forward前向传播时使用层：</p>
<pre><code>out = self.conv(X)    
out = self.pool(out)    </code></pre>
<p>传入卷积层的一般是４维数据[m,w,h,c]。此处创建的卷积层可以处理任意大小的图片。构造该层的参数如下：</p>
<pre><code>torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)    </code></pre>
<p>其中前五个参数最为重要：<br />
* in_channel：输入通道数<br />
* out_channel：输出通道数<br />
* kernel_size：卷积核大小<br />
* stride：步长<br />
* padding：扩边</p>
<p>下面从原理角度介绍各个参数的功能。</p>
<h3 id="重要概念">重要概念</h3>
<p>卷积网络的原理如下图所示，一个3x3的卷积核作用于6x6的图片之上，通过每个相邻的3x3区域计算一个值，具体方法是对应点做元素乘法之后相加，映射成右图中的一个点，然后逐步移动（Stride）遍历左图中所有区域，计算出右图中所有点作为输出。</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-8f03946db91737bd.gif?imageMogr2/auto-orient/strip"
alt="图片来自吴恩达深度学习" />
<figcaption aria-hidden="true">图片来自吴恩达深度学习</figcaption>
</figure>
<p><strong>kernel卷积核</strong></p>
<p>卷积核kernel，有时也叫作filter，具体的计算方法下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-f5b21910a457559a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>可以看到乘加的方法与全连接非常相似，不同的是使用卷积核之后，输出y中的每个元素只与部分x元素连接，计算量更小，即稀疏连接；使用同一组f与各个位置的x计算，参数更少，即共享参数。</p>
<p><strong>padding扩边</strong></p>
<p>上图中使用3x3的卷积核对6x6的图片做卷积操作，输出是3x3的图片，输出明显变小了，如果经过多次卷积图片会越变越小，另外，在卷积过程中边缘像素也被弱化了（边缘像素只对少数输出点起作用，使各像素点贡献不均衡）。为解决这一问题，一般工具都提供padding扩边功能，在卷积处理之前，延着边扩一圈（或者几圈），元素填充为0，如图片大小为6x6，padding为1时，图片大小变成8x8。目标是使得<strong>输出与处理之前的输入大小一致</strong>。</p>
<p>卷积可分为Valid Convolutions（带padding）和Same
Convolutions（不带padding）两种。padding的大小一般设置为p=(f+1)/2。其中f是卷积核大小，由于上/下，左/右都需要加边，所以除2，可以看到如果卷积核为偶数，则p有小数部分，因此，一般卷积核心都为奇数，以免造成不对称；另外，奇数填充有一个中心点，这样也能更好地描述卷积操作的位置。</p>
<p><strong>stride步长</strong></p>
<p>步长是卷积核在原图上每一步移动的距离。下图是步长为２时，第一步和第二步的卷积操作。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-7362750ec9cd014e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>简单地讲就是每次移动几个像素，stride一般设置为1或2，如何设置stride与卷积核大小相关，如果卷积核为3，步长为1，则各个卷积之间有一定的重叠；如果设置为４，则会漏掉一些像素。另外，如果stride设置较大会使输出图片变小，这也起到了一定的池化作用。</p>
<p>输出图片的大小可按以下公式计算：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-0946b0e817fdfd15.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中ｎ是图片大小，ｆ是卷积核大小，pad为扩边大小，stride为步长，注意当除法结果非整数时向下取整。</p>
<p><strong>channel通道</strong></p>
<p>通道变换是相对较难以理解的问题，从使用角度看，输入卷积层的是一张256x256x3，即长宽各为256像素，包含RGB三个颜色通道的图片，输出为32x32x16，即大小为32x32，提取了16组特征。下面来看看如何从3通道变成16通道。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-27e943bd852ea9e6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>如图所示，对三维数据进行三维卷积后，输出为二维（27次元素乘法之后做加法），如果使用16个三维卷积核做卷积，输出则是4x4x16个特征。可以说训练了16个卷积核，用于提取不同的16种特征。对照初始化时的操作，无需指定图片大小，只需指定输入通道数i，输出通道数o，即可提取o种特征。</p>
<p><strong>数据格式</strong></p>
<p>传入conv2d的数据格式一般是４维数组[m,w,h,c]，后三维分别是图片的宽高和输入通道数，第一维用于处理多张图片。需要注意的是forward时的输入通道数需要与初始化conv2d时设置的输入通道数一致。</p>
<p>###池化层</p>
<p>池化层的主要作用是缩小图片，以及提高鲁棒性。上面提到，通过卷积的步长也能达到使输出变小的效果，池化层的另一个重要功能提高鲁棒性。</p>
<p>池化层一般放置在卷积层之后，用于将某一种特征中的多个值用单个值表示，这里只讨论最简单普通的用法：与卷积层配合使用的池化层。最常见的两种池化分别是最大池化和平均池化，又以最大池化为主。</p>
<p>池化的主要参数也是：大小f，步长s，以及具体的池化方法max/mean。最常见的数池化是f=2,s=2,type=maxpool，如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-56260dbed1dfd528.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>maxpool可看作是提取了最显著的特征，另外，需要注意：</p>
<ul>
<li>池化可能有两个区域或者多个区域有重叠部分。<br />
</li>
<li>池化层没有需要训练的weight参数，也因为这个原因，在描述一个模型的层数时，一般不将池化层计算在内，只作为卷积层的附属。<br />
</li>
<li>对于三维数据，池化只对其中的wxh操作，输出的channel大小不变。</li>
</ul>
<h3 id="瓶颈层">瓶颈层</h3>
<p>瓶颈层的概念源于GoogleNet中提出inception，inception对输入图像并行执行多个卷积运算和池化操作，并将所有结果拼接为一个非常深地特征图（特征很多）。可以想见，这会引发大量计算，需要很多网络参数。</p>
<p>因此引入了瓶颈层，用于减少计算量，瓶颈指网络中最窄的位置。它常借助1x1的卷积层实现，上面介绍了创建一个卷积层至少需要指定输入通道数，输出通道数，以及卷积核大小，瓶颈层的卷积核大小为1x1，输入通道由输入数据决定，输出通道数人工指定，如果需要将192种特征压缩到16种，则输出通道设为16。因此，可以通过池化层缩减图片宽高，通过瓶颈层缩减通道数。</p>
<p>加入瓶颈层的方法不仅用于图像处理，在自然语言处理及其它功能的网络中也是常用技巧，比如某层输入为10000个元素，输出为1000个元素，则参数数量为10000x1000=10000000，如果加入100元素的瓶颈层，则计算参数为10000x100+1000x100=1100000，计算缩减到之前的十分之一。</p>
<h3 id="卷积网络常规用法">卷积网络常规用法</h3>
<ul>
<li>尽量使用论文中的超参数，不要自己从头设置。<br />
</li>
<li>网络结构中，一般wxh越来越小，channel越来越大，且常常是成倍减少或增加。<br />
</li>
<li>前边是若干卷积层，后面是一个或几个全连接层，最后是softmax。<br />
</li>
<li>层间数据越来越少，但不要下降太快。</li>
</ul>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>图片分割之_训练模型和预测</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E5%9B%BE%E7%89%87%E5%88%86%E5%89%B2%E4%B9%8B_%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%92%8C%E9%A2%84%E6%B5%8B/</url>
    <content><![CDATA[<h1 id="图片分割之_训练模型和预测">图片分割之_训练模型和预测</h1>
<p>#图形图像 #深度学习</p>
<h3 id="说明">1. 说明</h3>
<p> 本篇使用Mask
R-CNN算法，以及十几张从网络上下载的香蕉图片，训练一个模型。用于识别图像中的香蕉，不同于苹果，桔子，香蕉从不同的角度看差异很大，尤其是三五根香蕉放连在一起，或者整把香蕉的形态和单根香蕉差异很大。可以算是一种识别起来相对困难的水平。</p>
<p> 下图是用训练好的模型识别出的香蕉图片，可以看到，基本识别正确。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-da5f08774d71ba21.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 操作步骤可分为：安装工具，标注图片，修改源码，模型训练和模型预测。我的工作环境是Ubuntu，硬件有GPU支持，操作过程中使用了python，图片标注工具，以及shell脚本。</p>
<h3 id="安装工具">2. 安装工具</h3>
<p><strong>(1) 下载程序源码</strong></p>
<pre><code>$ git clone https://github.com/matterport/Mask_RCNN.git # (大概200多M)  </code></pre>
<p><strong>(2) 下载相关软件</strong></p>
<pre><code>$ sudo pip install opencv-python  
$ sudo pip install tensorflow  
$ sudo pip install scikit-image  
$ sudo pip install keras==2.0.8  
$ sudo pip install labelme # 标注工具  </code></pre>
<h3 id="标注图片">3. 标注图片</h3>
<p><strong>(1) 收集图片</strong></p>
<p> 香蕉图片可以从网上下载，也可用手机拍照，图片分辨率不用太高，1000x1000以下即可，如果分辨率太高，可用linux中的convert命令缩放。我使用的15张图片如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-34ace3d326fab314.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 需要注意的是，图片需要包括香蕉的各个角度，以及常见的多根组合的几种形态。</p>
<p><strong>(2) 用软件标注图片</strong></p>
<pre><code>$ labelme 图片文件名.jpg  </code></pre>
<p> labelme为一个图形化的标注工具，使用左侧面板中的create
polygons，将图片中所需识别的香蕉圈出来，如果某个点画错了，用Backspace可删除最后设置的点（用法类似于photoshop中的多边形套锁工具），标注完加入填入label名，这个名字后面在程序中会到，标注完注意保存文件，文件名默认为：图片名.json。锚点的细密程度请参考下图：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-2efff38ca0d65f21.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 标注无需粒度过细，Labelme工具比较智能，只要位置相近，就能把锚点自动贴近边界。好的工具让标注事半功倍，一般情况下，十几张图片半个多小时即可标注完成，另外，一个图中也可标注多个区域，label名都设置为banana即可。</p>
<p><strong>(3) 解析和拆分标注文件</strong></p>
<p> 使用labelme自带的 labelme_json_to_dataset 命令工具，可将 json
文件拆分成目录，目录中数据如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-eaed10a73e92e40d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 一条命令可以转换一个图片，当图片多时，建议使用 shell 脚本处理，shell
脚本示例如下，请根据环境调整。</p>
<pre><code>for file in `ls *.json`  
do  
    echo labelme_json_to_dataset $file  
    labelme_json_to_dataset $file  
done  
mkdir ../labelme_json/  
mv *_json ../labelme_json/  </code></pre>
<p><strong>(4) mask文件转码</strong></p>
<p> 由于不同版本的 labelme
生成的文件格式不同，有的mask是24位色，有的是8位色，用以下python程序看一下图片格式：</p>
<pre><code>from PIL import Image  
img = Image.open(None)  
print(img.mode)  </code></pre>
<p> 如果image.mode是P，即8位彩色图像，直接使用即可，如果是其它格式，使用以下程序将其转换成8位图片：</p>
<pre><code>Img_8 = img.convert(&quot;P&quot;)   
Img_8.save(None)  </code></pre>
<p> 将转换后的图片复制到另一文件夹即可，复制方法请参考以下shell脚本</p>
<pre><code>mkdir ../cv2_mask  
cd ../cv2_mask  
for file in `ls ../labelme_json`  
do  
    echo &#39;cp ../labelme_json/&#39;$file&#39;/label.png &#39;$file.png   
    cp &#39;../ labelme_json /&#39;$file&#39;/label.png&#39; $file.png   
done  </code></pre>
<p><strong>(5) 调整目录结构</strong></p>
<p> 把上述的原图放在pic目录中, 标注文件放在 json 目录中,
拆分后的标注文件放在 labelme_json 目录中，掩码mask放在cv2_mask目录中，
调整之后的目录结构如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-c75e101e618ef08b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 其中的 mine
本例中所有程序和数据，数据放在data目录中，训练好的模型放在models目录中。</p>
<h3 id="训练和预测">4. 训练和预测</h3>
<p><strong>(1) 训练模型</strong></p>
<p><strong>源码</strong></p>
<pre><code>import os  
import sys  
sys.path.append(xxxx) # 加入Mask_RCNN源码所在目录  
import random  
import math  
import re  
import time  
import numpy as np  
import cv2  
import matplotlib  
import matplotlib.pyplot as plt  
import tensorflow as tf  
from mrcnn.config import Config  
from mrcnn import model as modellib,utils  
from mrcnn import visualize  
import yaml  
from mrcnn.model import log  
from PIL import Image  
  
ROOT_DIR = os.getcwd()  
MODEL_DIR = os.path.join(ROOT_DIR, &quot;models&quot;)  
iter_num=0  
COCO_MODEL_PATH = os.path.join(ROOT_DIR, &quot;mask_rcnn_coco.h5&quot;)  
  
# 从网上下载训练好的基础模型  
if not os.path.exists(COCO_MODEL_PATH):  
    utils.download_trained_weights(COCO_MODEL_PATH)  
  
# 配置  
class ShapesConfig(Config):  
    NAME = &quot;shapes&quot; # 命名  
    GPU_COUNT = 1  
    IMAGES_PER_GPU = 1  
    NUM_CLASSES = 1 + 1  # 背景一类，香蕉一类，共两类  
    IMAGE_MIN_DIM = 320  
    IMAGE_MAX_DIM = 384  
    RPN_ANCHOR_SCALES = (8 * 6, 16 * 6, 32 * 6, 64 * 6, 128 * 6)  
    TRAIN_ROIS_PER_IMAGE = 100 # Aim to allow ROI sampling to pick 33% positive ROIs  
    STEPS_PER_EPOCH = 100  
    VALIDATION_STEPS = 50  
  
config = ShapesConfig()  
config.display()  
  
# 重写数据集  
class DrugDataset(utils.Dataset):  
    def get_obj_index(self, image):  
        n = np.max(image)  
        return n  
  
    # 获取标签  
    def from_yaml_get_class(self, image_id):  
        info = self.image_info[image_id]  
        with open(info[&#39;yaml_path&#39;]) as f:  
            temp = yaml.load(f.read())  
            labels = temp[&#39;label_names&#39;]  
            del labels[0]  
        return labels  
  
    # 填充mask  
    def draw_mask(self, num_obj, mask, image,image_id):  
        info = self.image_info[image_id]  
        for index in range(num_obj):  
            for i in range(info[&#39;width&#39;]):  
                for j in range(info[&#39;height&#39;]):  
                    at_pixel = image.getpixel((i, j))  
                    if at_pixel == index + 1:  
                        mask[j, i, index] = 1  
        return mask  
      
    # 读入训练图片及其配置文件  
    def load_shapes(self, count, img_floder, mask_floder, imglist, dataset_root_path):  
        self.add_class(&quot;shapes&quot;, 1, &quot;banana&quot;) # 自定义标签   
        for i in range(count):  
            filestr = imglist[i].split(&quot;.&quot;)[0]  
            mask_path = mask_floder + &quot;/&quot; + filestr + &quot;_json.png&quot;  
            yaml_path = dataset_root_path + &quot;labelme_json/&quot; + filestr + &quot;_json/info.yaml&quot;  
            cv_img = cv2.imread(None)  
            self.add_image(&quot;shapes&quot;, image_id=i, path=img_floder + &quot;/&quot; + imglist[i],  
                           width=cv_img.shape[1], height=cv_img.shape[0], mask_path=mask_path, yaml_path=yaml_path)  
  
    # 读取标签和配置   
    def load_mask(self, image_id):  
        global iter_num  
        print(&quot;image_id&quot;,image_id)  
        info = self.image_info[image_id]  
        count = 1  # number of object  
        img = Image.open(info[&#39;mask_path&#39;])  
        num_obj = self.get_obj_index(img)  
        mask = np.zeros([info[&#39;height&#39;], info[&#39;width&#39;], num_obj], dtype=np.uint8)  
        mask = self.draw_mask(num_obj, mask, img,image_id)  
        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)  
        for i in range(count - 2, -1, -1):  
            mask[:, :, i] = mask[:, :, i] * occlusion  
            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))  
        labels = []  
        labels = self.from_yaml_get_class(image_id)  
        labels_form = []  
        for i in range(len(labels)):  
            if labels[i].find(&quot;banana&quot;) != -1: # 自定义标签  
                labels_form.append(&quot;banana&quot;)  
        class_ids = np.array([self.class_names.index(s) for s in labels_form])  
        return mask, class_ids.astype(np.int32)  
  
#基础设置  
dataset_root_path=&quot;data/&quot;  
img_floder = dataset_root_path + &quot;pic&quot; # 基本图片目录  
mask_floder = dataset_root_path + &quot;cv2_mask&quot; # mask图片目录  
imglist = os.listdir(img_floder)  
count = len(imglist)  
  
# 构造训练集  
dataset_train = DrugDataset()  
dataset_train.load_shapes(count, img_floder, mask_floder, imglist, dataset_root_path)  
dataset_train.prepare()  
  
# 构造验证集  
dataset_val = DrugDataset()  
dataset_val.load_shapes(7, img_floder, mask_floder, imglist, dataset_root_path)  
dataset_val.prepare()  
  
# 建立模型  
model = modellib.MaskRCNN(mode=&quot;training&quot;, config=config,  
                          model_dir=MODEL_DIR)  
  
# 定义模式  
init_with = &quot;coco&quot;  # imagenet, coco, or last  
  
if init_with == &quot;imagenet&quot;:  
    model.load_weights(model.get_imagenet_weights(), by_name=True)  
elif init_with == &quot;coco&quot;:  
    model.load_weights(COCO_MODEL_PATH, by_name=True,  
                       exclude=[&quot;mrcnn_class_logits&quot;, &quot;mrcnn_bbox_fc&quot;,  
                                &quot;mrcnn_bbox&quot;, &quot;mrcnn_mask&quot;])  
elif init_with == &quot;last&quot;:  
    model.load_weights(model.find_last()[1], by_name=True)  
  
model.train(dataset_train, dataset_val,  
            learning_rate=config.LEARNING_RATE,  
            epochs=10,  
            layers=&#39;heads&#39;)  
  
model.train(dataset_train, dataset_val,  
            learning_rate=config.LEARNING_RATE / 10,  
            epochs=30,  
            layers=&quot;all&quot;)  
  </code></pre>
<p><strong>运行程序</strong></p>
<pre><code>$ python train.py  </code></pre>
<p> 在程序运行过程中，如果因为tensorflow版本与mask_rcnn不匹配，引起找不到keepdims问题，需要修改
Mask_RCNN/mrcnn/model.py，将其中的keepdims改为keep_dims即可。<br />
 我的机器训练完不到15分钟，如果把两次训练的迭代次数分别设成1和2则2分钟完成训练。</p>
<p><strong>(2) 预测模型</strong><br />
<strong>源码</strong></p>
<pre><code># -*- coding: utf-8 -*-  
  
import os  
import sys  
sys.path.append(os.path.dirname(os.getcwd())) # 注意：加mask_rcnn目录  
import skimage.io  
from mrcnn.config import Config  
from datetime import datetime   
import mrcnn.model as modellib  
from mrcnn import visualize  
  
ROOT_DIR = os.getcwd()  
sys.path.append(ROOT_DIR)  
MODEL_DIR = os.path.join(ROOT_DIR, &quot;models&quot;)  
  
# 配置，同train  
class ShapesConfig(Config):  
    NAME = &quot;shapes&quot;  
    GPU_COUNT = 1  
    IMAGES_PER_GPU = 1  
    NUM_CLASSES = 1 + 1  
    IMAGE_MIN_DIM = 320  
    IMAGE_MAX_DIM = 384  
    RPN_ANCHOR_SCALES = (8 * 6, 16 * 6, 32 * 6, 64 * 6, 128 * 6)  
    TRAIN_ROIS_PER_IMAGE =100  
    STEPS_PER_EPOCH = 100  
    VALIDATION_STEPS = 50  
  
class InferenceConfig(ShapesConfig):  
    GPU_COUNT = 1  
    IMAGES_PER_GPU = 1  
  
config = InferenceConfig()  
model = modellib.MaskRCNN(mode=&quot;inference&quot;, model_dir=MODEL_DIR, config=config)  
model.load_weights(&#39;models/shapes20190117T1428/mask_rcnn_shapes_0001.h5&#39;, by_name=True) # 注意换成你模型的路径  
#model.load_weights(&#39;models/shapes20190117T1428/mask_rcnn_shapes_0030.h5&#39;, by_name=True) # 注意换成你模型的路径  
#model.load_weights(&#39;mask_rcnn_coco.h5&#39;, by_name=True) # 注意换成你模型的路径  
  
class_names = [&#39;BG&#39;, &#39;banana&#39;]  
image = skimage.io.imread(None) # 注意事换成你要识别的图片  
  
a=datetime.now()   
results = model.detect([image], verbose=1)  
b=datetime.now()   
print(&quot;@@ detect duration&quot;,(b-a).seconds, &#39;second&#39;)  
r = results[0]  
# 画图  
visualize.display_instances(image, r[&#39;rois&#39;], r[&#39;masks&#39;], r[&#39;class_ids&#39;],   
                            class_names, r[&#39;scores&#39;])  
  </code></pre>
<p><strong>运行程序</strong></p>
<pre><code>$ python test.py  </code></pre>
<h3 id="分析总结">5. 分析总结</h3>
<ul>
<li><p>自动标注：当图片数量很多时，可以先训练少量图片，生成模型，让模型自动标注，人为检查标注是否正确，对于不正确的人工重新标注。</p></li>
<li><p>建议使用GPU：相比GPU，我用4核的CPU计算，速度目测差了50倍左右。个人觉得没有GPU，训练速度几乎是无法接受的。</p></li>
<li><p>迭代次数：迭代次数可以调整，如果同一个图，用网上下载的基础模型完全识别不出。而用第1次迭代和第30次迭代结果差不太多，以后再训练就可以减少迭代次数，以节约时间。</p></li>
<li><p>生成模型：由于迭代训练了30次，models目录下产生了30个模型文件，占空间比较大，不用的可以删除掉。</p></li>
<li><p>更多例程请参考原代码中的 Mask_RCNN/samples/ 目录。</p></li>
</ul>
<h3 id="问题及解决方法">6. 问题及解决方法</h3>
<ul>
<li>问题: 在CPU上运行时可能报错 SVD did not converge ，<br />
分析及解决：该问题发生成resize图片时，代码mrcnn/utils.py计算resize的scale里用两个int型相除，结果scale变成0，导致resize出错，解决访问是添加：scale
= float(max_dim) / image_max 强制类型转型即可。</li>
</ul>
<h3 id="参考">7. 参考</h3>
<ul>
<li><p>Mask RCNN训练自己的数据集<br />
<a
href="https://blog.csdn.net/l297969586/article/details/79140840">https://blog.csdn.net/l297969586/article/details/79140840</a></p></li>
<li><p>mask rcnn训练自己的数据集<br />
<a
href="https://blog.csdn.net/qq_29462849/article/details/81037343">https://blog.csdn.net/qq_29462849/article/details/81037343</a></p></li>
</ul>
]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>定向写作模型CTRL</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E5%AE%9A%E5%90%91%E5%86%99%E4%BD%9C%E6%A8%A1%E5%9E%8BCTRL/</url>
    <content><![CDATA[<h1 id="定向写作模型ctrl">定向写作模型CTRL</h1>
<h3 id="介绍">介绍</h3>
<p>CTRL全称为Conditional Transformer
Language有条件的文本生成模型，它始于Salesforce在2019年发布的论文《A
Conditional Transformer Language Model for Controllable
Generation》，该模型用于定向写作。论文地址如下：<a
href="https://arxiv.org/pdf/1909.05858.pdf">https://arxiv.org/pdf/1909.05858.pdf</a></p>
<p>这两年非常流行的BERT和GPT-2都基于Transformer模型，虽然代码量不大，逻辑也并不复杂，但是极大规模的数据量、训练强度和模型容量，以及利用无监督文本建模，使模型的能力空前强大，在一些领域已超过人类水平。</p>
<p>GPT-2使用各种类型的文章训练模型，包括散文、小说、新闻、科技文章，用它写作的文章也综合了各种风格。如果想生成“金庸风格”的小说，则需要用所有金庸先生的小说重新训练模型；或者从原模型中提取特征构造新模型；也可以在原有模型基础上fine-tuning。如需撰写新闻稿，则需要另行训练。</p>
<p>GPT-2模型根据文章开头的内容，继续向后联想，控制不了文章的具体内容，因此也有人把它称为“造谣神器”。除了瞎编，它的实际用途又在何处？如何更好的控制文章的内容，生成有价值的文本。</p>
<p>CTRL是继GPT-2后出现的写作模型，同样也基于Transformer。与之前模型不同的是：它无需进一步训练就可以解决特定领域的具体问题。CTRL模型可以指定文章的领域、风格、主题、时间、实体，实体间的关系，以及任务相关的行为等等，因此可以将其看成命题作文。它使用140G数据训练，参数规模1.63
billion（16亿，比GPT-2更大）。模型维度1280维，48层EncoderLayer，16头Attention，也是一个体量巨大的模型。</p>
<p>CTRL模型的最大优势是在生成文本时可指定文章的类型，同一模型可以写作不同风格的文章。论文也举出了用同一开头续写不同类型文章的实例，比如高分评论和低分评论的差异；“刀”在购物评论和恐怖小说的场景中生成的不同文章；按时间、国家写出文章中涉及的不同总统等等。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-eba60d8845368916.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>不同的角度，有不同的答案。换言之，CTRL关注了语料在不同场景中的不同含义。模型更符合实际应用的场景：使用者在同一时间，只可能生成某一特定类型，同时又希望单个模型支持生成各种类型的文章，CTRL可视为多任务学习。</p>
<p>由人写一个故事梗概：时间、地点、人物、事件，用模型按照某种风格遣词造句填充内容。它与之前的问答系统、文章概要又有何区别呢？原来的模型先用无监督数据训练模型，然后用有标注的问与答，内容与概要代入模型调优。标注数据毕竟有限；CTRL则海量的无监督数据进行了分类，这类似于简单的自动标注，让数据从一开始就更有针对性。</p>
<h3 id="具体实现">具体实现</h3>
<p>CTRL的核心思想是从无监督的海量数据集中定位文章所在的领域。大多数训练数据都从网络上抓取，在抓取过程中通过网址标题等信息估计它所在领域，并作为特征，代入训练。从而让模型写出各种类型的文章，同理在问答等领域中运用此技术，也可以更有针对性地解决问题。</p>
<p>CTRL底层同样也基于Transformer，使用了其中Encoder部分，模型底层改动不大。之前的模型是根据词序列中的前n-1个词计算下一个词n是哪个词的可能性，如式一所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-b3ab41c8d9bebc93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="（式一）" /><br />
CTRL又加入了条件c，即文章的控制信息如类型，在计算概率的同时考虑条件c。具体操作是在每一个序列的具体内容前加了入类型描述，使得在计算Attention过程中，类型与序列中的所有元素建立联系。如式二所示：</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-c36978b64348c1e0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="（式二）" />
<figcaption aria-hidden="true">（式二）</figcaption>
</figure>
<p>代码中定义了一些常见，并且可以在抓取时识别的类型，如下图示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-57a8c4206359f6cf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>除了类型，还支持将标题、下载的地址（有些下载地址中包含时间、实体等信息）……放在正文之前。除了上述改进，它还引入了新算法优化了后序词的筛选逻辑。</p>
<h3 id="代码分析">代码分析</h3>
<p>CTRL官方代码可从以下网址下载： <a
href="https://github.com/salesforce/ctrl">https://github.com/salesforce/ctrl</a></p>
<p>其中包括TensorFlow和Pytorch
两种实现方法，又细分为训练和应用两部分。以Pytorch为例，其核心代码主要在pytorch_transformer.py和pytorch_generation.py两个文件中。pytorch_transformer.py主要实现了Transformer模型，其内容是基础版Transformer模型的Encoder部分。pytorch_generation.py用于使用该模型撰写文章，其中包含解析数据和调用模型的方法。需要注意的是，使用该模型时，序列的第一位应为类型。模型训练部分在training_utils目录中用TensorFlow实现。</p>
<p>相对官方代码，更推荐Hugging
Face团队发布的Transformer例程集，支持TensorFlow和Pytorch两种实现方式，其中也包含CTRL的实现，源码位置在：</p>
<p><a
href="https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_ctrl.py">https://github.com/huggingface/transformers/blob/master/src/transformers/</a></p>
<p>实现Pytorch版本CTRL的代码有：configuration_ctrl.py, modeling_ctrl.py,
tokenization_ctrl.py，其中核心是modeling_ctrl.py，建议读者用debug工具跟踪调用模型的完整流程，查看每一步的输入及输出，便可完全理解该模型。调用方法如下：</p>
<pre><code>01 import torch  
02 from transformers import CTRLTokenizer, CTRLModel  
03 tokenizer = CTRLTokenizer.from_pretrained(&#39;ctrl&#39;)  
04 model = CTRLModel.from_pretrained(&#39;ctrl&#39;)、input_ids =  
05 torch.tensor(tokenizer.encode(&quot;Links Hello, my dog is cute&quot;,  
06 add_special_tokens=True)).unsqueeze(0) # Batch size 1  
07 outputs = model(input_ids)  </code></pre>
<p>注意：运行时将下载6.5G的预训练模型，虽然模型很大，但在没有GPU且机器性能不高的情况下也能正常调用模型预测部分。</p>
<h3 id="总结">总结</h3>
<p>CTRL不仅是一个自然语言处理问题的解决方案，同样也可应用到其它的序列处理问题之中。从NLP的演进可以看到，用无标注数据训练模型，生成一般性“常识”逐渐成为主流。人工不可能标注海量信息，目前，人们正试图使用更多知识和分析方法处理信息，并将知识融入模型结构，使人与工具更好地结合，并生成更加可控的模型。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>序列对抗网络SeqGAN</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E5%BA%8F%E5%88%97%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9CSeqGAN/</url>
    <content><![CDATA[<h1 id="序列对抗网络seqgan">序列对抗网络SeqGAN</h1>
<p>#自然语言处理 #机器学习</p>
<p>SeqGAN源自2016年的论文《SeqGAN: Sequence Generative Adversarial Nets
with Policy
Gradient》，论文地址：https://arxiv.org/pdf/1609.05473.pdf。其核心是用生成对抗网络处理离散的序列数据。</p>
<p>之前介绍了使用GAN生成图像的方法，由于图像是连续数据，可以使用调整梯度的方法逐步生成图像，而离散数据很难使用梯度更新。在自然语言处理（NLP）中使用GAN生成文字时，由于词索引与词向量转换过程中数据不连续，微调参数可能不起作用；且普通GAN的判别模型只对生成数据整体打分，而文字一般都是逐词（token）生成，因此无法控制细节。SeqGAN借鉴了强化学习（RL）的策略，解决了GAN应用于离散数据的问题。</p>
<h3 id="概念">概念</h3>
<p>与基本的GAN算法一样，SeqGAN的基本原理也是迭代训练生成模型G和判别模型D。假设用G生成一个词序列组成句子，由D来判别这个句子是训练集中的真实句子（True
data），还是模型生成的句子（Generate）；最终目标是用模型G生成以假乱真的句子，让D无法分辨。其操作过程如下：</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-920055a2ec8da4d5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片摘自论文" />
<figcaption aria-hidden="true">图片摘自论文</figcaption>
</figure>
<p>与普通对抗不同的是，在单次操作中，模型多次调用生成模型G和判别模型D。以生成文字为例，右侧的每一个红圈是一个生成词的操作，State为已生成的词串，在生成下一个词Next
action时，先调用生成模型G生成多个备选项，然后使用判别模型对各个选项评分（reward），根据评分选择最好的策略Policy，并调整策略模型（Policy
Gradient）。</p>
<h3 id="强化学习">强化学习</h3>
<p>SeqGAN主要借鉴了强化学习中的方法，如果不了解强化学习很难看懂论文中的公式和推导，下面先对强化学习做一个简单的介绍。</p>
<p>强化学习的核心是在实践中通过不断试错来学习最好的策略，一般强化学习学到的是一系列决策，其目标是最大化长期收益，例如围棋比赛中当前的操作不仅需要考虑接下来一步的收益，还需要考虑未来多步的收益。</p>
<p>强化学习有几个核心概念：状态s（State）、动作a（Action）、奖励r（Reward）。以生成词系列为例，假设词系列是Y1:T=(y1,...,yt,...,yT)，在第t个时间步，状态s是先前已生成的词(y1,...,yt−1)，动作a是如何选择要生成的词yt，这也是生成模型的工作Gθ(yt|Y1:t−1)，它通过前t-1个词以及模型参数θ来选择下一个词，确定了该词之后，状态也随之改变成s’，对应词(y1,...,yt)，以此类推，最终生成的系列(y1,...,yt,...,yT)，对序列的评分就是奖励r，如果生成的系列成功地骗过了判别模型D，则得1分，如果被识别出是机器生成的则得0分。</p>
<p>强化学习中还有两个重要概念：动作价值action-value和状态价值state-value。简单地说，动作价值就是在某个状态选择某一动作是好是坏，如果能确定每一个动作对应的价值，就很容易做出决定。动作价值不仅与当前动作有关，还涉及此动作之后一系列动作带来的价值。状态价值也是同理，它表示某个状态的好坏。</p>
<h3 id="seqgan原理">SeqGAN原理</h3>
<p>SeqGAN中生成模型G的目标是最大化期望奖励reward，简单说就是做出可能是奖励最大的选择，其公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5f912daa74dbd3ff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>上式中J是目标函数，E[]是期望，R是序列整体的奖励值，s是状态，θ是生成模型的参数，y是生成的下一个词（动作action），G是生成模型，D是判别模型，Q是动作价值（action-value）。简单地解释公式：希望得到一组生成模型G参数θ；能在s0处做出最佳选择，获取最大回报RT，而如何选择动作又取决于动作的价值Q。</p>
<p>动作价值算法如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-55e71b938e2590f2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>动作价值是由判别函数D判定的，第T个时间步是最后一个时间步，上式中列出的是判别函数对完整系列的打分。若判别该序列为真实文本，则奖励值R最大。</p>
<p>在生成第t个词时，如何选择（动作ａ）涉及前期已生成的t-1个词（状态ｓ），以及后续可能的情况，假设此时用模型Gβ生成Ｎ个备选词串（Yt:T），再用判别模型D分别对生成的N句（Y1:T）打分，此时使用了蒙特卡洛方法（MC），如下式所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d906ac3785650c21.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>这里的生成模型Gβ与前面Gθ通常使用同样的模型参数，有时为了优化速度也可使用不同模型参数。这里使用的蒙特卡洛算法，像下棋一样，不仅要考虑当前一步的最优解，还需要考虑接下来多步组合后的最优解，用于探索此节点以及此节点后续节点（Yt:T）的可能性，也叫roll-out展开，是蒙特卡洛搜索树中的核心技巧。</p>
<p>根据不同的时间步，采取不同的动作价值计算方法：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-c1cb70ae36dc1520.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>在最后一个时间步t=T时，直接使用判别函数D计算价值；在其它时间步，使用生成模型Gβ和蒙特卡洛算法生成Ｎ个后续备选项，用判别函数D打分并计算分数的均值。</p>
<p>SeqGAN与GAN模型相同，在训练生成器G的同时，判别器D也迭代地更新其参数。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d710e635fdb87ec7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>此处公式与GAN相同，即优化判别模型D的参数φ，使其对真实数据Pdata尽量预测为真，对模型Gθ生成的数据尽量预测为假。</p>
<h3 id="主要流程">主要流程</h3>
<p>其主要流程如下：</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-fd23c683c671358f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片摘自论文" />
<figcaption aria-hidden="true">图片摘自论文</figcaption>
</figure>
<ul>
<li><p>程序定义了基本生成器Gθ，roll-out生成器Gβ，判别器D，以及训练集S。</p></li>
<li><p>用MLE（最大似然估计）预训练生成器G。（2行）</p></li>
<li><p>用生成器生成的数据和训练集数据预训练判别器D。（4-5行）</p></li>
<li><p>进入迭代对抗训练：（6行）</p></li>
<li><p>训练生成器（7-13行）<br />
在每一个时间步计算Q，<strong>这是最关键的一步</strong>，它利用判别器Ｄ、roll-out生成器Gβ以及蒙特卡罗树搜索计算行为价值，然后更新policy
gradient策略梯度。</p></li>
<li><p>训练判别器（14-17行）<br />
将训练数据作为正例，生成器生成的样例作为反例训练判别模型D。</p></li>
</ul>
<h3 id="代码">代码</h3>
<p>推荐以下代码：</p>
<p>TensorFlow代码（官方）：<a
href="https://github.com/LantaoYu/SeqGAN">https://github.com/LantaoYu/SeqGAN</a> <br />
Pytorch代码：<a
href="https://github.com/suragnair/seqGAN">https://github.com/suragnair/seqGAN</a></p>
<p>其中Pytorch代码比较简单，与论文中描述的模型不完全一致，比如它的G和D都使用GRU作为基础模型，也没有实现rollout逻辑，只是一个简化的版本，优点在于代码简单，适合入门。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>怎么看目标检测的效果</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%80%8E%E4%B9%88%E7%9C%8B%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E6%95%88%E6%9E%9C/</url>
    <content><![CDATA[<h1 id="怎么看目标检测的效果">怎么看目标检测的效果</h1>
<p>#图形图像 #深度学习</p>
<p>怎么看目标检测的效果</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-27f97daf8bc78daa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<ol type="1">
<li><p>Recall&amp;Precision<br />
引用一个知乎上的例子：某池塘有1400条鲤鱼，300只虾，300只鳖。现在以捕鲤鱼为目的。撒一大网，逮着了700条鲤鱼，200只虾，100只鳖。那么，这些指标分别如下：正确率
Precision = 700 / (700 + 200 + 100) = 70% 召回率 Recall = 700 / 1400 =
50%<br />
（出处：<a
href="https://www.zhihu.com/question/19645541/answer/39732647">https://www.zhihu.com/question/19645541/answer/39732647</a>）</p></li>
<li><p>IoU：预测区域和目标区域重合比例，即交集除并集</p></li>
</ol>
<ol type="a">
<li>IoU=0.50: 重合比例大于0.5的算正例。<br />
</li>
<li>IoU=0.75: 重合比例大于0.75的算正例。<br />
</li>
<li>IoU=0.50:0.95: 从0.50到0.95每隔0.5计算一次，然后取均值。</li>
</ol>
<ol start="3" type="1">
<li>area：区域大小</li>
</ol>
<ol type="a">
<li>small：x&lt;32x32<br />
</li>
<li>medium：32x32&lt;x&lt;96x96<br />
</li>
<li>large：x&gt;96x96</li>
</ol>
<ol start="4" type="1">
<li><p>maxDets：最多取几个目标区域</p></li>
<li><p>其它：需要注意，区域评价的前提是类别正确</p></li>
</ol>
]]></content>
      <tags>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>梯度攻击</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A2%AF%E5%BA%A6%E6%94%BB%E5%87%BB/</url>
    <content><![CDATA[<h1 id="梯度攻击">梯度攻击</h1>
<p>#深度学习</p>
<p>模型攻击主要指人为地制造干扰迷惑模型，使之产生错误的结果。随着深度学习模型的广泛使用，人们发现它很容易被数据的轻微扰动所欺骗，于是开始寻找更加有效的攻击方法，针对攻击又有对抗攻击的方法，二者相互推进，不仅加强了模型的健壮性，有时还能提升模型的准确度。</p>
<h3 id="原理">原理</h3>
<p>想让攻击更加有效，导致模型分类错误，也就是使损失函数的值变大。正常训练模型时，输入x是固定的，标签y也是固定的，通过训练调整分类模型的参数w，使损失函数逐渐变小。而梯度攻击的分类模型参数w不变（分类逻辑不变），y也固定不变，若希望损失函数值变大，就只能修改输入。下面就来看看如何利用梯度方法修改输入数据。</p>
<h3 id="fgsm">FGSM</h3>
<p>FGSM是比较早期的梯度攻击算法，源于2015年的论文《EXPLAINING  AND
HARNESSING ADVERSARIAL EXAMPLES》，论文地址：<a
href="https://arxiv.org/pdf/1412.6572.pdf">https://arxiv.org/pdf/1412.6572.pdf</a>。FGSM全称是Fast
Gradient Sign
Method快速梯度下降法。其原理是<strong>求模型误差函数对输入的导数</strong>，然后用符号函数得到其梯度方向，并乘以一个步长ε，将得到的“扰动”加在原来的输入数据之上就得到了攻击样本。其公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-1eff2c8b6067e901.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中L是损失函数，θ是模型参数，x是输入，x’是扰动后的输入，y是输出，sgn是符号函数，ε为步长。由于只对数据做一次扰动，计算速度非常快，因此有Fast，而累加项是梯度方向，而不是梯度本身，因此有Sign，此种添加扰动的方法就称为Fast
Gradient Sign Method。</p>
<p>2017年，FGSM的作者又提出了FGM，对 FGSM
中符号函数部分做了一些修改，以便攻击文本。</p>
<h3 id="pgd">PGD</h3>
<p>PGD是FGSM的改进版本，它源于2018年的论文《Towards Deep Learning Models
Resistant to Adversarial Attacks》，论文地址：<a
href="https://arxiv.org/pdf/1706.06083.pdf">https://arxiv.org/pdf/1706.06083.pdf</a>。</p>
<p>FGSM从始至终只做了一次修改，改动的大小依赖步长ε，如果步长太大，则原数据被改得面目全非，如果改动太小又无法骗过模型。一般做干扰的目的是保持数据原始的性质，只为骗过模型，而非完全替换数据。如下图所示，当做了一个步长很大的扰动之后，原图直接变成了另一张图，不但机器无法辨认，人也无法辨认。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-c6e315b007b8342c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>为了让扰动更加小而有效，出现了迭代修改的方法PGD，每次进行少量修改，扰动多次，这样既避免了抖动过大，同时多次迭代又能在多个方向上修改复杂模型。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-71b1dcf3d59cb9ee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a10d247dc6ac532e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>注意等式右边的∏在这里不是连乘符号，它保证扰动过程中的数据x始终处于限制范围之内（若过大则裁剪）。此公式与类似FGSM类似，其中的α是每次修改的步长，而每一次修改的x<sup>t+1</sup>都基于其前一次修改x<sup>t</sup>。论文中提到，PGD攻击是最强的一阶攻击，由于相对复杂，PGD也需要更多的时间和算力。</p>
<h3 id="例程">例程</h3>
<p>以上两种算法原理都非常简单，而实际操作中，比较困难的是如何对输入求取梯度。下面使用识别Mnist手写体数据集为例展示攻击效果，先训练一个识别率在95%以上的模型，然后分别用两种方法加入扰动，并分析其识别率的变化。例程分为三部分：训练分类模型、攻击、做图。</p>
<p>训练分类模型：</p>
<pre><code>import torch  
import torch.nn as nn  
import torch.nn.functional as F  
import torch.optim as optim  
from torchvision import datasets, transforms  
from torch.autograd import Variable  
import numpy as np  
import matplotlib.pyplot as plt  
  
class Net(nn.Module):  
    def __init__(self):  
        super(Net, self).__init__()  
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)  
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)  
        self.conv2_drop = nn.Dropout2d()  
        self.fc1 = nn.Linear(320, 50)  
        self.fc2 = nn.Linear(50, 10)  
  
    def forward(self, x):  
        x = F.relu(F.max_pool2d(self.conv1(x), 2))  
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))  
        x = x.view(-1, 320)  
        x = F.relu(self.fc1(x))  
        x = F.dropout(x, training=self.training)  
        x = self.fc2(x)  
        return x  
  
device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) #启用GPU  
train_loader = torch.utils.data.DataLoader(  # 加载训练数据  
    datasets.MNIST(&#39;datasets&#39;, train=True, download=True,  
                   transform=transforms.Compose([  
                       transforms.ToTensor(),  
                       transforms.Normalize((0.1307,), (0.3081,))  
                   ])),  
    batch_size=64, shuffle=True)  
  
model = Net()  
model = model.to(device)  
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)  # 初始化优化器  
  
for epoch in range(1, 10 + 1):  # 共迭代10次  
    for batch_idx, (data, target) in enumerate(train_loader):  
        data = data.to(device)  
        target = target.to(device)  
        data, target = Variable(data), Variable(target)  
        optimizer.zero_grad()  
        output = model(data) # 代入模型  
        loss = F.cross_entropy(output,target)  
        loss.backward()  
        optimizer.step()  
        if batch_idx % 100 == 0:  
            print(&#39;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#39;.format(  
                epoch, batch_idx * len(data), len(train_loader.dataset),  
                       100. * batch_idx / len(train_loader), loss.item()))  
  
torch.save(model, &#39;datasets/model.pth&#39;) #保存模型  </code></pre>
<p>攻击：</p>
<pre><code>USE_PGD = False  
  
def draw(data):  
    ex = data.squeeze().detach().cpu().numpy()  
    plt.imshow(ex, cmap=&quot;gray&quot;)  
    plt.show()  
      
def test(model, device, test_loader, epsilon, t = 5, debug = False):  
    correct = 0  
    adv_examples = []  
  
    for data, target in test_loader:  
        data, target = data.to(device), target.to(device)  
        data.requires_grad = True # 以便对输入求导 ** 重要 **  
        output = model(data)  
        init_pred = output.max(1, keepdim=True)[1]  
        if init_pred.item() != target.item(): # 如果不扰动也预测不对，则跳过  
            continue  
        if debug:  
            draw(data)  
              
        if USE_PGD:              
            alpha = epsilon / t # 每次只改变一小步  
            perturbed_data = data  
            final_pred = init_pred  
            #while target.item() == final_pred.item(): # 只要修改成功就退出  
            for i in range(t): # 共迭代 t 次  
                if debug:  
                    print(&quot;target&quot;, target.item(), &quot;pred&quot;, final_pred.item())  
                loss = F.cross_entropy(output, target)   
                model.zero_grad()  
                loss.backward(retain_graph=True)  
                data_grad = data.grad.data # 输入数据的梯度 ** 重要 **  
  
                sign_data_grad = data_grad.sign() # 取符号（正负）  
                perturbed_image = perturbed_data + alpha * sign_data_grad # 添加扰动  
                perturbed_data = torch.clamp(perturbed_image, 0, 1) # 把各元素压缩到[0,1]之间  
  
                output = model(perturbed_data) # 代入扰动后的数据  
                final_pred = output.max(1, keepdim=True)[1] # 预测选项  
                if debug:  
                    draw(perturbed_data)  
        else:  
            loss = F.cross_entropy(output, target)   
            model.zero_grad()  
            loss.backward()  
  
            data_grad = data.grad.data # 输入数据的梯度 ** 重要 **  
            sign_data_grad = data_grad.sign() # 取符号（正负）  
            perturbed_image = data + epsilon*sign_data_grad # 添加扰动  
            perturbed_data = torch.clamp(perturbed_image, 0, 1) # 把各元素压缩到[0,1]之间  
  
            output = model(perturbed_data) # 代入扰动后的数据  
            final_pred = output.max(1, keepdim=True)[1]  
          
        # 统计准确率并记录，以便后面做图  
        if final_pred.item() == target.item():  
            correct += 1  
            if (epsilon == 0) and (len(adv_examples) &lt; 5):  
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()  
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))  
        else: # 保存扰动后错误分类的图片  
            if len(adv_examples) &lt; 5:  
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()  
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))  
  
    final_acc = correct / float(len(test_loader)) # 计算整体准确率  
    print(&quot;Epsilon: &#123;&#125;\tTest Accuracy = &#123;&#125; / &#123;&#125; = &#123;&#125;&quot;.format(epsilon, correct, len(test_loader), final_acc))  
    return final_acc, adv_examples  
  
epsilons = [0, .05, .1, .15, .2, .25, .3] # 使用不同的调整力度  
pretrained_model = &quot;datasets/model.pth&quot;  # 使用的预训练模型路径  
  
test_loader = torch.utils.data.DataLoader(  
    datasets.MNIST(&#39;datasets&#39;, train=False, download=True, transform=transforms.Compose([  
        transforms.ToTensor(),  
    ])),  
    batch_size=1, shuffle=True  
)  
model = torch.load(pretrained_model, map_location=&#39;cpu&#39;).to(device)  
model.eval()  
  
accuracies = []  
examples = []  
for eps in epsilons:  # 每次测一种超参数  
    acc, ex = test(model, device, test_loader, eps)  
    accuracies.append(acc)  
    examples.append(ex)  </code></pre>
<p>做图</p>
<pre><code># 做图  
plt.figure(figsize=(8,5))  
plt.plot(epsilons, accuracies, &quot;*-&quot;)  
plt.yticks(np.arange(0, 1.1, step=0.1))  
plt.xticks(np.arange(0, .35, step=0.05))  
plt.title(&quot;Accuracy vs Epsilon&quot;)  
plt.xlabel(&quot;Epsilon&quot;)  
plt.ylabel(&quot;Accuracy&quot;)  
plt.show()  
  
cnt = 0  
plt.figure(figsize=(8,10))  
for i in range(len(epsilons)):  
    for j in range(len(examples[i])):  
        cnt += 1  
        plt.subplot(len(epsilons),len(examples[0]),cnt)  
        plt.xticks([], [])  
        plt.yticks([], [])  
        if j == 0:  
            plt.ylabel(&quot;Eps: &#123;&#125;&quot;.format(epsilons[i]), fontsize=14)  
        orig,adv,ex = examples[i][j]  
        plt.title(&quot;&#123;&#125; -&gt; &#123;&#125;&quot;.format(orig, adv))  
        plt.imshow(ex, cmap=&quot;gray&quot;)  
plt.tight_layout()  
plt.show()  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a67610c54ac91c88.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>从例程运行结果可以看到，同样的改动大小ε，PGD明显比FGSM效果好，这让开发者使用更小的改动达到更好的效果，当然，PGD速度也比较慢。</p>
<p>用以上方法得到的不是一个神经网络模型，而是根据现有模型计算出来的，对单个实例的调整方法和结果。</p>
<p>本例是对图片分类模型的攻击，攻击文字模型时，主要是在Embedding层上添加扰动，涉及Token与Embedded转换问题，可以借助gensim等工具将梯度调整后的Embedded转换成文字。</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>模型实现举一反三</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E4%B8%BE%E4%B8%80%E5%8F%8D%E4%B8%89/</url>
    <content><![CDATA[<h1 id="模型实现举一反三">模型实现举一反三</h1>
<p>#深度学习</p>
<p>在很长一段时间里，大家都对深度学习模型有所误解，认为模型需要非常大量的数据训练，且只能过训练过的模式起作用——用猫的数据训练就只能识别猫，只有在训练数据中多次出现的模式才能被模型学习和应用，稍有变化，模型就无法正常工作。</p>
<p>实际上随着深度学习模型的发展，这些问题都在逐步改善。现在很多模型学习的不仅是解决具体的问题，比如识别图中的猫或者狗，还可以通过训练学习数据间的关系，在更抽象的层面学习，从而实现了举一反三。另外，随着迁移学习的流行，将海量数据中学到的知识用于只包括少量数据的新场景之中也变成了一种趋势。</p>
<p>本篇介绍几种比较巧妙的方法解决训练集中未出现过的问题。</p>
<p><strong>One-shot问题</strong></p>
<p>One-shot learning
指需要识别的物体在训练样本中很少出现，甚至在只出现一次的情况下，也能训练模型。Zero-shot与之类似，即使样本在训练数据中完全没出现过，也能正确识别或分类。</p>
<p>图片搜索是一个One-shot问题，比如网购平台上有很多衣服，不可能每一件都放入模型训练，图片搜索的目标是找到与之同款的一种或多种同款商品。同一款衣服自然有很多类似特征，比如颜色，质地，样式等等，但是使用深度网络学习出来的知识散落在网络的各个参数之中，无法确定各个输出的具体性质，并且图片中还包括不同背景，角度，以及人穿还是平铺等多种因素。</p>
<p>解决上述问题的方法是通过同一商品的不同照片训练模型，将图片的匹配程度作为目标函数，学习图片之间的关系，从而训练出能提取商品检索相关特征的模型。目标跟踪任务也使用了类似的技术。</p>
<p><strong>风格迁移</strong></p>
<p>风格迁移可以实现用一张图片的风格与另一张图片内容结合，生成新图片的功能，而非机械拼接图片。具体方法是先用预训练的视觉模型提取各个层次的图片特征，将某些层的目标结果设置为内容图片，某些层的目标结果设置为风格图片，反向调整图片内容。</p>
<p>其中提取风格的部分非常巧妙，模型计算每个通道输出数据之间的关系。比如风格图片某两个通道的输出有同增同减的关系，就调节目标图片，使它在该层也有类似的输出。</p>
<p>在风格迁移的任务中，被调整的不是网络参数，而是输入网络的数据，这种方法也常用于在对抗攻击中生成对模型更有攻击性的数据（梯度攻击）。</p>
<p><strong>类比推理</strong></p>
<p>类比推理是词向量的一种应用，首先利用大量自然语言数据训练词向量，使得每一词可使用N个属性描述，然后通过属性之间的运算实现推理，如：国王-王后=男-女，因此有：王后=国王-女+男。使用词向量还可以计算词间的距离。</p>
<p>通过迁移学习，让仍用少量数据训练的模型有更强的能力，比如：XXX与YYY在预训练的词向量模型提取的特征非常类似，YYY在训练集中出现过，而XXX只在测试集中出现，通过词向量的迁移，使XXX与YYY学到的知识结合。</p>
<p>这种方法也常用于解决Zero-shot问题，比如训练数据中没有老虎，但是通过与它近似的动物，以及用模型学到的各个特征之间的关系，识别出图片中的老虎。</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>残差网络ResNet代码解读</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9CResNet%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/</url>
    <content><![CDATA[<h1 id="残差网络resnet代码解读">残差网络ResNet代码解读</h1>
<p>#深度学习 #图形图像</p>
<h3 id="残差网络效果">残差网络效果</h3>
<p>卷积神经网络CNN的发展历史如图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ded5870f6c31609a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>从起初AlexNet的的8层网络，到ResNet的152层网络，层数逐步增加。当网络层数增加到一定程度之后，错误率反而上升，其原因是层数太多梯度下降变得越发困难。而ResNet解决了这一问题。</p>
<p>目前ResNet是应用最广的图像相关深度学习网络，图像分类，目标检测，图片分割都使用该网络结构作为基础，另外，一些迁移学习也使用ResNet训练好的模型来提取图像特征。</p>
<h3 id="残差网络原理">残差网络原理</h3>
<p>首先，来看看比较官方的残差网络原理说明：</p>
<p>“若将输入设为X，将某一有参网络层设为H，那么以X为输入的此层的输出将为H(X)。一般的CNN网络如Alexnet/VGG等会直接通过训练学习出参数函数H的表达，从而直接学习X
-&gt; H(X)
。而残差学习则是致力于使用多个有参网络层来学习输入、输出之间的残差即H(X)
- X即学习X -&gt; (H(X) - X) + X。其中X这一部分为直接的identity
mapping，而H(X) - X则为有参网络层要学习的输入输出间残差。”</p>
<p>第一次看到上述文字，我似乎明白了，但理解又不一定正确。在没看到代码之前，对VGG/ResNet的结构原理没什么感觉，几乎就是背下来哪个效果比较好，大概用了什么技术。后来看到了Pytorch中ResNet的代码，原来简单到＂五分钟包会＂的程度。用自然语言描述程序果然是把简单的问题搞复杂了。</p>
<h3 id="解读核心程序">解读核心程序</h3>
<p>直接看代码，不学习TensorFlow的复杂结构，也不使用生涩的公式语言，而用顺序结构的Pytorch作为通往深度学习的捷径。下面来解读Pytorch官方版的ResNet实现。完整代码见；</p>
<p><a
href="https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py">https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py</a></p>
<p>Torchvision是Torch的图像工具包，上述代码包含在Torchvision之中，同一目录下还有alexnet，googlenet，vgg的实现。ResNet代码共300多行，其中核心代码不到200行，实现了三个主要类：ResNet、BasicBlock、Bottleneck。</p>
<p><strong>1．残差是什么，如何实现？</strong></p>
<p>BasicBlock类中计算了残差，该类继承了nn.Module（Pytorch基本用法请见参考部分），实现了两个函数：用于创建网络结构的init和实现前向算法的forward。如下所示：</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-c8f648f67564edb4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="image.png" />
<figcaption aria-hidden="true">image.png</figcaption>
</figure>
<p>其中x是输入，out是输出，从程序代码可以看出，与基本流程不同的是，它加入了indentity，而indentity就是输入x本身（也支持下采样），也就是说，在经过多层转换得到的out上加输入数据x，即上面所说的
H(X)+X。如果设输出Y=H(X)+X，则有H(X)=Y-X，构建网络H(X)用于求取输出Y与输入X的差异，即残差。而之前的网络都是直接求从X到Y的方法。</p>
<p><strong>2．BasicBlock和Bottleneck</strong></p>
<p>BasicBlock类用于构建网络中的子网络结构（后称block），子网络中包含两个卷积层和残差处理。一个ResNet包含多个BasicBlock子网络。因此相对于传统网络，ResNet常被描绘成下图的结构，右侧的弧线是“+X”的操作。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-c442c8958696ab61.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>Bottleneck是BasicBlock的升级版，其功能也是构造子网络，resnet18和resnet34中使用了BasicBlock，而resnet50、resnet101、resnet152使用了Bottlenect构造网络。</p>
<p>Bottleneck和BasicBlock网络结构对比如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-0111229a263657a7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>左图中的BasicBlock包含两个3x3的卷积层，右图的Bottleneck包括了三个卷积层，第一个1x1的卷积层用于降维，第二个3x3层用于处理，第三个1x1层用于升维，这样减少了计算量。</p>
<p><strong>3．主控ResNet类</strong></p>
<p>ResNet中最常用的是ResNet50，它兼顾了准确性和运算量。下面以RenNet50作为示例，分析构建ResNet的具体方法。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-47e0884470492c77.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>在调用_resnet创建网络时，第二个参数指定使用Bottleneck类构建子网络，第三个参数指定了每一层layer由几个子网络block构成。</p>
<p>下图是ResNet的初始化部分init中，用于构建网络结构的代码（建议在github查看完整代码）。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-126491754b0fbc4e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>可以看到程序用函数_make_layer创建了四个层，以resnet50为例，各个层中block的个数依次是3,4,6,3个，而每个block（Bottleneck）中又包含三个卷积层，(3+4+6+3)*3共48个卷积层，外加第141行创建的另一卷积层和第154行创建的一个全连接层，总共50个主要层，这也是resnet50中50的含义。</p>
<p>除此以外，上述torchvision程序还提供了下载预测训练的模型参数，通过设置pretrain=True/False选择是否使用预训练的模型。</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-cb929ec89e02d609.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>如此这般，一个ResNet就实现完成了。</p>
<h3 id="参考">参考</h3>
<p>深度学习_卷积神经网络CNN<br />
<a
href="https://www.jianshu.com/p/49aa8f35d03e">https://www.jianshu.com/p/49aa8f35d03e</a></p>
<p>Pytorch初探<br />
<a
href="https://www.jianshu.com/p/cd72618fe126">https://www.jianshu.com/p/cd72618fe126</a></p>
]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习_卷积神经网络CNN</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN/</url>
    <content><![CDATA[<h1 id="深度学习_卷积神经网络cnn">深度学习_卷积神经网络CNN</h1>
<p>#深度学习 #图形图像</p>
<h2 id="引入">1. 引入</h2>
<p>卷积神经网络（CNN）是一种专门用来处理具有网格结构数据的神经网络．它属于前馈神经网络，它被定义为：至少在某一层用卷积代替了矩阵乘法的神经网络．最常见的应用场景是图像识别．<br />
前篇我们自己动手，用Python实现了一个BP神经网络，本篇我们在Keras框架之下实现卷积神经网络（Keras框架详见《深度学习_工具》篇）．Keras几乎是搭建CNN最简单的工具了，然而原理并不简单：除了基本的神经网络中用的误差函数，激活函数等概念以外（具体详见《深度学习_BP神经网络》），CNN还用到了卷积，池化，DropOut等方法．将在本文中逐一介绍．</p>
<h2 id="原理">2. 原理</h2>
<h4 id="图像识别">1) 图像识别</h4>
<p>先来看看图形学中的图像识别是如何实现的．</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-66d5c6c9e0b1bb4d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>我们拿到了原图（图上左），一般先将其转换成灰度图（图上中）．然后进行边缘检测，图像处理中常使用计算梯度方法（判断某像素与它相邻像素的差值）检测边缘．在CNN中我们用卷积来检测：先设计一个卷积核计算相邻像素的差值，然后用ReLU(f(x)=max(0,x))激活函数将那些差值小的置为0，即识别为非边缘（看到激活函数的厉害了吧，它把低于阈值的都扔掉了，这可是一般线性变换做不到的）．于是得到了边缘图（图上右）．处理后的图像是个稀疏的矩阵（多数点值都为0）．<br />
¬为了简化计算，我们希望将图片缩小，但在缩放的过程中，细的边缘线就会被弱化，甚至消失（图下左）．在CNN中用池化解决这一问题，如果把3*3个点缩放到1点，”最大池化”会将这9个点中最大的值，作为新点的值，于是无论强边缘还是弱边缘都被保留了下来（图下右）．<br />
边缘检测只是图像识别的第一步，之后还将识别一些更上层的特征，比如拐角，车轮，汽车的轮廓等等，它们都可由卷积实现．越往后的层越抽象，最终一个神经网络模型建起来和图像处理中的＂金字塔＂有类似的结构，虽然下层的每个点都是局部的，但是上层的点具有全局性．</p>
<h4 id="卷积">2) 卷积</h4>
<p>下面来看看卷积到底是什么，它与之前学习的全连接神经网络有什么不同．<br />
卷积定义是：通过两个函数f 和g
生成第三个函数的一种数学算子．呵呵，很抽象啊，形象地说，处理图像时，卷积就好像拿着一小块滤镜，把图像从左到右，从上到下，一格一格地扫一遍，如果在滤镜中看到想要的，就在下一层做个标记．看看下图就明白了．</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-a2a361f7b44a1440.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="（图片引自《深度学习》”花书”）" />
<figcaption
aria-hidden="true">（图片引自《深度学习》”花书”）</figcaption>
</figure>
<p>图中是一个二维平面上的卷积运算，输入是一个4x3的矩阵，卷积核（Kernel）是2x2的矩阵，输出是一个3x2的矩阵（卷积不都是2维的）．这就是卷积——一种特殊的线性运算，考虑以下几种情况：<br />
如果上图中的w,x,y,z都为0.25，则该卷积实现了均值运算（图片的模糊处理）<br />
如果上图中w+x+y+z=1，则该卷积实现了实现了加权平均．<br />
这个运算是不是有点眼熟，如果把Input中各点排着一列，把Kernel看成权值参数，则它是一个神经网络的连接．输入层有12个元素，隐藏层1有6个元素（先不管其它层）</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-b66e1dfbaf633f45.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="卷积网络与全连接网络" />
<figcaption aria-hidden="true">卷积网络与全连接网络</figcaption>
</figure>
<p>如图所示，左则是卷积层，右则是全连接的神经网络，全连接时，共有12<em>6=72个连接（输入</em>输出），72种权值；而卷积层只有24个连接（核大小*输出），４个权值w,x,y,z，分别用四种颜色标出．此处，引出了两个概念：<br />
共享权值（参数共享）：共享权值就是多个连接使用同一权值，卷积神经网络中共享的权值就是卷积核的内容，这样不但减小了学习难度．还带来的”平移等变”的性质，比如集体合影中每张脸都可以使用相同的卷积核（一组权值）识别出来，无论它在图中的什么位置，这样学习一张脸后，就能对每张脸应用相同的处理了．此技术多用于同一状态重复出现的情况下．（若图中只有一张脸，脸相关的卷积核共享作用就不大了）<br />
全连接，局部连接与卷积：全连接就是上一层的每个点都与下一层的每个点连接，每个连接都有其自已的权值；局部连接是只有部分点相互连续；卷积是在局部连续的基础上又共享了权值．<br />
卷积核可以是指定的，也可以是用梯度向前推出来的，可以是聚类算出来的（无监督学习），还可以先取一小块训练，然后用这小块训练的结果定义卷积的核．这取决于我们设计的不同算法．<br />
由此可见，卷积层是两层之间的连接方法，与全连接相比，它大大简化了运算的复杂度，还节省了存储空间．之所以能这样简化是因为图像中距离越近的点关系越大（序列处理也同理：离得越近关系越大）．</p>
<h4 id="池化">3) 池化</h4>
<p>池化是使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出，和卷积差不多，它也是层到层之间的运算，经过池化处理，层中节点可能不变，也可能变小（常用它降采样，以减少计算量）．<br />
最大池化就是将相邻的Ｎ个点作为输入，将其中最大的值输出到下一层．除了最大池化，池化算法还有：取平均值，加权平均等等．<br />
池化具有平移不变性：若对图片进行少量平移，经过池化函数后的大多数输出并不会发生改变，比如最大池化，移动一像素后，区域中最大的值可能仍在该区域内．<br />
同理，在一个稀疏的矩阵中（不一定是图像），假设对n点做最大池化，那么只要其中有一点非０，则池化结果非0．如下图所示，只要手写数据5符合其中一个判断标准，则将其识别为数字5．</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-46869861c1385474.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="（图片引用自《深度学习》＂花书＂）" />
<figcaption
aria-hidden="true">（图片引用自《深度学习》＂花书＂）</figcaption>
</figure>
<p>池化还经常用于处理不同尺寸的图片：比如有800x600和200*150两张图，想对它们做同一处理，可通过设定池化的输出为100x75来实现保留特征的缩放，以至扩展到任意大小的图片．<br />
基本上卷积网络都用使用池化操作．</p>
<h4 id="dropout">4) DropOut</h4>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-6d08bc7374e6170c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>再举个例子，现在我们来识别老鼠，一般老鼠都有两只耳朵，两只眼睛，一个鼻子和一个嘴，它们有各自的形状且都是从上到下排列的．如果严格按照这个规则，那么＂一只耳＂就不会被识别成老鼠．<br />
为提高鲁棒性，使用了DropOut方法．它随机地去掉神经网络中的一些点，用剩余的点训练，假设有一些训练集中的老鼠，被去掉的正是耳朵部分，那么＂一只耳＂最终也可能由于其它特征都对而被识别．<br />
除了提高鲁棒性，DropOut还有其它一些优点，比如在卷积神经网络中，由于共享参数，我们训练一小部分的子网络（由DropOut剪出）,参数共享会使得剩余的子网络也能有同样好的参数设定。保证学习效果的同时，也大大减少了计算量．<br />
DropOut就如同在层与层之间故意加入了一些噪声，虽然避免了过拟合，但它是一个有损的算法，小的网络使用它可能会丢失一些有用的信息．一般在较大型的网络中使用DropOut．</p>
<h4 id="总结">5) 总结</h4>
<p>卷积，池化，DropOut都是设计者根据数据的性质，采取的对全连接网络的优化和简化，虽然它们都是有损的，但是对计算和存储的优化也非常明显，使我们有机会将神经网络扩展到成百上千层．</p>
<h2 id="代码">3. 代码</h2>
<h4 id="说明">1) 说明</h4>
<p>代码的主要功能是根据Mnist库的图像数据训练手写数字识别．核心代码在后半部分，它使用了卷积层，池化层，Dropout层，Flatten层，和全连接层．</p>
<h4 id="代码-1">2) 代码</h4>
<p>（为了让大家复制粘贴就能运行，还是附上了全部代码）</p>
<pre><code># -*- coding: utf-8 -*-  
from __future__ import print_function  
import keras  
from keras.datasets import mnist  
from keras.models import Sequential  
from keras.layers import Dense, Dropout, Flatten  
from keras.layers import Conv2D, MaxPooling2D  
from keras import backend as K  
  
batch_size = 128 # 批尺寸  
num_classes = 10　# 0-9十个数字对应10个分类  
epochs = 12 # 训练12次  
  
# input image dimensions  
img_rows, img_cols = 28, 28 # 训练图片大小28x28  
  
# the data, shuffled and split between train and test sets  
(x_train, y_train), (x_test, y_test) = mnist.load_data()  
  
if K.image_data_format() == &#39;channels_first&#39;:  
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)  
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)  
    input_shape = (1, img_rows, img_cols)  
else:  
    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)  
    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)  
    input_shape = (img_rows, img_cols, 1)  
  
x_train = x_train.astype(&#39;float32&#39;)  
x_test = x_test.astype(&#39;float32&#39;)  
x_train /= 255  
x_test /= 255  
print(&#39;x_train shape:&#39;, x_train.shape)  
print(x_train.shape[0], &#39;train samples&#39;)  
print(x_test.shape[0], &#39;test samples&#39;)  
  
# convert class vectors to binary class matrices  
y_train = keras.utils.to_categorical(y_train, num_classes)  
y_test = keras.utils.to_categorical(y_test, num_classes)  
  
# 下面model相关的是关键部分  
model = Sequential()  
model.add(Conv2D(32, kernel_size=(3, 3), #加卷积层，核大小3x3，输出维度32  
                 activation=&#39;relu&#39;, #激活函数为relu  
                 input_shape=input_shape)) #传入数据  
model.add(Conv2D(64, (3, 3), activation=&#39;relu&#39;))　#又加一个卷积层  
model.add(MaxPooling2D(pool_size=(2, 2))) # 以2x2为一块池化  
model.add(Dropout(0.25)) # 随机断开25%的连接  
model.add(Flatten()) # 扁平化，例如将28x28x1变为784的格式  
model.add(Dense(128, activation=&#39;relu&#39;)) # 加入全连接层  
model.add(Dropout(0.5))　# 再加一层Dropout  
model.add(Dense(num_classes, activation=&#39;softmax&#39;)) # 加入到输出层的全连接  
  
model.compile(loss=keras.losses.categorical_crossentropy, # 设损失函数  
              optimizer=keras.optimizers.Adadelta(), # 设学习率  
              metrics=[&#39;accuracy&#39;])  
  
model.fit(x_train, y_train,  
          batch_size=batch_size, # 设批大小  
          epochs=epochs, # 设学习次数  
          verbose=1,  
          validation_data=(x_test, y_test))  
score = model.evaluate(x_test, y_test, verbose=0) # 用测试集评测  
print(&#39;Test loss:&#39;, score[0])  
print(&#39;Test accuracy:&#39;, score[1])  </code></pre>
<h2 id="cnn的历史">4. CNN的历史</h2>
<p>看CNN的发展，从1998年LeCun的经典之作LeNet,
到将ImageNet图像识别率提高了10个百分点的AlexNet, VGG(加入更多卷积层),
GoogleNet(使用了Inception一种网中网的结构),
再到RssNet(使用残差网络)，ImageNet的Top-5错误率已经降到3.57%，低于人眼识别的错误率5.1%，并且仍在不断进步．这些不断提高的成绩以及在更多领域的应用让神经变得越来越热门．</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-71bc7cd834a422e4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>从图中可见，从AlexNet的3层全连接神经网络，到ResNet的152层神经网络，全连接层越来越少，卷积层越来越多．除了算法的进步，人的知识也越来越多越来越细化地溶入了神经网络．</p>
<h2 id="参考">5. 参考</h2>
<ol type="1">
<li>CNN的发展史<br />
http://www.cnblogs.com/52machinelearning/p/5821591.html</li>
</ol>
]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习_循环神经网络RNN与LSTM</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN%E4%B8%8ELSTM/</url>
    <content><![CDATA[<h1
id="深度学习_循环神经网络rnn与lstm">深度学习_循环神经网络RNN与LSTM</h1>
<p>#深度学习 #时序 #自然语言处理</p>
<h2 id="循环神经网络rnn">1. 循环神经网络RNN</h2>
<h4 id="什么是rnn">1) 什么是RNN？</h4>
<p>循环神经网络（RNN）是一种节点定向连接成环的人工神经网络。具体应用有语音识别，手写识别，翻译等．</p>
<h4 id="什么时候使用rnn">2) 什么时候使用RNN？</h4>
<p>FNN（前馈神经网络，如BP，CNN等）效果已经不错了，RNN还需要更大量的计算，为什么要用RNN呢？如果训练N次，每次和每次都没什么关系，那就不需要RNN，但如果每个后一次都可能和前一次训练相关，比如说翻译：一个句子里面Ｎ个词，一个词为一次训练（train
instance），一个词的意思很可能依赖它的上下文，也就是其前次或后次训练，这个时候就需要RNN．</p>
<h4 id="rnn与fnn有何不同">3) RNN与FNN有何不同？</h4>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-30682a174766435b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /><br />
如图所示，左边的是前馈神经网络，数据按黑箭头方向从输入层经过隐藏层流入输出层，向前流动，因此叫做前馈网络．右图中，隐藏层中的数据除了传向输出层，还和下次输入一起训练后续的隐藏层，不再是单向，而是包含了循环，则构成了循环神经网络．下图是将各个时间点画在同一图上，左边前馈FNN的展开图，右边是RNN的展开图．<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-1b12093425d14470.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /><br />
简单地说，它只是在隐藏层处加了一个＂循环＂，但实际上问题没这么简单．之前说过（详见：深度学习_BP神经网络），输入层向隐藏层传数据时，根据权重Ｕ计算（为简化说明省略偏置），隐藏层向输出层传数据时，根据权重V计算（之前文档用字体w1,w2表示），循环神经网络又加了参数W，用于控制隐藏层的权重．看起来好像只是多了一次矩阵乘法和加法，但实际上RNN计算要比前馈网络复杂很多．原因我们看红色箭头，它标记的是误差反向传播，也就是根据实际结果y和输出层的预测结果o计算出的误差传回网络以调整权重UVW．由于每个隐藏层都依赖前一隐藏层的结果，因此误差不只要从隐藏层传回输入层，还要一层一层传回上一隐藏层．它使用计算变得很复杂，且无法并行．<br />
于是又有了下图中的变种，使用实际输出y，和下个x一次训练下一隐藏层，因为y中信息并不像h中那么丰富，因此可能效果会差一些．这里只是循环神经网络的几种情况，其它就不一一列举了，总的来说循环神经网络并无定式，主要指数据的流向中包含循环．<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-31fc8fcd8fdafb32.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="lstm">2. LSTM</h2>
<p>经常听到LSTM神经网络如何如何，其实LSTM不是一种网络，而是一种对RNN隐藏层的改进算法（改进算法有很多，这个因为效果好，所以比较著名）<br />
LSTM(Long short-term memory)是长短期记忆的简写．<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-948d58d52b5186eb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="引自：《深度学习》＂花书＂" /><br />
如果不断用隐藏层去计算下一时间隐藏层，当计算隐藏层的特征向量大于１时，经过N次迭代后值就会越来越大，最终发生爆炸，如果小于1，最后越来越小，导致消失．换句话说，过去会给我们启发，所以不能忘记过去，但如果每时每刻都被过去影响，就像滚雪球一样，最后也会悲剧．最好是把重点记住，然后在开始新篇章的时候更多地忘记过去．<br />
更直观的说，原来在输入层和隐藏层间是仿射变换加激活函数，现在用输入门，遗忘门输出门和状态层来代替隐藏单元的生成算法．其中每个门都有非线性变换．这几个门的关系，详见代码：</p>
<pre><code>input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)  #输入门  
forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)  #遗忘门  
update = tf.tanh(tf.matmul(i, cx) + tf.matmul(o, cm) + cb) 　#更新  
state = forget_gate * state + input_gate * update　# 更新状态, 遗忘门控制是否忘记旧时状态  
output_gate = tf.sigmoid(tf.matmul(i, ox) +  tf.matmul(o, om) + ob) #输出门  
return output_gate * tf.tanh(state), state #返回输出值  </code></pre>
<h2 id="程序">3. 程序</h2>
<h4 id="说明">1) 说明</h4>
<p>与前篇的BP网络和CNN网络一样，这次使用的仍然是MNIST手写数据识别．在练习了纯Python和Keras框架之后，
此次使用更低层的TensorFlow代码实现RNN．也顺便了解一个高级工具都封装了什么？<br />
每个图片仍然是28x28像素，前馈网络把28x28共748个像素值作为一个输入x数据传入输入层，而RNN把每张图当成一个序列，序列有28个元素（一行为一个元素），以每行的28个点为输入x传入输入层．简单地说就是切成一行一行训练，每行与下一行有一定联系．<br />
下图是时序图（为简化逻辑，此处只画了一个隐藏层），相对最一般的RNN，下图是一个变种：整个序列（28行）的输入对应同一个输出y（手写对应的数字）．<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-55224b4a777e0809.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" /></p>
<h5 id="代码">2) 代码</h5>
<pre><code># -*- coding: utf-8 -*-  
  
from tensorflow.examples.tutorials.mnist import input_data  
import tensorflow as tf  
import numpy as np  
  
# 在MINIST_data目录下载　mnist数据  
mnist = input_data.read_data_sets(&quot;MINIST_data/&quot;, one_hot=True)  
  
# RNN学习时使用的参数  
learning_rate = 0.001 # 学习率  
training_iters = 100000 # 训练实例数  
batch_size = 120 # 批大小  
display_step = 10 # 训练10批显示一次  
  
n_input = 28 # 每28个作为一个输入层的节点数（行中点）  
n_steps = 28 # 28个连续序列(列)  
n_hidden = 128 # 隐含层的节点数  
n_classes = 10 # 输出的节点数，0~9个数字，这里一共有10个  
  
x = tf.placeholder(&quot;float&quot;, [None, n_steps, n_input]) # 构建输入节点  
istate = tf.placeholder(&quot;float&quot;, [None, 2 * n_hidden]) # 构建隐藏节点，一个存节点，一个存状态  
y = tf.placeholder(&quot;float&quot;, [None, n_classes]) # 构建输出节点  
  
# 随机初始化各层的权值和偏置  
weights = &#123;  
&#39;hidden&#39;: tf.Variable(tf.random_normal([n_input, n_hidden])), # 输入到隐藏  
&#39;out&#39;: tf.Variable(tf.random_normal([n_hidden, n_classes])) # 隐藏到输出  
&#125;  
biases = &#123;  
&#39;hidden&#39;: tf.Variable(tf.random_normal([n_hidden])),  
&#39;out&#39;: tf.Variable(tf.random_normal([n_classes]))  
&#125;  
  
# 建立RNN模型，_X是批训练数据，_istate为隐藏节点  
def RNN(_X, _istate, _weights, _biases):  
    _X = tf.transpose(_X, [1, 0, 2]) # 把batch_size,n_steps,n_input顺序变为n_steps,batch_size,n_input  
    _X = tf.reshape(_X, [-1, n_input]) # 再转换为n_steps*batch_size, n_input  
    # 两个隐藏层：第一层直接计算，第二层用LSTM  
    _X = tf.matmul(_X, _weights[&#39;hidden&#39;]) + _biases[&#39;hidden&#39;] # 计算隐藏层的节点,此时X从输入节点转为隐藏节点  
    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0,state_is_tuple=False) # 定义lstm  
    _X = tf.split(_X, n_steps, 0) # 序列切片，每片是一个(batch_size, n_hidden)  
    outputs, states = tf.nn.static_rnn(lstm_cell, _X, initial_state=_istate) # 计算lstm rnn,states存状态  
    return tf.matmul(outputs[-1], _weights[&#39;out&#39;]) + _biases[&#39;out&#39;] #计算输出层  
  
pred = RNN(x, istate, weights, biases)  
  
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y)) # 损失函数为交叉熵  
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # 优化方法为Adam  
  
correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1)) # 计算错误数  
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32)) # 计算错误率  
  
init = tf.global_variables_initializer()  
  
sess = tf.InteractiveSession()  
sess.run(init)  
step = 1  
while step * batch_size &lt; training_iters:  
    batch_xs, batch_ys = mnist.train.next_batch(batch_size) # 随机抽取训练数据  
    batch_xs = batch_xs.reshape((batch_size, n_steps, n_input))  
    # 用feed_dict传入数据：输入，输出，隐藏层, 数据由placeholder定义, 运行optimizer  
    sess.run(optimizer, feed_dict=&#123;x: batch_xs, y: batch_ys, istate: np.zeros((batch_size, 2 * n_hidden))&#125;)  
    if step % display_step == 0: # 每display_step次批处理显示一次, 通过run运行accuracy,cost  
        acc = sess.run(accuracy, feed_dict=&#123;x: batch_xs, y: batch_ys, istate: np.zeros((batch_size, 2 * n_hidden))&#125;)  
        loss = sess.run(cost, feed_dict=&#123;x: batch_xs, y: batch_ys, istate: np.zeros((batch_size, 2 * n_hidden))&#125;)  
        print(&quot;Iter &quot; + str(step * batch_size) + &quot;, Minibatch Loss= &quot; + &quot;&#123;:.6f&#125;&quot;.format(loss) + &quot;, Training Accuracy= &quot; + &quot;&#123;:.5f&#125;&quot;.format(acc))  
    step += 1  
print(&quot;Optimization Finished!&quot;)  
  
test_len = 256  
test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))  
test_label = mnist.test.labels[:test_len]  
print(&quot;Testing Accuracy:&quot;, sess.run(accuracy, feed_dict=&#123;x: test_data, y: test_label, istate: np.zeros((test_len, 2 * n_hidden))&#125;))  </code></pre>
<h4 id="分析">3) 分析</h4>
<p>TensorFlow涉及了更多具体计算，比如格式转换，矩阵乘法等等，不像Keras从外面基本看不到具体的步骤的动作和结果．<br />
从代码中很容易明白为什么说TensorFlow是一个＂框架＂，程序的前50行，具体数据还没出现，程序就指定了数据的结构和流向，在接下来的sess部分，tf
才真正开始运算，把数据切块＂喂＂给框架，使其运行．它和一般程序调函数，确实不太一样．<br />
这里比较不容易理解的是数据怎么从feed_dict转入了RNN函数．在pred = RNN(x,
istate, weights,
biases)被运行时，其实里面并没有真正的数据在做转换和乘法，这里定义的是数据的流程．此时的x，istate里面还没有数据，而只是定义了数据形式，并告诉TensorFlow该数据需要如何处理．在后面feed_dict处理时才传入了真正的数据，并通过run()间接地调用了RNN().
sess.run()调用函数时，函数的各个参数都是从当前环境里取的．我理解这里的placeholder意思有点像C中定义的数据结构．</p>
<h2 id="问题与解答">4. 问题与解答</h2>
<h4 id="rnn的隐藏层是一个还是多个">1) RNN的隐藏层是一个还是多个？</h4>
<p>隐藏层可以是一个，也可以是多个（多层循环网络），比如说可以有三个隐藏层h1,h2,h3，其中h2将结果转给下一个实例的训练，还可以是双向的（一个传向前一时间点，一个传向后一时间点，即双向循环网络），一般为了简化，例子里都有单层的．</p>
<h4 id="rnn中反向传播梯度是怎么进行的">2)
RNN中反向传播梯度是怎么进行的？</h4>
<p>对于训练序列来说，如果序列中每个时间点的输入x都有对应的输出y，总损失就是所有时间步的损失之和．如果像MNIST中整个序列对应一个结果，则使用该结果与预测的误差．具体方法还是梯度下降，只是计算隐藏层与隐藏层之间权重的方法需要按时间往前推．</p>
<h2 id="参考">5. 参考</h2>
<h4 id="tensorflow学习笔记8基于mnist数据的循环神经网络rnn">1)
TensorFlow学习笔记（8）：基于MNIST数据的循环神经网络RNN</h4>
<p>https://segmentfault.com/a/1190000008346992</p>
<h4 id="解读tensorflow之rnn">2) 解读tensorflow之rnn</h4>
<p>http://weibo.com/p/23041853dd83fd0102x6wc?sudaref=www.baidu.com&amp;display=0&amp;retcode=6102&amp;sudaref=passport.weibo.com</p>
<h4 id="tensorflow遇到的问题汇总持续更新中......">3)
TensorFlow遇到的问题汇总（持续更新中......）</h4>
<p>http://www.cnblogs.com/hunttown/p/6866586.html</p>
<h4 id="利用-keras-下的-lstm-进行情感分析">4) 利用 Keras 下的 LSTM
进行情感分析</h4>
<p>http://blog.csdn.net/william_2015/article/details/72978387</p>
<h4
id="基于theano的深度学习deep-learning框架keras学习随笔-02-example">5)
基于Theano的深度学习(Deep Learning)框架Keras学习随笔-02-Example</h4>
<p>http://blog.csdn.net/niuwei22007/article/details/49053771</p>
<h4 id="循环神经网络rnn-recurrent-neural-networks介绍">6)
循环神经网络(RNN, Recurrent Neural Networks)介绍</h4>
<p>http://blog.csdn.net/heyongluoyao8/article/details/48636251</p>
<h4 id="零基础入门深度学习6---长短时记忆网络lstm">7)
零基础入门深度学习(6) - 长短时记忆网络(LSTM)</h4>
<p>https://www.zybuluo.com/hanbingtao/note/581764</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>深度学习</tag>
        <tag>时序</tag>
      </tags>
  </entry>
  <entry>
    <title>生成对抗网络GAN</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9CGAN/</url>
    <content><![CDATA[<h1 id="生成对抗网络gan">生成对抗网络GAN</h1>
<p>#深度学习</p>
<p>生成对抗网络GAN是一种深度学习模型，它源于2014年发表的论文：《Generative
Adversarial Nets》，论文地址：<a
href="https://arxiv.org/pdf/1406.2661.pdf">https://arxiv.org/pdf/1406.2661.pdf</a>。</p>
<p>GAN的用途非常广泛，比如：有大量的卡通头像，想通过学习自动生成卡通图片，此问题只提供正例，可视为无监督学习问题。不可能通过人工判断大量数据。如何生成图片？如何评价生成的图片好坏？GAN为此类问题提供了解决方法。</p>
<p>GAN同时训练两个模型：生成模型Ｇ（Generative
Model）和判别模型Ｄ（Discriminative
Model），生成模型Ｇ的目标是学习数据的分布，判别模型Ｄ的目标是区别真实数据和模型Ｇ生成的数据。以生成卡通图片为例，生成网络G的目标是生成尽量真实的图片去欺骗判别网络D。而D的目标就是尽量把G生成的图片和真实的图片分别开来。G和D构成了一个动态的“博弈过程”，通过迭代双方能力都不断提高。</p>
<p>对抗网络近年来发展迅速。下图是近几年 ICASSP
会议上所有提交的论文中包含关键词 “generative”、“adversarial” 和
“reinforcement” 的论文数量统计。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-67ce79eed3827145.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="用途">用途</h3>
<ul>
<li><p>生成数据
GAN常用于实现复杂分布上的无监督学习和半监督学习，学习数据的分布，模拟现有数据生成同类型的图片、文本、旋律等等。</p></li>
<li><p>数据增强
GAN也用于扩展现有的数据集，即数据增强。使用它训练好的生成网络，可以在数据不足时用于补充数据。</p></li>
<li><p>生成特定数据
GAN掌握了数据生成能力后，可通过加入限制，使模型生成特定类型的数据。比如改变图片风格，隐去敏感信息，实现诸如数据加密的功能。</p></li>
<li><p>使用判断模型
训练好的判别模型可以用于判断数据是否属于该类别，判断数据的真实性，以及判断异常数据。</p></li>
</ul>
<h3 id="原理">原理</h3>
<p><strong>生成模型和判别模型</strong></p>
<p>机器学习模型大体分为两类，生成模型（Generative
Model）和判别模型（Discriminative
Model）。生成模型学习得到联合概率分布P(x,y)，即特征x和标记y共同出现的概率，然后求条件概率分布。能够学习到数据生成的机制；判别模型学习得到条件概率分布P(y|x)，即在特征x出现的情况下标记y出现的概率。</p>
<p><strong>具体算法</strong></p>
<p>GAN使用下式评估模型效果：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-f903f60272d3cf52.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中Pdata是真实数据的分布，式中左半部分将真实数据x代入判别模型D(x)，D的输出范围是从0-1，0为假数据，1为真数据；由于x是真实数据，D模型希望D(x)=1；右半部分将随机噪声z代入生成模型G产生模拟数据G(z)，并使用判别模型D判别它是否为真实数据，G模型希望D(G(z))=1，1-D(G(z))=0；相反，D模型希望D(G(z))=0，1-D(G(z))=1。也就是说，G希望上式结果越小越好，而D希望上式结果越大越好。最终函数V既非最大，也非最小，找到双方的利益平衡点——生成数据完全拟合真实数据时达到纳什平衡。</p>
<p>论文中有推导过程，但有些跳步，从这里可以看到详细的推导过程： <a
href="https://blog.csdn.net/susanzhang1231/article/details/76906340">https://blog.csdn.net/susanzhang1231/article/details/76906340</a></p>
<p>其具体算法如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5e29732bce9a5c60.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中内部的for循环用于优化判别模型，先用随机噪声z生成m个数据，同时从真实数据中取m个数据，然后代入判别模型并根据判别结果优化模型参数；外部的for循环用于优化生成模型，可以看到生成模型只与公式中右侧计算相关。训练k次判别模型，训练1次生成模型，二者交替进行。</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-2c4993e04442fe5f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片摘自论文" />
<figcaption aria-hidden="true">图片摘自论文</figcaption>
</figure>
<p>图中展示了两个模型的优化过程，其中黑色代表真实数据，绿色表示生成数据，蓝色表示判别结果；在图(a)中，生成模型没能很好地模拟真实数据分布，差别模型也效果不佳；图(b)优化了判别模型；图(c)随着生成模型的优化，生成数据逐渐接近真实数据；图(d)是最终效果，生成模型完美拟合真实数据，两种数据分布一致，判别模型将无法区分真实数据和生成数据D(x)=1/2。</p>
<h3 id="代码">代码</h3>
<p>推荐例程： <a
href="https://github.com/RedstoneWill/MachineLearningInAction/blob/master/GAN/GAN_1.ipynb">https://github.com/RedstoneWill/MachineLearningInAction/blob/master/GAN/GAN_1.ipynb</a>
整个例程不到100行，使用GAN方法拟合曲线。生成模型G和判别模型D都使用深度学习网络，且互过逆过程。其核心代码摘录如下：</p>
<pre><code>G = nn.Sequential( # 生成模型  
    nn.Linear(N_IDEAS, 128),  
    nn.ReLU(),  
    nn.Linear(128, ART_COMPONENTS),  
)  
  
D = nn.Sequential( # 判别模型  
    nn.Linear(ART_COMPONENTS, 128),  
    nn.ReLU(),  
    nn.Linear(128, 1),  
    nn.Sigmoid(), # 计算判别结果  
)  
  
for step in range(10000):　# 10000次迭代  
    artist_paintings = artist_works() # 取真实数据  
    G_ideas = torch.randn(BATCH_SIZE, N_IDEAS) # 生成随机噪声  
    G_paintings = G(G_ideas) # 利用噪声生成模拟数据  
    prob_artist0 = D(artist_paintings) # 真实数据代入判别模型  
    prob_artist1 = D(G_paintings) # 模拟数据代入判别模型  
     
    D_loss = - torch.mean(torch.log(prob_artist0) + torch.log(1\. - prob_artist1)) # 误差函数  
    G_loss = torch.mean(torch.log(1\. - prob_artist1)) # 误差函数（见公式）  
  
    opt_D.zero_grad()  
    D_loss.backward(retain_graph=True) # 反向传播，模型D调参  
    opt_D.step()  
  
    opt_G.zero_grad()  
    G_loss.backward() # 反向传播，模型G调参  
    opt_G.step()  </code></pre>
<p>整体迭代了10000次，每次迭代时取真实数据，并将随机数代入生成模型G生成模拟数据，将数据代入判别模型D，然后根据损失函数调参。下图摘录了曲线拟合不同阶段的结果。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-b0e1f6c54ac20a97.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>在图像处理领域使用生成对抗网络可以让模型学习生成特定类型的图片。推荐生成卡通人物图片的例程：</p>
<p>https://github.com/chenyuntc/pytorch-book/tree/v1.0/chapter7-GAN生成动漫头像<br />
（《深度学习框架PyTorch：入门与实践》第七章的配套代码）</p>
<p>README中有对应的资源下载地址，该程序只有两三百行代码，在没有GPU支持的机器上花几个小时也能训练完成。模型效果如下图所示：其中左图为第一次迭代的结果，右图为第25次迭代后的结果。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-79891741d823c023.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>程序使用两个模型，其中一个用于生成图像，另一个用于判断图像是否为模型生成，两个深度学习网络互为逆过程，判别网络由多个卷积构成，用于层层提取特征，最终判断是否为真实图片，而生成网络由多个反卷积层构成，它通过随机噪声层层扩展生成图片。在博弈过程中两个模型各自优化，最终使模型具备生成特定类型图片的能力。</p>
<p>需要注意的是上例中的图片和曲线拟合都针对连续型数据，可以通过调整网络参数的方法逐渐逼近最佳值，对于生成文本一类的离散数据，则需要进一步修改模型。</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>用深度学习模型提取特征</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81/</url>
    <content><![CDATA[<h1 id="用深度学习模型提取特征">用深度学习模型提取特征</h1>
<p>#深度学习 #pytorch</p>
<h3 id="用途">用途</h3>
<p>有时候需要从图片（或文本）中提取出数值型特征，供各种模型使用。深度学习模型不仅可以用于分类回归，还能用于提取特征。通常使用训练好的模型，输入图片，输出为提取到的特征向量。</p>
<p>加入特征之后，结果往往不尽如人意，大致有以下原因：</p>
<ul>
<li><p>深度学习模型一般有N层结构，不能确定求取哪一层输出更合适。<br />
深度学习模型很抽象——几十层的卷积、池化、信息被分散在网络参数之中。提取自然语言的特征时，常常提取词向量层的输出作为特征，有时也取最后一层用于描述句意；图像处理时往往提取最后一层输出向量；在图像目标识别问题中，常提取后两层子网络的输出作为组合向量。如何选择提取位置，取决于对模型的理解，后文将对图像处理层进行详细说明。</p></li>
<li><p>针对不同问题训练出的模型，输出的特征也不同。<br />
通常下载的ResNet，VGG，BERT预训练模型，虽然通用性高，但解决具体问题的能力比较弱。比如在自然语言处理中，用GPT-2或者BERT训练的模型只面对普通文章，如果从中提取特征用于判断辱骂，有些脏字可能有效，但是更多的“多义词”会被它的普通含义淹没。
用自己的数据fine-tune后往往更有针对性，而fine-tune的目标也需仔细斟酌，否则可能起到反作用。比如希望用ResNet识别不同的衣服，就需要考虑到衣服的形状、质地、颜色等等因素，如果用衣服类型（大衣、裤子）的分类器去fine-tune模型，新模型可能对形状比较敏感，而对材质、颜色的识别效果反而变差。</p></li>
</ul>
<h3 id="原理">原理</h3>
<p>图像模型ResNet-50规模适中，效果也很好，因此被广泛使用。下面将介绍该模型各层输出的含义，以及用它提取图片特征的方法。</p>
<p>ResNet原理详见论文：<a
href="https://arxiv.org/pdf/1512.03385.pdf">https://arxiv.org/pdf/1512.03385.pdf</a>。常用的ResNet网络参数如下，</p>
<p>可以看到，它包含四层Bottlenect（子网络），越往后，获取的特征越抽象。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-9ef7fe8e0a5a2791.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>以单图为例，输入模型的图像结构为 [1, 3, 224,
224]，图片大小为224x224（大小根据具体图片而定），有红、绿、蓝3个通道。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-70f6715d008f5fab.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>第一步，经过一个7x7卷积层，步长为2，它的输出是：(1,64,112,112)，可视为64通道的112x112大小的图片，处理后效果如下图所示。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-1405be2d1d10434a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>该层共生成64张图片，由于步长是2，大小变为112x112，每一种特征提取方法对应一组参数，这些参数对每7x7个像素进行同样处理，最终生成一个新的像素。换言之，就是构造了64种特征提取方法，分别提取了颜色，形状，边缘等特征，也可以看到由于处理以卷积为基础，图像位置关系得以保留。</p>
<p>在输入一张图片时，一个224x224的图通过这一层，提取了64x112x112=802816维特征，该层一般称为第一组卷积层conv1，由于该层次太过底层，维度过大，很少使用该层特征。</p>
<p>经过第一层之后，又经过归一化，激活函数，以及步长为2的池化，输出大小为[1,
64, 56, 56]，如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ea20052297f05f6d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>然后依次传入四个Bottlenext子网络（原理同上），分别称为conv2<em>,
conv3</em>, conv4<em>,
conv5</em>（也有名为layer1,layer2,layer3,layer4），输出的大小也逐层递减，最终减致2048x7x7=100352，长宽分别是原始参数的1/32。Mask-RCNN中就可获取R-50的第4和第5次作为特征。四层输出如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d3ab184dcf52c8aa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>第一维是图像的张数，第二维是通道数，后两维分别是图片的宽高，从任一通道取出数据，都可以直接绘制该通道的图像。数据流至最后一个子网络conv5后输出是2048个7x7大小的图片。有时候将7x7的图片做最大池化或平均池化，最终得到一个值，可理解成从该通道提取的一个特征值。到这一步，特征已经和像素位置无关了。</p>
<p>如果希望提取到的特征不是2048维，则可以在后面再加一个输入为2048，输出为目标维度的全连接层。从上述分析中可以大概了解模型的规模，以及运算量。</p>
<p>另外一个常见的问题是：图像处理对图像的大小有没有要求？是不是所有大小的图片都可以直接代入模型？上例中使用224x224大小的图片，经过多层池化，最终变成了7x7大小。当然也可以代入更大图片（图片越大占用资源越多），比如448x224的图片，最终输出为14x7。一般在训练时，往往经过crop裁剪和resize缩放的步骤，把图片变为统一大小。输入模型时往往以batch为单位，同一batch中的数据大小必须一致，否则只能单张处理。</p>
<h3 id="示例">示例</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">下例为从指定的层提取ResNet50的特征。  </span><br><span class="line">  </span><br><span class="line">import torch  </span><br><span class="line">from torch import nn  </span><br><span class="line">import torchvision.models as models  </span><br><span class="line">import torchvision.transforms as transforms  </span><br><span class="line">import cv2  </span><br><span class="line">  </span><br><span class="line">class FeatureExtractor(nn.Module): # 提取特征工具  </span><br><span class="line">    def __init__(self, submodule, extracted_layers):  </span><br><span class="line">        super(FeatureExtractor, self).__init__()  </span><br><span class="line">        self.submodule = submodule  </span><br><span class="line">        self.extracted_layers = extracted_layers  </span><br><span class="line">   </span><br><span class="line">    def forward(self, x):  </span><br><span class="line">        outputs = []  </span><br><span class="line">        for name, module in self.submodule._modules.items():  </span><br><span class="line">            if name is &quot;fc&quot;:   </span><br><span class="line">                x = x.view(x.size(0), -1)  </span><br><span class="line">            x = module(x)  </span><br><span class="line">            if name in self.extracted_layers:  </span><br><span class="line">                outputs.append(x)  </span><br><span class="line">        return outputs  </span><br><span class="line">  </span><br><span class="line">model = models.resnet50(pretrained=True) # 加载resnet50工具  </span><br><span class="line">model = model.cuda()  </span><br><span class="line">model.eval()  </span><br><span class="line">  </span><br><span class="line">img=cv2.imread(None) # 加载图片  </span><br><span class="line">img=cv2.resize(img,(224,224));  </span><br><span class="line">img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)  </span><br><span class="line">transform = transforms.Compose(  </span><br><span class="line">    [transforms.ToTensor(),  </span><br><span class="line">     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  </span><br><span class="line">img=transform(img).cuda()  </span><br><span class="line">img=img.unsqueeze(0)  </span><br><span class="line">  </span><br><span class="line">model2 = FeatureExtractor(model, [&#x27;layer3&#x27;]) # 指定提取 layer3 层特征  </span><br><span class="line">with torch.no_grad():  </span><br><span class="line">    out=model2(img)  </span><br><span class="line">    print(len(out), out[0].shape)   </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>百度自动驾驶系统Apollo源码分析</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E7%99%BE%E5%BA%A6%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E7%B3%BB%E7%BB%9FApollo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1
id="百度自动驾驶系统apollo源码分析">百度自动驾驶系统Apollo源码分析</h1>
<p>#深度学习</p>
<p> Apollo（阿波罗）是百度今年发布的汽车自动驾驶系统，它是不是可以无人驾驶？安全性又如何保证？下面我们就来看看自动驾驶指的是什么，以及它是如何实现的．</p>
<p>##自动驾驶评级<br />
 先来看看什么是自动驾驶，2014年，SAE
International（国际汽车工程师协会）制订了一套自动驾驶汽车分级标准，其对自动化的描述分为5个等级。<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-220ff879e7f9e2ef.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="自动驾驶评级" /></p>
<p> 从辅助驾驶到全自动驾驶，都属于自动驾驶，只是级别不同，现在有很多车已经配置了定速巡航，自动泊车，这是从L1走向L2阶段；而L3是说人可以不进行主动驾驶，但需要时刻保持注意力；据说Google的Waymo自动驾驶系统已达到L4水平，它能在特定地理区域和条件下，完成整个动态驾驶任务．大家离L5还都有一段很长的路要走．百度的目标是2019年量产L3的汽车．<br />
 同样是自动，但是程度不同，具体要看：设计运行范围（operational design
domain，简称ODD），它包括地理位置、道路类型、速度范围、天气、时间、国家和地方性交通法律法规等等．</p>
<h2 id="硬件">硬件</h2>
<p> 下面来看看自动驾驶的汽车和普通汽车有什么不同，如图所示，自动驾驶汽车一般都包含：视频系统(摄像头),
传感器(雷达,激光雷达,GPS…), 它们用于建立场景和捕捉前后左右的距离，速度,
判断自已位置，同时车辆内部通过CAN总线监测车辆本身的情况, 并控制速度,
转向, 制动等等．当然还需要软件算法．<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-09c3c1bdb3a827cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="硬件" /></p>
<h2 id="软件">软件</h2>
<p> 软件收集硬件传来的视频和传感器数据,
进行数据处理并做出决策．其中包括: 感知当前的状态（车辆, 行人,
交通标志，动态，静态）, 预测之后的状态,
以及做下一步的规划（整体线路，当前决策）, 这有点像下棋．<br />
 出于安全性的考虑，大多数时候汽车不能上街测试，因此自动驾驶的开发过程中一般都使用虚拟系统，虚拟车辆在虚拟街道上运行的时候，还可以模拟其它车辆，行人，以及各种出错和违规的状态，模拟可能遇到的多种情况，以及车辆间的交互，它创建了增强学习的条件．使算法更快速地成长起来．<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-c1b60227f8e9dba9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="模拟环境" /></p>
<h2 id="安装apollo系统">安装Apollo系统</h2>
<p> Apollo是个开源的软件系统，可从git上下载源码，下面来看看具体的下载编译方法．</p>
<pre><code>$ git clone https://github.com/ApolloAuto/apollo  </code></pre>
<p>下载后，apollo目录下有安装说明README_cn.md，按此说明安装即可</p>
<pre><code>$ cd docker/scripts/  
$ ./install_docker.sh   </code></pre>
<p>此时如果报错找不到docker-engine，可用命令$ wget -qO-
https://get.docker.com/ |
sh手动安装docker，您可以把Docker理解成轻量的虚拟机，虚拟出单独的环境．运行一些特殊的程序，并把它和机器上其它程序隔离开．</p>
<pre><code>$ sudo ./dev_start.sh  </code></pre>
<p>此处会下载docker的镜像文件，16G数据下载到/var/lib/docker目录下，建议根分区留足空间，或者将该目录软链接到其它分区，做链接时需要暂时把docker服务停掉
$service docker stop/start</p>
<pre><code>$ sudo ./dev_into.sh  </code></pre>
<p>此时就进入了docker，可以编译了</p>
<pre><code>$ bash apollo.sh build  </code></pre>
<p>编译时请耐心等待，我的机器速度还可以，编了两个多小时，编译过程中在$HOME/.cache/.bazel中产生大约5G数据．</p>
<pre><code>$ bash scripts/hmi.sh  </code></pre>
<p>启动人机交互界面，此时在浏览器中打开http://localhost:8887，即可看到apollo界面了.<br />
<img
src="http://upload-images.jianshu.io/upload_images/5357893-c2e18cfe340808e7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="用户界面" /></p>
<h2 id="apollo源码分析">Apollo源码分析</h2>
<p> 源码主要是c++实现的，也有少量python，git下载几百兆，其实代码不太多，主要是地图和数据了大量空间，主要程序在apollo/modules目录中，我们把它分成以下几部分（具体说明见各目录下的modules）：<br />
1. 感知：感知当前位置，速度，障碍物等等<br />
Apollo/modules/perception<br />
2. 预测：对场景下一步的变化做出预测<br />
Apollo/modules/prediction<br />
3. 规划：<br />
(1) 全局路径规划：通过起点终点计算行驶路径<br />
Apollo/modules/routing<br />
(2) 规划当前轨道：通过感知，预测，路径规划等信息计算轨道<br />
Apollo/modules/planning<br />
(3)
规划转换成命令：将轨道转换成控制汽车的命令（加速，制动，转向等）<br />
Apollo/modules/control<br />
4. 其它<br />
(1) 输入输出<br />
i. Apollo/modules/drivers 设备驱动<br />
ii. Apollo/modules/localization 位置信息<br />
iii. Apollo/modules/monitor 监控模块<br />
iv. Apollo/modules/canbus 与汽车硬件交互<br />
v. Apollo/modules/map 地图数据<br />
vi. Apollo/modules/third_party_perception 三方感知器支持<br />
(2) 交互<br />
i. Apollo/modules/dreamview 可视化模块<br />
ii. Apollo/modules/hmi 把汽车当前状态显示给用户<br />
(3) 工具<br />
i. Apollo/modules/calibration 标注工具<br />
ii. Apollo/modules/common 支持其它模块的公共工具<br />
iii. Apollo/modules/data 数据工具<br />
iv. Apollo/modules/tools 一些Python工具<br />
(4) 其它<br />
i. Apollo/modules/elo 高精度定位系统，无源码，但有文档<br />
ii. Apollo/modules/e2e 收集传感器数据给PX2,ROS</p>
<p> 自动驾驶系统先通过起点终点规划出整体路径（routing）；然后在行驶过程中感知（perception）当前环境（识别车辆行人路况标志等），并预测下一步发展；然后把已知信息都传入规划模块（planning），规划出之后的轨道；控制模块（control）将轨道数据转换成对车辆的控制信号，通过汽车交互模块（canbus）控制汽车．<br />
 我觉得这里面算法技术含量最高的是感知perception和规划planning，具体请见代码．</p>
<h2 id="apollo开发者支持">Apollo开发者支持</h2>
<p> 点开Apollo网站的开发者界面
http://apollo.auto/opendata_cn.html　选择＂立即进入＂，即可看到给开发者提供的数据和测试资源.
确实有点超乎我的想像，尤其是仿真平台，有了它，没有车的情况下，也能做很多工作．而且文档也挺全的．(上传测试好像需要上传docker的img，看起来比较大，这个我也没仔细研究，也可能是看错了)</p>
<h2 id="总结">总结</h2>
<p> 自动驾驶发展到今天，离不开整体智能领域的发展，比如图像识别，各种高精度的传感器，地图数据，算法的进步都是自动驾驶的基础，并且仍在不断进步．而该领域的技术，之后也会被迁移到其它领域，比如机器人的三维场景定位，行为判断等等．<br />
 目前虽然离完全脱离人类操作还有一段距离，但自动驾驶中的各种技术越来越多地在新型汽车上得到应用，这个领域还是挺值得学习和期待的．</p>
<h2 id="参考">参考</h2>
<ol type="1">
<li>你怎么看待百度自动驾驶Apollo 1.5版本？<br />
https://www.zhihu.com/question/65638509/answer/236251671<br />
</li>
<li>Apollo自动驾驶框架试玩<br />
http://www.cnblogs.com/hackcat/archive/2017/07/06/7126042.html<br />
</li>
<li>全网唯一完整译文 | Waymo无人车报告：通往自动驾驶之路<br />
https://www.leiphone.com/news/201710/JknkYopJ14gVMSyK.html</li>
</ol>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读：GBDT能否被深度学习取代——TabNet</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_GBDT%E8%83%BD%E5%90%A6%E8%A2%AB%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%8F%96%E4%BB%A3TabNet/</url>
    <content><![CDATA[<h1
id="论文阅读gbdt能否被深度学习取代tabnet">论文阅读：GBDT能否被深度学习取代TabNet</h1>
<p>#深度学习 #论文阅读</p>
<p>论文名称：《TabNet: Attentive Interpretable Tabular Learning》<br />
论文地址：<a
href="https://arxiv.org/abs/1908.07442">https://arxiv.org/abs/1908.07442</a><br />
相关代码：<a
href="https://github.com/dreamquark-ai/tabnet">https://github.com/dreamquark-ai/tabnet</a><br />
)Pytorch版本（目前star:778）</p>
<p>《TabNet: Attentive Interpretable Tabular Learning》是google
2019年底的一篇论文，目前已更新到v5版本。其目标是使用深度学习注意力网络，构建具有可解释性的用于表格数据的模型；并且可以利用大量无标注数据，使用自监督学习的方法提高模型效果。</p>
<h2 id="简介">简介</h2>
<p>深度学习网络在图像、文本、声音等领域都具有经典框架并取得很好的效果，但对于最常用的数据表（由类别和数值型数据组成）至今没有通用的深度学习经典框架。
在数据表领域更常见的方法是使用集成决策树，这主要是由于：它能在超平面上计算出数据切分边界，具有可解释性，且训练速度快；另一方面也源于之前的深度学习模型设计出的结构并不太适合表格数据，网络参数过多，没有很好地归纳。可能导致无法定位到最佳解决方案。</p>
<p>设想将深度学习网络引入表格数据处理，源于它的诸多优势，如：在数据量越多的情况下它的表现越优异，它可以构建end-to-end模型，将图片数据和表格数据结合起来；减少特征工程的难度（这也是处理表格数据最重要的问题），从数据流中学习，end-to-end使模型应用于更多的场景，如数据自适应（迁移学习），生成模型，半监督学习等等。</p>
<p>论文的主要贡献在于：</p>
<ol type="1">
<li>模型可直接使用表格数据，不需要预先处理；使用的基于梯度下降的优化方法，使它能方便地加入端到端（end-to-end）的模型中。<br />
</li>
<li>在每一个决策时间步，利用序列注意力模型选择重要的特征，学习到最突出的特征，使模型具有可解释性。这是一种基于实例的特征选择（对于每个实例选择的特征不同），且它的特征选择和推理使用同一框架。<br />
</li>
<li>TabNet有两个明显优势，一方面是它在分类和回归中都表现出了与其它模型差不多的模型效果，另一方面，它具有局部可解释性（特征重要性和组合方法），和全局可解释性（特征对模型的贡献）。
(4) 对表格数据，使用无监督数据预训练（mask方法），可提高模型性能。</li>
</ol>
<h2 id="实现">实现</h2>
<p>关于具体实现的描述在论文第3-5页，看了一遍论文没看懂，又找了一篇翻译也没看懂，后来结合源码才看明白。下面按个人理解结合代码分析一下（与论文顺序不完全一致）。
以pytorch版本为例，核心网络结构的实现tab_network.py代码中。</p>
<h4 id="输入数据">输入数据</h4>
<p>表格类型的输入数据一般是数值型或者类别型，数据值直接代入模型，而类别型可能涉及N种取值，为简化模型，TabNet使用了可训练的Embedding方式处理类别型数据，即把一个类别型特征转换成几维数值型特征，通过它们的组合来表征，具体实现见EmbeddingGenerator类，它将每个类别型数据映射到数值类型，具体的映射方法通过训练得到。</p>
<h4 id="码器tabnetencoder">码器：TabNetEncoder</h4>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-3f09bbe22309d429.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>从结构图可以看到，无论是用于填充缺失特征的无监督学习（左），还是用于实际决策的有监督学习（右），都使用编码器TabNet
encoder先将输入特征编码；然后根据不同用途分别与decoder连接填充缺失特征，或与全连接层相连实现最终决策。</p>
<p><em>注：网络结构层层包含比较复杂，建议在回归示例的代码中使用print(clf.network)查看具体网络结构</em></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d8a9337775d5c59e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>编码器由多个FeatTransformer和多个AttentiveTransformer堆叠而成。编码器的输入是处理好的数值型特征，输出包括编码后的特征a[i]和供最终决策使用的数据d[i]。
图中的step表示决策步（时间步），它有点像决策树中的判断结点，每一步都接收输入的所有特征，并选择其中几个特征计算。调用者可设定使用多少个Step（一般是3-10，图中示例为2
step）。每个Step接收数据特征（图中黑线）作为输入，并使用上一步的输出（图中红线）对数据特征加权（决定哪些特征更加重要）。而每一步的输出通过累加的方式用于最终决策。</p>
<p><em>注：Transformer模型最早出现在NLP处理中，详见论文《Attention is
you
need》，它替代了传统的RNN模型，Attention，Encoder，Decoder是其核心技术。</em></p>
<p>文中使用的技术可算是Transformer模型在表格数据处理中的应用。而上图中的Transformer指的是大模型中的子模块。</p>
<h4 id="特征处理模块feature-transformer">特征处理模块Feature
transformer</h4>
<p>论文中展示了四层的Feature
transformer，它包括两个在所有决策步之间共享的层，和两个（Shared across
decision steps）与单个决策步相关的层（Decision step
dependent）。每一层又由GLU，归一化层和全连接层组成。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-58917fb294217e6b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>GLU门控线性单元Gated linear
units，它在全连接网络上加入了门控，其公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ec63660122bbe94e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>等式的前半部分为全连接层，后半部分使用门控方式决定哪些信息传向下一层。
Encoder图中Feature transformer后面带有split，split指Feature
transformer的输出分为两部分，一部分供最终预测Output使用，写作d[i]，另一部分继续向后传递a[i]，供注意力模块Attentive
transformer使用。</p>
<p>Feature Transformer采用了两种不同的模块：所有时间步共享Shared across
decision steps（整个TabNetEncoder共用一份），只影响单步的Decision step
dependent（内部创建）。从图中可以看到，先处理了共用部分，又进一步处理了单步相关模块，使用根号5用于保证模型稳定。</p>
<p>上图中的FC+BN+GLU相当于代码中的GLU_Layer，而虚线框对应GLU_Block。
最终，每一步的输出d[i]经过RELU()处理后累加，再经过一个全连接层FC作出决策Out。</p>
<h4 id="注意力模块attentive-transformer">注意力模块Attentive
transformer</h4>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-7022a3a328c5a306.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>以投资数据为示例，输入的每条记录是用户的具体情况，在第一步（第一个红字框）选择了职业相关的特征，通过职业特征计算出的结果，传给下一步（第二个红字框）并对投资相关的特征进行加权，有点像决策树在每一层判断节点上选择特征，而在这里选择的是多个特征的组合作为决策依据。</p>
<p>注意力模块，即Encoder图中的Attentive部分，它的灵感来源于处理文字和图片时只关注输入中的部分数据。在数据表中可看作每一步只选择其中几维数据处理，即特征选择，使用此方法简化了模型参数和学习效率。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-aa62b8c62c3dbb62.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其具体实现的方法是使用全连接层，归一化层，和Sparsemax，最终输出mask（用M表示）用于对输入数据加权。M的计算方法如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-cb3b416ac6cc0556.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中h是可被训练的模型参数（FC和BN实现），a[i-1]是前一个层提供给Attentive
transformer的输入，Sparsemax可视为Softmax的稀疏化版本。P[i-1]记录该特征在之前step中的使用程度（一般来说，如果之前用过，本次就不太可能再用），具体计算方法是：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-91bae208b0fd1db0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中i是决策步step，γ为松弛参数，如果它为1，则只要使用过，则会再被使用，如果γ较大，则特征可被多次使用。P[0]一般设置为全1。如果发现有些特征完全没用（通过无监督学习发现），可将其P[0]设置成0，以免浪费计算资源。</p>
<p>为了达到更好稀疏效果，还计算了稀疏正则化，并将每一步的值计入整体损失中：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a6c5f8bb879002b3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中ε作为参数传入模型，一般是个非常小的值。M越稀疏，Lsparse越小，Loss也越小；反之在大多数特征都冗余时，Loss较大；它的作用是在每个时间步上尽量关注更少的特征。</p>
<h4 id="模型可解释性">模型可解释性</h4>
<p>从原理上看，mask可以描述单个实例单步的特征重要性，使模型具备局部可解释性，全局可解释性则需要通过系数组合每个单步的重要性，文中提出了系数的计算方法：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-cd084e4126d5949e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>等式描述第b实例在第i个时间步对整体决策的贡献。</p>
<h4 id="表格数据的自监督学习">表格数据的自监督学习</h4>
<p>数据缺失是表格数据需要面对的重要问题，利用遮蔽训练方法（一般称mask方法，此mask与上面attention中的mask不同），是深度学习在自然语言处理中的一种常用方法，它使用大量无标数据训练，故意遮蔽（masked）一些有效数据，然后通过训练模型弥补数据缺失，间接实现了数据插补。使模型在数据缺失的情况下也能很好地工作。特别是在标注数据较少的情况下，效果更加明显。</p>
<p>具体方法是使用编码器与解码器结合的方式，解码器TabNetDecoder用于将编码后的特征还原到原始数据表特征。调用者也可以设置多步step解码，其中每一步由一个Feature
transforer和一个全连接层组成。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-852f8bebfbf418ad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>具体方法是，使用S∈{0,
1}掩码，使用(1-S)遮蔽部分数据后传给编码器再解码，最终将解码后的数据乘S得到被遮蔽的特征（预测值），然后通过被遮蔽部分的实际值与预测值的误差调整模型参数。具体方法如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-2434fc8f55739f2e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>这里使用了正则化，以避免各特征取值范围不同的问题。另外，在每次迭代时利用伯努利分布重新对S采样，以保证遮蔽各个特征。</p>
<h4 id="时间步">时间步</h4>
<p>使用决策树模型时，决策树的顶部一般是比较有辨识度的特征（对大多数实例重要的特征），预测时每个实例都使用同一决策树。
TabNet模型也在每个时间步选择部分特征运算，像是决策中的各个结点。不同的是，每一步可选择一个或多个特征组合，且可以根据不同实例在各个时间步选择不同的特征（该功能主要由Attention选择参数和step多步方法提供）。</p>
<p>从理论上说，相对于树模型对特征全局性评估，TabNet更善于评估单个实例的特征重要性。也因为如此，预测和归因可以使用了同一框架——它在决策过程中选择的特征，就是该实例的重要特征。</p>
<h2 id="用法">用法</h2>
<p>论文的实验和附录部分在不同数据集上对比了树模型与TabNet模型的效果，总之，准确率不比树模型低，且模型也不大，下面记录了自己做的一些实验，谈谈主观感受。</p>
<h4 id="安装">安装</h4>
<p>在网上可以找到基于pytorch和tensorflow的TabNet版本（下载地址见参考部分），以pytorch版本为例，为简安装方法如下：</p>
<pre class="shell"><code>$ pip install pytorch-tabnet   </code></pre>
<p><em>注：它对pytorch，scipy，sklearn，matplotlib都有一定要求</em></p>
<h4 id="示例">示例</h4>
<p>以pytorch版本为例，其网络结构实现在：</p>
<p><a
href="https://github.com/dreamquark-ai/tabnet/tree/develop/pytorch_tabnet">https://github.com/dreamquark-ai/tabnet/tree/develop/pytorch_tabnet</a>.py<br />
（调用逻辑：tab_model.py-&gt;abstract_model.py-&gt;tab_network.py）</p>
<p>如果不修改网络内部结构，仅使用它构建好的网络来训练模型和预测，非常简单，它封装成了类似于sklearn的调用方法，几乎不需要了解深度学习库的用法，调用API即可，回归例程，可参考：<br />
<a
href="https://github.com/dreamquark-ai/tabnet/blob/develop/regression_example.ipynb">https://github.com/dreamquark-ai/tabnet/blob/develop/regression_example.ipynb</a><br />
例程中对比了TabNet与XGBoost的用法和效果。</p>
<h4 id="使用效果">使用效果</h4>
<p>测试了代码中自带的回归示例，训练集大小(26072,
14)，使用我笔记本上的cpu，一次迭代约一两秒，146次迭代后early_stop，相对于xgboost的百次迭代还是慢了很多。对测试集(3267,
14)，tabnet预测速度0.15秒，而xgboost
0.012秒，虽说差了十倍，但还在可接受的范围内。又试了一下GPU的机器，也没有太明显的提速。个人感觉在小数据量（表格数据）处理中，是否使用GPU没那么重要。</p>
<p>在我的机器上，使用默认参数测试，xgboost在速度和准确率上还是有明显的优势。</p>
<h2 id="参考">参考</h2>
<p><a
href="https://www.jianshu.com/p/1012297aff38">Attention注意力机制</a></p>
<p><a
href="https://blog.csdn.net/qq_32458499/article/details/81513720">GLU（Gated
Linear Units）门控线性单元</a></p>
]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_多任务学习_MMoE</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0_MMoE/</url>
    <content><![CDATA[<h1 id="介绍">介绍</h1>
<p>英文题目：Modeling Task Relationships in Multi-task Learning with
Multi-gate Mixture-of-Experts<br />
中文题目：多门专家混合多任务学习中的任务关系建模<br />
论文地址：https://dl.acm.org/doi/pdf/10.1145/3219819.3220007<br />
领域：深度学习，多任务学习<br />
发表时间：2018<br />
作者：Jiaqi Ma，密歇根大学，谷歌<br />
出处：KDD<br />
被引量：137<br />
代码和数据：https://github.com/drawbridge/keras-mmoe<br />
阅读时间：22.07.24</p>
<h2 id="读后感">读后感</h2>
<p>多任务学习一般用于相同输入特征，用一个模型同时学习多个任务．一次预测多个标签，这样可以节约训练和预测时间，也能节约存储模型的空间．<br />
之前的方法主要是底层共用网络，上层针对每个任务分别训练自己的网络．这样做的问题是，如果多个任务相关性不强，可能向不同方向拉扯共享参数，虽然理论上多个任务可以互为辅助，提供更多信息，但实现效果往往不如单独训练模型效果好．</p>
<h2 id="介绍-1">介绍</h2>
<p>多任务学习效果一般取决于不同任务之间的相关性．文中提出的MMoE（Multi-gate
Mixture-of-Experts）是对之前方法<strong>MoE</strong>的改进．主要用于解决多任务相关性小时，同时优化多个目标的问题．比如同时预测用户是否购买及用户满意度．</p>
<p>在研究过程中，遇到的问题还有：如何衡量不同任务的相关性；如果不让模型由于多任务变得过大和过于复杂．</p>
<p><strong>文章贡献</strong><br />
* 提出MMoE结构，构建了基于门控的上层网络，模型可自动调节网络参数．<br />
* 设计了生成实验数据的方法，以便更好的衡量任务相关性对建模的影响<br />
* 在实验数据集中实现了更好的效果，解决了现实世界中大规模数据训练问题</p>
<h2 id="方法">方法</h2>
<p><img src="/attachments_2022/Pasted%20image%2020220724184704.png"
alt="Pasted%20image%2020220724184704.png" /><br />
之前的实现方法如图-1(a)所示，底层网络Shared
Bottom共享参数，上层使用双塔或多塔结构以适配不同任务：<br />
<img src="/attachments_2022/Pasted%20image%2020220724184950.png"
alt="Pasted%20image%2020220724184950.png" /><br />
其中k是具体任务，f(x)是底层模型，hk是上层模型．</p>
<p>进而是如图-1(b)所示的MoE模型（在后续的实验中也记作OMoE），它使用多个专家网络作为底层，利用输入计算门控值用于设置各个专家贡献的占比，然后将计算出的结果送入上层网络．<br />
<img src="/attachments_2022/Pasted%20image%2020220724185633.png"
alt="Pasted%20image%2020220724185633.png" /><br />
其中g是门控，n是专家的各数，公式结合了各个专家的结果．对于每个实体，只有部分网络被激活．</p>
<p>图-1(c)是本文提出的网络结构MMoE，与MoE不同的是它针对不同的任务计算不同的门控分别设置专家占比．<br />
<img src="/attachments_2022/Pasted%20image%2020220724185945.png"
alt="Pasted%20image%2020220724185945.png" /><br />
<img src="/attachments_2022/Pasted%20image%2020220724190014.png"
alt="Pasted%20image%2020220724190014.png" /><br />
其中的 Wgk 是可训练的矩阵，用于根据输入选择专家．</p>
<p>每个门控网络线性地将输入空间分割成n个区域，每个区域对应一个专家。MMoE决定不同门控制管理的区域如何相互重叠。如果某区域与任务的相关性较低，那么共享专家将受到惩罚，任务的门控网络将学会使用不同的专家。</p>
<h2 id="实验">实验</h2>
<h3 id="合成数据实验">合成数据实验</h3>
<p>合成数据能更好的对比不同任务相关性的影响，利用合成数据的实验对比如图-4所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220724190833.png"
alt="Pasted%20image%2020220724190833.png" /><br />
* 对于所有模型，相关度高的任务训练效果都更好<br />
*
在不同相关度的情况下，MMoE都好于OMoE和Shared-Bottom模型．而在相关性一致的情况下，MMoE和OMoE结果几乎一致<br />
*
基于MoE的两个模型效果都明显好于Shared-Bottom，且收敛更快，这说明MoE结构使模型更好训练．</p>
<h3 id="真实数据实验">真实数据实验</h3>
<h4 id="人口收入数据">人口收入数据</h4>
<p>使用人口收入数据，分别进行两组实验，第一组同时训练两个任务：训练收入是否超过50K和婚否；第二组同时训练教育程度和婚否．训练数据199523．训练结果如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220724191801.png"
alt="Pasted%20image%2020220724191801.png" /></p>
<h4 id="大规模的内容推荐">大规模的内容推荐</h4>
<p>利用谷歌数以亿计的推荐数据训练．目的是同时优化：与粘性相关的目标，如点击率和粘性时间；以及与满意度相关的目标．具体评价标准使用AUC和R-Squared
scores．效果如表-3所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220724192303.png"
alt="Pasted%20image%2020220724192303.png" /><br />
从图-6中可以看到不同专家对不同任务的贡献：<br />
<img src="/attachments_2022/Pasted%20image%2020220724192405.png"
alt="Pasted%20image%2020220724192405.png" /></p>
]]></content>
      <tags>
        <tag>深度框架</tag>
        <tag>多任务学习</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_对比学习_SimCLR</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0_SimCLR/</url>
    <content><![CDATA[<p>英文题目：A Simple Framework for Contrastive Learning of Visual
Representations<br />
中文题目：视觉表征对比学习的简单框架<br />
论文地址：https://arxiv.org/abs/2002.05709v2<br />
领域：深度学习，知识表示，半监督学习，对比学习<br />
发表时间：2020<br />
作者：Ting Chen，Hinton团队，Google Research<br />
出处：ICML<br />
被引量：1734<br />
代码和数据：https://github.com/leftthomas/SimCLR<br />
阅读时间：22.08.14</p>
<h1 id="读后感">读后感</h1>
<p>众所周知，有监督学习相比于无监督学习和半监督学习速度更快，效果更好，但也存在一些问题，比如难以泛化解决其它问题，需要高成本的标注等等．</p>
<p>对比学习是一种半监督学习（自监督学习），它可以生成一种表示，用一组数表征一个时间序列，一句话，一张图...
然后再代入下游任务．具体方法是用实例间的相似和差异学习怎么描述这个实例，从而捕捉内在的不变性；从高维到低维，构建更抽象地表示．</p>
<p>个人感觉有监督和半监督学习各有优势，实际建模时有效结合二者，即可以提升训练效率，也能减少标注成本．</p>
<h2 id="介绍">1 介绍</h2>
<p>对比学习属于自监督学习．自监督学习一般不需要标签，通过数据本身构造模型，训练结果可以支持更多下游任务．常见的自监督学习包括：<br />
* AutoEncoder自编码器<br />
* GAN生成对抗网络<br />
* Mask语言模型，如：BERT<br />
* Contrastive 对比学习模型，其原理是：语义相似-&gt;表征一致</p>
<p>文中提出了简单的对比学习表示框架SimCLR．</p>
<p><strong>本文主要贡献</strong><br />
* 利用数据增强构造训练数据<br />
* 构建可学习的非线性模型，提升数据表示质量<br />
* 构造特殊的损失函数<br />
* 相对于有监督学习，对比学习使用更大的批处理规模和更长的训练时间</p>
<h2 id="方法">2 方法</h2>
<h3 id="对比学习框架">2.1 对比学习框架</h3>
<ul>
<li>如图-2所示，对于实体x，使用数据增强方法分别构建xi和xj，将二者的组合看作正例对．<br />
</li>
<li>使用神经网络编码器 f 获取增强数据的向量表示 h，文中的 f
使用了用于图片处理的 ResNet．<br />
</li>
<li>使用小型神经网络进行投影变换
g，将向量映射到对比损失函数可以应用的数据空间，转换成向量表示z．<br />
</li>
<li>利用对比损失函数判别正反例，正例是对同一实例增强得到的数据对，反例是对不同实例增强产生的数据对．<br />
<img src="/attachments_2022/Pasted%20image%2020220814103850.png"
alt="Pasted%20image%2020220814103850.png" /><br />
反例一般使用同一batch中的数据构造，损失函数定义如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220814105614.png"
alt="Pasted%20image%2020220814105614.png" /><br />
设batch中包含N个实例，每个实例生成两个数据增强，则产生2N个增强数据，此时分子计算的是正例间的距离，分母计算负例间的距离，τ
是温度参数．<br />
具体算法如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220814105952.png"
alt="Pasted%20image%2020220814105952.png" /></li>
</ul>
<h3 id="使用大batch-size训练">2.2 使用大Batch Size训练</h3>
<p>将Batcch
size设置为256-8192，此时负例数据巨大，计算量也是巨大的．使用SGD/Momentum优化器可能造成模型不稳定，因此，使用LARS优化器，TPU，32-128个核不等，另外，还使用了全局的Batch归一化方法，以解决不同设备上并行训练时的归一化问题．</p>
<h3 id="评价策略">2.3 评价策略</h3>
<p>以预训练的模型为基础，最上层加入一个线性分类器，在冻结的基础网络上训练，以评价具体任务，将测试集准确率作为评价指标，另外，实验还与其它半监督学习和转移学习方法进行了对比．<br />
由于是对图片数据操作，使用了剪切，缩放，颜色失真，高斯模糊等方法进行数据增强；使用ResNet-50作为编码器，2层的投影变换网络，最终将数据映射到128维空间内．使用NT-Xent作为损失函数，LAR作为优化器，batch:4096，100次迭代．</p>
<h2 id="具体实现">3 具体实现</h2>
<p>这篇论文主要介绍了针对图片的对比学习方法，对于自然语言，时序数据，图结构的对比学习方法也与之类似，主要都是针对以下几个方面设计和实现：<br />
* 数据增强<br />
根据数据不同，增强方式如：切分/旋转/变化/随机Mask/随机噪声/选择不同阶段数据/dropout/采样；用来自同一样本的数据增强，生成正样本对；用来自不同样本的数据增强，生成负样本对．<br />
优化方法包括：通过数据增强更好地保留共性；锁定更有效的硬负例等．<br />
* 信息编码<br />
通过训练模型，将实体转换为相对低维的向量表示．<br />
* 损失函数<br />
根据数据设计损失函数，使正样本更加一致，负样本完全不同，邻近样本比正样本远，比负样本近．<br />
* 其它优化<br />
根据数据设计更复杂的结构，比如利用图中的邻居信息构建介于正负样本之间的样本作为中间样本；利用时序数据中来自同一数据源的不同时段数据作为中间样本....</p>
<h3 id="数据增强">3.1 数据增强</h3>
<p><img src="/attachments_2022/Pasted%20image%2020220814112211.png"
alt="Pasted%20image%2020220814112211.png" /><br />
文中对图片的处理方法如图-4所示，就其本质来看，数据增强的目标是调整一些已知特征，让模型学到图中未被修改的深层次特征．这也带来一些问题，比如上图中，增强只与具体图片相关，模型学到了这张图片中的狗，但并未学到狗的共性，这一点稍逊于有监督学习．<br />
不同的增强方法学习效果也不同，图-5展示了不同方法，以及不同方法组合的影响：<br />
<img src="/attachments_2022/Pasted%20image%2020220814112903.png"
alt="Pasted%20image%2020220814112903.png" /></p>
<p>可以看到，尽管模型可以区分对比学习中的正反例，但任何单个变换都不足以学习到很好的表征，而颜色失真和剪切的组合效果明显，这可能是由于遮蔽了单张图片的特性，从而学到了共性．</p>
<p>另外，从表-1中可以看到，数据增强的变化越大，SimCLR学习效果越好：<br />
<img src="/attachments_2022/Pasted%20image%2020220814113730.png"
alt="Pasted%20image%2020220814113730.png" /></p>
<h3 id="网络结构">3.2 网络结构</h3>
<p>无监督对比学习受益于更大的模型．如图-7所示：绿叉是90次迭代的有监督学习，红星是1000次迭代的对比学习，蓝点是100次迭代的对比学习．从中可以看到有监督学习的优势．对于无监督学习，网络的深度宽度影响更大．</p>
<p><img src="/attachments_2022/Pasted%20image%2020220814114107.png"
alt="Pasted%20image%2020220814114107.png" /><br />
投影变换可提升表示质量．图-8展示了使用不同结构的投影变换效果，对比结果发现，非线性变换（加ReLU激活函数）效果最好，而与输出维度无关．<br />
<img src="/attachments_2022/Pasted%20image%2020220814131300.png"
alt="Pasted%20image%2020220814131300.png" /><br />
如表-3所示，投影前的表示比投影后的表示携带更多信息，这可能是由于投影函数去除了一些对其它下游任务有用的信息．<br />
<img src="/attachments_2022/Pasted%20image%2020220814141517.png"
alt="Pasted%20image%2020220814141517.png" /></p>
<h3 id="损失函数和-batch-size">3.3 损失函数和 Batch Size</h3>
<p>实验证明，不同的损失函数，超参数对实验结果有显著影响．另外，更大的batch
size及迭代次数也能更好地优化模型．这可能与负例的硬度（难度）和数量相关．<br />
<img src="/attachments_2022/Pasted%20image%2020220814133957.png"
alt="Pasted%20image%2020220814133957.png" /></p>
<h2 id="实验">4 实验</h2>
<p>主实验结果如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220814134209.png"
alt="Pasted%20image%2020220814134209.png" /></p>
]]></content>
      <tags>
        <tag>知识表示</tag>
        <tag>对比学习</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_模型剪枝_彩票假设</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D_%E5%BD%A9%E7%A5%A8%E5%81%87%E8%AE%BE/</url>
    <content><![CDATA[<p>英文题目：The Lottery Tickets Hypothesis for Supervised and
Self-supervised Pre-training in Computer Vision Models<br />
中文题目：用基于彩票假设方法裁剪视觉模型<br />
论文地址：https://arxiv.org/pdf/2012.06908.pdf<br />
领域：机器视觉，深度学习，模型剪枝<br />
发表时间：2021<br />
作者：Tianlong Chen等，德克萨斯大学<br />
出处：CVPR<br />
被引量：26<br />
代码和数据：https: //github.com/VITA-Group/CV_LTH_Pre-training<br />
阅读时间：22.10.06</p>
<h2 id="读后感">读后感</h2>
<p>文章介绍了一种针对图像处理的剪枝算法，不同与以往先训练后剪枝的方法，它的目标是直接训练出一个稀疏的子网络，并使子网络性能与稠密网络性能相当。</p>
<h2 id="介绍">介绍</h2>
<p>预训练模型提升了计算机视觉的效果，目前主流的方法是有监督学习和半监督学习。作者提出：可否在不影响下游任务性能的同时，降低预训练模型的复杂度？<br />
文中提出基于彩票假设的方法（lottery ticket
hypothesis：LTH），LTH能在海量的稠密网络中，识别出高度稀疏的匹配子网络，同时实现完整模型的性能。</p>
<p>文中提出从两个角度结合预训练模型和LTH：(1)
把正常预训练出的模型权重作为LTH的初始化参数；(2)
寻找匹配的子网络常需要多轮修剪和重新训练，因此尽量让子网络能被各种下游任务重用，如图-1所示：<br />
<img src="/attachments_2022/Pasted%20image%2020221006101304.png"
alt="Pasted%20image%2020221006101304.png" /></p>
<p>剪枝算法一般分为非结构化剪枝和结构化剪枝，前者根据权重大小进行稀疏化；后者使用移除通道等方式，适用于更多硬件。</p>
<p>LTH与传统的先训练后剪枝方法不同，它致力于训练与稠密网络性能相当的稀疏的子网络。</p>
<h2 id="方法">方法</h2>
<h3 id="数据">数据</h3>
<p>把ResNet-50作为基础模型，将分类、目标检测和分割作为下游任务，不修剪第一个卷积层和与具体任务相关的最后层。定义f(x;
θ, γ)，其中x是输入的图像，θ是模型参数，γ是与具体任务相关的参数。</p>
<p>有监督预训练使用ImageNet训练ResNet-50模型；半监督训练使用基于ResNet-50的simCLR和MoCov2模型。</p>
<p>所有预训练都使用ImageNet数据，下游任务使用Fashion-MNIST，SVHN，CIFAR-10，Pascal
VOC等数据集，这些任务在分辨率，数据源，类别，颜色空间都有差异，具体如表-1所示：<br />
<img src="/attachments_2022/Pasted%20image%2020221006103554.png"
alt="Pasted%20image%2020221006103554.png" /></p>
<h3 id="子网络">子网络</h3>
<p>子网络：f (x; m⊙θ, ·)，其中m是用于剪枝的二值
mask，⊙是元素层面的乘积，设A为针对具体任务T的算法，t为迭代次数。θp为预训练的权重；θ0为随机初始化的权重；θi为第i轮训练后的权重。E为评价函数。定义如下：<br />
* 可达子网络<br />
可达子网络需要满足如下条件：<br />
<img src="/attachments_2022/Pasted%20image%2020221006110044.png"
alt="Pasted%20image%2020221006110044.png" /><br />
即：在使用相同的算法A和评价函数E的条件下，可达子网络的表现不比稠密网络差。<br />
* 中奖奖券<br />
如果 f(x; m⊙θ, r) 在 θ=θp
的条件下是可达子网络，此时的算法A就是中奖的奖券。<br />
* 普适子网络<br />
子网络 f(x; m⊙θ, γTi )
用于适配指定任务γTi，适用于所有任务的方法叫作普适子网络。</p>
<h3 id="剪枝方法">剪枝方法</h3>
<p>具体实现使用经典的迭代权值剪枝方法(IMP)，首先训练未修剪的密集网络用以完成任务T，然后删除部分具有全局最小值的权重，以修剪网络，使用该方法多次迭代。具体如算法-1所示：<br />
<img src="/attachments_2022/Pasted%20image%2020221006111305.png"
alt="Pasted%20image%2020221006111305.png" /></p>
<h3 id="预训练中奖奖券的迁移">预训练中奖奖券的迁移</h3>
<p>图-2展示了不同预训练模型稀疏参数的性能：<br />
<img src="/attachments_2022/Pasted%20image%2020221006112212.png"
alt="Pasted%20image%2020221006112212.png" /><br />
下面将在不同任务中，从三个角度讨论：(1)
中奖彩票在下游任务中表现如何？(2) 有监督和无监督模型哪个更好？(3)
普适模型和任务相关的模型有啥差异？</p>
<h4 id="迁移到分类任务">迁移到分类任务</h4>
<p>结果如图-3所示：<br />
<img src="/attachments_2022/Pasted%20image%2020221006114122.png"
alt="Pasted%20image%2020221006114122.png" /><br />
* 普适子网络(mP，
θp)可迁移到不同的下游分类任务。可以看到三种模型，只要不修剪得太厉害，其精度在修剪后差异不大。<br />
* 不同的预训练方式（有监督和自监督），对于不同数据集，表现不同。<br />
* 针对具体任务训练的模型 f(x; mT⊙θp, ·) 只在极度修剪时优于普适模型 f(x;
mp⊙θp,
·)。使用预训练模型参数作为修剪模型的初始参数时效果最好，使用随机初始化和少量迭代初始化的模型（粉色和灰色）在所有任务中都更差。</p>
<h4 id="迁移到目标检测和分割">迁移到目标检测和分割</h4>
<p>效果如图-5所示：<br />
<img src="/attachments_2022/Pasted%20image%2020221006115244.png"
alt="Pasted%20image%2020221006115244.png" /><br />
* 普适子网络(mP， θp)可成功地迁移到不同的下游任务中。<br />
*
不同于分类任务，在目标检测和分割任务中表现一致：MoCo都表现最好，有监督模型一般，Sim模型最差。<br />
* 针对具体任务训练的模型明显优于普适模型。</p>
]]></content>
      <tags>
        <tag>深度框架</tag>
        <tag>模型裁剪</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读：深度森林</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E6%B7%B1%E5%BA%A6%E6%A3%AE%E6%9E%97/</url>
    <content><![CDATA[<h1 id="论文阅读深度森林">论文阅读：深度森林</h1>
<p>#深度学习 #论文阅读</p>
<p>论文主题：《Deep Forest》<br />
论文地址：<a
href="https://arxiv.org/pdf/1702.08835.pdf">https://arxiv.org/pdf/1702.08835.pdf</a><br />
相关代码：<a
href="https://github.com/kingfengji/gcForest">https://github.com/kingfengji/gcForest</a><br />
相关代码：<a
href="https://github.com/LAMDA-NJU/Deep-Forest">https://github.com/LAMDA-NJU/Deep-Forest</a></p>
<p>深度森林是南大周志华老师前两年提出的一种基于随机森林的深度学习模型。</p>
<p>当前的深度学习模型大多基于深度学习神经网络（DNN），其中每一层都是可微的，在训练过程中通过反向传播调参。而本篇介绍的深度森林算法基于不可微的子模型，该算法把多个随机森林串联起来组成了深度学习模型。</p>
<p>作者认为深度模型的优越性主要在于：深度网络多层建构；模型特征变换；模型足够复杂。文中提出基于树模型的gcForest也可满足以上三点。相对于深度学习神经网络，它还有如下优势：使用较少的超参数；模型的复杂度可根据数据情况自动调整；使用模型的默认参数往往也能达到不错的学习效果。</p>
<h2 id="dnn的缺点">DNN的缺点</h2>
<ul>
<li>DNN超参数太多，调参难度大，需要大量技巧<br />
</li>
<li>DNN一般在大数据集上训练效果好，在中小数据集上表现较差，标注成本大<br />
</li>
<li>DNN是难以解释的黑盒模型<br />
</li>
<li>DNN需要事先设计网络结构，它的设计往往比实际需要的复杂度更高<br />
</li>
<li>在很多数据比赛中GBDT类模型效果往往更好</li>
</ul>
<h2 id="灵感">灵感</h2>
<p>作者设计灵感主要来源于深度学习模型和集成模型。</p>
<p>深度学习模型利用层层堆叠方法提升效果，因为即使给浅层网络设置很多单元，效果也不如深层网络；另外，决策树及GBDT决策树算法虽然也是层层推进，但效果也不如DNN的原因可能是它不能逐层提取更多特征，也就是说不支持模型内部特征转换（feature
transformation），且这些机器学习模型只有有限的复杂度。</p>
<p>集成模型中多模型集成比单模型有更好泛化效果。子模型需要兼顾准确性，多样性，互补性。比如森林中设置树模型多样性常常采用的方法有：数据采样方式不同，特征不同，模型参数不同，定义的输出不同等。</p>
<h2 id="实现方法">实现方法</h2>
<h4 id="森林堆叠">森林堆叠</h4>
<p>gcForest方法集成了多个森林，具体构建方法如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5085cae56e625d74.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>此例解决的是一个多分类问题，从左向右运行。模型输入是左侧的Input
Feature
Vector，最终输出为输入x属于三种类别的概率；模型深度为N层，每层包含两个完全随机树森林和两个随机森林；每一层的输入是前层的输出和基本特征（Input
Feature
Vector），输出为12个新特征（4模型x3类别）并传向后一层；使用验证集评价模型效果，当模型不再变好时停止继续训练。</p>
<h4 id="多粒度扫锚">多粒度扫锚</h4>
<p>DNN的重要优点在于识别出特征相关性，gcForest使用给特征分组的方法加入对特征相关性的支持：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-c26357dbecd56eea.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>假设输入400维特征，设置窗口宽度100，可取到301组特征，代入模型，产生903个输出（子模型输出x属于三个类别的概率301x3=903），如果使用两个森林ForestA和ForestB，则经过一层之后，输出1806个新特征。</p>
<p>再延展到更加复杂的结构：使用不同大小的滑动窗口：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-50ee1b73864542c8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>示例中分别使用了大小为100、200、300的滑动窗口，并使用不同的森林Forest
A/B/C分别处理，以达到更好效果（具体效果见实验部分）。</p>
<h4 id="参数对比">参数对比</h4>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-7929f63ee527e320.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>从参数对比中可以看到，DNN需要设计和尝试更多参数，而gcForest参数少，并且使用默认参数往往也能达到不错的效果。</p>
<h2 id="实验">实验</h2>
<p>文中实验主要在DNN擅长的领域，如图片、音频、自然语言处理等领域，使用中大规模数据对比多模型的使用效果。</p>
<h4 id="实验结果">实验结果</h4>
<p>图片分类：使用MNIST数据集，其中train 60000，test
10000，对比效果如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-f5095fd7a3aa03d3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>人脸识别</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-e4c64b074f7cedf6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>另外，文中还对比了音乐片断分类、手势识别、影评情感分类等，详见论文。</p>
<h4 id="低维数据与高维数据">低维数据与高维数据</h4>
<p>文中测试了模型在三种低维数据集上的表现LETTER：16个特征，训练集16000测试集4000；ADULT：14个特征，训练集32,561测试集16,281，YEAST：8个特征训练集1038测试集446。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-13f32eba72e3d414.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>也测试了在高维数据集CIFAR-10：训练集50000测试集10000图片，共10个类别，8192个特征。对比效果如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-c20bf7708127e755.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>可以看到优化的DNN方法ResNet，AlexNet明显优于gcForest，而gcForest在DNN以外的其它方法中效果最优；并且可以看到经过多滑动窗口和将最后一层替换成gbdt后，gcForest方法也有明显改进。</p>
<h4 id="运行时间">运行时间</h4>
<p>当使用25000实例5000特征，一层用时267.1秒。如果使用不同粒度，模型可以并行训练。</p>
<h4 id="多粒度特征叠加">多粒度特征叠加</h4>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ba2fc321fb6cc94f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>上图中使用多粒度特征时，将不同粒度提取的特征分别代入模型，此处实验将不同粒度提取的特征连接后统一代入模型，方法相对更简单，其效果与上述方法差别不大，模型效果对比如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-292b256bd54a479d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="使用方法">使用方法</h2>
<p>从github开源项目的demo中可以看到GCForest使用方法非常简单，类似Sklearn中的模型接口。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-1b79f74ba7772b62.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="总结">总结</h2>
<p>文中讨论的gcForest在目前很多深度学习领域表现也不错，并非想使用它去取代目前的DNN模型，而是提出了另一种深度学习的实现方法和可能性。</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_用深度和宽度网络构建推荐系统</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%92%8C%E5%AE%BD%E5%BA%A6%E7%BD%91%E7%BB%9C%E6%9E%84%E5%BB%BA%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h1
id="论文阅读_用深度和宽度网络构建推荐系统">论文阅读_用深度和宽度网络构建推荐系统</h1>
<p>#论文阅读 #推荐系统</p>
<p>论文地址：<a
href="https://arxiv.org/pdf/1606.07792.pdf">https://arxiv.org/pdf/1606.07792.pdf</a><br />
相关代码：<a
href="https://github.com/jrzaurin/pytorch-widedeep">https://github.com/jrzaurin/pytorch-widedeep</a></p>
<p>《Wide &amp; Deep Learning for Recommender
Systems》是2016年Google发表的一篇使用深线层网络相结合构建推荐系统的论文。</p>
<p>个人认为结合浅度学习和深度学习，是为一种处理表格数据，以及综合数据的好方法。这篇论文涉及：两种网络各自的优势；稀疏特征的组合；以及融合两种网络的具体方法。</p>
<p>使用非线性特征组合（具体方法见后）构造的线性网络（浅层网络）常被用于解决输入是稀疏特征的分类和回归问题，它的优点是高效且具有可解释性，缺点是需要大量特征工程。相对来说深层网络不需要太多特征工程，使用Embedding方法可将稀疏特征降维成稠密特征，它能构造在训练集中没见过的特征组合，而其问题在于过于泛化，当数据过于稀疏和高秩（具体见下文）时，它会推荐出一些无关的选项。文中方法结合了浅层网络的记忆力和深度网络的泛化力，使用TensorFlow实现，并将其应用在Google
Play的应用推荐系统中，取得了明显的提升。该方法也可应用于其它场景。</p>
<h2 id="介绍">介绍</h2>
<p>推荐系统的输入一般是用户相关数据及其上下文信息，系统在数据库中找到与之最匹配的商品项，排序后输出。这里涉及到记忆力和泛化力。记忆力可以看作寻找训练集中频繁出现的项目或特征组合，在历史数据中挖掘相关性；而泛化性则基于传递性，探索新的特征组合。</p>
<p>在浅层网络中常使用特征组合的方法，如将类别特征经过Onehot转换成二值特征，再将其进行组合，例如：AND(user_installed_app=netflix,impression_app=pandora)，即用户安装过netflix为其推荐的应用是pandora，当二者都为真时结果为真，其余情况下结果为假，从而确定了一些同时出现的组合对最终结果的影响。浅层网络通常会用到一些手动的特征工程，且无法找到在训练集中没出现过的组合。</p>
<p>深度网络可以找到一些训练集中未出现过的组合，且不需要手动做特征工程。当数据过于稀疏和高秩时，比如用户的特殊偏好或者比较小众的产品，并不在组合中大量出现，而稠密的嵌入层将会产出大量的非零组合，从而导致了无关的推荐。而浅层网络的“例外规则”用少量参数即可解决该问题。（深度网络更加宏观，浅度网络保存更多细节，不只是浅度线性模型，其它机器学习模型也类似）。</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-0157d3d72145856b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="（下方是输入，上方是输出）" />
<figcaption aria-hidden="true">（下方是输入，上方是输出）</figcaption>
</figure>
<h2 id="推荐系统">推荐系统</h2>
<p>推荐系统工作流程如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-558abc67e58b0856.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>Query表示用户在访问应用商店时产生的相关上下文信息，推荐系统返回App列表Ranked
items（也称impressions）。而用户的信息及与系统的交互过程都被记录到Logs中，以备训练模型使用Learner。</p>
<p>数据库（Database）中存储着数百万应用程序，用户查询又需要即时返回，因此第一步是检索（Retrieval），系统通过机器学习模型和人工定义的规则检索出少量可选项（比如100项）。最终通过模型输出排序（Ranking），排序根据概率P(y|X)，即：给定X的情况下（X包含用户信息和应用程序信息），用户动作为y（如安装app）的概率。</p>
<h2 id="算法原理">算法原理</h2>
<h4 id="wide组件">Wide组件</h4>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-dafe2aeb4db23c63.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>使用了简单的线性模型，其中w和b为模型参数，x由两部分组成，一部分为模型的输入x，另一部分为组合参数：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-39ed3b4da97e5e1e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中Cki为布尔类型，定义了第i维参数是否被使用在第k种组合中时，使用时值为1，否则为0。简单地说，就是使用某些方法（算法或者手动特征工程）新建了k个组合参数，每个参数涉及一个以上的x特征。</p>
<h4 id="deep组件">Deep组件</h4>
<p>深度组件一般是一个包含嵌入层的深度神经网络。如网络结构图所示，特征传入网络后被转换成低维高密度的实值（real-value）特征，即嵌入向量（Embedding），维度一般为10-100维，之后再逐层传入隐藏层，隐藏层计算方法如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-4328de0c0e0d9d53.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中l为层号，f为激活函数，W,b为网络参数，a为各层的入和输出（和一般神经网络无差别）。</p>
<h4 id="结合两种组件">结合两种组件</h4>
<p>文中以宽度组件和深度组件输出对数概率的加权和再传入公共的logstic函数联合训练模型。</p>
<p>需要注意的是，结合组件有两种方式联合训练（joint
train）和集成训练（ensemble）。集成训练是在训练过程中两组件相互无关，只在预测时将二者结合；而联合训练在训练时，优化误差函数，反向传播同时优化两个组件的参数。两种方法的模型大小也有区别，集成训练时，为了保证单个组件的精度，每个模型都比较大，而联合训练时宽度模型只需要弥补深度模型的弱点，构件少量的组合特征即可。</p>
<p>文中使用FTRL（Follow the regularized
leader）算法和L1正则化优化宽度模型，使用AdaGrad优化深度模型。最终组合的算法是：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-d9d7b61717dc4185.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中Y是二分类的标签，σ为sigmoid函数，φ(x)用于产生组合特征，w和b为网络参数。</p>
<h2 id="系统实现">系统实现</h2>
<p>具体实现分成：数据产生、模型训练、模型服务三部分。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-270bb439566c9265.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>数据包含用户数据和推荐数据，而标签为二值型，如用户是否安装了app。在数据产生阶段生成了词表，当字符特征出现次数足够多后，将词表可将字串映射成到整数ID。</p>
<p>模型结构如下图所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-9ef67ff9a78938ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>数据输入包含数据和词表产生的稀疏和稠密的特征以及标签。深度网络包含用户安装和推荐的app组合出的特征；深度模型将每一个类别型数据转换成32维的嵌入特征。然后将这些稠密特征连接在一起，最终组合出1200维特征。模型使用500
billion样本训练，更新模型时为缩减训练使用的时间，使用之前的模型参数初始化模型参数。最终提供的服务对每个请求能在10ms以内做出应答。</p>
<h2 id="实验结果">实验结果</h2>
<p>线上和离线的评测结果如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-95def2f242698ad2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="相关代码">相关代码：</h2>
<p>相关代码：<a
href="https://github.com/jrzaurin/pytorch-widedeep">https://github.com/jrzaurin/pytorch-widedeep</a></p>
<p>这是在github中找到的一个相对高星的项目，其实现方法也基于本篇介绍的论文。它可使用widedeep处理表格、文本数据、图像数据，基于pytorch框架实现。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-b32a17155261a822.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
]]></content>
      <tags>
        <tag>论文阅读</tag>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_神经网络知识蒸馏_DK</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F_DK/</url>
    <content><![CDATA[<p>英文题目：Distilling the Knowledge in a Neural Network<br />
中文题目：神经网络知识蒸馏<br />
论文地址：https://arxiv.org/pdf/1503.02531.pdf<br />
领域：深度学习<br />
发表时间：2015<br />
作者：Geoffrey Hinton，谷歌<br />
出处：NIPS<br />
被引量：6972<br />
阅读时间：2022.09.21</p>
<h2 id="读后感">读后感</h2>
<p>这是最早提出蒸馏模型的文章，它训练老师Teacher/学生Student两个模型，首先训练大而全的Teacher，然后用Teacher蒸馏出小而精的Student，S不仅学习T的对错判断，还学到更多细节，比如为什么错（错的离不离谱）。</p>
<h2 id="介绍">介绍</h2>
<p>作者提出训练和部署的模型<strong>未必是同一模型</strong>。大而复杂的模型效果(后简称Teacher/T)好，但相对复杂，预测时间长，占空间更大。作者提出如何把集成模型或大模型用一个小模型(后简称Student/S)实现。<strong>训练阶段产出大而全的模型，然后用蒸馏技术提炼小模型</strong>，以便部署。</p>
<p>和压缩参数相比，在输入输出之间建立新的映射可能是更好的模型瘦身方法。一般建模方法是：模型主要学习正例为什么分对，让负例概率越小越好。而实际上，负例的概率应该是有差异的。比如在<strong>识别宝马汽车时，垃圾车和胡萝卜都是负例，但垃圾车更像宝马。这一问题可能影响了模型对新数据的泛化</strong>。比如：在数据识别MNIST任务中，有时2看起来更像3，有时更像7，<strong>而像3的概率是10<sup>-6，像7的概率是10</sup>-9</strong>，差别非常微小。之前的方法是用对数修改Softmax作为损失函数，来计算小模型与大模型的误差。</p>
<p>参考：<a
href="https://zhuanlan.zhihu.com/p/105722023">一文详解Softmax函数</a></p>
<p>文中进一步提出了“蒸馏”方法，以得到更丰富的信息，通过提升Softmax的“<strong>温度</strong>”，直到产生合理的软目标。</p>
<p>小模型可以使用<strong>未标注的数据训练</strong>（大模型打标签），也可以使用训练集数据训练，实验证明，使用训练集数据，并<strong>结合软目标和实际的预测损失效果更好</strong>。</p>
<h2 id="方法">方法</h2>
<p>对于多分类问题，计算每个类的概率qi如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220912104118.png"
alt="Pasted%20image%2020220912104118.png" /><br />
其中T是温度参数，一般设成1，设成大于1时，则产生较软的概率分布。下面看看软目标与硬目标的差异：</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> softmax(x,T<span class="op">=</span><span class="dv">1</span>):  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    f_x <span class="op">=</span> np.exp(x<span class="op">/</span>T) <span class="op">/</span> np.<span class="bu">sum</span>(np.exp(x<span class="op">/</span>T), axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> f_x  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(softmax(np.array([[<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">5</span>]]), T<span class="op">=</span><span class="dv">1</span>))  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">#[[0.01321289 0.26538793 0.72139918]]  </span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(softmax(np.array([[<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">5</span>]]), T<span class="op">=</span><span class="dv">3</span>))  </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">#[[0.13312123 0.36186103 0.50501774]]  </span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(softmax(np.array([[<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">5</span>]]), T<span class="op">=</span><span class="dv">10</span>))  </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">#[[0.26030255 0.35137169 0.38832577]]  </span></span></code></pre></div>
<p>可以看到T=1时为硬目标，虽然4与5很相近，但概率差异很，调参时也将更重视最终的选择5；而T=10时，各项的得分又过于相近。</p>
<p>最终的损失函数由两部分组成，第一部分是用同样的温度训练的T模型和S模型两者间的差异；第二部分是S模型对实例真实标签的预测损失，此处的温度使用1，实验结果是对第二部分应用较低权重效果更好。</p>
<p><strong>梯度计算</strong></p>
<p>设zi是S模型结果，产生软概率qi，vi是T模型的结果，产生软概率pi，蒸馏模型的梯度计算如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220912113242.png"
alt="Pasted%20image%2020220912113242.png" /><br />
如果温度很高，根据e^x的泰勒展开，后面项忽略不计，只保留前两项，变成：<br />
<img src="/attachments_2022/Pasted%20image%2020220912122911.png"
alt="Pasted%20image%2020220912122911.png" /><br />
再假设所有样本的预测均值为0，<br />
<img src="/attachments_2022/Pasted%20image%2020220912123107.png"
alt="Pasted%20image%2020220912123107.png" /><br />
则有：<br />
<img src="/attachments_2022/Pasted%20image%2020220912123205.png"
alt="Pasted%20image%2020220912123205.png" /><br />
因此在温度T较高时，用梯度往回推损失函数就是最小化z和v的均方误差，即蒸馏的目标是让z和v尽量一致，对正负例给予相似的关注，S模型能学到更多细节。而当温度低时，则如同普通Softmax，相对不重视负例。实验表明，当S模型太小，无法捕捉到T模型的所有知识时，中等温度是一种折中。</p>
]]></content>
      <tags>
        <tag>知识蒸馏</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_胶囊网络CapsNet</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E8%83%B6%E5%9B%8A%E7%BD%91%E7%BB%9C_CapsNet/</url>
    <content><![CDATA[<h1 id="介绍">介绍</h1>
<p>英文题目：Dynamic Routing Between Capsules<br />
中文题目：胶囊之间的动态路由<br />
论文地址：https://papers.nips.cc/paper/2017/file/2cad8fa47bbef282badbb8de5374b894-Paper.pdf<br />
领域：深度学习<br />
发表时间：2017<br />
作者：Sara Sabour，Nicholas Frosst，Geoffrey E. Hinton<br />
出处：NIPS（机器学习和计算神经科学的国际会议）<br />
被引量：3466<br />
代码和数据：https://github.com/naturomics/CapsNet-Tensorflow<br />
阅读时间：22-03-29</p>
<h1 id="其它介绍">其它介绍</h1>
<p>大牛 Geoffrey E. Hinton 提出的 “胶囊网络” 到底是啥？</p>
<h1 id="精读">精读</h1>
<h2 id="摘要">1 摘要</h2>
<p>胶囊是一组神经元，其激活向量能表示特定类型的特征，比如一个对象或对象部分。文中用<strong>激活向量的长度表示存在的概率，用方向表示参数</strong>。一层激活胶囊通过变换矩阵为高层胶囊提供实例化参数。当<strong>多个低层胶囊预测一致时，高层胶囊被激活</strong>。实验部分使用MNIST数据集，证明在识别高度重叠的数字时，文中方法明显优于当时的卷积神经网络。</p>
<h2 id="介绍-1">2 介绍</h2>
<p>人类视觉通过确定的视点序列来忽略不相关的细节，以确保只以最高分辨率处理光学阵列的一小部分。在本文中，假设多层视觉系统在每个注视上创建了一个解析树状结构（<strong>不是所有都往下传，选部分往下传</strong>）。</p>
<p>解析树是从固定的多层神经网络中雕刻出来的，就像雕塑是从岩石上雕刻的一样。<strong>每一层可以分解成多个神经元组称为胶囊，解析树的每个节点都与一个激活的胶囊有关，通过迭代路由选择（路由（routing）</strong>：底层胶囊匹配高层胶囊，并将向量传递到高层胶囊的过程），<strong>每个激活的胶囊将选择其上层的一个胶囊作为其在树中的父节点</strong>，对于更高级的视频系统，迭代过程将解决将部件分配给整体的问题。</p>
<p>激活的胶囊可以表征实体的不同特性，比如位置，大小，方向，变形、速度、色调、纹理等。<strong>“是否存在”是一个特殊的特征，比较简单的方法是使用一个逻辑单元描述是否存在的概率</strong>。文中作者使用向量的模长来表征其是否存在，用向量的方向来描述其特征。使用非线性方法，保证方向不变，改变其大小的方式，将其限制在1以内。</p>
<p>胶囊的输出是向量，因此，可以<strong>使用动态路由来让胶囊的输出被发送到其上层与之匹配的父节点</strong>。将输出路由到可能父节点的概率之后归一化到1（softmax）。对于每个可能的父节点，胶囊使用它的输出和权重矩阵计算出"预测向量"，当预测向量与其可能的父节点匹配度高时，就增加其耦合系数，减少其它可能父节点的耦合系数，从而进一步增加了对其父节点输出的贡献（具体算法见第二部分）。这种通过<strong>路由选择的方式明显优于原始的最大池化方法</strong>，它允许一层的神经元忽略其下层最活跃特征以外的其它特征。</p>
<p>卷积神经网络能够将在图像中一个位置获得的权重值转换到其他位置，这对图像解析非常有帮助。为了实现这一点，文中方法使除了最后一层胶囊之外的所有胶囊都是卷积的。与CNN一样，使更高级别的胶囊覆盖图像的更大区域。而与max-pooling不同的是，不丢弃有关实体在区域内的准确位置的信息。对于低层的胶囊，采用“place-coded"，随着层次提升，更多的位置信息在胶囊的输出向量的实值分量中作为“rate-coding”。更高级别的胶囊代表着更复杂、更多自由度的实体，这表明胶囊的维度应该随着我们在层次结构中的上升而增加。</p>
<p>胶囊网络和传统神经网络相比的主要改进包括：将输出从标量变为向量，通过路由替代最大池化方法，对比如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220405203510.png"
alt="Pasted%20image%2020220405203510.png" /></p>
<h2 id="计算胶囊的输入输出">3 计算胶囊的输入输出</h2>
<p>文中提出的胶囊实现方法利用动态路由，简单直接且效果好。</p>
<p>希望用胶囊输出向量的长度来表示实体出现的概率，因此，使用非线性的激活函数squashing（压榨），来保证输出模长在0到1之间。辨别任务可以很好地利用该方法。<br />
<img src="/attachments_2022/Pasted%20image%2020220405101731.png"
alt="Pasted%20image%2020220405101731.png" /><br />
式中的vj是胶囊的输出，sj是全部输入；式中左边是模长，右边是方向。<br />
除第一层以外，sj是所有其上一层“预测向量”^uj|i的权重加和：<br />
<img src="/attachments_2022/Pasted%20image%2020220405102107.png"
alt="Pasted%20image%2020220405102107.png" /><br />
其中i指的是第l层中的胶囊，j指的是第l+1层中的胶囊。^uj|i通过l层胶囊输出ui和权重矩阵Wij计算到的；cij是<strong>耦合系数</strong>，它是在计算动态路由过程中迭代算出的。</p>
<p>耦合系数cij使用softmax计算得出，所有胶囊的cij加和为1。<br />
<img src="/attachments_2022/Pasted%20image%2020220405103521.png"
alt="Pasted%20image%2020220405103521.png" /><br />
bij是对数先验概率，它描述的是<strong>胶囊i与胶囊j的匹配关系</strong>；bij描述l层和l+1层之间胶囊i和j的相似度；b越高，c越高。</p>
<p>bij也可以和其它权重同时学习，它依赖于两个胶囊的位置和类型，而与当前输入图片无关。通过衡量当前每个胶囊输出的vj与胶囊i作出的预测^uj|i的一致性，迭代地计算耦合系数。</p>
<p><strong>一致性</strong>通过计算点积<span
class="math inline">\(a_{ij}=v_j.\hat{u}_{j|i}\)</span>得到，它被用于调整bij。两个向量点积用于描述它俩的一致性，向量越相似bij越大。</p>
<p>在卷积胶囊层中，每个胶囊层向上面层中的每一种胶囊层输出一个局部向量网格（涉及层中的多个点），该网格的每个成员以及每种胶囊层使用不同的变换矩阵。</p>
<p>路由函数计算方法如下：<br />
<img src="/attachments_2022/Pasted%20image%2020220405104106.png"
alt="Pasted%20image%2020220405104106.png" /></p>
<p>函数的输入是u，输出是v。<br />
输入参数包含l层的输出^uj|i，迭代次数r和层l；<br />
b用于描述第l层(i)和第l+1层(j)中各个胶囊的关系，将其初值设成0；<br />
进的r次迭代；<br />
使用softmax把b转换成0-1之前的c；<br />
然后利用c与l层的输出u计算出sj；<br />
sj通过激活函数squash（相当于卷积网络中的池化和激活函数）计算出该l+1层的输出vj；<br />
通过u与v的相似性迭代改进路由b；<br />
最终返回输出vj。</p>
<p>由此可见，与卷积网络提最重要差异是：<strong>它不仅计算了向下一层传的具体内容，还通过路由计算了是不是要往下传（b和c），传给谁（哪个j）</strong>。</p>
<h2 id="边际损失">4 边际损失</h2>
<p>以数字识别MNIST为例，只需要识别数字0-9，可将其看成k=10的分类问题。</p>
<p>使用实例向量的模长来表征实体（数字）存在的概率。为了识别图中可能出现的多个数字，在顶层，<strong>使用Lk分别评价每个胶囊(k)的损失</strong>。<br />
<img src="/attachments_2022/Pasted%20image%2020220405112903.png"
alt="Pasted%20image%2020220405112903.png" /><br />
当图片中存在该数字时Tk=1，m+上边界设为0.9，m-下边界设为0.1，λ用于权衡两个边界的权重，它控制无法识别该数字时的损失，以免在开始学习时胶囊的模长变得太小。文是将λ设为0.5，损失函数是所有胶囊损失的加和。</p>
<h2 id="胶囊网络结构">5 胶囊网络结构</h2>
<p><img src="/attachments_2022/Pasted%20image%2020220405113919.png"
alt="Pasted%20image%2020220405113919.png" /><br />
图-1展示了一个简单的胶囊网络结构，由两个卷积层和一个全连接层组成。Conv1是卷积核9x9的卷积层。</p>
<p>MINIST图片大小为28x28，卷积核大小为9x9，步长为1，输出为20x20的卷积结果（28-9+1-&gt;20），通道数为256，它将像素转换成局部特征，作为胶囊的输入（左图）。</p>
<p>PrimaryCapsules（中图）是低层的多维实体，它根据<strong>图像反推出物体的信息（反向渲染）</strong>。它与普通卷积把所有输出拼接在一起的方法不同，这也是胶囊的特性。</p>
<p>第二层（PrimaryCapsules）是32通道的卷积胶囊层（每个PrimaryCapsule包含8个卷积单元，9x9的卷积核，步长为2），每个PrimaryCapsule的输入是上一层Conv1输出的256x81，所有PrimaryCapsules共有32×6×6输出（(20-9+1)/2-&gt;6是卷积后的输出个数，32是通道数），注意此处输出的是向量（变标量输出为矢量输出是胶囊最重要的改进之一），每个输出是8D向量，6x6网格共享权重Wij。</p>
<p>最后一层<strong>DigitCaps</strong>（右图）对于每个数字有16D的输出。将8D转成16D，使用权重Wij。</p>
<p>模型只在第二层和第三层进行路由，第一层输出1D，因此不需要定向。所有bij初值都为0，因此，开始时输出ui对v0-v9有相等的概率。</p>
<h3 id="重建图片">5.1 重建图片</h3>
<p><img src="/attachments_2022/Pasted%20image%2020220405154125.png"
alt="Pasted%20image%2020220405154125.png" /><br />
如图-2所示，在第三层之后又加入了三个全连接层，用于重建与原始图片相同的图片，图片大小也为28x28=764。</p>
<p>使用重建后计算两图差异作为损失函数，尽量用第三层的输出还原图片。在训练过程中，我们屏蔽了除正确数字胶囊的活动向量之外的所有内容。将重建损失限制在0.0005，使它不会在训练时主导边际损失，这样做保证了模型的健壮性，并保留了图片的重要特征，重建结果如图-3所示：<br />
<img src="/attachments_2022/Pasted%20image%2020220405155004.png"
alt="Pasted%20image%2020220405155004.png" /></p>
<h2 id="胶囊网络用于mnist">6 胶囊网络用于MNIST</h2>
<p>数据集使用60K数据作为训练集，10K数据作为测试集。表-1展示了实验结果：<br />
<img src="/attachments_2022/Pasted%20image%2020220405205502.png"
alt="Pasted%20image%2020220405205502.png" /><br />
其中Baseline是三层卷积网络，参数35.4M，而CapsNet在不重建的情况下为8.2M和6.8M参数。</p>
<h3 id="胶囊的各个维度代表什么">6.1 胶囊的各个维度代表什么</h3>
<p>从图-4中可以看到，通过对输出的16个维度上扰动，展示了不同维度的捕捉的不同特征。<br />
<img src="/attachments_2022/Pasted%20image%2020220405210129.png"
alt="Pasted%20image%2020220405210129.png" /></p>
<h3 id="仿射变换的健壮性">6.2 仿射变换的健壮性</h3>
<p>实验表明，在不使用仿射变换数据训练的情况下，文中模型对加入仿射扰动的测试，准确率能达到79%，而传统模型只能达到66%。</p>
<h2 id="multimnist数据集">7 MultiMNIST数据集</h2>
<p>MultiMNIST是将MNIST数据叠加得到的数据集。训练数据大小为60M，测试数据为10M。<br />
结果如图-5所示，重建的数字分别用红色和绿色显示，其中L(l1,l2)是图中的数字，R(r1,r2)是重建的数字。图中左半边是识别正确的，右半边的识别错误的。<br />
<img src="/attachments_2022/Pasted%20image%2020220405211103.png"
alt="Pasted%20image%2020220405211103.png" /></p>
<h2 id="代码示例">8 代码示例</h2>
<h3 id="git上高星示例">8.1 git上高星示例</h3>
<p>https://github.com/laubonghaudoi/CapsNet_guide_PyTorch/blob/master/DigitCaps.py)</p>
<h3 id="主要模块">8.2 主要模块</h3>
<ul>
<li>main.py 程序入口<br />
</li>
<li>PrimaryCaps.py 第一层胶囊<br />
</li>
<li>DigitCaps.py 第二层胶囊<br />
</li>
<li>Decoder.py 胶囊后的决策层</li>
</ul>
<h2 id="参考">9 参考</h2>
<p><a
href="https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/114908500">胶囊网络全新升级！引入自注意力机制的Efficient-CapsNet</a></p>
<h2 id="引申学习">10 引申学习</h2>
<h3 id="引申一">10.1 引申一</h3>
<ul>
<li>论文题目：LEARNING TO PARSE IMAGES<br />
</li>
<li>相关概念：
<ul>
<li>可信网络（credibility networks）<br />
</li>
<li>从局部到整体，才更合理<br />
</li>
<li>对概率模型进行树状排序，局部组成整体<br />
</li>
<li>结构 256-64-4<br />
</li>
<li>其中隐藏层描述了64种潜在的分布<br />
</li>
<li>使用EM方法，是概率模型<br />
</li>
<li>解析树：类似于剪枝的筛选过程</li>
</ul></li>
</ul>
<h3 id="引申二">10.2 引申二</h3>
<ul>
<li>论文题目：TRANSFORMING AUTO-ENCODERS<br />
</li>
<li>相关概念：
<ul>
<li>提出胶囊：最终输出类似SIFT的描述<br />
</li>
<li>自编码器的变体，其中做了30个胶囊（自编码器），每个胶囊加入一些人工干预（如平移、缩放、光照等），让它学习固定的某种特征（如平移不变性）。<br />
</li>
<li>使用p来（类似gate）约束，超过一定范围后，这个胶囊就不使用了，由p值控制哪些局部信息组成整体信息<br />
</li>
<li>手动控制每个胶囊学到不同的东西 ，最终学到了视觉不变性。<br />
</li>
<li>模型泛化能力强。<br />
</li>
<li>胶囊抽取了某些部分的特征。<br />
</li>
<li>一个隐藏层的网络</li>
</ul></li>
</ul>
<figure>
<img src="/attachments_2022/Pasted%20image%2020220405173938.png"
alt="Pasted%20image%2020220405173938.png" />
<figcaption
aria-hidden="true">Pasted%20image%2020220405173938.png</figcaption>
</figure>
]]></content>
      <tags>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>语义相似度模型SBERT——一个挛生网络的优美范例</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E8%AF%AD%E4%B9%89%E7%9B%B8%E4%BC%BC%E5%BA%A6%E6%A8%A1%E5%9E%8BSBERT%E2%80%94%E2%80%94%E4%B8%80%E4%B8%AA%E6%8C%9B%E7%94%9F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BC%98%E7%BE%8E%E8%8C%83%E4%BE%8B/</url>
    <content><![CDATA[<h1 id="语义相似度模型sbert-一个挛生网络的优美范例">语义相似度模型SBERT
——一个挛生网络的优美范例</h1>
<p>#深度学习 #自然语言处理</p>
<p>论文地址：https://arxiv.org/abs/1908.10084<br />
论文中文翻译：https://www.cnblogs.com/gczr/p/12874409.html<br />
源码下载：https://github.com/UKPLab/sentence-transformers<br />
相关网站：https://www.sbert.net/</p>
<p>“论文中文翻译”已相当清楚，故本篇不再翻译，只简单介绍SBERT的原理，以及训练和使用中文相似度模型的方法和效果。</p>
<h3 id="原理">原理</h3>
<p>挛生网络Siamese
network（后简称SBERT），其中Siamese意为“连体人”，即两人共用部分器官。SBERT模型的子网络都使用BERT模型，且两个BERT模型共享参数。当对比A,B两个句子相似度时，它们分别输入BERT网络，输出是两组表征句子的向量，然后计算二者的相似度；利用该原理还可以使用向量聚类，实现无监督学习任务。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-b2a0a42ef78d44fa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>挛生网络有很多应用，比如使用图片搜索时，输入照片将其转换成一组向量，和库中的其它图片对比，找到相似度最高（距离最近）的图片；在问答场景中，找到与用户输入文字最相近的标准问题，然后给出相应解答；对各种文本标准化等等。</p>
<p>衡量语义相似度是自然语言处理中的一个重要应用，BERT源码中并未给出相应例程（run_glue.py只是在其示例框架内的简单示例），真实场景使用时需要做大量修改；而SBERT提供了现成的方法解决了相似度问题，并在速度上更有优势，直接使用更方便。</p>
<p>SBERT对Pytorch进行了封装，简单使用该工具时，不仅不需要了解太多BERT
API的细节， Pytorch相关方法也不多，下面来看看其具体用法。</p>
<h3 id="配置环境">配置环境</h3>
<p>需要注意的是机器需要能正常配置BERT运行环境，如GPU+CUDA+Pytorch+Transformer匹配版本。</p>
<pre><code>$ pip install sentence_transformers  </code></pre>
<p>下载源码</p>
<pre><code>$ git clone https://github.com/UKPLab/sentence-transformers.git  </code></pre>
<h3 id="模型预测">模型预测</h3>
<p>在未进行调优（fine-tune）前，使用预训练的通用中文BERT模型也可以达到一定效果，下例是从几个选项中找到与目标最相近的字符串。</p>
<pre><code>from sentence_transformers import SentenceTransformer  
import scipy.spatial  
  
embedder = SentenceTransformer(&#39;bert-base-chinese&#39;)  
corpus = [&#39;这是一支铅笔&#39;,  
  &#39;关节置换术&#39;,  
  &#39;我爱北京天安门&#39;,  
]  
corpus_embeddings = embedder.encode(corpus)  
# 待查询的句子  
queries = [&#39;心脏手术&#39;,&#39;中国首都在哪里&#39;]  
query_embeddings = embedder.encode(queries)  
# 对于每个句子，使用余弦相似度查询最接近的n个句子  
closest_n = 2  
for query, query_embedding in zip(queries, query_embeddings):  
  distances = scipy.spatial.distance.cdist([query_embedding], corpus_embeddings, &quot;cosine&quot;)[0]  
  # 按照距离逆序  
  results = zip(range(len(distances)), distances)  
  results = sorted(results, key=lambda x: x[1])  
  print(&quot;======================&quot;)  
  print(&quot;Query:&quot;, query)  
  print(&quot;Result:Top 5 most similar sentences in corpus:&quot;)  
  for idx, distance in results[0:closest_n]:  
    print(corpus[idx].strip(), &quot;(Score: %.4f)&quot; % (1-distance))  </code></pre>
<h3 id="训练中文模型">训练中文模型</h3>
<p><strong>模型训练方法</strong></p>
<p>训练原理：https://www.sbert.net/docs/training/overview.html<br />
训练示例说明：https://www.sbert.net/examples/training/sts/README.html<br />
训练示例代码：examples/training/sts/training_stsbenchmark.py</p>
<p><strong>训练中文模型</strong></p>
<p>把示例中的bert-base-cased换成bert-base-chinese，即可下载和使用中文模型。需要注意的是：中文和英文词库不同，不能将中文模型用于英文数据训练。</p>
<p><strong>下载中文训练数据</strong></p>
<p>下载信贷相关数据，csv数据7M多，约10W条训练数据，可在下例中使用</p>
<pre><code>$ git clone https://github.com/lixuanhng/NLP_related_projects.git  
$ ls NLP_related_projects/BERT/Bert_sim/data  </code></pre>
<p><strong>代码</strong></p>
<pre><code>from torch.utils.data import DataLoader  
import math  
from sentence_transformers import SentenceTransformer, LoggingHandler, losses, models, util  
from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator  
from sentence_transformers.readers import InputExample  
import logging  
from datetime import datetime  
import sys  
import os  
import pandas as pd  
  
model_name = &#39;bert-base-chinese&#39;  
train_batch_size = 16  
num_epochs = 4  
model_save_path = &#39;test_output&#39;  
logging.basicConfig(format=&#39;%(asctime)s - %(message)s&#39;,  
  datefmt=&#39;%Y-%m-%d %H:%M:%S&#39;,  
  level=logging.INFO,  
  handlers=[LoggingHandler()])  
  
# Use Huggingface/transformers model (like BERT, RoBERTa, XLNet, XLM-R) for mapping tokens to embeddings  
word_embedding_model = models.Transformer(model_name)  
  
# Apply mean pooling to get one fixed sized sentence vector  
pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),  
  pooling_mode_mean_tokens=True,  
  pooling_mode_cls_token=False,  
  pooling_mode_max_tokens=False)  
  
model = SentenceTransformer(modules=[word_embedding_model, pooling_model])  
train_samples = []  
dev_samples = []  
test_samples = []  
  
def load(path):  
  df = pd.read_csv(path)  
  samples = []  
  for idx,item in df.iterrows():  
    samples.append(InputExample(texts=[item[&#39;sentence1&#39;], item[&#39;sentence2&#39;]], label=float(item[&#39;label&#39;])))  
  return samples  
  
train_samples = load(&#39;/workspace/exports/git/NLP_related_projects/BERT/Bert_sim/data/train.csv&#39;)  
test_samples = load(&#39;/workspace/exports/git/NLP_related_projects/BERT/Bert_sim/data/test.csv&#39;)  
dev_samples = load(&#39;/workspace/exports/git/NLP_related_projects/BERT/Bert_sim/data/dev.csv&#39;)  
  
train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)  
train_loss = losses.CosineSimilarityLoss(model=model)  
evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name=&#39;sts-dev&#39;)  
warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up  
  
# Train the model  
model.fit(train_objectives=[(train_dataloader, train_loss)],  
  evaluator=evaluator,  
  epochs=num_epochs,  
  evaluation_steps=1000,  
  warmup_steps=warmup_steps,  
  output_path=model_save_path)  
  
model = SentenceTransformer(model_save_path)  
test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name=&#39;sts-test&#39;)  
test_evaluator(model, output_path=model_save_path)  </code></pre>
<p><strong>测试结果</strong></p>
<ul>
<li>直接使用预训练的英文模型，测试集正确率21%<br />
</li>
<li>直接使用预训练的中文模型，测试集正确率30%<br />
</li>
<li>使用1000个用例的训练集，4次迭代，测试集正确率51%<br />
</li>
<li>使用10000个用例的训练集，4次迭代，测试集正确率68%<br />
</li>
<li>使用100000个用例的训练集，4次迭代，测试集正确率71%</li>
</ul>
<p><strong>一些技巧</strong></p>
<p>除了设置超参数以外，也可通过构造训练数据来优化SBERT网络，比如：构造正例时，把知识“喂”给模型，如将英文缩写与对应中文作为正例对训练模型；构造反例时用容易混淆的句子对训练模型（文字相似但含义不同的句子；之前预测出错的实例，分析其原因，从而构造反例；使用知识构造容易出错的句子对），以替代之前的随机抽取反例。</p>
<h3 id="参考">参考</h3>
<ul>
<li>BERT中文实战（文本相似度） <a
href="https://blog.csdn.net/weixin_37947156/article/details/84877254">https://blog.csdn.net/weixin_37947156/article/details/84877254</a><br />
</li>
<li>Bert 文本相似度实战（使用详解） <a
href="https://zhuanlan.zhihu.com/p/367726571">https://zhuanlan.zhihu.com/p/367726571</a><br />
</li>
<li>Sentence-BERT: 一种能快速计算句子相似度的孪生网络 <a
href="https://www.cnblogs.com/gczr/p/12874409.html">https://www.cnblogs.com/gczr/p/12874409.html</a><br />
</li>
<li>Sentence-Bert论文笔记 <a
href="https://zhuanlan.zhihu.com/p/113133510?from_voters_page=true">https://zhuanlan.zhihu.com/p/113133510?from_voters_page=true</a></li>
</ul>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>轻量级BERT模型ALBERT</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E8%BD%BB%E9%87%8F%E7%BA%A7BERT%E6%A8%A1%E5%9E%8BALBERT/</url>
    <content><![CDATA[<h1 id="轻量级bert模型albert">轻量级BERT模型ALBERT</h1>
<p>#自然语言处理</p>
<p>BERT有很多改进版本，ALBERT是一个轻量化版本。ALBERT源自2020年的发表论文《ALBERT:
A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE
REPRESENTATIONS》，论文地址：<a
href="https://arxiv.org/pdf/1909.11942.pdf">https://arxiv.org/pdf/1909.11942.pdf</a>。从题目可以看出，论文重点是轻量化BERT模型，以及优化了半监督学习，本文主要关注轻量化模型部分。</p>
<p>目前NLP的高级模型BERT、GPT-2都基于Pretrain/fine-tune模式，先使用无监督学习的海量文本预训练出一个带有“语言常识”的大模型，然后再根据具体任务调优，这就完美解决了具体任务训练集不足的问题。模型往往拥有千万或亿级的参数，目前的趋势是随着模型功能能越来越强大，模型的规模也越来越大，这使普通开发者越发无法企及。</p>
<p>随着BERT模型越来越频繁地被使用到真实场景中，模型的速度、规模、硬件逐渐成为瓶颈。预训练模型一般都规模庞大，在后期调优以及调用模型时也都需要花费大量的内存、算力和时间。ALBERT在基本保证模型质量的前提下把模型缩小到BERT-LARGE的1/18（18M/334M），训练提速1.7倍。</p>
<h3 id="原理">原理</h3>
<p>ALBERT全称是 A Lite
BERT，轻量级的BERT，它使用了两种技术来简化参数：</p>
<p><strong>分解了词嵌入（Embedding）参数</strong></p>
<p>从原理来看，词嵌入表示的是词含义与上下文无关，而隐藏层表示的是词之间的组合含义，句子越长它的信息量越丰富，后者更加复杂，也需要更多参数。如果词表V非常大（词多），需要V×E空间存储参数，如果保持词嵌入层大小E与隐藏词H的大小一致，当H变大时，VxE也跟着迅速变大。因此，论文作者将原来词嵌入层大小恒等于隐藏层大小：E≡H，改为：H&gt;&gt;E。这样就减少了参数，也可以支持未来使用更大的词表，比如对中文来说，词为单位比以字为单位效果更佳，但词量又比较大。
当前BERT、GPT-2模型的隐藏层大小动辄512、768维，而腾讯词向量200维就可以很好地描述800多万词条的词性。因此，论文作者将词过嵌入过程从原来的V-&gt;H分解成：先把词V映射到E（V-&gt;E），再由E映射到H（E-&gt;H），使其复杂度从O(V×H)降到了O(V×E+E×H)，当E比H小很多时其优势尤为明显。</p>
<p><strong>共享了交叉层（cross-layer）参数</strong></p>
<p>ALBERT与BERT原理一样，都沿用了Transformer模型的方案，堆叠了多个Encoder层，BERT标准版12层，BERT-LARGE版24层来说。ALBERT共享了所有层的参数，使参数数据大幅减少。
论文作者对比了LARGE模型24层，每一层的输入与输出的L2距离以及cosine相似性，如下图所示。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-6cfd7b25d2fe679c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>可以看到，共享了参数之后ALBERT比BERT表现更加平滑稳定，
笔者个人认为：多层共享参数方法有点像RNN，BERT中每一层（layer）提取出不同层次的关系（有的在词法层，有的在词义层），由于参数足够多，存储在参数矩阵中的有效信息可能是稀疏的，因此将多层参数存储在一起，并没有产生严重的互相影响。</p>
<p>除了简化参数，ALBERT还在Next-sentence prediction
(NSP)方面对BERT做了一些训练方法上的优化，不是本篇重点，有兴趣的读者请直接查看论文。
效果</p>
<p>下面列出了ALBERT与BERT的对比效果，最后两列分别是二者在多者任务中的平均分和速度对比。可以看到，其模型参数显著减少，而计算提度相对没有那么明显，这是由于模型由于共享了参数，而层数和对应层的计算量没变，只减小了Embedding的计算量。也可以从表中看到，简化后模型效果相对于BERT变化不大。文中还针对不同的共享方法，以及不同Embedding大小提供了大量实验数据，详见论文。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-0f8437e89b650bc9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="代码">代码</h3>
<p>TensorFlow实现（官方源码）：<br />
<a
href="https://github.com/google-research/ALBERT">https://github.com/google-research/ALBERT</a></p>
<p>Pytorch实现（2.3.0以上版本支持ALBERT）：<br />
<a
href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a></p>
<p>中文版TensorFlow：<br />
<a
href="https://github.com/brightmart/albert_zh">https://github.com/brightmart/albert_zh</a></p>
<p>中文模型：<br />
<a
href="https://storage.googleapis.com/albert_models/albert_base_zh.tar.gz">https://storage.googleapis.com/albert_models/albert_base_zh.tar.gz</a></p>
<p>ALBERT用法与BERT基本一致。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>迁移学习之_猫狗大战</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E4%B9%8B_%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98/</url>
    <content><![CDATA[<h1 id="迁移学习之_猫狗大战">迁移学习之_猫狗大战</h1>
<p>#图形图像 #算法实战</p>
<h3 id="迁移学习">1. 迁移学习</h3>
<p> 迁移学习（transfer
learning）是指将已经学习的知识应用到其它领域，在图像识别问题中，是将训练好的模型通过简单调整来解决新的问题。从图像中提取特征，不一定需要算力强大的GPU，训练上百层的神经网络。</p>
<p> 卷积神经网络中卷积层和池化层可以抽取图片的几何特征，比如浅层的卷积用于抽取出一些直线，角点等简单的抽象信息，深层的卷积层用于抽取人脸等复杂的抽象信息，最后的全连接层是对图片分类的处理。因此，我们可以使用网络的前N-1层提取特征。</p>
<p> 例如，利用在ImageNet数据集上训练好的 ResNet50
模型来解决一个自定义的图像分类问题：保留训练好的 ResNet50
模型中卷积层的参数，只去掉最后一个全连接层，将新图像输入训练好的神经网络，利用前N-1层的输出作为图片的特征，将
ResNet50
模型作为图片特征提取器，提取得到的特征向量作为输入训练新的单层全连接网络来处理新的分类问题，或者将这些特征代入SVM，LR等其它机器学习模型进行训练和预测。</p>
<p> 在数据量足够的情况下，迁移学习的效果往往不如完全重新训练，但是迁移学习所需要的训练时间和训练样本要远远小于训练完整的模型。大多数情况下，更加实用。</p>
<h3 id="比赛介绍">2. 比赛介绍</h3>
<p> 猫狗大战是2013年Kaggle上的比赛，它使用25000张（约543M）猫狗图片作为训练集，12500张(约271M)图片作为测试集，数据都是分辨率400x400左右的小图片，目标是识别测试集中的图片是猫还是狗。赛题网址：https://www.kaggle.com/c/dogs-vs-cats。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-df7411e282107fc7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 对于图像识别，在数据量足量大的情况下，一般使用深度学习中的卷积神经网络（Convolutional
Neural Networks,
CNN），而本篇将从迁移学习的角度，看看如何应用现有的深度学习模型，从图片中提取特征，供分类器使用。使用此方法，即无需大量学习和训练模型的时间成本，又能解决图片识别相关的大多数问题。</p>
<h3 id="代码分析">3. 代码分析</h3>
<p><strong>(1) 数据及代码位置</strong></p>
<p> 数据及代码位置如下：cat_vs_dog.ipynb 中存放了所有代码，
train目录中存放所有训练数据，注意将猫和狗的图片分开目录存放，test目录存放测试数据。</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>├── cat_vs_dog.ipynb  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>├── README.md  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>├── test  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>│ └── test1  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>│ ├── <span class="ot">1.j</span><span class="er">pg</span>  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>│ ├── <span class="ot">2.j</span><span class="er">pg</span>  </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>│ └── …  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>└── train  </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  ├── cat  </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  ├── cat<span class="fl">.1</span>.jpg  </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  ├── cat<span class="fl">.2</span>.jpg  </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  └── …  </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  └── dog ├── dog<span class="fl">.1</span>.jpg  </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  ├── dog<span class="fl">.2</span>.jpg  </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  └── …  </span></code></pre></div>
<p><strong>(2) 提取特征</strong></p>
<p> 本例中使用了InceptionV3，Xception，ResNet50三种模型，分别提取图片特征，H5是一种文件存储格式，使用库h5py库存取。</p>
<pre><code>from keras.models import *  
from keras.layers import *  
from keras.applications import *  
from keras.preprocessing.image import *  
import h5py  
import warnings  
warnings.filterwarnings(&#39;ignore&#39;)  
  
def get_features(MODEL, width, height, lambda_func=None):  
 input_tensor = Input((height, width, 3))  
 x = input_tensor  
 if lambda_func:  
  
 x = Lambda(lambda_func)(x)  
 base_model = MODEL(input_tensor=x, weights=&#39;imagenet&#39;, include_top=False)  
 model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))  
 gen = ImageDataGenerator()  
  
 # 注意 train 和 test 是图片存储路径  
 train_generator = gen.flow_from_directory(&quot;train&quot;, (width, height), shuffle=False,  
 batch_size=16)  
 test_generator = gen.flow_from_directory(&quot;test&quot;, (width, height), shuffle=False,  
 batch_size=16, class_mode=None)  
 train = model.predict_generator(train_generator, train_generator.nb_sample)  
 test = model.predict_generator(test_generator, test_generator.nb_sample)  
 with h5py.File(&quot;data_%s.h5&quot;%MODEL.func_name) as h:  
 h.create_dataset(&quot;train&quot;, data=train)  
 h.create_dataset(&quot;test&quot;, data=test)  
 h.create_dataset(&quot;label&quot;, data=train_generator.classes)  
  
get_features(ResNet50, 224, 224)  
get_features(InceptionV3, 299, 299, inception_v3.preprocess_input)  
get_features(Xception, 299, 299, xception.preprocess_input)  </code></pre>
<p><strong>(3) 训练模型和预测</strong></p>
<p> 特征提取完成后，训练了简单的全连接神经网络，迭代次数为8次，并对测试集test进行预测，预测结果保存在y_pred之中，训练过程保存在history之后，此后分析其迭代效果。</p>
<pre><code>import h5py  
import numpy as np  
from sklearn.utils import shuffle  
from keras.models import *  
from keras.layers import *  
  
np.random.seed(12345678)  
X_train = []  
X_test = []  
  
for filename in [&quot;data_ResNet50.h5&quot;, &quot;data_Xception.h5&quot;, &quot;data_InceptionV3.h5&quot;]:  
 with h5py.File(filename, &#39;r&#39;) as h:  
 X_train.append(np.array(h[&#39;train&#39;]))  
 X_test.append(np.array(h[&#39;test&#39;]))  
 y_train = np.array(h[&#39;label&#39;])  
  
X_train = np.concatenate(X_train, axis=1)  
X_test = np.concatenate(X_test, axis=1)  
X_train, y_train = shuffle(X_train, y_train)  
input_tensor = Input(X_train.shape[1:])  
x = Dropout(0.5)(input_tensor)  
x = Dense(1, activation=&#39;sigmoid&#39;)(x)  
model = Model(input_tensor, x)  
model.compile(optimizer=&#39;adadelta&#39;,  
 loss=&#39;binary_crossentropy&#39;,  
 metrics=[&#39;accuracy&#39;])  
  
history = model.fit(X_train, y_train, batch_size=128, nb_epoch=8, validation_split=0.2)  
y_pred = model.predict(X_test, verbose=1)  
y_pred = y_pred.clip(min=0.005, max=0.995)  </code></pre>
<p><strong>(4) 训练结果分析</strong></p>
<pre><code>import matplotlib.pyplot as plt  
%matplotlib inline  
  
def plot_training(history):  
 acc = history.history[&#39;acc&#39;]  
 val_acc = history.history[&#39;val_acc&#39;]  
 epochs = range(len(acc))  
 plt.plot(epochs, acc, &#39;b&#39;)  
 plt.plot(epochs, val_acc, &#39;r&#39;)  
 plt.legend([&quot;acc&quot;, &quot;val_acc&quot;], loc=&#39;best&#39;)  
 plt.title(&#39;Training and validation accuracy&#39;)  
 plt.show()  
  
 loss = history.history[&#39;loss&#39;]  
 val_loss = history.history[&#39;val_loss&#39;]  
 plt.plot(epochs, loss, &#39;b&#39;)  
 plt.plot(epochs, val_loss, &#39;r&#39;)  
  
 plt.legend([&quot;loss&quot;, &quot;val_loss&quot;], loc=&#39;best&#39;)  
 plt.title(&#39;Training and validation loss&#39;)  
 plt.show()  
  
plot_training(history)  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-b40451638b97a71a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 使用matplotlib库，分别对8次迭代的准确率作图比较，从结果可以看出迭代两次之后，精确率就稳定下来。本例中使用了全部图片25000张训练模型，正确率相对较高。</p>
<p><strong>(5) 代码下载</strong></p>
<p> 本例中的代码以及少量图片可从git下载：https://github.com/xieyan0811/cat_vs_dog
由于整体图片有几百M，占空间大，特征提取时间长，所以只上传了几百张图片，如果想训练出上图展示的效果，请下载kaggle赛题中的所有数据，替换train和test目录即可，注意，需要把猫和猫的图片存放不同目录下。</p>
]]></content>
      <tags>
        <tag>图形图像</tag>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>风格迁移</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/</url>
    <content><![CDATA[<h1 id="风格迁移">风格迁移</h1>
<p>#深度学习</p>
<p>风格迁移应用非常有趣，通过风格迁移也可以看到深层网络如何在不同层次提取特征。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-6ccba11c8eb8d9d2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-62f8239ae4697e52.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>可以看到，不只是颜色发生了变化，边缘，色块，对比度，甚至是笔触­都转换成了明显的绘画效果．</p>
<p>《吴恩达深度学习》第四课第四周练习是一段风格迁移程序填空，编程语言为Keras，做完后感觉理解了细节的具体实现，但整体搭建框架和数据流向还比较糊涂。于是使用Pytorch又实现了一遍。下面列出此过程中的一些收获。</p>
<ul>
<li><p>如何使用预训练模型生成图片
例程中涉及三张图片，一张提供内容Ｃ，一张提供风格Ｇ，目标是生成新图片Ｎ，新图片可以从白噪声开始，也可以与内容图片一致。
与对抗生成网络不同的是，风格迁移并不使用从小图逐渐放大的方法生成数据，而是将图Ｎ的Tensor设置成requires_grad=True，然后通过梯度调整图片内容，类似于梯度攻击中生成对模型更有攻击性的数据。</p></li>
<li><p>如何结合风格和内容
误差函数由两部分组成，一部分是C内容与N内容的差异，另一部分是G风格与N风格的差异，内容差异比较简单，只需要计算某一层两图输出的距离即可。
风格被定义为，同一层各个通道之间的关系，比如在CNN第四层输出128个通道，计算各个通道间数据的相关性，若通道A和通道B相关性高被认为是某种风格，从而判断两张图片风格是否一致。
每一层的输出都可以用来评价风格和内容是否一致，并根据其差异调整图片，使其向更加一致的方向变化。</p></li>
</ul>
<p><strong>参考</strong></p>
<ul>
<li>使用 PyTorch 进行 风格迁移 <a
href="https://blog.csdn.net/fendouaini/article/details/101185963">https://blog.csdn.net/fendouaini/article/details/101185963</a><br />
</li>
<li>《深度学习》教程习题（Keras实现） <a
href="https://github.com/Wasim37/deeplearning-assignment">https://github.com/Wasim37/deeplearning-assignment</a></li>
</ul>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu重启后找不到gpudriver</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%8E%AF%E5%A2%83/ubuntu%E9%87%8D%E5%90%AF%E5%90%8E%E6%89%BE%E4%B8%8D%E5%88%B0gpudriver/</url>
    <content><![CDATA[<h1 id="ubuntu重启后找不到gpu-driver">ubuntu重启后找不到gpu driver</h1>
<p>#深度学习</p>
<p>使用nvidia-smi提示（此时X-window也无法正常启动，只能显示输密码界面）：</p>
<p>NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA
driver.<br />
Make sure that the latest NVIDIA driver is installed and running.</p>
<p>用以下命令自动重装驱动：</p>
<p>$ sudo ubuntu-drivers autoinstall</p>
<p>此时可正常使用nvidia-smi，启动gpu docker时又报错。</p>
<p>用以下命令查看驱动情况：</p>
<p>$ nvidia-container-cli -k -d /dev/tty info</p>
<p>也报错。分析发现系统自动安装的driver是430版本（之前好像安装过440或450，重启后不能正常使用）。</p>
<p>因此，用以下命令安装430配套的libcuda1：</p>
<p>$ sudo apt-get install libcuda1-430</p>
<p>安装后docker也可正常使用了。</p>
<h2 id="问题与解决">问题与解决</h2>
<ul>
<li>docker里找不到nvidia-smi<br />
在启动docker时加入：--gpus all</li>
</ul>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>搭建深度学习的docker环境</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%8E%AF%E5%A2%83/%E6%90%AD%E5%BB%BA%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84docker%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h1 id="搭建深度学习的docker环境">搭建深度学习的docker环境</h1>
<p>#Docker #深度学习</p>
<h3 id="介绍">介绍</h3>
<p>深度学习一般依赖比较复杂的环境，每个项目需要的底层库各有不同，有时在github中下载的代码只能运行在版本较低的的工具链之上。想在一台机器上建立适合所有项目的环境非常困难，大多数情况下使用docker维护不同项目针对的不同环境。</p>
<p>CUDA是NVIDIA推出的运算平台，一般通过它调用GPU，CUDA的主要版本有7.x,
8.x,9.x,10.x，目前最常用的是9和10，它们对接的上层软件版本也各不相同。如：</p>
<pre><code>torch 1.1.0/1.1.0 + torchvision 0.2.* + CUDA 9  
torch 1.2.0/1.3.0 + torchvision 0.3.* + CUDA 10  
torch 1.2.0/1.3.0 + torchvision 0.4.* + CUDA 10  
torch 1.4.0 + torchvision 0.5.* + CUDA 10  </code></pre>
<p>除了CUDA基础库以外，还需安装相关工具包。可以在同一个操作系统中安装多个CUDA版本，使用时切换即可。</p>
<p>在Docker中使用GPU除了在Docker内部安装CUDA及相关工具以外，还需要使用nvidia-docker启动镜像，并且要在宿主机上安装CUDA的底层支持（注意版本兼容）。</p>
<p>###宿主机安装Nvidia驱动</p>
<pre><code>$ sudo add-apt-repository ppa:graphics-drivers/ppa  
$ sudo apt-get update  
$ sudo ubuntu-drivers devices # 查看当前显卡及推荐的驱动  
$ sudo apt-get install nvidia-driver-435 # 选择其中一个推荐安装，尽量安装较高版本  
$ sudo apt install nvidia-utils-435 # nvidia-smi支持（查看显卡信息）  
$ sudo apt install nvidia-cuda-toolkit # nvcc支持（nv环境下的C语言编译器，注意：这个包比较大，一般在docker里使用，在宿主机不一定非要安装）  
$ sudo reboot  </code></pre>
<p>(后来再安装的时候，有时nvidia-cuda-toolkit和nvidia-utils-435冲突)<br />
重启之后，使用nvidia-smi命令即可看到机器上的显卡及当前使用情况：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-1e7290af94368fc2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="安装支持cuda的docker工具">安装支持CUDA的Docker工具</h3>
<p>安装Docker</p>
<pre><code># 安装系统工具  
$ sudo apt-get update  
$ sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common  
# 安装GPG证书  
$ curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -  
# 写入软件源信息  
$ sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu (lsb_release -cs) stable&quot;   
# 着情修改, 具体形如  
$ sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu jammy stable&quot;  
# 更新并安装 Docker-CE  
$ sudo apt-get -y update  
$ sudo apt-get -y install docker-ce  </code></pre>
<p>安装Nvidia-docker2</p>
<pre><code>$ curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | \  
 sudo apt-key add -  
$ distribution=$(. /etc/os-release;echo $ID$VERSION_ID)  
$ curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \  
 sudo tee /etc/apt/sources.list.d/nvidia-docker.list  
$ sudo apt-get update  
$ sudo apt-get install -y nvidia-docker2  
$ sudo pkill -SIGHUP dockerd  
$ sudo docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi # 测试  </code></pre>
<p>测试时自动从网上下载镜像nvidia/cuda，该镜像大小为2.83G，只包含基本的9.1版本的CUDA环境，不含Python相关工具。</p>
<p>###推荐Docker镜像</p>
<p>目前最常用的是CUDA 9.x和CUDA 10.x，推荐下面两个镜像。 下载方法：</p>
<pre><code>$ docker pull registry.cn-shanghai.aliyuncs.com/tcc-public/pytorch:1.1.0-cuda10.0-py3  
$ docker pull registry.cn-shanghai.aliyuncs.com/tcc-public/pytorch:latest-cuda9.0-py3   </code></pre>
<p>运行方法：</p>
<pre><code>$ nvidia-docker run --rm -it registry.cn-shanghai.aliyuncs.com/tcc-public/pytorch:latest-cuda9.0-py3 bash  </code></pre>
<p>它们的大小分别是4.17G和3.56G，以cuda-10.0版本为例，其内部为Ubuntu
16.04系统，可使用apt-get安装软件，其Python版本为3.6.5。pytorch版本为1.0.0。</p>
<h3 id="在docker中使用jupyter开发">在Docker中使用Jupyter开发</h3>
<p>在pytorch:1.1.0-cuda10.0-py3的基础上安装jupyter开发环境：<br />
在当前目录下创建Dockerfile，内容如下：</p>
<pre><code>FROM registry.cn-shanghai.aliyuncs.com/tcc-public/pytorch:1.1.0-cuda10.0-py3  
ADD . /  
RUN mkdir ~/.pip \  
 &amp;&amp; echo &quot;[global]\nindex-url = https://mirrors.aliyun.com/pypi/simple/&quot; &gt; ~/.pip/pip.conf  
RUN sed -i s@/archive.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.list  
RUN apt-get clean  
RUN apt-get update -y  
RUN pip install jupyter  
  
ENV PASSWORD=123456  
ENV CONFIG_PATH=&quot;/root/.jupyter/jupyter_notebook_config.py&quot;  
COPY &quot;jupyter_notebook_config.py&quot; $&#123;CONFIG_PATH&#125;  
WORKDIR /notebooks/  
#CMD [&quot;sh&quot;, &quot;run.sh&quot;]  </code></pre>
<p>在当前目录下创建jupyter配置文件jupyter_notebook_config.py，用于设置密码：</p>
<pre><code>import os  
from IPython.lib import passwd  
# c = c # pylint:disable=undefined-variable  
c = get_config()  
c.NotebookApp.ip = &#39;0.0.0.0&#39;  
c.NotebookApp.port = int(os.getenv(&#39;PORT&#39;, 8888))  
c.NotebookApp.open_browser = False  
# sets a password if PASSWORD is set in the environment  
if &#39;PASSWORD&#39; in os.environ:  
    password = os.environ[&#39;PASSWORD&#39;]  
    if password:  
        c.NotebookApp.password = passwd(password)  
    else:  
        c.NotebookApp.password = &#39;&#39;  
        c.NotebookApp.token = &#39;&#39;  
del os.environ[&#39;PASSWORD&#39;]  </code></pre>
<p>创建名为test:0.1的Docker镜像：</p>
<pre><code>$ sudo docker build . -t test:0.1  </code></pre>
<p>启动方法</p>
<pre><code>$ sudo nvidia-docker run --rm -v 宿主机目录:docker内部目录 -p 8891:8888 -it test:0.1 jupyter notebook --allow-root -y --no-browser --ip=0.0.0.0 --config=/root/.jupyter/jupyter_notebook_config.py  </code></pre>
<p>此时，用网络上任意一台机器可以访问docker启动的jupyter环境：http://宿主机IP地址:8891</p>
<h3 id="天池竞赛上传镜像">天池竞赛上传镜像</h3>
<p>下面为参加阿里天池大数据比赛时上传镜像的方法：</p>
<p>登录阿里云：<a
href="https://www.aliyun.com/product/acr">https://www.aliyun.com/product/acr</a>?<br />
进镜像仓库：<a
href="https://cr.console.aliyun.com/cn-shanghai/instances/repositories">https://cr.console.aliyun.com/cn-shanghai/instances/repositories</a><br />
具体流程见： <a
href="https://tianchi.aliyun.com/competition/entrance/231759/tab/174?spm=5176.12586973.0.0.547d780b0Cgnoh">https://tianchi.aliyun.com/competition/entrance/231759/tab/174?spm=5176.12586973.0.0.547d780b0Cgnoh</a><br />
创建一个镜像仓库，复制其公网地址。</p>
<p>在本地登录</p>
<pre><code>$ sudo docker login --username=您的用户名 registry.cn-shenzhen.aliyuncs.com  </code></pre>
<p>上传镜像</p>
<pre><code>$ sudo docker tag test:0.1 公网地址  
$ sudo docker push 公网地址  </code></pre>
<h3 id="问题及解决">问题及解决</h3>
<p><strong>问题一：安装证书报错</strong></p>
<p>问题：运行
<code>$ sudo add-apt-repository ppa:graphics-drivers/ppa</code>，报错：
Cannot add PPA: 'ppa:~graphics-drive/ubuntu/ppa'.
ERROR:'~graphics-drive' user or team does not exist.<br />
解决：CA证书损坏，可以通过命令 sudo apt-get install --reinstall
ca-certificates修复。</p>
<p><strong>问题二：显卡支持问题</strong></p>
<p>问题：查看NVIDIA驱动版本：
<code>$ sudo dpkg --list | grep nvidia-*</code> 时没有显示</p>
<p>解决：查看GPU型号：<code>$ lspci| grep -i nvidia</code>自动安装驱动：<code>$ sudo ubuntu-drivers autoinstall</code></p>
<p>（感谢sfthejia@buu.edu.cn反馈的问题及解决方法）</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习_工具</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%8E%AF%E5%A2%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<h1 id="深度学习_工具">深度学习_工具</h1>
<p>#深度学习</p>
<h2 id="引入">1. 引入</h2>
<p>深度学习的工具有很多Tensorflow, Theano, Caffe, Keras, MXNet,
Scikit-learn…有用c++写的，有用Python写的，还有Ｒ的，Java的，从哪里入手呢？<br />
先看看最热门的Tensorflow，它是谷歌研发的人工智能学习系统，主要优点是分布式计算，特别是在多GPU的环境中。Theano也是比较低级的库，一般单机使用．什么是低级库？就像炒回锅肉不用从杀猪开始，杀猪就是比较低级的工作，已经有人帮你做好了，像Keras这种较上层的工具，它把
Theano和TensorFlow包装成了更具人性化的API。至于是选择低级工具，还是上层工具，主要取决于您的目标是开肉联厂还是开饭馆．</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-fd6283f7184c6a7b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<h2 id="工具简介">2. 工具简介</h2>
<p>Caffe是c++写的库，是较低层级的库，它是个老牌的工具，工作稳定，性能也好，还提供绑定到Python上的编程语言，但相对没有Python类工具灵活．<br />
Theano是一个低级库，透明地使用GPU来完成数学计算．也是一个老牌的工具，工作比较稳定，只支持单机，可供Keras调用．<br />
TensorFlow也是个低级的库，由Google发布，其的主要优点是分布式计算，特别是在多GPU的环境中，可供Keras调用．<br />
CNTK也是个低级的库，微软发布，可供Keras调用．<br />
MXNet还是一个低级库，由C++实现的，同时提供了python,lua,R,和js等多种语言接口，优点是分布式计算，它支持多个CPU
/ GPU分配训练网络，可供Keras调用．<br />
Keras用得比较多，它把
Theano，TensorFlow，MXNet，CNTK包装成了更具人性化的API（低级的库想做完整的解决方案，还是要自己写很多代码），可供快速入门，但速度相对慢一些，在设计复杂算法时，也相对受限．<br />
Lasagne是基于Theano的，用于构建和训练网络的轻量级库。Lasagne的功能是Theano的低级编程和Keras的高级抽象之间的一个折中。<br />
NoLearn把Lasagne封装成了更具人性化的API（就如同Keras把
Theano和TensorFlow封装一样），此外，NoLearn中所有的代码都是与scikit-learn兼容的．<br />
Scikit-learn是Python中常用的机器学习库，除了深度学习也提供很多浅层模型，深度学习不是它的重点．<br />
Torch是由lua语言编写的深度学习库．<br />
这里所谓的高级／低级都是相对而言的，高级只是相对简单一些．在算法的使用层面，对上层调用比较多，但会牺牲一些效率，限制也比较多．在算法改进层面，更多用到低级库．<br />
接口怎么调都不过都是调库而已．关键还是看如何设计神经网络的结构，以及它背后的数学原理，所以说深度学习主要比拼的还是＂内功＂．</p>
<h2 id="工具选择">3. 工具选择</h2>
<p>上述工具很多是Python写的，或者有Python的接口，建议在Python层面调用．<br />
作为入门，建议选择Keras，基于以下原因：代码简单，资料多，可将Theano，Tensorflow等作为后端（只要安装好后端工具，就可以使用它了，无需了解具体用法；有一定扩展性（可用theano或tensorflow的语句来写扩展功能并和keras结合使用）．最主要的还是容易上手．</p>
<h2 id="kerastheanotensorflow简单安装">4.
Keras&amp;Theano&amp;Tensorflow简单安装</h2>
<h4 id="安装软件">1) 安装软件</h4>
<p>以下为最简单地安装方法，此文及下文中环境默认为ubuntu</p>
<pre><code>$ sudo pip install tensorflow  
$ sudo pip install theano  
$ sudo pip install keras  </code></pre>
<h4 id="安装例程">2) 安装例程</h4>
<p>学习keras最好从它的例程开始，需要下载keras源码</p>
<pre><code>$ git clone https://github.com/fchollet/keras.git  </code></pre>
<p>例程在keras/examples目录下<br />
推荐mnist_*例程，它分别使用了CNN，RNN，GAN等方法实现了手写数字的识别，可以先运行一下看看效果．代码很简单，不过是看代码时，就会发现，虽然只有几个语句，几个参数，但还是不明白，为什么要这么写？和那些讲原理的书有点对不上．因此，建议先自己写个简单神经网络具体实现（不是调库），以了解整个流程以及各个参数的具体作用．具体请见下一篇《深度学习——BP神经网络》</p>
<h2 id="配置gpu支持">5. 配置GPU支持</h2>
<h4 id="说明">1) 说明</h4>
<p>到上一步简单安装之后，例程基本都可以跑了．此部分，建议初学者看看就行了，不要急于把环境配置得一步到位．NVdriver+Cuda+TensorFlow+Theano各个软件版本相互依赖，又与机器的操作系统以及显卡型号相关，在配置的过程中的确有很多坑，有可能导致桌面无法启动，以致严重打乱学习的进程．强烈建议先把深度学习的框架弄明白了，需要大量计算时，再回来配置GPU．<br />
注意：只有评分在3.0以上的显卡才能支持tensorflow_gpu，具体型号见https://developer.nvidia.com/cuda-gpus．</p>
<h4 id="nvdriver">2) NVdriver</h4>
<p>nvidia的卡大部分都支持深度学习，只是性能不同。可用以下命令看看自己显卡情况（Tensorflow需要评分3.0以上，Theano只需支持cuda即可）</p>
<pre><code>$ lspci  | grep -i VGA  
$ nvidia-smi  </code></pre>
<p>显卡驱动可能不是最新的，一般在图形界面-&gt;系统设置-&gt;软件更新-&gt;附加驱动-&gt;选择nvidia的可用驱动．也可以用apt-get命令安装，还可以从Nvidia官网上下载安装脚本，但该方法需要先关掉图形界面，安装后再开启，比较麻烦．<br />
另外需要注意的是，不是版本号越高，支持的显卡越多，有些老的显卡只在低版本支持——这也就是安装中最大的坑：显卡驱动升级后不支持当前硬件，使得图形界面无法启动了——不断显示输入密码界面．</p>
<pre><code>$ ls /proc/driver/nvidia/gpus/  </code></pre>
<p>正常安装后，以上目录被生成．</p>
<h4 id="cuda">3) Cuda</h4>
<p>Cuda是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。各个机器学习库都通过Cuda库调用GPU．<br />
Cuda的安装可使用命令（不推荐此方法）</p>
<pre><code>$ apt-get install nvidia-cuda-toolkit  
$ nvcc -V # 安装成功后，看一下版本信息  </code></pre>
<p>至于安装后能否正常使用，就要看运气了．Cuda和Nvdriver，以及TensorFlow的版本都是强相关的，当使用apt-get安装Cuda时，有时会升级显卡驱动（安装时会提示升级一堆包，其中有nvidia-xxx），但升级后的驱动很可能不支持你的硬件．<br />
推荐从https://developer.nvidia.com/cuda-downloads下载run脚本安装，脚本安装会提示你是否升级显卡驱动，此时选No即可．安装后还需要设置一些bin和lib的环境变量．cuda有很多版本，需要找到与显卡驱动匹配的版本，否则安装后还是找不到gpu．</p>
<h4 id="tensorflow_gpu">4) Tensorflow_gpu</h4>
<p>Tensorflow有gpu和cpu两个版本，简单安装中安装的是cpu版本，gpu版本则需要系统中安装cuda和libcudnn，且与Tensorflow匹配．比如：最新的Tensorflow需要cude-8.0版本和cudnn-6.0与之匹配，其它版本会有各种各样奇怪的报错．安装命令如下：</p>
<pre><code>$ sudo pip install tensorflow_gpu  </code></pre>
<p>也可以从git中下载tensorflow最新代码编译，不过编译过程也需要安装bazel等工具支持，比较麻烦．<br />
我安装成功时使用的是用pip安装tensorflow_gpu，同时安装了cuda_8.0.44_linux.run和cudnn-8.0-linux-x64-v6.0.tgz（tgz包约200M，用15M的包会报错找不到函数）</p>
<p>测试程序<br />
安装后，可用以下程序测试tensorflow是否正常运行</p>
<pre><code>import tensorflow as tf  
  
hello = tf.constant(&#39;Hello, TensorFlow!&#39;)  
sess = tf.Session()  
print(sess.run(hello))  
a = tf.constant(10)  
b = tf.constant(32)  
print(sess.run(a + b))  </code></pre>
<h4 id="theano">5) Theano</h4>
<p>Theano也是基本于cuda调用GPU的，相对于Tensorflow要简单一些，它对cuda的版本要求不严格，只要在配置文件中设置正常即可调用GPU<br />
i. 配置文件</p>
<pre><code>$ vi ~/.theanorc  
内容如下  
[global]  
device=gpu  
floatX=float32  
  
[nvcc]  
optimizer=None  </code></pre>
<ol start="2" type="i">
<li>测试程序<br />
</li>
</ol>
<pre><code>from theano import function, config, shared, sandbox    
import theano.tensor as T    
import numpy    
import time    
    
vlen = 10 * 30 * 768  # 10 x #cores x # threads per core    
iters = 1000    
    
rng = numpy.random.RandomState(22)    
x = shared(numpy.asarray(rng.rand(vlen), config.floatX))    
f = function([], T.exp(x))    
print(f.maker.fgraph.toposort())    
t0 = time.time()    
for i in range(iters):    
    r = f()    
t1 = time.time()    
print(&quot;Looping %d times took %f seconds&quot; % (iters, t1 - t0))    
print(&quot;Result is %s&quot; % (r,))    
if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):    
    print(&#39;Used the cpu&#39;)    
else:    
    print(&#39;Used the gpu&#39;)    </code></pre>
<h2 id="参考">6. 参考</h2>
<h4 id="我最喜欢的9个-python深度学习库">1) 《我最喜欢的9个
Python深度学习库》</h4>
<p>http://blog.csdn.net/u013886628/article/details/51819142</p>
<h4 id="ubuntu16.04cuda8.0caffe安装教程">2)
《Ubuntu16.04+cuda8.0+caffe安装教程》</h4>
<p>http://blog.csdn.net/autocyz/article/details/52299889/</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>配置BERT运行环境</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/5_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%8E%AF%E5%A2%83/%E9%85%8D%E7%BD%AEBERT%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h1 id="配置bert运行环境">配置BERT运行环境</h1>
<p>#Pytorch #自然语言处理</p>
<p>自然语言处理库Transformers包含了BERT、GPT、GPT-2、Transformer-XL、XLNet、XLM等模型的实现，近两年Pytorch生态日趋成熟。因此，本文中使用Transformers的Pytorch支持来调用BERT模型。</p>
<h3 id="检查cuda版本">检查cuda版本</h3>
<p>深度学习模型如果没有GPU加持，训练速度几乎是无法忍受的，因此，在使用模型前请先确认GPU正常工作；另外，最新版本的Transformers需要Pytorch
1.5.0及以上版本，而Pytorch 1.5.0底层又依赖CUDA 10.2以上版本。</p>
<p>使用以下命令查看CUDA版本</p>
<pre><code>$ nvidia-smi  </code></pre>
<p>（查看右上角CUDA Version: xx.x）</p>
<p>如果低于10.2，可通过以下命令安装</p>
<pre><code>$ sudo apt-get install cuda-10-2  </code></pre>
<p>安装好后请重启系统</p>
<h3 id="安装方法一通用方法">安装方法一：通用方法</h3>
<p>由于安装依赖库可能干扰主机Linux系统中的Python环境，建议在docker中使用Transformers运行环境。</p>
<p>如果之前有比较常用的docker image，可通过pip安装transformers。</p>
<pre><code>$ pip install transformers  </code></pre>
<p>推荐下载transfromers源码安装，以保持例程与系统中软件版本一致</p>
<pre><code>$ git clone https://github.com/huggingface/transformers.git  
$ cd transformers  
$ python3 -m pip install --no-cache-dir .  </code></pre>
<h3 id="安装方法二标准方法">安装方法二：标准方法</h3>
<p>如果不考虑现有的docker
image，可利用官方提供的Dockerfile制做transforms镜像。</p>
<pre><code>$ git clone https://github.com/huggingface/transformers.git # README支持中文简体  
$ cd transformers/  
$ docker build -t transformers-pytorch-gpu:test1 docker/transformers-pytorch-gpu  </code></pre>
<p>（注意：在transformers目录下运行，否则Dockerfile中复制文件路径不对）</p>
<p>启动docker</p>
<pre><code>$ nvidia-docker run --rm -v /exports:/exports -it transformers-pytorch-gpu:test1 bash   </code></pre>
<p>（注意：使用nvidia-docker启动docker，否则无法在docker内部使用GPU）</p>
<h3 id="测试gpu是否正常工作">测试GPU是否正常工作</h3>
<p>在docker内运行以下Python程序，测试GPU+CUDA+Pytorch是否正常工作。</p>
<pre><code>import torch  
  
print(torch.cuda.is_available())  
print(torch.__version__)  
  
ngpu= 1  
device = torch.device(&quot;cuda:0&quot; if (torch.cuda.is_available() and ngpu &gt; 0) else &quot;cpu&quot;)  
print(device)  
print(torch.cuda.get_device_name(0))  
print(torch.rand(3,3).cuda())  </code></pre>
<h3 id="下载预训练好的中文bert模型">下载预训练好的中文BERT模型</h3>
<pre><code>$ git clone https://huggingface.co/bert-base-chinese  
$ cd bert-base-chinese/  </code></pre>
<p>从浏览器下载pytorch_model.bin覆盖目录中的pytorch_model.bin（用393M的文件覆盖134K的文件），或者复制download地址后用wget下载：</p>
<pre><code>$ wget https://huggingface.co/bert-base-chinese/resolve/main/pytorch_model.bin  </code></pre>
<p>（使用模型时指定bert-base-chinese，有些情况下模型可自动下载）</p>
<h3 id="测试中文bert">测试中文BERT</h3>
<pre><code>import torch  
from transformers import BertModel, BertConfig, BertTokenizer  
  
modle_path = &#39;/exports/git/bert-base-chinese&#39; # 下载模型的目录  
tokenizer = BertTokenizer.from_pretrained(modle_path)  
model = BertModel.from_pretrained(modle_path)  
input_ids = torch.tensor([tokenizer.encode(&quot;测试一下&quot;, add_special_tokens=True)])  
with torch.no_grad():  
  output = model(input_ids)  
  last_hidden_state = output[0]  
  pooler_output = output[1]  
  print(last_hidden_state[:, 0, :])  </code></pre>
<h3 id="语义相似度示例">语义相似度示例</h3>
<p>源码的transformers/examples/pytorch/目录下有各种例程，其中包含常用的问答，多选，分类等自然语言应用。</p>
<p>下面以语义相似度为例，看看如何使用BERT库解决实际问题。</p>
<p>GLUE(General Language Understanding Evaluation)是用于评估NLP
模型的一组标准，其中包含诸多项目，以语义相似度STS-B（Semantic Textual
Similarity）为目录，相关代码在：</p>
<p>transformers/examples/pytorch/text-classification/run_glue.py，可以该程序为入口学习如何使用BERT模型。</p>
<p><strong>安装依赖库</strong></p>
<pre><code>$ cd transformers/examples/pytorch/text-classification/  
$ pip install -r requirements.txt  </code></pre>
<p><strong>测试例程</strong>（具体请参考例程目录下的README）</p>
<pre><code>$ export TASK_NAME=stsb  
$ python run_glue.py --model_name_or_path bert-base-cased --task_name $TASK_NAME --do_train --do_eval --max_seq_length 128 --per_device_train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 3 --output_dir /tmp/$TASK_NAME/   </code></pre>
<p>此时程序将下载相似度训练数据，并按指定参数训练模型（外网时常连不通，请多试几次）。另外，也要以加参数--cache_dir
/exports/bert/
来指定数据存放路径。如果GPU配置正常，几分钟即可训练完成。</p>
<h3 id="参考">参考</h3>
<ul>
<li><p>PyTorch-Transformers:最先进的自然语言处理库(附带python代码)<a
href="https://baijiahao.baidu.com/s?id=1640539349483912777&amp;wfr=spider&amp;for=pc">https://baijiahao.baidu.com/s?id=1640539349483912777&amp;wfr=spider&amp;for=pc</a></p></li>
<li><p>transformers 安装 <a
href="https://pytorchchina.com/2020/02/29/transformers-%E5%AE%89%E8%A3%85/">https://pytorchchina.com/2020/02/29/transformers-%E5%AE%89%E8%A3%85/</a></p></li>
<li><p>中文新闻情感分类 Bert-Pytorch-transformers<a
href="https://blog.csdn.net/qq_21749493/article/details/103703085">https://blog.csdn.net/qq_21749493/article/details/103703085</a></p></li>
</ul>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>XGBoost_原理</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/XGBoost/XGBoost_%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<h1 id="xgboost_原理">XGBoost_原理</h1>
<p>#机器学习 #xgboost</p>
<h2 id="说明">1. 说明：</h2>
<p>难了不会，会了不难，你明白了，觉得这还用说？不明白，跳步之后，似懂非懂。本篇是我对论文《XGBoost:
A Scalable Tree Boosting
System》的阅读笔记，用大白话解释xgboost原理，学霸请跳过，懒得看公式的也请跳过。</p>
<h2 id="第一步整体误差重点整体视角">2.
第一步：整体误差（重点：整体视角）</h2>
<p>整体误差指的是XGBoost模型训练完成之后，将训练集中所有实例代入模型，用以下函数（总误差L()）衡量模型的好坏：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-559f88bfb4b14eb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>左边是训练集所有实例的误差之和，i指每个实例，y^是预测值，y是实际值，而l()是衡量y’与y差异的方法，比如RMSE。左边比较好理解，就是说训练一个模型，最好能对于所有的实例都做出与真实值相似的预测。<br />
右边是正则项，它的用途就是防止模型过拟合，比如说一个模型，一共400个实例，模型做了400个叶节点，与实例一一对应，它的泛化就很差，所以应该尽量简化模型，正则项在第四步详述。</p>
<h2 id="第二步计算t棵树时的误差重点从第t-1棵到第t棵">3.
第二步：计算t棵树时的误差（重点：从第t-1棵到第t棵）</h2>
<p>梯度下降决策树是由多棵树组成的模型。假设它由t棵树组成，误差是：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-b5050f86edc1948d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>还是看左边，计算n个实例误差的总合，y是实际值，而此时的预测值是，之前树的预测值y’(t-1)，加上第t棵树的预测值ft()，ft()就是第t棵树所做的工作。</p>
<h2 id="第三步泰勒公式重点从始至终计算的都是预测的误差l">4.
第三步：泰勒公式（重点：从始至终计算的都是预测的误差L()）</h2>
<p>泰勒公式：在已知函数在某一点（x0点）的各阶导数值的情况之下，泰勒公式可以用这些导数值做系数构建一个多项式来近似函数在这一点的邻域中的值。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-be6ed6a2f7cf2f60.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中Rn(x)是余项。<br />
 简单举个例子，我不知道x住哪儿f(x)，但知道x附近的x0住哪儿f(x0)，所以我先找到它，然后根据他俩距离的远近x-x0，以及他俩位置的相对方向（f()的导数），推出x大概住哪儿。<br />
换种写法，求点x附近，距离是delta x的点的f()，只考虑两阶导数：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-927d47516de69fb3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>本文中所求的函数f()是误差函数L()，代入进去是：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-2601264bc3fc7f2b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>这里的delta
x指的是x的细微变化，回想第二步的公式中，我们每训练一棵树ft()都相当于对上一步结果的微调，于是有：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-df35165fc03566fb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>也就是说，知道第t-1棵树预测结果与真实值的误差L(x)，这个误差函数的一阶导L’(x)，二阶导L’’(x)，又知道第t棵相对于第t-1棵做了什么微调ft()，于是估计出：加入第t棵树之后的预测值与真实值的误差。就有了以下公式：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-2813036908960d77.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中：gi和hi分别是误差函数l()对第t-1棵预测值的一阶导和二阶导。<br />
简单地说：一共t棵树的模型，它的误差是第t-1棵树构造模型的误差函数l()，加上误差函数一阶导gi乘第t棵树的贡献ft()，再加误差函数的二阶导hi乘第t棵树贡献的平方。</p>
<h2 id="第四步公式右侧正则项重点得分w">5.
第四步：公式右侧正则项（重点：得分w）</h2>
<p>先来看看最普通的单棵决策树，当训练完模型后，预测时把x代入树，顺着条件判断的分支，最后落入哪个叶节点，结果就是该叶节点的值。</p>
<p>而Boost决策树是多棵决策树，它对x的预测结果是，将x代入每棵决策树，得到多个叶节点的值w，将其结果累加得到预测值（最基本的逻辑）。这里各个叶节点的值w简称得分。</p>
<p>正则项是为了防止模型太复杂过拟合，公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-b30cbcb42759e163.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中T是树中的叶结点个数，w是叶节点的得分，γ和λ是可调节的参数，在整体L()计算公式中，w越大误差L越大(w不均匀)，树的叶子越多L也越大，为求得最小的L，最终在树的复杂度和准确度之间取得平衡。</p>
<h2 id="第五步以实例为单位变为以节点为单位累加重点转换视角">6.
第五步：以实例为单位变为以节点为单位累加（重点：转换视角）</h2>
<p>此时我们的焦点在ft(x)上，要分析L与ft的关系，第t-1棵树误差是个常数项，先忽略不看，可写成:</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-26b5e1875ab0fb97.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>每一个xi是一个实例的条件，它经过第t棵决策树ft()的处理后，会落在某个叶节点上，得到该叶节点的得分w，即：ft(xi)-&gt;wj，因此可将ft(xi)转换为wj，代入，得到以下公式：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a13091de3c32a3d9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中T是树的叶节点个数，需要注意的是其中Ij，它指的是落入树中节点j的所有训练实例。把右侧展开后加入，得到：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-4f201e41bc253594.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="第六步w如何取值使预测误差最小重点求极值">7.
第六步：w如何取值使预测误差最小（重点：求极值）</h2>
<p>这是个极值问题，求当误差函数L()为最小值时，wj的取值，求极值即导数为0的点，简单推导如下（写得不全，领会精神）：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-c5060f8ea534dc34.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>规范的写法是：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-7c6386a3837a2943.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>公式的含义是：叶节点的合理取值w取决于四个值，第一：落在该点的实例Ij都有哪些，第二/三：将这些实例代入之前t-1棵决策树预测后，误差的方向一阶导和二阶导，第四是系数λ，人工设置。其原理是，如果之前的树把该点预测大了，则在本树的w把它调小点。<br />
把计算好的w代入误差公式，简单推导如下（写得不全，领会精神）：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-e4b389b34986c92e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>规范的写法是：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-fa1dc73722a50147.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>用语言描述公式：误差最小的条件是，对所有（T个）叶节点，代入落入该节点的实例，用之前t-1棵树的误差的导出和正则项，即可计算出第t棵树的误差。<br />
此处我们看到，计算第t棵树的误差时，不需要计算出该树每个叶节点的w，只需把计算w的素材h,g,Ij,λ代入即可。</p>
<h2 id="第七步在分裂决策树时计算误差函数重点细化到每一次分裂">8.
第七步：在分裂决策树时计算误差函数（重点：细化到每一次分裂）</h2>
<p>此步骤关注的不是整棵树，而是每次分裂，最基本的贪婪算法是：生成树时，从根节点开始，遍历所有属性，遍历所有属性的可能取值作为分裂点，计算该分裂点左子树样本集合ll和右子树样本集合lr的误差，加起来和不分裂的误差相比，即可判断分裂是否合理。</p>
<p>注意这时的误差L计算的不是全树的误差，而权限于与本次分裂相关的实例在分裂前后的误差对比。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-19b1903c6517b7c7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>再啰嗦一句：误差大小取决于w；w值又取决于落入该叶节点的实例，之前的决策树对它们预测值的误差方向；实例有哪些又取决于怎么分裂，所以只要知道了怎么分裂，以前之前树的信息，就能算出分裂后的误差变化。</p>
<h2 id="参考">9. 参考</h2>
<h4 id="xgboost-a-scalable-tree-boosting-system">1) 《XGBoost: A
Scalable Tree Boosting System》</h4>
<p>https://pan.baidu.com/s/1skT2eeh</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>xgboost</tag>
      </tags>
  </entry>
  <entry>
    <title>XGBoost_源码初探</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/XGBoost/XGBoost_%E6%BA%90%E7%A0%81%E5%88%9D%E6%8E%A2/</url>
    <content><![CDATA[<h1 id="xgboost_源码初探">XGBoost_源码初探</h1>
<p>#机器学习 #xgboost</p>
<h2 id="说明">１. 说明</h2>
<p> 本篇来读读Xgboost源码。其核心代码基本在src目录下，由C++实现，40几个cc文件，代码11000多行，虽然不算太多，但想把核心代码都读明白，也需要很长时间。
我觉得阅读的目的主要是：了解基本原理，流程，核心代码的位置，修改从哪儿入手，而得以快速入门。因此，需要跟踪代码执行过程，同时查看在某一步骤其内部环境的取值情况。具体方法是：单步调试或在代码中加入一些打印信息，因此选择了安装编译源码的方式。</p>
<h2 id="下载编译">２. 下载编译</h2>
<p> 用参数--recursive可以下载它的支持包rabit和cur，否则编不过</p>
<pre><code>$ git clone --recursive https://github.com/dmlc/xgboost  
$ cd xgboost  
$ make -j4  </code></pre>
<h2 id="运行">３. 运行</h2>
<p> 测试程序demo目录中有多分类，二分类，回归等各种示例，这里从二分类入手。</p>
<pre><code>$ cd demo   
#运行一个测试程序   
$ cd binary_classification  
$ ./runexp.sh # 可以通过修改cfg文件，增加迭代次数等，进一步调试  </code></pre>
<h2 id="主流程">４. 主流程</h2>
<p> 下面从main()开始，看看程序执行的主要流程，下图是一个示意图，每个黄色框对应一个cc文件，可以将它视作调用关系图，并非完全按照类图绘制，同时省略了一些主流程以外的细节，请各位以领会精神为主。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-044784c7371c1c89.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="srccli_main.cc主程序入口">1)
Src/cli_main.cc：（主程序入口）</h4>
<ol type="i">
<li><p>CLIRunTask()：解析参数，提供三个主要功能：训练，打印模型，预测.</p></li>
<li><p>CLITrain()：训练部分，装载数据后，主要调用学习器Learner实际功能（配置cofigure，迭代，评估，存储……），其中的for循环包含迭代调用计算和评估。</p></li>
</ol>
<h4 id="srclearner.cc学习器">2) Src/learner.cc：（学习器）</h4>
<p> 定义三个核心句柄gbm_(子模型tree/linear)，obj_(损失函数)，metrics_(评价函数)</p>
<ol type="i">
<li><p>UpdateOneIter()：此函数会在每次迭代时被调用，主要包含四个步骤：调整参数（LazyInitDMatrix()），用当前模型预测（PredictRaw()，gbm_-&gt;
PredictBatch()），求当前预测结果和实际值的差异的方向（obj_-&gt;GetGradient()），根据差异修改模型（gbm_-&gt;DoBoost()），后面逐一细化。</p></li>
<li><p>EvalOneIter()
支持对多个评价数据集分别评价，对每个数据集，先进行预测（PredictRaw()），评价（obj_-&gt;EvalTransform()），再调metrics_中的各个评价器，输出结果。</p></li>
</ol>
<h4 id="srcmetricmetric.cc评价函数入口">3)
Src/metric/metric.cc（评价函数入口）</h4>
<p> 基本上，每个目录都有一个入口函数，metric.cc是评价函数的入口，learn允许同时支持多个评价函数（注意评价函数和误差函数不同）。主要三种评价函数：多分类，排序，元素评价，分别定义在三个文件之中。</p>
<h4 id="srcobjectiveobjective.cc损失函数入口">4)
Src/objective/objective.cc（损失函数入口）</h4>
<p> objective.cc是损失函数的入口，Learner::load()函数调用Create()创建误失函数，该目录中实现了：多分类，回归，排序的多种损失函数（每个对应一个文件），每个损函数最核心的功能是GetGradient()，另外也可以参考plugin中示例，自定义损失函数。
例如：src/objective/regression_obj.cc（最常用的损失函数RegLossObj()）计算一阶导，二阶导，存入gpair结构。这里加入了样本的权重，scale_pos_weight也是在此处起作用。</p>
<h4 id="srcgbmgbm.cc迭代器gradient-booster">5)
src/gbm/gbm.cc（迭代器Gradient Booster）</h4>
<p> 这里是对模型的封装，主要支持tree和linear两种方式，树分类器又包含GBTree和Dart两种，Dart主要加入了归一化和dropout防过拟合，详见参考部分。
gbm.cc中也有三个重要句柄：model_存储当前模型数据，updaters_管理每一次迭代的更新算法，
predictor_用于预测</p>
<ol type="i">
<li><p>DoBoost()和BoostNewTrees()
进一步迭代生成新树，详建更新器部分</p></li>
<li><p>Predict*() 调用各种预测，详见预测部分</p></li>
</ol>
<h4 id="srcpredictorpredictor.cc预测工具入口">6)
src/predictor/predictor.cc（预测工具入口）</h4>
<p> predictor.cc也是一个入口，可调用cpu和gpu两种预测方式。</p>
<ol type="i">
<li>PredValue()：核心函数，计算了从训练到当前迭代的所有回归树集合（以回归树为例）。</li>
</ol>
<h4 id="srctreetree_updater.cc树模型的具体实现">7)
src/tree/tree_updater.cc（树模型的具体实现）</h4>
<p> src/tree和src/linear分别是树和线性模型的具体实现，tree_updater是updater的入口，每一个Updater是对一棵树进行一次更新。其中的Updater分为两类：计算类和辅助类，<em>updater</em>都继承于TreeUpdater，互相之间又有调有关系，比如：prune调用sync，colmaker和fast_hist调用prune。</p>
<p> 以下为辅助类：</p>
<ol type="i">
<li><p>Src/tree/updater_prune.cc 用于剪枝</p></li>
<li><p>Src/tree/updater_refresh.cc 用于更新权重和统计值</p></li>
<li><p>Src/tree/updater_sync.cc
用于在分布式系统的节点间同步数据</p></li>
<li><p>Src/tree/split_evaluator.cc 定义了两种切分方法：弹性网络elastic
net,
单调约束monotonic，在此为切分评分，正则项在此发挥作用。打发的依据是差值，权重和正则化项。</p></li>
</ol>
<p> 以下为算法类（基本都在xgboost论文第三章描述）<br />
 对于树算法，最核心的是如何选择特征和特征的切分点，具体原理请见CART,算法，信息增益，熵等概念，这里实现的是几种树的生成方法。</p>
<ol start="22" type="a">
<li>Src/tree/updater_colmaker.cc 贪婪搜索算法(Exact Greedy
Algorithm)，最基本的树算法，一般都用它举例说明，这里提供了分布和非分布两种支持。在每个特征中选择该特征下的每个值作为其分裂点，计算增益损失。由内至外，关键函数分别是：
EnumerateSplit() 穷举每一个枚举值，用split_evaluator打分。
ParallelFindSplit() 多线程，其它同上 UpdateSolution()
调上面两个split()，更新候选方案 FindSplit()
在当前层寻找最佳切分点，对比各个候选方案，方案来自上面的UpdateSolution()</li>
</ol>
<ol start="6" type="i">
<li><p>Src/tree/updater_histmaker.cc 它是xgboost默认的树生成算法，
它和后面提到的skmaker都继承自BaseMaker（BaseMaker的父类是TreeUpdate）是基于直方图选择特征切分点。
HistMaker提取Local和Global两种方式，Global是学习每棵树前，
提出候选切分点；Local是每次分裂前，重新提出候选切分点。 UpdateHistCol()
对每一个col，做直方图分箱，返回一个分界Entry列表。</p></li>
<li><p>Src/tree/updater_skmaker.cc
继承自BaseMaker（BaseMaker父类TreeUpdate）加权分位数草图，用子集替代全集，使用近似的
sketch 方法寻找最佳分裂点。</p></li>
</ol>
<h2 id="其它">５. 其它</h2>
<h4 id="gpu多线程分布式">1) GPU，多线程，分布式</h4>
<p> 代码中也有大量操作GPU，多线程，分布式的操作，这里主要介绍核心流程，就没有提及，详见代码，其中.cu和.cuh是主要针对GPU的程序。</p>
<h4 id="关键字说明">2) 关键字说明</h4>
<p> CSR：csr_matrix一种存储格式<br />
 Dmlc（Deep Machine Learning in
Common）：分布式深度机器学习开源项目<br />
 Rabit：可容错的allrecude（分布式），支持python和C++，可以运行在包括MPI和Hadoop
等各种平台上面<br />
 Objective与Metric（Eval）：这里的Metric和Eval都指评价函数，Objective指损失函数，它们计算的都是实际值和预测值之间的差异，只是用途不同，Objective主要在生成树时使用，用于计算误差和通过误差的方向调整树；而评价函数主要用于判断模型对数据的拟合程度，有时通过它判断何时停止迭代。</p>
<h4 id="基于直方图的切分点选择">3) 基于直方图的切分点选择</h4>
<p> 分位数quantiles：即把概率分布划分为连续的区间，每个区间的概率相同。把数值进行排序，然后根据你采用的几分位数把数据分为几份即可。<br />
 xgboost用二阶导h对分位数进行加权，让相邻两个候选分裂点相差不超过某个值ε。因此，总共会得到1/ε个切分点。<br />
 通过特征的分布，按照加权直方图算法确定一组候选分裂点，通过遍历所有的候选分裂点来找到最佳分裂点。它不会枚举所有的特征值，而是对特征值进行聚合统计，然后形成若干个bucket(桶)，只将bucket边界上的特征值作为split
point的候选，从而获得性能提升，对稀疏数据效果好。</p>
<h4 id="参考">６. 参考</h4>
<h4 id="xgboost-documentation">1) XGBoost Documentation</h4>
<p><a
href="https://xgboost.readthedocs.io/en/latest/">https://xgboost.readthedocs.io/en/latest/</a></p>
<h4 id="xgboost入门与实战原理篇">2) xgboost入门与实战（原理篇）</h4>
<p><a
href="https://blog.csdn.net/sb19931201/article/details/52557382">https://blog.csdn.net/sb19931201/article/details/52557382</a></p>
<h4 id="xgboost解析系列--源码主流程">3) XGBoost解析系列--源码主流程</h4>
<p><a
href="https://blog.csdn.net/matrix_zzl/article/details/78699605">https://blog.csdn.net/matrix_zzl/article/details/78699605</a></p>
<h4 id="xgboost-论文翻译个人注释">4) XGBoost 论文翻译+个人注释</h4>
<p><a
href="https://blog.csdn.net/qdbszsj/article/details/79615712">https://blog.csdn.net/qdbszsj/article/details/79615712</a></p>
<h4 id="dart-booster">5) DART booster</h4>
<p><a
href="https://blog.csdn.net/Yongchun_Zhu/article/details/78745529">https://blog.csdn.net/Yongchun_Zhu/article/details/78745529</a></p>
<h4 id="我爱机器学习集成学习三xgboost">6)
『我爱机器学习』集成学习（三）XGBoost</h4>
<p><a
href="https://www.hrwhisper.me/machine-learning-xgboost/">https://www.hrwhisper.me/machine-learning-xgboost/</a></p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>xgboost</tag>
      </tags>
  </entry>
  <entry>
    <title>Xgboost之增量学习</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/XGBoost/XGboost_%E5%A2%9E%E9%87%8F%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="xgboost之增量学习">Xgboost之增量学习</h1>
<p>#机器学习 #xgboost</p>
<h2 id="说明">1. 说明</h2>
<p>当我们的训练数据非常多，并且还在不断增加时，每次都用全量训练，数据过多，时间过长，此时就可以使用增量训练：用新增的数据微调校正模型。</p>
<h2 id="全量与增量的差异">2. 全量与增量的差异</h2>
<p>在使用增量训练时，最关心的问题是：全量和增量的差别，从而确定增量训练的使用场景。</p>
<p>假设有200条数据，第一次训练150条，第二次训练50条，和直接用200条训练的差异在于：在第二次训练50条时，前150条数据已经不存在了，模型更拟合于后面的数据。如果我们定期增量训练，那么离当前时间越近的数据对模型影响越大，这也是我们想要的结果。但如果最后一批数据质量非常差，就可能覆盖之前的正确实例的训练结果，把模型带偏。</p>
<p>同理，如果我们按时间把数据分成几部分，然后按从早到晚的顺序多次训练模型，每个模型在上一个模型基础上训练，也间接地参加了后期实例的权重。</p>
<p>Xgboost提供两种增量训练的方式，一种是在当前迭代树的基础上增加新树，原树不变；另一种是当前迭代树结构不变，重新计算叶节点权重，同时也可增加新树。</p>
<p>对于已存在的决策树，早期训练的实例决定了模型的结构（选择哪些特征及分裂点），后期的实例决定最终的结果（叶节点的权重和新加入的树）。</p>
<p>综上，两个重点：第一，模型训练了一半，突然换了一批完全不同的数据继续训练，早期数据不再能再校正模型；第二，树一旦形成，结构就不再变化，后续的训练只能增加新树和重新计算前树的节点权重。</p>
<p>我觉得，还是尽量用全量数据训练，如果数据太多，必须增量时，尽量保证增量数据的质量和数量（均匀分布），以免带偏模型。</p>
<h2 id="例程">3. 例程</h2>
<p>xgboost源码中有增量训练的例程：tests/python/test_training_continuation.py，其中核心部分稍做修改如下：</p>
<pre><code># -*- coding: utf-8 -*-  
  
import xgboost as xgb  
from sklearn.datasets import load_digits # 训练数据  
  
xgb_params_01 = &#123;&#125;  
  
digits_2class = load_digits(2)  
X_2class = digits_2class[&#39;data&#39;]  
y_2class = digits_2class[&#39;target&#39;]  
  
dtrain_2class = xgb.DMatrix(X_2class, label=y_2class)  
gbdt_03 = xgb.train(xgb_params_01, dtrain_2class, num_boost_round=3) # 训练三棵树的模型  
print(gbdt_03.get_dump()) # 显示模型  
gbdt_03a = xgb.train(xgb_params_01, dtrain_2class, num_boost_round=7, xgb_model=gbdt_03) # 在原模型基础上继续训练  
print(gbdt_03a.get_dump())  </code></pre>
<h2 id="分析">4. 分析</h2>
<p>训练函数train()中有个参数xgb_model，可填写旧模型路径，或者模型指针，指定该参数后，新模型在旧模型的基础上训练。</p>
<p>从代码上看，增量训练的逻辑主要在python层面，和普通的训练模型比，只是在c++底层实现了用旧模型填充learner，而非初始化learner。</p>
<p>回想一下前篇讨论过的训练过程：代入实例预测-&gt;对比预测结果和实际结果差异（误差函数）及误差方向（误差函数导数）-&gt;添加新决策树改进模型。继续训练也是如此。</p>
<p>从上面代码的输出结果可以看到，第一次dump的决策树是三棵，第二次dump出十棵（第一次三棵加第二次七棵）其中的前三棵与之前完全一样。就是说增量训练后，原来模型中的所有树都没变，只是在后面追加了更多的树。</p>
<p>如果在params中设置’process_type’:’update’,’update’:’refresh,’refresh_leaf’:True，则前三棵树结构不变，叶节点权重改变，最终结果一共七棵树（更新前三棵，新建后四棵）。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>xgboost</tag>
      </tags>
  </entry>
  <entry>
    <title>Xgboost调试方法</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/XGBoost/XGboost_%E8%B0%83%E8%AF%95%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="xgboost调试方法">Xgboost调试方法</h1>
<p>#机器学习 #xgboost</p>
<h4 id="调试test目录下的测试用例">1. 调试test目录下的测试用例</h4>
<p> 在测试程序后面加入以下代码，即可启动调试程序</p>
<pre><code>if __name__ == &quot;__main__&quot;:  
    unittest.main()  </code></pre>
<h4 id="显示树结构">2. 显示树结构</h4>
<pre><code>import matplotlib.pyplot as plt   
fig,ax = plt.subplots()  
xgb.plot_tree(gbdt_03a, ax = ax, num_trees=0) # 显示模型中的第一棵树  
plt.show()  </code></pre>
<h4 id="打印详细调试信息">3. 打印详细调试信息</h4>
<p> 在xgb的params中设置：</p>
<pre><code>&#39;silent&#39;: 0,  
&#39;debug_verbose&#39;: 5  </code></pre>
<h4 id="修改源码">4. 修改源码</h4>
<p> 修改c++源码后如果运行c++程序，在xgboost目录下执行编译命令make，重新生成二进制程序xgboost，运行即可。</p>
<p> 修改c++源码后如果运行Python程序，需要将xgboost/lib/libxgboost.so，复制到python对应的库目录下（如：/usr/local/lib/python2.7/dist-packages/xgboost/lib/），注意源码和python库的版本一致性。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>xgboost</tag>
      </tags>
  </entry>
  <entry>
    <title>实战A股上市公司季度营收预测</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98A%E8%82%A1%E4%B8%8A%E5%B8%82%E5%85%AC%E5%8F%B8%E5%AD%A3%E5%BA%A6%E8%90%A5%E6%94%B6%E9%A2%84%E6%B5%8B/</url>
    <content><![CDATA[<h1 id="实战a股上市公司季度营收预测">实战A股上市公司季度营收预测</h1>
<p>#算法实战 #时序</p>
<h2 id="说明">1. 说明</h2>
<p> FDDC2018金融算法挑战赛01－A股上市公司季度营收预测，是天池最近的一个算法比赛，7月15是初赛提交的deadline，就最后两天了，也没法做得太细，看看怎么用最短的时间，抓住最关键的值，搭个简单的架子。</p>
<h2 id="数据分析">2. 数据分析</h2>
<h4 id="预测目标">1) 预测目标</h4>
<p> 2018年二季度的营业收入。</p>
<h4 id="已知数据">2) 已知数据</h4>
<p> 题目提供的除了报表数据，提交格式以外，还有一些说明文档，这些文档都需要看一遍，很多对题目的疑问都可以从中找到答案。</p>
<h4 id="分析">3) 分析</h4>
<p> 营业收入REVENUE在利润表Income_Statement.xls中，先来看看这个文件，它把金融，保险，银行和一般工商业分成四个sheet分别存放。<br />
下面分析一下其中占比最高的一般工商业（General
Business）公司，数据约20万条左右。涉及3500多家公司。时间范围是2009年4月到2018年7月。<br />
一般报表中的所有项目都是一起发布的，所以预测营收时，同期的其它数据也不知道。相对于用上期的其它数据预测本期的营收，还不如用历史的营收数据预测本期营收。<br />
 于是最简单的方法就是将其视为一个时间序列问题处理。用往期的营收，预测当期的营收，还可以参考：同比，环比作为对预测的验证。</p>
<h4 id="统计">4) 统计</h4>
<p> 画个直方图看看每支股票对应多少条数据，如下图所示，多一半的公司数据条数在80条左右，从2009-2017约十年时间，每年四季度出四个报表，再去掉约一半的修正数据，也就是说一半以上的公司包含十年以来的全部数据。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-95cbb23fb94ce15b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 本来是想：将数据周期在5年以上的，使用周期趋势的预测方法，2-5年的，用同比预测（参考去年同期）；2年以下的用环比预测（参考前一季度）。后来一看，需要预测的1500支股票，基本没有少于4年的，看来是多虑了。于是直接使用周期趋势的预测方法。</p>
<h2 id="处理缺失处理">3. 处理缺失处理</h2>
<p> 数据有一些重复的情况，比如某支股票N在2017年一季报有两条，且数据不同，这是由于表中包含了起始发布的数据，和后来修改的数据，采取的方法是：最后发布的数据，还有一些重要，因为时间有限，暴力地使用了drop_duplicates。<br />
 另外，有一些月份数据缺失，按缺失数据的多少，参考同比、环比或者用均值填补，当然如果有时间，也可以在网上抓数据填充。主要是注意不要错位，导致周期混乱。我这次由于使用的是prophet模型，所以不存在这种问题，如果复赛平台不允许使用该库，就需要手工处理了。</p>
<h2 id="拟合时间序列曲线">4. 拟合时间序列曲线</h2>
<p> 先找一个比较有规律的，比如000009，方法是做log1后用Prophet模型回归。下图是对之后的三个季度做了预测。其中黑色点是实际值，蓝线是预测值，看起来还可以。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-e3ca280f9202605c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> Q1是一季报，半年报S1包含了一二季，Q1包含了前三季，A是全年营收，一般来说，只把单个季度作为单位预测会更加准确一些，但本次我没做那么细。<br />
 模型使用的是Prophet，这个实在是特别简单。我觉得用其它方法真的很难在几个小时内完成一个比赛。预测1500个数据，我的机器大约训练半个小时左右。</p>
<h2 id="题外话">5. 题外话</h2>
<p> 看到这个题好长时间了，但评测的次数太少，少了很多刷榜的的乐趣，所以直拖到了截止日期的最后两天才开始写，核心代码100多行，天太热，不想弄了，提交参与一下，顺便分享给大家，算是抛砖引玉吧。<br />
 虽然没花太多时间写代码，却也在这一个月里读了一些关于财报的科普书《手把手教你读财报》，《一本书读懂财报》，加上之前学过会计，对三张表有了些基本的了解。说实话，我觉得这两道股票相关的题出得也不是特别走心，像本题给出的数据，很容易从网上抓到。在其中主要以学习业务逻辑为主。除比赛以外，主要希望对之后的股票操作有一些帮助。<br />
 明天最后一天，各位加油哦！</p>
]]></content>
      <tags>
        <tag>时序</tag>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战_瑞金医院MMC知识图谱大赛初赛</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98_%E7%91%9E%E9%87%91%E5%8C%BB%E9%99%A2MMC%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%A4%A7%E8%B5%9B%E5%88%9D%E8%B5%9B/</url>
    <content><![CDATA[<h1
id="实战_瑞金医院mmc知识图谱大赛初赛">实战_瑞金医院MMC知识图谱大赛初赛</h1>
<h3 id="说明">1. 说明</h3>
<p> 《瑞金医院MMC人工智能辅助构建知识图谱大赛》是一个天池的自然语言处理相关的比赛，初赛是命名实体识别（Named
Entity
Recognition，简称NER）。具体说，就是从医学文档里标注出药名，疾病，病因，临床表现，检查方法等十二种实体的类别和位置。这是一个有监督学习，它的训练集是标注好的医学文档。</p>
<p> 还是延续以往比赛的思路，找一个类似的简单项目，在其上修修改改，于是找到了
"参考1"
中的例程，它是一个在中文文本中标注地名，人名，组织名的程序，使用工具是tensorflow，算法是BiLSTM-CRF。</p>
<p> 花了不到两天的时间，混进了复赛，虽说是在别人的代码上修修改改，但也不失为一个NLP相关的深度学习入门，顺便熟悉一下如何使用tensorflow。我做的工作很简单：参考代码2000多行，修改了不到200行，主要就是把那套代码对这个项目做一个适配，没啥可说的，本文主要梳理了深度学习如何应用于自然语言处理，算法原理，以及Tensorflow的一些用法。</p>
<h3 id="深度学习能解决自然语言处理中的哪些问题">2.
深度学习能解决自然语言处理中的哪些问题</h3>
<p> 前一阵被BERT刷屏了，它是谷歌AI团队新发布新模型，传说在机器阅读理解顶级水平测试中狂破11项纪录，全面超越人类，测试主要来自QLUE和SquAD，它们包括：</p>
<p>MNLI：判断两个句子间是继承，反驳，关系。<br />
QQP：两个问句的类似程度。<br />
QNLI：问答系统，区分问题的正确答案和同一段中的其它描述。<br />
SST-2：电影评论的感情色彩标注。<br />
CoLA：判断语法是否正确。<br />
STS-B：语义相似度打分（1-5级）<br />
MRPC：两句语义是否等价。<br />
RTE：识别继承关系，和MNLI差不多，但数据集比较小。<br />
SquAD：阅读理解，在段落中找答案。</p>
<p> 看起来，只要有标注好的训练集数据，上述的各种关系都可以被预测，但是具体这些文字，又怎么代入模型呢？往下看…</p>
<h3 id="命名实体识别的bio标注集">3. 命名实体识别的BIO标注集</h3>
<p> BIO标注将每个元素标注为“B-X”、“I-X”或者“O”。其中，“B-X”表示此元素所在的片段属于X类型并且此元素在此片段的开头，“I-X”表示此元素所在的片段属于X类型并且此元素在此片段的中间位置，“O”表示不属于任何类型。形如：</p>
<p>本 O 课 O 题 O 组 O 前 O 期 O 研 O 究 O 及 O 相 O 关 O 研 O 究 O 结 O
果 O 已 O 经 O 明 O 确 O 1 B-Anatomy 1 I-Anatomy β I-Anatomy - I-Anatomy
H I-Anatomy S I-Anatomy D I-Anatomy 1 I-Anatomy 作 O 为 O 公 O 认 O 的 O
肥 B-Disease 胖 I-Disease 相 O 关 O 基 O 因 O</p>
<p> 本例中借鉴的工具使用了BIO标注集，因此，把赛题数据置换成了BIO格式，以便代入，可以看到，具体方法是以字为单位的标注（以词为单位，可能在分词的过程中引入一些误差，我也没尝试）。转换之后更容易看出，它是一个词序列的关系问题。</p>
<h3 id="命名实体识别的具体方法">4. 命名实体识别的具体方法</h3>
<p> BiLSTM-CRF是近两年业界比较流行的解决命名实体识别的方法，本题使用的也是这个方法，本题的解法可以分为三个步骤：第一，将文字向量化（Word
embedding）；第二，计算上下文之间的关系（Bi-LSTM）；第三，句子级的序列标注（CRF）。</p>
<p> 我借鉴的代码位置在https://github.com/Determined22/zh-NER-TF,
功能是标注出文字中的人名，地名，组织名。模型相关的代码在
model.py，我觉得特别核心的100行不到，建议一边看代码一边看以下说明，不妨在其中打印一些信息，追踪一下它的运行流程。</p>
<p><strong>(1) Word Embedding</strong></p>
<p> Word
Embedding词嵌入向量是NLP里一个重要的概念,我们利用它将一个词转换成固定长度的向量表示，从而便于进行数学处理。比如一篇文章里有1000个词，如果做one
hot提取特取，则需要新增1000个特征，而像got与get会被识别为不同的词，如果使用Word
Embedding，则可能将一些同义词提取为一个特征，从而实现降维和抽象的效果，具体实现方法是用上下文预测当前词，也可以理解为在神经网络上实现word2vec，详见参考二。</p>
<p> 总之，可以把该层更解为对把词置换为词向量，本例中映射前支持的中文字符有3000多个，降维的目标是300维，而每一维中的特征值是从3000映射到300后的概率分布，即可能性（有点像PCA降维）。从代码中可以看到，用tensorflow降维就几行代码，确实很方便（见代码中的model.py:lookup_layer_op）。</p>
<p><strong>(2) Bi-LSTM</strong></p>
<p> LSTM（Long Short-Term
Memory）长短期记忆网络，是RNN（时间递归神经网络）的一种，适合于处理和预测时间序列中间隔和延迟相对较长的重要事件。
Bi-LSTM即双向LSTM，本例中使用TensorFlow提供的LSTMCell类建立了正向和反向各一个LSTM，用bidirectional_dynamic_rnn()
结合成一个双向RNN（见代码中的model.py: biLSTM_layer_op）</p>
<p> 这一步，计算的是上下文之间的关系，谁更可能出现在前面，谁更可能出现在谁后面，还没真正标注。</p>
<p><strong>(3) CRF</strong></p>
<p> CRF是条件随机场，是在给定随机变量X的条件下，随机变量Y的马尔可夫随机场，这里使用的线性链条件随机场，在条件概率模型P(Y|X)中，Y是输出变量，表示标记序列（状态序列），X是输入变量，表示需要标注的观测序列，用最大似然估计计算条件概率模型P
^(Y|X)，预测时，对于给定的输入序列，求出条件概率P ^(y|x)最大的输出序列y
^（可能性最大的标注序列），详见代码中的tf.contrib.crf.crf_log_likelihood()。</p>
<p> 要了解CRF的原理，先要了解马尔可夫链，以及很多基础知识（虽然很有趣，但需要花很多时间），但在程序里调用它很容易，几行代码就够了，一开始了解它怎么用就够了。</p>
<h3 id="tensorflow">5. TensorFlow</h3>
<p> C++相对于
C，Python相对于Java，TensorFlow相对于之前的程序架构，它们不只是语法不同，更多的是程序的组织方式，和思考方法不同。</p>
<p> Tensorflow是基于图（Graph）的计算系统。而图的节点则是由操作（Operation）来构成的，而图的各个节点之间则是由张量（Tensor）作为边来连接在一起的。所以Tensorflow的计算过程就是一个Tensor流图。Tensorflow的图则是必须在一个Session中来计算。</p>
<p> 这样讲还是很抽象，简单地说，假设在程序中定义了三个函数（Operation）:
a,b,c，普通程序会顺序地调用a,b,c，而Tensorflow是指定a,b,c之间的依赖关系（Tensor），比如c依赖b的结果，b又依赖a的结果，运行时，使用Session.run()，只要告诉它，我最终需要c，程序自己找到它依赖的b，以及a来运行，通过数据流向把握整个过程，有点像Luigi的工作模式。具体请见"参考7"。</p>
<h3 id="参考">6. 参考</h3>
<p><strong>(1) DL4NLP ——
序列标注：BiLSTM-CRF模型做基于字的中文命名实体识别</strong><br />
<a
href="https://www.cnblogs.com/Determined22/p/7238342.html">https://www.cnblogs.com/Determined22/p/7238342.html</a></p>
<p><strong>(2) 浅谈词嵌入（word embedding）</strong><br />
<a
href="https://blog.csdn.net/puredreammer/article/details/78330821">https://blog.csdn.net/puredreammer/article/details/78330821</a></p>
<p><strong>(3) 神经网络中embedding层作用</strong><br />
<a
href="https://www.cnblogs.com/bonelee/p/7904495.html">https://www.cnblogs.com/bonelee/p/7904495.html</a></p>
<p><strong>(4) tensorflow学习笔记--embedding_lookup()用法</strong><br />
<a
href="https://blog.csdn.net/u013041398/article/details/60955847">https://blog.csdn.net/u013041398/article/details/60955847</a></p>
<p><strong>(5)
tensorflow笔记3：CRF函数：tf.contrib.crf.crf_log_likelihood()</strong><br />
<a
href="https://www.cnblogs.com/lovychen/p/8490397.html">https://www.cnblogs.com/lovychen/p/8490397.html</a></p>
<p><strong>(6) [学习笔记] TensorFlow 入门之基本使用</strong><br />
<a
href="https://www.cnblogs.com/flyu6/p/5555161.html">https://www.cnblogs.com/flyu6/p/5555161.html</a></p>
<p><strong>(7) Tensorflow学习笔记2：About Session, Graph, Operation and
Tensor</strong><br />
<a
href="https://www.cnblogs.com/lienhua34/p/5998853.html">https://www.cnblogs.com/lienhua34/p/5998853.html</a></p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战人品预测之一_国内大数据竞赛平台</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E4%BA%BA%E5%93%81%E9%A2%84%E6%B5%8B%E4%B9%8B%E4%B8%80_%E5%9B%BD%E5%86%85%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B%E5%B9%B3%E5%8F%B0/</url>
    <content><![CDATA[<h1
id="实战人品预测之一_国内大数据竞赛平台">实战人品预测之一_国内大数据竞赛平台</h1>
<p>#算法实战 #xgboost</p>
<h2 id="竞赛平台哪家强">1. 竞赛平台哪家强</h2>
<p> Kaggle是一个很好的竞赛平台，上面大牛很多，代码分享和思路讲解也很棒，但是它的用户信息和数据全都存在google服务器上，虽然网页能看到，但上传下载数据需要连外网，从当前的网络情况看来，只能用VPN，用起来实在太麻烦了。<br />
 国内的大数据竞赛平台，DataCastle和天池也不错，也有奖金。比赛结果后，排名靠前参加答辩的选手会将答辩PPT分享出来，有时也会分享代码。相对来说天池的数据包含丰富的业务场景，更粘近现实情况，有的比赛还提供在计算平台。<br />
 天池和Kaggle都有数据科学家的排行榜，以提供展示实力的途径。</p>
<h2 id="选择竞赛">2. 选择竞赛</h2>
<p> 从时效来看，建议一开始先选择参赛队多的往期题目，最好是获胜者提供了源代的。很多比赛在结束之后仍开放提交代码并提供线上评分（没有奖金），这样边做边学，速度更快，也不会陷入某个比赛无法自拔。<br />
 从难易来看，建议从简单的开始，如果影响因素太多，难以判别哪里出了问题。最好一开始选择纯数据的。</p>
<h2 id="典型问题">3. 典型问题</h2>
<p> 我觉得在实践的过程中，有几类典型问题是需要常试的：<br />
(1) 以xgboost为代表的数据挖掘问题<br />
(2) 自然语言处理相关的问题<br />
(3) 图像处理相关的问题<br />
(4) 关联规则相关问题<br />
(5) 时序相关问题<br />
 本篇中的例子是DataCastle平台的“微额借款用户人品预测大赛”，属于xgboost问题，详见：<br />
 http://www.pkbigdata.com/common/cmpt/微额借款用户人品预测大赛_竞赛信息.html</p>
<h2 id="人品预测项目">4. 人品预测项目</h2>
<h4 id="描述">(1) 描述</h4>
<p> 比赛的主题是通过数据挖掘来分析”小额微贷“申请借款用户的信用状况。提供的特征以x1,x2…表示，也就是说不知道各特征的具体意义。共1400个特征，带标签数据15000个，不带标签数据50000个，最终需要对5000个数据进行预测，上传预测结果，得到线上的AUC评分。<br />
 该题目就属于：数据不多且干净，参赛队近3000支，冠军使用的算法是数据大赛最常用xgboost，他还提供了答辩报告书和源码。</p>
<h4 id="比赛结果">(2) 比赛结果</h4>
<p> 从排行榜看，除第一名最高得分是0.77209，第二名0.76289之外，前400名分数都在0.7-0.735之间。当然这也可能是由于冠军分享了他在比赛中最高得分0.7341的代码，一些人后期使用了他的代码得到了高分。</p>
<h2 id="人品预测初体验">5. 人品预测初体验</h2>
<h4 id="随便找个模型">(1) 随便找个模型</h4>
<p> 第一步下载所有数据，扫了一眼文件格式，随便找个模型，代进去，预测之后上传服务器，以熟悉基本流程。因为是个分类问题，所以随便用了逻辑回归模型。</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>train_x <span class="op">=</span> pd.read_csv(<span class="st">&quot;train_x.csv&quot;</span>)  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>train_y <span class="op">=</span> pd.read_csv(<span class="st">&quot;train_y.csv&quot;</span>)  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>train_x <span class="op">=</span> train_x.drop(<span class="st">&#39;uid&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>)  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>train_y <span class="op">=</span> train_y.drop(<span class="st">&#39;uid&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>)  </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(train_x), <span class="bu">len</span>(train_y))  </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>logreg <span class="op">=</span> LogisticRegression()  </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>logreg.fit(train_x, train_y)  </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(logreg.score(train_x, train_y))  </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>test_output <span class="op">=</span> pd.DataFrame()  </span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>test_x <span class="op">=</span> pd.read_csv(<span class="st">&quot;input/test_x.csv&quot;</span>)  </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>test_output[<span class="st">&quot;uid&quot;</span>] <span class="op">=</span> test_x[<span class="st">&#39;uid&#39;</span>]   </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>test_x <span class="op">=</span> test_x.drop(<span class="st">&#39;uid&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>)  </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>test_y <span class="op">=</span> logreg.predict_proba(test_x)  </span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>test_output[<span class="st">&quot;score&quot;</span>] <span class="op">=</span> test_y[:,<span class="dv">1</span>]  </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_output[:<span class="dv">10</span>])  </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>test_output.to_csv(<span class="st">&#39;input/test_y.csv&#39;</span>, index<span class="op">=</span><span class="va">False</span>)  </span></code></pre></div>
<p> 看了一下，本地得分0.898xxx，觉得还不错，上传之后，在线得分0.51xxx，这得分和瞎蒙差不多。看了一下数据才发现，正反例数据比例不一致，正例占比0.8982，汗……不过好歹跑通了。</p>
<h4 id="尝试优化">(2) 尝试优化</h4>
<ol type="i">
<li><p>本地得分与在线得分<br />
 得分差异主要是正反例数据比例不一致引起的，它使得本地得分没什么参考价值，因为做得再差也能得到0.89左右的评分，而改进一点并不明显。<br />
 面对这种情况，比较简单的方法就是使正反例个数相同，为了不损失数据，我使用了重复加反例的方法，处理之后本地评分和线上评分就比较接近了。（有的模型支持roc_auc，直接设置也可以）</p></li>
<li><p>分开训练集和测试集<br />
 把带标签数据分成9:1，分别用于fit和score。因为之前加了反例，切分时需要先打乱顺序，避免反例都被分入了测试集。这样结果看起来，就正常多了。</p></li>
<li><p>尝试多个模型<br />
 尽管知道最终会使用xgboost，还是尝试了几个分类模型，发现有的模型本地得分是1.0，因为没分开训练和测试集，发生了过拟合，继续汗……<br />
 试了几种简单的树模型，得分比较高的是ExtraTreeClassifier()。树最重要的是限制过拟合，比如用min_samples_split或max_depth限制分支条件和树深。</p></li>
<li><p>尝试降维<br />
 1400个特征实在太多了，用50000个无标注数据计算PCA降维，观察数据降维后，前15维占有效数据的0.9999以上，所以使用PCA将1400维数据降到15维，再使用模型分类，效果变差很多，根本没法用。不过我觉得当特征特别多的时候，还是可以做PCA，然后用特征值最大数据做散点图分析数据。有助于选择分类器。<br />
 估计可能是缺失数据太多影响了PCA效果，于是尝试了SelectPercentile缩减特征值，它的原理是根据自变量和因变量的相关性降维，当缩特征数减到50%时，线上得分差别0.001以下，当缩减到10%时，正确率只有一半。</p></li>
<li><p>缺失数据<br />
 观察了一下数据，很多-1值，我试用均值mean填充了一下，效果不好，线上得分还下降了，估计是有的列缺失值太多引起的。</p></li>
</ol>
<h4 id="第一天的尝试结果">(3) 第一天的尝试结果</h4>
<p> 最终使用sklearn自带的gdbt算法，简单调参的情况下，得到了0.68*9的线上得分，名次在440名左右。为节省时间，未做更多尝试，开始学习冠军代码（见下篇）。</p>
<h2 id="收获">6. 收获</h2>
<h4 id="保存模型">(1) 保存模型</h4>
<p> 尝试PCA时，每计算一次PCA时间都很长，于是把PCA模型保存下来，节约了重复计算的时间，具体使用joblib库。</p>
<h4 id="评分">(2) 评分</h4>
<p> 不能每做一次都上传服务器，所以本地评分非常重要，一定要先把正反例比例，切分测试集和训练集这样的低级错误排查一遍。否则，根本没法评价优化是否成功。</p>
<h4 id="修改前先预测">(3) 修改前先预测</h4>
<p> 不要想当然地做降维，也不要因为数据多，开始就切数据，或者缩减实例。一定要先用基础数据做一遍后再优化。</p>
<h4 id="解决正反例分布不平衡问题假设正多负少">(4)
解决正反例分布不平衡问题（假设正多负少）</h4>
<ol type="i">
<li>把正样本分为几组，分别和负样本做模型，然后用Bagging集成<br />
</li>
<li>在负样本中有放回抽样，使正反比例一致。<br />
</li>
<li>负样本重复若干次，使正反比例一致。<br />
</li>
<li>用近邻的方法模拟负样本，使正反比例一致。</li>
</ol>
<h4 id="缺失值的处理">(5) 缺失值的处理</h4>
<ol type="i">
<li><p>什么是缺失值？<br />
很多时候，空值并不直接以Nan或”,,”这样的方式出现，有时是0，有时是-1，一定要直接看数据。</p></li>
<li><p>缺失值有哪些影响？<br />
缺失值多的情况下，不止降低预测效果，对降维也有影响。当缺失值太多，又想降维时，可使用SelectKBest系工具，它是根据自变量和因变量的相关性降维的方法。</p></li>
<li><p>缺失值怎么处理？<br />
如果缺失值太多，考虑去掉该特征，因为它可能是噪声，至于怎么界定“太多”，还要分析具体数据（具体见下篇）。<br />
对于连续值，可用中数填充，均值，插值，随机数填充等。<br />
对于离散值，可用一个特殊值填充缺失数据。</p></li>
</ol>
]]></content>
      <tags>
        <tag>算法实战</tag>
        <tag>xgboost</tag>
      </tags>
  </entry>
  <entry>
    <title>实战人品预测之三_向高手学习</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E4%BA%BA%E5%93%81%E9%A2%84%E6%B5%8B%E4%B9%8B%E4%B8%89_%E5%90%91%E9%AB%98%E6%89%8B%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="实战人品预测之三_向高手学习">实战人品预测之三_向高手学习</h1>
<p>#算法实战 #xgboost</p>
<p> 这是本系列“实战人品预测”的最后一篇：向高手学习。在之前的两篇：《实战人品预测之一_国内大数据竞赛平台》和《实战人品预测之二_热门模型xgboost》中我们尝试了DataCastle平台的“微额借款用户人品预测大赛”，对数据不做任何处理，仅用xgboost模型，经过50000次迭代，最终得分0.70，据说该代码最高得分可到0.717。距比赛中的最高分0.734仅0.017之差。前400名得分均在0.70以上，这最后的差距究竟在哪？<br />
 本篇以学习冠军“不得直视本王”（后简称大王）的竞赛报告书和代码的方式，向大王致敬，同时对比自己的不足，开拓思路，学习一些书本上没有的实战技巧。<br />
 竞赛报告书原文：http://blog.csdn.net/bryan__/article/details/50977513，内附源码地址。</p>
<h2 id="思路">１. 思路</h2>
<p> 我们看到大多数挖掘比赛都不修改模型，甚至上来就直接代入xgboost。参赛者的主要的工作是：特征工程，模型调参，组合模型。模型调参在上篇上已经详细说过了，本篇以介绍特征工程和组合模型为主。</p>
<h2 id="特征工程">２. 特征工程</h2>
<p> 下面列出了大王在特征工程中所做的工作，带*的是一些较新的思路。</p>
<h4 id="样本与缺失值">(1) 样本与缺失值 *</h4>
<p> 统计各样本的缺失值数据，把缺失值个数也作为一个特征，并用它排序，做图观测缺失值的分布规律。并剔除缺失值高于某一边界值的数据。</p>
<h4 id="one-hot-encoding">(2) One-Hot Encoding</h4>
<p> 有些算法只支持数值型数据，在枚举字段到数值型的转换过程中，如果把“男”，“女”，“小孩”，变为0,1,2，则“男”与“小孩”间的距离为２，大于“男”与“女”间的距离，这并不合理。于是变为{0,0,1},{0,1,0},{1,0,0}，这就是One-Hot编码。<br />
 具体实现使用工具：from sklearn.preprocessing import OneHotEncoder</p>
<h4 id="排序特征">(3) 排序特征 *</h4>
<p> 如果表中存储的是期末考试成绩，实例是人，特征是科目，那么排序特征就是某人在此科目的排名。这么做是为了加强对异常数据鲁棒性。<br />
 实现方法形如：<br />
test_rank['r'+feature] = test[feature].rank(method='max')<br />
 大王代码中的svm就是用排序特征做的，成绩0.69。</p>
<h4 id="离散特征">(4) 离散特征</h4>
<p> 使用排序特征做等量划分离散化。使用成绩的例子，就是把每个科目排序再分成10个组1-10。如果排名对应到其中一个组，你的值是3，则说明你的排名在20%-30%之间。</p>
<h4 id="记数特征">(5) 记数特征</h4>
<p> 离散特征累加得到记数特征。用n1…n10表示，n5中存的是离散特征中有几个5，以此类推。<br />
 排序特征-&gt;离散特征-&gt;记数特征，也是数学意义上的层层抽象。程序通过feature.csv对不同类型的数据拆分处理。并把新生成的特征（离散，记数…）和旧有特征放在一起，再做特征筛选。</p>
<h4 id="特征筛选feature_select">(6) 特征筛选（feature_select）*</h4>
<p> 由于缺失数据太多，影响了相关性，大王也使用了特征选择，而非降维。对于原数据，排序数据，离散数据使用的都是xgb做的特征选择，xgb提供的get_fscore()函数，可取得特征评分。<br />
 原理是xgb是一个boosting模型，它会在迭代过程中不断给上一次分错的特征加权，最终使得不同特征具有不同权重。</p>
<h2 id="组合模型">３. 组合模型</h2>
<p> 代码中M1-M5目录分别是大王不同的尝试</p>
<h4 id="m1">(1) M1：</h4>
<p> 独立模型，包含了单独使用xgboost和svm的代码。</p>
<h4 id="m2">(2) M2：</h4>
<p> Bagging方式抽取特征，预测后取平均。</p>
<h4 id="m3">(3) M3：</h4>
<p> 模型融合，主要是融合差异大的模型，然后对模型预测出的结果加权平均。</p>
<h2 id="半监督学习">４. 半监督学习</h2>
<h4 id="m4">(1) M4：</h4>
<p> 预测的无标签数据，其中score得分低于a或高于b的加入训练集，通过线上评分评测，调整a,b不断迭代。以扩充训练集。</p>
<h4 id="m5">(2) M5：</h4>
<p> 预测的无标签数据，做多次xgboost，选取线下auc提升最大的组合top500，从中抽实例加入训练集，观测线上表现，保留提分的样本。<br />
 观测线上表现，保留提分的样本，是比赛特有的方法。这也是为什么有些比赛，明明数据不充分，也有人达到了100%的线上正确率的原因。</p>
]]></content>
      <tags>
        <tag>算法实战</tag>
        <tag>xgboost</tag>
      </tags>
  </entry>
  <entry>
    <title>实战人品预测之二_热门模型xgboost</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E4%BA%BA%E5%93%81%E9%A2%84%E6%B5%8B%E4%B9%8B%E4%BA%8C_%E7%83%AD%E9%97%A8%E6%A8%A1%E5%9E%8Bxgboost/</url>
    <content><![CDATA[<h1
id="实战人品预测之二_热门模型xgboost">实战人品预测之二_热门模型xgboost</h1>
<p>#算法实战 #xgboost</p>
<h2 id="介绍">1. 介绍</h2>
<p>有人戏称数据挖掘比赛为GBDT调参大赛，因为在很多比赛后期，大家都使用GBDT类的算法，特征类似，只有模型参数不同，模型集成方法不同，最终大家的成绩差别也很小。</p>
<p>上篇《实战人品预测之一_国内大数据竞赛平台》，介绍DataCastle平台的“微额借款用户人品预测大赛”比赛规则，以及一些初步的尝试。本篇说说最终获胜的，也是GDBT类算法中使用频率最高的xgboost算法的使用和调参方法。</p>
<h2 id="xgboost原理">2. xgboost原理</h2>
<p>之前在《机器学习_集成算法》篇（http://www.jianshu.com/p/3c8cca3e1ca2）中介绍过GBDT类的算法，简单回顾一下：</p>
<p> Boosting算法不断地使用同一算法（比如决策树）建立新模型，而新模型分配给上一次错分样本更大的权重，最终根据按成功度加权组合得到结果。由于引入了逐步改进的思想，重要属性会被加权。</p>
<p>Gradient Boosting
Machine（GBM）梯度提升算法是目前比较流行的数据挖掘模型，它通过求损失函数在梯度方向下降的方法，层层改进，是泛化能力较强的算法，常用于各种数据挖掘比赛之中。常用的工具有XGBoost，LightGBM，sklearn提供的GradientBoostingClassifier等等。GBM常把决策树作为基模型，我们看到的GBDT梯度提升决策树，指的就是该算法。</p>
<h2 id="xgboost简单使用">3. xgboost简单使用</h2>
<h4 id="安装库">(1) 安装库</h4>
<p>xgboost是一个独立的软件包，需要单独安装</p>
<pre><code>$ pip install xgboost  </code></pre>
<h4 id="示例代码">(2) 示例代码</h4>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb  </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> xgb.XGBClassifier()  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>model.fit(train_x, train_y)  </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>model.score(test_x, test_y)  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>test_y <span class="op">=</span> model.predict(test_x)  </span></code></pre></div>
<h2 id="xgboost与sklearn">4. xgboost与sklearn</h2>
<p>xgboost提供了两种接口，一种是它自身的调用接口，另一种与sklearn的调用方式一样，上面的代码使用的是sklearn调用方式，它让用户能很快从sklearn的GBDT转到xgboost上。（不只xgboost，很多数据挖掘库都提供类似sklearn的调用方法）</p>
<p>另外一个好处是，它能与sklearn的工具GridSearchCV结合，实现自动调参，后面细说。</p>
<h2 id="xgboost参数">5. xgboost参数</h2>
<p>[[XGBoost_参数#参数]]</p>
<h2 id="调参">6. 调参</h2>
<p>当我第一次用xgboost替代了sklearn的
gdbt时，同样是默认参数，在不调参的情况下，成绩下降了0.05，主要是由于xgboost默认参数导致的，后来使用了冠军的参数，大概有0.02的提升。这说明调参是必须的。<br />
[[XGBoost_参数#调参]]</p>
<h2 id="总结">7. 总结</h2>
<p>通过本次实验，明显看到xgboost好处，比如支持多线程，可调节正反例权重，自带交叉验证，处理缺省值，包含了很多预处理的工作。</p>
<p>使用冠军代码做预测，没加任何的特征处理和其它算法的情况下，迭代共进行了50000次，线上得分超过0.7，这个得分和比赛结束时的最高分0.734已经差不太多了。每次打印出AUC值，能明显看出它的进化过程：不断迭代，直到收敛。从原理上看，该算法在基础参数没问题，在机器算力也足够的情况下，应该可以取得接近最佳的成绩。</p>
<p>扩展地看，增加错误权重，不断迭代的集成算法，与多算法结合效果都不错，具体可以参考sklearn自带工具AdaBoost。</p>
]]></content>
      <tags>
        <tag>算法实战</tag>
        <tag>xgboost</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据竞赛平台——Kaggle入门</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B%E5%B9%B3%E5%8F%B0%E2%80%94%E2%80%94Kaggle%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h1 id="大数据竞赛平台kaggle入门">大数据竞赛平台——Kaggle入门</h1>
<p>#算法实战</p>
<p> 在学习了一些数据挖掘和机器学习的算法之后，需要积累实际开发经验。在实践的过程中不仅需要自己摸索，还需要向牛人学习和请教。Kaggle就提供这样的数据平台，企业或者研究者可以将数据、问题描述、期望的指标发布到Kaggle上，开发者其数据下载到本地，分析，处理后将结果上传，Kaggle将结果排名显示，有的比赛设有资金。Kaggle还有活跃的讨论区，供大家交流。</p>
<h2 id="如何使用kaggle">如何使用Kaggle</h2>
<p> 我们先来看看，Kaggle的具体使用方法。在竞赛界面中https://www.kaggle.com/competitions，可看到比赛分类：Getting
Start，Playground，Featured，Research等（用不同颜色区分）．建议初学者从Getting
Start级别开始，在这个级别上可以看到更多的教程和代码分享，题目也比较简单，适合入门．</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-a67bfe7e3e509f9f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="competitions" />
<figcaption aria-hidden="true">competitions</figcaption>
</figure>
<p> 以参赛队最多的Tinanic沉船问题为例．https://www.kaggle.com/c/titanic．它的目标是预测乘客是否幸存．</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-469498f8b078de94.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="Titanic" />
<figcaption aria-hidden="true">Titanic</figcaption>
</figure>
<p> 界面中提供了问题描述（Overview），数据下载（Data），示例代码（Kernels），讨论区（Discussion），排行榜（Leaderboard），和规则（Rules）．</p>
<p> 数据一般是csv格式，它提供了含用条件和结果是训练样本（train.csv），只有条件没有结果的测试样本（test.csv），开发者用训练样本训练出模型，并对测试样本进行预测，预测的结果根据格式要求（gender_submission.csv）保存成文件，上传到Kaggle网站，网站给预测结果评分并排名。</p>
<p> Kernels中有开发者共享的解题思路和代码，大多数是用Python或Ｒ语言实现的。</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-dcc7862848b41ab1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="Kernels" />
<figcaption aria-hidden="true">Kernels</figcaption>
</figure>
<p> 例如Omar El Gabry的A Journey through
Titanic就是一个很好教程，它包含了读取数据，处理数据，导出结果的整个过程。用seaborn库图形化分析各个属性（见下图），使用sklearn库作为数据挖掘工具。其中有对数值类属性均值和标准差的计算，对枚举类属性的拆分/组合，处理各种缺失值，以及用人类常识调整特征，比如将父母兄弟配偶统一归入家庭关系，将16岁以下的男女统一归类为儿童等等，还计算了每个属性和结果的相关系数，是一个非常好的特征工程入门范例。在算法方面，它使用了sklearn提供的逻辑回归，SVM，随机森林，最近邻，朴素贝叶斯等方法训练。</p>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-c7bdc6e857ff47f5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="seaborn" />
<figcaption aria-hidden="true">seaborn</figcaption>
</figure>
<p> 训练之后开发者可通过Submit Predictions上传自己的预测结果（注意Submit
Predictions按钮登录后才显示），就可以看到排名了。<br />
这里提供了大量的数据，我们可以借此尝试求解各种类型的问题，同时参考他人的经验分享，快速提高实践能力。当再拿到一份新数据时，至少有一个思路。</p>
<h2 id="为什么用kaggle">为什么用Kaggle</h2>
<p> 在网上看过一篇文章，题目大概是《Kaggle对找工作有什么好处》，其中的答案是“没有”，因为初学者很难在Kaggle中拿到名次，参与程度可深可浅，无法通过它判断你的水平。我觉得Kaggle不是一个贴标签的东西，可以把它作为练习的场地，以及和高手学习机会。</p>
<p> 我们之前看到的书基本都是一个算法，一个算法的讲，当学习了一些算法之后，它们是零散的点，需要在用的过程中把这些点串起来，具体应用中有很多坑，需要自己踩一遍，和照着书打代码是完全不同的，而Kaggle正好给我们提供了这样的数据和评价体系。</p>
<p> 有人说，那我也可以自己拿爬虫抓数据啊，而且我可以找我更有兴趣的数据来做．对于自己找的数据，当对预测结果满意的时候，很难判断到底是数据本身的信息量不够，还是算法不好．Kaggle上是很多人同时比赛，只要拿自己的成绩和Top1的比一比，就能判断是什么问题了，而且很多人会在Kernels中公布算法，在Discussion中讨论，我们也可以在其中提出自己的问题。最重要的是这个过程中，你和他们在思考同一个问题，这种学习即不是填压式的，又可以给你引导。如果能够做到排名靠前就更好了。</p>
<h2 id="kaggle遇到的问题">Kaggle遇到的问题</h2>
<p> 使用Kaggle中遇到的最大问题连不上外网，比如：注册后，在邮箱中点击激活时，出现＂You
did not enter the correct captcha response. Please try
again＂，这是由于连接google失败导致的。不过只有在注册，下载，上传文件时需要连接外网。</p>
<p> 现在访问外网越来越难了，建议买一些收费的流量（注册激活用不了一两兆），有的工具第一次注册会送你几百兆流量．比较麻烦的是Kaggle的数据都是存在google
storage上的，所以下数据时也要连外网．不过像上例中的纯文本数据，也用不了几百K.</p>
]]></content>
      <tags>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战天池精准医疗大赛——复赛之妊娠糖尿病与基因数据分析</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E5%A4%A9%E6%B1%A0%E7%B2%BE%E5%87%86%E5%8C%BB%E7%96%97%E5%A4%A7%E8%B5%9B%E2%80%94%E2%80%94%E5%A4%8D%E8%B5%9B%E4%B9%8B%E5%A6%8A%E5%A8%A0%E7%B3%96%E5%B0%BF%E7%97%85%E4%B8%8E%E5%9F%BA%E5%9B%A0%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1
id="实战天池精准医疗大赛复赛之妊娠糖尿病与基因数据分析">实战天池精准医疗大赛——复赛之妊娠糖尿病与基因数据分析</h1>
<p>#算法实战 #xgboost</p>
<h2 id="说明">1. 说明</h2>
<p> 初赛提供的是血常规，肝功能，肾功能，生化的检验结果，预测血糖的具体值。复赛加入了SNP的五十多个位点数据，预测被试者是否为妊娠糖尿病，是个二分类问题。下面做了一些简单的数据分析和相关资料采集。</p>
<h2 id="糖尿病相关的snp数据重要性排序">2.
糖尿病相关的SNP数据重要性排序</h2>
<p> SNP数据取值为1,2,3，为枚举值，没有大小关系，因此做onehot编码，转换为形如：SNP1_3，表示SNP1取值为3作为单一特征．
相关性排序描述的是单个特征与结果的相关性，决策重要性描述的是单个特征与其它特征组合后与结果的相关性．
下面均为重要性前十的特征，数字为重要性评分．</p>
<h4 id="相关性排序负号为负相关">1) 相关性排序（负号为负相关）：</h4>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-e49cb4031e127ebe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="决策重要性排序五次交叉验证模型评分累加">2)
决策重要性排序（五次交叉验证模型评分累加）：</h4>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-66ff4910925af6d9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="总结">3) 总结</h4>
<p> SNP34，SNP37在两种排序中均占前4位，可以说是重要性最高的特征，SNP21,
SNP53，SNP40在前十中同时出现，也有较高优先级．</p>
<h2 id="糖尿病相关的其它信息">3. 糖尿病相关的其它信息</h2>
<p> 表中表出重要性前十位的特征，数字为重要性评分</p>
<h4 id="相关性排序">1) 相关性排序：</h4>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-7c106ffeaa82f1cd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="决策重要性排序五次交叉验证模型评分累加-1">2)
决策重要性排序（五次交叉验证模型评分累加）：</h4>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-596f06bfe959b7ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="总结-1">3) 总结</h4>
<p> 特征VAR00007的重性最高，主办方未告知该值的具体含义．比较重要的特征还有：TG（甘油三脂）；孕前BMI，孕前体重，BMI分类（与肥胖有关）；年龄；hsCRP（超敏C-反应蛋白），wbc（白细胞）（与当前身体状况相关）．</p>
<h2 id="数据分析">4. 数据分析</h2>
<h4 id="特征分类与组合">1) 特征分类与组合</h4>
<p> 把特征分为三类：基因信息，秘密信息，其它信息．
其中基因信息是名为SNP*的特征值（归为Ａ类），秘密信息是名为VAR00007的特征值（归为B类），除此之外的其它信息几乎都是描述当前身体状况的信息（归为C类）．
使用GBDT模型，CV=5交叉验证，训练集数据在参数相同的情况下：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-e0ded8c78b35c45d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="分析">2) 分析</h4>
<p> Ｂ类和C类组合后，准确率并没有提升（使用混淆矩阵对比预测结果，B类与Ｃ类一致的预测仅占61％，也就是说结果并不一致，猜测B类和C类特征相关性不大）．当Ｂ类（或C类）信息与A类信息结合后，准确率有明显提升，即：基因信息与其它信息组合后提高预测成功率约5%左右．</p>
<h2 id="相关资料">5. 相关资料</h2>
<h4 id="词汇">1) 词汇</h4>
<ol type="i">
<li><p>SNP 单核苷酸多态性(single nucleotide
polymorphism,SNP)，主要是指在基因组水平上由单个核苷酸的变异所引起的DNA序列多态性。它是人类可遗传的变异中最常见的一种。占所有已知多态性的90%以上。SNP在人类基因组中广泛存在，平均每500～1000个碱基对中就有1个，人类30亿碱基中共有300万以上的SNP．SNP所表现的多态性只涉及到单个碱基的变异．
之前听说的羊水穿刺，就是提取婴儿的DNA，对SNP相应的位点检测。</p></li>
<li><p>TG（Triglyceride） 甘油三酯,血脂的一种．</p></li>
<li><p>hsCRP
超敏C-反应蛋白是机体受到微生物入侵或组织损伤等炎症性刺激时肝细胞合成的急性相蛋白</p></li>
<li><p>apoA1 载脂蛋白</p></li>
<li><p>wbc 白细胞</p></li>
</ol>
<h4 id="糖尿病与基因">2) 糖尿病与基因</h4>
<ol type="i">
<li><p>血液中的葡萄糖只有在有胰岛素的条件才才能进入肌肉，脂肪，肝细胞发挥供能作用。胰岛素释放及细胞摄入葡萄糖之间的平衡可以使得血糖水平保持在一个较小的波动范围。
1型糖尿病（T1D）是因为免疫系统杀死了生产胰岛素的β细胞；2型糖尿病（T2D）是因为代谢紊乱阻碍了胰岛素的正常功能。在2型糖尿病患者体内，由于机体不能产生足量胰岛素，或者机体对胰岛素产生抵抗，血糖水平会升高到过高水平。
此前的糖尿病研究大多是分析基因对免疫系统改变（T1D）和肝脏代谢紊乱（T2D）的影响。遗传学背景是胰腺β细胞生存的关键。有些人的β细胞比较强壮，有些人的β细胞比较脆弱。脆弱的β细胞更容易发展成糖尿病，不论是1型还是2型，β细胞基因缺陷是两种糖尿病的共同根源．</p></li>
<li><p>糖尿病分为1型、2型、特异型和妊娠糖尿病4大类。除特异型糖尿病外，其他类型糖尿病（也可称普通糖尿病）均系多基因病，参与的每个基因对于糖尿病易感性来说必不可少，但其贡献率都不太大，故称其为易感基因。 </p></li>
<li><p>国际上共报告了23个糖尿病易感基因，我国也报告了几个候选易感基因，但经比对发现，在不同地域和不同种族间，其易感基因谱是有区别的。
相关基因包括：定位在１号染色体上的两个小区域中。还有9号染色体上的CDKN2A、CDKN2B基因和定位在3号染色体上的IGF2BP2基因以及CDKALl基因。还有TCF7L2、SLC30A8、HHEX、PPARG、KCNJl1、SREBF2和FTO等．
TM6SF2基因变异与肝脂肪变性(俗称“脂肪肝”)有关，影响着2型糖尿病的风险。（它和脂功指标提供的信息有一定重合）．
一氧化氮合成酶1转接蛋白（NOS1AP）基因。这个基因位点的遗传缺陷可使得中国人Ⅱ型糖尿病的患病风险上升17％。
PAX4的基因的变异与２型糖尿病有关，而这个变异仅发生在中国、韩国、新加坡等东亚国家人群中。</p></li>
</ol>
<h2 id="一些想法">6. 一些想法</h2>
<p> 在数据分析的过程中，有一些感受，不一定对，在此分享一下，糖尿病分成单基因病（特异型糖尿病）和多基因病，我们现在看到最多的二型糖尿病是多基因病，也就是说它是由多个基因共同作用的结果，这种多基因糖尿病估计再过一百年，也不太可能通过编辑基因的方式治疗，因为一个基因可能有多种影响，修改了某个基因之后，这个毛病治好了，可能其它毛病又出来了。<br />
 也治不了，还分析它干嘛呢？从基因的角度看确实有一些人是某种疾病的易感人群，有的是皮肤病，有的是癌症。在没有基因检测的时候，一般通过亲属家人的健康情况来预测，基因检测相对更准确。从数据看来，各种身体指标，比如说免疫力，肥胖，年龄也都起一定作用。<br />
 有了这些技术的支持，就不用因为亲人有某种遗传病，而对自己的健康疑神疑鬼，直接就做检查就好了。如果不幸属于易感人群，多注意相关的诱发因素可以大大降低患病概率，总比去切乳腺强。</p>
<h2 id="参考">7. 参考</h2>
<h4 id="snp的概念和特点">1) SNP的概念和特点</h4>
<p><a
href="https://www.biomart.cn/experiment/430/457/462/15761.htm">https://www.biomart.cn/experiment/430/457/462/15761.htm</a></p>
<h4 id="型糖尿病相关基因的研究进展">2) 2型糖尿病相关基因的研究进展</h4>
<p><a
href="http://www.docin.com/touch/detail.do?id=1724337751">http://www.docin.com/touch/detail.do?id=1724337751</a></p>
<h4 id="型糖尿病的相关基因多态性的研究进展">3)
2型糖尿病的相关基因多态性的研究进展</h4>
<p><a
href="https://wenku.baidu.com/view/3338d9f3f90f76c661371ae8.html###">https://wenku.baidu.com/view/3338d9f3f90f76c661371ae8.html###</a></p>
<h4 id="单核苷酸多态性与2型糖尿病易感基因相关性的研究进展">4)
单核苷酸多态性与2型糖尿病易感基因相关性的研究进展</h4>
<p><a
href="https://wenku.baidu.com/view/0ca204a07375a417876f8f27.html?mark_pay_doc=1&amp;mark_rec_page=1&amp;mark_rec_position=3&amp;clear_uda_param=1">https://wenku.baidu.com/view/0ca204a07375a417876f8f27.html?mark_pay_doc=1&amp;mark_rec_page=1&amp;mark_rec_position=3&amp;clear_uda_param=1</a></p>
<h4 id="上帝的手术刀基因编辑简史">5) 《上帝的手术刀——基因编辑简史》</h4>
<p>作者：王立铭，出版社：浙江人民出版社</p>
]]></content>
      <tags>
        <tag>算法实战</tag>
        <tag>xgboost</tag>
      </tags>
  </entry>
  <entry>
    <title>实战天池精准医疗大赛——复赛总结</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E5%A4%A9%E6%B1%A0%E7%B2%BE%E5%87%86%E5%8C%BB%E7%96%97%E5%A4%A7%E8%B5%9B%E2%80%94%E2%80%94%E5%A4%8D%E8%B5%9B%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1
id="实战天池精准医疗大赛复赛总结">实战天池精准医疗大赛——复赛总结</h1>
<p>#算法实战</p>
<h2 id="说明">1. 说明</h2>
<p> 精准医疗复赛结束，最终排名在20左右。第一名的大神相当厉害，尤其是换数据之后，那分数简直是甩出其他人好几条街，非常想学习一下他的解决方案，可惜答辩定在七月，而且不一定公开，估计到时候都忘了。<br />
 我在复赛中用的是个中规中矩的方案，也在这里记录和分享一下，写得比较随性，各位就别当纯技术文档看了。</p>
<h2 id="特征工程">2. 特征工程</h2>
<h4 id="特征去噪">(1) 特征去噪</h4>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-b358f17e8519921b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 噪声数据是在最后一天才发现的，原因是训练集加入Ａ榜答案之后，线下分数反而下降了，于是怀疑A榜数据是不是有什么问题？在检查过程中，阴错阳差地发现，有一些特殊值高出正常值几十倍，比如说有个BUN（血尿素氮）为2055，另外ApoA1和ApoB1存在数据单位不一致的问题，然后对它们进行了修正。<br />
 在本问题中，噪音数据比较容易发现，一方面是特征不多，可以人工过滤，别一方面体验指标有可参考范围，容易界定是否为异常值。如果数据多或者经过了脱敏处理，就需要一些更精确的算法，比如离群点检测等等。</p>
<h4 id="特征分类">(2) 特征分类</h4>
<p> 在本问题中，把特征分成两类：基因数据和其它数据。基因数据是以SNP开头的，取值为1,2,3，估计是位点信息，其值没有大小关系，因此作为枚举类型处理，做了onehot变换。其它特征均作为数值型处理。（注：SNP主要是指在基因组水平上由单个核苷酸的变异所引起的DNA序列多态性。）</p>
<h4 id="标准化">(3) 标准化</h4>
<p> 对数值型数据处了标准化处理，即：新数据=(原数据-均值)/标准差。然后将数值型的缺失值全部填充为０，即均值。</p>
<h4 id="缺失值处理">(4) 缺失值处理</h4>
<p> 对SNP数据的缺失值处理试验了三种方法：<br />
 第一种是做onehot后不处理缺失值，即1变成[1,0,0], 2变成[0,1,0],
3变成[0,0,1]，缺失变成[0,0,0]。<br />
 第二种是取出现次数最多的值作为缺失值，比如大多数都是2，则缺失值设为2。<br />
 第三种是填加一种新值代表缺失值，这种方法线下效果最好，最终采了此方法。</p>
<h4 id="特征调整">(5) 特征调整</h4>
<p> 去掉了孕前体重和身高，因为特征中还包括了孕前BMI，从经验看BMI可以取代体重和身高带有的信息，从数据看，删掉后的确有所提升。也尝试删掉其它一些特征和特征组合，效果都不明显。<br />
 有一些干扰特征，比无用特征更麻烦，从特征重要性排序看，还挺靠前，其实是来捣乱的。就比如说，有人被杀了，刚好XX早上和他打了一架，于是大家把XX当成重要嫌疑人，结果真凶跑了。</p>
<h2 id="算法模型">3. 算法模型</h2>
<p> 模型使用的是xgboost的分类，5折交叉验证。这类问题大多数都使用梯度提升决策树算法（GBDT类），只是具体工具有所差别。<br />
 这里主要的技术点是调参，我是用sklearn的GridSearchCV实现调参。其中一个核心的参数是scale_pos_weight，它指定了正反例的权重，直觉是：“患病者”的数据应该更重要。这个值我也是通过调参找到了训练集对应的最佳值。设置后A榜成绩提高了，Ｂ榜试的少没法下结论。<br />
 使用scale_pos_weight引发的问题是，预测的结果分布和训练集不一致。如果想要分布一致，简单地可以把判断标准从0.5向上或向下调，规范的一点的方法是做排序之后取前N个。<br />
 大家好像都看到了结果的分布问题，于是最后一天，在群里讨论预测结果里有多少个1？这又涉及了复赛的评分指标F1。</p>
<h2 id="评分指标">4. 评分指标</h2>
<p> 复赛的评分指标是F1分数（F1
Score），是统计学中用来衡量二分类模型精确度的一种指标。它同时兼顾了分类模型的准确率和召回率。F1分数可以看作是模型准确率和召回率的一种加权平均，它的最大值是1，最小值是0．<br />
f1=(2<em>P</em>R)/(P+R)<br />
其中P的精确率（预测正确的正样本/预测的正样本），R是召回率（预测正确的正样本/实际正样本）．<br />
 简单的说，如果瞎蒙一半对一半错，F1在0.5左右，如果蒙全1，F1为0.667。看起来，如果拿不准就蒙成1，胜算更大。</p>
<h2 id="其它尝试">5. 其它尝试</h2>
<p> 还尝试了一些其它方法，但都因效果不佳，没用到最终代码里，也在此分享一下思路。<br />
(1) 模型融合：将同一模型，不同参数的概率结果取均值作为预测。<br />
(2)
取更多的1：针对评价标准，调高scale_pos_weight，使预测中含更多的1。<br />
(3) 组合和去掉一些特征：用循环组合的方式加入和去掉一些特征。<br />
(4) 取各模型的TopX值：取各个模型分别认为最可能患病的实例。</p>
<h2 id="结果分析">6. 结果分析</h2>
<p> 分析了一下模型预测的结果，基本分为三部分：<br />
 第一种：各个算法的结论一致，并且是对的。<br />
 第二种：各个算法的结论一致，并且是错的。<br />
 第三种：各个算法的结论不一致，有对有错。<br />
 前两种往往混在一起的，算法都得到了一致的结论，能查出来就查出来了，查不出来也没办法了，毕竟数据也并非携带了所有信息。而第三种是疑似状态，也正是检验算法的关键。</p>
<h2 id="遗憾和教训">7. 遗憾和教训</h2>
<p> 遗憾的是还有一些算法，不同算法的组合，特征组合，尤其是不同基因的组合，还都没有尝试，就结束了。教训也很多：<br />
(1)
不要试图参加deadline时间相近的多个比赛，时间不够，就没法做大的修改。<br />
(2) 数据量小的比赛里暂时领先并不说明能模型好，很可能是过拟合了。<br />
(3) 多看，仔细看别人的方案，少做“重复造轮子”的事情。<br />
(4) 不要总是使用熟悉的工具，在这种比赛里尝试更重要。</p>
<p> 除了加强技术以外，安排，心态也都很重要。总之，成绩不好，就是还有提升空间，继续努力中。</p>
]]></content>
      <tags>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战天池精准医疗大赛——观看答辩总结</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E5%A4%A9%E6%B1%A0%E7%B2%BE%E5%87%86%E5%8C%BB%E7%96%97%E5%A4%A7%E8%B5%9B%E2%80%94%E2%80%94%E8%A7%82%E7%9C%8B%E7%AD%94%E8%BE%A9%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1
id="实战天池精准医疗大赛观看答辩总结">实战天池精准医疗大赛——观看答辩总结</h1>
<p>#算法实战</p>
<h2 id="说明">1. 说明</h2>
<p> 今天是天池精准医疗大赛（糖尿病预测）的最终答辩，学习了一下前六名的经验分享．把自己没想到的列出来，如下．</p>
<h2 id="特征">2. 特征</h2>
<ol type="1">
<li><p>多特征组合：<br />
一般是现有特征加减乘除的组合，在特征多的情况下，先取强特征相互组合<br />
．<br />
</p></li>
<li><p>数据分析：<br />
常用分析方法：IV值分析（information
value），方差，残差，单变量分析，PCA等等．<br />
特征的相关性与去冗余：特征和结果的相关性分析可能找不出一些非线性相关，但是特征之间的强相关，可以帮助去掉一些冗余．<br />
小数据集中某些特征，可能引起过拟合．</p></li>
<li><p>缺失值填充：<br />
Nuclear，MICE，最近邻填充．<br />
对于不同缺失比例，可使用不同方法填充．</p></li>
<li><p>单指标特征概率相对分布图<br />
衡量单变量在取值变化过程中，正负样本比例随取值变化的一个相对变化程度的总结（这个值与相关性差别很大）．可以在去掉和不去掉缺失值的情况下，分别统计．<br />
连续特征／离散特征使用不同的统计方法：QQPlot，四分位图．</p></li>
<li><p>将不同特征划分为不同的训练集和测试集．<br />
这可能是一种人为的预分类．</p></li>
</ol>
<h2 id="算法">3. 算法</h2>
<ol type="1">
<li><p>因子分解机FM</p></li>
<li><p>适合小数据量的catboost模型</p></li>
<li><p>用遗传算法调参</p></li>
<li><p>模型级联<br />
先用A算法筛，筛出的疑似再用其它算法筛．<br />
弱模型组合时需要注意模型差异性．</p></li>
<li><p>分类时可用回归模型，回归时可用分类模型</p></li>
</ol>
<h2 id="最终结果处理">4. 最终结果处理</h2>
<ol type="1">
<li><p>把重要数据和规则存下来，在没模型的情况下也能使用．</p></li>
<li><p>除了精确度，还要考虑实例数量，如某种情况下可能100%得病，但人数少．</p></li>
</ol>
]]></content>
      <tags>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战天池精准医疗大赛之一_数据分析</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E5%A4%A9%E6%B1%A0%E7%B2%BE%E5%87%86%E5%8C%BB%E7%96%97%E5%A4%A7%E8%B5%9B%E4%B9%8B%E4%B8%80_%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1
id="实战天池精准医疗大赛之一_数据分析">实战天池精准医疗大赛之一_数据分析</h1>
<p>#算法实战</p>
<h2 id="赛题说明">1. 赛题说明</h2>
<p> 天池精准医疗大赛——人工智能辅助糖尿病遗传风险预测，这是明天即将开始的天池大数据比赛。赛题名字看起来很高深，其实是根据年龄，性别，肝功，血常规等体验指标，预测血糖值。数据挺少的，特征40个左右，训练集5000多个实例，测试集1000个实例。任何机器都能很快跑完。比赛地址：<br />
https://tianchi.aliyun.com/competition/introduction.htm?spm=5176.100066.0.0.57e6e8dfMg8Z8V&amp;raceId=231638</p>
<h2 id="预处理">2. 预处理</h2>
<h4 id="缺失数据">(1) 缺失数据</h4>
<p> 有大量的缺失值，特征分四类，分别是乙肝、血常规、肝功能、肾功能，一般的缺失值都是缺失整个类别数据（由于患者未做某项检查）。除血常规以外，其余三项都有大量的缺失值，尤其是乙肝类检查，多一半都是空值。
如果去掉这些数据，将会损失3/4的数据量。假设：医生不要求做该项检查，说明他认为该项指标基本正常，则在指标的正常范围内取随机值填充。</p>
<h4 id="其它操作">(2) 其它操作</h4>
<p> 替换去掉其中中文字符</p>
<h2 id="数据分析">3. 数据分析</h2>
<h4 id="相关性分析">(1) 相关性分析：</h4>
<p> 岁数与血糖的相关性最大为0.32，甘油三酯相关性0.23，还有年龄，碱性磷酸酶，白细胞计数等6项指标在0.15左右。(data.corr(),
data.cov())</p>
<h4 id="pca降维">(2) PCA降维：</h4>
<p> 前15个特征约占信息量的99.8%</p>
<h4 id="分析血糖值分布">(3) 分析血糖值分布：</h4>
<p>绝大多数分布在4-15之间，比赛前期可将此范围之外的认为噪声。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-afd12dd5c907f593.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="算法">4. 算法</h2>
<h4 id="算法分析">(1) 算法分析</h4>
<p> 这是一个有监督的回归问题，此比赛基本可以定位成特征工程加调参问题。预计先使用GBDT和随机森林，后面集成多个模型。
因为数据少，主要注意过拟合问题，可能使用先分类后回归的方式。注意回归不是按正确率计算结果的，此题根据题目要求，评估指标为MSE</p>
<h4 id="迭代分析">(2) 迭代分析</h4>
<p> 左图是迭代与误差的关系，迭代到100次后，测试集误差不再下降，训练集还在下降，好像开始过拟合，当然这与我设置的学习率相关，右图是迭代后计算的特征权重排序。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-96294e508d3a1846.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="查看预测的主要出错位置">(3) 查看预测的主要出错位置</h4>
<p> 从训练集中切出10%作为测试，蓝线是实际值，橙线为预测值，可以看到，由于大部分值分布在5-6之间，因此所有预测都被拉到了这个区间之内。
忽然想到之前“微信互动”预测中有一种做法，就是找到一个值，将训练集中所有实例都预测成该值，再计算误差。代入此题，试了一下，设为5.6分时误差最小，为2.4，比gbdt的2.2误差略高一些，说明算法比瞎蒙还是好一点。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-04353b079c45aa5e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="一些想法">5. 一些想法</h2>
<ol type="1">
<li><p>一般去医院看病有问题的居多，所以相对正常值有些偏差，医生也可能作出有倾向性的判断。</p></li>
<li><p>该题可以把已有的知识和算法融合，使用一些现成的数据，比如正常范围。</p></li>
<li><p>周末检查拿结果的可能是比较特殊的病人。</p></li>
<li><p>岁数分成几段，更具代表意义。</p></li>
<li><p>可将数据修改为正常值，偏高，偏低，几个层次，做分段特征。</p></li>
<li><p>考虑病情比较严重的情况，可能需要分开处理，作为噪点先拿出来。</p></li>
<li><p>预测只是想知道被测试人是否为糖尿病，而不关注是预测与实际值的微小差距，所以也可以将其处理为分类问题。</p></li>
<li><p>可能需要对误差函数和评价函数做微调。</p></li>
</ol>
<h2 id="一些尝试">6. 一些尝试</h2>
<ol type="1">
<li><p>在本地测试，删除所有缺失数据的实例，预测效果好很多。</p></li>
<li><p>如不考虑大于10的数据，预测效果好很多。</p></li>
<li><p>目前在特征工程方面，只做了修改缺失值，而排序特征，离散特征，统计特征都还没做，算法方面只使用了sklearn自带的gbdt，其它算法也还没试。</p></li>
</ol>
]]></content>
      <tags>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战天池精准医疗大赛之三_分类回归与排序</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E5%A4%A9%E6%B1%A0%E7%B2%BE%E5%87%86%E5%8C%BB%E7%96%97%E5%A4%A7%E8%B5%9B%E4%B9%8B%E4%B8%89_%E5%88%86%E7%B1%BB%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h1
id="实战天池精准医疗大赛之三_分类回归与排序">实战天池精准医疗大赛之三_分类回归与排序</h1>
<p>#算法实战</p>
<h2 id="说明">1. 说明</h2>
<p> 开赛第一周挣扎在前100的边缘，第二周挣扎在前20的边缘，第三周懒得弄了，坐等换数据。初赛的前100名可进复赛，所以在前100中排名前后也没啥意义，开始的时候觉得自己分数蒙的成份很高，换了数据就完蛋，然后不断改进，坐实；后来就有点瞎叫劲了。又傲娇又胆小，也没结交到队友，至今还是孤军作战。记录一下本周收获，也不知这些都公开之后会不会被打出排行榜[哭脸]。</p>
<h2 id="分类与回归">2. 分类与回归</h2>
<p> 所有回归都可以抽象成分类，比如训练集有100个数，最差的情况下就是分成100个类，或者处理成99次二分类。而对于具体数值的回归，可通过其所属类别中的元素计算，比如：中值，均值，期望值，评估函数最佳值等等。<br />
 细数参与过的几个比赛：医疗大赛是切分正常和糖尿病，微博互动是切分正常和巨量互动，淘宝穿搭是切分普通组合和常见的组合，人品预测是切分普通和人品不好的，股票是切分普通和大涨的。基本都是从正常中寻找反常数据，几乎都可以当成不均衡的分类问题处理，而且它们有个共同的特点，就是越特殊的值权重越大，比如说预测对一个高血糖值对评分的贡献多过上百个普通值。<br />
 把分类理解成数据的抽象，可简化问题，也可以在其上运用复杂的计算。同样是使用GBDT类的算法，分类就比回归灵活很多，尤其是二分类。</p>
<h2 id="排序rank">3. 排序（Rank）</h2>
<p> 排序可以视为一种算法，或者算法中的一个实用的小工具。比如特征工程中的排序特征，排序更常见的是用在评价函数之中。<br />
 比如本题原本是一个回归问题，我们把它当成分类处理，分类的边界划在哪？是界定正常值的6.1，还是界定糖尿病的11.1，还是中值？问题的核心是：把从黑到白的柔和过渡通过划边界描述成了非黑即白的二元对立——人通常也是这么做的，比如，把人分为好人与坏人。<br />
 排序提供了一种辅助的方法：它把所有人排了序，越靠前是好人的可能性越大。如果越靠前越容易是反常数据，那么取前Ｎ个就可以轻松地过滤数据和分类，搜索引擎也是类似的排序原理。<br />
 具体到本题，我是先对所有数据做回归，然后用不同边界分类筛出各个档位的特殊数据，用该档的均值预测特殊数据，其中用排序控制特殊数据的多少。原理非常简单，不过还需要调整算法，比如在分类中想要找可能性最大的前N个，不考虑其它，和把所有数据都尽量正常分类，做法肯定不同，详见后面“基于排序的评价函数”。</p>
<h2 id="正常与反常">4. 正常与反常</h2>
<p> 上面说到，本题我用了分类加回归，分类那么好，为什么还加回归呢？像上面“分类与回归”中说到的100个数回归等99次二分类，从这个角度看分类和回归本来是一个东西，只是粒度不同。也就是说处理任何问题，都需要在不同粒度下分析。<br />
 举个例子，追涨杀跌和低买高卖明显是不同的操作策略。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-f70bdb5e42630b17.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>在蓝色点卖出，绿色点买入，相对于黑色的趋势线是低买高卖（细粒度），而根据黑色上升趋势线操作又是追涨行为（组粒度）。这里趋势就是常态，请注意：常态不仅是不动的状态，一条横线，也有可能是斜线或者曲线，它可以是用回归拟合出来的模型；而蓝色和绿色点就是反常，反常没有一定之规，主要看常态是什么。比如大家都上辅导班，你不上就反常了。</p>
<h2 id="基于排序的评价函数">5. 基于排序的评价函数</h2>
<p> 这里主要基于xgboost工具，它提供排序的评价函数有：ams，auc，pre，ndcg，map。其中大多数找不到相应的中文说明，建议看源码：xgboost/src/metric/rank_metric.cc</p>
<h4 id="xgboost相关说明">(1) xgboost相关说明</h4>
<ol type="i">
<li><p>评价函数<br />
xgboost中，一般通过eval_metric设置软件自带的评价函数，也可以通过feval自定义评价函数。评价函数包括回归相关的，分类相关的，这里主要介绍排序相关的。一般评价函数的输入变量是训练数据和预测值。输出是评价函数名称和评价分值。</p></li>
<li><p>参数<br />
有些评价函数可以带参数，形如：ndcg@2，ndcg@，ndcg@2-。一般是从1-0的排序，如果设置了减号，可以支持从0向1的排序。</p></li>
<li><p>weight<br />
权重是通过scale_pos_weight或者作为DMatrix参数设置的，比如正例和反例的比例为1:4，将scale_pos_weight设为4，在计算时正例将乘权重4。weight在有些评估函数中也发挥作用，比如ams和auc。</p></li>
</ol>
<h4 id="xgboost提供的评价函数">2) xgboost提供的评价函数</h4>
<ol type="i">
<li>PRE<br />
PRE全称是Precision，即准确率。根据实际和预测的不同，一般有四种情况：tp，fn，fp，tn，如下图所示：</li>
</ol>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-380f227424ac05c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>实圈代表实际为真，空圈代表实际为假，tp是预测成真实际也是真的；tn为预测是假实际也是假的，fp是实际是假预测成了真，fn是实际是真预测成了假。精确率Precision和召回率Recall是常用的技术指标。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-c50c2e4bc570e978.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>Precision指的是在所有预测成真的实例中实际为真的比例，也就是绿占圆的比例。该评价可以加参数，即只计算排序后前Ｎ个实例的精确率。</p>
<ol start="2" type="i">
<li>MAP<br />
MAP全称是Mean Average
Precision。翻成中文是平均精度均值，即对均值再求均值，求的是所有类的average
precision的平均，公式如下：</li>
</ol>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-9b9c23aaec127f3f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中Q是类数，AveP(q)是q类的精度均值。</p>
<ol start="3" type="i">
<li>MDCG<br />
MDCG全称是Normalized Discounted Cumulative Gain。公式如下：</li>
</ol>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-bd09655a60e62855.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中p是数据项数，reli是第i项的评分结果，分子表示评级越高分值越高，分母是排名越靠前分母值越小分值越高。DCG是当前所有条目的评分，而IDCG是对当前所有评级评分。<br />
NDCG是一种源自搜索引擎的算法，越靠前权重越大，单项评级越高权值越大，求最累加得分。<br />
具体说明见：https://en.wikipedia.org/wiki/Discounted_cumulative_gain</p>
<ol start="4" type="i">
<li>AUC<br />
AUC全称是Area Under
Curve，曲线下面积，其中曲线指的是ROC曲线，ROC的横轴是假阳率fpr，纵轴是tpr真阳率，公式如下：</li>
</ol>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-e7acd48c140564c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>利用tpr和fpr画出的曲线，形如：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-bc546211a4d49ab7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>ROC曲线上的每个位置描述了在不同分界点上tpr和fpr的大小，而曲线下面积描述了该模式对各种分界的综合成绩。<br />
AUC对类别是否均衡并不敏感，几乎是分类常用的评估算法。</p>
<ol start="22" type="a">
<li>AMS<br />
AMS全称是Approximate Median Significance，公式如下：</li>
</ol>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-d19fb0c4619c8259.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中s,b分别是未经正则化的真正例(TP)和假正例(FP)，br是常数化正则项设为10，log是自然对数。<br />
它的格式是ams@k，其中参数k是个百分比，指定topn占数据的百分比，它主要评估序列的前n项。评价函数求出的是序列中最大的ams值，及它所在的位置。<br />
AMS是Kaggle的Higgs
Boson比赛中的评价函数，详见源码：xgboost/demo/kaggle-higgs。这种评分标准用得不太多。</p>
<h2 id="一些想法">6. 一些想法</h2>
<p> 我觉得写算法和写应用有个明显的不同：写应用可以大量借鉴别人的代码，API都是一样的，你能做的我也能做，但算法比赛不同，照抄照搬还想超过人家基本不可能。<br />
 在看别人代码的时候，最终成果可能只有几百行，但是推理和尝试的代码量比成果多得多，这部分最终并没呈现出来，看似简单的答案只是冰山一角。因此，有时看了人家的答案，觉得每句都能理解，到了自己做的时候，还是照猫画虎，只能微调。<br />
 我觉得恐怕还是要在实战中磨炼自己的套路。</p>
]]></content>
      <tags>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战天池精准医疗大赛之二_再接再厉</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E5%A4%A9%E6%B1%A0%E7%B2%BE%E5%87%86%E5%8C%BB%E7%96%97%E5%A4%A7%E8%B5%9B%E4%B9%8B%E4%BA%8C_%E5%86%8D%E6%8E%A5%E5%86%8D%E5%8E%89/</url>
    <content><![CDATA[<h1
id="实战天池精准医疗大赛之二_再接再厉">实战天池精准医疗大赛之二_再接再厉</h1>
<p>#算法实战</p>
<h2 id="说明">1. 说明</h2>
<p> 之前参加的都是往期赛，新人赛，这是第一人参加正式比赛，先谈谈感受。
天池精准医疗已开赛一周，排行搒上大家整体的误差从0.9提升到0.8，也就是说一开始0.88分还名列前茅，一周之后，这个分数早已榜上无名了。比想象中激烈，我也是反复出榜（榜单仅列出前一百名），偶尔侥幸进入前十，时刻准备着再次被踢出排行榜,
也算是体验了一把逆水行舟的乐趣。
很多时候反复实验仍然提高不了成绩，感觉完全没有方向，大家都在摸索，和一边做一边对照正确答案，确实不一样。也有一些算法，我知道它，却不知道什么时候用它。在此也记录一下经验教训。</p>
<h2 id="特征工程">2. 特征工程</h2>
<p> 开始的时候做了一些特征工程，包括填充缺失值，为SVM计算排序特征，还找到化验单各项指标的正常的范围值，根据各项指标正常与否做离散特征，根据指标的合格数量计算统计特征等等。但相对于简单地判断中值，均值，效果都没有明显地提高。后来做了标准化，效果挺明显的，而且转换后缺失值就可以直接填0了。
也分析了一下，为什么正常范围没起到作用，化验之后不都是看这个吗？后来在肉眼观察血糖各个档位特征统计值的时候，发现血糖高者某些生化指标和整体均值有明显差异，但仍在正常范围之内，另外在不正常的情况下，差值的大小也很重要，所以这种一刀切的方法好像不行。</p>
<h2 id="分析结果分布">3. 分析结果分布</h2>
<p> 本题预测结果是血糖值，大致分布如下：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-acb7282fe880873d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>我们把它称为大地和星空问题，大地指的是5-6之间的区域，80%以上的血糖都分布在这个区域，此区域也是容易被预测的，而上面星星点点的是星空，虽然数量不多，却起着决定性的作用。这还要从评分公式说起：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-98a8c218a39caadd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>由公式可知，评估指标是均方误差MSE的二分之一，其中m是实例个数，y’是预测值，y是实际值，关键是右上角的平方，它进一步放大了大的误差值。拿测试集来说，其中有1000个实例，即m=1000，如果把某个实例5.5预测成5，它对误差的贡献是(5-5.5)^2
/2000=0.000125，如果把20预测成5，误差为(5-20)^2
/2000=0.1125，它是前者的900倍，这个距离可以在排行榜拉开好几百名的差距了。这么看来，那些小的差异可以先不管。
再来看看训练集中血糖的分布：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-e6fe0e0501c974fa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>一般把大于6.1的认为是高血糖，大于11.1的认为是糖尿病。在训练集提供的5642个实例中，大于6.1的911个，大于11.1的97个。如果测试集的分布与训练集一致，大约有17个实例血糖在11.1以上。<br />
 但是在讨论群里面很多人对测试集的预测都没有超过10的，按测试数据估计，只占总人数1.7%的糖尿病人的误差就占了总误差的将近一半。<br />
 再考虑这个题目要解决什么问题，如果根本测不出谁是糖尿病患者，只是纠结正常范围内的小误差，这算法就没意义了。<br />
 一开始我的计算结果也是这样的，这可能是源于大家都在使用Boost迭代改进算法，它的原理是不断迭代，并在每次计算时加大前一次算错实例的权重，可以想见，本题中80%多都是正常血糖值，于是它模型拉向了均值，大量分枝在5附近做细小切分，后来试了等深分箱，也没什么用。
基于这个原因，我尝试修改了算法的损失函数，评价函数，实例权重等等，但效果都太好，这也可能因为我个人水平有限。后来直接把回归问题改成了先分类后回归，效果还可以。</p>
<h2 id="问题规模">4. 问题规模</h2>
<p> 本题是一个小规模数据的问题，因为数据量小，经常引发线上与线下评分不一致，而且容易造成过拟合，以及和测试集相关的作弊问题。不过即使数据再少，也有20W+的数据，人的大脑也处理不了。下面来看看不同数据量与算法选择的关系，从另一角度分析一下星空问题的解法。假设下面三种情况：<br />
第一种情况：从5000个实例中找到包含5个实例的类别。（血糖超20）<br />
第二种情况：从5000个实例中找到包含100个实例的类别。（血糖超11.1，尿糖病）<br />
第三种情况：从5000个实例中找到包含1000个实例的类别。（血糖超6.1，不正常）</p>
<p> 第一种情况下，类中只有5个实例，实例太少，无法取均值，因为只要其中一值太大或太小，都会严重影响均值。此时，每个实例都很重要，可以考虑使用距离类的算法，比如K近邻。另外，可以查看这些实例中各个特征与均值的差异，从而构建规则。<br />
 第二种情况下，类中有100个实例，占整体的2%，这些实例之间可能有一些重合的特点，可以统计的一些共同特征，一般不止一种模式，可尝试聚类，找到一些规律。也可以用类的统计特征和整体的统计特征相比较，或者考虑贝叶斯类的算法。
 第三种情况下，类中有1000个实例，占整体20%，这也是最常见的一种情况，它不再是从正常中找异常，而是从正常中找正常，基本属于大地问题了，有1000个实例，量也足够大，必然涵盖了很多种情况，可以考虑分类树比如GBDT类型的算法。<br />
 以上三种情况都是从整体中选出少数实例，里面有一个隐含的特征非常重要：整体的均值，它的作用就像是人的常识一样。</p>
<h2 id="算法">5. 算法</h2>
<p> 选择算法上有个误区：非此即彼。我们希望把每个实例都正确分类，但这往往是不可能的。比如在本题的情况下，可以先用GBDT的算法做一个baseline。在改进的过程中，选择一些规则类的算法。<br />
 这里指的规则，比如说，我们只关心血糖高于11.1的（正例），就可以从树分类器上切出一些只含有正例的分枝，而并不关注树的其它部分，从而生成一套规则集。预测时，符合规则的按糖尿病处理，不合规则的再用baseline预测。</p>
<h2 id="调参">6. 调参</h2>
<p> 本题中我试用过SVM, RF, LightGbm,
xgboost，评分最高的还是LightGbm和xgboost，除了速度有些差异以外，结果几乎是一样的，使用的是sklearn的cv调参。<br />
 需要注意的是，有的参数还是需要具体问题具体分析，不能只依赖自动调参，比如说，像最小叶节点这种参数，一般为避免过拟合，自动调参会建议5-6，但本问题中血糖超过20的只有4个实例，而且明显不能归为同一类，如果限定了最小叶节点为5，那这种大值就永远预测不到了。</p>
<h2 id="竞赛方法">7. 竞赛方法</h2>
<p> 一开始觉得技术圈里的交流实在是太少了，和Kaggle没法比（虽然Kaggle中的文章和示例也主要在新手学习区）。后来进了钉钉群，发现还挺热闹的，可能因为群里反馈更快，很多东西就在群里交流了，结果也没能记录下来。
尽管大家不会在钉钉群里详细讲算法，但有时只言片语也有很大的启发作用，尤其是在没有思路的情况下。另外，有的人会试一些算法，然后公开结论，这样也能少走很多冤枉路。<br />
 另外需要注意的是调整心态，反复被踢出排行榜的心态必然不好，于是很想打回来，不断寻找下一次提交的目标，每天提交两次，每个计划都是8小时以内的，不断寻找部局最优解，微调再微调。但如果不在整个结构上调整，提分会特别有限。</p>
]]></content>
      <tags>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战天池精准医疗大赛之四_初赛总结</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E5%A4%A9%E6%B1%A0%E7%B2%BE%E5%87%86%E5%8C%BB%E7%96%97%E5%A4%A7%E8%B5%9B%E4%B9%8B%E5%9B%9B_%E5%88%9D%E8%B5%9B%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1
id="实战天池精准医疗大赛之四_初赛总结">实战天池精准医疗大赛之四_初赛总结</h1>
<p>#算法实战</p>
<h2 id="说明">1. 说明</h2>
<p> 这两天因为改赛制，改评测方法，钉钉群里说什么的都有，我也跟着焦虑，做了小一个月，虽然对自己的算法有点信心，但是强人也很多，不知能不能进复赛．复赛数据和目标都不一样，相当于一场新的比赛．</p>
<p> 在赛前，比赛的第一周结束，第二周结束，各发过一篇：<br />
《实战天池精准医疗大赛之一_数据分析》<br />
《实战天池精准医疗大赛之二_再接再厉》<br />
《实战天池精准医疗大赛之三_分类回归与排序》</p>
<p> 本文是初赛的最后一篇，总结一下：最后阶段的算法集成；最终模型用到的所有具体算法；以及常见的坑．</p>
<h2 id="集成算法">2. 集成算法</h2>
<p> 数据从3到38不均衡分布，使用分类的情况下，不能确定边界划在哪里，最终使用多个边界，生成多个分类器，问题的难点在于，每个分类器的参数不同，比如：血糖小于5的，和血糖大于15的，比例差别很大，使用GBDT时，树的深度，节点权重需要分别调整，这里我使用了8个二分类器，做了一个自动调参的程序，调参的思想类似折半查找，以节省算力．</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-9e91fe622c1590d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 二分类器的目标都是切分＂正常＂与＂异常＂，比如视15以上的为异常，15以下为正常，由于是二分类问题，可用scale_pos_weight设定正反例的权重，即使反例很少也能挑出来．<br />
 比较特别的地方是结合8个二分类器的结果，有一些分类结果可能是矛盾的，比如这个分类器预测血糖应该在10以上，那个分类器预测血糖应该在8以下．也试过线性回归等等算法，最后使用的是投票一致的结果，大概意思是，如果分类结果同时在7以上，8以上，9以上，12以上，才判断它在12以上．对于那些没法判断的，或者认为正常的，则使用回归的结果．<br />
 这个集成原理上应该算是stacking类的算法，即把前面模型的结果作为后面模型的输入．也有点像增补的方法，就是用回归提供基本预测，再用分类器筛出比较确定的高血糖，预测成更高的值．相当于人工改值变成了机器改值．</p>
<h2 id="具体实现">3. 具体实现</h2>
<h4 id="特征工程">1) 特征工程</h4>
<p> 使用了比赛提供了30几个特征，除了把日期稍做调整，没加任何特征（也有人构造了上千个特征，而且提分了，但是我没用）。我做的唯一特征处理是标准化，另外训练之前去掉了一些完全不靠谱的属性，比如ID号等，之前的文章中介绍过。</p>
<h4 id="算法">2) 算法</h4>
<p> 最终使用的是xgboost，分类和回归使用的都是该工具．调用时使用了交叉验证，和技术圈中baseline的类似，回归用了10折，分类用了5折．<br />
 算法中比较特别的地方就是把回归改为了部分分类问题，但也带来一些新的问题，比如分界位置不对会把一簇数据切成两半；分类只能提高一定准确率，可能原来高血糖识别率是5%，用了分类后变成15%，但还有85%分辨不出来，分类后再做回归的话，还可能产生新的错误．<br />
 另外，在所有分类的评估和调参的过程中都使用了精确度precision替代auc（具体见文档：《医疗之三》），目的是找到确定的异常点，而不是让所有实例都正确分类．换言之，只关注＂真正例＂所占的比例，不管错的和不确定的点有多少．<br />
 由于分类器太多，写了自动调参程序，也有一些收获，比如，像max_depth等重要参数需要先稳定下来，再调其它；参数的取值范围不一样，有的变化步长是整数，有的是小数，还有范围，需要区别对待；还有特别重要的一点是，有的参数变化对结果的影响是线性的，有的是凸性，有的是多峰的，如果是线性或凸性的，可以用一些优化使调参更快，如果是多峰的，就需要用小的步长遍历整个取值范围．做好了调参程序，以后其它的数据挖掘也都省事儿了．<br />
 另外需要注意的还有，分类器对数据预测的分类结果是它属于某类的概率，二分类问题中就是一个0-1之间的小数．由于非均衡分类使用了scale_pos_weight参数，不能直接使用0.5作为分类的标准．解决该问题的方法是，如果正例占20%，则在预测结果中概率最高的20%认为是正例即可．另外，这些概率值也可以作为新的特征来使用，当然它与旧值会存在一些相关性．也可以将小数转成排序特征，这样也能比较清楚地看到它在所有实例中所处的位置．</p>
<h2 id="常见坑">4. 常见坑</h2>
<h4 id="放弃了正确的方向">1) 放弃了正确的方向</h4>
<p> 有时候本来选对了方向，但尝试后效果不好，于是放弃．到后来才发现，原来正确的方法一开始就想到了，就是没能坚持下来．可能也是因为一开始选择太多了，得有多大把握才能一条道走到黑，不去尝试其它？所以，可能需要在不同阶段再次尝试同一算法．</p>
<p>####2) 不同的人使用同一算法，效果不同<br />
 在初始阶段，有时候调了半天算法，还不如baseline效果好，于是对baseline各种调参，但上分很少，还不如手动改几个重要值上分快，因此产生错觉：这还不如我用肉眼看呢？最后得出结论：机器学习就是不如人呀。<br />
有时候钉钉上菜鸟听和大佬用同一算法，效果天差地别，所以像我这样的还需要多磨练．</p>
<h4 id="过拟合">3) 过拟合</h4>
<p> 有的参数直觉上没用，比如体验日期，序列号，明显和血糖高不高没关系，在训练集中加入后确实可以提分，却造成模型的过拟合，使线上得分下降。所以，觉得完全不辈谱，却能提分的，最好把它去掉。</p>
<h4 id="模块开发">4) 模块开发</h4>
<p> 有一次看一个天池答辩视频，讲组里人的分工，这个人做特征，那个人改算法，另一个人做集成，一开始不太明白，做前边步骤的人，怎么评价自己的工作质量。后来想这和调参一样，比如A-&gt;B-&gt;C三个步骤，我做B，那么就拿稳定的A和C模块，只改Ｂ部分，然后看评分变化。不过在一开始各个模块都频繁变化的情况下，确实挺难。我觉得组队可能还是主要各做各的，但是有一些头脑风暴和方法借鉴，或者是主要一个人带着另几个人做比较好一些。</p>
<h4 id="作弊与公平">5) 作弊与公平</h4>
<p> 这个比赛的讨论群特别热闹，一开始有人发现测试数据中有几个异常值对评分影响大，通过多次提交的对照能找出来，然后对结果数据手动改值，得到高分，一传十十传百，有个阶段不改值的人根本进不了排行榜。<br />
 这个问题的原因是数据量小．一共5000个数据，其中有十几个特殊数据，还能手动改，要是有5000万个数据，特征的十几万个，谁还能改？<br />
 另外，这和评价函数有关，常用的评价函数均方误差，均方根误差，基本都是累加每个实例误差的平方，比如有两个实例，一个误差是1，另一个是10，误差平方和是1<sup>2+10</sup>2=101，两个误差值差了10倍，但后一个误差对整体误差的贡献是前一误差的100倍，数越大越明显，于是有人问为什么不用绝对值，而用平方呢？这是因为平方更容易求导。<br />
 那什么样的实例误差最大呢？一般数据都是高斯分布，也就是数据集中地分布在均值附近，边缘较少，也就是不均衡分布。当使用一些迭代改进算法时，为正确预测大多数实例，模型的预测值会向均值收缩，这也就是为什么大家预测之后发现高血糖的比例明显减少了。也就是说高血糖被预测成了均值，误差会比较大．解决此类问题，可以给不同实例分配不同权重，把回归问题，先当分类问题处理等等。<br />
 什么算作弊？听人说改哪个实例算作弊？自已找出特殊实例就不算？手动改值算作弊机器改就不算？如果说能找出模型把血糖高的自动筛选出来，这题不就解了么？的确有人花了很多时间精力，由于别人作弊，开小号，而不能晋级，确实挺可惜的．但是，有的组人多，有的组人少，有人机器快，有人机器慢，本来就没有绝对的公平．<br />
 咱们也尽量佛系一点，毕竟进了复赛也进不了决赛，对吧．</p>
<p> 顺便得瑟一下，进复赛了，哦耶！</p>
]]></content>
      <tags>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战微博互动预测之一_问题分析</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E5%BE%AE%E5%8D%9A%E4%BA%92%E5%8A%A8%E9%A2%84%E6%B5%8B%E4%B9%8B%E4%B8%80_%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1
id="实战微博互动预测之一_问题分析">实战微博互动预测之一_问题分析</h1>
<p>#算法实战</p>
<h2 id="天池竞赛平台">1. 天池竞赛平台</h2>
<p> 微博互动预测是一个天池平台的竞赛，和其它平台相比，天池的数据量更大，赛题更接近实际场景。微博互动比赛算是其中比较小的，训练数据也有300多Ｍ，上百万条记录（虽然数据较多，但也是普通开发机可以处理的量级）。数据内容也比较丰富，和提供匿名纯特征拼算法的竞赛相比，它需要研究业务，发挥的空间也更大。<br />
 天池平台的大多数比赛分为线下赛和线上赛。第一阶段线下赛和Kaggle，DC差不多，就是在本地计算，然后上传预测结果，线上评分排名（每天两次），如果第一阶段排名靠前，可进入第二阶段线上赛，线上赛使用天池平台算力和工具，海量数据，支持分布计算，但也被线上工具所限。</p>
<h2 id="新浪微博互动预测">2. 新浪微博互动预测</h2>
<p> 微博互动预测是前两年的赛题，现在仍开放线下赛，可以上传预测结果，计分并排名。它代表了现实中的一大类应用：数据量大，需要参赛者提取特征，数据有现实中的意义，无规律数据占多数，可多维度分析等等。赛题具体见：<br />
https://tianchi.aliyun.com/getStart/introduction.htm?spm=5176.100066.0.0.6f2c778dQSMdqc&amp;raceId=231574</p>
<h2 id="观察数据">3. 观察数据</h2>
<p> 微博互动预测的训练集是123Ｗ条微博，预测测试集中数据转发，评论和赞的情况。<br />
 训练数据中，字段并不多，包括：用户标记，博文标记，发博时间，转发数，评论数，赞数，博文内容。<br />
*
用户标记：大多数用户发文不止一条，可通过转发数，评论数，赞数预测该用户的粉丝，以及粉丝的习惯。<br />
* 博文标记：是微博的id，可看作索引。<br />
* 发博时间：可分解出工作日，节假日，时间段等属性。<br />
*
转发数，评论数，赞数：是预测的目标，也可用于计算用户的特征和分析其相关性。<br />
*
博文内容：可解析出更多特征，如分词聚类，情绪分析，是否包含链接，是否包含表情，是否包含视频，是否自动生成，是否为广告（含：天猫，淘宝，超便宜），长度，是否@谁，是否为转发#，文章分类（新闻，技术，笑话，心情…）</p>
<h2 id="统计数据">4. 统计数据</h2>
<h4 id="统计转发评论点赞个数后统称反馈">(1)
统计转发，评论，点赞个数（后统称反馈）</h4>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-8fee459c25f54d1d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 我们既可以把它当成回归问题，也可以把它当成分类问题，如果是分类问题，则是非均衡分类，score时需要考虑分布情况。<br />
 可见，如果把所有情况都预测成0，也能拿到一定分数。</p>
<h4 id="反馈个数做图">(2) 反馈个数做图</h4>
<p> 下面列出了转发，评论，点赞的分布图，横坐标是反馈个数（如转发数），纵坐标是该反馈出现的次数，如０次转发出现了上百万次（由于影响显示，做图截取掉了）。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-8d2efacf51043383.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="反馈均数">(3) 反馈均数</h4>
<p> 平均每篇获得反馈个数是，转发：3.54，评论：1.26，赞：2.22。<br />
 可见，虽然大多数人没得到反馈，但被关注的少数人拉高了平均分。</p>
<h4 id="统计用户">(4) 统计用户</h4>
<p> 训练数据中共37000多个用户，人均发文33篇，首先用把每个用户得到的转发，评论，点赞的均值加在一起，可计算出关注度，即下图中的黑线，按关注度对用户排序，下图分别显示了关注度和各种反馈之间的关系，以及分布，从中也能看到在30000多人里只有几十个人平均每篇的反馈之和超过100，且以转发为主。<br />
 截掉了图的左侧，其中显示有15000多人，从未得到过任何反馈，占了全体用户数的0.412，所以说没人理也很正常。估计可能因为不太使用微信，只发广告，自动生成消息，或者好友太少。后面会做进一步分析。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-a13f1dfbdb531596.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="单个用户分析">(5) 单个用户分析</h4>
<p> 下面是对某个用户的转发分析，他共发文733篇，其中最多的一篇被转发8949次，也因为影响显示被截掉了，其中有167篇文是0次转发，大多数分布在０-100次以内。从中还可以估计一下他的粉丝数，至少有8949人，方法是max(f,l,c)。<br />
 可见，在粉丝多的情况下，反馈更多地取决于内容。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-906de8a16ba10aeb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="问题分析">5. 问题分析</h2>
<p> 再来看看比赛的评分标准，下面公式中f代表转发，c代表评论，l代表赞，p代表预测，r代表真实值；deviation是真实值与预测值的偏差，具体公式如下：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-122bcd56707bb73d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>precision是准确率，根据偏差算出：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-c587b88982343438.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>sig为符号函数，当x&gt;0时sig(x)=1，当x&lt;=0时，sig(x)为0。Counti为每篇的反馈总数，当Counti&gt;100时，以按100计算。<br />
 也就是说，当计算的偏差和在正负20%以内，则将反馈总数计入成绩。有两点需要注意：<br />
 第一，反馈越多在评分中权重越大，比如反馈为500的文章，如果预测正确，贡献是反馈为0文章的500倍。<br />
 第二，反馈越多偏差越大，比如实际为200次转发，预测成了500次，偏差deviation=(500-200)/(200+5)=1.63；实际为2次，预测成5次，deviation=(5-2)/(2+5)=0.43。</p>
<p>##6. 整体分析<br />
 从直觉上看，最强的特征应该是用户的被关注度，其次是内容，然后是时间。<br />
 试验了一下，计算出了每个用户转发，评论，赞的均值，对于训练集中出现过的用户，直接将均值四舍五入作为预测，对没出现过的用户预测为0（整体均值）。线上得分26.49%，排名260名左右。加入一些算法后成绩反而下降了，估计可能是由于少量有规律数据和大量无规律数据混在一起，规律被湮没了，当然也有算法的选择问题。<br />
 从不同角度看：直接可见的是文章，间接可见的是用户的特征。从已有数据可以提取到用户的发文数，各种反馈的均值，方差，关注度，估计粉丝数，以及他的粉丝对他各种文章的反馈。也可以根据不同反馈（不同的人，身边不同圈子）给用户做聚类。当某个用户个人信息不足时，取他所属类别的均值，这有点像股票分析也要先分析某支股票的股性，再分析其行为。<br />
 初步觉得这应该是一个聚类，分类和回归结合的问题，有点像树回归。我觉得在前期，相对于分析信息内容，分析用户行为可能带来更大的信息增益。</p>
]]></content>
      <tags>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战微博互动预测之三_xgboost答疑解惑</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E5%BE%AE%E5%8D%9A%E4%BA%92%E5%8A%A8%E9%A2%84%E6%B5%8B%E4%B9%8B%E4%B8%89_xgboost%E7%AD%94%E7%96%91%E8%A7%A3%E6%83%91/</url>
    <content><![CDATA[<h1
id="实战微博互动预测之三_xgboost答疑解惑">实战微博互动预测之三_xgboost答疑解惑</h1>
<p>#算法实战 #xgboost</p>
<h2 id="说明">1. 说明</h2>
<p> 前两篇完成了特征工程的相关工作：加入用户的统计特征，分析文本信息内容，并作为新特征加入了数据集。<br />
本篇我们来看看算法，实战微博互动预测（后简称本例）的评估算法如下：</p>
<p> 公式中f代表转发，c代表评论，l代表赞，p代表预测，r代表真实值；deviation是真实值与预测值的偏差，具体公式如下：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-c34387675e5e2a7f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>precision是准确率，根据偏差算出：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-969ae68744069615.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>sig为符号函数，当x&gt;0时sig(x)=1，当x&lt;=0时，sig(x)为0。Counti为每篇的反馈总数，当Counti&gt;100时，以按100计算。</p>
<p> 与大多数评估算法不同，本例中每个实例有不同权重，反馈越多实例权重越大。而我们常用的算法比如GBDT是根据误差迭代改进的，默认情况下各实例权重是一样的，这块儿需要单独处理一下。<br />
 具体算法还是使用xgboost库，之前看到的大多数关于xgboost的文章，要么是讲数学原理，要么是参数的中文说明，xgboost似乎还是一个黑盒，下面就结合具体问题看看xgboost的使用。</p>
<h2 id="xgboost注意事项">2. xgboost注意事项</h2>
<p> xgboost提供两种调用方式，一种是自身接口，一种是类似sklearn的接口，建议使用自身接口，因为很多重要功能，如存取模型，评估功能都无法通过sklearn接口调用。<br />
 在资料，示例和文档都不多的情况下，建议下载源码，学习其中的example,demo，test中的使用方法，以及直接分析源码的调用流程。</p>
<h2 id="xgboost源码">3. xgboost源码</h2>
<p> 一般使用xgboost直接用pip
install安装即可，下载源码主要以学习为主。<br />
 下载使用命令：</p>
<pre><code>git clone https://github.com/dmlc/xgboost  </code></pre>
<p> xgboost主要是c语言实现的，本例中主要通过python接口调用，在demo目录中可以看到示例。</p>
<h2 id="xgboost学习率与迭代次数">4. xgboost学习率与迭代次数</h2>
<p> xgboost是一种迭代改进的算法，它每次给错误分类的实例增加权重，并进入下一次迭代。因此需要指定迭代次数和每次权重改进的程度（学习率）。<br />
 迭代次数通过num_boost_round设置，次数越多，花费时间越长，xgboost除了可以设置固定迭代次数以外，还可以根据评估，判断如果n次不再改进，则停止迭代（具体见eval部分）。<br />
 学习率通过eta设置，它是每次迭代之后对原模型的改进程度，学习率越高收敛越快，但也可能因为粒度太大，错过极值点。<br />
调参方法是先粗调再细调：一开始将学习率设大一点，比如0.1-0.3；次数设少一点，比如50次，即能快速改善模型又不花太长时间。后面细调时再变小学习率，增加迭代次数。</p>
<h2 id="xgboost的eval系列参数">5. xgboost的eval系列参数</h2>
<p> eval系列参数用于评估模型的状态，可以在每次迭代之后给模型打分，它本身与模型如何计算无关（无论它设成什么，最终模型都不变），只是评估当前模型好坏。这个功能非常重要，比如：有时候会看到在迭代过程中训练集评分提高，而测试集评分下降，一般就是过拟合了。使用它还可以控制当模型不再改进时，停止迭代（具体通过early_stopping_rounds设置）。</p>
<h4 id="evals设置估计数据">1) evals设置估计数据</h4>
<p> evals可设置训练集和测试集，在每次迭代后用训练集和测试集代入模型，并给预测结果评分。</p>
<h4 id="eval_metric现成的评估函数">2) eval_metric现成的评估函数</h4>
<p> 可以设置rmse,logloss,error,merror,mlogloss,auc,ndcg,map等xgb自带的评估函数。</p>
<h4 id="feval自定义评估函数">3) feval自定义评估函数</h4>
<p> 本例就需要自定义估伻函数，使用feval方法实现。它和梯度下降算法无法，主要用于显示，并判断何时终止迭代。最好别写太复杂，否则会延长计算时间。</p>
<h4 id="early_stopping_rounds自动停止迭代">4)
early_stopping_rounds自动停止迭代</h4>
<p> 通过early_stopping_rounds设置，如果在n轮内正确率没有提升，则退出迭代，具体根据evals给出的数据判断，若其中包含多组数据，则取最后一个。<br />
 如果设置了early_stopping_rounds，模型会生成三个属性，best_score,　
best_iteration, bst.best_ntree_limit，以便下次选择最合适的迭代次数。</p>
<h4 id="verbose_eval输出评估信息">5) verbose_eval输出评估信息</h4>
<p> 如果设置为True输出评估信息，设置为数字，如5则每5次评估输出一次。</p>
<h2 id="样本不均衡问题">6. 样本不均衡问题</h2>
<h4 id="设置scale_pos_weight">1) 设置scale_pos_weight</h4>
<p> 有时会遇到样本不均衡的问题，比如正例占99%，反例占1%，那么如果预测为全正例或者随机抽机，正确率也占99%。此时可使用scale_pos_weight提高反例权重，默认为1，不增加权重。</p>
<h4 id="dmatrix设置weight">2) DMatrix设置weight</h4>
<p> 使用xgb自带的调用接口
(非sklearn接口)，需要把数据转成DMatrix格式，如果想给不同实例分配不同权重，可以转换时使用weight参数，它传入与实例个数等长的数组，数组中每个数对应一个实例的权重，在xgb每次迭代后调整权重时也会将它计算在内。</p>
<h2 id="xgboost自带的调参方法">7. Xgboost自带的调参方法</h2>
<p> 之前文章中说过Xgboost与sklearn的GridSearchCV结合调参的方法。Xgboost内部的cv()函数提供了交叉验证的功能，也可用于调参。网上例程不多，具体可参见源码中的：demo/guide-python/cross_validation.py</p>
<h2 id="xgboost的误差函数">8. Xgboost的误差函数</h2>
<p> Xgboost可以处理二分类，多分类，回归问题。处理不同问题，主要的区别在于指定不同的误差函数，xgboost会根据不同误差函数计算的结果调整权重进行下一次迭代。通过参数objective可设置xgb自带的误差函数：回归一般用reg:xxx（如reg:linear），二分类用binary:xxx（如binary:logistic），多分类用multi:xxx（如multi:softmax）。误差函数的功能是通过训练集的label和预测值计算一阶梯度，二阶梯度，在源码中可以看到它们是如何实现的（C语言部分）。在调用train()训练时，也可以用参数obj自定义误差函数。</p>
<h2 id="本例中xgb的使用">9. 本例中xgb的使用</h2>
<h4 id="评估">1) 评估</h4>
<p> 本例的评分算法和普通算法差别很大，因此使用feval自定义了评估函数，效果还不错，就是计算时间比较长。所以有时会把它暂时注释掉。</p>
<h4 id="误差函数">2) 误差函数</h4>
<p> 本例是一个回归问题，因此使用了reg:linear，线性计算误差函数，它的实现非常简单，一阶梯度是预测值与标签值相减，二阶梯度是1.0。</p>
<h4 id="关于权重">3) 关于权重</h4>
<p> 本题要求反馈多的实例在计算结果时拥有更大的权重，一开始的想法是给这些实例加权，于是使用了在DMatrix转换时设置weight，后来又自定义了误差函数。但效果都不好，正确率不升反降。我觉得可能由于这是一个回归问题，回归的权重算法是：偏差越大，权重越大，以促进快速收敛。一般反馈多的实例偏差都大，如果再把权重计算再内，就重复加权了。</p>
]]></content>
      <tags>
        <tag>算法实战</tag>
        <tag>xgboost</tag>
      </tags>
  </entry>
  <entry>
    <title>实战微博互动预测之二_中文分析</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E5%BE%AE%E5%8D%9A%E4%BA%92%E5%8A%A8%E9%A2%84%E6%B5%8B%E4%B9%8B%E4%BA%8C_%E4%B8%AD%E6%96%87%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1
id="实战微博互动预测之二_中文分析">实战微博互动预测之二_中文分析</h1>
<p>#算法实战 #自然语言处理</p>
<h2 id="说明">1. 说明</h2>
<p> 前篇《实战微博互动预测之一_问题分析》中，已经对微博的整体反馈情况，以及单个用户的反馈做了初步的分析。本篇将从微博的信息内容中提取更多特征。<br />
 文本分析是数据分析中的常用技术，使用范围很广，比如：信息搜索，内容推荐，文章分类，内容提取等等。其核心是分析连续的文本，抽取关键数据，再进行下一步分析。</p>
<h2 id="文本分析">2. 文本分析</h2>
<h4 id="tf-idf算法">1) TF-IDF算法</h4>
<p> TF-IDF是一种统计方法，TF指词频，IDF是逆向文件频率。TF好理解，就是词在文章中出现的频率，出现频率高的词更可能是文章的关键词。但有些词如：“是”，“的”，“了”（即停用词）在任何文章出现频率都高，于是使用IDF。IDF通过总文件数目除以包含该词语之文件的数目，再将商取对数得到，它弱化了常用词的权重。TF-IDF倾向于过滤掉常见的词语，保留重要的词语。</p>
<h4 id="中文分词">2) 中文分词</h4>
<p> 中文分析一般以词为单位，与英文不同的是中文的词与词之间没有空格划分，所以处理时，首先要分词。简单的方法是把所有词放在一个词典中，通过正向匹配，逆向匹配，双向匹配等方式分词，这种方式经常会产生歧义；也可以利用统计的方法如HMM，SVM通过训练学习分词。实际操作中最常使用的方法是直接调库。常用库有jieba分词，SnowNLP等，后面详述。</p>
<h4 id="文本分析功能">3) 文本分析功能</h4>
<p> 常见的文本分析一般有：分词，计算TF、IDF，词性标注，提取关键词，提取摘要，情感分析，文本相似度等等。</p>
<h4 id="文本分析工具">4) 文本分析工具</h4>
<p> 有很多在线工具提供API实际自然语言的处理，效果比离线的好一些，但在处理大量数据时，速度太慢了。下面来看看常用的离线工具。</p>
<ol type="i">
<li><p>NLTK<br />
Natural Language
Toolkit，自然语言处理工具包，它是NLP领域中，最常使用的一个Python库。功能非常全，但对中文处理相对弱一些。</p></li>
<li><p>SnowNLP<br />
SnowNLP是一个中文工具，它实现了大部分文本分析的常用功能，并且可以自己训练数据。但是试了一下它自带的分析器，如：情感分析，关键词提取功能，代入微博文本，效果都不太好，后面只使用了它的分词功能。使用方法如下：</p></li>
</ol>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> snownlp <span class="im">import</span> SnowNLP  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> SnowNLP(<span class="st">&quot;跟框架学代码设计，跟应用学功能设计&quot;</span>)  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(s.words) <span class="co"># 分词  </span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(s.sentiments) <span class="co"># 消极or积极，结果在0-1之间  </span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(s.tags) <span class="co"># 词性标注  </span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(s.keywords(<span class="dv">3</span>))　<span class="co">#　关键词  </span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(s.summary(<span class="dv">3</span>)) <span class="co"># 摘要  </span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(s.tf) <span class="co"># tf  </span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(s.idf) <span class="co"># idf  </span></span></code></pre></div>
<p> 我的机器速度一般，计算1000条微博20s，处理所有数据约5小时左右。</p>
<ol start="3" type="i">
<li>结巴分词<br />
结巴分词的效果也不错，支持自定义词典，词性标注等等，具体使用方法如下：<br />
</li>
</ol>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#encoding=utf-8  </span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jieba  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(jieba.cut(<span class="st">&quot;跟框架学代码设计，跟应用学功能设计&quot;</span>, cut_all<span class="op">=</span><span class="va">True</span>))  </span></code></pre></div>
<ol start="4" type="i">
<li>其它<br />
 这里只使用了分词功能，所以用哪个工具都差不多。除上述工具，还有PyLTP，THULAC，Pynlpir，CoreNLP等中文文本处理工具，详见：<br />
http://blog.csdn.net/sinat_26917383/article/details/77067515</li>
</ol>
<h2 id="文本的简单分析">3. 文本的简单分析</h2>
<p> 微博的训练数据有100多万条，分析一遍花很多时间，所以第一步，先对文本做简单的字符串处理，包括：判断是否含有@，是否含有链接，提取标题，提取表情。这里主要用到的技术是：对DataFrame数据列的函数处理apply，以及正则表达式。</p>
<h4 id="正则表达式">1) 正则表达式</h4>
<p> 具体使用re库，假设标题是用”##”，”【
】”，”《》”括起来的字符串。提取标题的方法如下：</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>patt<span class="op">=</span>re.<span class="bu">compile</span>(<span class="vs">r&#39;[#【《](.*?)[#】》]&#39;</span>,re.S)  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>topics<span class="op">=</span>patt.findall(content) <span class="co"># 提取标题  </span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>plain<span class="op">=</span>re.sub(patt,<span class="st">&#39;&#39;</span>, content) <span class="co"># 从正文中去掉标题  </span></span></code></pre></div>
<h4 id="apply处理列数据">2) Apply处理列数据</h4>
<p> 假设content列存储的是文本信息，提取标题到topic列中：</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> getTopic(content):  </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>   …  </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;topic&#39;</span>]<span class="op">=</span>data.content.<span class="bu">apply</span>(getTopic)  </span></code></pre></div>
<p> 注意尽量不要用for循环处理DataFrame，那样做速度非常慢。</p>
<h2 id="文本提供的信息量">4. 文本提供的信息量</h2>
<h4 id="统计分析">1) 统计分析</h4>
<p> 没人关注的用户发的文约占9%（发的所有微博都得不到反馈），这部分数据单独处理。<br />
 其它数据统计如下：带标题占39%，带链接占55%，带表情占12%，带@占20%。</p>
<h4 id="计算相关系数">2) 计算相关系数</h4>
<p> dataframe.corr()<br />
 计算得出的结论和人的经验类似：带表情的更容易得到反馈，自己写的更容易得到反馈（不带标题，不带链接），带链接的容易被转发，带@得到的反馈较少，正文长度与转发相关……</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-89db5d85ad384ff6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="分析">3) 分析</h4>
<p> 从上面的分析看来，用户个人的相关数据比信息内容重要得多，但回想前篇我们对单一用户的数据分析，他发的700多条微信中，167条转发0次，而其中有一篇被转发了8000多次。对于用户个体来说，还是需要根据信息内容来进一步判断。这个原理就如同决策树，在第一层“用户信息”的信息增益更大，但在第一层之后，其它信息就变得重要了。</p>
<h2 id="文本的复杂分析">5. 文本的复杂分析</h2>
<p> 分词和文章分类，都是庞大的体系，有很多方法构造和优化。但在微博预测问题中，只是想借此得到更多的数据特征。所以这里不去构造分类器，而是寻找现成最简单有效的方法，这里使用了SnowNLP和《同义词词林》。<br />
 首先使用SnowNLP对标题和正文分词和词性标注，然后筛选出句子中的名词，代入同义词词林，找到相应的分类。<br />
 同义词词林是一本词典，最初目标是提供较多的同义词语，对创作和翻译工作有所帮助。它把中文词组分为大类，中类，小类。这里对信息中的名词归类，最终将信息归类。分词后共抽取名词性关键字2605965个，去重后18515个，用词林分成95个类别。<br />
 使用时还需要解决一词多义，以及句中含有不同类别名词的问题，具体的方法是优先选择：社会，经济，文教等抽象分类。</p>
<h2 id="一些想法">6. 一些想法</h2>
<p> 一开始做的时候，数据很多，可提取的特征也多，有点无从下手。解决的方法是：先切出一部分，使用现有的工具测试。<br />
 当数据多的时候，每个操作，尤其是面向所有数据的操作，都会花很多时间，最好是先处理少量记录，并且记下各个步骤的运行时间。<br />
 我觉得无论是写算法还是文本分析，能确定的都用确定的，不能确定的再用统计方法处理。比如某个用户数据中均值确定，方差很少，那就直接用均值。</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战文本分类对抗攻击</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/</url>
    <content><![CDATA[<h1 id="实战文本分类对抗攻击">实战文本分类对抗攻击</h1>
<p>#算法实战</p>
<p>文章写得比较长，先列出大纲，以便读者直取重点。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-61ade595267cca47.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>“文本分类对抗攻击”是清华大学和阿里安全2020年2月举办的一场AI比赛，从开榜到比赛结束20天左右，内容是主办方在线提供1000条辱骂样本，参赛者用算法逐条扰动，使线上模型将其判别为非辱骂样本，尽量让扰动较小同时又保留辱骂性质（辱骂性质前期由模型判定，最终由人工判定）。</p>
<h3 id="比赛规则">比赛规则</h3>
<p>线上模型和评测使用的1000条样本不公开，选手根据赛方指定的接口实现算法，并用docker方式提交以供线上评测，每天最多评测15次，单次运行时间需控制在30分钟之内。<br />
<strong>（第一个知识点：熟悉Docker，简单环境调试）</strong></p>
<p>其评价公式如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-746c32affadd74e7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>共1000条评测样本（samples=1000且全部为辱骂文本），vi为最终的人工评测结果，1为辱骂，0为非辱骂在（只对最终入围数据作人工评测，前期提交都认为vi=1）；ci是分类结果，由多个线上模型作出评判并取均值，攻击成功为1，攻击失败为0；pi是原始文本与扰动文本的差异，综合考虑了字符差异和语义差异，最终结果Sfinal满分为1000分。详见赛题介绍：
<a
href="https://tianchi.aliyun.com/competition/entrance/231762/information">https://tianchi.aliyun.com/competition/entrance/231762/information</a>
细看之下，可以发现，其中最重要值是ci，如果未攻击成功，该样本ci得分为0，而修改的多少pi相对ci没那么重要，只作为判断句意变化的辅助手断（否则整句替换将取得高分）。</p>
<p>比赛提供一个线下评测模型，它可能是多个线上模型之一，明显弱于线上模型，也就是说能攻击线下模型的算法，不一定能攻击线上模型；过分与线下模型对抗还可能造成对线下模型过拟合，反而影响算法的线上效果。但对选手来说，线下模型是一个重要参考，可以使用它做基础评价，此次比赛不提供训练数据，因此自行收集数据后，可用线下模型来判别其辱骂性质。</p>
<p>赛题可分解成两部分：定位哪些词是决定辱骂与否的关键词，以及如何替换，一开始笔者的工作重心在前者，认为只要能定位得足够精准，定位到足够少的词，随意替换成特殊字符即可；后来发现替换特殊字符可能改变其辱骂性质，而替换成特殊字符与替换成词线上得分差异非常大。因此，定位和生成都很重要。</p>
<h3 id="收集数据">收集数据</h3>
<p>比赛不提供任何辱骂数据，靠选手自行采集，赛方给出一个辱骂文本生成网站：骂人宝典https://nmsl.shadiao.app/，可使用它生成一些辱骂数据（骂得够狠），试了一下，使用爬虫只能抓取1500条左右，去重之后仅400多条，可见一斑，但不足以训练。<br />
<strong>（第二个知识点：爬虫与寻找辱骂场景，简单的数据工程）</strong></p>
<p>笔者绞尽脑汁寻找网络辱骂的密集地带，典型场景，却始终未果。最终定位到豆瓣的低分影评，发现一星两星的影评辱骂比例在10-20%左右。觉得挺奇怪，不喜欢还买票去看，看完了还骂，这是怎么想的，看了评分最低的10部电影，还真不是没听说的电影和演员，还不乏王晶、郭德纲、周润发等明星，引起大家负面情绪可能不是实际的好坏，而是实际与期待的差异（差值）：评价=实际-期待。</p>
<p>最终觉得下载太麻烦，于是在CSDN下载了影评数据库，花一些C币节省了时间。从中过滤出20000+辱骂数据，这样的数据量也可供简单训练了。</p>
<p>另外，还下载了“网络敏感词”，用于关键字判别。一开始笔者认为带脏字的才叫辱骂，毕竟网络上长期以来都以此作为评价标准，后来发现，如果只屏蔽脏字，得分在100之内（约只占10%）。目前的模型可以通过词之间的相互作用识别出大部分不带脏字却有攻击性的语言，只是要消耗一些时间和算力。</p>
<h3 id="算法尝试">算法尝试</h3>
<p>本次比赛笔者尝试了很多算法，虽然最终模型用到的不多，但也算对自然语言对抗的一些学习和尝试，在此分享。</p>
<h4 id="对抗模型gan">对抗模型GAN</h4>
<p>目前常用的对抗模型源自2014年的论文《Generative Adversarial
Nets》，它同时训练两个深度学习网络，生成模型G（进攻）和判别模型D（防守），比如用对抗模型生成卡通头像，模型G用于生成头像，模型D用于判别图片是模型G生成的，还是实际的头像。两个模型交替训练，迭代提升。具体方法是通过梯度调整网络参数。由于图片是连续型数据，因此可以通过逐步微调来改进模型。</p>
<p>对抗网络生成序列数据时常使用SeqGAN方法，它源自2016年的论文《SeqGAN:
Sequence Generative Adversarial Nets with Policy
Gradient》，与简单对抗不同的是，在一单次生成过程中，模型多次用到了生成模型G和判别模型D。以生成文字为例，每生成新词时，调用生成模型G根据当前已生成的词生成多个备选项，并使用判别模型对其评分（reward），根据评分选择最好的策略Policy，并调整策略模型（Policy
Gradient）。这里涉及很多强化学习中的概念。</p>
<p>本赛题只需要替换句中的少数文字，较少涉及GAN生成连续数据时遇到的问题，可以将语言模型（比如BERT）作为生成模型，线下模型作为判别模型，用生成语句的评分变化调整生成模型，从而生成不易被察觉的辱骂文本，但这样做不能保证保留辱骂性质。<br />
<strong>（第二个知识点：对抗网络）</strong></p>
<h4 id="强化学习模型">强化学习模型</h4>
<p>强化模型中最重要的概念是状态S，行为A，奖励R，根据当前状态，选择行为A，获得奖励R，然后逐步调整模型参数，以便再次遇到状态S时选择更好的行为，以便得到更大奖励。</p>
<p>近年来强化模型中最流行的算法是蒙特卡洛梯度策略，也是SeqGAN中用到的强化学习算法，蒙特卡洛树搜索常用于情况非常多，无法一一列举的场景，比如：当前比赛中一句话“ABCDEFGHIJKLMNOPQRSTUVWXYZ”，共26个词，如果从中删除三个词（多数情况不止三个）能达到最佳效果，则有2600种可能，若判别每种可能性，并且每次都生成这几个字的换代方案，将非常耗费时间。</p>
<p>最简单的方法是随机抽取，但是随机抽取的效果又不好，蒙特卡洛树搜索方法比较复杂，简单地说，就是一开始随机抽取一些组合，对其评分，并记录下来，对于评分越高的组合赋予更高的下次被选中的概率，经过多次迭代，使随机抽取偏向评分更高的策略。梯度策略一般使用深度学习网络与蒙特卡洛树搜索相结合，用两个模型分别调整策略和状态价值，使模型更快收敛。</p>
<p><strong>（第四个知识点：强化学习模型）</strong></p>
<p>笔者借鉴了蒙特卡洛梯度策略中的强化高分项随机抽取方法，作为定位辱骂关键词的算法。</p>
<h4 id="attention模型">Attention模型</h4>
<p>Attention模型最几年超越了Text-CNN，RNN成为最流行的自然语言处理算法，其中又以GPT和BERT最为流行。GPT常用于生成文章，而BERT则更加灵活，由于其可参考前后两个方向的上下文，在完型填空类的应用中有明显优势。</p>
<p>本赛题在定位了辱骂位置之后，需要用其它词替换辱骂词，类似于完型填空，非常适合使用BERT模型，且BERT模型源码中提供了完型填空功能的API（笔者使用的是Transformers库Pytorch版本的BertForMaskedLM）。由于BERT可下载中文的预训练模型，由此无需训练也可生成较为通顺的语句。<br />
<strong>（第五个知识点：自然语言处理模型）</strong></p>
<p>在使用模型中也遇到一些问题：</p>
<ul>
<li><p>BERT是结构和参数都很巨大的模型，每次预测都很耗时（尤其是在没有GPU支持的情况下），因此必须限制使用次数，还有一种方案是使用ALBERT，它是一个简化版的BERT，效果差异不大，但模型只有BERT的几十分之一大小，速度也更快一些。</p></li>
<li><p>是否需要使用自己构建的辱骂数据集对BERT做fine-tune，这是个两难选择，如果find-tune，那么BERT生成的文本更趋近辱骂，更容易被模型识别，如果不fine-tune，生成非辱骂文本，最终版本又可能通不过人工评测。且本地数据集都使用线下模型过滤得到，这样训练也可能会过拟合线下模型。</p></li>
</ul>
<p>笔者还做了另外一些尝试，比如训练GPT，使用BERT训练一个辱骂判别模型，把数据拆分成8:2分别用于训练和验证时，测试集的成功率在97-98%，从它模型的Embedding层以及隐藏层中抽取数据，希望能定位到一些辱骂的关键词，但是由于数据过于细碎，最终没能实现（当时没想到用gensim根据Embedding找同义词，以及用加减法做组合减去辱骂性质的方法，后来觉得非常值得尝试）。</p>
<p>笔者在本次比赛提交的最终版本中只使用了基本的BERT模型，每次选可能性最高的topN个词作为备选项，选出其中辱骂评分最低的，并限制了调用次数，同时尝试批量预测以节约时间。但调用次数太少，线上没能达到期望的效果。感觉最好的方法可能是使用BERT模型与评测工具相结合，先用辱骂数据fine-tune辱骂模型，然后在生成词的过程中将评测工具的得分作为评价，让模型向生成非辱骂的方向进化，听起来就很矛盾，也还没来得及尝试。</p>
<h4 id="其它算法">其它算法</h4>
<p>除了上述典型方案之外，笔者还尝试了其它一些方法，下面列出其中比较有效的方法。</p>
<ul>
<li><p>计算差异<br />
对于句子“ABCDEFGHIJKLMKOPQRSTUVWXYZ”，从第1个字符开始，每添加一个字符，对该句进行一次评分，如：第一次“A”，第二次“AB”，并将二者差异作为B的评分，最终排序各词的辱骂性质，依次替换分数最高的词，如果替换后判别不是辱骂，则完成修改。这样的好处在于，对于26个词组成的句子，基础判别只需要做26次，也明显减少了替换次数。原理是如果某词加入后分数明显增加，则说明它是关键词（可能由于与前词组合后才变得关键），分越高越应该被替换。
除了从前向后添加，还尝试了从后向前添加，去掉某个词后对句子评分等方法，其中上述的从前向后添加方法效果最好。
在强化学习的评价中也涉及差异对比，用相对打分（绝对分值减均值）替代绝对分数，该方法在机器学习中也常用于抽取关键特征。</p></li>
<li><p>辱骂词替换<br />
估计绝大多数选手都使用了，敏感词替换，比如把“某个亲属”，“某个动词”替换成非敏感词。这里笔者将其作为辅助手段，在其它处理完成之后进行了辱骂词替换。主要根据“网络敏感词”表中“色情”中的内容判别辱骂词。</p></li>
<li><p>高频词<br />
另外一种定位高频词的方法是使用蒙特卡罗方法定位各句中可能性最大的辱骂词，并统计其中最高频的词，然后对各句替换这些词。</p></li>
</ul>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-ef15dbf50045f509.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>可以看到，最高频的词是“你”，当时笔者认为这个词太普遍，并未加以处理（此处埋下伏笔），而对其它一些更明显的辱骂词做了变换。</p>
<ul>
<li>与黑盒对抗<br />
线上模型对选手来说几乎是黑盒，它与线下评测版本的差异只能靠猜测和试榜（尽可能多提交版本，通过线上得分猜测其内部逻辑）。这样对抗限制了很多模型的效果，因为线下评分变好，可能是对线下模型的过拟合，线上反而可能变差。换言之，这不完全是一个有监督学习问题，因为线下的label并非线上的label，同样也不完全算强化学习问题，因为线下的reward也不是真实的reward，除非我们自己在线下实现与线上类似的评测逻辑（短时间内很难做到）。<br />
另外一个难点在于，最后还加入了人工评测，需要让线上模型认为不是骂人，而人认为是骂人，又增加了一层难度，且这个层面的判别完成没有label和reward可用。</li>
</ul>
<h3 id="借鉴他人算法">借鉴他人算法</h3>
<p>终于在比赛结束前的最后一个小时冲进了排行榜第一页（Top20），感觉像长跑比赛里，已经筋疲力尽，还被前面的同学落下好几圈，终于坚持跑到了终点，然后豁然轻松。晚上大家就在钉钉群里公开了很多方法，果然脑洞大开，总结如下：</p>
<h4 id="弱点攻击">弱点攻击</h4>
<p>一位大侠的算法是把实例中所有的“你”字替换成与之类似的同音同意字，并在该字之后加一个阿拉伯数字，只用一行代码打到600多分，完胜所有人。
相信很多同学也观察到了辱骂中“你”字的特殊性，但“你”在人的认知中明显不是辱骂词。后来赛方也在聊天时说，对有些明显的辱骂词做了保护，但也没特殊处理“你”字，这便形成了最终被击破的漏洞。
只替换“你”提分有限，更有趣的是他还在“你”后面加了数字，笔者认为这个方法可以用于攻击文字组合后的特殊含义，尤其是打破了CNN、RNN类模型的前后依赖性，能想到这点也很厉害。
<strong>（第六个知识点：模型原理）</strong>
添加的还是“数字”，其实在赛方提供的demo中，就可以看到如果将“死”替换成４就能骗过模型，数字也可以算是一个漏洞，或者说暗门。而这位排名第一的大侠有效地结合了上述三点。</p>
<h4 id="在文中加减内容">在文中加减内容</h4>
<p>大家也分别尝试了向文中加符号，加空格，加文字来降低其辱骂性质，尤其对于短文本，试想如果句子只有两个字，全部替换掉，则相似度得分为0，只替换其中一个，还可能被识别为辱骂，加入内容也是个好办法。但不知为何，笔者尝试后并没提分。删除内容也是一种方法，尤其是长文本可能导致大量计算，适当删减也是一种好办法。</p>
<p>####用词向量找同义词<br />
定位辱骂关键词，并找同义词替换，也是一种普遍使用的方法，有人使用了腾讯词向量，它提供800多万中文词条，相对于传统的同义词词林或词表来说，可以说非常高科技了，但是它提供的是一个通常意义上的词义，自然语言任务可用它从文字中提取特征向量化（供机器学习算法使用），下面是官方给出的示例。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-004c8708df921cc8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>除了近义词，Gensim还提供了加法减法功能，比如“king” - “man” + “woman”
≈”queen”，也是很好的想法。
腾讯词向量虽然内容丰富，但是速度也非常慢，使用赛方提供的词向量可能更好一些，另外，还可以用辱骂语料训练模型，并从中提取词向量，以及使用上面提到的减法功能。已在blog上具体用法文档。<br />
<strong>（第七个知识点：知识面）</strong></p>
<h4 id="梯度攻击">梯度攻击</h4>
<p>赛方比较推荐的方法是梯度攻击，其原理是调整输入让损失函数变大，具体做法是损失函数对输入求导，然后根据导数方向调整输入数据，调整Embedding层数据后再通过词向量工具反推具体文字。很巧妙的方法，如果不看论文，自己很难想到。</p>
<p>####Fasttext模型<br />
赛方给出的线下评测是Fasttext模型，速度快且效果好。赛后看了fasttext相关论文，发现似乎还可以从简单模型与深度学习模型的差异下手来寻找漏洞，比如n-gram一般涉及的相关词很少，因此通过拉大词距，就可能造成干扰，也可以从中提取词向量特征，词袋模型不支持语序等等。</p>
<h3 id="总结">总结</h3>
<p>攻击比赛需要研究对方的算法原理，弱点。这一次没有深入探索赛方提供的信息，本来是半黑盒，让我理解成了全黑盒。没好好读题，然后越走越偏，太多explore又太少exploit，需要在未来的比赛中认真对待。</p>
<p>比赛和真实场景有很大差别，比赛可以通过试榜、拟合评价函数争取高分，而实际场景中更重视问题本身，比如怎么能更好地识别辱骂，更好的保留句意和辱骂性质同时骗过模型，如何利用新的技术，泛化现有算法，而不仅是捕捉模型的漏洞。</p>
<p>这次虽然成绩不佳，但也收获颇丰：有的领域从未知到已知，有的从模糊到了解，有的从知道到使用。非常感谢赛方提供的平台以及活跃在讨论区的小伙伴们。</p>
<p>赛后一周回顾了比赛相关的技术，写了一些文档：</p>
<p>生成对抗网络GAN<br />
https://blog.csdn.net/xieyan0811/article/details/104297872</p>
<p>序列对抗网络SeqGAN<br />
https://blog.csdn.net/xieyan0811/article/details/104820731</p>
<p>自然语言处理——使用词向量（腾讯词向量）<br />
https://blog.csdn.net/xieyan0811/article/details/104737002</p>
<p>梯度攻击<br />
https://blog.csdn.net/xieyan0811/article/details/104790915</p>
<p>轻量级BERT模型ALBERT<br />
https://blog.csdn.net/xieyan0811/article/details/104838175</p>
<p>强化学习（一）基本概念和工具<br />
https://blog.csdn.net/xieyan0811/article/details/104848328</p>
<p>Fasttext快速文本分类<br />
https://blog.csdn.net/xieyan0811/article/details/104873708</p>
<p>最近准备换一份自然语言处理（或者深度学习）相关的算法工作，工作地点最好在北京海淀附近，可以给个机会的小伙伴请与我联系哦。
:P 邮箱xieyan0811@sina.com，微信66768512。</p>
]]></content>
      <tags>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战淘宝穿衣搭配</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E6%B7%98%E5%AE%9D%E7%A9%BF%E8%A1%A3%E6%90%AD%E9%85%8D/</url>
    <content><![CDATA[<h1 id="实战淘宝穿衣搭配">实战淘宝穿衣搭配</h1>
<p>#算法实战</p>
<h2 id="说明">1. 说明</h2>
<p> 《淘宝穿衣搭配》比赛是2015年的一个天池算法比赛，现已开放为新人赛，仍可下载数据，上传结果及计算排名。具体地址是：
<a
href="https://tianchi.aliyun.com/getStart/information.htm?spm=5176.100067.5678.2.78904065HrZLpP&amp;raceId=231575">https://tianchi.aliyun.com/getStart/information.htm?spm=5176.100067.5678.2.78904065HrZLpP&amp;raceId=231575</a><br />
 这是一个集图片、文字、数据挖掘于一体的比赛，可下载的数据是千万级的，在网上也可以找到冠军及一些选手的解题思路。新人可用来练手，通过评分定位自己的实力，也能从前人的思路中受到启发。</p>
<h2 id="具体问题">2. 具体问题</h2>
<p> 竞赛数据包含三部分，分别是：商品基本信息数据（分类、文本、图像）；用户历史行为数据（用户、商品、购买时间）；和专家提供的搭配套餐数据（商品组合）。任务是预测给定商品最佳搭配的前200个商品。
具体计分公式是：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-00414b564e156a61.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>其中n表示答案集合中商品的数量，p(k)表示在k截断之前的预测准确率，当第k个商品在答案集合中Δ(k)为1，否则为0。从中可见：在答案中越靠前的商品权重越大。<br />
 购物表数据共1361万条，用户110万个，50万种商品，不重复关键字8万多个，280种分类。</p>
<h2 id="问题分析">3. 问题分析</h2>
<p> 测试集中的数据均未出现在专家推荐表中，无法直接使用专家推荐。测试集中出现的商品大约有一半即没被购买过，也没被推荐过，要想对预测它的搭配，就需要找到与之类似的商品。因此本题可分解成两部分：求某商品的最佳搭配，求某商品的近似商品。<br />
 求最佳搭配，可在专家推荐表中获取商品所在组中的其它商品，用户购买记录可将用户在某一时段购买的商品认为是可配搭商品，并从中减掉不可搭配的品种。不可搭配的品种由专家推荐表算出，280个类别可以有约280x280种组合，而专家给出的可组合类别只有不到1000种。<br />
 求近似商品，可通过商品信息中商品的分类，关键字，图片计算，主要使用在同类中找关键字TF/IDF加权后最近似的商品。</p>
<h2 id="无监督学习和半监督学习">4. 无监督学习和半监督学习</h2>
<p> 此题代表了一类典型的问题：从以往的用户行为中寻找规律，以便辅助和引导用户之后的行为，像视频，新闻，购物推荐都属于此类问题，俗称啤酒尿布问题（在超市购物时买尿布的往往也买啤酒）。<br />
 此题应该算是一个无监督或半监督学习问题。尽管用公式给出了计分标准，但开发者仍不知道预测搭配的5000x200项中，具体哪些正确的，哪些是错误的。线上每天只有两次评分机会，根据其反馈只能在粗略的方向上调整。<br />
 因为是无监督学习，各个特征影响的大小，很多都是靠人和经验和猜，然后花大量的时间在线上验证自己的猜测，监督学习算法，迭代改进算法都无法使用。于是在第二赛段，有些选手将其改造成半监督学习：通过专家推荐生成正例，通过随机抽取生成反例，这样就可以代入算法了。
常用于处理无监督学习的方法有聚类，关联规则，规则等等。</p>
<h2 id="规则算法">5. 规则算法</h2>
<p> 有人把此题解法戏称为“规则吊打”，就是说它非常考验规则。再看看自己的解法，以及别人分享出的算法，前期几乎都是“人”总结出来的规则，比如：同一个人在同一季节购买的更可能是搭配，对同时购买次数进行排序，有些类别不适合搭配等等。如果不知道数据的具体意义，这些规则都无法获得。当然，这也是特征工程的一部分。<br />
 常见的与规则相关的算法有从决策树中抽取规则，它是一个监督学习；还有关联规则，比如Apriori算法或Fp-Growth算法，基本都属于统计类算法，该类算法也适用于本文中的问题。</p>
<h2 id="文本分析">6. 文本分析</h2>
<p> 题目给出的数据中包括商品的描述，给出的不是具体的文字，而是其关键字转换成的ID号，就是说一个商品的描述信息由多个
ID号组成。如果两件商品都包括很多同样的关键字，则说明它们可能是近似商品。这只是一个粗略的比较，可能与一件相品关键字个数相同的几百件商品，所以还要考虑每个关键字的重要程度。几乎所有人都使用了TF/IDF算法，使用中也有一些技巧，比如在什么范围内取IDF？是在同一类中取，还是在所有商品中取。</p>
<h2 id="图像处理">7. 图像处理</h2>
<p> 除了数据表，此题还提供了好几G的图片，也是用来计算商品的相似度和搭配度的，由于图片太多，处理时间太长，并且需要大量存储空间，所以很多人都忽略了该特征。也有人处理了其中的一部分，比如只在找不到搭配信息，没有购买记录，又找不到关键字类似的商品时，才分析其图片信息。求取图片特征的方法可以用SIFT（有相应的python库），即尺度不变特征变换。</p>
<h2 id="一些小技巧">8. 一些小技巧</h2>
<h4 id="大数据问题">(1) 大数据问题</h4>
<p> 此题应该算是数据量较大的问题，一次处理上千万条数据，内存不够会让程序运行起来非常慢，又只能使用一个cpu，因此在前期处理时，可切成了几个小数据集，用多线程分别计算后再合并。</p>
<h4 id="按时间分组">(2) 按时间分组</h4>
<p> 除了统计每个用户购买的所有商品以外，还需要考虑季节，比如冬天的不能和夏天的搭配，可使用判断前后一个月内购买，以及将时间分为春夏秋冬等方法。</p>
<h4 id="简化成模型">(3) 简化成模型</h4>
<p> 题目给的信息量很大，而我们关注的只是测试集中的5000个商品，以及与它近似的商品，因此，在前期可以先不考虑简化成模型，因为简化都或多或少会造成数据损失。</p>
<h4 id="上传结果评分">(4) 上传结果评分</h4>
<p> 如果同时改进了几个问题，那最好分开评测，因为同时提交，会分不清哪些是加分项，哪些是减分项。</p>
]]></content>
      <tags>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战美年健康AI大赛之一_自然语言处理</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E7%BE%8E%E5%B9%B4%E5%81%A5%E5%BA%B7AI%E5%A4%A7%E8%B5%9B%E4%B9%8B%E4%B8%80_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<h1
id="实战美年健康ai大赛之一_自然语言处理">实战美年健康AI大赛之一_自然语言处理</h1>
<p>#算法实战 #自然语言处理</p>
<h2 id="说明">1. 说明</h2>
<p> 一直想找个自然语言处理（NLP）相关的比赛．起始看到＂美年健康AI大赛＂的时候，觉得和之前糖尿病比赛很相似，还是GBDT调参大赛．解包一看几百兆数据，觉得自己机器可能跑不动（后来确实加了一条内存），都没打开看数据就放弃了．<br />
 后来两个朋友都推荐做这个比赛，说是NLP的，打开数据一看，欸～还挺有意思的．数据量大的好处是稳定，我线上线下基本是同增同减（只提交过三次，目前为止是同增同减），就是看那病情诊断看得心惊肉跳的，腿都软了．</p>
<h2 id="比赛介绍">2. 比赛介绍</h2>
<p> 言归正传，介绍一下比赛内容，比赛提供了涉及5万多人的800多万条各项体验数据，有数据型的，也有字符型的．体验项目名称经过了脱敏处理，检查结果的文字内容未脱敏，目标是预测：收缩压、舒张压、甘油三酯、高密度脂蛋白胆固醇和低密度脂蛋白胆固醇这五项指标，预测具体的值，是一个回归问题．简单说就是分析哪些指标与高血压／高血脂相关．<br />
 我使用的是lightgbm模型，简单调参，对字符串只做了一些简单的处理，过滤出一些我认为重要的文字特征，当前最好成绩是0.03002（今天中午）．NLP建构正在进行中．<br />
 估计最后大多数人还是使用GBDT类算法，对于模型调参和基本的特征工程就不再重复，详见之前的＂糖尿病比赛＂．<br />
 本文主要说说自然语言处理，此处的目的是把文字转换成数值，枚举，或者布尔类型，以方便代入模型．数据里面包含了很多文本，粗算也有上百万条，其中涉及至少几百种类型的检查，眼科，牙科，心脏，Ｂ超等等，不可能为每种检查写一套正则表达式，下面来看看如何使用NLP的方法简化工作．</p>
<h2 id="专业领域的自然语言处理">3. 专业领域的自然语言处理</h2>
<p> 一开始做的时候首先想到用一些现成的工具，比如snowNLP或者jieba把文字分成短句，词组，取其中的关键词等等．然后发现，医疗报告相对于普通文章有很大不同．普通文章可能有各种句式，各种结构，篇幅可能很长，其中可能有些和主题无关的信息等等．体验结果中的文字，结构相对比较简单．<br />
 先来看看提供的txt数据，它包括：用户id，体项项目名称，体验结果．体验结果可以分成四种情况：<br />
 第一种：纯数值型，无需处理．<br />
 第二种：枚举型及其变种，如：＂阴性＂，＂未见异常＂等等，简单处理即可转成数值．<br />
 第三种：简单混合型，如：＂&gt;100次/分,窦性心动过速＂，此类型以数值为主．<br />
 第四种：复杂混合型，如：＂甲状腺内见多个低回声结节，最大位于右叶约14mm×8mm，结节周边有血管环绕＂．这种情况可能是纯文字，可能是文字和数值混合，相对比较复杂，也很有趣，它包含了第二和第三两种情况．</p>
<h2 id="预处理">4. 预处理</h2>
<p> 在处理文本之前，先要做些预测处理，比如：归一大小写，各种符号的全角半角，处理输入错误，多余的空格等等．</p>
<h2 id="枚举型及其变种">5. 枚举型及其变种</h2>
<p> 常见的一些枚举有＂正常＂，＂未见明显异常＂，＂阴性＂，＂阳性＂，以及加减号等等，相对来说比较容易判断．需要注意的是同一内容可能有几种不同的表达，此时需要判断它的关键词，尤其是注意其中的包含否定词．只要unique()少，就适合将其视为枚举处理．</p>
<h2 id="简单混合型">6. 简单混合型</h2>
<p> 文本中会有长句包含短句，括号内外等等情况，这里只考虑：以数值为核心的短句．这经常出现在一个字段中其它都是纯数字，而某几个值被写成＂&lt;30次＂．如果一个短句含有数字，可以把它分解成三部分：前缀+数字+后缀．其中数字又包括：数值，符号，单位．我处理的方法是将其拆分后保存在结构中，借助Python灵活的结构，这一操作并不复杂．<br />
 同时还要需要考虑包含多个数值的情况，比如：&lt;
30（正常范围30-50）．分优先级处理，比如括号内的优先级更低，带大于小于和范围比具体数值优先级更低等等．如果不借助结构，直接用正则判断会非常复杂．<br />
 数字部分除了0-9和小数点正负号外，还可能包含大于，范围，描述面积体积的乘号等等，也是有限的几种情况，可以分别用正则实现．<br />
 后缀以单位为主：长度，体积，频率等等，可能性有限，可一一列举．<br />
 前缀和其它后缀可能是一些描述性信息，其中也可提取出一些信息，比如：＂左眼/右眼＂，可能涉及一个体验结果用多个字段描述，放在复杂混合型中讨论．</p>
<h2 id="复杂混合型">7. 复杂混合型</h2>
<p> 复杂混合型是最难处理的一种情况，里面包含大量的医生诊断信息，很重要．这类特征大概有100种左右．在此也能尽量多地使用自然语言处理的方法．<br />
 第一个技术是递归分组，文本中会有长句包含短句，括号内外等等情况，首先要分组，大组（段）包括中组，中组（句）包含小组（词），以及再小的组，有些数据分成足够小的组，就可以用枚举和简单型来处理了．<br />
 第二个技术是词性，有一些现成的工具可以分词，给出词性，而名词一般是核心词，可以把一个短句看成三部分：1什么东西，2怎么了，3具体数值．<br />
 第三个技术是TF/IDF，这与词频相关．举个例子：肝脏Ｂ超报告，人看一遍就能从报告中总结出以下特征：形状，血管，无回声区及其大小，大概五六种重要指标．这些描述指标会在文本中多次出现，这就需要查找出现次数多的词，另外还需要去掉一些每个特征都可能包括的关键字，比如＂正常/大小/高/低＂．此时就可以对一个体验项目取出一组关键词，然后把这些关键词相关的属性（第二/三个技术）分别归入不同特征．<br />
 另外还可以边提取边筛选，比如说：我们得到了新的bool型特征：肝上是否有囊肿，可以计算它的不同取值(有/无)时，目标值的统计数据是否发生变化，假设：高压均值为120，如果在有囊肿的情况下高压均值为125，则说明这个新特征有意义．</p>
<h2 id="其它">8. 其它</h2>
<p> 首先，需要用经验手动做一些映射表，比如同一字段中出现的＂S＂与＂敏感＂，未见异常的Ｎ种说法．<br />
 另外，还有一些＂后门＂，早晚有人说，现在说出来，总比最后一天才说强：文字信息会带一些＂血压＂，＂血脂＂相关的关键字，就是前面说的＂关键文字特征＂．有的特征里直接就写＂血压高＂．如果不想做复杂的NLP，可以写正则只分析这些特征．相关的还有＂血糖＂，＂肥胖＂之类的关键字，举一反三吧．（感觉这么说有点搅局）</p>
<h2 id="总结">9. 总结</h2>
<p> 综上，特征工程阶段使用了数值处理，自然语言处理，正则表达式．在结构上涉及层层包含的关系，自动生成判断逻辑（进行中…）．我理解NLP并不只是分词，主谓宾定状补的解析，词间的相似度，它在各个层次上的抽象也很重要．尽量自动化处理．虽然目前不能避免人工干预，但是程序也确实在很大程度上减少了工作量．<br />
 我觉得来回试榜效果不好．心里很浮躁，反正现在时间还早，不如在深度和结构上多花点时间．如果做下去再有一些新的思路，后续再加文档吧．</p>
]]></content>
      <tags>
        <tag>自然语言处理</tag>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战美年健康AI大赛之三_大数据量的简化</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E7%BE%8E%E5%B9%B4%E5%81%A5%E5%BA%B7AI%E5%A4%A7%E8%B5%9B%E4%B9%8B%E4%B8%89_%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%87%8F%E7%9A%84%E7%AE%80%E5%8C%96/</url>
    <content><![CDATA[<h1
id="实战美年健康ai大赛之三_大数据量的简化">实战美年健康AI大赛之三_大数据量的简化</h1>
<p>#算法实战</p>
<h2 id="说明">1. 说明</h2>
<p> 美年健康也是一个认真打的比赛，初赛Ｂ榜最高分0.0279，排名15．<br />
 最初是想用它实践一下自然语言处理，后面发现，另一个与之前比赛不同的地方，就是数据量很大，之前也做过几十上百万条记录的，但是特征少，这次57000多个记录，2700多个特征．从提取特征到训练完成，我的代码要跑近三个小时，后来审核代码的阶段，在群里看到很多人代码都需要运行很长时间．<br />
 初赛90%以上的时间都花在自然语言处理上了，像去噪，特征筛选，调参，模型组合，结果分析几乎都没做，能刷到第15，应该偷笑了．<br />
 在初赛结束后的几天里，开始尝试特征选择，希望优化整个过程，才发现数据量大的不能像之前那么处理．上述没做的那些，不是没有精力，是没时间．在大数据上做这些太花时间．在”大数据”里面，应该先要做一些简化，否则很多时间都浪费掉了．<br />
 本篇就来说说大数据和小数据的不同点以及应对方法．</p>
<h2 id="提取特征">2. 提取特征</h2>
<p> 这个题里面有些文本特征，和一些文本数值混合特征．首先要做的是清理和提取，尤其是”-1”,”正常”,”未见异常”,”阴性”，其实是同一种情况，还有不同单位换算，如果这些不处理好，用什么模型效果都不好．<br />
 尽管特征已经很多，但还得加，因为像Ｂ超结果，它确实能提供数值以外的其它信息．<br />
 文本中携带的信息太多了，总结一下大家的做法：<br />
(1) 先把文本为主的和数据为主的分开．<br />
(2)
对文本为主的：分词，提取关键字，统计出现频率（TF/IDF，聚类等等）．<br />
(3) 判断高频词是否在字段是存在，生成一些的的布尔特征．<br />
(4)
人工检查高频文本，选出像＂脂肪肝＂，＂高血糖＂这样的关键字及字段写正则．<br />
(5) 还有直接在Excel里用公式做的，手工改的…<br />
 总的来说，还是＂数据太多＂，如果只有几个文本字段，且每个都不长，写判断或者正则就好了．但如果是上百个特征，就只能采取一些自动的方法了．<br />
 在这种情况下，注意边取边筛，使用一些＂单变量特征选择＂的方法，比如计算特征与目标的相关性，分析残差等方法，以避免爆炸式增长．</p>
<h2 id="特征筛选">3. 特征筛选</h2>
<h4 id="删掉缺失值太多的特征">(1) 删掉缺失值太多的特征</h4>
<p> 怎么衡量缺失值的多少？比如说决策树每个叶节点至少20个实例，那么非空实例小于20的特征肯定没用．从本文中提取特征，也是同理．</p>
<h4 id="删掉无意义特征">(2) 删掉无意义特征</h4>
<p> 如果该特征所有取值都是1，它就没有判断价值，很少有这样的．但可能会有如果有值则为1，其它全空的情况，这就要看如何处理缺失值．如果均值填充就变成全1了．还有枚举型某种取值实例太少，不足一个叶节点的情况．总之，需要看看分布．</p>
<h4 id="删掉重复特征">(3) 删掉重复特征</h4>
<p> 可以直接用drop_duplicates删掉的并不多，但在上千个特征的采集过程中，一般都会有些显性和隐性的重复，比如：＂子宫＂，＂输卵管＂这些关键字与＂血压＂强相关，原因是＂性别＂和＂血压＂强相关．所以这样的关键字提取很多也没什么用．<br />
 此时可以分析特征间的相关性corr()．corr()只能检测线性相关，所以绝对值如果低并不说明无关，但如果值高，一定相关．那如果两个特征相关性为1，就可以去掉其中一个了？也不行！计算相关性时一般忽略掉空值，这个也要考虑在内．</p>
<h4 id="单变量特征筛选">(4) 单变量特征筛选</h4>
<p> Sklearn也提供了一些特征筛选的方法：sklearn.feature_selection.*，比如SelectKBest可以支持卡方Chi2．Sklearn对数据有一些要求，比如有的要求非空．<br />
 另外用于检测单变量与目标相关性的还有互信息，皮尔森相关系数，最大信息系数等等．<br />
 残差分析也是一种常用方法．简单地说就是：计算当X位于不同取值范围时，Y均值的变化．从而检查X是否对Y有影响，它能检测到一些非线性相关的情况．</p>
<h4 id="基于模型的特征选择">(5) 基于模型的特征选择</h4>
<p> 基于模型的特征选择，指用模型训练完成之后，通过模型输出的特征重要性feature_importances_，选取其前N个特征．<br />
这个是训练之后才能得到的数据，都训练完了，时间都花掉了，才选出特征有什么用呢？这是个先有鸡还是先有蛋问题．<br />
 首先，用这种方法选出的重要特征可以更好地解释模型和数据．而且它是多特征组合的结果，不只考虑了局部特征．<br />
 另外，还可以用它筛掉一些干涉性特征，比如做10折交叉验证，其中9次都认为某特征不重要，其余那一次，很可能是干扰，也算一种统计吧．<br />
 一个小技巧是，在提取特征的过程中，可以边提取边训练（设置参数，少量实例，少量特征以快速训练）至少能粗分出某个新特征重要与否，是否应该保留．</p>
<h4 id="其它方法">(6) 其它方法</h4>
<p> 还有主成分分析PCA等方法．方差分析 ANOVA，信息值分析IV等等．<br />
 上述都是从特征角度筛选，还有从实例角度筛选（不限于此题），比如分析广告和购买时，那些从来不买东西，从来不点广告的人，可能就需要另外处理，或者在回归前先做个分类，计算一些统计特征（有点跑题了）．</p>
<h2 id="选择模型">4. 选择模型</h2>
<p> 在梯度下降决策树GBDT类算法为例，不同的工具，用时不同，优势不同．<br />
 xgboost比sklearn自带的GBDT快，lightgbm比xgboost快，catboost最慢，但它在小数据集中效果好．一般情况下，xgboost得分一般比lightgbm要高一点．<br />
 也没有哪个好，哪个不好，针对不同的情况选择不同的模型吧．像这种＂大数据＂的，lightgbm相对快一些．</p>
<h2 id="交叉验证">5. 交叉验证</h2>
<p> GBDT类模型一般都会配合交叉验证，这样可以把所有训练数据都用起来，还能得到一个靠谱的本地得分．之前都用5折交叉验证，这次从5折改到10折，分数有明显提高．<br />
 折数设定和数据量相关，假设只有1000个实例，用10折交叉，仅有100个实例用来测试，可想而知，很多情况都测不到，结果不够稳定．如果有40000个实例，10折测试数据也有4000个，子训练集增加了4000，相对更合理．<br />
 但也有相应的问题，就是数据集越大，训练时间越长，5折变为10折，训练时间也会翻倍．</p>
<h2 id="总结">6. 总结</h2>
<p> 对于海量数据，除了建立集群，Hadoop以外，从特征到模型，能做的事情还很多．在数据多的情况下，无论是数据分析，去噪，筛选都需要自动做．我觉得还是多研究现有工具和自己写一些通用的工具吧．</p>
]]></content>
      <tags>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战美年健康AI大赛之二_相关问题与思考</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E7%BE%8E%E5%B9%B4%E5%81%A5%E5%BA%B7AI%E5%A4%A7%E8%B5%9B%E4%B9%8B%E4%BA%8C_%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%E4%B8%8E%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<h1
id="实战美年健康ai大赛之二_相关问题与思考">实战美年健康AI大赛之二_相关问题与思考</h1>
<p>#算法实战</p>
<h2 id="说明">1. 说明</h2>
<p> 上次把钉钉号写回复里了，最近就有不少师兄加我，问一些关于比赛的问题，五一后可能也没啥时间回复了，下面就把常见的问题统一总结一下，只是我个人理解，欢迎大家纠正指导。</p>
<h2 id="你用了哪些方法做到0.286">2. 你用了哪些方法做到0.286？</h2>
<p> 说出来可能有人不信，我只用了五折的lightgbm，参数都没怎么调，去缺失值，去噪，特征选择，归一化，模型融合，目前为止都没做，所有时间都花在NLP上了，其中很多试尝还在进行中，还未加入模型，也不知最终能不能提分。</p>
<p> 目前的方案中，一方面是把一些数值字符混合型数据变成数值型代入模型，另外还有在做NLP时发现的一些关键性的字段，提取出了其中是否含有某个关键字作为新的特征，总共涉及不到10个特征。</p>
<h2 id="怎么提分">3. 怎么提分？</h2>
<p> 常被问到的一个问题是被卡在某一瓶颈了，怎么提分？我觉得大多情况是特征不足。如果以数值为主，要多看看自然语言处理，再找些特征，毕竟特征决定了上限，而优化模型只能是不断接近该上限。</p>
<h2 id="不做nlp最高多少分">4. 不做NLP最高多少分？</h2>
<p> 这要看如何区分数值特征和文本特征，我的数值特征有2000多个，去掉缺失值多的也有1000多。</p>
<p> 是否使用NLP是很抽象的界限，像“详见纸质报告”和数值中的“单位”，“增大”，“减少”，对它们进行处理后数值变量会增加很多，这种处理算不算NLP呢？有人说用纯数值能到0.3以下，我觉得主要还是看怎么判定数值特征。</p>
<h2 id="从文本提取特征的方法都有什么">5.
从文本提取特征的方法都有什么？</h2>
<p> 有的文本特征我处理成：一个旧列对应一个新布尔列/数值列/枚举列，有的是一个旧列对应几个新列，主要还是和文本内容相关。</p>
<p> 特征有两千多列，确实不能一一分析，但仔细看一下，去掉可转成数值和枚举的特征之后，纯文本的特征顶多一百来个。</p>
<h2 id="特征多好还是特征少好">6. 特征多好，还是特征少好？</h2>
<p> 我觉得这就好比破案，线索肯定是越多越好，但真正用得上的，其实没几个．不是多少的问题，是质量的问题．</p>
<p> 一开始肯定要通过搜索，组合的方式寻找更多的特征，尤其像双高这种赛题，包含在文本中的特征太多了．但是在后期代入模型时，去掉一些无用和干扰的特征，速度和质量都会提高．</p>
<p> 在大数据集中的无用特征，会降低性能；在小数据集中的干扰特征，会过拟合测试集．美年数据相对比较多，加了无用特征降分的影响其实不是太大，就是比较花时间（降也降不了太多）。</p>
<p> 所以我觉得应该是：寻找更多高质量特征，去掉低质量特征．＂模型狗代言人＂在糖尿病比赛top2技术分享贴（在天池精准医疗大赛的技术圈），＂北方的郎＂在盐城上牌答辩上（在往期直播中），都介绍了特征筛选方法及其效果．</p>
<h2 id="有什么自然语言处理相关的书籍">7.
有什么自然语言处理相关的书籍？</h2>
<p> 乔姆斯基是现代语言学的泰斗级人物，传说他著作的引用率排名人文领域的前10位（仅次于马克思，列宁，莎士比亚，圣经，亚里士多德，柏拉图和弗洛伊德，排在黑格尔和西塞罗之前）．他的书就是所谓＂经典著作＂：人都希望已经读过，但却没人愿意去读．比较学术性，需要花大量时间和精力。中文译本也不多，他的理论在研究过程中不断进化，如果想看，建议看他后期的作品。反正我是读不下去:P</p>
<p> 我比较喜欢史蒂芬•平克，他的书可以归类为：自然语言，生物科学，心理学，或者人工智能．幽默且文笔非常好，看起来比较轻松．做自然语言处理，推荐看他写的《语言本能》．如果有空，推荐看他的＂语言与人性＂三部曲：《语言本质》，《思想本质》，《心智探奇》，都是大而厚的书．</p>
<p> 从技术的角度，推荐《Python自然语言处理》，以NLTK为核心，其中有很多实例和习题，可以边看边做．不过主要针对英文．<br />
如果，各位师兄有什么好的推荐，请给我留言．</p>
<h2 id="常见的坑">8. 常见的坑</h2>
<p> 大家都希望构建一个对所有特征都可用，且简单明了的处理逻辑。但我觉得自然语处理相关的问题，并没那么简单，它更像是建立一棵树，我们把不同情况归类，对各个类别使用不同的处理方式。大家很多时候是卡在找不到一种通用的处理方法，而不是完全没有思路。而通用的方法可能根本就不存在。</p>
<h2 id="为啥比赛">9. 为啥比赛？</h2>
<p> 之前试过同时打几个比赛，有时候一天几套代码来回切．但是效果非常不好，回头看就是哪个都没能深入．我希望自己在每个比赛中都有不同的提升，不是名次的提升．</p>
<p> 比如糖尿病的核心的GBDT模型和特征工程，双高是自然语言处理，汽车上牌是时序问题，之后还想找些神经网络和图片的．但是有时候不自觉的，用习惯一种模型就变着法得往里代入．</p>
<p> 参加比赛的目的是什么？不可能每个人都排名前十，排行榜除了激励作用，其它名次还有啥用？虽然我在竞争过程中，也不自觉地刷名次．</p>
<p> 重要的还是在研究问题过程中的积累吧，我以文章的方式积累，也有积累代码的，积累人气的……至少想清楚，积累什么？否则很容易被环境左右，弄得挺闹心的。</p>
<h2 id="是菜鸟还是大牛">10. 是菜鸟还是大牛？</h2>
<p> 加好友，常被问到的问题有：学弟 or
学长？毕业了吗？你多大？在哪个城市？工作了吗？工作几年？——各种标签．先评价一下能力，毕竟这不是个交友的平台，合作就要看水平；然后，看一下是不是一路人；再决定交流的态度；其实不用那么麻烦．</p>
<p> 劝一句：新来的同学，有什么问题，客气点直接问，毕竟加了好友，一般知道的，能说的，都会说．像比较核心的，或者占用大量时间和精力的，需要的亲密关系也不是一半天能建立起来的．搭顺风车和走捷径也并不容易．</p>
<p> 再劝一句：大神，您也尽量保持谦虚和开放的心态．谁说大牛都得德艺双馨、有问必答，还都得回答正确？能帮上忙的不妨搭把手，不想说不想做，就客气的说NO好了，无需解释，也无需想太多．<br />
 （我既不是大神，也不是菜鸟）</p>
<p> 如果我跟你说“大神，以后我有问题就找你了啊！”，你啥感受？</p>
<p> 之前旁听过一段佛教《中观》课，里面的同学无论男女老幼都互称师兄，第一次被一位大爷叫师兄的时候心里毛毛的，后来就习惯了．在说话前先称呼别人师兄的时候，也会不自觉地代入一种谦虚、朴素的心态．</p>
<p> 并不是想假装小学妹，只是觉得这样交流比较舒服。咱们互为师兄，相互学习。</p>
<p> 您说呢，师兄？</p>
]]></content>
      <tags>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战美年健康AI大赛之四_复赛使用数加平台</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E7%BE%8E%E5%B9%B4%E5%81%A5%E5%BA%B7AI%E5%A4%A7%E8%B5%9B%E4%B9%8B%E5%9B%9B_%E5%A4%8D%E8%B5%9B%E4%BD%BF%E7%94%A8%E6%95%B0%E5%8A%A0%E5%B9%B3%E5%8F%B0/</url>
    <content><![CDATA[<h1
id="实战美年健康ai大赛之四_复赛使用数加平台">实战美年健康AI大赛之四_复赛使用数加平台</h1>
<p>#算法实战</p>
<h2 id="说明">1. 说明</h2>
<p> 美年健康AI大赛的复赛是线上赛，只能使用数加平台。第一次用数加，也遇到一些问题，在此总结一下。</p>
<h2 id="问题及解答">2. 问题及解答</h2>
<h4 id="如何登录">(1) 如何登录？</h4>
<p> 得到复赛资格之后，天池赛题网页左侧的列表中就会多出一项“数加”，点击进入后，按提示得到RAM帐号，即可以登录“数据开发平台”和“机器学习平台”，注意登录帐号是用户名和企业别名的组合。<br />
 网页上提供的Demo有点旧了，是2015年的，那时候好像还叫“御膳房”。建议官方及时更新，这样大家可以节约点时间，技术支持人员也没那么累。</p>
<h4 id="如何访问数据">(2) 如何访问数据？</h4>
<p> 进入“数据开发平台”，点击上方的“数据管理”，即可进入数据界面，左侧的查找数据，可以通过关键字查找该项目下的表，像本题查找meinian就可以看到很多表，其中包括管理员建立的和其他参赛者建立的。
具体的项目名和表名见“赛题与数据”中复赛的说明。需要注意的是一般先要把项目数据用SQL复制到自己的空间中，然后再进行下一步操作。详见“代码分享”部分。
复制到自己空间后，就可以在“数据管理”-&gt;“个人帐号的表”中查看表信息了。</p>
<h4 id="如何写程序和运行">(3) 如何写程序和运行？</h4>
<p> 进入“数据开发平台”，点击上方的“数据开发”，在左侧的任务开发树中可以创建程序。这里提供了SQL，Shell，Python等工具。并支持目录结构。</p>
<h4 id="数加平台能否使用python">(4) 数加平台能否使用Python？</h4>
<p> 能否使用pandas的DataFrame？
之前听说数加平台只能用SQL+Java，于是很多人都重新学习工具，占用了大部分时间，美年初赛时大多数人使用的都是Python，也希望在复赛中使用初赛代码。那么数加平台能否使用Python呢？<br />
 不同比赛提供的工具不同，美年复赛可以使用Python，具体方法是右键点“任务开发”，“新建任务”，在类型中选择PYODPS即可编写Python程序。
PYODPS帮助文档见：<a
href="http://pyodps.readthedocs.io/zh_CN/latest/index.html">http://pyodps.readthedocs.io/zh_CN/latest/index.html</a></p>
<h4 id="odps是什么">(5) ODPS是什么？</h4>
<p> ODPS(Open Data Processing
Service),是阿里巴巴通用计算平台提供数据仓库解决方案．</p>
<h4 id="线上python如何访问数据表">(6) 线上Python如何访问数据表</h4>
<p> 从PYODPS帮助文档中看到，可以通过o访问数据表，而o通过以下方式获得：</p>
<pre><code>from odps import ODPS  
o=ODPS(&#39;**your-access-id**&#39;, &#39;**your-secret-access-key**&#39;, &#39;**your-default-project**&#39;, endpoint=&#39;**your-end-point**&#39;)   </code></pre>
<p> 大家花了很多时间找access-key,
access-secret，在个人信息中看到access-key不对子用户开放，然后我们就以为python不能用了，悲剧了。<br />
 其实在数加线上，o不用赋值就可以直接使用，access-key和access-secret是针对离线运行PYODPS的。希望官方在文档或者赛题中明确写一下（真心地没想到o可以直接使用）。<br />
 读写数据及odps与dataframe转换，详见“代码分享”部分。</p>
<h4 id="在何处提交结果">(7) 在何处提交结果</h4>
<p> 题目提供的表中有测试集a：meinian_round2_submit_a，把答案写入用户空间的该表中，系统则会在评测时间自动对该表内容评测。因此，复制库成功后，表的内容为全0，评测时就有了成绩，得分约为9.1781，很低的分数。</p>
<h2 id="代码分享">3. 代码分享</h2>
<p>（功能基本实现，代码还待优化，仅供参考）</p>
<h4 id="把数据复制到本地">(1) 把数据复制到本地</h4>
<p> 数据开发-&gt;任务开发-&gt;新建任务-&gt;ODPS SQL
写以下SQL语句，并运行（一共5个表，都用此方法复制）</p>
<pre><code>create table if not exists meinian_round2_data_part1 as select * from odps_tc_257100_f673506e024.meinian_round2_data_part1;  </code></pre>
<h4 id="其它常用sql语句">(2) 其它常用SQL语句</h4>
<p> 查看已有的表<br />
 show tables;<br />
 查看表内容<br />
 select * from meinian_round2_data_part1;<br />
 看表中有多少条数据<br />
 select count(*) from meinian_round2_data_part1;</p>
<h4 id="将odps转成pandas的dataframe">(3)
将ODPS转成pandas的DataFrame</h4>
<pre><code>from odps import ODPS  
from odps.df import DataFrame  
submit_basedata = DataFrame(o.get_table(&#39;meinian_round2_submit_a&#39;))  
submit_data = submit_basedata.to_pandas()  
print(&quot;total&quot;, len(submit_data))   </code></pre>
<h4 id="存储odps数据">(4) 存储ODPS数据</h4>
<p> 这个我写了还没等到评测，不一定对，仅供参考。
具体功能是把训练集的均值作为预测值，因为不太会用writer，直接调用总是追加数据，只好在每次添加之前删表又重建，此处有待优化。</p>
<pre><code>import numpy as np  
from odps import ODPS  
from odps.df import DataFrame  
from odps.models import Schema  
  
train_basedata = DataFrame(o.get_table(&#39;meinian_round2_train&#39;))  
train_data = train_basedata.to_pandas()  
  
submit_basedata = DataFrame(o.get_table(&#39;meinian_round2_submit_a&#39;))  
submit_data = submit_basedata.to_pandas()  
submit_data[&#39;sys&#39;] = train_data[&#39;sys&#39;].mean()  
submit_data[&#39;dia&#39;] = train_data[&#39;dia&#39;].mean()  
submit_data[&#39;tl&#39;] = train_data[&#39;tl&#39;].mean()  
submit_data[&#39;hdl&#39;] = train_data[&#39;hdl&#39;].mean()  
submit_data[&#39;ldl&#39;] = train_data[&#39;ldl&#39;].mean()  
  
table_name = &#39;test&#39;  
odps.delete_table(table_name, if_exists=True)  
odps.create_table(table_name,  
 &#39;vid string, sys bigint, dia bigint, tl double, hdl double, ldl double&#39;)  
t = odps.get_table(table_name)  
  
with t.open_writer() as writer:  
 outdata = np.array(submit_data).tolist()  
 writer.write(outdata)  
 print(&quot;outdata length&quot;, len(outdata))  
 writer.close()  
  
print(&quot;@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@&quot;)  
print(train_data.mean())  
print(submit_data.mean())  </code></pre>
<h2 id="基本步骤">4. 基本步骤</h2>
<ol type="1">
<li>把数据表复制到自己的用空间<br />
</li>
<li>将pyodps转成pandas的dataframe<br />
</li>
<li>数据处理和挖掘<br />
</li>
<li>将dataframe结果转回pyodps能识别的格式存盘。</li>
</ol>
<p> 我也刚开始做，觉得来好像这样转换一下，初赛的代码大部分就可用了。其它还没试，先这样吧，有空再写，祝师兄们马到成功
!!!</p>
]]></content>
      <tags>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战药物分子筛选之一_初探</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E8%8D%AF%E7%89%A9%E5%88%86%E5%AD%90%E7%AD%9B%E9%80%89%E4%B9%8B%E4%B8%80_%E5%88%9D%E6%8E%A2/</url>
    <content><![CDATA[<h1 id="实战药物分子筛选之一_初探">实战药物分子筛选之一_初探</h1>
<p>#算法实战</p>
<h2 id="说明">１. 说明</h2>
<p> 基于人工智能的药物分子筛选，是最近在DC大数据平台上看到的一个新比赛．这个题目对于我这种半科盲来说好难．花了一些时间才弄明白它是干嘛的．这是一家药品公词举办的比赛．我理解题目是这样的：给出三种数据：致病蛋白信息（病），小分子信息（药），蛋白和小分子间的亲和力（药和病能否结合），预测Ｎ种没见过的致病蛋白与已知的小分子之间的亲和力．简单地说就是知道一些病和药的特征以及它们之间的关系，预测一些新的病用什么药治．具体数据如下：</p>
<p>­­<img
src="https://upload-images.jianshu.io/upload_images/5357893-6fbf190be383ca8c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="数据分析">２. 数据分析</h2>
<p> 蛋白质由氨基酸组成，氨基酸一共有20种，每一种用一个英文字母表示．蛋白质有四级结构，一级结构是组成蛋白质的氨基酸序列，二三四级还有螺旋折叠什么时，这里我们只考虑其一级结构，即某个蛋白质由哪些氨基酸组成的，它们的长度以及前后顺序是怎样的．在给出的数据（df_protein*.csv）中，氨基酸序列形如：
FCIPTSSTIEQQNSTRVRQNTREHPSTANTVDRTNHQLENLEAETAPLP
它是一个由字母组成的序列．最长的一项长度为7023，最短的长度为26个字符．测试集给出了与训练集不同的蛋白质及其序列，用于模拟发现新致病蛋白的场景．</p>
<p> 小分子的数据（df_molecule.csv）中包含分子指纹及对应的18种物化属性，对于训练集和预测集是一样的．而亲和力数据（df_affinity*.csv）是蛋白质和小分子之间的关系（多对多），也是我们要预测的目标．</p>
<h2 id="算法分析">３. 算法分析</h2>
<p> 计算的目标是找到有哪些特征的小分子和哪些特征的蛋白质可以结合．小分子数据中包括20个特征，而蛋白质数据只包括氨基酸序列（后简称序列）．由于预测集和训练集中的蛋白质没有交集，所以只能通过序列来分析蛋白质的性质．</p>
<p> 比较理想的方法是将把序列拆分成一些氨基酸片断，把是否含有该片断作为蛋白质的特征，代入模型，问题就变成了用小分子的特征和蛋白质的特征预测它们之间亲和力数值大小的回归问题．</p>
<p> 如何拆分序列很关键．有点像自然语言处理（NLP）中，把一个中文句子拆成多个中文词汇，然后找出其中的关键词．而事先并不知道哪些字可以合成一个词，词汇也不定长，具体方法是用一些文章来自我训练，可使用类似Apriori寻找频繁项集的算法．</p>
<p> 从蛋白质的角度看，总是一起出现的字母组合可以看成一个词，在本题中即有意义的片断；从亲和力角度看，如果一个小分子对应的几个蛋白质中都含有相同的片断，可以将其视为有意义的片断．</p>
<p> 当然这里面也有一些坑，比如说某几个蛋白质对应的序列只有一个氨基酸的差异，我们也不能把它们相同的序列都认为是一个有意义的片断，就比如有三个句子：＂我喜欢春天的花＂，＂我喜欢春天的草＂，＂我喜欢春天的树＂．其中＂我喜欢春天的＂虽然同时出现了好几次，但明显不是一个词．另外还有大片断包含小片断等等情况．其中的序列长度范围，出现频率都需要边做边调整．</p>
<h2 id="相关知识">４. 相关知识</h2>
<h4 id="ik-analyzer">(1) IK analyzer</h4>
<p>IK
Analyzer是一个开源的,基于java语言开发的轻量级中文分词工具包．除了基于字符串的分词，还提供了基于统计和机器学习的分词．</p>
<h4 id="n-gram">(2) N-Gram</h4>
<p>N-Gram是一种语言模型，nltk工具集中包含此工具，它可以评价两个字符串的相似程度．常用于模糊匹配．比如我们可以用它衡量两个蛋白质之间的差异，配合最近邻类的算法使用．但是相对来说，这种算法不容易指向实质．</p>
<h4 id="gensim的word2vec">(3) Gensim的Word2Vec</h4>
<p>Word2Vec词向量，可将自然语言中的字词转为计算机可以理解的稠密向量．它描述了每个词和其上下文的词的集合的相关情况．</p>
<h4 id="ncbi">(4) NCBI</h4>
<p>NCBI (National Center for Biotechnology
Information）是美国国立生物技术信息中心。在这上面可以查到一些蛋白质序列和DNA序列的信息．</p>
<h4 id="blast">(5) BLAST</h4>
<p>BLAST（Basic Local Alignment Search
Tool）是一套在蛋白质数据库或DNA数据库中进行相似性比较的分析工具。BLAST程序能迅速与公开数据库进行相似性序列比较。其结果中的得分是对一种对相似性的统计说明。</p>
<h2 id="参考">５. 参考</h2>
<h4
id="蛋白质序列分析及结构预测-第一讲-httpswenku.baidu.comview7903145ad1f34693dbef3ed8.html">(1)
蛋白质序列分析及结构预测 第一讲
https://wenku.baidu.com/view/7903145ad1f34693dbef3ed8.html</h4>
]]></content>
      <tags>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战量化投资大赛之一_baseline</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84%E5%A4%A7%E8%B5%9B%E4%B9%8B%E4%B8%80_baseline/</url>
    <content><![CDATA[<h1
id="实战量化投资大赛之一_baseline">实战量化投资大赛之一_baseline</h1>
<p>#算法实战</p>
<h2 id="说明">1. 说明</h2>
<p> 昨天在群里看到了：凤凰金融量化投资大赛，详情见： <a
href="http://www.dcjingsai.com/common/cmpt/%E5%87%A4%E5%87%B0%E9%87%91%E8%9E%8D%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84%E5%A4%A7%E8%B5%9B_%E7%AB%9E%E8%B5%9B%E4%BF%A1%E6%81%AF.html">http://www.dcjingsai.com/common/cmpt/%E5%87%A4%E5%87%B0%E9%87%91%E8%9E%8D%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84%E5%A4%A7%E8%B5%9B_%E7%AB%9E%E8%B5%9B%E4%BF%A1%E6%81%AF.html</a>
看了一下数据，大概是利用过去两年Ｎ支股票的数据，预测未来半年的走势，然后再从这Ｎ支股票里选出20-50支作为组合，看谁的组合半年后收益最大，以此排名．数据包含股票代码，收盘价，和八十多个脱敏后的特征．</p>
<h2 id="一些想法">2. 一些想法</h2>
<p> 我关注的一支股票，昨天跌停了，今天该买还是该卖？单看涨跌和趋势线是没法判断．涨跌和很多因素有关，比如跌停日的交易量，消息面，基本面，外盘，大盘涨跌，近期趋势．一般跌停次日的涨跌的概率等等，人基本是通过这些因素综合判断．<br />
 估计上述的很多成分被包含在比赛提供的80多个特征之中（毕竟是专业人士给出的数据）．于是特征工程就简单了很多，可以更多地关注模型．当然像标准化，移动平均线这些特征还是需要做．<br />
 再看模型，预测未来半年走势，是时序问题，提供的多个特征，可以使用决策树分类或回归．提交的结果又用到排序．最近时序和特征的比赛特别多，前一段的盐城上牌，汽车销售，正在进行中的阿里妈妈转化率都是．<br />
 此题是对股票数据的一种呈现方式，以此类推，只要我们有基本面，技术面，消息面的大量数据，也可以构造类似的问题．比如说，把涨跌看成二分类问题，用历史数据训练，可能将命中率从0.5提高到0.6，看起来提升不大，但是如果机构有大量资金，可以购买几十上百支股票组合，并且有一个较长的交易时间段，那么算法的提升对应的就是收益，这也是大数定律的含义．</p>
<h2 id="一种简单的方案">3. 一种简单的方案</h2>
<p> 今天做了一种非常简单的方案，线上得分48左右，下面介绍一下原理．</p>
<h4 id="数据">(1) 数据</h4>
<p> 每个CSV代表一天的数据，按照从1-488的从小到大的时间序列顺序排列．文件中，第一列是股票代码，第二列是收盘价，后面是脱敏特征．<br />
 首先是把所有数据都放在一起，如果还存成csv的话，大概185M，总共有934支股票，取每天各股的均值，作为大盘指数看待，整体走势如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-5ee31fe067db253a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>这种情况不太常见，股票在三个月内涨了一倍，又迅速跌回原位．看了其中几支股票，和大盘走势都比较相似．</p>
<h4 id="分析">(2) 分析</h4>
<p> 先分析一下，争取最大程度地简化问题．因为不能空仓，无论大盘是涨是跌，手里必须拿着至少20支股票．就算未来半年暴跌，大家也必须持有．所以这个题的目标是不一定能赢利，但需要跑赢大盘，跑赢其他人，可以看作各股和大盘之间的关系．<br />
 当然大盘的趋势对选股也有影响，比如在下降趋势中就趋向更保守的操作．选股个数在20-50之间，预测的股票个数越多，算法越保守，因为排在后面的趋势没那么明显．
本次的具体解决方案是：取出大盘指数，然后挑选和大盘相比走势最强的20支股票，整个过程中只用了线性拟合，也没拆分训练测试集，只是最最简单的方法．</p>
<h4 id="去掉大盘趋势">(3) 去掉大盘趋势</h4>
<p> 实验证明，去掉大趋势时，除法比减法效果更好．因为对不同股票作归一化不太容易，这里选择了除法．下面四条曲线中，红色是大盘走势，蓝色为某股走势，黄色为该股减大盘，绿色为该股除大盘，相对的，绿色曲线更能表征该个股的特征，去除大盘的因素，绿线趋势向上，其斜率即紫色线．</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-e098d5684a4ac289.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 计算周期不一定是两年，可以是一年，半年等等，计算出它的斜率，再比较出斜率最大的前20，就是该模型的结果．
这个模型也有些问题，比如，选出来的很多是次新股，另外，还要考虑当前的价格是不是太贵了，如果最终价格离直线太远，是不是趋势已改变．这些在后期做模型的时候，都需要抽象成特征．目前，这些我都通过图观察出来的，并且在程序里直接加了判断．</p>
<p> 话说，这比赛奖金不高．要是真能搞出几个靠谱的模型，谁还在意奖金？有时候一开始玩就不由自主地看得重排名．这个比赛争取用开放的心态来做，不用别人的baseline，自己的东西也不藏着掖着，边做边写文档．比赛的官方交流是QQ群，貌似还不是只针对这个比赛的，看看有没有也想玩的，咱们­建个钉钉群？</p>
]]></content>
      <tags>
        <tag>算法实战</tag>
      </tags>
  </entry>
  <entry>
    <title>实战量化投资大赛之二_GBDT模型</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/4_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/%E5%AE%9E%E6%88%98%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84%E5%A4%A7%E8%B5%9B%E4%B9%8B%E4%BA%8C_GBDT%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1
id="实战量化投资大赛之二_gbdt模型">实战量化投资大赛之二_GBDT模型</h1>
<p>#算法实战 #xgboost #时序</p>
<h2 id="说明">1. 说明</h2>
<p> 对股票预测这种典型的时序问题，使用梯度下降决策树，确实是有点生搬硬套．主要思路是想使用提供的特征值f1-f87，看看哪些特征更加重要．<br />
 具体方法是把历史数据用计算趋势和移动平均线的方式添加到特征之中，此时记录的前后顺序就不再重要，用122天（半年）后的价格作为结果Ｙ，随机将所有记录分成训练集和测试集，做回归模型．线上最高得分47左右．</p>
<h2 id="特征工程">2. 特征工程</h2>
<p> 用GBDT模型主要是特征工程和调参，一开始我只是加了一些趋势和与均线关系的特征，预测后取前20，线上得分34左右．觉得这个模型几乎没法用．然后分析了取出的top20是怎样一些股票，发现其中多一半都包含停牌或者高送转．预测不成功的原因是：没做数据清洗，这里确实需要一些行业背景知识．<br />
 不只是GBDT模型，用统计模型也一样，这些特殊值都会成为干扰项．在去掉了高送转，次新股，停牌之后，同样的模型，RMSE误差不到之前的1/3，比之前靠谱多了．<br />
 具体工作如下：</p>
<h4 id="合并数据">(1) 合并数据</h4>
<p> 把数据合成一个大文件，用pickle格式保存，pickle是python的序列化格式，它并不比csv节约空间，但读取速度快．</p>
<h4 id="提取统计特征">(2) 提取统计特征</h4>
<p> 这里是将第一赛段的900多支股票，每天的数据计算均值，得出类似大盘指数，以代表整体趋势，同时还计算了每天的各股价格与指数之比，从而可以统计出各股一段时间之内的趋势比大盘强还是比大盘弱．</p>
<h4 id="缺失值和标准化">(3) 缺失值和标准化</h4>
<p> 对所有脱敏的特征f*做标准化，并将其缺失值设为０，即均值．</p>
<h4 id="计算序列特征">(4) 计算序列特征</h4>
<p> 计算当前值与20,60,122,244日均线之间的涨跌关系，同时生成Y，将各股当日数据之后第122天的数据做为目标Y，加入数据集，供监督学习使用．</p>
<h4 id="计算斜率">(5) 计算斜率</h4>
<p> 根据各股某日以及前所有日期数据，用直线拟合，计算其斜率，作为该日斜率，这和之前计算的＂与N日均线之间的涨跌关系＂类似．</p>
<h4 id="标注特殊数据">(6) 标注特殊数据</h4>
<p> 由于高送转会影响影响超势，均线等数据，像送转，次新又都具有其自身的规则．暂时标注，短期不处理．<br />
 计算各支股票数据的开始日期，以判断是否为次新股，计算每支股票数据各有多少天的数据，以判断停牌时长．</p>
<h2 id="关于模型">3. 关于模型</h2>
<p> 前篇分享的纯趋势模型．它是先计算出整体趋势，在各股趋势中除去了整体趋势，然后做线性拟合，选出斜率最大的20支股票．线上分数48.5．<br />
 本篇分析的阶度下降决策树，具体用的是lightgbm模型做回归．线上分数47．<br />
 对比两种模型各选出前20支，只有两支相同，但分数都高于平均水平．值得注意的是：很多用决策树算出要涨的股票，作图后看着趋势是向下的，但是模型整体评分还是不错．也就是说从特征中可以提取到趋势以外的东西．这可能是基于基本面的预测（由于f*特征做了脱敏处理，不能确定它们具体是什么）．</p>
]]></content>
      <tags>
        <tag>时序</tag>
        <tag>算法实战</tag>
        <tag>xgboost</tag>
      </tags>
  </entry>
  <entry>
    <title>啥是图神经网络？</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/6_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/7_%E7%9F%A5%E8%AF%86%E5%9B%BE/%E5%95%A5%E6%98%AF%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<p>昨天有个朋友问我：＂你了解图神经网络么？＂，想了半天，不知从何说起．这半年，读了一些相关论文，TransR，TransE，GNN，<a
href="https://www.jianshu.com/p/83b3cc23d21e">GCN</a>，<a
href="https://www.jianshu.com/p/a48f314a1557">GIN</a>，还有一些综述性的．好像大概能说明白，它是怎么做的，但又不能完全说明白它是干啥的，进而扩展到自然语言模型，知识图谱，你说它们是干啥的？在网上一搜，出来的往往是具体实现方法（how），而具体干啥讲得很抽象（what）．</p>
<p>试试说说我的理解，也不一定对：从根本上看，它们都是知识表示，文本向量化．通俗地讲就是把文本编码成一串数，文本可能是一个字（＂生＂），一个词（＂苹果＂），一个短语（＂你说呢＂）或者一个句子（＂我是一个句子＂）...
让文字可以量化，比较，计算．</p>
<p>比如：提到自然语言模型，可能首先想到的是 <a
href="https://blog.csdn.net/xieyan0811/article/details/104199828">BERT</a>，<a
href="https://blog.csdn.net/xieyan0811/article/details/104278168">GTP</a>，它可以用来做阅读理解，完型填空，判断对错，续写文章等等．模型将一段文字转换成一串数，再传入下游任务（比如：阅读理解），参与决策具体问题．而
BERT
类模型解决的问题是某个字（比如＂生＂）在不同上下文环境下到底是什么意思？然后把它在这里的意思转换成一串数．</p>
<p>再如：知识图谱，一度困惑它是干啥的？把文献或者网站上的大段文字通过命名识体识别，知识抽取等技术切成小的单元，获取它们之间的关系，放在三元组的结构里，存在图数据库中．可以通过这些小文本之间的关系从一个词＂联想＂到另一个词，做一些推荐的工具，然后呢？怎么利用它参与决策？</p>
<p>这就引出了图神经网络GNN，如同BERT通过对海量数据中上下文的学习来计算每个词的含义，GNN利用图中实体（简单理解实体就是词）之间的关系，也是通过海量数据，计算实体的含义，并且用向量表示出来．同样也是送入下游任务，参与进一步决策．</p>
<p>图神经网络的算法原理很简单，假设我是一个实体（比如：词），利用我的邻居来算我（红色），我的邻居（蓝色）又根据它的邻居计算（这其中也包括我），经过数次反复迭代，直到表示我们的向量逐渐趋于稳定（不再因为迭代而变化），此时就认为找到了合适的编码．比较推荐之前写的<a
href="https://www.jianshu.com/p/83b3cc23d21e">论文阅读_GCN</a>，把邻接矩阵，度矩阵，拉普拉斯矩阵这些基本概念介绍了一下．<br />
<img src="None" alt="Pasted%20image%2020220717060802.png" /></p>
<p>进而又演生出结合上下文（比如BERT）和知识图（比如GNN）的模型，如<a
href="https://www.jianshu.com/p/364f04f145ea">ERNIE-THU</a></p>
<p>归根结底，它们都是知识的表示，<strong>用一串数代表某种概念</strong>．不限于自然语言处理，图神经网络还可以描述蛋白质分子结构，社群中的人际关系等等．而GIN，GCN，GNN这些方法则是具体实现的技术．</p>
<p>这串数即向量，形如:
[8,66,993,32,5...]，每一个维度（其中的每个数）可能描述某种更加抽象的概念（比如：大小，形状，情绪...），又或者几个数共同表示一个概念，这里＂苹果＂和＂桃＂的数值差异很小，因为它们的含义相近，＂爱＂和＂恨＂距离也很近，因为它们同为情绪，而＂爱＂和＂积木＂则距离很远；＂生＂在与不同上下文的组合中可能被转换成完全不同的向量...</p>
<p>这些数并没有什么实质的意义，同一个词送入BERT编码成这样的向量，送入GPT编码成那样的向量，GNN编码又完全不同...
但是，如果是好的编码器，＂苹果＂和＂桃＂的距离就会很近．和世界上所有的概念一样，这里没有绝对的正确，但有相对的＂差不多＂．</p>
]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>知识表示</tag>
      </tags>
  </entry>
  <entry>
    <title>AI绘画_SD_下载模型</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/AI%E7%BB%98%E7%94%BB/AI%E7%BB%98%E7%94%BB_SD_%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h2 id="模型下载">1 模型下载</h2>
<p>Stable Diffusion (简称SD) 模型主要从 Huggingface, github, Civitai
下载。<br />
Huggingface：主要提供主流 AI 绘画模型下载。<br />
github：也有一些小模型放在 github 下供下载使用。<br />
Civitai：AI艺术共享平台，可下载海量SD开源模型（推荐）。</p>
<h2 id="模型类别">2 模型类别</h2>
<p>SD
支持不同类型的模型，比如：基础模型，Lora，ControlNet，VAE，CLIP等。模型扩展名一般为ckpt，safetensors，pt，pth等。下面介绍几种最重要的模型。</p>
<h2 id="基础模型">3 基础模型</h2>
<h3 id="介绍">3.1 介绍</h3>
<p>基础模型一般包含完整的 TextEncoder、U-Net、VAE。<br />
模型大小一般为2-8G，真实风格模型相对2D风格模型更大。<br />
目前最新的模型是 SDXL 1.0（约占8G显存），最常用的模型是 SD
1.5（约占4G显存）。<br />
需要手工下载后，复制到 models/Stable-diffusion/
目录下，才可识别和使用。</p>
<h3 id="推荐">3.2 推荐</h3>
<ul>
<li>v1-5-pruned-emaonly：默认模型，偏真实风格，可从 huggingface
下载<br />
</li>
<li>bluePencilXL_v010.safetensors：最新版 SDXL 1.0 模型<br />
</li>
<li>anythingV3_fp16.ckpt：2D 动画风格<br />
</li>
<li>Counterfeit：接近真实场景的二次元风格（2.5D），氛围感很好，老式动慢风格</li>
</ul>
<h2 id="lora模型">4 Lora模型</h2>
<h3 id="介绍-1">4.1 介绍</h3>
<p>Lora是一种较小的绘画模型，一般体积在几十到几百兆左右。它是对大模型的微调。生成图片时只能选择一个大模型，但可选择多个Lora。</p>
<p>Lora解决的问题是：单个模型难以覆盖不同风格，而基础模型又太大，普通设备无法训练，Lora可分别针对：主体，风格，动作训练增补模型，与基础模型配合使用，以改进具体功能。</p>
<p>Lora只需要少量的数据就可以训练（如几十张标注的相片），比训练大模型要简单很多，用户可以用自己的数据训练Lora，也可在
Civitai 进行下载，下载后放到 SD的 models/Lora/ 目录下即可使用。</p>
<h3 id="推荐-1">4.2 推荐</h3>
<ul>
<li>Detail Tweaker LoRA：增强/减少细节，保持整体风格/人物;
可结合各种基础模型(包括动画和现实模型)。<br />
</li>
<li>GHIBLI_Background：吉卜力风格（类似宫崎骏动画风格），治愈系画风的建筑和景观（背景）。</li>
</ul>
<h2 id="vae模型">5 VAE模型</h2>
<h3 id="介绍-2">5.1 介绍</h3>
<p>VAE是变分自编码器，负责将潜空间的数据转换为正常图像。<br />
在SD中切换
VAE，可看作切换滤镜，它在生成图片过程中配合主模型使用，起到调色和微调的作用，比如有些模型色调不够清晰明亮，可考虑加
VAE 一起使用。<br />
切换模型时，对应的VAE有时会自动下载；手动下载VAE模型，需要复制到
models/VAE/ 目录下，然后在 WebUI 界面上设置：Setting选项卡-&gt;左边选
Stable Diffusion-&gt;SD VAE</p>
<h3 id="推荐-2">5.2 推荐</h3>
<p>mse-840000：通用 VAE<br />
ClearVAE：动漫 VAE</p>
<h2 id="controlnet模型">6 ControlNet模型</h2>
<h3 id="介绍-3">6.1 介绍</h3>
<p>AI
绘图的主要问题是画面不可控，只能通过多次尝试，再筛选的方式出图，很难达到可预期的稳定输出，ControlNet
主要解决这一问题。其主原理是：利用额外网络对基础模型做微调。</p>
<p>ControlNet可以提取图片的线稿、人的资态、风景等难以用 prompt
描述的元素。在生成图片时叠加各种效果，比如给图A中的人设置图B中的姿式。它包括预处理和叠加模型，预处理是从图片A中提取行为，叠加模型将该行为应用到图片B的生成中。相对于图生图，ControlNet
提供的信息更为纯粹。</p>
<p>具体原理见论文 2023年2月 ：https://arxiv.org/abs/2302.05543，</p>
<h3 id="安装">6.2 安装</h3>
<ul>
<li>安装 ControlNet 插件（目前星最高的插件）：<br />
WebUI界面-&gt;Extension 选项卡-&gt;Available选项卡-&gt;Load
from按钮-&gt;Order选按Star排序-&gt;安装 sd-webui-controlnet
插件，正常安装后在 Installed选项卡中可以看到<br />
</li>
<li>下载模型<br />
预处理器会自动从 HuggingFace
下载；模型需要另外安装，模型下载地址：<br />
https://huggingface.co/lllyasviel/ControlNet/tree/main/models<br />
目前有8个模型可供下载，每个模型大小都在5G左右，和之前相比做了一些合并。</li>
</ul>
<h3 id="主要功能">6.3 主要功能</h3>
<ul>
<li>资态约束：Openpose（可根据参考图设置：表情，手指、身体资态）<br />
</li>
<li>空间深度约束：Depth（对空间场景深度的还原，含人体）<br />
</li>
<li>抽取线条和还原：Canny 用于还原外型特征；SOFTEDGE/HED
整体边缘检测，识别大概轮廓；比CANNY约束小；SCIBBLE
涂鸦，比SOFTEDGE更自由，可根据简单涂鸦生成图片（注意：画线稿时不要加阴影，如果使用白底黑线，需要用
invert 预处理器）<br />
</li>
<li>物品类形约束：Seg<br />
</li>
<li>风格约束：Normal</li>
</ul>
<h3 id="使用方法">6.4 使用方法</h3>
<ul>
<li>上传图片
<ul>
<li>在界面左下点开 ControlNet 折叠界面<br />
</li>
<li>上传待参考的图片（如上传一张线稿）<br />
</li>
</ul></li>
<li>选择模型
<ul>
<li>选择类型 Control Type，比如
canny，选中后列出该类别对应的所有可用的预处理和模型<br />
</li>
<li>选预处理 Preprocess，比如
canny，预处理器将从图片中读取信息；然后点右边的爆炸图标，可预览其处理效果。<br />
</li>
<li>选择 ControlNet 模型，比如 control_sd15_canny，用于生成图像。<br />
</li>
</ul></li>
<li>设置参数
<ul>
<li>注意一定要勾选 Enable，否则 ControlNet 不起作用。<br />
</li>
</ul></li>
<li>生成图
<ul>
<li>点击右上角的生成按钮生成图像</li>
</ul></li>
</ul>
<h3 id="注意">6.5 注意</h3>
<ul>
<li>测试 ControlNet 效果时，需要固定
Seed，以保证每次生成的基础图是一样的<br />
</li>
<li>第一次使用涂鸦功能时，可尝试xdog模式，它的效果更好</li>
</ul>
<h2 id="其它模型">7 其它模型</h2>
<p>其它模型，比如恢复面部细节的 CodeFormer，利用图片生成提示词的 CLIP
&amp; DeepBooru，一般第一次使用时都会自动下载模型到 models
的对应子目录中，需要耐心等待。如果下载不成功，请根据后台提示下载文件，然后复制到对应目录。</p>
<h2 id="注意事项">8 注意事项</h2>
<ul>
<li>如果想真正把SD应用起来，一定要使用
Lora和ControlNet，Lora负责指定具体的主体和场景，ControlNet负责更好地控制画面。<br />
</li>
<li>基础模型需要与其上的 VAE，Lora 版本一致，否则无法使用<br />
</li>
<li>基础模型与其上的 VAE，Lora 风格尽量（动画/真实）一致<br />
</li>
<li>使用 ControlNet
时被修改的图片和参考图片最好风格一致，动画人物和真人比例不一致可能造成问题</li>
</ul>
<h2 id="参考">9 参考</h2>
<p><a
href="https://www.bilibili.com/video/BV1TM4y1p7RJ/?-Arouter=story&amp;buvid=XY75FD87D1E2396A755EF849CB0F9ADCEBC95&amp;is_story_h5=false&amp;mid=wYI4b1h%2FHXXzTePLTpqSZQ%3D%3D&amp;p=1&amp;plat_id=163&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=c0b74b39-70a4-4583-bd43-98f978c6d8d6&amp;share_source=WEIXIN&amp;share_tag=s_i&amp;timestamp=1691989625&amp;unique_k=9VwxqJ2&amp;up_id=1814756990">SDXL模型b站视频</a><br />
<a
href="https://zhuanlan.zhihu.com/p/640637930?utm_id=0">耗时7天，终于把15种ControlNet模型搞明白了！</a><br />
<a
href="https://baijiahao.baidu.com/s?id=1764942391242220507&amp;wfr=spider&amp;for=pc">Stable
Diffusion进阶教程！超详细的 ControlNet 实用入门指南</a></p>
]]></content>
      <tags>
        <tag>大模型应用</tag>
      </tags>
  </entry>
  <entry>
    <title>AI绘画_SD_搭建环境</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/AI%E7%BB%98%E7%94%BB/AI%E7%BB%98%E7%94%BB_SD_%E6%90%AD%E5%BB%BA%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<p>一周之内体验了：Diffusion，CLIP，Segment
Anything，Insightface，LoRA，ConnectNet
诸多算法的实际应用，全部是本地部署，0花费。</p>
<h2 id="选择-ai-绘画工具">1 选择 AI 绘画工具</h2>
<p><img
src="/attachments_2023/Pasted%20image%2020230915110713.png" /><br />
目前 Ai 绘画界有两大主流工具，Midjourney（简称MJ） 和 Stable
Diffusion（称SD）。<br />
MJ 于 2022 年 3 月首次面世，已从 V3 模型发展至 V5 模型，SD 由 Stability
AI 公司和非营利研究人员在2022年8月推出的，可在本地免费部署。</p>
<p>MJ
更适合新手入门，10刀/月，30刀/月，60刀/月三档收费；低付费的图片是共享的，高付费服务能一对一出图；学习提示词门槛低；有一定的审核要求，敏感词比较多；少量设置后的画面看起来就很炫，但不太受控，自娱自乐还行，难以稳定输出。</p>
<p>SD
可以设置大量参数，下载海量模型，本地部署，提示词百无禁忌，针对实际工作中的目标，更需要
SD 来定制。它需要本地硬件支持，以及更高的学习成本。</p>
<p>如果只想玩一下，国内也有一些免费平台，浏览器端和手机端微信端都有，就是生成效果比较差。</p>
<p>从两个产品不同的生态圈就可以看出，开放的系统明显呈现出众人拾柴火焰高的趋势，从平台、插件、模型，到文档，工具都越做越好。另外，LoRA
技术让大家都可以自己训练自己的增补小模型，Civitai圈的交流氛围，加入的人也越来越多。这就相当于MJ一个公司和所有人拼，又没有特别过人的核心技术。</p>
<p>艺术给人带来的体验和工作体验不太一样，大家更向往彼此的认同感，除了经济价值，工作本身就是工作的动力，这也成为一种巨大助推力。</p>
<h2 id="搭建-sd-环境">2 搭建 SD 环境</h2>
<h3 id="介绍">2.1 介绍</h3>
<p>Stable Diffusion
（简称：SD）支持：通过描述生成图，或者改图，做自己的卡通头像，生成各种风格的画作，给线稿上色，修复相片，换脸，抠图
…… 点两下鼠标，几秒就能生成一张作品。在自家机器上搭建一个 SD
环境，不用花钱，不用上网也能使用。</p>
<p>不过还是有点门槛，比如：<br />
* 安装时需要 “科学”连接下载网站（否则无法随心选择海量模型）<br />
* 英文尚可，能看懂界面和简单说明（用翻译软件也不是不行）<br />
* 会一点Python如遇问题自己能解决（也不一定会遇到问题）<br />
* 有带6G以上显存的 GPU 的机器（没有 GPU 会很慢，但也能用）<br />
* 至少 20G 的磁盘剩余空间（这个必须有，建议
50G，最好是SSD，否则加载模型特别慢）</p>
<p>本教程中我使用了 Ubuntu + Docker
方式安装，这是目前我能找到最简单的方法，几乎只需要输入一个命令，即可运行基本功能；当然前提是事先安装了
Ubuntu 系统 Docker 环境以及 GPU 驱动。</p>
<p>这仅仅是运行环境，后面涉及各种模型的组合，调参，插件，了解工具周边生态，与其它工具联合使用；还有审美，光影的感觉，对受众内心的揣摩……
总之，当一个 AI 画手也不是件容易的事。</p>
<h3 id="基础环境">2.2 基础环境</h3>
<p>操作系统: Ubuntu 22.04<br />
显卡: NVIDIA GTX 1080 Ti 11GB 显存</p>
<h3 id="安装方法">2.3 安装方法</h3>
<p>SD github 项目中推荐直接在系统中安装环境。我则更喜欢把
Python、git、conda 一系列工具都打包在内的 docker
安装方式，这避免了与机器上安装的其它工具的冲突。<br />
<strong><em>siutin/stable-diffusion-webui-docker</em></strong>
是目前下载量最大的 Stable Diffusion 镜像，几乎和 Stable Diffusion github
版本同步更新，相比几个同类镜像，它的大小和易用性也是最好的。</p>
<h4 id="cpu-版本">2.3.1 CPU 版本</h4>
<pre><code>$ docker run -it --name sdw --network host \  
  -v $(pwd)/models:/app/stable-diffusion-webui/models \  
  -v $(pwd)/outputs:/app/stable-diffusion-webui/outputs \  
  -v $(pwd)/extensions:/app/stable-diffusion-webui/extensions \  
  --rm siutin/stable-diffusion-webui-docker:latest-cpu \  
  bash  # 安装  
$ ./webui.sh --skip-torch-cuda-test --use-cpu all --share --precision full --no-half --listen # 运行  </code></pre>
<p>下载后安装模型即可使用。<br />
参数：--no-half 由于我这边一直报错，所以设置了该参数。<br />
参数：--listen 设置后可使用其 ip 地址访问服务，否则只允许本机用
127.0.0.1访问，服务默认端口为 7860。<br />
参数：--enable-insecure-extension-access 允许使用插件</p>
<h4 id="gpu-版本">2.3.2 GPU 版本</h4>
<pre><code>$ nvidia-docker run -it --name sdw --gpus all --network host \  
  -v $(pwd)/models:/app/stable-diffusion-webui/models \  
  -v $(pwd)/outputs:/app/stable-diffusion-webui/outputs \  
  -v $(pwd)/extensions:/app/stable-diffusion-webui/extensions \  
  --rm siutin/stable-diffusion-webui-docker:cuda-v1.5.1-2023-08-02 \  
  bash  
$ ./webui.sh --share --listen --enable-insecure-extension-access  </code></pre>
<h4 id="下载模型">2.3.3 下载模型</h4>
<p>我下载的第一个模型是：<br />
https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors<br />
可用于生成真实场景，修图，换图等，大小为4.2G，下载后放入
stable-diffusion-webui/models/Stable-diffusion/ 目录。</p>
<h4 id="使用">2.3.4 使用</h4>
<p>如果上述程序不报错，在浏览器打开 127.0.0.1:7860，即可看到 gradio
生成的界面。</p>
<h4 id="注意事项">2.3.5 注意事项</h4>
<ul>
<li>请将模型、输出、扩展名映射到 docker
以外的目录，以保证正常保存数据。<br />
</li>
<li>以 bash 方式进入镜像后，使用命令运行 webui.sh
工具，这样可以在重启时一定程度保留现场，也较方便调试。<br />
</li>
<li>安装时，我的CPU版正常运行了，GPU版老是报错，于是升级了宿主机的GPU驱动（从470升到535，nvidia-driver-535,
nvidia-utils-535两个包），重启后一切正常<br />
</li>
<li>CPU版本工具 3分钟生成一张图，GPU版本
7秒生成一张图，是完全不同的体验。<br />
</li>
<li>插件和模型数据未必都下载到 models 目录下，所以我后来做了 docker
commit，以保存现场。</li>
</ul>
<h3 id="调试命令">2.4 调试命令</h3>
<ul>
<li>查看 torch 可否支持当前 GPU<br />
</li>
</ul>
<pre><code>python -c &quot;import torch; print(torch.cuda.is_available())&quot;  </code></pre>
<ul>
<li>查看当前 GPU 硬件<br />
</li>
</ul>
<pre><code>lspci |grep VGA  </code></pre>
<ul>
<li>venv<br />
venv是Python的虚拟环境工具，以支持多个Python环境并存。它是Python
3.3版本后标准库中的一个模块。stable diffusion 使用了venv 将环境搭建在
/app/stable-diffusion-webui/venv/下，自行调试需设置 venv：<br />
</li>
</ul>
<pre><code>python -m venv venv # 设置环境  
source venv/bin/activate # 激活环境  </code></pre>
<h2 id="源码">3 源码</h2>
<p>源码并不多，去掉 .git 目录，只有4M左右。当前版本共 160 个 python
文件，主要包含：内置函数extensions-builtin，支持工具scripts，以及主功能模块modules。整体
python 代码量在 3W-4W 行左右。界面基于 gradio 框架开发。</p>
<h2 id="相关资源">4 相关资源</h2>
<p><a
href="https://github.com/AUTOMATIC1111/stable-diffusion-webui.git">Stable
Diffusion 源码</a><br />
<a
href="https://hub.docker.com/r/siutin/stable-diffusion-webui-docker">相关
Docker 镜像</a><br />
<a
href="https://www.bilibili.com/read/cv23247324/">最详细的WEBUI启动参数</a></p>
<p><a
href="/1_Note/2_算法/8_图形图像/AI绘画/AI绘画_SD_下载模型">AI绘画_SD_下载模型</a></p>
]]></content>
      <tags>
        <tag>大模型应用</tag>
      </tags>
  </entry>
  <entry>
    <title>AI绘画_SD_界面操作</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/AI%E7%BB%98%E7%94%BB/AI%E7%BB%98%E7%94%BB_SD_%E7%95%8C%E9%9D%A2%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h2 id="介绍">1 介绍</h2>
<p>本文将介绍 Stable Diffusion
的具体使用方法。首先，介绍界面中的重要元素，如图所示：<br />
<img src="/attachments_2023/Pasted%20image%2020230818140318.png" />1.
基础模型：基础模型是最重要的设置项<br />
2. 文生图：选项卡列出了各大功能，文生图指通过文字生成图片<br />
3. 图生图：图生图指通过图片和文字生成图片<br />
4. 修复照片：用于优化图片，提升精度，常用来修复旧照片<br />
5. 设置：软件设置，VAE模型可在此设置<br />
6. 插件：用于安装和管理插件，注意命令行启动时应允许安装插件<br />
7.
提示词：提示词分为正向提示和负向提示，负向提示用于限制可能的问题<br />
8. 采样方式：常用 Euler a ，DPM2++2M Karras<br />
9.
提示词相关性：设置画面与提示词的相关性，一般设为5-10，如果太高，色彩会过于饱和<br />
10.
扩展模型：设置基础模型的附加模型，Embedding和LoRA模型就在此设置<br />
11. 生成按钮：按此按钮生成图片</p>
<h2 id="提示词">2 提示词</h2>
<h3 id="提示词格式">2.1 提示词格式</h3>
<ul>
<li>提示词用于描述待生成的图像内容<br />
</li>
<li>提示词可支持中文，但不如英文理解的好<br />
</li>
<li>多个提示词可用逗号隔开，无需符合英文语法<br />
</li>
<li>对提示词加权重：
<ul>
<li>用小括号把关键词括起来（curly
hair），这样括号一次就是1.1倍权重，那括两次((curly
hair))就是1.1×1.1=1.21倍，以此类推；<br />
</li>
<li>对提示词减权重：用中括号把单词括起来，如：[curly hair]<br />
</li>
<li>指定权重数值 (关键词:数值):（curly hair：1.3）</li>
</ul></li>
</ul>
<h3 id="正向提示词">2.2 正向提示词</h3>
<ul>
<li>设定画质：masterpiece, best quality, Highly detailed,<br />
</li>
<li>设定人物：性别，年龄，发型，衣服颜色，样式，身材<br />
</li>
<li>设定人物表情&amp;动作：微笑，大笑，酷<br />
</li>
<li>设定人物关系：如母亲和女儿<br />
</li>
<li>设定画面内其它物品<br />
</li>
<li>设定方向：如人物背面<br />
</li>
<li>设定背景：背景内容，背景风格<br />
</li>
<li>设定风格：水彩画 water painting art，水墨画 ink drawing，漫画风
Anime, 鲜艳 Vivid Colors, 前景实背景虚 Bokeh，素描 Sketch，线图 a line
drawing<br />
</li>
<li>光感镜头：rayonism，perfect lighting, sharp focus</li>
</ul>
<h3 id="负向提示词">2.3 负向提示词</h3>
<ul>
<li>手指问题，手型问题：bad hands, missing fingers, (too many
fingers:1.2)<br />
</li>
<li>五官问题：(unclear eyes:1.2)<br />
</li>
<li>多出来的胳膊和腿：(missing arms:1.2), (extra legs:1.2),(missing
legs:1.2), (extra arms:1.2)<br />
</li>
<li>画质问题：(worst quality:2), (low quality:2), blurry</li>
</ul>
<h3 id="注意">2.4 注意</h3>
<ul>
<li>上述提示词只是举例，具体请看参考部分的《提示词词缀使用指南》<br />
</li>
<li>从 https://civitai.com/
点击模型生成的图，可以看到提示和参数，用于参考<br />
</li>
<li>虽然可以指定风格，但是生成的具体画质和风格主要看 基础模型 和
LoRA模型 的能力<br />
</li>
<li>手指问题如果比较严重，建议使用 ControlNet 的
Openpose+Depth，负向提示词，或者After Detailer插件</li>
</ul>
<h2 id="文生图-图生图">3 文生图 &amp; 图生图</h2>
<p>文生图和图生图是 SD
的核心功能，其中图生图也支持识别文字描述，故可将文生图看作图生图的一部分。相对来说图生图功能也更丰富。本部分以图生图为主，讲解具体用法。<br />
<img src="/attachments_2023/Pasted%20image%2020230818143719.png" /></p>
<h3 id="图生图与文生图的差别">3.1 图生图与文生图的差别</h3>
<p>可以看到图生图界面比文生图多了一些控件，主要差别如下：<br />
* 生成图片之前首先要上传一张基础图片。<br />
* 反推咒语：Interrogate CLIP / Interrogate DeepBooru
按钮分别支持两种方法从图片中提取提示词，第一次使用时在后台下载模型，时间较长。<br />
* 子功能又细分为以下六种：<br />
*
img2img：基础的图生图功能，常用于整图风格的改变，比如将相片改成2D效果<br />
* Sketch：涂鸦功能，可在基础图上绘制颜色，画好主色后，细节直接交给 AI
绘制<br />
* Inpaint：修改部分图，常用于换衣服，换脸等局部修改<br />
* Inpaint sketch：用涂鸦方式修改部分图<br />
* Inpaint upload：上传部分图蒙板，以便更精确地改图<br />
* Batch：批量改图<br />
* 重绘幅度（Denosing
strength）：设置值越大表示对原图重绘幅度越大，相对的提示词影响也越大，0.5为分界点，一般设为
0.5 以上就与原图不太像了。</p>
<h2 id="插件">4 插件</h2>
<h3 id="sd-webui-controlnet">4.1 sd-webui-controlnet</h3>
<p>ControlNet 让用户更精确地绘制姿势动作、面部特征、风格等元素。是 SD
中最重要的插件，没有之一，之前文档里已经介绍了，不再缀述。</p>
<h3 id="sd-webui-tagcomplete">4.2 sd-webui-tagcomplete</h3>
<p>TagComplete
提供了提示词补全功能。当开始输入提示词时，它会列出与输入相关提示词，也可用'&lt;'呼出Lora等提示词。</p>
<h3 id="sd-webui-segment-anything">4.3 sd-webui-segment-anything</h3>
<p>Segment-anything
用于自动抠图，效果非常好，它基于人对世界的认知抠图，而非只考虑颜色，能一键抠出整个人。其用法类似ControlNet，安装之后，在Inpaint界面的下方出现
Segment Anything 折叠界面。<br />
需要下载模型：https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth<br />
大小为 2.4G，复制到 extensions/sd-webui-segment-anything/models/sam/
后即可使用，效果如下：<br />
<img src="/attachments_2023/Pasted%20image%2020230818180425.png"
alt="|400" /></p>
<h3 id="adetailer">4.4 adetailer</h3>
<p>After Detailer
是一种后处理，可选择不同模型对手和脸精调。一般的操作是：利用随机种子生成图片，当遇到一张图片其它方面都比较满意，但手或脸的细节有问题时，固定该种子，打开
After Detailer
功能，重新生成即可。我试了一下，修手一般，修脸效果不错，具体使用的是
face_yolov8n.pt 模型。</p>
<h3 id="sd-webui-roop">4.5 sd-webui-roop</h3>
<p>Roop提供换脸功能，由于我的 SD 安排在 Linux
服务器上，可以"科学"，整个操作下来，除了一开始网络不好，进入虚拟环境中安装了一下依赖（requirements.txt），后面安装软件下载模型都是自动完成的，比Windows系统简单得多。<br />
其核心使用了 insightface 模型，具体也在 img2img 的左下方操作。<br />
注意：如果换脸不成功，需要关注一下服务后台的提示信息，可能是网络连接问题，可能是
CodeFormer 问题（如果是CodeFormer问题，将Restore
Face设成None即可）。<br />
<img src="/attachments_2023/Pasted%20image%2020230819221518.png" /></p>
<h2 id="实际应用">5 实际应用</h2>
<p>下面列举几个最常用的使用场景，以介绍具体的使用方法。</p>
<h3 id="真人相片变卡通形象">5.1 真人相片变卡通形象</h3>
<h4 id="准备">5.1.1 准备</h4>
<ul>
<li>一张照片</li>
</ul>
<h4 id="sd-操作">5.1.2 SD 操作</h4>
<ul>
<li>大模型选二次元风格模型: Kakigori_V2<br />
</li>
<li>选择 img2img-&gt;img2img 子类别<br />
</li>
<li>上传一张真实照片<br />
</li>
<li>点 Interrogate CLIP
按钮，用模型分析图片对应的提示词（此步可省略）<br />
</li>
<li>根据自己的对图片的理解和目标修改提示词，尽量用英文<br />
</li>
<li>修改 denosing 参数为 0.5（根据效果调整）<br />
</li>
<li>多生成几张图片，选取喜欢的<br />
</li>
<li>注意：生成图片的风格主要看选择的基础模型风格及提示词</li>
</ul>
<h3 id="换头换衣服换背景">5.2 换头&amp;换衣服&amp;换背景</h3>
<h4 id="准备-1">5.2.1 准备</h4>
<ul>
<li>一张照片</li>
</ul>
<h4 id="sd-操作-1">5.2.2 SD 操作</h4>
<ul>
<li>大模型选择真实场景模型: v1-5-pruned-emaonly<br />
</li>
<li>选择 img2img-&gt;inpaint sketch 子类别<br />
</li>
<li>上传一张真实照片<br />
</li>
<li>切换颜色，绘制需要修改的区域<br />
</li>
<li>填写提示词，比如把衣服换成旗袍：cheongsam（一定要填写）<br />
</li>
<li>修改 denosing 参数为 0.5（根据效果调整）<br />
</li>
<li>多生成几张图片，选取喜欢的</li>
</ul>
<h3 id="老照片修复">5.3 老照片修复</h3>
<h4 id="准备-2">5.3.1 准备</h4>
<ul>
<li>模糊的图片</li>
</ul>
<h4 id="sd-操作-2">5.3.2 SD 操作</h4>
<ul>
<li>修复二次元的照片选“R-ESRGAN 4x+Anime68”，实物照片选“R-ESRGAN
4x+”<br />
</li>
<li>反复测试，如果不清楚，把 GFPGAN 强度拉大</li>
</ul>
<h3 id="线稿上色">5.4 线稿上色</h3>
<h4 id="准备-3">5.4.1 准备</h4>
<ul>
<li>签字笔画稿<br />
</li>
<li>PhotoShop简单上色</li>
</ul>
<h4 id="sd操作">5.4.2 SD操作</h4>
<ul>
<li>大模型选: kakigori_V2.safetensors<br />
</li>
<li>选择 img2img-&gt;img2img 子类别<br />
</li>
<li>正向提示：sexy lips, blonde hair, blue eyes, green dress,
<lora:add_detail:2><br />
引处使用了 Lora:add_detail 用于添加细节<br />
</li>
<li>导入待上色的画稿作为基础图<br />
</li>
<li>Sampling method: DPM++ SDE Karras （更为细腻）<br />
</li>
<li>Donose strength：0.67<br />
</li>
<li>打开 ControlNet 折叠
<ul>
<li>Scribble（Enable）<br />
</li>
<li>Preprocessfor：canny<br />
</li>
<li>Model：control_sd15_canny<br />
</li>
</ul></li>
<li>其它项都使用默认值，生成即可<br />
</li>
<li>说明：效果主要依靠大模型和两个Lora模型比较给力，另外使用了
ControlNet 的涂鸦模型，它是自由度最高的填色工具，加入了很多细节。<br />
<img src="/attachments_2023/Pasted%20image%2020230819220151.png" /></li>
</ul>
<h3 id="原理分析">5.5 原理分析</h3>
<p>这是目前很喜欢的一组参数，用于将真人图片转成动漫风格，替换背景，保持表情和动作：</p>
<pre><code>a handsome Asia young man in the forest &lt;lora:add_detail:1&gt; &lt;lora:Pyramid lora_Ghibli_n3_0.7+Pyramid lora_Ghibli_v2_0.3:0.57&gt; rayonism  
Steps: 20, Sampler: DPM++ 2M Karras, CFG scale: 7, Seed: 1672545665, Size: 512x512, Model hash: 8eccdfe4b6, Model: deepboys25D_v30, Denoising strength: 0.63, ControlNet 0: &quot;preprocessor: scribble_xdog, model: control_sd15_scribble [fef5e48e], weight: 1, starting/ending: (0, 1), resize mode: Crop and Resize, pixel perfect: False, control mode: Balanced, preprocessor params: (512, 32, 200)&quot;, Lora hashes: &quot;add_detail: 7c6bad76eb54, Pyramid lora_Ghibli_n3_0.7+Pyramid lora_Ghibli_v2_0.3: 895eb832de9d&quot;, Version: v1.5.1  </code></pre>
<p>其核心点如下（按重要性排序）：<br />
*
选了一个2.5D风格的底模，能很好地还原人物，人物形象有特色、统一、稳定，明度精细度均不错<br />
* 使用了 ControlNet 的 scribble 涂鸦功能 scribble_xdog，这样既可以将
denosing
设大，让画面变化更加丰富，又有效地控制了人物的轮廓和表情变化<br />
* 提示词对年龄、性别、人种、背景起到了简单的限制作用<br />
* 使用了光照提示词 rayonism，外加 LoRA: add
detail，精细刻画提升了画面质感<br />
* 背景使用 LoRA：Ghibli 吉卜力风格（类似宫崎骏动画风格）<br />
<img src="/attachments_2023/Pasted%20image%2020230819210418.png" /></p>
<h2 id="参考">6 参考</h2>
<p><a href="http://www.dtmao.cc/Android/75280.html">Stable Diffusion
提示词词缀使用指南（Prompt）</a><br />
<a
href="https://baijiahao.baidu.com/s?id=1764400546694636799&amp;wfr=spider&amp;for=pc">Stable
Diffusion 图生图(img2img)干货技巧，值得收藏</a><br />
<a
href="https://www.bilibili.com/video/BV1P14y1q7j3/?-Arouter=story&amp;buvid=XY75FD87D1E2396A755EF849CB0F9ADCEBC95&amp;is_story_h5=false&amp;mid=wYI4b1h%2FHXXzTePLTpqSZQ%3D%3D&amp;p=1&amp;plat_id=163&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=30b88b0a-e229-43f9-8f14-ed39d54b0478&amp;share_source=WEIXIN&amp;share_tag=s_i&amp;timestamp=1691990655&amp;unique_k=ysCvFmQ&amp;up_id=3493095272352370">stable
diffusion插件</a><br />
<a href="https://zhuanlan.zhihu.com/p/621083328">Stable
Diffusion-采样器篇</a></p>
]]></content>
      <tags>
        <tag>大模型应用</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_U-NET</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/AI%E7%BB%98%E7%94%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F_U-NET/</url>
    <content><![CDATA[<p>英文名称: U-Net：Convolutional Networks for Biomedical Image
Segmentation<br />
中文名称: U-Net：用于生物医学图像分割的卷积网络<br />
论文地址: http://link.springer.com/10.1007/978-3-319-24574-4_28<br />
出处：journal: Medical Image Computing and Computer-Assisted
Intervention – MICCAI 2015<br />
时间: <strong>2015</strong></p>
<h2 id="读后感">1 读后感</h2>
<p>本文主要针对的问题是<strong>优化生物医学图像领域的图像识别</strong>，之前图像模型往往需要数千张标注图片训练。而医学影像数据往往存在图片大，图片中内容多（比如一张图中可能有很多的不正常细胞），难以做几千张图片的标注，除了正常异常，还常常需要标出具体位置。之前的方法是用滑动窗口将图像切成小块训练，这种方法比较慢图像重叠造成冗余，还要根据具体情况考虑切分方法，才能在上下文和效率之取得平衡。</p>
<p>文中提出的解决方法是：设计了<strong>U型网络结构和训练策略</strong>，相对于普通的卷积网络，增加了右侧的上采样卷积，从而恢复图像。</p>
<p>最终效果是，训练使用<strong>更少的数据</strong>即可训练，网络<strong>速度快</strong>，且验证在多个任务上<strong>效果好</strong>。</p>
<h2 id="模型结构">2 模型结构</h2>
<p>在结构上，它与卷积网络的区别在于：除了压缩（左侧），还加入了上采样的扩展部分（右侧），网络结构是基本对称的。网络只使用了卷积层，没有使用全连接层。</p>
<p><img src="/attachments_2023/Pasted%20image%2020230824085134.png"
alt="|600" /><br />
网络的左边是压缩，右边是扩展。压缩部分是普通的卷积网络，通过卷积和下采样操作，分辨率不断变小，特征通道变多；右边的扩展包含上采样和卷积，特征通道减少。在最后一层，使用
1x1 卷积将每个 64 分量特征向量映射到分类问题中的类别。网络总共有 23
个卷积层。</p>
<h3 id="损失函数">2.1 损失函数</h3>
<p>目标函数定义如下：<br />
<span class="math display">\[E=\sum_{\mathbf{x} \in \Omega}
w(\mathbf{x}) \log
\left(p_{\ell(\mathbf{x})}(\mathbf{x})\right)\]</span><br />
除了交叉熵以外，还对不同实例做了<strong>w加权</strong>：<br />
<span class="math display">\[w(\mathbf{x})=w_{c}(\mathbf{x})+w_{0} \cdot
\exp
\left(-\frac{\left(d_{1}(\mathbf{x})+d_{2}(\mathbf{x})\right)^{2}}{2
\sigma^{2}}\right)\]</span><br />
其中根据经验将w0设为10，σ设为5，<strong>wc是平衡类别频率的权重图，d1 :
是到最近细胞边界的距离，d2
是到第二个最近细胞边界的距离</strong>，即：离边界越近，权重越大，从而使模型着重学习细胞边界，从图d中可以看到其权重示意。<br />
<img src="/attachments_2023/Pasted%20image%2020230824102033.png" /></p>
<h3 id="数据增强">2.2 数据增强</h3>
<p>在训练策略上，由于缺少医学图像数据，在训练时还做了一些数据增强，一方面增加了训练数据，另一方面支持平移和旋转不变性以及对变形和灰度值变化的鲁棒性。特别是弹性形变，这里使用随机位移向量在粗略的
3 x 3 网格上生成平滑变形，对于移出的位置，从标准差为 10
像素的高斯分布中采样填充，然后使用双三次插值计算每像素位移。</p>
]]></content>
      <tags>
        <tag>模型结构</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_扩散模型_DDPM</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/AI%E7%BB%98%E7%94%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B_DDPM/</url>
    <content><![CDATA[<p>英文名称: Denoising Diffusion Probabilistic Models<br>
中文名称: 去噪扩散概率模型<br>
论文地址: http://arxiv.org/abs/2006.11239<br>
代码地址1: https://github.com/hojonathanho/diffusion （论文对应代码
tensorflow）<br>
代码地址2: https://github.com/AUTOMATIC1111/stable-diffusion-webui
stable-diffusion-webui/modules/models/diffusion/ddpm_edit.py (推荐
pytorch)<br>
时间: 2020-12-16<br>
作者: Jonathan Ho, 加州大学伯克利分校<br>
引用量: 3286</p>
<p><a href="/1_Note/2_算法/8_图形图像/AI绘画/论文阅读_生成模型_VAE">论文阅读_生成模型_VAE</a></p>
<h2 id="读后感">读后感</h2>
<p>论文优化了扩散模型的具体实现，并证明了扩散模型可生成高质量的图像。具体方法是结合扩散概率模型和朗之万动力学去噪的加权变分训练模型。</p>
<h2 id="学习路径">学习路径</h2>
<p>论文中公式很多，有些依赖DM论文，VAE论文，还有跳步，虽然方法部分不长，但是很难读明白。至今看到最好的解读是：<br>
* <a href="https://huggingface.co/blog/annotated-diffusion">The
Annotated Diffusion Model</a>（英文）<br>
文章除了原理，还提供了核心代码分析。</p>
<h2 id="方法">方法</h2>
<h3 id="扩散模型">扩散模型</h3>
<p>扩散模型由加噪 q 和去噪 p
两部分组成，如图-2所示，先从右往左看下边部分<strong>加噪q</strong>，x0是原始图像，经过T步逐渐加噪变为纯高斯噪声XT（时间步常设为
T=1000），其中每一步的图像xt根据上一步的xt-1通过加少量高斯噪声得到；再看上边部分去噪pθ，它是q的逆过程，每一步通过xt得到xt-1，最终还原图像x0，p由神经网络实现，θ
是神经网络参数，最后得到的深度学习模型就是可用噪声生成真实图像的网络。<br>
<img src="/attachments_2023/Pasted%20image%2020230902110431.png"></p>
<p>每个时间步加噪力度不同，这里 用 β 控制加噪的力度：<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="26.24ex" height="2.034ex" role="img" focusable="false" viewBox="0 -705 11598.1 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mo" transform="translate(777.8,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="msub" transform="translate(1833.6,0)"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="mn" transform="translate(599,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(3113.9,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="msub" transform="translate(4169.7,0)"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="mn" transform="translate(599,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(5450,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mo" transform="translate(6228,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(6672.7,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(7117.3,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(7562,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="msub" transform="translate(8617.8,0)"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="mi" transform="translate(599,-150) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g><g data-mml-node="mo" transform="translate(10042.4,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mn" transform="translate(11098.1,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container></span><br>
也就是说加噪的力度越来越大，这也很容易理解，加噪过程中先从小的噪声加起，在恢复图像的逆过程中，去噪越来越精细。加噪到了第T步时，图像就变成了纯噪声。<br>
<img src="/attachments_2023/Pasted%20image%2020230823171028.png"><br>
加噪过程 q 的每一步依赖上一步的图片：<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.469ex;" xmlns="http://www.w3.org/2000/svg" width="39.313ex" height="4.07ex" role="img" focusable="false" viewBox="0 -1149.5 17376.2 1799"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mrow" transform="translate(626.7,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1612,0)"><path data-c="2223" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msub" transform="translate(2167.8,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4016.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(5310.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(6366,0)"><g data-mml-node="mi"><path data-c="4E" d="M343 705Q358 705 358 698Q360 696 370 658T411 524T484 319Q536 174 590 82L595 73L615 152Q646 274 683 407Q729 571 752 637T799 727Q852 780 937 788Q939 788 947 788T958 789H962Q979 789 979 765Q979 722 951 692Q942 683 924 683Q888 681 859 672T818 654T803 639Q784 608 708 322T631 15Q631 14 630 15Q630 17 629 15Q628 14 628 12Q621 -4 601 -17T560 -31Q550 -31 546 -28T530 -7Q484 67 458 123T398 272Q352 392 314 514L306 535V534Q306 533 296 488T272 379T234 239T185 100T127 -7T61 -50Q34 -50 4 -34T-27 8Q-27 33 -12 61T18 90Q21 90 36 77T87 57H92Q109 57 123 78T162 173Q206 299 232 417T265 599T276 667Q284 681 304 693T343 705Z"></path></g></g><g data-mml-node="mrow" transform="translate(7511.7,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M180 96T180 250T205 541T266 770T353 944T444 1069T527 1150H555Q561 1144 561 1141Q561 1137 545 1120T504 1072T447 995T386 878T330 721T288 513T272 251Q272 133 280 56Q293 -87 326 -209T399 -405T475 -531T536 -609T561 -640Q561 -643 555 -649H527Q483 -612 443 -568T353 -443T266 -270T205 -41Z"></path></g><g data-mml-node="msub" transform="translate(597,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1542.3,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="msqrt" transform="translate(1986.9,0)"><g transform="translate(1020,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(1722.4,0)"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="TeXAtom" transform="translate(599,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g></g><g data-mml-node="mo" transform="translate(0,120.8)"><path data-c="221A" d="M263 249Q264 249 315 130T417 -108T470 -228L725 302Q981 837 982 839Q989 850 1001 850Q1008 850 1013 844T1020 832V826L741 243Q645 43 540 -176Q479 -303 469 -324T453 -348Q449 -350 436 -350L424 -349L315 -96Q206 156 205 156L171 130Q138 104 137 104L111 130L263 249Z"></path></g><rect width="2626.7" height="60" x="1020" y="910.8"></rect></g><g data-mml-node="msub" transform="translate(5633.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(7482.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(7927.3,0)"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="TeXAtom" transform="translate(599,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(8831.5,0)"><g data-mml-node="mi"><path data-c="1D408" d="M397 0Q370 3 218 3Q65 3 38 0H25V62H139V624H25V686H38Q65 683 218 683Q370 683 397 686H410V624H296V62H410V0H397Z"></path></g></g><g data-mml-node="mo" transform="translate(9267.5,0) translate(0 -0.5)"><path data-c="29" d="M35 1138Q35 1150 51 1150H56H69Q113 1113 153 1069T243 944T330 771T391 541T416 250T391 -40T330 -270T243 -443T152 -568T69 -649H56Q43 -649 39 -647T35 -637Q65 -607 110 -548Q283 -316 316 56Q324 133 324 251Q324 368 316 445Q278 877 48 1123Q36 1137 35 1138Z"></path></g></g></g></g></svg></mjx-container></span><br>
加入高斯噪声N。它的两个参数分别是均值（根据前一时间步Xt-1的图像）和方差（小的噪声BtI）。<br>
向后去噪的过程定义为p，理论上使用它可还原原始图像，但它相对难以实现。<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="10.629ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 4697.8 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(536,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g><g data-mml-node="mo" transform="translate(917.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1306.6,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3120.6,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msub" transform="translate(3398.6,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4308.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span><br>
这里的 θ
是待学习的神经网络权重。假设这个反向过程也是高斯的，也需要均值和方差。<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="40.291ex" height="2.351ex" role="img" focusable="false" viewBox="0 -789 17808.8 1039"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="mo" transform="translate(917.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1306.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3155.6,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msub" transform="translate(3433.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="mi" transform="translate(640,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(4378.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5045.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(6101.4,0)"><g data-mml-node="mi"><path data-c="4E" d="M343 705Q358 705 358 698Q360 696 370 658T411 524T484 319Q536 174 590 82L595 73L615 152Q646 274 683 407Q729 571 752 637T799 727Q852 780 937 788Q939 788 947 788T958 789H962Q979 789 979 765Q979 722 951 692Q942 683 924 683Q888 681 859 672T818 654T803 639Q784 608 708 322T631 15Q631 14 630 15Q630 17 629 15Q628 14 628 12Q621 -4 601 -17T560 -31Q550 -31 546 -28T530 -7Q484 67 458 123T398 272Q352 392 314 514L306 535V534Q306 533 296 488T272 379T234 239T185 100T127 -7T61 -50Q34 -50 4 -34T-27 8Q-27 33 -12 61T18 90Q21 90 36 77T87 57H92Q109 57 123 78T162 173Q206 299 232 417T265 599T276 667Q284 681 304 693T343 705Z"></path></g></g><g data-mml-node="mo" transform="translate(7080.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(7469.4,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(9318.4,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="msub" transform="translate(9763,0)"><g data-mml-node="mi"><path data-c="1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path></g><g data-mml-node="mi" transform="translate(636,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="mo" transform="translate(10780.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(11169.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mo" transform="translate(12114.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(12559.6,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(12920.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(13309.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(13754.2,0)"><g data-mml-node="mi"><path data-c="3A3" d="M666 247Q664 244 652 126T638 4V0H351Q131 0 95 0T57 5V6Q54 12 57 17L73 36Q89 54 121 90T182 159L305 299L56 644L55 658Q55 677 60 681Q63 683 351 683H638V679Q640 674 652 564T666 447V443H626V447Q618 505 604 543T559 605Q529 626 478 631T333 637H294H189L293 494Q314 465 345 422Q400 346 400 340Q400 338 399 337L154 57Q407 57 428 58Q476 60 508 68T551 83T575 103Q595 125 608 162T624 225L626 251H666V247Z"></path></g><g data-mml-node="mi" transform="translate(755,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="mo" transform="translate(14890.9,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(15279.9,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mo" transform="translate(16225.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(16669.8,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(17030.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(17419.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span><br>
也就是说，这里需要对均值、方差建模，求取网络权重
θ，且模型是和时间步t相关的，具体操作时通过位置嵌入将 t
编码到输入数据中。DDPM论文中建议只对均值建模，将方差设为常数，这样更简单一些。</p>
<h3 id="目标函数">目标函数</h3>
<p>损失函数定义为，所有时间步损失之和：<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="21.774ex" height="1.92ex" role="img" focusable="false" viewBox="0 -683 9623.9 848.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(958.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(2014.6,0)"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mn" transform="translate(714,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(3354.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(4354.6,0)"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mn" transform="translate(714,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(5472.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mo" transform="translate(6250.1,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(6694.8,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(7139.4,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(7584.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(8362.1,0)"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(714,-150) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></g></svg></mjx-container></span><br>
其中每个时间步（除了第0个时间步是原图）以外，计算的都是正向反向两个高斯分布的KL散度。</p>
<h4 id="简化计算加噪过程">简化计算加噪过程</h4>
<p>由于高斯分布的积累也是高斯分布，所以在加噪过程中，可以直接计算出第t步的数据，从而简化从0-t的多步计算，这里又引入了一个变量
α：</p>
<p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="11.802ex" height="2.034ex" role="img" focusable="false" viewBox="0 -705 5216.5 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mi" transform="translate(673,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(1256,0)"><g data-mml-node="text"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="text" transform="translate(278,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g></g><g data-mml-node="mn" transform="translate(2589.8,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(3312,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(4312.3,0)"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="mi" transform="translate(599,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g></g></svg></mjx-container></span></p>
<p>and</p>
<p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.69ex;" xmlns="http://www.w3.org/2000/svg" width="12.925ex" height="2.626ex" role="img" focusable="false" viewBox="0 -855.6 5712.8 1160.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mo" transform="translate(347.8,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g><g data-mml-node="mi" transform="translate(673,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(1256,0)"><g data-mml-node="text"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="text" transform="translate(278,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g></g><g data-mml-node="msubsup" transform="translate(2589.8,0)"><g data-mml-node="mi"><path data-c="3A0" d="M128 619Q121 626 117 628T101 631T58 634H25V680H724V634H691Q651 633 640 631T622 619V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V634H232V348L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V619Z"></path></g><g data-mml-node="TeXAtom" transform="translate(783,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(783,-247) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(469,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1247,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="msub" transform="translate(4658.1,0)"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mi" transform="translate(673,-150) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g></g></g></svg></mjx-container></span></p>
<p>两个α可视为β的函数，可以提前计算出来。使得由x0直接计算出xt，而不用逐步迭代。<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="35.654ex" height="2.925ex" role="img" focusable="false" viewBox="0 -1042.9 15759.3 1292.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(460,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(849,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="mi" transform="translate(640,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(1794.3,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msub" transform="translate(2072.3,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="mn" transform="translate(640,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(3115.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3782.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4838.4,0)"><g data-mml-node="mi"><path data-c="4E" d="M343 705Q358 705 358 698Q360 696 370 658T411 524T484 319Q536 174 590 82L595 73L615 152Q646 274 683 407Q729 571 752 637T799 727Q852 780 937 788Q939 788 947 788T958 789H962Q979 789 979 765Q979 722 951 692Q942 683 924 683Q888 681 859 672T818 654T803 639Q784 608 708 322T631 15Q631 14 630 15Q630 17 629 15Q628 14 628 12Q621 -4 601 -17T560 -31Q550 -31 546 -28T530 -7Q484 67 458 123T398 272Q352 392 314 514L306 535V534Q306 533 296 488T272 379T234 239T185 100T127 -7T61 -50Q34 -50 4 -34T-27 8Q-27 33 -12 61T18 90Q21 90 36 77T87 57H92Q109 57 123 78T162 173Q206 299 232 417T265 599T276 667Q284 681 304 693T343 705Z"></path></g></g><g data-mml-node="mo" transform="translate(5817.4,0)"><path data-c="28" d="M241 -250Q203 -212 174 -140T144 39Q144 158 180 288T296 544T481 746L487 750H499Q517 750 517 740Q517 736 495 716Q399 630 331 491T236 228T208 3Q208 -73 224 -130T255 -214T271 -244Q271 -250 252 -250H241Z"></path></g><g data-mml-node="msub" transform="translate(6334.4,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="mi" transform="translate(640,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(7279.6,0)"><path data-c="3B" d="M184 358Q184 385 206 408T258 431Q279 431 293 418T308 383Q308 354 284 332T233 310Q212 310 198 324T184 358ZM107 47Q107 77 130 99T180 121Q226 121 226 61Q226 25 214 -14T182 -84T144 -140T109 -180T88 -194T77 -185T70 -172Q70 -169 84 -155T121 -112T161 -48Q180 -10 180 3Q180 4 174 2Q172 2 166 1T156 0Q135 0 121 13T107 47Z"></path></g><g data-mml-node="msqrt" transform="translate(7753.3,0)"><g transform="translate(1020,0)"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mo" transform="translate(347.8,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g><g data-mml-node="mi" transform="translate(673,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mo" transform="translate(0,132.9)"><path data-c="221A" d="M263 249Q264 249 315 130T417 -108T470 -228L725 302Q981 837 982 839Q989 850 1001 850Q1008 850 1013 844T1020 832V826L741 243Q645 43 540 -176Q479 -303 469 -324T453 -348Q449 -350 436 -350L424 -349L315 -96Q206 156 205 156L171 130Q138 104 137 104L111 130L263 249Z"></path></g><rect width="978.3" height="60" x="1020" y="922.9"></rect></g><g data-mml-node="msub" transform="translate(9751.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="mn" transform="translate(640,-150) scale(0.707)"><path data-c="30" d="M414 665Q562 665 562 490Q562 426 534 318Q451 -21 251 -21Q222 -21 202 -15Q155 2 134 40T110 144Q110 201 127 286T187 470T287 614Q348 665 414 665ZM187 98Q187 59 208 37T260 15Q320 15 365 83Q394 128 440 312T487 547Q487 580 471 600T433 627Q428 628 408 628Q381 628 353 609T311 569Q279 526 239 364T190 143Q187 120 187 98Z"></path></g></g><g data-mml-node="mo" transform="translate(10802.9,0)"><path data-c="2C" d="M106 46Q106 68 121 90T167 120Q168 120 173 120T180 121Q232 121 232 59V54Q232 18 219 -20T186 -88T145 -143T109 -181T88 -194Q84 -194 77 -185T69 -171Q69 -168 70 -166T76 -161T85 -154T101 -139T124 -114Q146 -88 162 -58T183 -12T188 7Q187 7 183 5T172 2T156 0Q129 0 118 14T106 46Z"></path></g><g data-mml-node="mo" transform="translate(11276.6,0)"><path data-c="28" d="M241 -250Q203 -212 174 -140T144 39Q144 158 180 288T296 544T481 746L487 750H499Q517 750 517 740Q517 736 495 716Q399 630 331 491T236 228T208 3Q208 -73 224 -130T255 -214T271 -244Q271 -250 252 -250H241Z"></path></g><g data-mml-node="mn" transform="translate(11793.6,0)"><path data-c="31" d="M248 491Q228 491 228 502Q228 516 236 532Q237 536 246 537T275 541T314 552Q350 567 382 595T430 644L446 664Q450 666 454 666Q468 666 468 658Q468 647 395 359Q321 63 321 59Q321 52 334 50T388 46H422Q428 37 428 35Q428 19 421 5Q416 0 405 0Q400 0 361 1T263 2Q215 2 185 2T142 1T127 0Q110 0 110 11Q110 13 113 25T118 40Q120 46 146 46Q196 46 212 49T235 61Q238 66 295 295L353 526L340 519Q328 512 302 503T248 491Z"></path></g><g data-mml-node="mo" transform="translate(12526.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(13527,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mo" transform="translate(347.8,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g><g data-mml-node="mi" transform="translate(673,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(14505.3,0)"><path data-c="29" d="M326 497Q326 546 320 588T304 655T285 699T269 728T262 740Q262 746 267 749L272 750Q276 750 281 750H293Q331 712 360 640T390 461Q390 332 339 171T188 -116Q161 -150 121 -188T47 -250H35Q17 -250 17 -240Q17 -236 39 -216Q135 -130 203 9T298 272T326 497Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(14914.3,0)"><g data-mml-node="mi"><path data-c="1D408" d="M397 0Q370 3 218 3Q65 3 38 0H25V62H139V624H25V686H38Q65 683 218 683Q370 683 397 686H410V624H296V62H410V0H397Z"></path></g></g><g data-mml-node="mo" transform="translate(15350.3,0)"><path data-c="29" d="M326 497Q326 546 320 588T304 655T285 699T269 728T262 740Q262 746 267 749L272 750Q276 750 281 750H293Q331 712 360 640T390 461Q390 332 339 171T188 -116Q161 -150 121 -188T47 -250H35Q17 -250 17 -240Q17 -236 39 -216Q135 -130 203 9T298 272T326 497Z"></path></g></g></g></svg></mjx-container></span></p>
<h4 id="用预测噪声代替预测均值">用预测噪声代替预测均值</h4>
<p>另一个优化是：通过重新参数化高斯分布的均值，让神经网络从一个均值预测器变成了噪声预测器，即：让神经网络学习对图片的<strong>附加噪声</strong>建模（这里只考虑高斯分布的均值建模，先不考虑方差）。实验证明，该方法效果更好。经过数学推导，均值与噪声关系如下：<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.308ex;" xmlns="http://www.w3.org/2000/svg" width="41.782ex" height="5.587ex" role="img" focusable="false" viewBox="0 -1449.5 18467.7 2469.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path></g><g data-mml-node="TeXAtom" transform="translate(636,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(1184.3,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1334.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1778.9,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(2139.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(3991,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(5046.8,0)"><g data-mml-node="mn" transform="translate(885.6,676)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="msqrt" transform="translate(220,-729.6)"><g transform="translate(853,0)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(673,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g></g><g data-mml-node="mo" transform="translate(0,-90.4)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z"></path></g><rect width="978.3" height="60" x="853" y="649.6"></rect></g><rect width="2031.3" height="60" x="120" y="220"></rect></g><g data-mml-node="mrow" transform="translate(7318.1,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z"></path></g><g data-mml-node="msub" transform="translate(736,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1903.5,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mfrac" transform="translate(2903.7,0)"><g data-mml-node="msub" transform="translate(1544.7,676)"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="TeXAtom" transform="translate(599,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="msqrt" transform="translate(220,-855.1)"><g transform="translate(853,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(1722.4,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mo" transform="translate(347.8,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g><g data-mml-node="TeXAtom" transform="translate(673,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g></g><g data-mml-node="mo" transform="translate(0,35.1)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z"></path></g><rect width="2700.7" height="60" x="853" y="775.1"></rect></g><rect width="3753.7" height="60" x="120" y="220"></rect></g><g data-mml-node="msub" transform="translate(6897.4,0)"><g data-mml-node="mi"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g><g data-mml-node="TeXAtom" transform="translate(439,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(7884.7,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1334.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1778.9,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(2139.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(10413.7,0) translate(0 -0.5)"><path data-c="29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z"></path></g></g></g></g></svg></mjx-container></span><br>
第t步损失函数Lt如下：<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.21ex;" xmlns="http://www.w3.org/2000/svg" width="51.277ex" height="4.208ex" role="img" focusable="false" viewBox="0 -1325.3 22664.4 1860"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(500,0)"><g data-mml-node="mi"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g></g><g data-mml-node="mo" transform="translate(1128.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2128.4,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g></g><g data-mml-node="mi" transform="translate(439,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="mo" transform="translate(2949.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(3338.1,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="mi" transform="translate(640,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(4283.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(4728,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(5089,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="msup" transform="translate(5478,0)"><g data-mml-node="mo"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g><g data-mml-node="mn" transform="translate(533,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(6692.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(7748.1,0)"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(8248.1,0)"><g data-mml-node="mi"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g></g><g data-mml-node="mo" transform="translate(8876.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(9876.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g></g><g data-mml-node="mi" transform="translate(439,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="mo" transform="translate(10697.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msqrt" transform="translate(11086.2,0)"><g transform="translate(1020,0)"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mo" transform="translate(347.8,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g><g data-mml-node="mi" transform="translate(673,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mo" transform="translate(0,132.9)"><path data-c="221A" d="M263 249Q264 249 315 130T417 -108T470 -228L725 302Q981 837 982 839Q989 850 1001 850Q1008 850 1013 844T1020 832V826L741 243Q645 43 540 -176Q479 -303 469 -324T453 -348Q449 -350 436 -350L424 -349L315 -96Q206 156 205 156L171 130Q138 104 137 104L111 130L263 249Z"></path></g><rect width="978.3" height="60" x="1020" y="922.9"></rect></g><g data-mml-node="msub" transform="translate(13084.5,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="mn" transform="translate(640,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(14350.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msqrt" transform="translate(15350.5,0)"><g transform="translate(1020,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(389,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(1111.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2111.4,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mo" transform="translate(347.8,3) translate(-250 0)"><path data-c="AF" d="M69 544V590H430V544H69Z"></path></g></g></g><g data-mml-node="mi" transform="translate(673,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(3089.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(0,115.3)"><path data-c="221A" d="M1001 1150Q1017 1150 1020 1132Q1020 1127 741 244L460 -643Q453 -650 436 -650H424Q423 -647 423 -645T421 -640T419 -631T415 -617T408 -594T399 -560T385 -512T367 -448T343 -364T312 -259L203 119L138 41L111 67L212 188L264 248L472 -474L983 1140Q988 1150 1001 1150Z"></path></g><rect width="3478.7" height="60" x="1020" y="1205.3"></rect></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(19849.2,0)"><g data-mml-node="mi"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g></g><g data-mml-node="mo" transform="translate(20255.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(20699.8,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(21060.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="msup" transform="translate(21449.8,0)"><g data-mml-node="mo"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g><g data-mml-node="mn" transform="translate(533,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(22386.4,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g></g></g></svg></mjx-container></span><br>
其中 ϵ 是在时间步 t 采样的噪声，εθ 是神经网络。</p>
<h3 id="算法">算法</h3>
<p>最终求的是误差网络e的权重参数θ。<br>
<img src="/attachments_2023/Pasted%20image%2020230902165242.png"></p>
<p>在训练过程中：<br>
* 抽取样本图片x0<br>
* 随机抽取时间步t<br>
* 采样高斯噪声ϵ，使用该噪声和时间步t生成第t步的加噪图像<br>
* 训练神经网络基于加噪图像xt和该步βt来预测噪声</p>
<p>在推理过程中：<br>
* 取一个高斯噪声做为XT图片<br>
* 通过T步对其进行去噪<br>
* 随机取z作为高斯噪声的方差参数<br>
* 代入上述公式，利用神经网络预测的 ϵ
为第t步图片去噪，从而得到第t-1步图片<br>
* 最终还原原始图片</p>
]]></content>
      <tags>
        <tag>图形图像</tag>
        <tag>模型结构</tag>
        <tag>扩散模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_扩散模型_DM</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/AI%E7%BB%98%E7%94%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B_DM/</url>
    <content><![CDATA[<p>英文名称: Deep Unsupervised Learning using Nonequilibrium
Thermodynamics<br />
中文名称: 使用非平衡热力学原理的深度无监督学习<br />
论文地址: http://arxiv.org/abs/1503.03585<br />
代码地址:
https://github.com/Sohl-Dickstein/Diffusion-Probabilistic-Models<br />
时间: 2015-11-18<br />
作者: Jascha Sohl-Dickstein, 斯坦福大学<br />
引用量: 1813</p>
<h2 id="读后感">1 读后感</h2>
<p>论文目标是建立<strong>灵活且易用</strong>的<strong>数据生成模型</strong>。它利用非平衡统计物理学原理：通过扩散过程（少量加噪）系统地、缓慢地破坏数据分布中的结构；然后，学习反向扩散过程，恢复数据结构。</p>
<h2 id="介绍">2 介绍</h2>
<h3 id="扩散模型与变分模型">2.1 扩散模型与变分模型</h3>
<p>扩散模型与变分模型原理类似，都是将图片拆成一系列高斯分布的均值和方差，而扩散模型是一个逐步变化的过程，主要差别如下：</p>
<ul>
<li>原理不同：扩散模型使用物理学、准静态过程和退火采样的思想。由于任何平滑目标分布都存在扩散过程，因此理论上该方法可以捕获任意形式的数据分布。<br />
</li>
<li>展示了用简单的乘法，将一个<strong>分布逐步转换为另一分布</strong>的过程。<br />
</li>
<li>解决了推理模型和生成模型之间目标的<strong>不对称性</strong>，将正向（推理）过程限制为简单的函数形式，反向（生成）过程将具有相同的函数形式。<br />
</li>
<li>可训练具有数<strong>千层（时间步）</strong> 的模型。<br />
</li>
<li><strong>精细控制</strong>每层中熵产生的上限和下限。</li>
</ul>
<h2 id="方法">3 方法</h2>
<p><img
src="/attachments_2023/Pasted%20image%2020230823113243.png" /><br />
请记住图中这些符号，很多后续文章都延用了这些符号的定义。</p>
<h3 id="向前轨迹">3.1 向前轨迹</h3>
<p>其中蓝色是扩散过程，从左往右看，总共T步，每步加一点高斯噪声，将瑞士卷图扩散成了高斯分布，扩展过程设为q。每步都根据上一步数据而来：<br />
<span class="math display">\[q\left(\mathbf{x}^{(0 \cdots
T)}\right)=q\left(\mathbf{x}^{(0)}\right) \prod_{t=1}^{T}
q\left(\mathbf{x}^{(t)} \mid \mathbf{x}^{(t-1)}\right)\]</span></p>
<h3 id="反向轨迹">3.2 反向轨迹</h3>
<p>中间红色部分是扩散的逆过程，从右往左看，图片逐步恢复，恢复过程设为p；在训练过程中，通过学习高斯扩散的逆过程，使数据转换回原分布，从而生成数据。<br />
<span class="math display">\[p\left(\mathbf{x}^{(0 \cdots
T)}\right)=p\left(\mathbf{x}^{(T)}\right) \prod_{t=1}^{T}
p\left(\mathbf{x}^{(t-1)} \mid \mathbf{x}^{(t)}\right)\]</span><br />
最后一行展示了反向扩散过程的漂移项。fμ (x(t), t)
是高斯逆马尔可夫转移的均值和协方差的函数。</p>
<p>扩散的原理是通过<strong>马尔可夫链逐渐将一种分布转换为另一种分布</strong>。最终，估计概率分布的任务简化为对高斯序列的均值和协方差函数的回归任务（这里的0状态指的是原始图，T状态指高斯分布图）；由于扩散链中的每个步骤都具有可分析评估的概率（对比正向和反向变化中每一步数据的相似度），因此也可以对整个链进行分析评估。</p>
<h3 id="模型概率">3.3 模型概率</h3>
<p>计算将图像恢复成原图的概率，可拆解成每一步变化的累积。<br />
<span class="math display">\[\begin{aligned}  
p\left(\mathbf{x}^{(0)}\right)= &amp; \int d \mathbf{x}^{(1 \cdots T)}
p\left(\mathbf{x}^{(0 \cdots T)}\right) \frac{q\left(\mathbf{x}^{(1
\cdots T)} \mid \mathbf{x}^{(0)}\right)}{q\left(\mathbf{x}^{(1 \cdots
T)} \mid \mathbf{x}^{(0)}\right)} \\  
= &amp; \int d \mathbf{x}^{(1 \cdots T)} q\left(\mathbf{x}^{(1 \cdots
T)} \mid \mathbf{x}^{(0)}\right) \frac{p\left(\mathbf{x}^{(0 \cdots
T)}\right)}{q\left(\mathbf{x}^{(1 \cdots T)} \mid
\mathbf{x}^{(0)}\right)} \\  
= &amp; \int d \mathbf{x}^{(1 \cdots T)} q\left(\mathbf{x}^{(1 \cdots
T)} \mid \mathbf{x}^{(0)}\right) \\  
&amp; p\left(\mathbf{x}^{(T)}\right) \prod_{t=1}^{T}
\frac{p\left(\mathbf{x}^{(t-1)} \mid
\mathbf{x}^{(t)}\right)}{q\left(\mathbf{x}^{(t)} \mid
\mathbf{x}^{(t-1)}\right)}  
\end{aligned}\]</span></p>
<h3 id="训练">3.4 训练</h3>
<p>具体方法是计算熵 H 和 KL
散度。其推导与变分贝叶斯方法中对数似然界限的推导类似。DK散度描述了每一时间步数据分布的差异，熵描述了数据的混乱程度。<br />
<span class="math display">\[\begin{aligned}  
L &amp; \geq K \\  
K= &amp; -\sum_{t=2}^{T} \int d \mathbf{x}^{(0)} d \mathbf{x}^{(t)}
q\left(\mathbf{x}^{(0)}, \mathbf{x}^{(t)}\right) . \\  
&amp; D_{K L}\left(q\left(\mathbf{x}^{(t-1)} \mid \mathbf{x}^{(t)},
\mathbf{x}^{(0)}\right) \| p\left(\mathbf{x}^{(t-1)} \mid
\mathbf{x}^{(t)}\right)\right) \\  
&amp; +H_{q}\left(\mathbf{X}^{(T)} \mid
\mathbf{X}^{(0)}\right)-H_{q}\left(\mathbf{X}^{(1)} \mid
\mathbf{X}^{(0)}\right)-H_{p}\left(\mathbf{X}^{(T)}\right) .  
\end{aligned}\]</span><br />
<strong>设置扩散率 βt</strong><br />
热力学中，在平衡分布之间移动时所采取的时间表决定了损失多少自由能。简单地说，就是如何设置每一步变化的大小。一般情况下，第一步β设成一个很小的常数，以防过拟合，然后2-T步逐步扩大。将在之后的DDPM中详述。</p>
<h3 id="乘以分布计算后验">3.5 乘以分布计算后验</h3>
<p>对大多数模型而言，乘以分布计算量大，而在扩散模型中则比较简单，第二个分布可以被视为扩散过程中每个步骤的小扰动。</p>
]]></content>
      <tags>
        <tag>图形图像</tag>
        <tag>模型结构</tag>
        <tag>扩散模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_扩散模型_LDM</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/AI%E7%BB%98%E7%94%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B_LDM/</url>
    <content><![CDATA[<p>英文名称: High-Resolution Image Synthesis with Latent Diffusion
Models<br>
中文名称: 使用潜空间扩散模型合成高分辨率图像<br>
地址: https://ieeexplore.ieee.org/document/9878449/<br>
代码: https://github.com/CompVis/latent-diffusion<br>
作者：Robin Rombach<br>
日期: 2022-06-01<br>
引用: 2275</p>
<h2 id="读后感">1 读后感</h2>
<p>Latent Diffusion Models
（LDMs）基于潜空间的扩散模型，是目前主流的基础模型，Stable diffusion
就是基于 LDMs
原理工作的。之前的扩散模型运算都在像素层面，优化通常会消耗数百个 GPU
天，且评估和推理成本也很高。LDMs
大量自编码器的运算基于潜空间数据，降低了计算复杂度，从而大幅节省了算力，并保持了图像质量和灵活度，它让更多人可以训练模型。其应用场景包含<strong>有条件（根据文本或图像生成图像）和无条件（去噪/着色/根据涂鸦合成）的图像生成</strong>。</p>
<h2 id="研究背景和动机">研究背景和动机</h2>
<p>扩散模型是由逐层去噪的自动编码器构建的，基于似然的模型。这种模型倾向于<strong>花费过多的容量和资源对难以察觉的细节进行建模</strong>，尽管使用了重新加权的变分目标，但在
RGB 图像的高维空间中训练和生成仍需要大量计算。</p>
<p>LDMs
学习可以分为<strong>两个阶段</strong>：首先找到一个<strong>感知上等效但计算上更合适的空间</strong>（感知压缩）；然后，在其上<strong>训练扩散模型（语义压缩）</strong>。另外，本中还通过设计架构，分离了自动编码和具体的任务，使得同一编码器可用于<strong>多个任务</strong>。</p>
<p>论文贡献如下：<br>
*
优化压缩，支持更忠实和详细的重建效果，有效构建<strong>高分辨率图像</strong>。<br>
* 在多种任务中，显著降低了推理成本。<br>
*
不需要对重建和生成能力进行微妙的加权，几乎不需要对潜在空间进行正则化。<br>
* 模型可以卷积方式使用并渲染约 1024x1024 像素的大而一致的图像。<br>
*
设计了基于交叉注意力的调节机制，实现了多模式训练模型（一个模型支持多个功能）。<br>
* 在github上开源了算法。</p>
<h2 id="方法">方法</h2>
<p>明确分离压缩阶段和生成阶段有以下优势：(1)
脱离高维空间，在低维空间中的扩散模型更高效；(2) 继承了 UNet
架构的归纳偏差，这对具有空间结构（上下左右的相关性）的数据特别有效； (3)
获得通用压缩模型，其潜在空间可用于训练多种生成模型，也可用于其他下游应用。</p>
<p><img src="/attachments_2023/Pasted%20image%2020230828154849.png"></p>
<p>主逻辑分成三部分，第一部分是像素空间与潜空间之间的转换，即感知图像压缩（粉色）；第二部分是在潜空间操作的扩散模型（绿色）；第三部分是用文本描述或其它图片作为条件，控制图像生成（白色）。</p>
<h3 id="感知图像压缩">感知图像压缩</h3>
<p>感知压缩模型由一个通过感知损失和基于 patch
的对抗目标相结合的自编码器组成。<br>
给定 RGB 空间中的图像 x ∈ RH×W ×3，编码器 E 将 x 编码为潜在表示 z =
E(x)，解码器 D 从潜在表示重建图像，给出 ̃ x = D( z) = D(E(x))，其中 z ∈
Rh×w×c。编码器按因子 f = H/h = W/w
对图像进行下采样（后面实验发现，下采样在4,8,16时效果最好）。</p>
<h3 id="潜空间扩散模型">潜空间扩散模型</h3>
<h4 id="扩散模型">扩散模型</h4>
<p>扩散模型原理比较复杂，详见<a href="/1_Note/2_算法/8_图形图像/AI绘画/论文阅读_扩散模型_DDPM">论文阅读_扩散模型_DDPM</a>，这里只做简单介绍：<br>
*
有一张图x0，分多步，每步向图里加入少量噪声，图将变得越来越模糊，最后变成了一张全是噪声的图xT，将<strong>加噪操作设为q</strong>。<br>
*
在中间过程第t步，有可能从第t步还原出第t-1步的图像，以此类推，一步一步往上倒，理论上，就能从最后一步xT还原出原图x0。将<strong>去噪操作设为p</strong>。<br>
* 所以建模的目标是找到从t步还原第t-1步的方法，也就是对p建模。<br>
<img src="/attachments_2023/Pasted%20image%2020230822175634.png"><br>
经过简化，最终扩散模型的目标函数是：<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.469ex;" xmlns="http://www.w3.org/2000/svg" width="35.903ex" height="4.07ex" role="img" focusable="false" viewBox="0 -1149.5 15869.3 1799"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g><g data-mml-node="mi" transform="translate(828,0)"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2370.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(3426.2,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D53C" d="M12 666Q12 675 24 683H582Q590 680 593 672V588Q593 514 591 502T575 490Q567 490 563 495T555 517Q552 556 517 590Q486 623 445 634T340 648H282Q266 636 264 620T260 492V370H277Q329 375 358 391T404 439Q420 480 420 506Q420 529 436 529Q445 529 451 521Q455 517 455 361Q455 333 455 298T456 253Q456 217 453 207T437 197Q420 196 420 217Q420 240 406 270Q377 328 284 335H260V201Q261 174 261 134Q262 73 264 61T278 38Q281 36 282 35H331Q400 35 449 50Q571 93 602 179Q605 203 622 203Q629 203 634 197T640 183Q638 181 624 95T604 3L600 -1H24Q12 5 12 16Q12 35 51 35Q92 38 97 52Q102 60 102 341T97 632Q91 645 51 648Q12 648 12 666ZM137 341Q137 131 136 89T130 37Q129 36 129 35H235Q233 41 231 48L226 61V623L231 635L235 648H129Q132 641 133 638T135 603T137 517T137 341ZM557 603V648H504Q504 646 515 639Q527 634 542 619L557 603ZM420 317V397L406 383Q394 370 380 363L366 355Q373 350 382 346Q400 333 409 328L420 317ZM582 61L586 88Q585 88 582 83Q557 61 526 46L511 37L542 35H577Q577 36 578 39T580 49T582 61Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(700,-204.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(572,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(850,0)"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g><g data-mml-node="mo" transform="translate(1256,0)"><path data-c="223C" d="M55 166Q55 241 101 304T222 367Q260 367 296 349T362 304T421 252T484 208T554 189Q616 189 655 236T694 338Q694 350 698 358T708 367Q722 367 722 334Q722 260 677 197T562 134H554Q517 134 481 152T414 196T355 248T292 293T223 311Q179 311 145 286Q109 257 96 218T80 156T69 133Q55 133 55 166Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(2034,0)"><g data-mml-node="mi"><path data-c="4E" d="M343 705Q358 705 358 698Q360 696 370 658T411 524T484 319Q536 174 590 82L595 73L615 152Q646 274 683 407Q729 571 752 637T799 727Q852 780 937 788Q939 788 947 788T958 789H962Q979 789 979 765Q979 722 951 692Q942 683 924 683Q888 681 859 672T818 654T803 639Q784 608 708 322T631 15Q631 14 630 15Q630 17 629 15Q628 14 628 12Q621 -4 601 -17T560 -31Q550 -31 546 -28T530 -7Q484 67 458 123T398 272Q352 392 314 514L306 535V534Q306 533 296 488T272 379T234 239T185 100T127 -7T61 -50Q34 -50 4 -34T-27 8Q-27 33 -12 61T18 90Q21 90 36 77T87 57H92Q109 57 123 78T162 173Q206 299 232 417T265 599T276 667Q284 681 304 693T343 705Z"></path></g></g><g data-mml-node="mo" transform="translate(3013,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(3402,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mo" transform="translate(3902,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(4180,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(4680,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5069,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(5347,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(8379,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="5B" d="M224 -649V1150H455V1099H275V-598H455V-649H224Z"></path></g><g data-mml-node="msubsup" transform="translate(472,0)"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g><g data-mml-node="mo" transform="translate(1128.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2128.4,0)"><g data-mml-node="mi"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g><g data-mml-node="TeXAtom" transform="translate(439,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(3115.7,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1299.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1743.9,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(2104.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(5609.7,0)"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(6142.7,477.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(6142.7,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(7018.2,0) translate(0 -0.5)"><path data-c="5D" d="M16 1099V1150H247V-649H16V-598H196V1099H16Z"></path></g></g></g></g></svg></mjx-container></span><br>
这里考虑第t步，xt是第t步的加噪图像，经过训练来预测其输入 xt 的去噪变体
ε，目标是让实际值和模型预测值尽量一致，通过训练给模型调参。</p>
<h4 id="潜空间的扩散模型">潜空间的扩散模型</h4>
<p>将作用于像素级的扩散模型转换为作为于压缩低频空间（潜空间）的扩散模型。与高维像素空间相比，该空间更适合基于似然的生成模型，因为它可以专注于数据的重要语义；且在较低维度进行训练更为高效。</p>
<p>公式变为：<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.469ex;" xmlns="http://www.w3.org/2000/svg" width="39.494ex" height="4.07ex" role="img" focusable="false" viewBox="0 -1149.5 17456.6 1799"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(681,0)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g><g data-mml-node="mi" transform="translate(1509,0)"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g></g><g data-mml-node="mo" transform="translate(2837.8,0)"><g data-mml-node="text"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="text" transform="translate(278,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g></g><g data-mml-node="msub" transform="translate(4171.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D53C" d="M12 666Q12 675 24 683H582Q590 680 593 672V588Q593 514 591 502T575 490Q567 490 563 495T555 517Q552 556 517 590Q486 623 445 634T340 648H282Q266 636 264 620T260 492V370H277Q329 375 358 391T404 439Q420 480 420 506Q420 529 436 529Q445 529 451 521Q455 517 455 361Q455 333 455 298T456 253Q456 217 453 207T437 197Q420 196 420 217Q420 240 406 270Q377 328 284 335H260V201Q261 174 261 134Q262 73 264 61T278 38Q281 36 282 35H331Q400 35 449 50Q571 93 602 179Q605 203 622 203Q629 203 634 197T640 183Q638 181 624 95T604 3L600 -1H24Q12 5 12 16Q12 35 51 35Q92 38 97 52Q102 60 102 341T97 632Q91 645 51 648Q12 648 12 666ZM137 341Q137 131 136 89T130 37Q129 36 129 35H235Q233 41 231 48L226 61V623L231 635L235 648H129Q132 641 133 638T135 603T137 517T137 341ZM557 603V648H504Q504 646 515 639Q527 634 542 619L557 603ZM420 317V397L406 383Q394 370 380 363L366 355Q373 350 382 346Q400 333 409 328L420 317ZM582 61L586 88Q585 88 582 83Q557 61 526 46L511 37L542 35H577Q577 36 578 39T580 49T582 61Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(700,-204.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="45" d="M144 470Q144 556 240 630T451 705Q564 705 564 637Q564 611 540 573Q529 559 505 547T464 534Q448 534 448 545Q448 552 455 562Q463 577 463 591Q463 600 462 604T456 616T436 627T400 635Q396 635 390 635T380 636Q291 636 258 568Q245 544 245 516Q245 463 290 438T391 410Q415 410 415 398Q415 392 407 380T376 356T326 341Q288 340 260 327Q218 311 187 276T143 208T130 151Q130 113 156 88T211 55T268 47Q349 47 403 125Q415 144 439 157T483 171Q499 171 499 160Q499 148 475 120T413 59T315 3T197 -22Q124 -22 77 14T30 105Q30 126 39 154T66 216T122 288T209 354L223 362Q144 400 144 470Z"></path></g></g><g data-mml-node="mo" transform="translate(564,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(953,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1525,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(1914,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2192,0)"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g><g data-mml-node="mo" transform="translate(2598,0)"><path data-c="223C" d="M55 166Q55 241 101 304T222 367Q260 367 296 349T362 304T421 252T484 208T554 189Q616 189 655 236T694 338Q694 350 698 358T708 367Q722 367 722 334Q722 260 677 197T562 134H554Q517 134 481 152T414 196T355 248T292 293T223 311Q179 311 145 286Q109 257 96 218T80 156T69 133Q55 133 55 166Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(3376,0)"><g data-mml-node="mi"><path data-c="4E" d="M343 705Q358 705 358 698Q360 696 370 658T411 524T484 319Q536 174 590 82L595 73L615 152Q646 274 683 407Q729 571 752 637T799 727Q852 780 937 788Q939 788 947 788T958 789H962Q979 789 979 765Q979 722 951 692Q942 683 924 683Q888 681 859 672T818 654T803 639Q784 608 708 322T631 15Q631 14 630 15Q630 17 629 15Q628 14 628 12Q621 -4 601 -17T560 -31Q550 -31 546 -28T530 -7Q484 67 458 123T398 272Q352 392 314 514L306 535V534Q306 533 296 488T272 379T234 239T185 100T127 -7T61 -50Q34 -50 4 -34T-27 8Q-27 33 -12 61T18 90Q21 90 36 77T87 57H92Q109 57 123 78T162 173Q206 299 232 417T265 599T276 667Q284 681 304 693T343 705Z"></path></g></g><g data-mml-node="mo" transform="translate(4355,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(4744,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mo" transform="translate(5244,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(5522,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(6022,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(6411,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(6689,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(10073.3,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="5B" d="M224 -649V1150H455V1099H275V-598H455V-649H224Z"></path></g><g data-mml-node="msubsup" transform="translate(472,0)"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g><g data-mml-node="mo" transform="translate(1128.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2128.4,0)"><g data-mml-node="mi"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g><g data-mml-node="TeXAtom" transform="translate(439,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(3115.7,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="TeXAtom" transform="translate(498,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1192.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1636.9,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(1997.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(5502.7,0)"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(6035.7,477.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(6035.7,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(6911.2,0) translate(0 -0.5)"><path data-c="5D" d="M16 1099V1150H247V-649H16V-598H196V1099H16Z"></path></g></g></g></g></svg></mjx-container></span><br>
文中模型的主干 εθ 通过时间条件 UNet
实现。由于前向过程是固定的，在训练期间可以通过 E 有效地获得
zt，并且只需通过 D 即可将来自 p(z) 的样本解码到图像空间。</p>
<h4 id="条件机制">条件机制</h4>
<p>扩散模型原则上能够对 p(z|y)
形式的条件分布进行建模。它通过条件去噪自动编码器 εθ(zt, t, y)
来实现，通过输入条件
y（通过文本生成图像，通过图像生成图像）控制合成过程。</p>
<p>具体方法是通过交叉力注意机制增强其底层 UNet 主干网，Attention(Q, K, V
)，<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.044ex;" xmlns="http://www.w3.org/2000/svg" width="50.713ex" height="3.444ex" role="img" focusable="false" viewBox="0 -1060.7 22415.3 1522.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mo" transform="translate(1068.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msubsup" transform="translate(2124.6,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1136.2,530.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(977,-324.2) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4327.1,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="msub" transform="translate(4827.3,0)"><g data-mml-node="mi"><path data-c="1D711" d="M92 210Q92 176 106 149T142 108T185 85T220 72L235 70L237 71L250 112Q268 170 283 211T322 299T370 375T429 423T502 442Q547 442 582 410T618 302Q618 224 575 152T457 35T299 -10Q273 -10 273 -12L266 -48Q260 -83 252 -125T241 -179Q236 -203 215 -212Q204 -218 190 -218Q159 -215 159 -185Q159 -175 214 -2L209 0Q204 2 195 5T173 14T147 28T120 46T94 71T71 103T56 142T50 190Q50 238 76 311T149 431H162Q183 431 183 423Q183 417 175 409Q134 361 114 300T92 210ZM574 278Q574 320 550 344T486 369Q437 369 394 329T323 218Q309 184 295 109L286 64Q304 62 306 62Q423 62 498 131T574 278Z"></path></g><g data-mml-node="TeXAtom" transform="translate(687,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(5974.9,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="TeXAtom" transform="translate(498,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1192.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(7556.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(8000.8,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mo" transform="translate(9167.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msubsup" transform="translate(10223.4,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1136.2,530.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(977,-309.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g></g></g><g data-mml-node="mo" transform="translate(12425.9,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="msub" transform="translate(12926.1,0)"><g data-mml-node="mi"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"></path></g><g data-mml-node="TeXAtom" transform="translate(470,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g><g data-mml-node="mo" transform="translate(13777.7,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(14166.7,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(14656.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(15045.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(15490.4,0)"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g><g data-mml-node="mo" transform="translate(16537.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msubsup" transform="translate(17593,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1136.2,530.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(977,-309.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g></g></g><g data-mml-node="mo" transform="translate(19795.5,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="msub" transform="translate(20295.7,0)"><g data-mml-node="mi"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"></path></g><g data-mml-node="TeXAtom" transform="translate(470,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g><g data-mml-node="mo" transform="translate(21147.3,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(21536.3,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(22026.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span><br>
其中y是条件，φi(zt) 是 UNet 的中间表示，的WQ, WK,
WV是可学习的投影矩阵。<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.469ex;" xmlns="http://www.w3.org/2000/svg" width="46.557ex" height="4.07ex" role="img" focusable="false" viewBox="0 -1149.5 20578.1 1799"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(681,0)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g><g data-mml-node="mi" transform="translate(1509,0)"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2852,0)"><g data-mml-node="text"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="text" transform="translate(278,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g></g><g data-mml-node="msub" transform="translate(4185.7,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D53C" d="M12 666Q12 675 24 683H582Q590 680 593 672V588Q593 514 591 502T575 490Q567 490 563 495T555 517Q552 556 517 590Q486 623 445 634T340 648H282Q266 636 264 620T260 492V370H277Q329 375 358 391T404 439Q420 480 420 506Q420 529 436 529Q445 529 451 521Q455 517 455 361Q455 333 455 298T456 253Q456 217 453 207T437 197Q420 196 420 217Q420 240 406 270Q377 328 284 335H260V201Q261 174 261 134Q262 73 264 61T278 38Q281 36 282 35H331Q400 35 449 50Q571 93 602 179Q605 203 622 203Q629 203 634 197T640 183Q638 181 624 95T604 3L600 -1H24Q12 5 12 16Q12 35 51 35Q92 38 97 52Q102 60 102 341T97 632Q91 645 51 648Q12 648 12 666ZM137 341Q137 131 136 89T130 37Q129 36 129 35H235Q233 41 231 48L226 61V623L231 635L235 648H129Q132 641 133 638T135 603T137 517T137 341ZM557 603V648H504Q504 646 515 639Q527 634 542 619L557 603ZM420 317V397L406 383Q394 370 380 363L366 355Q373 350 382 346Q400 333 409 328L420 317ZM582 61L586 88Q585 88 582 83Q557 61 526 46L511 37L542 35H577Q577 36 578 39T580 49T582 61Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(700,-204.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="45" d="M144 470Q144 556 240 630T451 705Q564 705 564 637Q564 611 540 573Q529 559 505 547T464 534Q448 534 448 545Q448 552 455 562Q463 577 463 591Q463 600 462 604T456 616T436 627T400 635Q396 635 390 635T380 636Q291 636 258 568Q245 544 245 516Q245 463 290 438T391 410Q415 410 415 398Q415 392 407 380T376 356T326 341Q288 340 260 327Q218 311 187 276T143 208T130 151Q130 113 156 88T211 55T268 47Q349 47 403 125Q415 144 439 157T483 171Q499 171 499 160Q499 148 475 120T413 59T315 3T197 -22Q124 -22 77 14T30 105Q30 126 39 154T66 216T122 288T209 354L223 362Q144 400 144 470Z"></path></g></g><g data-mml-node="mo" transform="translate(564,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(953,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1525,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(1914,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2192,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2682,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2960,0)"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g><g data-mml-node="mo" transform="translate(3366,0)"><path data-c="223C" d="M55 166Q55 241 101 304T222 367Q260 367 296 349T362 304T421 252T484 208T554 189Q616 189 655 236T694 338Q694 350 698 358T708 367Q722 367 722 334Q722 260 677 197T562 134H554Q517 134 481 152T414 196T355 248T292 293T223 311Q179 311 145 286Q109 257 96 218T80 156T69 133Q55 133 55 166Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4144,0)"><g data-mml-node="mi"><path data-c="4E" d="M343 705Q358 705 358 698Q360 696 370 658T411 524T484 319Q536 174 590 82L595 73L615 152Q646 274 683 407Q729 571 752 637T799 727Q852 780 937 788Q939 788 947 788T958 789H962Q979 789 979 765Q979 722 951 692Q942 683 924 683Q888 681 859 672T818 654T803 639Q784 608 708 322T631 15Q631 14 630 15Q630 17 629 15Q628 14 628 12Q621 -4 601 -17T560 -31Q550 -31 546 -28T530 -7Q484 67 458 123T398 272Q352 392 314 514L306 535V534Q306 533 296 488T272 379T234 239T185 100T127 -7T61 -50Q34 -50 4 -34T-27 8Q-27 33 -12 61T18 90Q21 90 36 77T87 57H92Q109 57 123 78T162 173Q206 299 232 417T265 599T276 667Q284 681 304 693T343 705Z"></path></g></g><g data-mml-node="mo" transform="translate(5123,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(5512,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mo" transform="translate(6012,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(6290,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(6790,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(7179,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(7457,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(10630.6,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="5B" d="M224 -649V1150H455V1099H275V-598H455V-649H224Z"></path></g><g data-mml-node="msubsup" transform="translate(472,0)"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g><g data-mml-node="mo" transform="translate(1128.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(2128.4,0)"><g data-mml-node="mi"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g><g data-mml-node="TeXAtom" transform="translate(439,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(3115.7,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="TeXAtom" transform="translate(498,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1192.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1636.9,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(1997.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(2442.6,0)"><g data-mml-node="mi"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"></path></g><g data-mml-node="TeXAtom" transform="translate(470,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3294.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(3683.2,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4173.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4562.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mo" transform="translate(8067,0)"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(8600,477.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(8600,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(9475.5,0) translate(0 -0.5)"><path data-c="5D" d="M16 1099V1150H247V-649H16V-598H196V1099H16Z"></path></g></g></g></g></svg></mjx-container></span><br>
通过图像条件对数据来训练模型。其中 τθ 和 εθ 联合优化。
这种调节机制非常灵活，因为 τθ
可以由特定领域的专家网络进行参数化，τθ处理后条件入引绿色块，通过交叉注意力，作用于主干网络εθ，影响图像的生成。有效地解耦了条件模块和图像模块，即使后面加入其它条件，也不需要考虑修改绿色的主干网。</p>
]]></content>
      <tags>
        <tag>图形图像</tag>
        <tag>模型结构</tag>
        <tag>扩散模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_扩散模型_SDXL</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/AI%E7%BB%98%E7%94%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B_SDXL/</url>
    <content><![CDATA[<pre class="ad-info"><code>英文名称: SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis  
中文名称: SDXL：改进潜在扩散模型的高分辨率图像合成  
论文地址: http://arxiv.org/abs/2307.01952  
代码: https://github.com/Stability-AI/generative-models  
时间: 2023-07-04  
作者: Dustin Podell  </code></pre>
<h2 id="读后感">1 读后感</h2>
<p>SD 是语言引导的扩散模型。SDXL 是 2023年7月 Stable Diffusion
新发的大模型框架，它是潜在扩散模型（LDM）扩展。其主要效果是：<strong>加强了画面细腻度，优化了构图，以及对语言的理解能力</strong>。</p>
<p>我对比了 SD 1.5 和 SDXL
模型，感觉速度差不太多，个人感觉：图片质量，对文字的理解略有提升，可能因为目前
SDXL
的基模比较少，用的还不太多。个人理解，目前阶段，无论是AI写作，绘画还是编程，都需要与人和其它工具深度结合，远不到可以独立解决问题，自动生成最终成果的阶段，但确实能提升效率和效果。</p>
<p>这篇文章没有使用一般的技术论文结构，他将相关工作，方法，实验都写到了第二部分，具体方法也没做太多展开；限制和展示分别写在了正文和附录中。</p>
<h2 id="研究背景和动机">2 研究背景和动机</h2>
<p>视觉创作领域的一个主要问题是，虽然黑盒模型通常被认为是最先进的，但其架构的不透明性阻碍了对其性能的评估和验证。缺乏透明度阻碍了复现，抑制了创新，并阻止社区在这些模型的基础上进一步推动科学和艺术的进步。而本文提出了
SDXL 开源模型，显著提高了 SD
的性能，可与最先进的图像生成器相媲美的合成结果。</p>
<p>具体方法是：<br />
* SDXL 使用了之前三倍大的 U-Net
作为主干网络，增加的参数包括：引入第二个文本编码器，更多的注意力块和更大的交叉注意力上下文。<br />
* 增加两种调节技术，在多种大小和长宽比上优化模型训练。<br />
*
增加了基于扩散的refine模块，应用于去噪过程，提高了生成样本的视觉保真度。</p>
<h2 id="方法">3 方法</h2>
<p><img
src="/attachments_2023/Pasted%20image%2020230829112904.png" /></p>
<h3 id="架构与规模">3.1 架构与规模</h3>
<p>U-Net是当前扩散模型的主流架构，SDXL把 U-Net
网络扩展到之前的三倍大小，具体参数如表-1所示：<br />
<img
src="/attachments_2023/Pasted%20image%2020230829133510.png" /><br />
将 Transformer 的大部分计算转移到 UNet
中的较低级别特征，以提升效率。结构上：省略了最高特征级别的 Transformer
块，在较低级别使用 2 和 10 个块，并完全删除 UNet
中的最低级别（8×下采样）。</p>
<p>另外，还选择了更为强大的文本编码器，文本编码器的参数总大小为817M。除了使用交叉注意力根据文本输入来调节模型之外，还根据
OpenCLIP 模型的池化文本嵌入来调节模型。</p>
<h3 id="微调节">3.2 微调节</h3>
<h4 id="根据图像大小微调">3.2.1 根据图像大小微调</h4>
<p>LDM
由于其两阶段结构，训练模型需要最小的图像尺寸。一般有两种主流方法，一种是丢弃小分辨率图片（如&lt;512像素）；另一种方式是上采样。<br />
<img src="/attachments_2023/Pasted%20image%2020230829135424.png"
alt="|400" /><br />
如图所示，在预训练的数据集中，小于256的图像占39%，如果将之丢弃，可能影响模型性能和泛化，而对太多图片上采样可能使生成的图片变得模糊。</p>
<p>文中提出的方法是：根据原始图像分辨率来调节 UNet
模型，将图像的原始宽高，csize = (horiginal, woriginal)
作为模型的附加条件。每个组件使用傅立叶特征编码独立嵌入，这些编码连接成向量，将其添加到时间步嵌入以输入模型。推理时，传入待生成图片的宽高，模型将学会参考
csize 生成图像。</p>
<p>具体实验用 ImageNet 数据训练三个LDM模型，将图像大小限制为
512x512。<br />
<img src="/attachments_2023/Pasted%20image%2020230829140842.png"
alt="|350" /><br />
CIN-512-only
去掉了512以下的图片，CIN-nocond使用所有图片但未做处理，CIN-size-cond
将图像大小传入模型。实验结果说明，对于小数据量训练，csize确实提升了效果。</p>
<h4 id="根据裁剪参数调节">3.2.2 根据裁剪参数调节</h4>
<p><img
src="/attachments_2023/Pasted%20image%2020230829141400.png" /><br />
图-4 展示了 SD 之前版本的另一个常见问题，构图不对，这是由于 Pytorch
要求输入大小相同的数据，而训练数据中图片长宽比不同。一般处理方法是先缩放，再随机从其长边剪切图像再训练。</p>
<p>文中提出的方法与处理大小的方法类似，将裁剪坐标 ctop 和 cleft
进行统一采样，并通过傅里叶特征嵌入，将它们作为条件参数输入到模型中。推理时，将ctop,
cleft设为0。</p>
<h3 id="多尺度训练">3.3 多尺度训练</h3>
<p>一般生成的图像都为
512x512，1024x1024，而实际的需求往往不是这样的。为解决这一问题，文中将数据划分为不同纵横比的桶，将像素数尽可能保持接近
1024x1024 像素。</p>
<p>在优化过程中，每个 batch
由同一存储桶的图像组成，在每个训练步骤的存储桶大小之间交替。此外，模型接收桶大小作为条件，表示为整数元组
car = (htgt, wtgt)，并将其嵌入到傅立叶空间中。</p>
<h3 id="改进自编码器">3.4 改进自编码器</h3>
<p>通过改进自编码器来改善生成图像中的局部细节。文中调整 batch size（256
vs
9）训练自编码器，另外使用指数移动平均值跟踪权重。新的自编码器在所有评估的重建指标中都优于原始模型。</p>
<h3 id="refine-阶段">3.5 Refine 阶段</h3>
<p>右图使用了 Refine
模块，可以看到更多细节，这种方法有效提升了局部细节效果（如背景/人脸细节）。<br />
<img src="/attachments_2023/Pasted%20image%2020230829144636.png" /></p>
<p>具体方法是：在同一潜在空间中训练一个单独的 LDM，该 LDM
专门用于高质量、高分辨率数据，并采用SDEdit 在基础模型的样本上引入
加噪-去噪 过程。在推理时，从基础 SDXL
渲染潜变量，并使用相同的文本输入，通过细化模型直接在潜空间中对它们进行扩散和去噪。其用户评价效果与其它模型对比，如图-1的左侧所示。</p>
<h2 id="限制和展望">4 限制和展望</h2>
<h3 id="展望">4.1 展望</h3>
<ul>
<li>当前模型为两阶段模型，之后倾向于变为单阶段模型。<br />
</li>
<li>文本理解力有待进一步提升。<br />
</li>
<li>结构上，之后更倾向于大规模 Transformer 框架。<br />
</li>
<li>模型增大加大了推理成本，未来将侧重于减少推理所需的计算量。<br />
</li>
<li>目前使用离散时间方法，后将尝试连续时间方法，以提高采样灵活性，并且不需要噪声时间校正。</li>
</ul>
<h3 id="限制">4.2 限制</h3>
<p>（附录 B）<br />
*
模型在​​合成复杂的结构时可能会遇到挑战，例如人手，其原因可能是手类物体出现的差异非常大，模型很难提取真实
3D 形状和物理限制的知识。<br />
*
模型生成的图像没有达到完美的照片真实感。例如微妙的灯光效果或微小的纹理变化。<br />
* 模型由数据训练而成，可能包含一些社会和种族偏见。<br />
*
多个对象或主题下的“概念出血”现象：不同视觉元素的意外合并或重叠。比如“蓝色帽子”和“红色手套”，生成时变成了蓝色手套和红色帽子。这是由于文本编码器无法绑定正确的属性和对象造成的。另外，渲染长文本时也会遇到困难。</p>
<h2 id="实际使用">5 实际使用</h2>
<h3 id="模型下载">5.1 模型下载</h3>
<ul>
<li>文生图:
https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0<br />
</li>
<li>图生图:
https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0</li>
</ul>
<h3 id="速度测试">5.2 速度测试</h3>
<ul>
<li>SDXL 生成一张 512x512图 10-20s 左右</li>
</ul>
<h3 id="其它">5.3 其它</h3>
<ul>
<li>SDXL提示词 https://zhuanlan.zhihu.com/p/646828832<br />
</li>
<li>需要把提示词写得特别清晰，如果不指定风格，常是简笔画风格。<br />
</li>
<li>之前的模型有的模型很有自己的风格，这不是普适的模型能做到的。<br />
</li>
<li>refiner模型：挺喜欢它的细节的，尤其是物体和风景，简直就和相片一样，且有艺术感。<br />
</li>
<li>关键词:
<ul>
<li>加更多细节：a detailed painting</li>
</ul></li>
</ul>
]]></content>
      <tags>
        <tag>图形图像</tag>
        <tag>模型结构</tag>
        <tag>扩散模型</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_模型结构_ControlNet</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/AI%E7%BB%98%E7%94%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84_ControlNet/</url>
    <content><![CDATA[<p>英文名称: Adding Conditional Control to Text-to-Image Diffusion
Models<br />
中文名称: 向文本到图像的扩散模型添加条件控制<br />
论文地址: http://arxiv.org/abs/2302.05543<br />
代码: https://github.com/lllyasviel/ControlNet<br />
时间: 2023-02-10<br />
作者: Lvmin Zhang</p>
<p><img
src="/attachments_2023/Pasted%20image%2020230821182200.png" /></p>
<h2 id="读后感">1 读后感</h2>
<p>ControlNet 几乎是 Stable Diffusion
中最重要的功能插件，利用它可对画面内容进入精准控制。本文介绍了
ControlNet 的原理和具体功能。</p>
<p>ControlNet 是一种对文本生成图像的优化方法。比如：生成 AI
画作时，画面中人体的形态，面部表情都难以精准控制，ControlNet
基于图生图的操作方式，从另一图中提取对应元素，用于新图像的生成，大幅提升了人对大模型的控制力。</p>
<p>具体方法是调整网络结构，基于预训练的扩散模型，根据新输入的描述和指定任务对应的条件进一步训练模型。使模型既可以在小数据量（&lt;50K）时在个人设备上训练，也可以在大数据量时在集群中训练。</p>
<p>其核心技术是在原大网络参数不变的情况下，叠加一个小型网络，以实现最终的调参。</p>
<h3 id="背景知识">1.1 背景知识</h3>
<p>对于文本生成图片的大模型，往往需要考虑以下因素：</p>
<ul>
<li>数据问题：在训练数据量不够大的情况下，解决过拟合/泛化问题。<br />
</li>
<li>资源问题：解决训练时间和内存问题，使模型在个人电脑上也能训练。<br />
</li>
<li>形式问题：支持各种图像处理问题具有不同形式的问题定义、用户控件或图像注释。</li>
</ul>
<h2 id="方法">2 方法</h2>
<p>ControlNet是一种网络结构。如图所示：<br />
<img
src="/attachments_2023/Pasted%20image%2020230821172532.png" /><br />
原始网络结构如图 2-a 所示，输入为x，输出为y，theta为网络参数；<br />
<span class="math display">\[y=F(x;\theta)\]</span><br />
加入了ControlNet的网络如图 2-b
所示，它将大模型的权重复制为“可训练副本”和“锁定副本”：锁定副本用于保留原网络能力，被锁定不参与调参；可训练副本在特定任务的数据集上根据条件c进行训练，以学习有条件控制；网络输出
y 为“可训练副本”和“锁定副本”两部分叠加的结果。</p>
<p>其中还加入了两个"零卷积"层 zero convolution（公式中的
Z），它是1x1且初始值为0的卷积层。<br />
<span class="math display">\[y_c = F(x;\theta)+Z(F(x +
Z(c;\theta_{z1});\theta_c);\theta_{z2})\]</span><br />
可想见，开始调参时，由于Z网络初值是0，y值只有等式左边部分，即保留了原始网络；后面逐步调参后，等式右边部分开始变化。</p>
<p>将该结构应用到扩散模型，如图-3所示：<br />
<img
src="/attachments_2023/Pasted%20image%2020230821173625.png" /><br />
左侧是基础网络，权重被锁定，右侧为 ControlNet 部分，只对其 Encoder
部分进行了调整，使模型训练仅需要增加约 23% 的 GPU 内存和 34%
的时间；同时由于左侧的原始网络参数不变，又使用了零卷积的方法，有效避免了直接在网络上调参带偏网络的问题，同时还可以使
ControlNet 的影响可调节。</p>
<h2 id="其它">3 其它</h2>
<p>文章的 3.5 节及附录部分列出了几种常见的 ControlNet
控制方法，包含：控制人物表情和动作，控制场景深度，控制画面中的线条等，并展示了相应的效果图。可视作功能介绍和效果展示。</p>
]]></content>
      <tags>
        <tag>模型结构</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_模型结构_LoRA</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/AI%E7%BB%98%E7%94%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84_LoRA/</url>
    <content><![CDATA[<p>英文名称: LoRA: Low-Rank Adaptation of Large Language Models<br />
中文名称: LORA：大语言模型的低阶自适应<br />
论文地址: http://arxiv.org/abs/2106.09685<br />
代码: https://github.com/microsoft/LoRA pytorch，风格简捷<br />
时间: 2021-10-16<br />
作者: Edward J. Hu<br />
引用量: 657</p>
<h2 id="读后感">1 读后感</h2>
<p>LoRA 是 Low-Rank
的缩写，它是一种大模型微调技术。一开始用于优化自然语言模型，但是后来自然语言模型后来选择了
Prompt 的道路；而该技术在图像领域得到了广泛的应用，比如 Stable Diffusion
的一众 LoRA 模型，从背景风格到人物形像，不用精调 2-8 G
的基础模型，通过训练 只有几十到几百兆 LoRA 模型，就可以实现建模。</p>
<p>它针对的问题是：当模型大到一定程度，比如 GPT-3 有 175B
参数，精调变得费时而昂贵。其解决方法是：它<strong>修改了fine-tune过程</strong>，提出低阶自适应技术，<strong>冻结了预训练的模型权重，并将可训练的秩分解矩阵注入到
Transformer
架构的每一层中</strong>，这大大减少了下游任务中可训练参数的数量。其的效果是：与使用
Adam 微调的 GPT-3 175B 相比，LoRA 可以将可训练<strong>参数数量减少
10,000 倍，GPU 内存需求减少 3 倍</strong>。且推理时没有额外延迟。</p>
<h2 id="介绍">2 介绍</h2>
<h3 id="感性理解">2.1 感性理解</h3>
<p>先用图像建模举个例子，比如使用 LAION-5B 数据集训练底模，它包含 58.5
亿个 图像-文本对，如果我们在其基础上用 200
张图片精调模型，可以想见，最终模型的大多数参数与底模差异不大；如果也使用与原模型一样大的空间存储是很浪费的，需要保留的只是当前风格和通用风格的差异，信息量并不大。这种情况下，使用
LoRA模型，相当于对两个模型的<strong>差异做降维</strong>后再存储。这种情况下，相对于5G的底模，LoRA
模型可能只有10-20M。</p>
<h3 id="lora-优势">2.2 LoRA 优势</h3>
<p>之前的优化 fine-tune
的方法主要有：只精调部分参数，训练额外层，调节激活函数等，这些方法精调效果往往不是很好，有的还会引起推理延迟。LoRA优势如下：</p>
<ul>
<li>对于一个大模型，可针对不同下游任务训练多个LoRA小模型，方便存储和切换。<br />
</li>
<li>训练效率更高，硬件需求更低，只需要优化注入的小得多的低秩矩阵。<br />
</li>
<li>与完全微调的模型相比，不会引入推理延迟。<br />
</li>
<li>LoRA 与许多现有方法正交，可与其中许多方法相结合。</li>
</ul>
<p>（既不复杂，使用时也没有太多限制条件）</p>
<h2 id="背景知识">3 背景知识</h2>
<h3 id="矩阵的秩-rank">3.1 矩阵的秩 Rank</h3>
<p>矩阵的秩是指矩阵中线性独立的行向量或列向量的最大数量，即矩阵中的最大线性无关行（或列）的数量。对于一个
m 行 n 列的矩阵，它的秩记为r，r 的取值范围是 0 到 min(m, n)。当 r = 0
时，表示该矩阵是一个零矩阵，所有元素都为零。</p>
<h3 id="全秩-full-rank">3.2 全秩 Full-Rank</h3>
<p>当 r = min(m, n)
时，表示矩阵的所有行（或列）都是线性无关的，即全秩（满秩，full-rank）矩阵。</p>
<h3 id="低秩-low-rank">3.3 低秩 Low-Rank</h3>
<p>低秩表示（Low-Rank
Representation，简称LRR）的基本思想是将高维数据表示为低维子空间中的低秩表示。假设数据中的信息可以由较少的关键特征表示。通过将数据表示为低秩矩阵，LRR可以实现降维和去噪的效果，从而提取出数据中的重要特征。</p>
<h2 id="方法">4 方法</h2>
<h3 id="低秩参数矩阵">4.1 低秩参数矩阵</h3>
<p>之前论文《Intrinsic Dimensionality Explains the Effectiveness of
Language Model
Fine-Tuning》证明，预训练的语言模型具有较低的“内在维度”（实际不需要那么大维度），即使随机投影到较小的子空间，仍可有效学习。我们假设权重的更新
fine-tune 也具有较低的“内在维度”。</p>
<p>将预训练的权重矩阵定义为W0，其维度为 d×k，通过用低秩分解 W0 + ΔW = W0
+ BA 用后者来约束其更新，其中 B 为 d×r 维，A 为 r×k 维，并且秩 r
&lt;&lt; min(d, k)。训练期间，W0 被冻结，不更新，而 A 和 B
包含可训练参数。W0 和 ΔW = BA
都与相同的输入相乘，并且它们各自的输出向量按维度求和。<br />
<span class="math display">\[h = W_0x + ∆W x = W_0x + BAx\]</span><br />
<img src="/attachments_2023/Pasted%20image%2020230825092614.png"
alt="|250" /><br />
对 A 使用随机高斯初始化，对 B 使用零初始化，因此 ΔW = BA
在训练开始时为零。然后按 α/r 缩放 ΔW x ，其中 α 是 r 中的常数，调整 α
与调整学习率大致相同。</p>
<p>这里的 r 需要设置，如果 r 与 d 维度相同，即降维时，理论上其效果和
fine-tune 一致，而具体 r 如何设置详见对比实验部分。</p>
<h3 id="将-lora-应用于-transformer-框架">4.2 将 LORA 应用于 Transformer
框架</h3>
<p>从原理来看，LoRA 可用于任何神经网络中。在 Transformer
架构中，自注意力模块中有四个权重矩阵（Wq、Wk、Wv、Wo），MLP
模块中有两个。研究限制为仅调整下游任务的注意力权重，并冻结 MLP
模块。后面的对比实验针对这四个矩阵做了 LoRA 测试。</p>
<p>这样做最显著的好处是减少内存和存储量。对于使用 Adam 训练的大型
Transformer，如果使用 r &lt;&lt; d 的模型，可以将 VRAM 使用量减少多达
2/3。在 GPT-3 175B 上，可将训练期间的 VRAM 消耗从 1.2TB 减少到 350GB。当
r = 4 并且仅调整查询和值投影矩阵时，检查点大小减少了大约 10,000倍（从
350GB 到 35MB）。</p>
<p>RoLA 还允许支持定制多个模型，这些模型可在预训练权重存储在 VRAM
中的机器上动态地换入换出。与完全微调相比，由于不需要计算绝大多数参数的梯度，GPT-3
175B 训练期间的速度提高了 25%。</p>
<h2 id="实验">5 实验</h2>
<p>实验部分分别对 RoBERTa，GPT-2，GPT-3
做了针对下游任务的对比实验，从实验部分可以看到，LoRA模型参数非常少，且效果往往不低于fine-tune，有时效果更好。<br />
<img src="/attachments_2023/Pasted%20image%2020230825104121.png" /></p>
<h2 id="对比实验">6 对比实验</h2>
<h3 id="在-transformer-中的哪些权重矩阵上应用-lora">6.1 在 Transformer
中的哪些权重矩阵上应用 LORA</h3>
<p>文中实验限定了参数整体大小，针对不同的 LoRA
设置，对比模型性能。这里只考虑了自注意力中的权重矩阵，如果使用 1
种类型的注意力权重，则 r = 8；如果使用 2 种类型，则对应于 r =
4，结果如表 5 所示：<br />
<img
src="/attachments_2023/Pasted%20image%2020230825112811.png" /><br />
实验证明 Wq,Wv 组合可提供最佳性能，4 阶也能捕获足够的 ΔW
信息，因此适应更多的权重矩阵比适应具有更大阶数的单一类型权重效果更好。</p>
<h3 id="最佳-rank-的大小是多少">6.2 最佳 rank 的大小是多少</h3>
<p>实验对比了不同秩大小的模型效果，可以看到，r=1 时 Wq，Wv
就可以满足一定效果，而单独调节 Wq 需要更大的 r。这说明 ΔW
只需要很低的秩（另外两个实验也验证了数据的低秩性质）。<br />
<img src="/attachments_2023/Pasted%20image%2020230825113213.png" /></p>
<h3 id="δw-与-w-对比">6.3 ΔW 与 W 对比</h3>
<p>观察 ∆W 与 W 的相关性，具体方法是将 W 映射到 ∆W 的 r
维子空间中，然后用 Frobenius 范数，对比其一致性。<br />
<img
src="/attachments_2023/Pasted%20image%2020230825115307.png" /><br />
实验得出结论：与随机矩阵相比，ΔW 与 W 具有更强的相关性；ΔW 不重复 W
的顶部奇异方向，而是仅放大 W 中未强调的方向；放大系数相当大：r = 4 时为
21.5 ≈
6.91/0.32。这表明低秩适应矩阵可能会<strong>放大特定下游任务的重要特征，这些特征是在一般预训练模型中学习但未强调的</strong>。</p>
<h2 id="实用技巧">7 实用技巧</h2>
<h3 id="lora-与-基础模型">7.1 LoRA 与 基础模型</h3>
<p>根据 LoRA
原理可知，LoRA保存的是精调与基础模型（底模）差异的降维数据，所以 LoRA
与训练它的底模强相关，一般 LoRA
描述中也有对其底模的说明，一般情况下，至少二者的
2D/现实风格需要一致。<br />
当然也有像 “Detail Tweaker LoRA” 这样不挑底模的 LoRA。</p>
<h3 id="lora-权重">7.2 LoRA 权重</h3>
<p>在引用 LoRA 时，可在 Prompt 中指定 LoRA 权重，一般默认为 1，虽然 SD
是基于 LDM 技术，理论上，其特征是连续的，可微调的，但是将 LoRA
设得太大，结果往往也是反常识的。</p>
<h3 id="多个-lora-叠加">7.3 多个 LoRA 叠加</h3>
<p>操作时可以叠加使用多个 LoRA。实际使用时，尽量叠加不同类型的
LoRA，比如一个增加画面细节，另一个修改背景风格，它们调整的往往不是一组权重，问题不大；但是不建议叠加同一类型的
LoRA，在同一组权重上反复计算，效果往往不可控。</p>
]]></content>
      <tags>
        <tag>模型结构</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_生成模型_VAE</title>
    <url>/1_Note/2_%E7%AE%97%E6%B3%95/8_%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F/AI%E7%BB%98%E7%94%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B_VAE/</url>
    <content><![CDATA[<p>英文名称: Auto-Encoding Variational Bayes<br>
中文名称: 自编码变分贝叶斯<br>
论文地址: http://arxiv.org/abs/1312.6114<br>
时间: 2013<br>
作者: Diederik P. Kingma, 阿姆斯特丹大学<br>
引用量: 24840</p>
<h2 id="读后感">1 读后感</h2>
<p>VAE 变分自编码（Variational
Autoencoder）是一种<strong>生成模型</strong>，它结合了自编码器和概率图模型的思想。它的目标是：解决对复杂性高，且量大的数据难以拟合的问题。具体方法是：使用基于变分推理的原理，以变分下界作为目标函数，用梯度方法求取模型参数。</p>
<h2 id="通俗理解">2 通俗理解</h2>
<p><img src="/attachments_2023/Pasted%20image%2020230901142322.png"><br>
听起来非常抽象，简单地说：变分自编码器是自编码器的改进版。</p>
<h3 id="自编码器">2.1 自编码器</h3>
<p>自编码器通常由编码器和解码器两部分组成，其中编码器将原始数据映射到低维表示，解码器则将低维表示映射回原始数据空间。即：原始数据为x，将其输入编码器降维后，变成数据z，再经过编码器还原成数据
x'。它常用于<strong>高维数据的低维表示</strong>和<strong>从低维表示中生成高维数据</strong>。比如：图像去噪，修复图片，生成高分辨率图片等。</p>
<h3 id="变分自编码器">2.2 变分自编码器</h3>
<p>变分自编码器在中间加了一层逻辑，它假设中间过程的数据 z
每个维度都是正态分布的，可以使用：均值 μ 和 方差 σ
表示。由此，就变成了变分自编码器：训练编码器和解码器网络，可将图片x分布压缩后再拆分成多个高斯分布的叠加，如上图所示。</p>
<h2 id="相关概念">3 相关概念</h2>
<h3 id="为什么用高斯分布">3.1 为什么用高斯分布</h3>
<p>使用高斯分布的原因是：每张训练图片的内容都不一样，训练过程中产生的潜空间z也是离散的，不能确定它的分布。比如数据有满月和半月，但无法产生2/3月亮。而高斯分布是连续的，如果能把中间的表征z用正态分布描述，它就是平滑的，理论上就可以产生介于两图之间的内容图片，它具有一定的潜在空间的连续性和插值性质。</p>
<h3 id="高斯混合模型-gmm">3.2 高斯混合模型 GMM</h3>
<p><img src="/attachments_2023/Pasted%20image%2020230824114606.png" alt="|400"><br>
可以想见，z的分布相当复杂，不是一个简单的高斯分布可以描述的。图中红色为分布曲线。它可分解为一系列不同频率、不同振幅、不同相位的正弦波。也就是说可以用多个正态分布（高斯分布）的叠加去逼近任意一个分布。可以说
VAE 是对 GMM 方法的改进版。</p>
<h3 id="kl散度">3.3 KL散度</h3>
<p>用于衡量两个分布之间的距离。</p>
<h3 id="最大似然估计">3.4 最大似然估计</h3>
<p>似然与概率类似，但有如下区别：给定一个函数P(x|θ)，x是样本点，θ
是参数。<br>
（1）当 θ 为常量， x为变量时，称 P 为关于 x 的概率函数；<br>
（2）当 x 为常量， θ 为变量时，称 P 为关于 θ 的似然函数；<br>
求解最大似然是指：求使得样本点 x 能够以最大概率发生的 θ 的取值。</p>
<h3 id="变分推断">3.5 变分推断</h3>
<p><strong>变分</strong> Variational
是通过引入一个简化的参数化分布来近似复杂的后验分布。这个参数化分布被称为<strong>变分分布</strong>，它属于一种可计算的分布族。通过调整变分分布的参数，使其尽可能接近真实的后验分布，从而实现近似推断。</p>
<h3 id="变分下界">3.6 变分下界</h3>
<p><strong>变分下界</strong>（variational lower
bound）通常用于衡量变分分布与真实后验分布之间的差异。<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="32.418ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 14328.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mi" transform="translate(764,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(1445,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mi" transform="translate(2204,0)"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"></path></g><g data-mml-node="mo" transform="translate(3244.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(4300.6,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mo" transform="translate(5064.6,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mi" transform="translate(5342.6,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(5640.6,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(6125.6,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mtext" transform="translate(6602.6,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mi" transform="translate(6852.6,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mo" transform="translate(7355.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(7744.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(8316.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(8761.2,0)"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mo" transform="translate(9226.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(9837.4,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(10837.7,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(11135.7,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(11620.7,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mtext" transform="translate(12097.7,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mi" transform="translate(12347.7,0)"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(12807.7,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(13196.7,0)"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mo" transform="translate(13661.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(14050.7,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container></span><br>
其中，ELBO 代表变分下界（Evidence Lower
BOund），x代表观测数据，z代表未知变量，p(x,
z)表示真实的联合分布，q(z)表示变分分布。</p>
<h3 id="代入本文中场景">3.7 代入本文中场景</h3>
<p>有一张图 x（后验分布），想把它映射成 z，假设 z
是混合高斯分布(先验分布)，各维可能描述颜色，材质……，用函数函数 g() 把 x
分解成高斯分布，它的逆过程是用 f() 根据高斯分布还原原始图 x‘
，最终恢复的图片 x'=f(g(x))，目标是想让 x'-x 值尽量小，就是说：图 x
转成潜空间 z 再转回原始图 x'，图像最好没变化。<br>
综上所述，无论x是什么，通过变换，产生的x'都与x很像，中间过程的 z
还能用高斯参数表示，求这样的函数f和g的神经网络。</p>
<h3 id="蒙特卡洛估计">3.8 蒙特卡洛估计</h3>
<p>蒙特卡洛估计（Monte Carlo
estimation）是一种基于随机抽样的统计估计方法，用于计算复杂问题的数值近似解。其基本思想是通过生成大量的随机样本，利用这些样本的统计特性来估计问题的解。</p>
<h2 id="方法">4 方法</h2>
<p>（以下图和公式中的变量含义重新开始定义，不要与上面混淆）<br>
<img src="/attachments_2023/Pasted%20image%2020230824135723.png" alt="300"><br>
先看一下论文主图，N是数据集，x是真实空间（可观察），z是潜空间（不可观察的连续空间）；实线表示生成模型
pθ(z)pθ(x|z)，虚线表示p的变分近似
qφ(z|x)（也称识别模型），文中使用的方法是用 qφ(z|x) 模拟难以计算的
pθ(z|x)，变分参数 φ 与生成模型参数 θ
一起学习。这里的q可视为编码器，而p视为解码器。</p>
<h3 id="变分边界">4.1 变分边界</h3>
<p>边界似然（Marginal
Likelihood）是各观测数据点（每张图片）在给定模型下的概率之和（原图的概率），值越大模型越好，它描述的是图像重建的好不好（重建损失）。<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.819ex;" xmlns="http://www.w3.org/2000/svg" width="37.023ex" height="6.74ex" role="img" focusable="false" viewBox="0 -1733 16364.1 2978.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(298,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(783,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mtext" transform="translate(1260,0)"><path data-c="A0" d=""></path></g><g data-mml-node="msub" transform="translate(1510,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="mo" transform="translate(2427.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msup" transform="translate(2816.6,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(389,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(889,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4375.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(4820,0)"><path data-c="B7" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mo" transform="translate(5320.2,0)"><path data-c="B7" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mo" transform="translate(5820.4,0)"><path data-c="B7" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mo" transform="translate(6098.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(6543.1,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mo" transform="translate(1277,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(8376.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(9042.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="munderover" transform="translate(10098.7,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(148.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(408,1150) scale(0.707)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g><g data-mml-node="mi" transform="translate(11709.4,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(12007.4,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(12492.4,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mtext" transform="translate(12969.4,0)"><path data-c="A0" d=""></path></g><g data-mml-node="msub" transform="translate(13219.4,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="mo" transform="translate(14137,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msup" transform="translate(14526,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(15975.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span><br>
各数据点的概率：<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.688ex;" xmlns="http://www.w3.org/2000/svg" width="53.094ex" height="2.822ex" role="img" focusable="false" viewBox="0 -943.3 23467.5 1247.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(298,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(783,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mtext" transform="translate(1260,0)"><path data-c="A0" d=""></path></g><g data-mml-node="msub" transform="translate(1510,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="mo" transform="translate(2427.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2816.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(3388.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(3777.6,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4122.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4511.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5178.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(6234.2,0)"><g data-mml-node="mi"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g><g data-mml-node="TeXAtom" transform="translate(861,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(889,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g></g><g data-mml-node="mo" transform="translate(8255.3,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(8644.3,0)"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D711" d="M92 210Q92 176 106 149T142 108T185 85T220 72L235 70L237 71L250 112Q268 170 283 211T322 299T370 375T429 423T502 442Q547 442 582 410T618 302Q618 224 575 152T457 35T299 -10Q273 -10 273 -12L266 -48Q260 -83 252 -125T241 -179Q236 -203 215 -212Q204 -218 190 -218Q159 -215 159 -185Q159 -175 214 -2L209 0Q204 2 195 5T173 14T147 28T120 46T94 71T71 103T56 142T50 190Q50 238 76 311T149 431H162Q183 431 183 423Q183 417 175 409Q134 361 114 300T92 210ZM574 278Q574 320 550 344T486 369Q437 369 394 329T323 218Q309 184 295 109L286 64Q304 62 306 62Q423 62 498 131T574 278Z"></path></g></g><g data-mml-node="mo" transform="translate(9635.8,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(10024.8,0)"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mo" transform="translate(10489.8,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msup" transform="translate(10767.8,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(12216.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(12605.9,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mo" transform="translate(12883.9,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msub" transform="translate(13161.9,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="mo" transform="translate(14079.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(14468.5,0)"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mo" transform="translate(14933.5,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msup" transform="translate(15211.5,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(1123,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(16935.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(17546.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(18547.1,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(19228.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(19617.1,0)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mo" transform="translate(20086.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(20530.8,0)"><path data-c="1D711" d="M92 210Q92 176 106 149T142 108T185 85T220 72L235 70L237 71L250 112Q268 170 283 211T322 299T370 375T429 423T502 442Q547 442 582 410T618 302Q618 224 575 152T457 35T299 -10Q273 -10 273 -12L266 -48Q260 -83 252 -125T241 -179Q236 -203 215 -212Q204 -218 190 -218Q159 -215 159 -185Q159 -175 214 -2L209 0Q204 2 195 5T173 14T147 28T120 46T94 71T71 103T56 142T50 190Q50 238 76 311T149 431H162Q183 431 183 423Q183 417 175 409Q134 361 114 300T92 210ZM574 278Q574 320 550 344T486 369Q437 369 394 329T323 218Q309 184 295 109L286 64Q304 62 306 62Q423 62 498 131T574 278Z"></path></g><g data-mml-node="mo" transform="translate(21184.8,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="msup" transform="translate(21629.4,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(23078.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span><br>
前半部分 DKL 是z的模拟值和真实后验的 KL 散度，KL 散度一定大于0，后半部分
L 是变分下界（建模的目标）：<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.469ex;" xmlns="http://www.w3.org/2000/svg" width="66.788ex" height="4.07ex" role="img" focusable="false" viewBox="0 -1149.5 29520.5 1799"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(1278,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(1444.7,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(536,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D73D" d="M213 -8Q130 -8 85 50T40 200V207Q40 303 83 428Q122 535 189 608Q279 702 381 702Q410 702 437 693T492 661T537 593T554 486Q554 428 539 362T495 230T425 111T330 25T213 -8ZM433 562Q433 600 419 625T377 651Q363 651 348 644T311 619T268 557T229 453Q225 441 217 411T208 378H401Q433 500 433 562ZM161 140Q161 43 217 43Q249 43 280 74Q310 103 332 150T378 287Q385 313 385 315Q385 316 289 316H192Q191 308 183 275T169 205T161 140Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(2594.7,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M180 96T180 250T205 541T266 770T353 944T444 1069T527 1150H555Q561 1144 561 1141Q561 1137 545 1120T504 1072T447 995T386 878T330 721T288 513T272 251Q272 133 280 56Q293 -87 326 -209T399 -405T475 -531T536 -609T561 -640Q561 -643 555 -649H527Q483 -612 443 -568T353 -443T266 -270T205 -41Z"></path></g><g data-mml-node="msup" transform="translate(597,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2081.1,0) translate(0 -0.5)"><path data-c="29" d="M35 1138Q35 1150 51 1150H56H69Q113 1113 153 1069T243 944T330 771T391 541T416 250T391 -40T330 -270T243 -443T152 -568T69 -649H56Q43 -649 39 -647T35 -637Q65 -607 110 -548Q283 -316 316 56Q324 133 324 251Q324 368 316 445Q278 877 48 1123Q36 1137 35 1138Z"></path></g></g><g data-mml-node="mo" transform="translate(5550.6,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(6606.4,0)"><g data-mml-node="mi"><path data-c="4C" d="M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z"></path></g></g><g data-mml-node="mrow" transform="translate(7463,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M180 96T180 250T205 541T266 770T353 944T444 1069T527 1150H555Q561 1144 561 1141Q561 1137 545 1120T504 1072T447 995T386 878T330 721T288 513T272 251Q272 133 280 56Q293 -87 326 -209T399 -405T475 -531T536 -609T561 -640Q561 -643 555 -649H527Q483 -612 443 -568T353 -443T266 -270T205 -41Z"></path></g><g data-mml-node="mi" transform="translate(597,0)"><path data-c="1D73D" d="M213 -8Q130 -8 85 50T40 200V207Q40 303 83 428Q122 535 189 608Q279 702 381 702Q410 702 437 693T492 661T537 593T554 486Q554 428 539 362T495 230T425 111T330 25T213 -8ZM433 562Q433 600 419 625T377 651Q363 651 348 644T311 619T268 557T229 453Q225 441 217 411T208 378H401Q433 500 433 562ZM161 140Q161 43 217 43Q249 43 280 74Q310 103 332 150T378 287Q385 313 385 315Q385 316 289 316H192Q191 308 183 275T169 205T161 140Z"></path></g><g data-mml-node="mo" transform="translate(1159,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1603.7,0)"><path data-c="1D753" d="M274 -7Q232 -4 195 7T125 38T71 94T51 176V190Q51 213 60 242T95 307T156 373T255 425T393 451L397 452L427 568Q434 597 443 636Q452 677 456 685T472 694H486H495Q517 694 517 680L514 665Q510 650 503 621T489 564L460 451H469Q527 447 574 430T657 370T693 266Q693 163 599 82T350 -7H346L322 -100Q301 -190 295 -197Q291 -202 283 -202H269H258Q238 -202 238 -188Q238 -186 260 -96L283 -7H274ZM449 400Q448 400 404 225T359 47T366 45Q464 55 516 119Q542 149 558 199T575 295Q575 387 462 398L449 400ZM384 398Q384 399 381 399Q350 399 298 378T214 308Q168 236 168 149Q168 68 259 49Q282 44 294 44H295L384 398Z"></path></g><g data-mml-node="mo" transform="translate(2315.7,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="msup" transform="translate(2760.3,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4244.4,0) translate(0 -0.5)"><path data-c="29" d="M35 1138Q35 1150 51 1150H56H69Q113 1113 153 1069T243 944T330 771T391 541T416 250T391 -40T330 -270T243 -443T152 -568T69 -649H56Q43 -649 39 -647T35 -637Q65 -607 110 -548Q283 -316 316 56Q324 133 324 251Q324 368 316 445Q278 877 48 1123Q36 1137 35 1138Z"></path></g></g><g data-mml-node="mo" transform="translate(12582.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(13638,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D53C" d="M12 666Q12 675 24 683H582Q590 680 593 672V588Q593 514 591 502T575 490Q567 490 563 495T555 517Q552 556 517 590Q486 623 445 634T340 648H282Q266 636 264 620T260 492V370H277Q329 375 358 391T404 439Q420 480 420 506Q420 529 436 529Q445 529 451 521Q455 517 455 361Q455 333 455 298T456 253Q456 217 453 207T437 197Q420 196 420 217Q420 240 406 270Q377 328 284 335H260V201Q261 174 261 134Q262 73 264 61T278 38Q281 36 282 35H331Q400 35 449 50Q571 93 602 179Q605 203 622 203Q629 203 634 197T640 183Q638 181 624 95T604 3L600 -1H24Q12 5 12 16Q12 35 51 35Q92 38 97 52Q102 60 102 341T97 632Q91 645 51 648Q12 648 12 666ZM137 341Q137 131 136 89T130 37Q129 36 129 35H235Q233 41 231 48L226 61V623L231 635L235 648H129Q132 641 133 638T135 603T137 517T137 341ZM557 603V648H504Q504 646 515 639Q527 634 542 619L557 603ZM420 317V397L406 383Q394 370 380 363L366 355Q373 350 382 346Q400 333 409 328L420 317ZM582 61L586 88Q585 88 582 83Q557 61 526 46L511 37L542 35H577Q577 36 578 39T580 49T582 61Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(700,-176.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(479,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D753" d="M274 -7Q232 -4 195 7T125 38T71 94T51 176V190Q51 213 60 242T95 307T156 373T255 425T393 451L397 452L427 568Q434 597 443 636Q452 677 456 685T472 694H486H495Q517 694 517 680L514 665Q510 650 503 621T489 564L460 451H469Q527 447 574 430T657 370T693 266Q693 163 599 82T350 -7H346L322 -100Q301 -190 295 -197Q291 -202 283 -202H269H258Q238 -202 238 -188Q238 -186 260 -96L283 -7H274ZM449 400Q448 400 404 225T359 47T366 45Q464 55 516 119Q542 149 558 199T575 295Q575 387 462 398L449 400ZM384 398Q384 399 381 399Q350 399 298 378T214 308Q168 236 168 149Q168 68 259 49Q282 44 294 44H295L384 398Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1032.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(1421.5,0)"><g data-mml-node="mi"><path data-c="1D433" d="M48 262Q48 264 54 349T60 436V444H252Q289 444 336 444T394 445Q441 445 450 441T459 418Q459 406 458 404Q456 399 327 229T194 55H237Q260 56 268 56T297 58T325 65T348 77T370 98T384 128T395 170Q400 197 400 216Q400 217 431 217H462V211Q461 208 453 108T444 6V0H245Q46 0 43 2Q32 7 32 28V33Q32 41 40 52T84 112Q129 170 164 217L298 393H256Q189 392 165 380Q124 360 115 303Q110 280 110 256Q110 254 79 254H48V262Z"></path></g></g><g data-mml-node="mo" transform="translate(1932.5,0)"><path data-c="2223" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(2210.5,0)"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="mo" transform="translate(2817.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(16822,0)"><g data-mml-node="mo"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mo" transform="translate(278,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(1222.7,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(2500.7,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(2667.3,0)"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(479,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D753" d="M274 -7Q232 -4 195 7T125 38T71 94T51 176V190Q51 213 60 242T95 307T156 373T255 425T393 451L397 452L427 568Q434 597 443 636Q452 677 456 685T472 694H486H495Q517 694 517 680L514 665Q510 650 503 621T489 564L460 451H469Q527 447 574 430T657 370T693 266Q693 163 599 82T350 -7H346L322 -100Q301 -190 295 -197Q291 -202 283 -202H269H258Q238 -202 238 -188Q238 -186 260 -96L283 -7H274ZM449 400Q448 400 404 225T359 47T366 45Q464 55 516 119Q542 149 558 199T575 295Q575 387 462 398L449 400ZM384 398Q384 399 381 399Q350 399 298 378T214 308Q168 236 168 149Q168 68 259 49Q282 44 294 44H295L384 398Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3699.8,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4088.8,0)"><g data-mml-node="mi"><path data-c="1D433" d="M48 262Q48 264 54 349T60 436V444H252Q289 444 336 444T394 445Q441 445 450 441T459 418Q459 406 458 404Q456 399 327 229T194 55H237Q260 56 268 56T297 58T325 65T348 77T370 98T384 128T395 170Q400 197 400 216Q400 217 431 217H462V211Q461 208 453 108T444 6V0H245Q46 0 43 2Q32 7 32 28V33Q32 41 40 52T84 112Q129 170 164 217L298 393H256Q189 392 165 380Q124 360 115 303Q110 280 110 256Q110 254 79 254H48V262Z"></path></g></g><g data-mml-node="mo" transform="translate(4877.6,0)"><path data-c="2223" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(5433.3,0)"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="mo" transform="translate(6040.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(6651.6,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(7651.8,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(8929.8,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(9096.5,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(536,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D73D" d="M213 -8Q130 -8 85 50T40 200V207Q40 303 83 428Q122 535 189 608Q279 702 381 702Q410 702 437 693T492 661T537 593T554 486Q554 428 539 362T495 230T425 111T330 25T213 -8ZM433 562Q433 600 419 625T377 651Q363 651 348 644T311 619T268 557T229 453Q225 441 217 411T208 378H401Q433 500 433 562ZM161 140Q161 43 217 43Q249 43 280 74Q310 103 332 150T378 287Q385 313 385 315Q385 316 289 316H192Q191 308 183 275T169 205T161 140Z"></path></g></g></g><g data-mml-node="mo" transform="translate(10079.9,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(10468.9,0)"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="mo" transform="translate(11075.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(11520.5,0)"><g data-mml-node="mi"><path data-c="1D433" d="M48 262Q48 264 54 349T60 436V444H252Q289 444 336 444T394 445Q441 445 450 441T459 418Q459 406 458 404Q456 399 327 229T194 55H237Q260 56 268 56T297 58T325 65T348 77T370 98T384 128T395 170Q400 197 400 216Q400 217 431 217H462V211Q461 208 453 108T444 6V0H245Q46 0 43 2Q32 7 32 28V33Q32 41 40 52T84 112Q129 170 164 217L298 393H256Q189 392 165 380Q124 360 115 303Q110 280 110 256Q110 254 79 254H48V262Z"></path></g></g><g data-mml-node="mo" transform="translate(12031.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(12420.5,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></g></svg></mjx-container></span><br>
这里的E是期望，右测是变分下界 ELBO 的公式。<br>
通过移项得到了变分下界的目标函数，公式如下：<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.469ex;" xmlns="http://www.w3.org/2000/svg" width="72.107ex" height="4.07ex" role="img" focusable="false" viewBox="0 -1149.5 31871.2 1799"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="4C" d="M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z"></path></g></g><g data-mml-node="mrow" transform="translate(856.7,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M180 96T180 250T205 541T266 770T353 944T444 1069T527 1150H555Q561 1144 561 1141Q561 1137 545 1120T504 1072T447 995T386 878T330 721T288 513T272 251Q272 133 280 56Q293 -87 326 -209T399 -405T475 -531T536 -609T561 -640Q561 -643 555 -649H527Q483 -612 443 -568T353 -443T266 -270T205 -41Z"></path></g><g data-mml-node="mi" transform="translate(597,0)"><path data-c="1D73D" d="M213 -8Q130 -8 85 50T40 200V207Q40 303 83 428Q122 535 189 608Q279 702 381 702Q410 702 437 693T492 661T537 593T554 486Q554 428 539 362T495 230T425 111T330 25T213 -8ZM433 562Q433 600 419 625T377 651Q363 651 348 644T311 619T268 557T229 453Q225 441 217 411T208 378H401Q433 500 433 562ZM161 140Q161 43 217 43Q249 43 280 74Q310 103 332 150T378 287Q385 313 385 315Q385 316 289 316H192Q191 308 183 275T169 205T161 140Z"></path></g><g data-mml-node="mo" transform="translate(1159,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1603.7,0)"><path data-c="1D753" d="M274 -7Q232 -4 195 7T125 38T71 94T51 176V190Q51 213 60 242T95 307T156 373T255 425T393 451L397 452L427 568Q434 597 443 636Q452 677 456 685T472 694H486H495Q517 694 517 680L514 665Q510 650 503 621T489 564L460 451H469Q527 447 574 430T657 370T693 266Q693 163 599 82T350 -7H346L322 -100Q301 -190 295 -197Q291 -202 283 -202H269H258Q238 -202 238 -188Q238 -186 260 -96L283 -7H274ZM449 400Q448 400 404 225T359 47T366 45Q464 55 516 119Q542 149 558 199T575 295Q575 387 462 398L449 400ZM384 398Q384 399 381 399Q350 399 298 378T214 308Q168 236 168 149Q168 68 259 49Q282 44 294 44H295L384 398Z"></path></g><g data-mml-node="mo" transform="translate(2315.7,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="msup" transform="translate(2760.3,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4244.4,0) translate(0 -0.5)"><path data-c="29" d="M35 1138Q35 1150 51 1150H56H69Q113 1113 153 1069T243 944T330 771T391 541T416 250T391 -40T330 -270T243 -443T152 -568T69 -649H56Q43 -649 39 -647T35 -637Q65 -607 110 -548Q283 -316 316 56Q324 133 324 251Q324 368 316 445Q278 877 48 1123Q36 1137 35 1138Z"></path></g></g><g data-mml-node="mo" transform="translate(5975.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(7031.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(7809.6,0)"><g data-mml-node="mi"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g><g data-mml-node="TeXAtom" transform="translate(861,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(889,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(9997.5,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M180 96T180 250T205 541T266 770T353 944T444 1069T527 1150H555Q561 1144 561 1141Q561 1137 545 1120T504 1072T447 995T386 878T330 721T288 513T272 251Q272 133 280 56Q293 -87 326 -209T399 -405T475 -531T536 -609T561 -640Q561 -643 555 -649H527Q483 -612 443 -568T353 -443T266 -270T205 -41Z"></path></g><g data-mml-node="msub" transform="translate(597,0)"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(479,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D753" d="M274 -7Q232 -4 195 7T125 38T71 94T51 176V190Q51 213 60 242T95 307T156 373T255 425T393 451L397 452L427 568Q434 597 443 636Q452 677 456 685T472 694H486H495Q517 694 517 680L514 665Q510 650 503 621T489 564L460 451H469Q527 447 574 430T657 370T693 266Q693 163 599 82T350 -7H346L322 -100Q301 -190 295 -197Q291 -202 283 -202H269H258Q238 -202 238 -188Q238 -186 260 -96L283 -7H274ZM449 400Q448 400 404 225T359 47T366 45Q464 55 516 119Q542 149 558 199T575 295Q575 387 462 398L449 400ZM384 398Q384 399 381 399Q350 399 298 378T214 308Q168 236 168 149Q168 68 259 49Q282 44 294 44H295L384 398Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(1796.1,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M180 96T180 250T205 541T266 770T353 944T444 1069T527 1150H555Q561 1144 561 1141Q561 1137 545 1120T504 1072T447 995T386 878T330 721T288 513T272 251Q272 133 280 56Q293 -87 326 -209T399 -405T475 -531T536 -609T561 -640Q561 -643 555 -649H527Q483 -612 443 -568T353 -443T266 -270T205 -41Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(597,0)"><g data-mml-node="mi"><path data-c="1D433" d="M48 262Q48 264 54 349T60 436V444H252Q289 444 336 444T394 445Q441 445 450 441T459 418Q459 406 458 404Q456 399 327 229T194 55H237Q260 56 268 56T297 58T325 65T348 77T370 98T384 128T395 170Q400 197 400 216Q400 217 431 217H462V211Q461 208 453 108T444 6V0H245Q46 0 43 2Q32 7 32 28V33Q32 41 40 52T84 112Q129 170 164 217L298 393H256Q189 392 165 380Q124 360 115 303Q110 280 110 256Q110 254 79 254H48V262Z"></path></g></g><g data-mml-node="mo" transform="translate(1385.8,0)"><path data-c="2223" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msup" transform="translate(1941.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3425.6,0) translate(0 -0.5)"><path data-c="29" d="M35 1138Q35 1150 51 1150H56H69Q113 1113 153 1069T243 944T330 771T391 541T416 250T391 -40T330 -270T243 -443T152 -568T69 -649H56Q43 -649 39 -647T35 -637Q65 -607 110 -548Q283 -316 316 56Q324 133 324 251Q324 368 316 445Q278 877 48 1123Q36 1137 35 1138Z"></path></g></g><g data-mml-node="mo" transform="translate(5818.8,0)"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g><g data-mml-node="msub" transform="translate(6318.8,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(536,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D73D" d="M213 -8Q130 -8 85 50T40 200V207Q40 303 83 428Q122 535 189 608Q279 702 381 702Q410 702 437 693T492 661T537 593T554 486Q554 428 539 362T495 230T425 111T330 25T213 -8ZM433 562Q433 600 419 625T377 651Q363 651 348 644T311 619T268 557T229 453Q225 441 217 411T208 378H401Q433 500 433 562ZM161 140Q161 43 217 43Q249 43 280 74Q310 103 332 150T378 287Q385 313 385 315Q385 316 289 316H192Q191 308 183 275T169 205T161 140Z"></path></g></g></g><g data-mml-node="mo" transform="translate(7302.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(7691.2,0)"><g data-mml-node="mi"><path data-c="1D433" d="M48 262Q48 264 54 349T60 436V444H252Q289 444 336 444T394 445Q441 445 450 441T459 418Q459 406 458 404Q456 399 327 229T194 55H237Q260 56 268 56T297 58T325 65T348 77T370 98T384 128T395 170Q400 197 400 216Q400 217 431 217H462V211Q461 208 453 108T444 6V0H245Q46 0 43 2Q32 7 32 28V33Q32 41 40 52T84 112Q129 170 164 217L298 393H256Q189 392 165 380Q124 360 115 303Q110 280 110 256Q110 254 79 254H48V262Z"></path></g></g><g data-mml-node="mo" transform="translate(8202.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(8591.2,0) translate(0 -0.5)"><path data-c="29" d="M35 1138Q35 1150 51 1150H56H69Q113 1113 153 1069T243 944T330 771T391 541T416 250T391 -40T330 -270T243 -443T152 -568T69 -649H56Q43 -649 39 -647T35 -637Q65 -607 110 -548Q283 -316 316 56Q324 133 324 251Q324 368 316 445Q278 877 48 1123Q36 1137 35 1138Z"></path></g></g><g data-mml-node="mo" transform="translate(19407.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(20408.1,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D53C" d="M12 666Q12 675 24 683H582Q590 680 593 672V588Q593 514 591 502T575 490Q567 490 563 495T555 517Q552 556 517 590Q486 623 445 634T340 648H282Q266 636 264 620T260 492V370H277Q329 375 358 391T404 439Q420 480 420 506Q420 529 436 529Q445 529 451 521Q455 517 455 361Q455 333 455 298T456 253Q456 217 453 207T437 197Q420 196 420 217Q420 240 406 270Q377 328 284 335H260V201Q261 174 261 134Q262 73 264 61T278 38Q281 36 282 35H331Q400 35 449 50Q571 93 602 179Q605 203 622 203Q629 203 634 197T640 183Q638 181 624 95T604 3L600 -1H24Q12 5 12 16Q12 35 51 35Q92 38 97 52Q102 60 102 341T97 632Q91 645 51 648Q12 648 12 666ZM137 341Q137 131 136 89T130 37Q129 36 129 35H235Q233 41 231 48L226 61V623L231 635L235 648H129Q132 641 133 638T135 603T137 517T137 341ZM557 603V648H504Q504 646 515 639Q527 634 542 619L557 603ZM420 317V397L406 383Q394 370 380 363L366 355Q373 350 382 346Q400 333 409 328L420 317ZM582 61L586 88Q585 88 582 83Q557 61 526 46L511 37L542 35H577Q577 36 578 39T580 49T582 61Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(700,-247.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(479,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D753" d="M274 -7Q232 -4 195 7T125 38T71 94T51 176V190Q51 213 60 242T95 307T156 373T255 425T393 451L397 452L427 568Q434 597 443 636Q452 677 456 685T472 694H486H495Q517 694 517 680L514 665Q510 650 503 621T489 564L460 451H469Q527 447 574 430T657 370T693 266Q693 163 599 82T350 -7H346L322 -100Q301 -190 295 -197Q291 -202 283 -202H269H258Q238 -202 238 -188Q238 -186 260 -96L283 -7H274ZM449 400Q448 400 404 225T359 47T366 45Q464 55 516 119Q542 149 558 199T575 295Q575 387 462 398L449 400ZM384 398Q384 399 381 399Q350 399 298 378T214 308Q168 236 168 149Q168 68 259 49Q282 44 294 44H295L384 398Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(1032.5,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M152 251Q152 646 388 850H416Q422 844 422 841Q422 837 403 816T357 753T302 649T255 482T236 250Q236 124 255 19T301 -147T356 -251T403 -315T422 -340Q422 -343 416 -349H388Q359 -325 332 -296T271 -213T212 -97T170 56T152 251Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(458,0)"><g data-mml-node="mi"><path data-c="1D433" d="M48 262Q48 264 54 349T60 436V444H252Q289 444 336 444T394 445Q441 445 450 441T459 418Q459 406 458 404Q456 399 327 229T194 55H237Q260 56 268 56T297 58T325 65T348 77T370 98T384 128T395 170Q400 197 400 216Q400 217 431 217H462V211Q461 208 453 108T444 6V0H245Q46 0 43 2Q32 7 32 28V33Q32 41 40 52T84 112Q129 170 164 217L298 393H256Q189 392 165 380Q124 360 115 303Q110 280 110 256Q110 254 79 254H48V262Z"></path></g></g><g data-mml-node="mo" transform="translate(969,0)"><path data-c="2223" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msup" transform="translate(1247,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,289) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2731.1,0) translate(0 -0.5)"><path data-c="29" d="M305 251Q305 -145 69 -349H56Q43 -349 39 -347T35 -338Q37 -333 60 -307T108 -239T160 -136T204 27T221 250T204 473T160 636T108 740T60 807T35 839Q35 850 50 850H56H69Q197 743 256 566Q305 425 305 251Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(24309.8,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="5B" d="M224 -649V1150H455V1099H275V-598H455V-649H224Z"></path></g><g data-mml-node="mi" transform="translate(472,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(1750,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(1916.7,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="TeXAtom" transform="translate(536,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D73D" d="M213 -8Q130 -8 85 50T40 200V207Q40 303 83 428Q122 535 189 608Q279 702 381 702Q410 702 437 693T492 661T537 593T554 486Q554 428 539 362T495 230T425 111T330 25T213 -8ZM433 562Q433 600 419 625T377 651Q363 651 348 644T311 619T268 557T229 453Q225 441 217 411T208 378H401Q433 500 433 562ZM161 140Q161 43 217 43Q249 43 280 74Q310 103 332 150T378 287Q385 313 385 315Q385 316 289 316H192Q191 308 183 275T169 205T161 140Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(3066.7,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M180 96T180 250T205 541T266 770T353 944T444 1069T527 1150H555Q561 1144 561 1141Q561 1137 545 1120T504 1072T447 995T386 878T330 721T288 513T272 251Q272 133 280 56Q293 -87 326 -209T399 -405T475 -531T536 -609T561 -640Q561 -643 555 -649H527Q483 -612 443 -568T353 -443T266 -270T205 -41Z"></path></g><g data-mml-node="msup" transform="translate(597,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2358.9,0)"><path data-c="2223" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(2914.6,0)"><g data-mml-node="mi"><path data-c="1D433" d="M48 262Q48 264 54 349T60 436V444H252Q289 444 336 444T394 445Q441 445 450 441T459 418Q459 406 458 404Q456 399 327 229T194 55H237Q260 56 268 56T297 58T325 65T348 77T370 98T384 128T395 170Q400 197 400 216Q400 217 431 217H462V211Q461 208 453 108T444 6V0H245Q46 0 43 2Q32 7 32 28V33Q32 41 40 52T84 112Q129 170 164 217L298 393H256Q189 392 165 380Q124 360 115 303Q110 280 110 256Q110 254 79 254H48V262Z"></path></g></g><g data-mml-node="mo" transform="translate(3425.6,0) translate(0 -0.5)"><path data-c="29" d="M35 1138Q35 1150 51 1150H56H69Q113 1113 153 1069T243 944T330 771T391 541T416 250T391 -40T330 -270T243 -443T152 -568T69 -649H56Q43 -649 39 -647T35 -637Q65 -607 110 -548Q283 -316 316 56Q324 133 324 251Q324 368 316 445Q278 877 48 1123Q36 1137 35 1138Z"></path></g></g><g data-mml-node="mo" transform="translate(7089.4,0) translate(0 -0.5)"><path data-c="5D" d="M16 1099V1150H247V-649H16V-598H196V1099H16Z"></path></g></g></g></g></svg></mjx-container></span><br>
目标函数是<strong>最大化变分下界</strong>（Variational Lower
Bound）：第一项 KL散度（Kullback-Leibler
Divergence）衡量了潜在变量的分布与先验分布之间的差异（z的差异：越小越好），第二项
重建损失（Reconstruction
Loss）衡量了重建样本与原始样本之间相似度（x为原图的概率：越大越好），所以整体
L 越大越好。</p>
<p>z
对应的多个高斯分布的均值和方差都不是固定的值，它们通过神经网络计算得来，神经网络的参数通过训练得到。</p>
<h3 id="具体实现">4.2 具体实现</h3>
<p>这里引入了噪声变量e作为辅助变量，来实现 q 的功能。<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="11.268ex" height="2.364ex" role="img" focusable="false" viewBox="0 -750 4980.7 1045"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mo" transform="translate(288.1,-18) translate(-250 0)"><path data-c="2DC" d="M179 601Q164 601 151 595T131 584T111 565L97 577L83 588Q83 589 95 603T121 633T142 654Q165 668 187 668T253 650T320 632Q335 632 348 638T368 649T388 668L402 656L416 645Q375 586 344 572Q330 565 313 565Q292 565 248 583T179 601Z"></path></g></g></g><g data-mml-node="mo" transform="translate(742.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(1798.6,0)"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(510,-150) scale(0.707)"><path data-c="1D719" d="M409 688Q413 694 421 694H429H442Q448 688 448 686Q448 679 418 563Q411 535 404 504T392 458L388 442Q388 441 397 441T429 435T477 418Q521 397 550 357T579 260T548 151T471 65T374 11T279 -10H275L251 -105Q245 -128 238 -160Q230 -192 227 -198T215 -205H209Q189 -205 189 -198Q189 -193 211 -103L234 -11Q234 -10 226 -10Q221 -10 206 -8T161 6T107 36T62 89T43 171Q43 231 76 284T157 370T254 422T342 441Q347 441 348 445L378 567Q409 686 409 688ZM122 150Q122 116 134 91T167 53T203 35T237 27H244L337 404Q333 404 326 403T297 395T255 379T211 350T170 304Q152 276 137 237Q122 191 122 150ZM500 282Q500 320 484 347T444 385T405 400T381 404H378L332 217L284 29Q284 27 285 27Q293 27 317 33T357 47Q400 66 431 100T475 170T494 234T500 282Z"></path></g></g><g data-mml-node="mo" transform="translate(2780,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(3169,0)"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g><g data-mml-node="mo" transform="translate(3575,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(4019.7,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(4591.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span><br>
对某个函数 f(z) 的期望进行蒙特卡洛估计，具体通过采样实现，其minibatch
是从有N个数据点的数据集中，随机抽取M个点：<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.819ex;" xmlns="http://www.w3.org/2000/svg" width="51.111ex" height="6.74ex" role="img" focusable="false" viewBox="0 -1733 22591.2 2978.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="4C" d="M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z"></path></g></g><g data-mml-node="mo" transform="translate(690,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1079,0)"><path data-c="1D73D" d="M213 -8Q130 -8 85 50T40 200V207Q40 303 83 428Q122 535 189 608Q279 702 381 702Q410 702 437 693T492 661T537 593T554 486Q554 428 539 362T495 230T425 111T330 25T213 -8ZM433 562Q433 600 419 625T377 651Q363 651 348 644T311 619T268 557T229 453Q225 441 217 411T208 378H401Q433 500 433 562ZM161 140Q161 43 217 43Q249 43 280 74Q310 103 332 150T378 287Q385 313 385 315Q385 316 289 316H192Q191 308 183 275T169 205T161 140Z"></path></g><g data-mml-node="mo" transform="translate(1641,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2085.7,0)"><path data-c="1D753" d="M274 -7Q232 -4 195 7T125 38T71 94T51 176V190Q51 213 60 242T95 307T156 373T255 425T393 451L397 452L427 568Q434 597 443 636Q452 677 456 685T472 694H486H495Q517 694 517 680L514 665Q510 650 503 621T489 564L460 451H469Q527 447 574 430T657 370T693 266Q693 163 599 82T350 -7H346L322 -100Q301 -190 295 -197Q291 -202 283 -202H269H258Q238 -202 238 -188Q238 -186 260 -96L283 -7H274ZM449 400Q448 400 404 225T359 47T366 45Q464 55 516 119Q542 149 558 199T575 295Q575 387 462 398L449 400ZM384 398Q384 399 381 399Q350 399 298 378T214 308Q168 236 168 149Q168 68 259 49Q282 44 294 44H295L384 398Z"></path></g><g data-mml-node="mo" transform="translate(2797.7,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(3242.3,0)"><g data-mml-node="mi"><path data-c="1D417" d="M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z"></path></g></g><g data-mml-node="mo" transform="translate(4111.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4778.1,0)"><path data-c="2243" d="M55 283Q55 356 103 409T217 463Q262 463 297 447T395 382Q431 355 446 344T493 320T554 307H558Q613 307 652 344T694 433Q694 464 708 464T722 432Q722 356 673 304T564 251H554Q510 251 465 275T387 329T310 382T223 407H219Q164 407 122 367Q91 333 85 295T76 253T69 250Q55 250 55 283ZM56 56Q56 71 72 76H706Q722 70 722 56Q722 44 707 36H70Q56 43 56 56Z"></path></g><g data-mml-node="msup" transform="translate(5833.9,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="4C" d="M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z"></path></g></g><g data-mml-node="mo" transform="translate(484,213) translate(-278 0)"><path data-c="2DC" d="M374 597Q337 597 269 627T160 658Q101 658 34 606L24 597L12 611Q1 624 1 626Q1 627 27 648T55 671Q120 722 182 722Q219 722 286 692T395 661Q454 661 521 713L531 722L543 708Q554 695 554 693Q554 692 528 671T500 648Q434 597 374 597Z"></path></g></g></g><g data-mml-node="TeXAtom" transform="translate(723,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(7516.7,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M152 251Q152 646 388 850H416Q422 844 422 841Q422 837 403 816T357 753T302 649T255 482T236 250Q236 124 255 19T301 -147T356 -251T403 -315T422 -340Q422 -343 416 -349H388Q359 -325 332 -296T271 -213T212 -97T170 56T152 251Z"></path></g><g data-mml-node="mi" transform="translate(458,0)"><path data-c="1D73D" d="M213 -8Q130 -8 85 50T40 200V207Q40 303 83 428Q122 535 189 608Q279 702 381 702Q410 702 437 693T492 661T537 593T554 486Q554 428 539 362T495 230T425 111T330 25T213 -8ZM433 562Q433 600 419 625T377 651Q363 651 348 644T311 619T268 557T229 453Q225 441 217 411T208 378H401Q433 500 433 562ZM161 140Q161 43 217 43Q249 43 280 74Q310 103 332 150T378 287Q385 313 385 315Q385 316 289 316H192Q191 308 183 275T169 205T161 140Z"></path></g><g data-mml-node="mo" transform="translate(1020,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1464.7,0)"><path data-c="1D753" d="M274 -7Q232 -4 195 7T125 38T71 94T51 176V190Q51 213 60 242T95 307T156 373T255 425T393 451L397 452L427 568Q434 597 443 636Q452 677 456 685T472 694H486H495Q517 694 517 680L514 665Q510 650 503 621T489 564L460 451H469Q527 447 574 430T657 370T693 266Q693 163 599 82T350 -7H346L322 -100Q301 -190 295 -197Q291 -202 283 -202H269H258Q238 -202 238 -188Q238 -186 260 -96L283 -7H274ZM449 400Q448 400 404 225T359 47T366 45Q464 55 516 119Q542 149 558 199T575 295Q575 387 462 398L449 400ZM384 398Q384 399 381 399Q350 399 298 378T214 308Q168 236 168 149Q168 68 259 49Q282 44 294 44H295L384 398Z"></path></g><g data-mml-node="mo" transform="translate(2176.7,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="msup" transform="translate(2621.3,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D417" d="M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(902,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4316.5,0) translate(0 -0.5)"><path data-c="29" d="M305 251Q305 -145 69 -349H56Q43 -349 39 -347T35 -338Q37 -333 60 -307T108 -239T160 -136T204 27T221 250T204 473T160 636T108 740T60 807T35 839Q35 850 50 850H56H69Q197 743 256 566Q305 425 305 251Z"></path></g></g><g data-mml-node="mo" transform="translate(12569,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(13624.8,0)"><g data-mml-node="mi" transform="translate(301.5,676)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mi" transform="translate(220,-686)"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><rect width="1251" height="60" x="120" y="220"></rect></g><g data-mml-node="munderover" transform="translate(15282.4,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(148.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(350.4,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(16893.1,0)"><g data-mml-node="mover"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="4C" d="M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z"></path></g></g><g data-mml-node="mo" transform="translate(484,213) translate(-278 0)"><path data-c="2DC" d="M374 597Q337 597 269 627T160 658Q101 658 34 606L24 597L12 611Q1 624 1 626Q1 627 27 648T55 671Q120 722 182 722Q219 722 286 692T395 661Q454 661 521 713L531 722L543 708Q554 695 554 693Q554 692 528 671T500 648Q434 597 374 597Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(17749.8,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M180 96T180 250T205 541T266 770T353 944T444 1069T527 1150H555Q561 1144 561 1141Q561 1137 545 1120T504 1072T447 995T386 878T330 721T288 513T272 251Q272 133 280 56Q293 -87 326 -209T399 -405T475 -531T536 -609T561 -640Q561 -643 555 -649H527Q483 -612 443 -568T353 -443T266 -270T205 -41Z"></path></g><g data-mml-node="mi" transform="translate(597,0)"><path data-c="1D73D" d="M213 -8Q130 -8 85 50T40 200V207Q40 303 83 428Q122 535 189 608Q279 702 381 702Q410 702 437 693T492 661T537 593T554 486Q554 428 539 362T495 230T425 111T330 25T213 -8ZM433 562Q433 600 419 625T377 651Q363 651 348 644T311 619T268 557T229 453Q225 441 217 411T208 378H401Q433 500 433 562ZM161 140Q161 43 217 43Q249 43 280 74Q310 103 332 150T378 287Q385 313 385 315Q385 316 289 316H192Q191 308 183 275T169 205T161 140Z"></path></g><g data-mml-node="mo" transform="translate(1159,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1603.7,0)"><path data-c="1D753" d="M274 -7Q232 -4 195 7T125 38T71 94T51 176V190Q51 213 60 242T95 307T156 373T255 425T393 451L397 452L427 568Q434 597 443 636Q452 677 456 685T472 694H486H495Q517 694 517 680L514 665Q510 650 503 621T489 564L460 451H469Q527 447 574 430T657 370T693 266Q693 163 599 82T350 -7H346L322 -100Q301 -190 295 -197Q291 -202 283 -202H269H258Q238 -202 238 -188Q238 -186 260 -96L283 -7H274ZM449 400Q448 400 404 225T359 47T366 45Q464 55 516 119Q542 149 558 199T575 295Q575 387 462 398L449 400ZM384 398Q384 399 381 399Q350 399 298 378T214 308Q168 236 168 149Q168 68 259 49Q282 44 294 44H295L384 398Z"></path></g><g data-mml-node="mo" transform="translate(2315.7,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="msup" transform="translate(2760.3,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4244.4,0) translate(0 -0.5)"><path data-c="29" d="M35 1138Q35 1150 51 1150H56H69Q113 1113 153 1069T243 944T330 771T391 541T416 250T391 -40T330 -270T243 -443T152 -568T69 -649H56Q43 -649 39 -647T35 -637Q65 -607 110 -548Q283 -316 316 56Q324 133 324 251Q324 368 316 445Q278 877 48 1123Q36 1137 35 1138Z"></path></g></g></g></g></svg></mjx-container></span><br>
可以将KL散度看成限制参数φ的正则化项。而重建误差部分：先用函数 gφ(.)
将数据点 x 和随机噪声向量映射到该数据点的近似后验样本z，然后计算 log
pθ(x(i)|z(i,l))，等于生成模型下数据点 x(i)
的概率密度，从而计算重建误差。</p>
<h3 id="变分自编码器-1">4.3 变分自编码器</h3>
<p>在变分自编码器的场景中，先验是中心各向同性的多元高斯分布：<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.469ex;" xmlns="http://www.w3.org/2000/svg" width="38.738ex" height="4.07ex" role="img" focusable="false" viewBox="0 -1149.5 17122.4 1799"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(1278,0)"><path data-c="2061" d=""></path></g><g data-mml-node="msub" transform="translate(1444.7,0)"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="TeXAtom" transform="translate(479,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D753" d="M274 -7Q232 -4 195 7T125 38T71 94T51 176V190Q51 213 60 242T95 307T156 373T255 425T393 451L397 452L427 568Q434 597 443 636Q452 677 456 685T472 694H486H495Q517 694 517 680L514 665Q510 650 503 621T489 564L460 451H469Q527 447 574 430T657 370T693 266Q693 163 599 82T350 -7H346L322 -100Q301 -190 295 -197Q291 -202 283 -202H269H258Q238 -202 238 -188Q238 -186 260 -96L283 -7H274ZM449 400Q448 400 404 225T359 47T366 45Q464 55 516 119Q542 149 558 199T575 295Q575 387 462 398L449 400ZM384 398Q384 399 381 399Q350 399 298 378T214 308Q168 236 168 149Q168 68 259 49Q282 44 294 44H295L384 398Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(2643.8,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M180 96T180 250T205 541T266 770T353 944T444 1069T527 1150H555Q561 1144 561 1141Q561 1137 545 1120T504 1072T447 995T386 878T330 721T288 513T272 251Q272 133 280 56Q293 -87 326 -209T399 -405T475 -531T536 -609T561 -640Q561 -643 555 -649H527Q483 -612 443 -568T353 -443T266 -270T205 -41Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(597,0)"><g data-mml-node="mi"><path data-c="1D433" d="M48 262Q48 264 54 349T60 436V444H252Q289 444 336 444T394 445Q441 445 450 441T459 418Q459 406 458 404Q456 399 327 229T194 55H237Q260 56 268 56T297 58T325 65T348 77T370 98T384 128T395 170Q400 197 400 216Q400 217 431 217H462V211Q461 208 453 108T444 6V0H245Q46 0 43 2Q32 7 32 28V33Q32 41 40 52T84 112Q129 170 164 217L298 393H256Q189 392 165 380Q124 360 115 303Q110 280 110 256Q110 254 79 254H48V262Z"></path></g></g><g data-mml-node="mo" transform="translate(1385.8,0)"><path data-c="2223" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msup" transform="translate(1941.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(640,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3425.6,0) translate(0 -0.5)"><path data-c="29" d="M35 1138Q35 1150 51 1150H56H69Q113 1113 153 1069T243 944T330 771T391 541T416 250T391 -40T330 -270T243 -443T152 -568T69 -649H56Q43 -649 39 -647T35 -637Q65 -607 110 -548Q283 -316 316 56Q324 133 324 251Q324 368 316 445Q278 877 48 1123Q36 1137 35 1138Z"></path></g></g><g data-mml-node="mo" transform="translate(6944.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(8000,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(9278,0)"><path data-c="2061" d=""></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(9444.7,0)"><g data-mml-node="mi"><path data-c="4E" d="M343 705Q358 705 358 698Q360 696 370 658T411 524T484 319Q536 174 590 82L595 73L615 152Q646 274 683 407Q729 571 752 637T799 727Q852 780 937 788Q939 788 947 788T958 789H962Q979 789 979 765Q979 722 951 692Q942 683 924 683Q888 681 859 672T818 654T803 639Q784 608 708 322T631 15Q631 14 630 15Q630 17 629 15Q628 14 628 12Q621 -4 601 -17T560 -31Q550 -31 546 -28T530 -7Q484 67 458 123T398 272Q352 392 314 514L306 535V534Q306 533 296 488T272 379T234 239T185 100T127 -7T61 -50Q34 -50 4 -34T-27 8Q-27 33 -12 61T18 90Q21 90 36 77T87 57H92Q109 57 123 78T162 173Q206 299 232 417T265 599T276 667Q284 681 304 693T343 705Z"></path></g></g><g data-mml-node="mrow" transform="translate(10590.3,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M180 96T180 250T205 541T266 770T353 944T444 1069T527 1150H555Q561 1144 561 1141Q561 1137 545 1120T504 1072T447 995T386 878T330 721T288 513T272 251Q272 133 280 56Q293 -87 326 -209T399 -405T475 -531T536 -609T561 -640Q561 -643 555 -649H527Q483 -612 443 -568T353 -443T266 -270T205 -41Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(597,0)"><g data-mml-node="mi"><path data-c="1D433" d="M48 262Q48 264 54 349T60 436V444H252Q289 444 336 444T394 445Q441 445 450 441T459 418Q459 406 458 404Q456 399 327 229T194 55H237Q260 56 268 56T297 58T325 65T348 77T370 98T384 128T395 170Q400 197 400 216Q400 217 431 217H462V211Q461 208 453 108T444 6V0H245Q46 0 43 2Q32 7 32 28V33Q32 41 40 52T84 112Q129 170 164 217L298 393H256Q189 392 165 380Q124 360 115 303Q110 280 110 256Q110 254 79 254H48V262Z"></path></g></g><g data-mml-node="mo" transform="translate(1108,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="msup" transform="translate(1552.7,0)"><g data-mml-node="mi"><path data-c="1D741" d="M294 -8Q265 -8 244 -5T213 1T201 4Q200 4 192 -32T172 -111T155 -168Q134 -211 86 -211Q62 -211 48 -196T34 -158Q37 -144 103 123T174 404Q182 424 201 438T244 452Q271 452 284 436T298 404Q298 392 267 269T235 114Q235 43 305 43Q342 43 375 68T418 110Q420 112 455 253T492 397Q514 444 562 444Q587 444 601 429T615 397Q615 387 599 320T563 178T542 93Q540 81 540 72Q540 42 558 42Q580 42 596 75Q606 94 616 134Q621 155 624 158T646 162H651H662Q682 162 682 148Q681 142 679 132T665 94T641 47T602 9T548 -8Q523 -8 502 -3T468 11T446 27T432 40L429 46Q367 -8 294 -8Z"></path></g><g data-mml-node="TeXAtom" transform="translate(741,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3137.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(3582.4,0)"><g data-mml-node="mi"><path data-c="1D748" d="M35 151Q35 190 51 236T99 327T184 404T306 443Q307 443 316 443T342 443T378 444T425 444T476 444Q606 444 626 444T655 439Q677 426 677 400Q677 358 639 340Q625 333 563 333Q510 333 510 331Q518 319 518 272Q518 155 437 74T226 -8Q123 -8 79 41T35 151ZM396 278Q396 314 375 323T305 332Q249 332 222 310T180 243Q171 219 162 178T153 116V110Q153 43 234 43Q347 43 382 199Q383 203 383 204Q396 255 396 278Z"></path></g><g data-mml-node="TeXAtom" transform="translate(719,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(500,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(889,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1234,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(5499,0)"><g data-mml-node="mi"><path data-c="1D408" d="M397 0Q370 3 218 3Q65 3 38 0H25V62H139V624H25V686H38Q65 683 218 683Q370 683 397 686H410V624H296V62H410V0H397Z"></path></g></g><g data-mml-node="mo" transform="translate(5935,0) translate(0 -0.5)"><path data-c="29" d="M35 1138Q35 1150 51 1150H56H69Q113 1113 153 1069T243 944T330 771T391 541T416 250T391 -40T330 -270T243 -443T152 -568T69 -649H56Q43 -649 39 -647T35 -637Q65 -607 110 -548Q283 -316 316 56Q324 133 324 251Q324 368 316 445Q278 877 48 1123Q36 1137 35 1138Z"></path></g></g></g></g></svg></mjx-container></span><br>
其中均值和标准差是编码 MLP 的输出。由于是高斯分布：<br>
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="36.069ex" height="2.802ex" role="img" focusable="false" viewBox="0 -943.3 15942.4 1238.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="TeXAtom" transform="translate(498,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1012,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(1310,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2027.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(3082.9,0)"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(510,-150) scale(0.707)"><path data-c="1D719" d="M409 688Q413 694 421 694H429H442Q448 688 448 686Q448 679 418 563Q411 535 404 504T392 458L388 442Q388 441 397 441T429 435T477 418Q521 397 550 357T579 260T548 151T471 65T374 11T279 -10H275L251 -105Q245 -128 238 -160Q230 -192 227 -198T215 -205H209Q189 -205 189 -198Q189 -193 211 -103L234 -11Q234 -10 226 -10Q221 -10 206 -8T161 6T107 36T62 89T43 171Q43 231 76 284T157 370T254 422T342 441Q347 441 348 445L378 567Q409 686 409 688ZM122 150Q122 116 134 91T167 53T203 35T237 27H244L337 404Q333 404 326 403T297 395T255 379T211 350T170 304Q152 276 137 237Q122 191 122 150ZM500 282Q500 320 484 347T444 385T405 400T381 404H378L332 217L284 29Q284 27 285 27Q293 27 317 33T357 47Q400 66 431 100T475 170T494 234T500 282Z"></path></g></g><g data-mml-node="mo" transform="translate(4064.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msup" transform="translate(4453.4,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(5902.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(6347.1,0)"><g data-mml-node="mi"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g><g data-mml-node="TeXAtom" transform="translate(439,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(687,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(7597,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(8263.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msup" transform="translate(9319.5,0)"><g data-mml-node="mi"><path data-c="1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path></g><g data-mml-node="TeXAtom" transform="translate(636,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(11021.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msup" transform="translate(12022,0)"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g><g data-mml-node="TeXAtom" transform="translate(604,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(13692.3,0)"><path data-c="2299" d="M56 250Q56 394 156 488T384 583Q530 583 626 485T722 250Q722 110 625 14T390 -83Q249 -83 153 14T56 250ZM682 250Q682 322 649 387T546 497T381 542Q272 542 184 459T95 250Q95 132 178 45T389 -42Q515 -42 598 45T682 250ZM311 250Q311 285 332 304T375 328Q376 328 382 328T392 329Q424 326 445 305T466 250Q466 217 445 195T389 172Q354 172 333 195T311 250Z"></path></g><g data-mml-node="msup" transform="translate(14692.6,0)"><g data-mml-node="mi"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g><g data-mml-node="TeXAtom" transform="translate(439,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(687,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g></g></svg></mjx-container></span><br>
引入高斯分布的KL散度，最终目标函数是：<br>
<img src="/attachments_2023/Pasted%20image%2020230901205808.png"></p>
]]></content>
      <tags>
        <tag>模型结构</tag>
      </tags>
  </entry>
  <entry>
    <title>Android常用命令及工具</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/Android%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%8F%8A%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<h1 id="android常用命令及工具">Android常用命令及工具</h1>
<p>#移动开发 #android</p>
<p>1. 切换java版本<br />
update-alternatives --config java<br />
update-alternatives --config javac<br />
该命令会列出可选项，显示当前项，然后输入选哪个</p>
<p>2. eclipse编译步骤</p>
<ol type="a">
<li><p>在eclipse中对已存在的目录新建工程</p></li>
<li><p>加jar包：jar包上-&gt;右键-&gt;build path</p></li>
<li><p>试编：菜单-run-&gt;run configurations，加新的android
configure，指定项目<br />
注意所有文件的权限,含raw,jar,so等</p></li>
<li><p>导出不签名的名：项目名上-&gt;右键-&gt;Android tools-&gt;export
unsigned apk</p></li>
<li><p>签名，在源码目录下运行：./sign.sh
unsigned_apk_path，即生成/tmp/xxx.apk</p></li>
</ol>
<p>3. 切换软件安装位置<br />
切换安装到SD卡<br />
adb shell pm setInstallLocation 2<br />
切换安装到手机内存<br />
adb shell pm setInstallLocation 1</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android常用工具</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/Android%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<h1 id="android常用工具">Android常用工具</h1>
<p>#移动开发 #android</p>
<p>一、 Log</p>
<p>1. logcat 不同级别的打印信息，级别如下<br />
V Verbose<br />
D Debug<br />
I Info<br />
W Warn<br />
E Error<br />
F Fatal<br />
S Silent</p>
<p>2. 如何在 log 里打行号和时间<br />
getFileName ()<br />
getClassName ()<br />
getMethodName ()<br />
getLineNumber ()</p>
<p>二、 Adb</p>
<p>1. 把程序装手机里：一般程序装 apk 即可</p>
<ol type="1">
<li><p>手机打开，边上 usb 线，直接连上电脑</p></li>
<li><p>系统 ubuntu 8.04<br />
sdk 包 android-sdk-linux_x86-1.5_r3/tools/adb shell<br />
变 root 权限 ( 因为连接真机，若边模拟器就无所谓哪个用户了 )</p></li>
<li><p>使用命令 adb devices 看设备是否连上了<br />
如果同时启了模拟器和连接了手机， adb 会让你选择与谁连接</p></li>
<li><p>注意：如果你有多个 SDK ，千万要使用匹配的 adb
命令，最好用绝对路径，否则很容易得到提示说找不设备，如果说找不到
adb<br />
，请尝试以下方法<br />
** $ killall adb ** **<br />
$ rmmod ehci_hcd<br />
$ ./adb kill-server<br />
$ ./adb start-server **</p></li>
</ol>
<p>2. adb 常用参数</p>
<ol type="1">
<li><p>adb devices<br />
察看手机是否连接 ( 手机需要打开 USB debug)</p></li>
<li><p>adb pull **<br />
A ** 为手机路径， B 为电脑路径，意思为：把文件从手机复制到电脑上
****</p></li>
<li><p>adb push **** 为手机路径， B
为电脑路径，意思为：把文件从电脑复制到手机上 ****</p></li>
<li><p>adb remount<br />
得到手机的系统文件读写权</p></li>
<li><p>adb install 包名<br />
安装 pc 中的 apk 软件到手机</p></li>
<li><p>adb shell<br />
进入手机的超级终端 Terminal</p></li>
</ol>
<p>3. adb shell</p>
<p>** 1) ** 看当前 log 信息<br />
** # logcat **</p>
<ol start="2" type="1">
<li><p>在 adb shell 用普通 shell 命令<br />
** # busybox df<br />
# busybox ls **</p></li>
<li><p>android 上的网络调试<br />
adb shell 支持以下命令</p></li>
</ol>
<ol type="a">
<li><p>** # ping **<br />
发出 ping 命令，查看 Google.com 是否可用</p></li>
<li><p>** # ifconfig **<br />
lo 是本地或 loopback 连接。<br />
tiwlan0 是 WiFi 连接</p></li>
</ol>
<ol start="4" type="1">
<li>数据库使用与调试</li>
</ol>
<ol type="a">
<li><p>操作数据库<br />
** # cd /data/data/com.android.mails/databases/<br />
# sqlite3 ** ** 库名 ** **<br />
sqlite &gt; select * from ** ** 表名 **<br />
Ctr+D 退出<br />
程序中参见关键字 : execSQL, rawQuery</p></li>
<li><p>查看数据字典<br />
** sqlite &gt; .sch **</p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Eclipse编译带so库或jar包的android应用</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/Eclipse%E7%BC%96%E8%AF%91%E5%B8%A6so%E5%BA%93%E6%88%96jar%E5%8C%85%E7%9A%84android%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<h1
id="eclipse编译带so库或jar包的android应用">Eclipse编译带so库或jar包的android应用</h1>
<p>#移动开发 #android</p>
<p>1. 环境的搭建</p>
<ol type="1">
<li><p>安装java环境（见之前文档）</p></li>
<li><p>安装eclipse环境（见之前文档）<br />
打开Eclipse ，选择菜单中的Help - Software Updates – Available Software –
Add Site -<br />
输入地址(https://dl-ssl.google.com/android/eclipse/) （如果有问题请试用
）点击OK - 选择上面添加的地址 -<br />
点击 Install 安装插件，完成后重启Eclipse即可</p></li>
<li><p>下载相应SDK（本例以android 3.0以上SDK为例）</p></li>
<li><p>指定SDK位置<br />
打开Eclipse ，选择菜单中的Windows – Preferences – Android - SDK Location
-<br />
点击Browse，选择Android SDK所在的位置，点击OK保存即可。</p></li>
<li><p>下载相关环境<br />
早期的SDK，只要下载一个SDK压缩包即可，现在的SDK压缩包中不包含tools,确良platform等必要的工具，需要用eclipse连网下载，方法：菜单-&gt;Window-&gt;Android<br />
SDK Manager，然后选择需要的SDK版本下载即可。</p></li>
<li><p>建立AVD</p></li>
</ol>
<ol type="a">
<li><p>为什么要建立AVD<br />
运行时需要Android环境，如果没有Android手机，或者手机版本与SDK版本不一致时，就需要建立一个虚拟运行环境AVD</p></li>
<li><p>菜单-&gt;Window-&gt;AVD Manager，建立虚拟机环境。Android<br />
3.0以上默认是宽屏PAD的分辨率，因为屏幕大，操作起来特别慢，如果调手机应用，建议设在800x480以下）</p></li>
</ol>
<p>2. 导入现有工程</p>
<ol type="1">
<li><p>如果应用在eclipse中建立，使用<br />
菜单-&gt;New-&gt;Import，选择源码所在目录</p></li>
<li><p>如果应用在源码中建立，使用<br />
菜单-&gt;New-&gt;Project-&gt;Android-&gt;Android
project，选择从一个已有的目录建立工程</p></li>
</ol>
<p>3. 引入三方jar包<br />
在源码环境中编译只要修改Android.mk即可，在eclipse中编译需要引入jar包</p>
<ol type="1">
<li><p>项目名-&gt;右键-&gt;build path-&gt;add libraries-&gt;User
Library-&gt;User<br />
Libraries-&gt;New-&gt;输入名字-&gt;</p></li>
<li><p>如果之前jar包就在源码目录中，可以选中jar包-&gt;右键-&gt;Build
path-&gt;add to build path-&gt;Add<br />
jARs...-&gt;加入jar包-&gt;OK-&gt;Finish</p></li>
</ol>
<p>4. 引入so文件<br />
在源码环境中编译修改Android.mk即可将源文件编成so，将加入apk，可以不使用NDK，在eclipse中编译步骤如下</p>
<ol type="1">
<li>NDK</li>
</ol>
<ol type="a">
<li><p>下载NDK<br />
<a
href="http://dl.google.com/android/ndk/android-ndk-r4b-linux-x86.zip">http://dl.google.com/android/ndk/android-ndk-r4b-linux-x86.zip<br />
</a></p></li>
<li><p>设置环境变量<br />
export NDK_ROOT=NDK安装目录<br />
可以把以上命令加入~/.bashrc，每次启动shell时自动运行</p></li>
<li><p>编译so中<br />
进行源码所在目录，如ndk包中所带示例<br />
cd $NDK_ROOT/samples/hello-jni<br />
然后执行<br />
$NDK_ROOT/ndk-build<br />
或者在任一目录执行<br />
$NDK_ROOT/ndk-build -C $NDK_ROOT/samples/hello-jni.<br />
此时即可在hello-jni/libs/armeabi/目录下产生so库</p></li>
<li><p>注意</p></li>
</ol>
<ol type="i">
<li><p>C源代码需要安在jni目录下，NDK会在项目目录下找jni/Android.mk，用于编译</p></li>
<li><p>源码目录中最上层必须有AndroidManifest.xml</p></li>
<li><p>显示编译时的具体命令<br />
$NDK_ROOT/ndk-build –B V=1</p></li>
</ol>
<ol start="2" type="1">
<li>将so库编进apk</li>
</ol>
<ol type="a">
<li>在源码目录中建立libs/armeabi/，然后将libxxx.so拷到该目录下即可编到apk包中（apk生成在bin目录下），可以试用unzip将apk解包看看lib是否存在。同时在adb<br />
shell看logcat信息，以辅助调试。</li>
</ol>
<ol start="3" type="1">
<li>在eclipse中签名<br />
项目名-&gt;右键-&gt;Android Tools-&gt;Export Unsigned Application
Package…<br />
然后再对其签名</li>
</ol>
<p>5. 好处：</p>
<ol type="1">
<li><p>高版本的SDK以及使用NDK更规范，让代码更不容易出错。</p></li>
<li><p>android
3.0源码至今没有发布，而像admob这样的广告商又要求2011年10月之后的新加入的广告，只有在android<br />
3以上的SDK下编译，才能正常显示。这种情况下只能使用android 3.2和android
4.0的SDK开发。</p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu上安装和使用AndroidStudio</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/Ubuntu%E4%B8%8A%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8Android-Studio/</url>
    <content><![CDATA[<h1 id="ubuntu上安装和使用android-studio">Ubuntu上安装和使用Android
Studio</h1>
<p>#移动开发 #android</p>
<h2 id="对比eclipse与android-studio开发">1． 对比Eclipse与Android
Studio开发</h2>
<table>
<colgroup>
<col style="width: 16%" />
<col style="width: 50%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: center;">Eclipse开发</th>
<th style="text-align: right;">Android Studio开发</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Java开发工具</td>
<td style="text-align: center;">JDK (可通用)</td>
<td style="text-align: right;">JDK (可通用)</td>
</tr>
<tr class="even">
<td>Android开发工具</td>
<td style="text-align: center;">Android SDK</td>
<td style="text-align: right;">Android SDK</td>
</tr>
<tr class="odd">
<td>集成开发环境</td>
<td style="text-align: center;">Eclipse</td>
<td style="text-align: right;">Android Studio</td>
</tr>
<tr class="even">
<td>命令行编译工具</td>
<td style="text-align: center;">Ant</td>
<td style="text-align: right;">Gradle</td>
</tr>
<tr class="odd">
<td>结构</td>
<td style="text-align: center;">Android
Studio的Project类于Eclipse的Workspace</td>
<td style="text-align: right;">Android
Studio的module类似于Eclipse的Project</td>
</tr>
<tr class="even">
<td>优点</td>
<td
style="text-align: center;">Eclipse支持C/C++/Java/Python起初大家都有它做Android开发，熟悉度高</td>
<td
style="text-align: right;">针对Android安装使用方便一些，5.0以后的有些功能只能在Android
Studio上使用</td>
</tr>
</tbody>
</table>
<h2 id="说明">2． 说明</h2>
<ol type="1">
<li><pre><code>        本文的安装环境是Ubuntu 16.10，其它Ubuntu版本也可以，强烈建议使用64位系统，因为最新版本Studio可执行程序(如adb)都是64位的；如果用32位系统，替换和升级相当麻烦。  </code></pre></li>
<li><pre><code>        强烈建议先翻墙（可通过修改/etc/hosts实现），安装时需要连接google服务器，否则很多安装包（Gardle，Android SDK）需要手动下载安装，有版本适配问题，容易出错。  </code></pre></li>
<li><pre><code>        网上一些安装教程用三条apt命令直接安装AndroidStudio，我在Ubuntu12.04，16.04，16.10上尝试均不成功，可能是Ubuntu版本不太一样，此处使用下载压缩包的方法安装  </code></pre></li>
<li><pre><code>        有些安装教程，用命令行安装JDK，Gardle等等工具，这主要针对早期Android Studio版本，目前版本Android Studio 2.3的JDK，Gardle，Android SDK都是安装包已包含和自动下载的，无需再手动安装。  </code></pre></li>
</ol>
<h2 id="安装">3． 安装</h2>
<ol type="1">
<li><pre><code>        下载Android studio安装包http://www.android-studio.org/（一定要下最新版本，早期版本配置比较麻烦）  </code></pre></li>
<li><pre><code>        安装  </code></pre></li>
</ol>
<pre><code>$ cd /exports/  
$ unzip android-studio-ide-162.3871768-linux.zip  
$ sudo ln -s /exports/android-studio/bin/studio.sh /bin/  
$ studio.sh （即可运行）  </code></pre>
<p>首次运行时提示下载和安装数据，第一次安装完成后，有的功能不能即时生效，退出Studio再进即可。</p>
<h2 id="其它">4． 其它</h2>
<ol type="1">
<li><pre><code>        升级更高版本的Android SDKAndroid Studio 菜单Tools-&gt;Android-&gt;SDKManager，选中需要的API版本安装即可（占空间比较多，不建议全部安装）  </code></pre></li>
<li><pre><code>        Android Studio数据  </code></pre></li>
</ol>
<ol type="i">
<li><pre><code>        Android SDK一般在第一次安装时让用户指定AndroidSDK安装目录，默认装在$HOME/Android/Sdk目录下  </code></pre></li>
<li><pre><code>        Gradle默认安装在$HOME/.gradle/wrapper/dists/gradle-3.3-all/55gk2rcmfc6p2dg9u9ohc3hw9/gradle-3.3目录下，如果想在命令行编译，使用用该目录下bin/gradle即可  </code></pre></li>
</ol>
<ol start="3" type="1">
<li><pre><code>        自定义JDK和Android SDK目录Android Studio主界面-&gt;菜单-&gt;File-&gt;OtherSettings-&gt;Default Project Structure…或Welcome界面Configure-&gt;ProjectDefault-&gt;Project Structure  </code></pre></li>
<li><pre><code>        在命令行编译程序  </code></pre></li>
</ol>
<pre><code>$ sudo ln -s ~/.gradle/wrapper/dists/gradle-3.3-all/55gk2rcmfc6p2dg9u9ohc3hw9/gradle-3.3/bin/gradle/bin/  
$ export JAVA_HOME=/exports/android-studio/jre/  
$ export PATH=$JAVA_HOME/bin/:$PATH  
$ gradle clean  
$ gradle build  </code></pre>
<ol start="5" type="1">
<li><pre><code>        Android Studio是否可以与Eclipse共用JDK和Android SDK  </code></pre></li>
</ol>
<ol type="i">
<li><pre><code>        JDK通过设置优先路径，即可和Eclipse共用，方法如下：  </code></pre></li>
</ol>
<pre><code>$ export JAVA_HOME=/exports/android-studio/jre/  
$ export PATH=$JAVA_HOME/bin/:$PATH  </code></pre>
<ol start="2" type="i">
<li><pre><code>        Android SDKEclipse开发需要: Java+Eclipse+ADT+AndroidSDK组合使用，ADT与Android SDK版本必须匹配．Android Studio下载的最新AndroidSDK可能版本高于ADT，因而无法与Eclipse共用（failed to get the required ADTversion number from the SDK，遇到此问题，在http://www.androiddevtools.cn/ 下载低版本即可）</code></pre></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android_G1_刷机</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/android_G1_%E5%88%B7%E6%9C%BA/</url>
    <content><![CDATA[<h1 id="android_g1_刷机">android_G1_刷机</h1>
<p>#移动开发 #android</p>
<p><strong>（刷机有风险，操作需谨慎）</strong></p>
<p>注意：虽说刷机有风险，但如果你按部就班地做下来，该注意的都注意了，想刷成砖头也很困难；<br />
相反本来对系统就不熟，一目十行地看完说明，随便下一个升级包就野蛮操作，完全成功的可能性也不大。</p>
<hr />
<p>1. 相关知识</p>
<ol type="1">
<li>分区</li>
</ol>
<ol type="a">
<li><p>splash1 ：开机画面，备份后的文件为 splash1.img</p></li>
<li><p>recovery ：该分区是恢复模式 ( 即 power+home 进入的界面 ) ，备份为
recovery.img</p></li>
<li><p>boot ：内核启动分区，备份为 boot.img</p></li>
<li><p>system ： Android 系统部分，目录表示为 /system
，通常为只读，备份为 system.img</p></li>
<li><p>cache ：缓存文件夹，目录表示为 /cache ，备份为 cache.img</p></li>
<li><p>userdata ：用户安装的软件以及各种数据，目录为 /data ，备份为
data.img</p></li>
</ol>
<ol start="2" type="1">
<li>模式</li>
</ol>
<ol type="a">
<li><p>正常模式<br />
正常开机的模式，用户使用此模式</p></li>
<li><p>恢复模式<br />
开机时按 power+home 键进入该模式，通常用此模式简单地升级系统</p></li>
<li><p>工程模式<br />
开机时按 power+camera 键进入该模式，在此模式中可通过使用 fastboot
工具修改各个分区<br />
（有的需要再按back键才能进入）</p></li>
</ol>
<ol start="3" type="1">
<li>刷机前的准备</li>
</ol>
<ol type="a">
<li><p>保证电量充足</p></li>
<li><p>保证在连接 PC 刷机的情况下，结束前不能拨掉 USB 线</p></li>
<li><p>保证升级包的正确性（ MD5 校验）</p></li>
</ol>
<p>2. 刷机前的备份<br />
从网上下载的升级包，在没有使用之前，不能确定它是否能用，是否支持中文，有什么致命的错误，所以最好在升级前备份原有的系统，保证它至少能恢复到能用的状态。</p>
<ol type="1">
<li>查看是否支持备份功能</li>
</ol>
<ol type="a">
<li><p>关机后，按 power+home 键开机进入恢复模式</p></li>
<li><p>此时一般能看到文字菜单，如果只看到黄色三角的图，按 Alt+L
可出现菜单</p></li>
<li><p>如果菜单含有 ”[Alt+S] nandroid 备份 ”
选项，则可以直接备份，否则需要先升级 recovery
分区，以得到备份工具</p></li>
</ol>
<ol start="2" type="1">
<li>升级 recovery 分区以得到备份工具<br />
升级此分区时不要过于担心，即使升级失败，系统仍可启动到正常模式和工程模式，以便重新烧写</li>
</ol>
<ol type="a">
<li><p>下载 recovery 分区的镜像文件<br />
<a
href="http://n0rp.chemlab.org/android/cm-recovery-1.4.img下载了recovery1.4">http://n0rp.chemlab.org/android/cm-recovery-1.4.img<br />
</a></p></li>
<li><p>把 cm-recovery-1.4.img 拷到 SD 卡的根目录</p></li>
<li><p>在 PC 上使用 adb shell 操作手机系统（可以使用手机中的超级终端
terminal emulator ），用如下命令烧写<br />
recovery 分区<br />
_ # su<br />
# flash_image recovery /sdcard/cm-recovery-1.4.img _</p></li>
<li><p>关机后，按 power+home
键开机进入恢复模式，即可看到备份工具</p></li>
</ol>
<ol start="3" type="1">
<li>recovery 分区功能<br />
关机后，按 power+home 键开机进入恢复模式，可看到以下选项</li>
</ol>
<ol type="a">
<li><p>[Home+back] 重启</p></li>
<li><p>[Alt+S] 刷已改名为 update.zip 的刷机包</p></li>
<li><p>[Alt+A] 直接刷 sd 卡里 zip 文件的刷机</p></li>
<li><p>[Alt+W] 恢复出厂设置，它恢复的是 userdata 分区和 cache<br />
分区，恢复之后用户数据都被删除了，升级系统后，如果不能正常使用，可以尝试恢复出厂设置</p></li>
<li><p>[Alt+B] nandroid 备份</p></li>
<li><p>[Alt+R] 恢复上一次的备份（只能恢复最后一次备份）</p></li>
<li><p>[Alt+F] 修复 Ext 系统文件（ App to sd 有用）</p></li>
<li><p>[Alt+X] 进入控制台</p></li>
</ol>
<ol start="4" type="1">
<li>备份分区<br />
使用 Alt+B 备份分区<br />
备份的文件保存在 SDCARD 的 nandroid 目录下面，以日期开头命名</li>
</ol>
<p>3. 使用 zip 包升级（恢复模式刷机）<br />
这是比较简单的升级方式，用户往往从网上下载升级包，操作容易也不容易出错，它更新的是
system 分区和 boot<br />
分区，即使升级失败，系统仍可启动到恢复模式和工程模式，以便重新烧写</p>
<ol type="1">
<li><p>把升级 zip 包改名为 update.zip ，放到 SD 卡的根目录</p></li>
<li><p>关机后，按 power+home 键开机进入恢复模式</p></li>
<li><p>此时一般能看到文字菜单，如果只看到黄色三角的图，按 Alt+L
可出现菜单</p></li>
<li><p>先使用 Alt+W 恢复出厂设置，此操作会清除用户数据</p></li>
<li><p>再按 Alt+S 刷机</p></li>
<li><p>有些机器会自动重启，如未自动重启，按 home+back
键手动重启</p></li>
</ol>
<p>4. 使用 fastboot 工具升级（工程模式刷机）<br />
可刷新各个分区，即使升级失败，也可以进入工程模式重新刷机</p>
<ol type="1">
<li><p>在 PC 端安装 fastboot 工具（ Windows/Linux 均可， Window
系统需要安装手机驱动）</p></li>
<li><p>用 USB 线连接手机和计算机，然后按 power+camera
键进入工程模式（有的需要再按back键才能进入）</p></li>
<li><p>看设备是否连接正常<br />
在 PC 端运行<br />
_ $ ./fastboot devices _<br />
看是否能正常列出设备，形如 HTC***</p></li>
<li><p>擦除分区<br />
_ $ ./fastboot erase _ _ 分区名 _ _<br />
_ 如： _ $ fastboot erase system _</p></li>
<li><p>刷新分区<br />
_ $ ./fastboot flash _ _ 分区名 _ _ _ _ 镜像文件名 _<br />
如： _ $ fastboot flash system system.img _</p></li>
<li><p>重新启动<br />
_ $ ./fastboot reboot _<br />
或者 按 “call+menu+power” 也可重启</p></li>
</ol>
<p>(转载请注明出处： <a
href="http://xy0811.spaces.live.com/">http://xy0811.spaces.live.com/</a>
)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>androidfota升级</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/androidfota%E5%8D%87%E7%BA%A7/</url>
    <content><![CDATA[<h1 id="android-fota升级">android fota升级</h1>
<p>#移动开发 #android</p>
<p>1. 简介<br />
fota( Firmware Over The Air ) ，移动终端空中下载软件升级技术。<br />
原理是根据算法把新旧版本之间的差别做成一个软件包，手机从服务器上下载到手机里，由手机完成软件版本的升级</p>
<p>2. 用户操作</p>
<ol type="1">
<li><p>设置－ &gt; 关于手机－ &gt;
检查更新，检查是否有更新版本。</p></li>
<li><p>可以使用默认设置自动更新：设置－ &gt; 关于手机－ &gt;
自动系统检查</p></li>
</ol>
<p>3. 升级过程<br />
MT710 的 FOTA 由中国移动服务器发起，服务器发送 FOTA<br />
信息到手机，手机收到信息并确认后，手机将自动上网下载升级包，下载后，手机将重启完成软件的更新。用户需要按照手机的提示，确认下载和
安装<br />
即可，不需要其他操作，也不需要对手机进行特殊设置。下载中断时手机会自动续接，直到下载完毕。在手机
FOTA<br />
过程中，需要保持手机在网络良好的连接状态，电池电量充足。</p>
<p>4. Fota 的相关源码</p>
<ol type="1">
<li><p>升级界面<br />
package/app/Fota/*</p></li>
<li><p>系统层<br />
system/core/fota/*</p></li>
<li><p>底层库支持<br />
external/fotalib/*</p></li>
<li><p>fota 分区<br />
因为像 boot.img 需要在系统之前修改，所以有 fota 启动方式<br />
bootable/bootloader/legacy/fota*</p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android之安装使用NDK</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/android%E4%B9%8B%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8NDK/</url>
    <content><![CDATA[<h1 id="android之安装使用ndk">android之安装使用NDK</h1>
<p>#移动开发 #android</p>
<p>1. 为什么需要 NDK<br />
NDK 不能做界面，只能做功能支持的库。<br />
NDK 与不使用 NDK ，直接使用 JNI
相比，它能把库打包，并且很方便的安装。<br />
NDK 使得没有源码的 eclipse 的环境编译 C/C++ 库变得非常方便。<br />
NDK 通常是用来编译和安装 C/C++
库的，常用做库的移植，很多软件会以此方式提供源码。</p>
<p>2. 下载<br />
<a
href="http://bbs.weiphone.com/read-htm-tid-521406.html">http://bbs.weiphone.com/read-htm-tid-521406.html<br />
</a></p>
<p>3. 安装 NDK</p>
<p>_ $ tar xvjf OpenCV-2.1.0.tar.bz2<br />
$ cd android-ndk-1.6_r1<br />
$ export NDKROOT=<code>pwd</code><br />
$ ./build/host-setup.sh _</p>
<p>4. 试用：编译其测试程序</p>
<p>_ $ _ _ make APP=hello-jni _ __</p>
<p>此时生成 out/apps/hello-jni/libhello-jni.so</p>
<p>(转载请注明出处: <a
href="http://xy0811.spaces.live.com">http://xy0811.spaces.live.com</a>
)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android的包管理</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/android%E7%9A%84%E5%8C%85%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h1 id="android的包管理">android的包管理</h1>
<p>#移动开发 #android</p>
<p>1. 说明<br />
包管理（ Package manager
）非常重要，它关系着软件包的安装，卸载，查看和使用，它是运行在后台的一个服务，名叫<br />
PackageManagerService ，包括对软件包的解包，验证，安装等</p>
<p>2. 系统软件包管理信息存储在哪<br />
/data/system/packages.xml<br />
通过它可以看到系统安装的所有软件包，以及软件包的信息</p>
<p>3. 包管理相关源码在哪<br />
frameworks/base/services/java/com/android/server/PackageManagerService.java</p>
<p>4. 系统自带的软件能升级吗（即安装在系统分区 system
中的包，如电话，短信）<br />
可以升级，如果升级 /system/app 目录中的包， PackageManagerServer.java
对此情况进行处理，被升级的包出现<br />
package.xml 的 updated-package 字段中，新的包信息会写在 package
字段中，卸载新包后，原包会恢复到<br />
package 字段中。启动时新的包会优先地被启动</p>
<p>5. 为什么安装软件时会报错</p>
<ol type="1">
<li><p>版本不匹配<br />
比如在 2.2 的 SDK 上编译的软件，不能在 1.6 上安装<br />
AndroidManifest.xml 中可以对版本所安装系统的版本进行指定</p></li>
<li><p>签名信息不匹配<br />
软件升级时会做签名信息对比，如果前后两个包签名不一致，则不能安装</p></li>
<li><p>包完整性不满足<br />
签名是对包中每个文件进行的，它的压缩格式是 zip
，如果手工解包后替换了某文件再打包，被替换的文件与签名验证不一致，则不能安装</p></li>
<li><p>格式不对<br />
有些从网上下载的包可能打了多层压缩，比如又将 apk 打包成了 rar
格式，建议解压缩看一下格式再安装</p></li>
</ol>
<p>6. 包的权限</p>
<ol type="1">
<li><p>软件在 AndroidMenifest.xml
中都会指明其需要的权限，安装包时图形界面也通常显示出它所需要的权限，供用户判断是否安装</p></li>
<li><p>特殊情况<br />
有些软件没有说明需要访问 SD
卡和打电话的权限，但安装后却出现此权限。<br />
当使用旧的 SDK 所做的包向新的 SDK 安装时，可能出现这种情况，见<br />
framework/base/core/java/android/content/pm/PackageParser.java
中的<br />
NEW_PERMISSION ，此处判断编译使用的 SDK 版本是否在 android1.6 之前
(DONUT)<br />
，如果在之前就加入这两个权限。</p></li>
</ol>
<p>(转载请注明出处: <a
href="http://xy0811.spaces.live.com">http://xy0811.spaces.live.com</a>
)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android的换肤</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/android%E7%9A%84%E6%8D%A2%E8%82%A4(theme)/</url>
    <content><![CDATA[<h1 id="android的换肤">android的换肤</h1>
<p>#移动开发 #android #theme</p>
<h2 id="相关概念">1. 相关概念</h2>
<h4 id="换肤">1) 换肤</h4>
<p>变换应用的背景，控件样式，应用图标及应用内部版式等与风格相关的界面元素</p>
<h4 id="资源">2) 资源</h4>
<p>资源由字串，图片，版式等元素组成，通常存放在 res 目录中， apk
打包时利用 aapt 工具 ( 实现见<br />
frameworks/base/tools/aapt) 对资源进行解析，并生成 apk 文件。</p>
<p>打包时资源分成两个部分，一部分完全写入 resources.arsc 文件（如
values* ），另一部分的索引信息写入resources.arsc
，而自身内容也做相应变化（如：将9patch的
png图其中的9patch信息从图片中可见变为记录在文件内部 ）</p>
<h4 id="相关文件">3) 相关文件</h4>
<p>公用资源存放在 /system/framework/framework-res.apk
包中，应用资源存放在各个应用的 apk<br />
包中（含应用图标，内部图片及布局），有的 android
产品可在设置中换背景图</p>
<h4 id="换肤思路">4) 换肤思路</h4>
<p>apk 是以 zip
压缩格式打包的文件，把它解开，然后把其中的图片换成新图片，再打包，替换原系统中的
apk 包，即可完成换肤。</p>
<h2 id="当前的换肤方法">2. 当前的换肤方法</h2>
<h4 id="使用-update.zip-升级">1) 使用 update.zip 升级</h4>
<p><strong>a) 原理</strong></p>
<p>update.zip 通常包含一个 update-script 脚本，用以决定更新
zip中的哪些包到系统中，一般分为全部更换和部分更换，全部更换为更换
system, userdata,
boot个分区的全部内容，部分更新可以更新单个或多个系统中的文件</p>
<p><strong>b) 方法</strong></p>
<p>下载 theme 的压缩包，放入 SD 卡，关机后启动到烧写模式，然后用
update.zip 升级系统</p>
<p><strong>c) 特点</strong></p>
<ul>
<li><p>全部更换等于完全重装了系统，用户数据都找不到了，影响很大</p></li>
<li><p>部分更新只替换部分内容，而替换的部分可能和其它部分冲突，造成变慢或无法启动等严重的问题</p></li>
<li><p>无论全部更新或者部分更换，只能更换到文件层（即使用 adb shell 时用
ls 可看到的文件）无法替换 jar 包或 apk包内部的内容</p></li>
<li><p>网上可下载的皮肤包各式各样，有大有小，没有一定的规范，基于各个版本，需要一个一个试</p></li>
<li><p>安装后无法恢复，所以试验前一定要使用 nandroid 备份原分区</p></li>
</ul>
<p><strong>d) 皮肤下载</strong></p>
<ol type="i">
<li><p><a
href="http://forum.xda-developers.com/forumdisplay.php?f=450">http://forum.xda-developers.com/forumdisplay.php?f=450</a></p></li>
<li><p><a
href="http://android-themes.net/">http://android-themes.net</a><br />
其中的 Blue_Star_5_ADP1.zip ， cm4.281-theme-update.zip ，
LBP-0[1].4.5.zip ，Rex3WixCSDI.zip 等</p></li>
</ol>
<h4 id="使用-metamorph-工具">2) 使用 metamorph 工具</h4>
<p><strong>a) 原理</strong></p>
<p>更换 jar/apk 包中内容</p>
<p><strong>b) 方法</strong></p>
<p>得到 root 权限，安装 metamorph 工具（可从 market 下载的 apk
包）及其依赖工具，下载皮肤的 zip 包到<br />
sd 卡，然后通过 metamorph 应用程序选择安装</p>
<p><strong>c) 特点</strong></p>
<ul>
<li><p>metamorph 为开源软件，可下载调试其源码</p></li>
<li><p>格式规范，有一些 theme 可用</p></li>
<li><p>用此方法，不只能换资源，也能改程序，不安全</p></li>
<li><p>需要 root 权限，不是一般用户可以操作的</p></li>
<li><p>不能回退到之前资源，只能通过 nandroid 备份原分区</p></li>
<li><p>由于可以只替换部分资源，所以换几次后可能出现上一资源残留的问题</p></li>
<li><p>资源包太大或有问题，会影响系统正常使用，甚至无法启动</p></li>
</ul>
<p><strong>d) 皮肤下载</strong></p>
<p><a
href="http://www.androidin.net/bbs/thread-34043-1-1.html">http://www.androidin.net/bbs/thread-34043-1-1.html</a></p>
<h2 id="说明">3. 说明</h2>
<p>由于至今 android
源码中还未提供友好的换肤接口，使得我们只能使用即麻烦又不安全的方法换肤。即使如此，网上还是能下载到大量
android<br />
皮肤。</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
        <tag>theme</tag>
      </tags>
  </entry>
  <entry>
    <title>android的系统升级方法对比</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/android%E7%9A%84%E7%B3%BB%E7%BB%9F%E5%8D%87%E7%BA%A7%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/</url>
    <content><![CDATA[<h1 id="android的系统升级方法对比">android的系统升级方法对比</h1>
<p>#移动开发 #android</p>
<p>1. 说明<br />
一般常用系统升级有两种方式 update.zip 和 fastboot,
下面介绍它们的区别和联系</p>
<p>2. update.zip</p>
<ol type="1">
<li><p>使用方法<br />
一般把 update.zip 放在 SD 卡上，按 home+power
重启到烧机模式，通过在菜单中选择之后烧写</p></li>
<li><p>编译源码时 update.zip 会生成在 out/target/product/xxxx/<br />
目录中（只有针对某硬件的才能生成，虚拟机版本没有，因为里面包含内核所在的
boot.img ，不针对硬件，不编内核），它是对整个系统的升级</p></li>
<li><p>update.zip 可以更新整个系统，或更新系统的一部分， update.zip
通常包含一个 update-script<br />
脚本，用以决定更新 zip 中的哪些部分到系统中，全部更换为更换 system,
userdata, boot<br />
个分区的全部内容，部分更新可以更新单个或多个系统中的文件</p></li>
</ol>
<p>3. fastboot</p>
<ol type="1">
<li><p>使用方法<br />
用数据线连接手机和电脑，按 camera+power 重启到工程模式，然后在 PC 端使用
android 开发包自带的 fastboot<br />
命令烧写</p></li>
<li><p>通常烧写 system.img, userdata.img ， boot.img 三个包，编译源码时
*.img 会生成在<br />
out/target/product/xxxx/ 目录中，只有针对某硬件的编译才能生成
boot.img.<br />
有时也烧写 recover.img ， recover.img 是烧机模式使用的系统</p></li>
</ol>
<p>4. 对比</p>
<ol type="1">
<li><p>系统生成 update.zip 中的 system 目录对应 fastboot 方法中的
system.img</p></li>
<li><p>系统生成 update.zip 中的 boot.img 对应 fastboot 目录中的
boot.img</p></li>
<li><p>update.zip 更灵活， fastboot 更稳定</p></li>
</ol>
<p>(转载请注明作者及出处 <a
href="http://xy0811.spaces.live.com">http://xy0811.spaces.live.com</a>
)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Ant编译Android</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E4%BD%BF%E7%94%A8Ant%E7%BC%96%E8%AF%91Android/</url>
    <content><![CDATA[<h1 id="使用ant编译android">使用Ant编译Android</h1>
<p>#移动开发 #android</p>
<p>（转载请注明出处: http://blog.csdn.net/xieyan0811）</p>
<p>使用Ant编译Android应用程序很方便，在Window和Linux下均可使用。尤其是将一个软件打成稍有差异的多个包时，非常实用。最近积累了一些小经验，下面分享一下：</p>
<h3 id="如何在linuxwindow上安装ant">1. 如何在Linux/Window上安装Ant|</h3>
<ol type="1">
<li><p>在Linux下直接用ant安装即可)</p>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    $ sudo apt-get install ant  </span><br><span class="line">	```  </span><br><span class="line">	  </span><br><span class="line">1) 在Windows下安装设置步骤如下（在XP及Win7可正常使用）  </span><br><span class="line">  </span><br><span class="line">a) 下载ant最新版本的二进制包    </span><br><span class="line">[ http://ant.apache.org/bindownload.cgi  </span><br><span class="line">](http://ant.apache.org/bindownload.cgi)    </span><br><span class="line">此包为压缩包，解包即可直接使用。  </span><br><span class="line">  </span><br><span class="line">b) 设置环境变量  </span><br><span class="line">  </span><br><span class="line">i. 我的电脑-&gt;右键-&gt;属性-&gt;高级-&gt;环境变量（Win7类似）  </span><br><span class="line">  </span><br><span class="line">ii. 在系统变量中加入ANT_HOME，设置为ant解压的目录，形如：    </span><br><span class="line">C:\Program Files\apache-ant-1.9.4  </span><br><span class="line">  </span><br><span class="line">iii. 在系统变量Path中加入Ant可执行程序路径，形如：    </span><br><span class="line">C:\Program Files\apache-ant-1.9.4\bin  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">###  2\. 如何为已存在的开发包建立ant编译环境  </span><br><span class="line">  </span><br><span class="line">（除Ant还需要安装JDK和Android  </span><br><span class="line">SDK，请参考http://wenku.baidu.com/link?url=NN8HYiTx7113MVK2KDDOHT3gRPLbLcFRCIg28UOrhnsI6_litOGKbuU5oAH1ubpMrS6JRtJacpjgl4sQD002lG2v8OE3RAw-  </span><br><span class="line">zgIq1tokHCK）  </span><br><span class="line">  </span><br><span class="line">1) 在Linux下执行（android程序在AndroidSDK的tools目录下）    </span><br><span class="line">  </span><br><span class="line">    ```  </span><br><span class="line">    android update project --name app_name -t 1 -p /home/xieyan/appsrcdir  </span><br><span class="line">	```  </span><br><span class="line">  </span><br><span class="line">2) 在Windows下执行（android.bat程序在AndroidSDK的tools目录下）    </span><br><span class="line">  </span><br><span class="line">    ```  </span><br><span class="line">    android.bat update project --name app_name -t 1 -p c:\xieyan\appsrcdir  </span><br><span class="line">	```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">###  3\. 如何自动签名生成Release包  </span><br><span class="line">  </span><br><span class="line">1) 在源码目录下，建立ant.properties文件，将签名信息写入其中，形如：    </span><br><span class="line">  </span><br><span class="line">    ```  </span><br><span class="line">    key.store=xxx/yyy.keystore  </span><br><span class="line">    key.alias=zzz.keystore  </span><br><span class="line">    key.store.password=123456  </span><br><span class="line">    key.alias.password=123456  </span><br><span class="line">	```  </span><br><span class="line">  </span><br><span class="line">2) 再运行antrelease，即可在bin目录下生成签名后的apk文件  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">###  4\. 如何设置和使用Ant中的变量  </span><br><span class="line">  </span><br><span class="line">1) 在ant.properties中可以设置Ant中使用的变量，其格式为name=value  </span><br><span class="line">  </span><br><span class="line">2) 也可以生成其它properties文件，在build.xml中使用以下命令包含该配置文件：    </span><br><span class="line">	```  </span><br><span class="line">	&lt;property file=”文件路径”/&gt;  </span><br><span class="line">	```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">###  5\. 如何扩展build.xml文件以添加更多方法，如何调用方法  </span><br><span class="line">  </span><br><span class="line">1)  </span><br><span class="line">在源码目录下建立custom_rules.xml，将自定义方法放在其中即可使用；也可以将自定义方法加入build.xml中，但由于更换编译环境，有时需要重新生成build.xml，新加入的方法就被覆盖了。  </span><br><span class="line">  </span><br><span class="line">2) custom_rules.xml同build.xml格式相同，形如：    </span><br><span class="line">  </span><br><span class="line">    ```  </span><br><span class="line">    &lt;project name=&quot;custom_rules&quot;&gt;  </span><br><span class="line">      &lt;target name=&quot;testme&quot;&gt;  </span><br><span class="line">        &lt;echo message=&quot;testtest!&quot; /&gt;  </span><br><span class="line">      &lt;/target&gt;  </span><br><span class="line">    &lt;/project&gt;  </span><br><span class="line">	```  </span><br><span class="line">  </span><br><span class="line">3) 此时使用ant testme，即可执行该方法，看到test test!的显示信息  </span><br><span class="line">  </span><br><span class="line">4) 在一个方法中调用另一个或多个方法，使用depends，形如：    </span><br><span class="line">  </span><br><span class="line">    ```  </span><br><span class="line">    &lt;target name=&quot;testme&quot; depends=”fun1,fun2”&gt;  </span><br><span class="line">	```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">###  6\. 如何在Ant中复制文件  </span><br><span class="line">  </span><br><span class="line">1) 先用delete删除原文件，再使用copy复制，形如：    </span><br><span class="line">  </span><br><span class="line">    ```  </span><br><span class="line">    &lt;delete file=&quot;res/drawable-hdpi/logo.png&quot;/&gt;  </span><br><span class="line">    &lt;copy file=&quot;xxx/logo.png&quot;  </span><br><span class="line">                         tofile=&quot;res/drawable-hdpi/logo.png&quot;/&gt;  </span><br><span class="line">	```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">###  7\. 如何在Ant中执行二进制程序  </span><br><span class="line">  </span><br><span class="line">1) 使用exec执行二进制程序，每个参数放在一个arg中，形如：    </span><br><span class="line">      </span><br><span class="line">    ```  </span><br><span class="line">    &lt;replaceregexp file=&quot;src/com/xxx/yyy/zzz.java&quot;  </span><br><span class="line">        match=&#x27;(.*)public static final StringXXX=(.*)&#x27;  </span><br><span class="line">        replace=&#x27;    public static final String XXX = &quot;$&#123;YYY&#125;&quot;;&#x27;  </span><br><span class="line">        byline=&quot;true&quot;/&gt;  </span><br><span class="line">	```  </span><br><span class="line"></span><br><span class="line">###  8\. 如何在源码中替换字符串  </span><br><span class="line">  </span><br><span class="line">1) 使用replaceregexp替换字符串，可使用通配符    </span><br><span class="line">  </span><br><span class="line">    ```  </span><br><span class="line">    &lt;replaceregexp file=&quot;src/com/xxx/yyy/zzz.java&quot;  </span><br><span class="line">        match=&#x27;(.*)public static final StringXXX=(.*)&#x27;  </span><br><span class="line">        replace=&#x27;    public static final String XXX = &quot;$&#123;YYY&#125;&quot;;&#x27;  </span><br><span class="line">        byline=&quot;true&quot;/&gt;  </span><br><span class="line">	```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">###  9\. 如何修改字体串及Window/Linux下中文乱码问题的解决  </span><br><span class="line">  </span><br><span class="line">1)  </span><br><span class="line">一般字符串定义在strings.xml中，它是一个xml文件，而replaceregexp中不能直接处理尖括号，需要使用转符；另外需要注意含有中文的文件，需要将编译指定为utf-8，形如：    </span><br><span class="line">  </span><br><span class="line">    ```      </span><br><span class="line">    &lt;replaceregexp encoding=&quot;utf-8&quot;file=&quot;res/values/strings.xml&quot;  </span><br><span class="line">        match=&#x27;(.*)string name=&quot;app_name&quot;(.*)&#x27;  </span><br><span class="line">        replace=&#x27;    &lt;string name=&quot;app_name&quot;&gt;$&#123;APP_NAME&#125;&lt;/string&gt;&#x27;  </span><br><span class="line">        byline=&quot;true&quot;/&gt;  </span><br><span class="line">	```  </span><br><span class="line">	  </span><br><span class="line">2)  </span><br><span class="line">上例中的APP_NAME是ant中定义的一个变量，中文可能产生乱码，如果直接写在build.xml或custom_rules.xml中，可用直接使用utf8字符，如果放在properties变量文件中，需要使用native2ascii进入编码转换。native2ascii是java工具，用于将本地字符转为ascii字符，因此其源数据文件(native)在不同系统中也需要使用不同编译，例如在linux下默认源编码为utf-8，在Windows下为gbk，如果想多平台通用，需要在使用native2ascii命令时加入  </span><br><span class="line">--encoding参数，形如：    </span><br><span class="line">  </span><br><span class="line">    ```  </span><br><span class="line">    &lt;target name=&quot;native2ascii&quot;&gt;  </span><br><span class="line">        &lt;delete file=&quot;$&#123;ascii_props&#125;&quot;/&gt;  </span><br><span class="line">        &lt;execexecutable=&quot;native2ascii&quot;&gt;  </span><br><span class="line">            &lt;argvalue=&quot;$&#123;native_props&#125;&quot;/&gt;  </span><br><span class="line">            &lt;argvalue=&quot;$&#123;ascii_props&#125;&quot;/&gt;  </span><br><span class="line">            &lt;argvalue=&quot;-encoding&quot;/&gt;  </span><br><span class="line">            &lt;argvalue=&quot;GBK&quot;/&gt;  </span><br><span class="line">        &lt;/exec&gt;  </span><br><span class="line">    &lt;/target&gt;  </span><br><span class="line">	```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">###  10\. 如何修改包名（形如：com.xxx.yyy）  </span><br><span class="line">  </span><br><span class="line">1)  </span><br><span class="line">修改包名，需要修改AndroidManifest.xml以及源码中各个java文件和xml文件，还需要先从AndroidManifest.xml中取到当前包名，以进行替换，形如：    </span><br><span class="line">  </span><br><span class="line">    ```  </span><br><span class="line">    &lt;target name=&quot;set-pkg&quot;&gt;  </span><br><span class="line">        &lt;xmlpropertyfile=&quot;AndroidManifest.xml&quot; collapseAttributes=&quot;true&quot; /&gt;  </span><br><span class="line">        &lt;propertyname=&quot;old_package_name&quot; value=&quot;$&#123;manifest.package&#125;&quot;/&gt;  </span><br><span class="line">        &lt;property name=&quot;new_package_name&quot;value=&quot;com.xxx.yyy&quot;/&gt;  </span><br><span class="line">      </span><br><span class="line">        &lt;deletedir=&quot;$&#123;build.bin&#125;&quot; /&gt;  </span><br><span class="line">        &lt;deletedir=&quot;$&#123;build.gen&#125;&quot; /&gt;  </span><br><span class="line">      </span><br><span class="line">        &lt;replaceregexpfile=&quot;AndroidManifest.xml&quot;  </span><br><span class="line">            match=&#x27;package=&quot;(.*)&quot;&#x27;  </span><br><span class="line">            replace=&#x27;package=&quot;$&#123;new_package_name&#125;&quot;&#x27;  </span><br><span class="line">            byline=&quot;false&quot;/&gt;  </span><br><span class="line">      </span><br><span class="line">        &lt;replaceregexpmatch=&quot;$&#123;old_package_name&#125;&quot;  </span><br><span class="line">            replace=&quot;$&#123;new_package_name&#125;&quot;  </span><br><span class="line">            byline=&quot;true&quot;&gt;  </span><br><span class="line">            &lt;filesetdir=&quot;$&#123;src&#125;&quot; includes=&quot;**/*.java&quot; /&gt;  </span><br><span class="line">        &lt;/replaceregexp&gt;  </span><br><span class="line">      </span><br><span class="line">        &lt;replaceregexpmatch=&quot;$&#123;old_package_name&#125;&quot;  </span><br><span class="line">            replace=&quot;$&#123;new_package_name&#125;&quot;  </span><br><span class="line">            byline=&quot;true&quot;&gt;  </span><br><span class="line">            &lt;filesetdir=&quot;$&#123;res&#125;&quot; includes=&quot;**/*.xml&quot; /&gt;  </span><br><span class="line">        &lt;/replaceregexp&gt;  </span><br><span class="line">    &lt;/target&gt;  </span><br></pre></td></tr></table></figure></p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Ant编译Android工程（Linux系统）</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E4%BD%BF%E7%94%A8Ant%E7%BC%96%E8%AF%91Android%E5%B7%A5%E7%A8%8B%EF%BC%88Linux%E7%B3%BB%E7%BB%9F%EF%BC%89/</url>
    <content><![CDATA[<h1
id="使用ant编译android工程linux系统">使用Ant编译Android工程（Linux系统）</h1>
<p>#移动开发 #android</p>
<p>一、问题<br />
同一套Android代码，希望通过配置文件的形式，制作成不同包名的多个package（多包名，多版本号，多市场logo，多广告商）。</p>
<p>二、解决方法<br />
使用Ant编译</p>
<p>三、Ant安装和使用</p>
<p>1. 环境：Ubuntu 10.04</p>
<p>2. 安装工具</p>
<ol type="1">
<li><p>安装jdk 1.6及android-sdk-linux-r15（见android
sdk相关文档）</p></li>
<li><p>安装ant 1.83版本<br />
由于android-sdk-linux-r15需要ant 1.8.0以上版本，在ubuntu
10.04上使用apt-<br />
get自动安装的版本太低，所以使用源码包安装方法</p></li>
</ol>
<ol type="a">
<li><p>下载<br />
ant最新版（当前为1.8.3）<br />
下载junit-4.9.jar包，ant编译时需要此包</p></li>
<li><p>安装<br />
** $ tar xvzf ../tgz/apache-ant-1.8.3-src.tar.gz<br />
$ cd apache-ant-1.8.3<br />
$ cp /usr/lib/jvm/java-6-sun/lib/junit-4.9.jar lib/optional/<br />
$ export JAVA_HOME=/usr/lib/jvm/java-6-sun<br />
$. build.sh<br />
$. build.sh install **</p></li>
</ol>
<p>3. 建立工程</p>
<ol type="1">
<li><p>列出目标平台ID<br />
** $ $ANDROID_SDK_DIR/tools/android list targets **</p></li>
<li><p>建立新的android工程（效果同使用eclipse新建android工程一致）<br />
** $ $ANDROID_SDK_DIR/tools/android create project –k 包名 –a 项目名 –t
目标平台<br />
ID –p 路径 **</p></li>
<li><p>编译工程<br />
** $ ant debug **<br />
此时在bin目录下生成相应的apk文件<br />
（jar包和so库都放在libs目录下即可被打入apk包，位置同android源码编译中位置一致）</p></li>
<li><p>在虚拟机中安装并运行<br />
** $ $ANDROID_SDK_DIR/tools/android list avd **<br />
列出所有的AVD<br />
** $ $ANDROID_SDK_DIR/tools/emulator –avd 指定 AVD 名称 **<br />
操作模拟器时，键盘F2对应菜单键，Home键对应设备的Home键<br />
** $ $ANDROID_SDK_DIR/platform-tools/adb install xxx.apk **<br />
在虚拟机中打开应用即可</p></li>
</ol>
<p>4. 对原有工程用ant编译</p>
<ol type="1">
<li><p>建立ant编译脚本build.xml<br />
** $ $ANDROID_SDK_DIR/tools/android update project --name 项目名 –t
目标平台 ID<br />
–p 路径 **</p></li>
<li><p>编译工程</p></li>
</ol>
<ol type="a">
<li><p>编译debug版本<br />
** $ ant debug **<br />
生成带debug签名的apk</p></li>
<li><p>生成release版本<br />
** $ ant release **<br />
生成带未签名的apk，之后手动签名即可<br />
编辑build.properties文件，其中指定签名相关资源，可自动签名</p></li>
</ol>
<p>5.
将一套代码通过简单配置自动生成多个apk包（此处只介绍最简单的方法）</p>
<ol type="1">
<li><p>原理<br />
使用 ** ant –f **
参数指定运行脚本，在该脚本中修改代码，资源，脚本的内容，然后再运行ant编译出相应的apk，原理和手动替换资源一样。</p></li>
<li><p>方法<br />
参见：http://bbs.chinaunix.net/thread-3637817-1-1.html</p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>典型应用之——将库打进apk</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8%E4%B9%8B%E2%80%94%E2%80%94%E5%B0%86%E5%BA%93%E6%89%93%E8%BF%9Bapk/</url>
    <content><![CDATA[<h1 id="典型应用之将库打进apk">典型应用之——将库打进apk</h1>
<p>#移动开发 #android</p>
<p>1. 介绍<br />
应用程序时常需要调用 C 库，并通过 apk 包安装到系统当中。我们可以通过 NDK
来安装库，如果你有源代码开发环境，可以通过<br />
Android.mk 脚本很简单地将 java 程序和 c 库放在一个项目中编译和安装。</p>
<p>2. 原理<br />
利用在 Android.mk 中加 LOCAL_JNI_SHARED_LIBRARIES 指定安装库</p>
<p>3. 例程</p>
<ol type="1">
<li><p>功能<br />
将加法用 c 语言实现，并编成 so 库，在 Java 层通过 JNI
方式调用它，并将界面和库打成一个 apk 包安装</p></li>
<li><p>可从此处下载可独立运行的代码<br />
<a
href="http://download.csdn.net/source/2841528">http://download.csdn.net/source/2841528<br />
</a></p></li>
<li><p>核心代码及说明</p></li>
</ol>
<ol type="a">
<li>java 程序<br />
</li>
</ol>
<pre><code>package com.android.mylib;    
    
import android.app.Activity;    
import android.os.Bundle;    
import android.widget.TextView;    
    
public class MyLibActivity extends Activity &#123;    
@Override    
public void onCreate(Bundle savedInstanceState) &#123;    
super.onCreate(savedInstanceState);    
    
TextView tv = new TextView(this);    
int x = 55;    
int y = 8;    
int z = 0;    
    
System.loadLibrary(&quot;test&quot;);  //  ** ** 装载  ** ** libtest.so  ** ** 库  ** **    
z = testme(x, y);  //  ** ** 调用  ** ** JNI    
tv.setText(x + &quot;+&quot; + y + &quot;=&quot; + z);    
setContentView(tv);    
&#125;    
    
public native int testme(int x, int y);  //  ** ** 声明  ** ** JNI    
&#125;    </code></pre>
<ol start="2" type="a">
<li>项层 Android.mk<br />
</li>
</ol>
<pre><code>LOCAL_PATH:= $(call my-dir)    
include $(CLEAR_VARS)    
    
LOCAL_MODULE_TAGS := user eng    
LOCAL_SRC_FILES := $(call all-subdir-java-files)    
LOCAL_PACKAGE_NAME := mylib    
LOCAL_JNI_SHARED_LIBRARIES := libtest  //  ** ** 安装库  ** **    
    
include $(BUILD_PACKAGE)    
include $(LOCAL_PATH)/jni/Android.mk  //  ** ** 调用库的编译  ** **    
include $(call all-makefiles-under,$(LOCAL_PATH))  **  </code></pre>
<ol start="3" type="a">
<li>jni 程序 （ C 程序实现 ）<br />
</li>
</ol>
<pre><code>#include  &lt;jni.h&gt;    
    
JNIEXPORT jint JNICALL Java_com_android_mylib_MyLibActivity_testme    
(JNIEnv *env, jobject obj, jint x, jint y) &#123; // JNI  ** ** 的实现  ** **    
return x + y;    
&#125;    
  </code></pre>
<ol start="4" type="a">
<li>jni 层 Android.mk<br />
</li>
</ol>
<pre><code>LOCAL_PATH := $(call my-dir)    
include $(CLEAR_VARS)    
    
|LOCAL_MODULE_TAGS := user eng    
LOCAL_MODULE := libtest    
    
LOCAL_SRC_FILES := jnitest.c    
LOCAL_C_INCLUDES += /    
$(JNI_H_INCLUDE)    
LOCAL_PRELINK_MODULE := false    
    
include $(BUILD_SHARED_LIBRARY) //  ** ** 编译  ** ** so  ** ** 库  **  </code></pre>
<ol start="4" type="1">
<li>执行结果<br />
安装 apk 包后 ， 用 adb shell 进入手机系统 ， 然后<br />
</li>
</ol>
<pre><code>ls /data/data/com.android.mylib/lib/  </code></pre>
<p>可以看到库被安装到此处</p>
<p>2. 注意<br />
对库进行调试不能 adb install -r, 要先 uninstall, 否则有时覆盖不了库</p>
<p>3. 参考</p>
<ol type="1">
<li>c 回调 java 函数 , 可参数<br />
<a
href="http://blog.sina.com.cn/s/blog_4b650d650100lw43.html">http://blog.sina.com.cn/s/blog_4b650d650100lw43.html<br />
</a></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>典型应用之——将数据打进apk</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8%E4%B9%8B%E2%80%94%E2%80%94%E5%B0%86%E6%95%B0%E6%8D%AE%E6%89%93%E8%BF%9Bapk/</url>
    <content><![CDATA[<h1 id="典型应用之将数据打进apk">典型应用之——将数据打进apk</h1>
<p>#移动开发 #android</p>
<p>1. 介绍<br />
需要安装一些资源到系统中，比如多媒体文件，配置文件或者某种数据文件，可以把它打包放在资源
raw 目录中，然后在程序中读取解包，并安装在指定目录下</p>
<p>2. android 框架对多媒体的支持<br />
apk 包中的数据一般都放在 res/raw 目录下，只有它的拥有者能通过
openRawResourceFd 的方式访问，如果不在 java<br />
层访问，或者要将其安装在其它位置，就需要在 java 程序中对其进行处理</p>
<p>3. 例程</p>
<ol type="1">
<li><p>功能<br />
把多媒体及数据文件打在 zip 包放在 res/raw 下，并将其打在安装包 apk
中，在程序中点击按钮时将其安装在指定目录下</p></li>
<li><p>可从此处下载可独立运行的代码<br />
<a
href="http://download.csdn.net/source/2841538">http://download.csdn.net/source/2841538<br />
</a></p></li>
<li><p>核心代码及说明<br />
** package com.android.mydata;</p></li>
</ol>
<p>import android.app.Activity;<br />
import android.os.Bundle;<br />
import android.widget.Button;<br />
import android.widget.TextView;<br />
import android.content.res.AssetFileDescriptor;<br />
import android.content.res.Resources;<br />
import android.view.View.OnClickListener;<br />
import android.view.View;</p>
<p>import java.io.File;<br />
import java.io.FileOutputStream;<br />
import java.io.IOException;<br />
import java.io.InputStream;<br />
import java.util.zip.ZipEntry;<br />
import java.util.zip.ZipInputStream;</p>
<p>public class MyDataActivity extends Activity {<br />
String rootDirectory = "/data/data/com.android.mydata/data/"; // ** **
安装的目录<br />
** **<br />
TextView status;</p>
<p><span class="citation" data-cites="Override">@Override</span><br />
public void onCreate(Bundle savedInstanceState) {<br />
super.onCreate(savedInstanceState);<br />
setContentView(R.layout.main);<br />
Button btn = (Button) findViewById(R.id.button);<br />
status = (TextView) findViewById(R.id.status);<br />
btn.setText("install"); // ** ** 点击此按钮开始安装 ** **<br />
status.setText("wait...");<br />
btn.setOnClickListener(new OnClickListener() {<br />
public void onClick(View v) {<br />
unpack();<br />
status.setText("okey...");<br />
}<br />
});<br />
}</p>
<p>boolean unpack() {<br />
FileOutputStream out;<br />
byte buf[] = new byte[16384];<br />
try {<br />
Resources res = getResources(); // ** ** 获得资源句柄 ** **<br />
AssetFileDescriptor fd = res.openRawResourceFd(R.raw.test); // ** **
压缩文件为<br />
** ** test.zip<br />
InputStream stream = fd.createInputStream();<br />
ZipInputStream zis = new ZipInputStream(stream);<br />
ZipEntry entry = zis.getNextEntry();<br />
while (entry != null) {<br />
if (entry.isDirectory()) { // ** ** 对文件夹处理 ** **<br />
File newDir = new File(rootDirectory + entry.getName());<br />
newDir.mkdir();<br />
} else { // ** ** 对文件处理 ** **<br />
String name = entry.getName();<br />
File outputFile = new File(rootDirectory + name);<br />
String outputPath = outputFile.getCanonicalPath();<br />
name = outputPath<br />
.substring(outputPath.lastIndexOf("/") + 1);<br />
outputPath = outputPath.substring(0, outputPath<br />
.lastIndexOf("/"));<br />
File outputDir = new File(outputPath);<br />
outputDir.mkdirs();<br />
outputFile = new File(outputPath, name);<br />
outputFile.createNewFile();<br />
out = new FileOutputStream(outputFile);</p>
<p>int numread = 0;<br />
do {<br />
numread = zis.read(buf);<br />
if (numread &lt;= 0) {<br />
break;<br />
} else {<br />
out.write(buf, 0, numread);<br />
}<br />
} while (true);<br />
out.close();<br />
}<br />
entry = zis.getNextEntry();<br />
}<br />
return true;<br />
} catch (IOException e) {<br />
e.printStackTrace();<br />
return false;<br />
}<br />
}<br />
} **</p>
<ol start="4" type="1">
<li>注意：打包数据不能太小， 否则会出错。数据打包使用如下命令<br />
zip -r ../test.zip *</li>
</ol>
<p>4. 参考</p>
<ol type="1">
<li><p>源代码语音合成 external/svox/picolanginstaller
对语音数据的安装</p></li>
<li><p><a
href="http://cnmsdn.com/html/201010/1287296527ID8341.html">http://cnmsdn.com/html/201010/1287296527ID8341.html<br />
</a></p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>半小时搞定Arduino环境（含蓝牙模块与Android通讯）</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E5%8D%8A%E5%B0%8F%E6%97%B6%E6%90%9E%E5%AE%9AArduino%E7%8E%AF%E5%A2%83%EF%BC%88%E5%90%AB%E8%93%9D%E7%89%99%E6%A8%A1%E5%9D%97%E4%B8%8EAndroid%E9%80%9A%E8%AE%AF%EF%BC%89/</url>
    <content><![CDATA[<h1
id="半小时搞定arduino环境含蓝牙模块与android通讯">半小时搞定Arduino环境（含蓝牙模块与Android通讯）</h1>
<p>#移动开发 #android</p>
<h3 id="我的硬件">1. 我的硬件</h3>
<p>Arduino UNO R3，蓝牙模块，电脑（ubuntu 12.04），手机（Android）</p>
<h3 id="下载软件">2. 下载软件</h3>
<p>由于用apt-get在ubuntu中安装的arduino软件可能版本过低，没有相应硬件对应的设置，所以请在arduino网站下载最新软件<br />
http://arduino.cc/en/Main/Software#.UyfR0ZFGeBs</p>
<h3 id="电脑连接arduino">3. 电脑连接arduino</h3>
<p>连好线，打开arduino软件<br />
设置：菜单-&gt;Tools-&gt;Board-&gt;Arduino Uno<br />
设置：菜单-&gt;Tools-&gt;Serial port-&gt;/dev/ttyACM0</p>
<h4 id="调试简单程序">4. 调试简单程序</h4>
<p>写界面中输入程序<br />
void setup() { // put your setup code here, to run once:<br />
Serial.begin(9600);<br />
}<br />
void loop() {<br />
// put your main code here, to run repeatedly:<br />
Serial.println("hello");<br />
}<br />
点工具栏上的对勾：开始编译<br />
点工具栏上右键头：把程序安装到开发板<br />
点工具栏右上角的放大镜：看到程序执行后的打印信息</p>
<h3 id="通过蓝牙连接手机和arduino">5. 通过蓝牙连接手机和Arduino</h3>
<ol type="a">
<li><p>接线<br />
VCC：接Arduino的5V<br />
GND：接Arduino的GND<br />
TXD：发送端，一般表示为自己的发送端，接Arduino的RX<br />
RXD：接收端，一般表示为自己的接收端，接Arduino的TX。</p></li>
<li><p>写Arduino端程序<br />
void setup()<br />
{<br />
Serial.begin(9600);<br />
}</p></li>
</ol>
<p>void loop()<br />
{<br />
while(Serial.available())<br />
{<br />
char c=Serial.read();<br />
if(c=='A')<br />
{<br />
Serial.println("Hello I am amarino");<br />
}<br />
}<br />
}<br />
把程序安装到Ardunio开发板时，请先断开蓝牙模块，因为它们的数据都走串口，会引起冲突造成安装失败。<br />
c) 手机安装对应软件<br />
http://amarino.googlecode.com/files/Amarino_2_v0_55.apk<br />
在手机设置中打开蓝牙，然后点击应用左下角的Add BT<br />
Device，选定自己的蓝牙模块，密码为1234，连接后点击右下边的Monitoring，点Send即可。<br />
d) 参考文档<br />
http://www.bhubbs.com/thread-1055-1-1.html</p>
<p><img
src="https://img-%20blog.csdn.net/20140318193311953?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlleWFuMDgxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" /></p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>华为手机安装英文TTS</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E5%8D%8E%E4%B8%BA%E6%89%8B%E6%9C%BA%E5%AE%89%E8%A3%85%E8%8B%B1%E6%96%87TTS/</url>
    <content><![CDATA[<h1 id="华为手机安装英文tts">华为手机安装英文TTS</h1>
<p>#移动开发 #android</p>
<p>想读个英文文档，用讯飞读英文，效果实在是……</p>
<p>在应用汇下载安装 Google
TTS（华为软件商店里没有），软件被安装到系统中，位置在：</p>
<p>设置-&gt;智能辅助-&gt;无障碍-&gt;文字转语言(TTS)输出-&gt;Google文字转语音引擎。</p>
<p>就可以正常使用了。</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>华为手机开启adb调试模式</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E5%8D%8E%E4%B8%BA%E6%89%8B%E6%9C%BA%E5%BC%80%E5%90%AFadb%E8%B0%83%E8%AF%95%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="华为手机开启adb调试模式">华为手机开启adb调试模式</h1>
<p>#移动开发 #android</p>
<p>手机 Honor 6x，界面版本 EMUI 8.0.0</p>
<p>1. 在设置-&gt;系统-&gt;关于手机，连续按几次"版本号" (注意:
在学生模式下不能使用)</p>
<p>2. 退到上一层，出现“开发人员选项”（与“关于手机”并列）</p>
<p>3.
选中“开发者选项”，选中“仅充电模式下允许ADB调式”，选中”USB调试“（注意先后顺序不能变）</p>
<p>4. 在Ubuntu 16.04中安装adb工具：</p>
<pre><code>sudo apt-get install android-tools-adb  </code></pre>
<p>5. 连接：</p>
<pre><code>$ sudo adb shell  </code></pre>
<p>6. 如果还不成功，请参考：</p>
<p>Ubuntu16.04配置ADB调试环境<br />
https://blog.csdn.net/u012351661/article/details/78201040</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>如何关闭Android手机上网流量</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E5%A6%82%E4%BD%95%E5%85%B3%E9%97%ADAndroid%E6%89%8B%E6%9C%BA%E4%B8%8A%E7%BD%91%E6%B5%81%E9%87%8F/</url>
    <content><![CDATA[<h1 id="如何关闭android手机上网流量">如何关闭Android手机上网流量</h1>
<p>#移动开发 #android</p>
<p>前几天我爸买了一个Android手机，刚用第一天，就收到短信说手机余额不足十元，我爸吓了一跳，赶快关机了。他跟我说：“你把这流量给我关了吧”，我说“要是关了，手机报彩信就收不着了？”“没有我不要了，这太费钱了！”我二大爷也遇上同样情况，去营业厅把上网业务全给关了；今天又听说我们邻居张老师，也是Android手机，不到一天手机里一百多块钱都被扣没了，又换回原来的手机用了，反正他们说什么也不想再试了。</p>
<p>随着智能手机的普及，中老年人遇到这种问题的还真不少。流量可以关！不就是设置一下吗？还用写文档？但我也不能挨家帮他们关！还是写出来吧，可能对他们有用。</p>
<p>为什么这么费钱？原因是这样的：智能手机有些软件有上网功能，有些软件是自动更新的，几M流量对于下载软件来说，根本不算什么。以移动资费为例，没办套餐1M十元，最便宜的套餐5元/月可用30M流量（即1M一毛七分钱），超出30M部分1M一元，这样使用套餐前后价格就差了60倍！</p>
<p>彩信和用手机上网，使用的其实不是同一个接入点。也就是说，可以通过设置，让手机只能收发彩信，而关闭其它的GPRS上网功能，以节约流量。设置方法如下：在Android系统中，进入设置-&gt;无线和网络-&gt;移动网络-&gt;接入点名称，进入cmnet相关项，删除其中的有用信息即可（这样就切断了GPRS上网的途径）。在Android4.0系统中，进入设置-&gt;无线和网络-&gt;更多-&gt;移动网络-&gt;接入点名称-&gt;进入cmnet相关项，删除其中的有用信息即可。注意设置后最好重启手机，否则很可能设置不能生效。当然，建议删除之前先备份其中内容，以防之后想使用GPRS上网功能，却不知道怎么设回去了（当然网上很容易查到设置方法）。</p>
<p>我一般用手机上网都连家里的WIFI，这样不用花钱。偶尔在外面看看微博什么的，就申请了每月十块钱70M的流量，很少用超。后来我给我爸的手机申请了5元/月的30M流量套餐（发送KTSJLL5到10086，在北京使用正常，其它地方没试过，也可以打10086转人工），然后删除了cmnet上网设置，流量就没再出问题了，能正常收发彩信。建议再安装手机版的360手机卫士，这样就可以看到是哪个软件使用了流量？随时查看本月流量的使用情况。</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>常用的android软件列表（apk包）</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E5%B8%B8%E7%94%A8%E7%9A%84android%E8%BD%AF%E4%BB%B6%E5%88%97%E8%A1%A8%EF%BC%88apk%E5%8C%85%EF%BC%89/</url>
    <content><![CDATA[<h1 id="常用的android软件列表apk包">常用的android软件列表（apk包）</h1>
<p>#移动开发 #android</p>
<p>1. 常用的 android 软件列表（ apk 包）</p>
<ol type="1">
<li><p>手写输入法<br />
<a
href="http://www.kuruan.net/soft/zikushuru/2009-08-25/1745.html">http://www.kuruan.net/soft/zikushuru/2009-08-25/1745.html<br />
</a></p></li>
<li><p>拼音输入法<br />
<a
href="http://www.kuruan.net/soft/zikushuru/2009-06-28/309.html">http://www.kuruan.net/soft/zikushuru/2009-06-28/309.html<br />
</a></p></li>
<li><p>Office 办公套件<br />
<a
href="http://www.kuruan.net/soft/bangongshangwu/2009-10-21/3111.html">http://www.kuruan.net/soft/bangongshangwu/2009-10-21/3111.html<br />
</a></p></li>
<li><p>金山词霸<br />
<a
href="http://www.kuruan.net/soft/dushuxuexi/2010-02-28/5191.html#edown">http://www.kuruan.net/soft/dushuxuexi/2010-02-28/5191.html#edown<br />
</a></p></li>
<li><p>文件管理器<br />
<a
href="http://www.kuruan.net/soft/xitongyingyong/2010-04-02/5567.html#edown">http://www.kuruan.net/soft/xitongyingyong/2010-04-02/5567.html#edown<br />
</a></p></li>
<li><p>注意<br />
以上软件有些需要把 zip 改名为 apk 后安装，有些 zip 要解开后目录中有 apk
文件 , 根据文件内容不同处理方式也不同</p></li>
</ol>
<p>米乐手机软件</p>
<p><a
href="http://www.milcn.com/shouji/soft/Android/xitong/2010/0503/11764.html">http://www.milcn.com/shouji/soft/Android/xitong/2010/0503/11764.html<br />
</a></p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>建立AndroidSDK开发环境</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E5%BB%BA%E7%AB%8BAndroidSDK%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h1 id="建立android-sdk开发环境">建立Android SDK开发环境</h1>
<p>#移动开发 #android</p>
<p>建立 SDK 开发环境</p>
<p>一、 系统平台<br />
Linux 系统： ubuntu 8.04 ，最好用 ubuntu
系统，否则可能遇到缺少库，编译器版本不对等一系列问题，安装和使用详见文档《<br />
ubuntu 系统的使用》</p>
<p>二、 安装 JDK</p>
<p>1. 为什么使用 JDK<br />
用以支持 Android 和 Eclipse ： Android 中的应用都是 java 程序，所以想在
Linux 上建立开发<br />
Android 环境，就需要安装 java 虚拟机</p>
<p>2. 安装方法</p>
<p>使用 ubuntu 安装包<br />
$ sudo apt-get install sun-java6-bin</p>
<p>4. 测试是否安装成功<br />
$ java -version</p>
<p>三、 安装 Android SDK</p>
<p>1. 为什么使用 Android SDK<br />
Android SDK 包含 创建和运行 Android
应用程序所需的一切，包括设备仿真器和高级调试工具，如果你只想看看
Android<br />
运行起来什么样，那只安装它就可以</p>
<p>2. 安装</p>
<ol type="1">
<li><p>注意选择你所使用平台和硬件对应的版本<br />
平台 windows, linux, mac<br />
版本 1.0, 1.5, 1.6…</p></li>
<li><p>下载<br />
打开网页 <a
href="http://code.google.com/android/download_list.html">http://code.google.com/android/download_list.html<br />
</a><br />
下载 android-sdk-linux_x86-1.0_r1.zip</p></li>
<li><p>安装<br />
$ unzip ../recv/android-sdk-linux_x86-1.0_r1.zip<br />
无需编译，解开就能运行</p></li>
</ol>
<p>3. 运行<br />
$ cd android-sdk-linux_x86-1.0_r1/tools<br />
$ ./emulator -datadir ../../ // datadir
是一个必须存在的目录，用来存放数据<br />
耐心等待，特别特别的慢，看到主菜单大概要三四分钟，请注意，安装到这一步，
android 就能在你的 Linux 系统中运行了</p>
<p>4. 设置路径<br />
$ export
PATH=$PATH:/exports/android/test/android-sdk-linux_x86-1.0_r1/tools<br />
最好把环境变量的设置加入 $USER/.bashrc 脚本中</p>
<p>5. 创建并使用模拟的 500M SD 卡<br />
$ ./mksdcard -l SD500M 500M ../../sd500m.img 建立虚拟 SD
卡的映像文档<br />
$ ./emulator -sdcard ../../sd500m.img -datadir ../../</p>
<p>6. 缩放屏幕 0.5 倍<br />
$ ./emulator -scale 0.5 -datadir ../../</p>
<p>7. SDK 目录结构</p>
<ol type="1">
<li><p>Add-ons<br />
扩展的第三方库所在目录（如现在所放的地图库）</p></li>
<li><p>Docs ， documention.html<br />
本地和网上提供的 SDK 文档</p></li>
<li><p>Platforms<br />
含 1.1 和 1.5 两种 SDK<br />
Samples 其中含示例代码<br />
android.jar 为 java 打包文件，其中包含构建应用程序的所有 Android SDK
类</p></li>
<li><p>Tools<br />
构建应用程序的命令行工具（ adb, emulator… ）</p></li>
<li><p>Usb_driver<br />
Android （ G1 ）设备连接计算机后所需的驱动程序，只有 Window 平台需要，
Linux 平台可以自动识别</p></li>
</ol>
<p>四、 安装 eclipse</p>
<p>1. 为什么使用 eclipse<br />
eclipse 是一个基于 java
的开发平台，它是一个框架，通过安装插件构建开发环境， java 就是它的插件，
android<br />
也是一组插件，我们利用它用发和调试运行在 android 上的程序</p>
<p>2. 安装</p>
<ol type="1">
<li><p>下载<br />
打开网页 <a
href="http://www.eclipse.org/downloads/">http://www.eclipse.org/downloads/<br />
</a><br />
下载 Eclipse IDE for Java EE Developers</p></li>
<li><p>解压<br />
tar xvzf ../download/eclipse-jee-ganymede-SR1-linux-gtk.tar.gz</p></li>
<li><p>运行<br />
cd eclipse<br />
./eclipse<br />
使用默认的 workspace 就可以了</p></li>
</ol>
<p>3. 安装 android 的 eclipse 插件</p>
<ol type="1">
<li><p>在 eclipse 中点击菜单 Help-&gt;Software Updates ……</p></li>
<li><p>切换到 Available Software 标签，点 Add Site ……按钮</p></li>
</ol>
<p>_ 3) _ 在弹出的对话框里输入 _ <a
href="https://dl-ssl.google.com/android/eclipse/">https://dl-ssl.google.com/android/eclipse/<br />
</a> _ _ ，然后按 _ _ OK _</p>
<ol start="4" type="1">
<li>选项新出新的 Developer tools 然后点 Install ……</li>
</ol>
<ol type="a">
<li><p>Android Developer Tools</p></li>
<li><p>Android DDMS （ Dalvik Debug Monitor Service ）<br />
查看线程，堆栈，内存占用，广播，虚拟 GPS 坐标等</p></li>
</ol>
<ol start="5" type="1">
<li><p>点 Next ，然后 Finish</p></li>
<li><p>重新启动 Eclipse 后生效</p></li>
</ol>
<p>4. 指定 Android SDK 对应的目录</p>
<ol type="1">
<li><p>在 eclipse 中点击菜单 Window- &gt;Preferences</p></li>
<li><p>左侧选 Android ，右侧选 Browse ……，指定你 android SDK
的安装目录</p></li>
<li><p>点击 Apply ，然后点 OK</p></li>
</ol>
<p>五、 配置 AVD （ Android Virtual Device ）</p>
<p>1. 用于配置一些模拟器的特性：模拟器影像大小 / 触摸屏 / 轨迹球 /
摄像头 / 屏幕分辨率 / 键盘 /GSM<br />
/GPS/Audio 录放 /SD 卡支持 / 缓存区大小等</p>
<p>2. 如果用 SDK1.5 可能出现提示让你建立 AVD<br />
Name:AVD1.5<br />
Target: Android 1.5 - 1.5<br />
SDCard: 64M<br />
点 Create AVD<br />
然后再点 finish 即可</p>
<p>六、 第一个 android 程序</p>
<p>1. 建立 project</p>
<ol type="1">
<li><p>在 eclipse 中点击菜单 File-&gt;New-&gt;Project ……</p></li>
<li><p>选择 Android Project 按 Next</p></li>
<li><p>填写 project 的各项内容如下<br />
Project name: test_xy 目录名 , 它位于你设定的 workspace 之下<br />
Package name: com.android.test 打包名称<br />
Activity name: TestXy 类名 ( 生成文件 TestXy.java)<br />
Application name: test_app_name 可执行程序名<br />
然后点 Finish 按钮</p></li>
</ol>
<p>2. 填写代码<br />
这时可以看到代码界面了，从左边的树中打开代码<br />
test_xy à src à com.android.testxy à _ TestXy.java _ _ à _ _ TestXy
_<br />
_ à _ _ onCreate _<br />
修改其中代码(不改也行)</p>
<p>3. 运行</p>
<ol type="1">
<li><p>在 eclipse 中点击菜单 Run- &gt;Run Configurations ……</p></li>
<li><p>双击左边的 Android Application ，产生了一个 New Configuration
，点开它填写内容如下：<br />
Name: yan_config // 随便起一个<br />
Project: test_xy // 刚才起的 project, 即目录名</p></li>
<li><p>点击 Apply ，然后点 Run ，多等一会儿就出来了</p></li>
</ol>
<p><a
href="http://whereq.blogspot.com/2008/11/android-emulator-how-to.html"></a></p>
<p><a
href="http://whereq.blogspot.com/2008/11/android-emulator-how-to.html"></a></p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>建立Android源码开发环境</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E5%BB%BA%E7%AB%8BAndroid%E6%BA%90%E7%A0%81%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h1 id="建立android源码开发环境">建立Android源码开发环境</h1>
<p>#移动开发 #android</p>
<p>Android 源码的编译</p>
<p>一、 配置环境</p>
<p>1. 磁盘<br />
需要 6G 以上剩余空间</p>
<p>2. Linux 系统</p>
<p>Ubuntu 6.06 以上版本，我用的是 buntu 8.04 ，具体请见下篇文档《 ubuntu
系统的使用》</p>
<p>3. Git 工具 (Git 1.5.4 以上版本 )<br />
它是类似 CVS
的版本管理工具，如果你的代码不用从网上下载，而是从别人处复制，则无需此工具<br />
$ sudo apt-get install git-core gnupg</p>
<p>4. Java 环境 (JDK 5.0 update12 以上版本 )<br />
$ sudo apt-get install sun-java6-jdk<br />
具体安装请见上篇文档《 Android 环境的搭建》</p>
<p>5. Python (Python 2.4 以上版本 )<br />
从 <a
href="http://www.python.org/download/下载2.4">http://www.python.org/download/
下载 2.4<br />
</a> 以上版本<br />
$ tar xvzf python-2.4.5.tgz<br />
$ cd python-2.4.5/<br />
$ ./configure<br />
$ make; make install</p>
<p>6. 依赖的 deb 包<br />
$ sudo apt-get install flex bison gperf libsdl-dev libesd0-dev
libwxgtk2.6-dev<br />
build-essential zip curl<br />
其中 flex bison build-essential zip curl 可以从光盘安装<br />
其余 gperf libsdl-dev libesd0-dev libwxgtk2.6-dev
需要从网上安装，它们还依赖一些安装包，所以要用<br />
apt-get 下载，不要直接下 deb 包安装</p>
<p>7. 调试工具<br />
$ sudo apt-get install valgrind</p>
<p>二、 下载及编译运行 android 源码</p>
<p>1. 下载安装脚本<br />
$ wget <a
href="http://android.git.kernel.org/repo">http://android.git.kernel.org/repo<br />
</a><br />
$ chmod 777 repo<br />
$ cp repo /bin/</p>
<p>2. 用安装脚本下载源码<br />
$ mkdir android_code<br />
$ cd android_code<br />
$ repo init -u git://android.git.kernel.org/platform/manifest.git<br />
$ repo sync<br />
以上命令是下载最新版本，也可以下载其它版本<br />
如我买的手机，在设置 -&gt; 关于手机 -&gt; 固件版本中看到是 1.5
，所以下载 1.5 版本，方法如下<br />
$ repo init -u git://android.git.kernel.org/platform/manifest.git
-b<br />
android-1.5r3<br />
$ repo sync // 此后会长时间下载</p>
<p>3. 编译</p>
<ol type="1">
<li><p>正常编译<br />
$ cd android_code<br />
$ make<br />
映像编译成功后会在目录 android_code/src/out/target/product/generic
下产生一些 image 文件：<br />
ramdisk.img system.img userdata.img</p></li>
<li><p>可能出现的 问题及解决方法</p></li>
</ol>
<p>1. make 若提示找不到 -lncurses ，则需要做以下链接<br />
ln –s /lib/libncurses.so.5 /lib/libncurses.so</p>
<p>2. make 若提示找不到 run-java-tool ，则需要设置 java 的安装路径<br />
$ export ANDROID_JAVA_HOME=$JAVA_HOME</p>
<p>3. 若提提示找不到 zlib.h, 则运行如下命令安装 zlib 开发包<br />
$ sudo apt-get install zlib1g-dev</p>
<p>4. 下了一个最新版本后显示说只能使用 java-1.5 版本，于是从 1.6
版本降回 1.5<br />
$ sudo apt-get install sun-java5-jdk flex<br />
$ sudo update-java-alternatives -s java-1.5.0-sun</p>
<p>5. 如果报错 "compression requires the missing zlib module" 可能是
python 找不到<br />
zlib 库<br />
这时需要先安装 zlib 库 , 然后重编 python, 并取代当前版本 python<br />
$ sudo apt-get install zlib1g-dev<br />
$ python2.6 --version<br />
可看到当前版本 , 下载当前版本 , 重新编译安装<br />
$ tar xvzf python-2.6.2.tgz<br />
$ cd python-2.6.2/<br />
$ ./configure --prefix=/usr/local<br />
$ make; make install</p>
<ol start="3" type="1">
<li><p>编译 sdk<br />
$ make sdk<br />
此时 SDK 产生于此目录下： android_code/out/host/linux-x86/sdk/<br />
此包如同下载的 sdk 包，可供 eclipse
使用，注意把它移动其它位置使用，否则一编译其它应用，它就被删除掉了</p></li>
<li><p>编译不同 Android 硬件平台对应版本<br />
需要在 make 前先针对设备进行设置，形如：<br />
$ choosecombo 1 1 8 3<br />
使用不同参数，编译结果存存储的目录不同<br />
默认包生成目录：
android_code/out/target/product/qsd8250_surf/system/app/<em>.apk<br />
以上选项包生成目录：
android_code/out/target/product/generic/system/app/</em>.apk</p></li>
</ol>
<p>4. 运行</p>
<ol type="1">
<li><p>运行普通的虚拟器 emulator<br />
emulator 的路径是：<br />
/home/xieyan/bin/android_code/out/ host/linux-x86/bin/emulator<br />
设置环境变量 export PATH=$PATH:android_src/out/host/linux-x86/bin<br />
$ . build/envsetup.sh<br />
$ partner_setup<br />
$ emulator</p></li>
<li><p>指定 img 运行<br />
$ export<br />
ANDROID_PRODUCT_OUT=/home/xieyan/bin/android_code/out/target/product/generic<br />
$ emulator -image system.img -data userdata.img -ramdisk
ramdisk.img</p></li>
</ol>
<p>三、 常用的源码文件</p>
<p>1. frameworks/base/core/java/android/widget/ 下边<br />
Android 系统控件的实现</p>
<p>2. package/apps<br />
普通应用程序的实现</p>
<p>3. out/target/product/generic/system/apps/*.apk<br />
安装包生成的位置</p>
<p>四、 参考</p>
<p>1. 官方网站的安装说明<br />
<a
href="http://source.android.com/download">http://source.android.com/download</a></p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>用Ant打Android的三方jar包_可包含各种资源</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E7%94%A8Ant%E6%89%93Android%E7%9A%84%E4%B8%89%E6%96%B9jar%E5%8C%85_%E5%8F%AF%E5%8C%85%E5%90%AB%E5%90%84%E7%A7%8D%E8%B5%84%E6%BA%90/</url>
    <content><![CDATA[<h1
id="用ant打android的三方jar包_可包含各种资源">用Ant打Android的三方jar包_可包含各种资源</h1>
<p>#移动开发 #android</p>
<p>有时候需要把部分功能编成Jar包，以便多个工程共用。</p>
<p>一般情况下，用ant生成的jar包只能带编译后的class文件，而其中用到的res资源，assets,
libs下的资源都编不进去。</p>
<p>使用eclipse的exports可以导出jar包，但是每次都要取消一些不用的文件，生成一次操作半天。</p>
<p>用以下脚本可以实现该功能，其原理是：Jar文件本来就是一个zip格式的压缩包，把你需要的东西都放里面，然后打包即可，而Ant就帮我们做了这件事.</p>
<pre><code><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;project default=&quot;build&quot; &gt;  </span><br><span class="line">  </span><br><span class="line">    &lt;property  </span><br><span class="line">        name=&quot;project.dir&quot;  </span><br><span class="line">        value=&quot;.&quot; /&gt;  </span><br><span class="line">  </span><br><span class="line">    &lt;property  </span><br><span class="line">        name=&quot;makejar.dir&quot;  </span><br><span class="line">        value=&quot;$&#123;project.dir&#125;/markjar&quot; /&gt;  </span><br><span class="line">  </span><br><span class="line">    &lt;target name=&quot;build&quot; &gt;  </span><br><span class="line">  </span><br><span class="line">        &lt;mkdir dir=&quot;$&#123;makejar.dir&#125;&quot; /&gt;  </span><br><span class="line">  </span><br><span class="line">        &lt;copy  </span><br><span class="line">            file=&quot;AndroidManifest.xml&quot;  </span><br><span class="line">            todir=&quot;$&#123;makejar.dir&#125;&quot; /&gt;  </span><br><span class="line">  </span><br><span class="line">        &lt;copy todir=&quot;$&#123;makejar.dir&#125;&quot; &gt;  </span><br><span class="line">  </span><br><span class="line">            &lt;fileset  </span><br><span class="line">                dir=&quot;.&quot;  </span><br><span class="line">                includes=&quot;res/**&quot; /&gt;  </span><br><span class="line">  </span><br><span class="line">            &lt;fileset  </span><br><span class="line">                dir=&quot;.&quot;  </span><br><span class="line">                includes=&quot;assets/**&quot; /&gt;  </span><br><span class="line">  </span><br><span class="line">            &lt;fileset  </span><br><span class="line">                dir=&quot;.&quot;  </span><br><span class="line">                includes=&quot;libs/**&quot; /&gt;  </span><br><span class="line">        &lt;/copy&gt;  </span><br><span class="line">  </span><br><span class="line">        &lt;jar destfile=&quot;bin/ok.jar&quot; &gt;  </span><br><span class="line">  </span><br><span class="line">            &lt;fileset  </span><br><span class="line">                dir=&quot;bin/classes&quot;  </span><br><span class="line">                excludes=&quot;**/R.class,**/R$*.class&quot; /&gt;  </span><br><span class="line">  </span><br><span class="line">            &lt;fileset dir=&quot;$&#123;makejar.dir&#125;&quot; /&gt;  </span><br><span class="line">        &lt;/jar&gt;  </span><br><span class="line">    &lt;/target&gt;  </span><br><span class="line">  </span><br><span class="line">&lt;/project&gt;  </span><br></pre></td></tr></table></figure></code></pre>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>编译android2.1(eclair)源码ForHTCG1</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E7%BC%96%E8%AF%91android2.1(eclair)%E6%BA%90%E7%A0%81ForHTCG1/</url>
    <content><![CDATA[<h1 id="编译-android-2.1-eclair-源码-for-htc-g1">编译 android 2.1
(eclair) 源码 For HTC G1</h1>
<p>#移动开发 #android</p>
<p>1. 说明</p>
<ol type="1">
<li><p>下载编译最基本的 android 源码，无法在真机上使用（不能生成
boot.img<br />
），只能在模拟器上使用。这是因为没有编译相关机型的内核和硬件驱动。以下介绍的是用
android 源码编译出对应 HTC G1<br />
的版本，和烧写的过程。编译生成的版本除相机不能用之外，其它绝大部分功能都能正常使用，在
G1 上运行 2.1 版的速度也不错。</p></li>
<li><p>本文主要参考日文文档 G1/G2
烧机指南，感谢原文作者，原文地址：<br />
<a
href="http://code.google.com/p/android-%20development-environment/wiki/EclaironADP1andADP2">_
http://code.google.com/p/android-development-<br />
environment/wiki/EclaironADP1andADP2 _</a><br />
同时加入中文系统的支持和 JIT
支持（提高速度），以及相关文字解释。</p></li>
<li><p>以下步骤都经过验证（只验证 G1 手机， G2
部分请参见日文文档），实验系统 ubuntu8.04 ，实验日期 2010 年 5<br />
月 8 日</p></li>
<li><p>关键字 : android 2.1 eclair g1 源码编译</p></li>
</ol>
<p><a href="None"></a></p>
<p>2. 建立 android 源码编译目录</p>
<pre><code>$ export ANDROID=/exports/android/android_2.1_cn/    
$ mkdir -p $ANDROID    
$ cd $ANDROID  _  </code></pre>
<p>3. 源码下载</p>
<pre><code>$ repo init -u git://android.git.kernel.org/platform/manifest.git -b  
android-2.1_r2  _ _ ＃设定下载  _ _ 2.1  _ _ 版代码  _ _    
$ vi .repo/local_manifest.xml #  _ _ 新建下载配置文件  _    </code></pre>
<p>编辑内容如下</p>
<p>注意：其中 msm 是高通芯片组， path 指明下载到源码目录中的位置， name
指明 git 上的项目名</p>
<pre><code>$ repo sync #  _ _ 开始下载代码，此时需要等待较长时间  _  </code></pre>
<p>4. 打补丁以支持动态壁纸（此为步骤为可选）</p>
<pre><code>$ wget  [ http://android-development-  
environment.googlecode.com/files/patch_devphone_eclair.tar.gz  
](http://android-development-  
environment.googlecode.com/files/patch_devphone_eclair.tar.gz)    
$ tar zxvf patch_devphone_eclair.tar.gz    
$ ./patch/eclair-build-patch.sh  _  </code></pre>
<p>5. 编译内核及无线网络驱动</p>
<pre><code>$ cd $ANDROID/kernel    
$ make ARCH=arm CROSS_COMPILE=../prebuilt/linux-x86/toolchain/arm-  
eabi-4.4.0/bin/arm-eabi- msm_defconfig #  _ _ 设定默认的  _ _ msm  _ _ 配置  _ _    
$ vi .config #  _ _ 修改新生成的配置文件，以重新设置  _ _ CPU  _ _ 最高频率，修改如下：  _    
修改  _ _ CONFIG_MSM_CPU_FREQ_ONDEMAND_MAX  _ _ 项为  _ _  
CONFIG_MSM_CPU_FREQ_ONDEMAND_MAX=528000  _    
$ make ARCH=arm CROSS_COMPILE=../prebuilt/linux-x86/toolchain/arm-  
eabi-4.4.0/bin/arm-eabi- #  _ _ 编译内核  _ _    
$ cd $ANDROID/system/wlan/ti/sta_dk_4_0_4_32    
$ make ARCH=arm CROSS_COMPILE=$ANDROID/prebuilt/linux-x86/toolchain/arm-  
eabi-4.4.0/bin/arm-eabi- KERNEL_DIR=$ANDROID/kerne l  _ _ ＃编译无线网络驱动  _ _    
$ cp $ANDROID/kernel/arch/arm/boot/zImage $ANDROID/vendor/htc/dream-  
open/kernel    
$ cp $ANDROID/system/wlan/ti/sta_dk_4_0_4_32/wlan.ko  
$ANDROID/vendor/htc/dream-open/wlan.ko  _  </code></pre>
<p>6. 编译 android 源码<br />
在 HTC 网站 <a href="http://developer.htc.com/adp.html">_
http://developer.htc.com/adp.html _<br />
</a><br />
下载名为 _ signed-dream_devphone_userdebug-ota-14721.zip _
的包，并把它放在 $ANDROID<br />
目录下</p>
<pre><code>$ cd $ANDROID    
$ source build/envsetup.sh    
$ lunch aosp_dream_us-eng #  _ _ 指明机型  _ _    
$ cd vendor/htc/dream-open    
$ ./unzip-files.sh  _ _ ＃ 解压  _ _ htc  _ _ 相关驱动  _ _    
$ cd $ANDROID    
$ vi buildspec.mk  _ _ ＃ 新建配置文件  _ _    
_ _ 加入如下内容  _ _    
CUSTOM_LOCALES:=zh_CN  _ _ #  _ _ 设置编译为中文系统  _    
WITH_JIT:=true  _ _ #  _ _ 加入  _ _ JIT  _ _ 支持，使得运算速度加快  _ _ 1-2  _ _ 倍  _    
$ make -j2  _ _ ＃  _ _ _ _ 编译  _ _ android  _ _ 源码，需要等待较长时间  _  </code></pre>
<p>7. 把编译好的软件烧写到手机<br />
用 usb 线连接手机到电脑，按 home+power 键将手机启动到工程模式，按 back
键准备烧写</p>
<pre><code>$  export PATH=$PATH:$ANDROID/out/host/linux-x86/bin  #  _ _ 把烧写工具所在目录加上路径  
$ cd out/target/product/dream-open/    
$ fastboot flash system system.img    
$ fastboot flash boot boot.img    
$ fastboot reboot  </code></pre>
<p>烧写系统后第一次启动手机需要几分钟，请耐心等待</p>
<p>8. 参考</p>
<ol type="1">
<li><p>刷写部分未详细描述，具体请参考文档<br />
<a
href="http://xy0811.spaces.live.com/blog/cns!F8AECD2A067A6B17!1452.entry">_
http://xy0811.spaces.live.com/blog/cns!F8AECD2A067A6B17!1452.entry
_<br />
</a></p></li>
<li><p>源码编译部分未详细描述，具体请参考文档<br />
<a
href="http://xy0811.spaces.live.com/blog/cns!F8AECD2A067A6B17!1364.entry">_
http://xy0811.spaces.live.com/blog/cns!F8AECD2A067A6B17!1364.entry
_<br />
</a></p></li>
</ol>
<p>（转载请注明出处： http://xy0811.spaces.live.com ）</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>编译在G1上运行的android2.2(froyo)代码_山寨版</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E7%BC%96%E8%AF%91%E5%9C%A8G1%E4%B8%8A%E8%BF%90%E8%A1%8C%E7%9A%84android2.2(froyo)%E4%BB%A3%E7%A0%81_%E5%B1%B1%E5%AF%A8%E7%89%88/</url>
    <content><![CDATA[<h1
id="编译在g1上运行的android-2.2froyo代码_山寨版">编译在G1上运行的android
2.2(froyo)代码_山寨版</h1>
<h2 id="一-说明">一、 说明</h2>
<p>1. 下载编译最基本的 android 源码，无法在真机上使用（不能生成
boot.img<br />
），只能在模拟器上使用。这是因为没有编译相关机型的内核和硬件驱动。以下介绍的是用
android 源码编译出对应 HTC G1<br />
的版本，和烧写的过程。编译生成的版本绝大部分功能都能正常使用（电话，短信，上网，音乐，软件安装等正常使用，
SD 卡还不能自动挂载，正在修改之中），在<br />
G1 上运行 2.2 版稳定性不错，也很顺畅。</p>
<p>2. 本文主要参考编译 android 2.1 的日文文档 G1/G2
烧机指南，感谢原文作者，原文地址：<br />
<a
href="http://code.google.com/p/android-%20development-environment/wiki/EclaironADP1andADP2">http://code.google.com/p/android-development-<br />
environment/wiki/EclaironADP1andADP2</a><br />
同时加入中文系统的支持和 2.2 部分相关修改，以及相关文字解释。</p>
<p>3. 以下步骤都经过验证（只验证 G1 手机），实验系统 ubuntu8.04
，实验日期 2010 年 7 月 2 日</p>
<p>4. 关键字 : android 2.2 froyo g1 源码编译</p>
<p>二、 编译</p>
<p>1. 建立 android 源码编译目录<br />
_ $ export ANDROID=/exports/android/android_2.2/<br />
$ mkdir -p $ANDROID<br />
$ cd $ANDROID _</p>
<p>2. 源码下载<br />
_ $ repo init -u git://android.git.kernel.org/platform/manifest.git
-b<br />
android-2.2_r1 ＃设定下载 2.2 版代码 _<br />
_ $ vi .repo/local_manifest.xml # _ <em>新建下载配置文件</em><br />
<em>编辑内容如下</em><br />
_</p>
<p>_<br />
注意：其中 msm 是高通芯片组， path 指明下载到源码目录中的位置， name
指明 git 上的项目名<br />
_ $ repo sync # 开始下载代码，此时需要等待较长时间 _</p>
<p>3. 编译内核及无线网络驱动<br />
_ $ cd $ANDROID/kernel<br />
$ make ARCH=arm CROSS_COMPILE=../prebuilt/linux-x86/toolchain/arm-<br />
eabi-4.4.0/bin/arm-eabi- msm_defconfig # 设定默认的 msm 配置 _<br />
_ $ make ARCH=arm
CROSS_COMPILE=../prebuilt/linux-x86/toolchain/arm-<br />
eabi-4.4.0/bin/arm-eabi- # _ <em>编译内核</em><br />
_ $ cd $ANDROID/system/wlan/ti/sta_dk_4_0_4_32<br />
$ make ARCH=arm CROSS_COMPILE=<span
class="math inline">\(ANDROID/prebuilt/linux-x86/toolchain/arm-
eabi-4.4.0/bin/arm-eabi- KERNEL_DIR=\)</span>ANDROID/kerne l _
<em>＃编译无线网络驱动</em><br />
_ $ cp $ANDROID/kernel/arch/arm/boot/zImage
$ANDROID/vendor/htc/dream-<br />
open/kernel<br />
$ cp $ANDROID/system/wlan/ti/sta_dk_4_0_4_32/wlan.ko<br />
$ANDROID/vendor/htc/dream-open/wlan.ko _</p>
<p>4. 编译 android 源码<br />
在 HTC 网站 <a
href="http://developer.htc.com/adp.html">http://developer.htc.com/adp.html<br />
</a><br />
下载名为 signed-dream_devphone_userdebug-ota-14721.zip 的包，并把它放在
_ $ANDROID 目录下<br />
_<br />
_ $ cd $ANDROID<br />
$ source build/envsetup.sh<br />
$ lunch aosp_dream_us-eng # _ <em>指明机型</em><br />
_ $ cd vendor/htc/dream-open<br />
$ ./unzip-files.sh _ _ ＃ 解压 htc 相关驱动 _<br />
_ $ cd $ANDROID<br />
$ vi buildspec.mk _ _ ＃ 新建配置文件 _<br />
<em>加入如下内容</em><br />
_ CUSTOM_LOCALES:=zh_CN # _ <em>设置编译为中文系统</em><br />
_ $ vi build/core/prebuild.mk<br />
_ _ 注掉第 59 行 ($error No LOCAL_CERTIFICATE……)<br />
，否则编不过，这是由于对硬件部分的一个包的签名检测不过引起的（硬件部分的代码已经很久没更新了）
_<br />
_ $ vi device/htc/dream-sapphire/libsensors/Android.mk<br />
_ _ 将第 39 行，改为 LOCAL_MODULE:=sensor.trout1<br />
，否则编不过，这是由于硬件部分的模块名与源码中自带的模块名冲突引起
_<br />
_ $ vi hardware/msm7k/libaudio/Android.mk<br />
_ _ 在第 29 行 (CLEAR_VARS 之后 ) ，加入
LOCAL_PRELINK_MODULE:=false,<br />
否则，系统无法运行，启动时会报错“ failed to link libandroid_servers.so ”
_<br />
_ $ make -j4 _ _ ＃ 编译 android 源码，需要等待较长时间 _<br />
_ $ mmm -B $ANDROID/packages/apps/Luancher2/ snod # _<br />
<em>编译桌面程序，否则桌面将无法启动，系统总停在开机动画</em><br />
_ $mmm -B $ANDROID/framework/base/packages/DefaultContainerService/ snod
# _<br />
_ 编译 ContainerService ，否则无法安装软件 _</p>
<p>三、 把编译好的软件烧写到手机</p>
<p>用 usb 线连接手机到电脑，按 home+power 键将手机启动到工程模式，按
back 键准备烧写<br />
_ $ export PATH=<span
class="math inline">\(PATH:\)</span>ANDROID/out/host/linux-x86/bin # _
<em>把烧写工具所在目录加上路径</em><br />
_ $ cd out/target/product/dream-open/<br />
$ fastboot flash system system.img<br />
$ fastboot flash boot boot.img<br />
$ fastboot reboot _<br />
烧写系统后第一次启动手机需要几分钟，请耐心等</p>
<p>四、 修改</p>
<p>1. 支持 SD 卡<br />
_ $ adb remount<br />
$ adb push $ANDROID/system/core/rootdir/etc/vold.fstab /etc/ _<br />
烧写手机后 SD 卡没有挂载是由于没有找到配置文件，将挂载服务 vold
所需的配置文件 vold.fstab 写入手机即可，然后重启即可 .<br />
注意，你的 SD 卡最好只含一个 fat 格式分区，如果之前自己配置过早期的
APP2SD ，分有 ext2 分区，可能出现卡不被识别的情况<br />
.</p>
<p>2. 支持 GPRS 上网<br />
添加 APN 即可上网和发彩信，详见 <a
href="http://www.andbeta.com/Basics/678.html">http://www.andbeta.com/Basics/678.html<br />
</a></p>
<p>3. 支持 APP2SD<br />
_ $ adb shell<br />
# pm setInstallLocation 2 _<br />
重启之后，程序即被安装到 SD 卡上</p>
<p>五、 参考</p>
<p>1. 刷写部分未详细描述，具体请参考文档<br />
<a
href="http://xy0811.spaces.live.com/blog/cns!F8AECD2A067A6B17!1452.entry">http://xy0811.spaces.live.com/blog/cns!F8AECD2A067A6B17!1452.entry<br />
</a></p>
<p>2. 源码编译部分未详细描述，具体请参考文档<br />
<a
href="http://xy0811.spaces.live.com/blog/cns!F8AECD2A067A6B17!1364.entry">http://xy0811.spaces.live.com/blog/cns!F8AECD2A067A6B17!1364.entry<br />
</a></p>
<p>注意：以上灰色标出的是与编译 éclair 不同的部分</p>
<h2 id="转载请注明作者及出处-httpxy0811.spaces.live.com">(
转载请注明作者及出处 [ http://xy0811.spaces.live.com</h2>
<p>](http://xy0811.spaces.live.com/) )</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>编译在G1上运行的android2.2(froyo)代码_正规版</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E7%BC%96%E8%AF%91%E5%9C%A8G1%E4%B8%8A%E8%BF%90%E8%A1%8C%E7%9A%84android2.2(froyo)%E4%BB%A3%E7%A0%81_%E6%AD%A3%E8%A7%84%E7%89%88/</url>
    <content><![CDATA[<h1
id="编译在g1上运行的android-2.2froyo代码_正规版">编译在G1上运行的android
2.2(froyo)代码_正规版</h1>
<p>#移动开发 #android</p>
<h2 id="一-说明"><strong>一、</strong> ** 说明 **</h2>
<p>1. 下载编译最基本的 android
源码，只能在模拟器上使用，无法在真机上使用（不能生成 boot.img<br />
）。这是因为没有编译相关机型的内核和硬件驱动。以下介绍的是用 android
源码编译出对应 HTC G1<br />
的版本，和烧写的过程。编译生成的版本除相机以外，其它功能均正常，稳定性不错，也很顺畅。</p>
<p>2. 以下步骤都经过验证（只验证 G1 手机），实验系统 ubuntu8.04
，实验日期 2010 年 7 月 12 日</p>
<p>3. 关键字 : android 2.2 froyo g1 源码编译</p>
<h3 id="二-编译"><strong>二、</strong> ** 编译 **</h3>
<p>1. 建立 android 源码编译目录<br />
_ $ export ANDROID=/exports/android/android_2.2/<br />
$ mkdir -p $ANDROID<br />
$ cd $ANDROID _</p>
<p>2. 源码下载<br />
_ $ repo init -u git://android.git.kernel.org/platform/manifest.git
-b<br />
android-2.2_r1<br />
$ vi .repo/local_manifest.xml #
新建下载配置文件，用以下载内核，编辑内容如下 _<br />
_</p>
<p>_<br />
注意：其中 msm 是高通芯片组， path 指明下载到源码目录中的位置， name
指明 git 上的项目名<br />
_ $ repo sync # 开始下载代码，此时需要等待较长时间 _</p>
<p>3. 编译内核及无线网络驱动<br />
_ $ cd $ANDROID/kernel<br />
$ make ARCH=arm CROSS_COMPILE=../prebuilt/linux-x86/toolchain/arm-<br />
eabi-4.4.0/bin/arm-eabi- msm_defconfig # 设定默认的 msm 配置 _<br />
_ $ make ARCH=arm
CROSS_COMPILE=../prebuilt/linux-x86/toolchain/arm-<br />
eabi-4.4.0/bin/arm-eabi- # _ <em>编译内核</em><br />
_ $ cd $ANDROID/system/wlan/ti/sta_dk_4_0_4_32<br />
$ make ARCH=arm CROSS_COMPILE=<span
class="math inline">\(ANDROID/prebuilt/linux-x86/toolchain/arm-
eabi-4.4.0/bin/arm-eabi- KERNEL_DIR=\)</span>ANDROID/kerne l _
<em>＃编译无线网络驱动</em><br />
_ cp $ANDROID/kernel/arch/arm/boot/zImage
$ANDROID/device/htc/dream/kernel<br />
cp $ANDROID/system/wlan/ti/sta_dk_4_0_4_32/wlan.ko<br />
$ANDROID/device/htc/dream/wlan.ko _</p>
<p>4. 配置编译选项<br />
_ vi device/htc/dream/AndroidBoard.mk ＃若 kernel 存在，则不重新编译 _ _
kernel<br />
ifeq ($(TARGET_PREBUILT_KERNEL),)<br />
TARGET_PREBUILT_KERNEL := $(LOCAL_PATH)/kernel<br />
endif</p>
<p>file := $(INSTALLED_KERNEL_TARGET)<br />
ALL_PREBUILT += $(file)<br />
$(file): $(TARGET_PREBUILT_KERNEL) | $(ACP)<br />
$(transform-prebuilt-to-target) _</p>
<p>5. 编译 android 源码<br />
_ $ cd $ANDROID<br />
$ vi buildspec.mk # 加入如下内容，以支持中文 _<br />
_ CUSTOM_LOCALES:=zh_CN<br />
$ source build/envsetup.sh<br />
$ lunch full_dream-userdebug _ <em>＃指定编译机型</em><br />
_ $ make -j2 _</p>
<p>6. 以打补丁的方式加入不提供源码的库<br />
此时的系统可以被烧写，但电话音乐等基本功能均不正常，需要从系统或其它升级包中提取出源码中不包含的库，以支持相应功能。<br />
在 HTC 网站 <a
href="http://developer.htc.com/adp.html">http://developer.htc.com/adp.html<br />
</a><br />
下载名为 signed-dream_devphone_userdebug-ota-14721.zip 的包（一个普通的
update<br />
包），并把它放在 $ANDROID 目录下，并将其改名为 dreaem_update.zip<br />
_ $ mv signed-dream_devphone_userdebug-ota-14721.zip
dream_update.zip<br />
$ cd device/htc/dream<br />
$ ./unzip-files.sh ＃ 此时会提示有几个库找不后，后面有对应解决办法
_<br />
_ $ cd $ANDROID<br />
$ vi vendor/htc/dream/device_dream-vendor-blobs.mk<br />
_ _ 删除包含以下内容的行，这是由于在 update.zip
中找不到相应库，为编译通过，选去掉它们 _<br />
_ libGLES_qcom.so<br />
liblvmxipc.so<br />
liboemcamera.so<br />
libstagefrighthw.so<br />
$ make<br />
$ cp device/htc/dream/wlan.ko<br />
out/target/product/dream/system/lib/modules/wlan.ko _
<em>＃网卡驱动</em><br />
_ $ make snod _ _ ＃ 重新生成 system.img _</p>
<h3 id="三-把编译好的软件烧写到手机"><strong>三、</strong> **
把编译好的软件烧写到手机 **</h3>
<p>用 usb 线连接手机到电脑，按 home+power 键将手机启动到工程模式，按
back 键准备烧写<br />
_ $ export PATH=<span
class="math inline">\(PATH:\)</span>ANDROID/out/host/linux-x86/bin # _
<em>把烧写工具所在目录加上路径</em><br />
_ $ cd out/target/product/dream/<br />
$ fastboot flash system system.img<br />
$ fastboot flash boot boot.img<br />
$ fastboot reboot _<br />
烧写系统后第一次启动手机需要几分钟，请耐心等</p>
<h3 id="四-修改"><strong>四、</strong> ** 修改 **</h3>
<p>1.
安装中文字体（可以在烧写前加入，加在此处用以说明在启动后修改系统的方法）<br />
_ $ adb shell<br />
# su 取得 root 权限 _<br />
_ # mount -o remount,rw -t yaffs2 /dev/block/mtdblock3 /system _ _ 使
system<br />
分区可写 _<br />
_ # chmod 777 /system/fonts _ <em>使某个目录有写权限</em><br />
_ # exit<br />
# exit<br />
$ adb push frameworks/base/data/fonts/DroidSansFallback.ttf
/system/fonts/ _<br />
<em>加中文字体</em><br />
_ $ adb reboot _</p>
<p>2. 支持 GPRS 上网<br />
添加 APN 即可上网和发彩信，详见 <a
href="http://www.andbeta.com/Basics/678.html">http://www.andbeta.com/Basics/678.html<br />
</a></p>
<p>3. 设置帐户<br />
添加帐户时，服务器填写 m.google.com</p>
<h3 id="五-参考"><strong>五、</strong> ** 参考 **</h3>
<p>1. 刷写部分未详细描述，具体请参考文档<br />
<a
href="http://xy0811.spaces.live.com/blog/cns!F8AECD2A067A6B17!1452.entry">http://xy0811.spaces.live.com/blog/cns!F8AECD2A067A6B17!1452.entry<br />
</a></p>
<p>2. 源码编译部分未详细描述，具体请参考文档<br />
<a
href="http://xy0811.spaces.live.com/blog/cns!F8AECD2A067A6B17!1364.entry">http://xy0811.spaces.live.com/blog/cns!F8AECD2A067A6B17!1364.entry<br />
</a></p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>编译在N1(G5,Passion)上运行的姜饼（GingerBread,Android2.3）代码</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E7%BC%96%E8%AF%91%E5%9C%A8N1(G5,Passion)%E4%B8%8A%E8%BF%90%E8%A1%8C%E7%9A%84%E5%A7%9C%E9%A5%BC%EF%BC%88GingerBread,Android2.3%EF%BC%89%E4%BB%A3%E7%A0%81/</url>
    <content><![CDATA[<h1
id="编译在n1g5-passion上运行的姜饼gingerbreadandroid-2.3代码">编译在N1(G5,
Passion)上运行的姜饼（GingerBread,Android 2.3）代码</h1>
<p>#移动开发 #android</p>
<p>( 转载请注明出处 : <a
href="http://blog.csdn.net/xieyan0811">http://blog.csdn.net/xieyan0811<br />
</a> )</p>
<p>1. 修改效果</p>
<ol type="1">
<li><p>在 32 位系统上正常编译通过， N1 上能运行，带 root 权限</p></li>
<li><p>带 N1 原始的四色 X 开机动画，默认语言为简体中文</p></li>
<li><p>带 google market
，文件管理器，百度中文手写输入法，金山词霸等常用软件</p></li>
<li><p>打电话，收发短信， WIFI ，移动网络，热点上网正常（ APN
已设）</p></li>
<li><p>音频，视频，照像，摄像， Gps ， Sensor 使用正常</p></li>
<li><p>目前未测到不正常的功能</p></li>
</ol>
<p>2. 下载 android 2.2 或 2.3 的 sdk<br />
刷机使用的 fastboot 和 adb 都需要从 sdk 中获得</p>
<p>3. 对 N1 的处理</p>
<ol type="1">
<li>Bootloader 解锁</li>
</ol>
<ol type="a">
<li><p>关机后，按 Power+ 音量减开机，按音量键选 fastboot ，然后按 Power
进入</p></li>
<li><p>在 PC 端运行解锁命令如下（ fastboot 命令可从 SDK/tools
目录得到）</p></li>
<li><p>_ # fastboot oem unlock _</p></li>
<li><p>通过音量和 Power 键选 Yes
，重新启动，此时看到屏幕下面有一个解决锁标志</p></li>
</ol>
<ol start="2" type="1">
<li>注意：解锁后手机里的用户数据全被清除了，所以解锁之前需要先备份</li>
</ol>
<p>4. 刷带 nandroid 的 recovery<br />
recovery
用于系统升级，通常情况下即使刷坏了，也不影响手机正常使用。它只对 boot,
system, userdata<br />
三个分区做备份，有些版本的 recovery 带 nandroid
功能，它用于备份和恢复当前手机系统</p>
<ol type="1">
<li>普通使用</li>
</ol>
<ol type="a">
<li><p>关机后，按 Power+ 音量减开机，按音量键选 recovery ，然后按 Power
进入，此时看到叹号和小绿人</p></li>
<li><p>按音量加减 +Power 进入菜单，此模式可以使用 update.zip<br />
升级，但不能备份当前系统，强烈建议升级前备份原系统，因为原生的一般都比后烧的稳定</p></li>
<li><p>按 Power+ 音量减 + 滚轮重启</p></li>
</ol>
<ol start="2" type="1">
<li>替换带 nandroid 的 recovery ，以备份原有系统</li>
</ol>
<ol type="a">
<li><p>下载 recovery-RA-nexus-v1.7.0.img （见下面指定的地址）</p></li>
<li><p>关机后，按 Power+ 音量减开机，按音量键选 fastboot ，然后按 Power
进入</p></li>
<li><p>/ 在 PC 端运行烧写命令如下<br />
</p></li>
</ol>
<pre><code>$ fastboot flash recovery recovery-RA-nexts-v1.7.0.img  </code></pre>
<ol start="4" type="a">
<li><p>在手机端菜单中选择进入 bootloader</p></li>
<li><p>在 bootloader 中选 recovery ，就可看到 recovery
的新选项，用轨迹球可以操作</p></li>
<li><p>备份数据和恢复选项<br />
更新的 recovery 除正常备份外还可以备份 google 帐号数据，备份
app2sd<br />
中扩展的数据，和恢复到选定的版本（早期版本只支持恢复到最后备份的版本）</p></li>
</ol>
<ol start="3" type="1">
<li>注意<br />
用以上方法烧写 recovery 分区，系统重启后 recovery
又会恢复，这是由于开机时被 /data/recovery.img<br />
恢复了，如果不想被刷回，可将下载的 recovery.img 放到 /data/ 下即可（需要
root 权限）</li>
</ol>
<p>5. 编译 android 2.3 （如不想编译请跳过此步，直接下载编好的 img
烧写）</p>
<ol type="1">
<li>安装 jdk<br />
android 之前的版本使用 jdk1.5 编译，而 android 2.3 默认要求使用
jdk1.6</li>
</ol>
<ol type="a">
<li>安装 jdk 1.6<br />
</li>
</ol>
<pre><code>$ sudo apt-get install sun-java6-jdk  </code></pre>
<ol start="2" type="a">
<li>在同一台机器上同时编译 android 2.2 和 android 2.3
，用以下方法进行切换<br />
</li>
</ol>
<pre><code>$ sudo update-java-alternatives -s java-1.5.0-sun  </code></pre>
<ol start="2" type="1">
<li><p>用 git 下载 2.3 源代码<br />
配置 linux 环境，安装 git 及 repo 请参见相关文档</p></li>
<li><p>解决只能在 64 位系统编译的问题<br />
android 2.3 默认只能在 64 位系统中编译，为了不重装系统可以用以下方法在
32 系统上编译</p></li>
</ol>
<ol type="a">
<li>修改 main.mk<br />
</li>
</ol>
<pre><code>$ vi build/core/main.mk  
将  75  行左右判断  64  位的部分注释掉，或修改如下：  
ifneq (i686,$(findstring i686,$(build_arch)))  </code></pre>
<ol start="2" type="a">
<li>修改 clearsilver 中的编译选项，将下面四个文件中的 -m64 改为
-m32<br />
</li>
</ol>
<pre><code>external/clearsilver/cgi/Android.mk,    
external/clearsilver/java-jni/Android.mk,    
external/clearsilver/util/Android.mk,    
external/clearsilver/cs/Android.mk  </code></pre>
<ol start="4" type="1">
<li>编译前的准备工作</li>
</ol>
<ol type="a">
<li><p>连接手机和电脑</p></li>
<li><p>将手机中的没有源码的库补丁到源码中（我的 N1 系统为 android 2.2
）<br />
</p></li>
</ol>
<pre><code>$ cd device/htc/passion/    
$ ./extract-files.sh  此处需要的  adb  命令从  SDK  中获取  _  </code></pre>
<ol start="3" type="a">
<li>修改源码</li>
</ol>
<ol type="i">
<li><p>解决照像摄像问题（ android 2.3
支持了多摄像头之后接口改变），修改<br />
frameworks/base/services/camera/libcameraservice/CameraService.cpp<br />
frameworks/base/media/libstagefright/omx/OMXNodeInstance.cpp<br />
frameworks/base/media/libstagefright/OMXCodec.cpp<br />
frameworks/base/media/libstagefright/CameraSource.cpp</p></li>
<li><p>解决进应用闪白问题，修改<br />
frameworks/base/libs/ui/GraphicBuffer.cpp</p></li>
</ol>
<ol start="5" type="1">
<li>编译<br />
</li>
</ol>
<pre><code>$ . build/envsetup.sh    
$ lunch 3  #  此处选择硬件平台为  _ _ N1(Passion)    
$ choosecombo 1 1 full_passion 3  # 3  为指定编译工程模式，即带  root  权限  _    
$ make –j6  </code></pre>
<p>6. 下载 img</p>
<ol type="1">
<li><p>此版本为个人测试使用，在本人上周网购的自带 android 2.2 的港版 N1
上正常使用，不能保证所有 N1<br />
都使用正常，烧机后果自负，建议大家自行编译。再次提醒：请在烧写前先用
recovery nandroid 备份当前系统。以下为下载地址：<br />
<a
href="http://iask.sina.com.cn/u/ish?retcode=0">http://iask.sina.com.cn/u/ish?retcode=0<br />
</a><br />
（含 md5, system, userdata, boot, recovery ）</p></li>
<li><p>下载后可通过 fastboot 烧写，方法如下<br />
</p></li>
</ol>
<pre><code>$ fastboot flash system system.img    
$ fastboot flash boot boot.img    
$ fastboot flash userdata userdata.img  </code></pre>
<p>7. 参考</p>
<ol type="1">
<li><p>Android 2.3 使用的 google market 可从此处下载<br />
<a
href="http://blog.csdn.net/silenceburn/archive/2010/12/24/6096822.aspx">http://blog.csdn.net/silenceburn/archive/2010/12/24/6096822.aspx<br />
</a></p></li>
<li><p>设置 apn 的方法<br />
<a
href="http://mobile.yesky.com/447/9288447.shtml">http://mobile.yesky.com/447/9288447.shtml<br />
</a></p></li>
<li><p>Recovery 的使用请参考<br />
<a
href="http://anriqing.blogbus.com/logs/77459519.html">http://anriqing.blogbus.com/logs/77459519.html<br />
</a></p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>解析apk包内容</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%B7%A5%E5%85%B7/%E8%A7%A3%E6%9E%90apk%E5%8C%85%E5%86%85%E5%AE%B9/</url>
    <content><![CDATA[<h1 id="解析apk包内容">解析apk包内容</h1>
<p>#移动开发 #android</p>
<p>1． 说明<br />
写应用程序，很多时候遇到问题想看看别人的应用是怎么实现的，又苦于没有源码，
apk 是 zip 压缩格式，而解压后 xml<br />
是加密格式，也看不到源码。下面介绍用 google 官方发布的 apktool
工具来解开 apk 包，从而得到正常显示的 xml<br />
文件和文本格式的程序，虽然不是 java 程序，但能看出逻辑。</p>
<p>2． 方法</p>
<ol type="a">
<li><p>下载工具<br />
<a
href="http://code.google.com/p/android-apktool/downloads/">http://code.google.com/p/android-apktool/downloads/<br />
</a><br />
或者<br />
<a
href="http://u.115.com/file/f12d8136c3">http://u.115.com/file/f12d8136c3</a><br />
需要下载 apktool2.3.2.tar.bz2 和 apktool-install-linux-2.2_r01-1.tar.bz2
，前面的是<br />
jar 包，后面的是调用它的平台相关的脚本</p></li>
<li><p>将它们解压在同一目录下</p></li>
<li><p>当 java 切换成 1.6 版本</p></li>
<li><p>运行<br />
apktool –d apk 名 目录名<br />
即可将信息解到指定目录下</p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>AIDL——Android接口描述语言</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/AIDL%E2%80%94%E2%80%94Android%E6%8E%A5%E5%8F%A3%E6%8F%8F%E8%BF%B0%E8%AF%AD%E8%A8%80/</url>
    <content><![CDATA[<h1 id="aidlandroid接口描述语言">AIDL——Android接口描述语言</h1>
<p>#移动开发 #android</p>
<p>1. 要解决什么问题<br />
它可以让后续的开发者无需了解内部，只根据接口实现相关的操作用，常用于在不同的Activity中对Service进行控制。</p>
<p>2. 什么是AIDL<br />
AIDL (Android Interface Definition<br />
Language)：Android接口描述语言，编译器可以通过aidl文件生成一段代码，通过预先定义的接口达到两个进程内部通信进程的目的.<br />
如果需要在一个Activity中, 访问另一个Service中的某个对象,
需要先将对象转化成AIDL可识别的参数(可能是多个参数),<br />
然后使用AIDL来传递这些参数, 在消息的接收端,
使用这些参数组装成自己需要的对象。</p>
<p>3. 如何对aidl进行操作<br />
启动service有两种方式，一种通过bindService来启动，调用退出时，服务也将停止，或者用unbind来停止；另一种通过startService来启动，调用退出时，服务还在运行，只能通过stop来停止。<br />
使用aidl时，先引入aidl的相关类，然后使用bind &lt;-&gt; unbind，start
&lt;-&gt; stop，或者start&amp;bind &lt;-&gt;<br />
unbind&amp;stop，不同调用方式的生命周期不同，详见参考网页。</p>
<p>4. 参数规则<br />
必须导入(import)所有非内置类型，哪怕是这些类型是在与接口相同的包中。AIDL能支持的数据类型有：Java编程语言的主要类型
(int,<br />
boolean等) —不需要 import 语句；<br />
类String, List,Map, CharSequence不需要import
语句，但需要Parcelable封装，否则会报错。</p>
<p>5. 参考<br />
<a
href="http://blog.csdn.net/lganggang131/article/details/6553468">http://blog.csdn.net/lganggang131/article/details/6553468<br />
</a><br />
<a
href="http://www.oschina.net/question/195301_32171">http://www.oschina.net/question/195301_32171<br />
</a></p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>AndroidDensity</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/AndroidDensity/</url>
    <content><![CDATA[<h1 id="android-density">Android Density</h1>
<p>#移动开发 #android</p>
<p>1. 什么是 density</p>
<ol type="1">
<li><p>density<br />
density 表示每英寸有多少个显示点 ( 逻辑值 ) ，它的单位是 dpi ： dot per
inch ，通常屏幕大时，<br />
density 就大，屏幕小时， density 就小，通常<br />
屏幕实际分辨率为 240px<em>400px 时， density=120<br />
屏幕实际分辨率为 320px</em>533px ， density=160<br />
屏幕实际分辨率为 480px*800px ， density=240</p></li>
<li><p>分辨率<br />
是整个屏是多少点，比如 800x480 ，它是软件的显示单位</p></li>
<li><p>从 Android1.6 版本开始支持 density( 对应 API Level 4)<br />
用于解决应用在屏幕大小不同的硬件上正常显示的问题</p></li>
</ol>
<p>2. 相关代码及设置</p>
<ol type="1">
<li>AndroidManifest.xml</li>
</ol>
<p>这个参数在 API Level 4 也就是 SDK 1.6 以后才启用的，而且 1.6 版本的
API Level 4 的应用默认值就是<br />
True</p>
<ol start="2" type="1">
<li><p>资源目录名（ android 2.0 以后）<br />
res/xxx-hdpi 当 density 为 240 时，使用此目录下的资源<br />
res/xxx-mdpi 当 density 为 160 时，使用此目录下的资源<br />
res/xxx-ldpi 当 density 为 120 时，使用此目录下的资源<br />
res/xxx 不常后缀，为默认设置，同 xxx-mdpi</p></li>
<li><p>资源单位（ xml 文件中定义大小的单位）</p></li>
</ol>
<ol type="a">
<li><p>dp=dip=dx ( ** Density independent pixel ** )<br />
基于屏幕密度的抽象单位，设备无关的点，用于说明与密度无关的尺寸和位置。这些单位是相对于一个
160dpi 的屏幕，所有一个 dp 是 160dpi<br />
屏幕上的一个点。</p></li>
<li><p>px<br />
px 指软件的单位点，设备相关的点</p></li>
<li><p>具体使用</p></li>
</ol>
<ol type="i">
<li><p>布局时尽量使用单位 dip ，少使用 px<br />
若使用 px ，如果设某控件大小 400x400px ，在 800x480 上显示正常，而在
533x320 的屏上就超出屏幕了<br />
若使用 dp ，如果设某控件大小为 160x160dp ，就可以通过从系统中取 density
来算出真正的大小，比如在 800x480<br />
屏的 density 设为 240 ，而 533x320 屏的 density 设为 160
，借以下公式计算<br />
pixels = dips * (density / 160)<br />
在 800x480 在屏中显示 240 象素，而在 533x320 的屏中显示为 160
象素，控件在屏中显示的比例是一样的。</p></li>
<li><p>内部的处理过程分为三步：<br />
取 screen 中其它元素，转为应用的值，计算应用各控件位置，然后再转成
800x480 以供真正显示<br />
若 res-xxx 不存在，则读取 res 有的资源，然后对其做相应缩放</p></li>
</ol>
<p>3. 实现 density 的关键源码</p>
<ol type="1">
<li><p>BitmapFactory.java （用于缩放图片）</p></li>
<li><p>ComptibilityInfo.java （用于位置计算）</p></li>
</ol>
<p>(转载请注明作者及出处 <a
href="http://xy0811.spaces.live.com/">http://xy0811.spaces.live.com/</a><br />
)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>AndroidPrelink实现的源码分析</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/AndroidPrelink%E5%AE%9E%E7%8E%B0%E7%9A%84%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="android-prelink实现的源码分析">Android
Prelink实现的源码分析</h1>
<p>#移动开发 #android</p>
<p>1. 原理简介</p>
<ol type="1">
<li><p>Prelink<br />
Prelink
即预链接技术是利用事先链接以代替运行时链接的技术，以加快共享库的加载速度，它不仅能加快程序启动时间，还可以减少部分内存开销（它能使<br />
KDE 的启动时间减少 50%
）。每次程序执行时，进行的链接动作都是一样的，链接相对来说开销很大，尤其是嵌入式系统。</p></li>
<li><p>普通 Linux 系统的 Prelink<br />
Redhat 系统中 prelink 工具 (/etc/cron.dialy/prelink)<br />
会修改可执行程序，把它与所需库的链接信息加入可执行程序。在程序运行时，使用
glibc(glibc &gt; 2.3.1-r2) 中的 ld-<br />
linux.so 来进行链接。用此方式，每次更新动态库后，使用它的程序都需要重新
prelink ，因为新库中的符号信息，地址等很可能与原来不同了。</p></li>
<li><p>Android 的 Prelink<br />
Android 源码中有一组 map 文件，其中定义了需要预连接的动态库，其 Prelink
信息以及对应的逻辑地址（ 4G<br />
地址空间中位置），在动态库编译时，预处理程序 apriori 根据 map
文件中的定义，生成预链接信息重定向信息，并加入这些二进制文件<br />
lib*.so
的末尾。它主要节约了查询函数地址等工作所用的时间，动态库重定位的开销。在运行程序，动态库加载时，加载程序
linker<br />
判断动态库是否为 Prelink
的，如果是的话，就在首次使用时将其加载到指定的内存空间，直接使用预编译信息。</p></li>
</ol>
<p>2. 源码分析</p>
<ol type="1">
<li>动态库的编译脚本</li>
</ol>
<ol type="a">
<li><p>源代码<br />
frameworks/base/media/libmedia/Android.mk 等库的编译选项文件</p></li>
<li><p>配置<br />
可在 Android.mk 中设置该库是否需要 Prelink ，默认是使用 Prelink
的，也可设置成否，方法如下：<br />
LOCAL_PRELINK_MODULE := false</p></li>
<li><p>分析<br />
此设置只用于动态库的编译，编译时用 showcommands
参数即可看到具体编译使用到的命令行，如在某个库的目录中运行 mm<br />
showcommands ，即可看到相应的 Prelink 操作，示例如下：<br />
target Prelink: libxxx<br />
out/host/linux-x86/bin/apriori --prelinkmap
build/core/prelink-linux-<br />
arm-2G.map --locals-only --quiet xxx.so --output xxx.so<br />
如果该库设置为需要 prelink ，则也需要在 map
文件中加入相应项，否则编译不通过</p></li>
</ol>
<ol start="2" type="1">
<li>内核</li>
</ol>
<ol type="a">
<li><p>源码<br />
kernel/arch/arm/configs/xxx_defconfig<br />
arch/arm/mach-msm/include/mach/vmalloc.h</p></li>
<li><p>配置<br />
CONFIG_VMSPLIT_2G=y 一般默认为 3G /1G ，此项 即设置为 2G /2G</p></li>
<li><p>分析<br />
xxx_defconfig 为默认的内核配置文件 ( 修改其中的 CONFIG_VMSPLIT_*)
，也可通过 make menuconfig<br />
配置，与 Prelink 相关的主要是指定用户空间和内核空间内存如何分配 4G
的虚拟内存空间（ Memory split ），一般有三种方式：<br />
3G /1G ， 2G /2G ， 1G /3G(user/kernel) ，一般默认的是用户空间 3G<br />
(0x0-0xBFFFFFFF) ，内核空间 1G (0xC0000000 - 0xFFFFFFFF)</p></li>
<li><p>内存分析示例，以 3G /1G 为例 ( 见
build/core/prelink-linux-arm.map)<br />
0xC0000000 - 0xFFFFFFFF Kernel<br />
0xB0100000 - 0xBFFFFFFF Thread 0 static<br />
0xB0000000 - 0xB00FFFFF Linker<br />
0xA0000000 - 0xBFFFFFFF Prelinked System Libraries<br />
0x90000000 - 0x9FFFFFFF Prelinked App Libraries<br />
0x80000000 - 0x8FFFFFFF Non-prelinked Libraries<br />
0x40000000 - 0x7FFFFFFF mmap’s stuff<br />
0x10000000 - 0x3FFFFFFF Thread Stacks<br />
0x00000000 - 0x0FFFFFFF .text / .data / heap</p></li>
</ol>
<ol start="3" type="1">
<li>map 文件</li>
</ol>
<ol type="a">
<li><p>源代码<br />
build/core/prelink-linux-<arch>*.map</p></li>
<li><p>配置<br />
编译时有多个 map 文件可先，根据不同的硬件平台及内存分配 (3G/1G, 2G/2G)
修改系统配置<br />
device/*/BoardConfig.mk 选择使用不同的 map 文件 .<br />
如 prelink-linux-arm-2G.map, prelink-linux-arm.map<br />
系统中每加入一个需要 prelink 的动态库，需要在 map
文件添加相应的项</p></li>
<li><p>分析<br />
在用户空间，共定义了三块与链接相关地址间空<br />
系统库分配的内存： Prelinked System Libraries<br />
应用库分配的内存： Prelinked App Libraries<br />
无 prelink 库分配的内存： Non-prelinked Libraries</p></li>
<li><p>map 文件规则<br />
需要在 build/core/prelink-linux-arm.map 中加入形如 libhellod.so
0x96000000 。<br />
手工指定某个库相应的 prelink 地址范围，库应用对齐 1M<br />
边界，注意库与库之间的间隔数，如果指定不好编译的时候会提示说地址空间冲突的问题。另外，注意排序，这里要把数大的放到前面去，按照大小降序排序。</p></li>
</ol>
<ol start="4" type="1">
<li>apriori 程序</li>
</ol>
<ol type="a">
<li><p>源代码<br />
build/tools/apriori/*</p></li>
<li><p>配置<br />
device/*/BoardConfig.mk 中设置<br />
TARGET_USES_2G_VM_SPLIT := true 以配置 Prelink 的地址空间</p></li>
<li><p>分析<br />
apriori 中的 prelinkmap.c 它用根据整个系统设置 device/*/BoardConfig.mk
的内存分配规则（ 3G<br />
/1G, 2G/2G ）来判断 map 中指定地址是否符合 Prelink
的地址空间范围，如果正常，则在 so 的末尾加入 prelink<br />
信息和标识 ( 文件以 PRE 结束 )<br />
apriori
可以预先为若干共享库确定加载地址，并为有依赖关系的共享库做静态重定位和连接
, 该命令加入参数 --verbose ，即可显示出<br />
prelink 的细节。</p></li>
</ol>
<ol start="5" type="1">
<li>linker 程序</li>
</ol>
<ol type="a">
<li><p>源代码<br />
bionic/linker/*<br />
(bionic 目录中存放一些基础的库，如 libc, libstdc++, libthread_db, linker
等 )</p></li>
<li><p>分析<br />
linker 是 Android 的专用动态链接库键接器， Linker 和传统 Linux 使用的
linker(ld.so,ld-<br />
linux.so.2,ld-linux.so.3) 有所不同。库的编译参数 -dynamic-linker
指定了键接器为<br />
/system/bin/linker( 也可以手动换成别的 ) ， 该信息将被存放在 ELF 文件的
.interp<br />
节中，内核执行目标映像文件前将通过该信息加载并运行相应的解释器程序
linker ，并链接相应的共享库， 共享库以 ELF<br />
文件的形式保存在文件系统中 。 核心的 load_elf_binary
会首先将其映像文件映射到内存，然后映射并执行其解释器也就是 linker<br />
的代码。 linker 的代码段是进程间共享的，但数据段为各进程私有。<br />
所有外部过程引用都在映像执行之前解析 , Android
中的共享库和可执行映像都默认采用 ELF 格式的文件 .<br />
程序头表包含了加载到内存中的各种段的索引及属性信息，它将告诉加载器如何加载映像，初始化时，动态链接器首先解析出外部过程引用的绝对地址，一次性的修改所有相应的<br />
GOT 表项。<br />
linker 会在共享库加载时，调用 is_prelinked 查看该库是否是 prelink
的，并在 alloc_mem_region<br />
中检查目的地址是否被占用。 如果该库不是 prelink
的，则库加载的起始地址为零。</p></li>
</ol>
<p>3. 参考文档：</p>
<ol type="1">
<li><p>动态库优化—— Prelink （预连接）技术<br />
<a
href="http://www.eefocus.com/article/09-04/71629s.html">http://www.eefocus.com/article/09-04/71629s.html<br />
</a></p></li>
<li><p>Android build system note - 一醉千年 - CSDN 博客<br />
<a
href="http://blog.csdn.net/yili_xie/archive/2009/12/01/4906865.aspx">http://blog.csdn.net/yili_xie/archive/2009/12/01/4906865.aspx<br />
</a></p></li>
<li><p>Linux, Android 基础知识总结<br />
<a
href="http://wenku.baidu.com/view/f68fc029647d27284b735100.html">http://wenku.baidu.com/view/f68fc029647d27284b735100.html<br />
</a></p></li>
<li><p>android Linker 浅析<br />
<a
href="http://blog.csdn.net/dinuliang/archive/2010/04/20/5509009.aspx">http://blog.csdn.net/dinuliang/archive/2010/04/20/5509009.aspx<br />
</a></p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android基本组件及其交互</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/Android%E5%9F%BA%E6%9C%AC%E7%BB%84%E4%BB%B6%E5%8F%8A%E5%85%B6%E4%BA%A4%E4%BA%92/</url>
    <content><![CDATA[<h1 id="android基本组件及其交互">Android基本组件及其交互</h1>
<p>#移动开发 #android</p>
<p>一、 Android 的基本组件</p>
<p>1. Activity<br />
应用程序中每个屏幕显示都通过继承和扩展基类 Activity<br />
在一个应用程序中每个 Activity 都是独立的</p>
<p>2. Service<br />
Service 是没有可见的用户界面，但可以长时间在后台运行</p>
<p>3. Broadcast<br />
用户接受广播通知的组件，广播是一种同时通知多个对象的事件通知机制<br />
应用程序注册不同的 Broadcast Receiver ，从而接收不同广播通知<br />
不实现图形界面</p>
<p>4. Content Provider<br />
应用程序彼此间需要共享资源，数据通讯时，采用 content provider 机制<br />
它能将应用程序特写的数据提供给另一个应用程序使用</p>
<p>二、 组件间的通讯</p>
<p>1. ContentProvider 用于提供， ContentResolver 用于调用</p>
<p>2. Intent<br />
用于在不同组件间传递消息： Activity, Service, Broadcast<br />
Intent
一般带有一个组件对另一组件的请求的动作名称，请求动作及相关数据</p>
<ol type="1">
<li><p>Activity 相互调用<br />
Intent in = new Intent(ac01.this, pickup.class);<br />
startActivity(in);</p></li>
<li><p>Activity 与 Broadcast 相互调用<br />
public class AlarmReceiver extends BroadcastReceiver {<br />
<span class="citation" data-cites="Override">@Override</span><br />
public void onReceive(Context context, Intent intent)<br />
{<br />
ac01 app = ac01. <em>getApp</em> ();<br />
app.btEvent("from AlarmReceiver");<br />
}<br />
}<br />
Intent intent = new Intent(ac01.this, AlarmReceiver.class);<br />
PendingIntent p_intent = PendingIntent. <em>getBroadcast</em>
(ac01.this, 0, intent,<br />
0);<br />
// We want the alarm to go off 30 seconds from now.<br />
long firstTime = SystemClock. <em>elapsedRealtime</em> ();<br />
firstTime += 800;<br />
// Schedule the alarm!<br />
AlarmManager am = (AlarmManager)getSystemService( <em>ALARM_SERVICE</em>
);<br />
am.setRepeating(AlarmManager. <em>ELAPSED_REALTIME_WAKEUP</em> ,
firstTime, 800,<br />
p_intent);</p></li>
<li><p>Activity 与 Service 相互调用<br />
public class NotifyService extends Service{<br />
<span class="citation" data-cites="Override">@Override</span><br />
protected void onCreate() {<br />
ac01 app = ac01. <em>getApp</em> ();<br />
app.btEvent("from NotifyService");<br />
}<br />
<span class="citation" data-cites="Override">@Override</span> public
IBinder onBind(Intent intent) { return null; }<br />
}<br />
context.startService(new Intent(context, NotifyService.class));</p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android改变窗口标题栏的布局</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/Android%E6%94%B9%E5%8F%98%E7%AA%97%E5%8F%A3%E6%A0%87%E9%A2%98%E6%A0%8F%E7%9A%84%E5%B8%83%E5%B1%80/</url>
    <content><![CDATA[<h1 id="android改变窗口标题栏的布局">Android改变窗口标题栏的布局</h1>
<p>#移动开发 #android</p>
<p>一、 重点<br />
一般应用的 Title 都是建立应用时在 AndroidManifest.xml 中配置的，或是用
setTitle<br />
设置的简单字符串，要是想加入按钮，图片等多个复杂的布局，使用以下方法：<br />
在窗口建立时，可以把一个 xml 布局设置成该应用的 Title</p>
<p>二、 实例</p>
<ol type="a">
<li><p>功能：把 title 设置成为一个字串和一个按钮的组合</p></li>
<li><p>修改 xxActivity.java 代码<br />
** public ** ** void onCreate(Bundle savedInstanceState) {<br />
super.onCreate(savedInstanceState);<br />
requestWindowFeature(Window.FEATURE_CUSTOM_TITLE); ** // 注意顺序
**<br />
setContentView(R.layout.main); ** // 注意顺序 **<br />
getWindow().setFeatureInt(Window.FEATURE_CUSTOM_TITLE, ** // 注意顺序
**<br />
R.layout.title);<br />
} **</p></li>
<li><p>填加 title.xml 代码<br />
** "1.0" encoding="utf-8"? &gt;<br />
xmlns:android= <a
href="http://schemas.android.com/apk/res/android">http://schemas.android.com/apk/res/android<br />
</a><br />
android:layout_width= "wrap_content"<br />
android:layout_height="wrap_content"&gt;<br />
"@+id/text"<br />
android:layout_width="wrap_content"<br />
android:layout_height="wrap_content"<br />
android:layout_alignParentLeft="true"<br />
android:text="text" /&gt;<br />
"@+id/button"<br />
android:layout_width="wrap_content"<br />
android:layout_height="30px"<br />
android:text="button" /&gt;</p></li>
</ol>
<p>三、 注意</p>
<ol type="a">
<li><p>注意设置顺序<br />
requestWindowFeature 要在 setContentView 之前<br />
getWindow().setFeatureInit 最好在 setContentView 之后</p></li>
<li><p>注意 requestWindowFeature( Window.FEATURE_CUSTOM_TITLE )
不要和其它对 TITLE<br />
的设置 requestWindowFeature(xxxx) 一起使用</p></li>
</ol>
<p>**</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android电源管理</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/Android%E7%94%B5%E6%BA%90%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h1 id="android电源管理">Android电源管理</h1>
<p>#移动开发 #android</p>
<p>Android 电源管理</p>
<p>一、 相关概念</p>
<p>1.
出于节电的需要，一般应用在用户一段时间无操作的情况下屏幕变暗，然后进后休眠状态</p>
<p>2. 用户只能在 ” 设置 -&gt; 声音和显示 ”
中设置所有应用默认的屏幕亮度和进行待机的时间</p>
<p>3.
电源管理的实现分内核应用两部分，通过下面介绍的接口，我们可以设置应用程序的电源管理，以控制与其休眠相关的状态（是否需要进入休眠，调整
cpu<br />
频率，键盘灯的开关，屏幕的亮暗等）</p>
<p>二、 设置电源管理常用的几种状态<br />
PARTIAL_WAKE_LOCK 屏幕关，键盘灯关，不休眠<br />
SCREEN_MID_WAKE_LOCK 屏幕灰，键盘灯关，不休眠<br />
SCREEN_BRIGHT_WEEK_LOCK 屏幕亮，键盘灯关，不休眠<br />
FULL_WAKE_LOCK 屏幕亮，键盘灯亮，不休眠</p>
<p>三、 使用电源管理注意事项</p>
<p>1. 可在 onCreate 时设置该界面的电源管理，在 onDestroy 时取消设置</p>
<p>2. 可在 onResume 时设置该界面的电源管理，在 onPause 时取消设置</p>
<p>3. 注意设置是以 Activity 为单位，不是以应用为单位</p>
<p>4. 注意在 AndroidManifest.xml 中声明该应用有设置电源管理的权限</p>
<p>5. 注意加锁解锁要成对出现</p>
<p>6. 注意多个用途最好用多个锁，不要一锁多用，以免出错</p>
<p>7. 注意对运行在后台和异常时对锁的处理</p>
<p>8. 注意在网络连接或传输时最好加锁，以免传输被中断</p>
<p>9. 注意加锁以保证程序逻辑</p>
<p>四、 代码举例</p>
<p>1. 源码修改</p>
<ol type="1">
<li><p>引入电源管理包，以使用相关类<br />
** import ** ** android.os.PowerManager; **</p></li>
<li><p>类中加入变量<br />
** PowerManager.WakeLock mWakeLock; **</p></li>
<li><p>修改 onCreate<br />
** public ** ** void onCreate(Bundle savedInstanceState) {<br />
super.onCreate(savedInstanceState);<br />
PowerManager pm =<br />
(PowerManager) getSystemService(Context. <em>POWER_SERVICE</em> );<br />
mWakeLock = pm.newWakeLock(PowerManager.
<em>SCREEN_BRIGHT_WAKE_LOCK</em> ,<br />
"XYTEST");<br />
mWakeLock.acquire();<br />
} **</p></li>
<li><p>修改 onDestroy<br />
** public ** ** void onDestroy()<br />
{<br />
super.onDestroy();<br />
mWakeLock.release();<br />
} **</p></li>
</ol>
<p>2. AndroidManifest.xml 文件修改<br />
** "android.permission.WAKE_LOCK"/ &gt; **</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android的开机流程</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/Android%E7%9A%84%E5%BC%80%E6%9C%BA%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="android的开机流程">Android的开机流程</h1>
<p>#移动开发 #android</p>
<p>y</p>
<p>1. 系统引导 bootloader</p>
<ol type="1">
<li><p>源码： bootable/bootloader/*</p></li>
<li><p>说明：加电后， CPU 将先执行 bootloader
程序，此处有三种选择</p></li>
</ol>
<ol type="a">
<li><p>开机按 Camera+Power 启动到 fastboot ，即命令或 SD<br />
卡烧写模式，不加载内核及文件系统，此处可以进行工厂模式的烧写</p></li>
<li><p>开机按 Home+Power 启动到 recovery 模式，加载 recovery.img ，
recovery.img<br />
包含内核，基本的文件系统，用于工程模式的烧写</p></li>
<li><p>开机按 Power ，正常启动系统，加载 boot.img ， boot.img<br />
包含内核，基本文件系统，用于正常启动手机（以下只分析正常启动的情况）</p></li>
</ol>
<p>2. 内核 kernel</p>
<ol type="1">
<li><p>源码： kernel/*</p></li>
<li><p>说明： kernel 由 bootloader 加载</p></li>
</ol>
<p>3. 文件系统及应用 init</p>
<ol type="1">
<li><p>源码： system/core/init/*</p></li>
<li><p>配置文件： system/rootdir/init.rc ，</p></li>
<li><p>说明： init 是一个由内核启动的用户级进程，它按照 init.rc
中的设置执行：启动服务（这里的服务指 linux 底层服务，如<br />
adbd 提供 adb 支持， vold 提供 SD
卡挂载等），执行命令和按其中的配置语句执行相应功能</p></li>
</ol>
<p>4. 重要的后台程序 zygote</p>
<ol type="1">
<li><p>源码： frameworks/base/cmds/app_main.cpp 等</p></li>
<li><p>说明： zygote 是一个在 init.rc
中被指定启动的服务，该服务对应的命令是 /system/bin/app_process</p></li>
</ol>
<ol type="a">
<li><p>建立 Java Runtime ，建立虚拟机</p></li>
<li><p>建立 Socket 接收 ActivityManangerService 的请求，用于 Fork
应用程序</p></li>
<li><p>启动 System Server</p></li>
</ol>
<p>5. 系统服务 system server</p>
<ol type="1">
<li><p>源码：
frameworks/base/services/java/com/android/server/SystemServer.java</p></li>
<li><p>说明：被 zygote 启动，通过 System Manager 管理 android
的服务（这里的服务指<br />
frameworks/base/services
下的服务，如卫星定位服务，剪切板服务等）</p></li>
</ol>
<p>6. 桌面 launcher</p>
<ol type="1">
<li><p>源码： ActivityManagerService.java 为入口，
packages/apps/launcher* 实现</p></li>
<li><p>说明：系统启动成功后 SystemServer 使用 xxx.systemReady()
通知各个服务，系统已经就绪，桌面程序 Home<br />
就是在 ActivityManagerService.systemReady()
通知的过程中建立的，最终调用<br />
startHomeActivityLocked() 启 launcher</p></li>
</ol>
<p>7. 解锁</p>
<ol type="1">
<li><p>源码：<br />
frameworks/policies/base/phone/com/android/internal/policy/impl/<em>lock</em></p></li>
<li><p>说明：系统启动成功后 SystemServer 调用 wm.systemReady() 通知
WindowManagerService<br />
，进而调用 PhoneWindowManager ，最终通过 LockPatternKeyguardView<br />
显示解锁界面，跟踪代码可以看到解锁界面并不是一个 Activity
，这是只是向特定层上绘图，其代码了存放在特殊的位置</p></li>
</ol>
<p>8. 开机自启动的第三方应用程序</p>
<ol type="1">
<li><p>源码：<br />
frameworks/base/services/java/com/android/server/am/ActivityManagerService.java</p></li>
<li><p>说明：系统启动成功后 SystemServer 调用<br />
ActivityManagerNative.getDefault().systemReady() 通知 ActivityManager
启动成功，<br />
ActivityManager 会通过置变量 mBooting
，通知它的另一线程，该线程会发送广播<br />
android.intent.action.BOOT_COMPLETED
以告知已注册的第三方程序在开机时自动启动。</p></li>
</ol>
<p>9. 总结<br />
综上所述，系统层次关于启动最核心的部分是 zygote( 即 app_process) 和
system server ， zygote<br />
它负责最基本的虚拟机的建立，以支持各个应用程序的启动，而 system server
用于管理 android 后台服务，启动步骤及顺序。</p>
<p>10. 参考</p>
<p><a
href="http://blog.csdn.net/basonjiang_sz/category/648399.aspx">http://blog.csdn.net/basonjiang_sz/category/648399.aspx<br />
</a></p>
<p>(转载请注明出处: <a
href="http://xy0811.spaces.live.com/">http://xy0811.spaces.live.com/</a>
)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android系统文件结构</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/Android%E7%B3%BB%E7%BB%9F%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<h1 id="android系统文件结构">Android系统文件结构</h1>
<p>#移动开发 #android</p>
<p>一、 镜像文件 image</p>
<p>1. 如何得到镜像文件</p>
<ol type="1">
<li><p>编译 android 源码之后，在 out/target/product/generic 产生<br />
ramdisk.img 、 system.img 、 userdata.img</p></li>
<li><p>SDK 的 platforms/android-*/images<br />
ramdisk.img 、 system.img 、 userdata.img</p></li>
</ol>
<p>2. 各镜像文件的含义</p>
<ol type="1">
<li><p>system.img 是由 system
目录打包压缩得到的，以只读方式挂载。</p></li>
<li><p>userdata.img 是由 data
目录打包压缩得到的，以读写方式挂载，用于存放用户数据，用户安装的软件包在被装在这里。</p></li>
<li><p>ramdisk.img 是模拟器的文件系统，把 ramdisk.img 解压出来可知道，
ramdisk.img<br />
里的文件和根文件夹的文件基本一样。</p></li>
</ol>
<p>3. 镜像文件的挂载顺序<br />
模拟器装载 ramdisk.img 并解压到内存，接着分别把 system.img 和
userdata.img 挂载到 ramdisk<br />
下的 system 和 data 目录。</p>
<p>4. 如何更改系统的镜像文件</p>
<ol type="1">
<li><p>模拟器<br />
运行模拟器时指明镜像文件名参数，可以使用新生成的镜像文件</p></li>
<li><p>真机<br />
通过烧写替换原有镜像文件</p></li>
</ol>
<p>** 二、 ** ** 系统目录说明 ** ****</p>
<p>** 1. ** ** 应用程序安装目录 ** ****</p>
<p>** 1) ** ** 系统应用程序所在目录<br />
/system/app/*.apk <strong> </strong>**</p>
<p>** 2) ** ** 用户安装应用程序所在目录<br />
/data/app/*.apk <strong> </strong>**</p>
<ol start="3" type="1">
<li>注意：</li>
</ol>
<ol type="a">
<li>在模拟器中，每重启一次， /system/app/ 下的应用都会被还原，有时
/data/app 下也会被清除</li>
</ol>
<p>** b) ** 若在 /system/app 和 /data/app
下有重名的应用，不一定会启动哪一个，尤其是在 adb install<br />
杀死正在运行的程序时，有时旧的就会被启动 ****</p>
<p>2. 用户数据所在目录<br />
/data/data/ 应用包名 /shared_prefs 配置文件<br />
/data/data/ 应用包名 /databases/* 库文件所在目录</p>
<p>3. SD 卡对应目录<br />
/sdcard/</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>androidflash分区(nandflash)</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/androidflash%E5%88%86%E5%8C%BA(nandflash)/</url>
    <content><![CDATA[<h1 id="android-flash分区nand-flash">android flash分区(nand flash)</h1>
<p>#移动开发 #android</p>
<p>1. 查看当前系统的分区情况</p>
<pre><code>$ adb shell    
$ cat /proc/mtd  </code></pre>
<p>2. 分区对应的 img （源码编译后生成在 out/target/product/xxx/
目录下）</p>
<ol type="a">
<li>modem( 多个，支持电话和 GPS)</li>
</ol>
<p>amss.mbn</p>
<ol start="2" type="a">
<li>bootloader( 启动用 )</li>
</ol>
<p>appsboot.mbn</p>
<ol start="3" type="a">
<li><p>空中升级<br />
fota*( 升级用 , 可能多个 )</p></li>
<li><p>内核和文件系统<br />
boot.img( 内核和基本文件系统 )</p></li>
<li><p>系统分区<br />
system.img( 系统分区 )</p></li>
<li><p>用户数据分区<br />
userdata.img( 数据分区 )</p></li>
</ol>
<p>3. 参考</p>
<ol type="a">
<li>bootloader 启动顺序<br />
http://blog.csdn.net/yili_xie/archive/2010/05/14/5592276.aspx</li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android之JNI</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/android%E4%B9%8BJNI/</url>
    <content><![CDATA[<h1 id="android之jni">android之JNI</h1>
<p>#移动开发 #android</p>
<p>1. 为什么使用 JNI<br />
JNI （ Java Native Interface ） Java 程序中调用 C/C++
开发的共享库，主要用于提高程序效率，或者<br />
Android 应用对 C/C++ 库的调用（多用于调用移植的库，如语音合成库 pico
，图像识别库 opencv 等）</p>
<p>2. android 源码中自带的实例<br />
development/samples/SimpleJNI/*</p>
<p>3. 实例</p>
<ol type="1">
<li><p>编译环境<br />
Ubuntu 10.04, android 源码环境</p></li>
<li><p>重要代码说明</p></li>
</ol>
<ol type="a">
<li>java 代码<br />
</li>
</ol>
<pre><code>_ package com.android.myjni;  _  
_ _  
_ import android.app.Activity;  _  
_ import android.widget.TextView;  _  
_ import android.os.Bundle;  _  
_ _  
_ public class MyJniActivity extends Activity  _  
_ &#123;  _  
_ @Override  _  
_ public void onCreate(Bundle savedInstanceState)  _  
_ &#123;  _  
_ super.onCreate(savedInstanceState);  _  
_ _  
_ TextView tv = new TextView(this);  _  
_ tv.setText( stringFromJNI() ); //  _ _ 调用内部函数，和调用普通函数一样  _ __  
_ setContentView(tv);  _  
_ &#125;  _  
_ _  
  
_ public native String stringFromJNI(); //  _ _ 用  _ _ native  _ _ 关键字，声名  _ _  
JNI  _ _ 函数，说明它是用  _ _ C++/C  _ _ 语言实现的  _ __  
_ _  
_ static &#123;  _  
_ System.loadLibrary(&quot;test&quot;); //  _ _ 装载名为  _ _ libtest.so  _ _ 的库，库要放在指定的文件夹下  
_ _ (/system/lib  _ _ 或  _ _ /data/data/xxx/lib/)  _  
_ &#125;  _  
_ &#125;  _  </code></pre>
<ol start="2" type="a">
<li>C/C++ 代码<br />
</li>
</ol>
<pre><code>_ #include  _  
_ #include  _  
_ _  
_ jstring  _  
  
_ Java_com_android_myjni_MyJniActivity_stringFromJNI( JNIEnv* env, jobject  
thiz ) // C  _ _ 函数实现，函数名字不同  _ _ (Java_  _ _ 项目名  _ _ _  _ _ 类名  _ _ _  _ _  
函数名  _ _ )  _ _ ，参数要做一些转换  _ __  
_ &#123;  _  
_ return (*env)- &gt;NewStringUTF(env, &quot;Hello from JNI !&quot;); //  _ _ 返回字串  _ __  
_ &#125;  _  </code></pre>
<ol start="3" type="1">
<li>Android.mk ，在编译脚本中指名即编译 java 程序，也编译 C/C++
程序<br />
</li>
</ol>
<pre><code>_ LOCAL_PATH:= $(call my-dir)  _  
_ include $(CLEAR_VARS)  _  
_ _  
_ LOCAL_SRC_FILES := $(call all-java-files-under, src)  _  
_ _  
_ LOCAL_PACKAGE_NAME := myjni  _  
_ include $(BUILD_PACKAGE) //  _ _ 编译  JAVA  包  _  
_ _  
_ include $(CLEAR_VARS)  _  
_ LOCAL_C_INCLUDES := /  _  
_ $(JNI_H_INCLUDE) /  _  
_ LOCAL_PRELINK_MODULE:=false  _  
_ LOCAL_MODULE := libtest  _  
_ LOCAL_SRC_FILES := jni/test-jni.c  _  
_ _  
_ include $(BUILD_SHARED_LIBRARY) //  _ _ 编译  C  库  _  </code></pre>
<ol start="4" type="1">
<li>编译<br />
</li>
</ol>
<pre><code>$ cd myjni    
$ mm  </code></pre>
<ol start="5" type="1">
<li>安装<br />
</li>
</ol>
<pre><code>$ adb install out/target/product/xxx/system/app/myjni.apk    
$ adb push out/target/product/xxx/system/lib/libtest.so  
/data/data/com.android.myjni/lib/  </code></pre>
<ol start="6" type="1">
<li>完整例程下载<br />
<a
href="http://download.csdn.net/source/2610530">http://download.csdn.net/source/2610530<br />
</a></li>
</ol>
<p>4. 说明<br />
此例中将 so 库手动 push 到 android 系统中，如果想将 so 库打在 apk
包里安装，建议采用 NDK<br />
，另有一种不太正式的方式不用 NDK 也能实现此功能（不推荐），见<br />
<a
href="http://blog.csdn.net/chenji001/archive/2009/09/27/4601622.aspx">http://blog.csdn.net/chenji001/archive/2009/09/27/4601622.aspx<br />
</a></p>
<p>(转载请注明出处: <a
href="http://xy0811.spaces.live.com/">http://xy0811.spaces.live.com/</a>
)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android应用的启动过程</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/android%E5%BA%94%E7%94%A8%E7%9A%84%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="android应用的启动过程">android应用的启动过程</h1>
<p>#移动开发 #android</p>
<p>1. 说明<br />
应用的启动过程通常是通过 startActivity
函数，无论是在应用中调其它应用还是在桌面（桌面是 Launcher<br />
应用）上点击，最终都将通过这个函数启动进程或者界面，下面以分析代码的方式，介绍它具体的工作过程</p>
<p>2. 过程</p>
<ol type="1">
<li>Launcher/src/com/android/launcher.java</li>
</ol>
<p>在应用或桌面上启动应用，例如桌面应用的启动由于中调用了
startActivity() 函数</p>
<ol start="2" type="1">
<li><p>frameworks/base/core/java/android/app/Activity.java:startActivity()<br />
Activity.java 继承了 Context.java ，并实现了它的 startActivity()
，它向下调用了<br />
execStartActivity()</p></li>
<li><p>frameworks/base/core/java/android/app/Instrumentation.java:execStartActivity()<br />
execStartActivity 利用 IntentFilter 得到具体 Activity ，并调用了更下层的
startActivity</p></li>
<li><p>frameworks/base/core/java/android/app/ActivityManagerNative.java<br />
ActivityManagerProxy.startActivity()<br />
IBinder.transact(….);<br />
它通过 Binder 的方式与 ActivityManagerService.java
通讯，并发送启动请求</p></li>
<li><p>frameworks/base/core/java/android/os/Binder.java:execTransact()<br />
Binder 消息转递的实现，用于用户应用与后台服务的通讯</p></li>
<li><p>frameworks/base/services/java/com/android/server/am/ActivityManagerService.java<br />
onTransact();<br />
startProcessLocked() ；<br />
开启新线程</p></li>
<li><p>frameworks/base/core/java/android/os/Process.java 的函数 start
为入口<br />
通过 socket 发给 zygote 进程</p></li>
<li><p>frameworks/base/core/java/com/android/internal/os/Zygote*.java<br />
告知虚拟机新建进程，此时会将要建立的进程名，用户名，组名一并传给虚拟机，以建立进程</p></li>
<li><p>dalvik/libcore/dalvik/src/main/java/dalvik/system/Zygote.java<br />
虚拟机处理</p></li>
<li><p>dalvik/vm/native/dalvik_system_Zygote.c
(forkAndSpecializeCommon)<br />
虚拟机处理</p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android开机动画</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/android%E5%BC%80%E6%9C%BA%E5%8A%A8%E7%94%BB/</url>
    <content><![CDATA[<h1 id="android-开机动画">android 开机动画</h1>
<p>#移动开发 #android</p>
<p>1. 介绍<br />
android 开机画面由三部分组成，第一部分在 bootloader
启动时显示，第二部分在启动 kernel 时显示，第三部分在系统启动时（<br />
bootanimation ）显示（动画）</p>
<p>2. bootloader 开机图片</p>
<ol type="1">
<li><p>一般使用 rle 格式图片，不同的 android
系统不同此图片可能放在不同位置，以下实例均以 G1 为例， G1 放在<br />
splash 分区中</p></li>
<li><p>制作 rle 格式开机图片</p></li>
</ol>
<ol type="a">
<li><p>将图片转成 320x480 ， 256 色，保存成不带 Alpha 通道的 png
格式</p></li>
<li><p>使用 convert 工具将 splash.png 转换成８位色的 splash.raw<br />
convert splash.png -depth 8 rgb:splash.raw<br />
确认 splash.raw 大小为 460800 字节</p></li>
<li><p>使用 android 工具 rgb2565 改变图像格式<br />
out/host/linux-x86/bin/rgb2565 &lt; splash.raw &gt; splash.raw565<br />
确认 splash.raw565 大小为 307200 字节</p></li>
</ol>
<ol start="3" type="1">
<li>烧写（以 G1 为例）<br />
按 Power+Camera 启动到烧写模式<br />
fastboot flash splash1 splash.raw565</li>
</ol>
<p>3. kernel 开机图片</p>
<ol type="1">
<li>相关代码<br />
kernel/drivers/video/msm/msm_fb.c （ G1 使用高通芯片组 MSM7201
芯片组）<br />
它会读出根目录下的 xx.rle ，并显示为开机画面， rle 做法同上</li>
</ol>
<p>4. bootanimation 开机动画</p>
<ol type="1">
<li>android 2.0 之前</li>
</ol>
<ol type="a">
<li><p>说明<br />
使用 bootanimation
程序显示开机画面，如需修改开机画面，需要修改源码</p></li>
<li><p>代码<br />
frameworks/base/cmds/bootanimation/*<br />
frameworks/base/core/res/assets/images/android-logo*</p></li>
</ol>
<ol start="2" type="1">
<li>android 2.0 及之后</li>
</ol>
<ol type="a">
<li><p>说明<br />
使用 bootanimation
程序显示开机画面，如需修改开机画面，不用修改代码，只需按格式要求做
bootanimation.zip<br />
包，放在系统的 /system/media 目录中，或 /data/local
目录中即可，两个目录下都存在时，优先使用 /data/local<br />
下的</p></li>
<li><p>代码<br />
frameworks/base/cmds/bootanimation/*<br />
frameworks/base/core/res/assets/images*</p></li>
<li><p>制作动画包</p></li>
</ol>
<ol type="i">
<li><p>描述文件 desc.txt<br />
480 427 30<br />
p 1 0 part0<br />
p 0 10 part1<br />
总体说明： 480 为宽度， 427 为高度， 30 为帧数，即每秒播放动画 30
帧<br />
部分说明：第一项 p 为标志符，第二项为循环次数 1 为只播放 1
次，０为无限循环，第三项为两次循环之间间隔的帧数，第四项为对应的目录名</p></li>
<li><p>图片<br />
图片放在 desc.txt 中目录名指定的目录中，目录中按字符顺序播放</p></li>
<li><p>打包</p></li>
</ol>
<p>² windows<br />
使用 winrar 找包，选择 ZIP 格式，压缩标准要选 “ 储存 ”</p>
<p>² linux<br />
zip -0 -r ../bootanimation.zip ./*<br />
linux 命令使用 -0 指定压缩等级为最低等级 stored
，即只归档不压缩，否则可能由于包格式问题引起动画显示为黑屏</p>
<p>² 注意<br />
打包不要带上层目录</p>
<p>5. 参考</p>
<ol type="1">
<li><p>bootanimation 相关<br />
<a
href="http://blog.21ic.com/user1/2537/archives/2009/65606.html">http://blog.21ic.com/user1/2537/archives/2009/65606.html<br />
</a></p></li>
<li><p>rle 文件制作<br />
<a
href="http://hi.baidu.com/kernel_linux/blog/item/9eff140f9d089c206159f3cb.html">http://hi.baidu.com/kernel_linux/blog/item/9eff140f9d089c206159f3cb.html<br />
</a></p></li>
<li><p>bootloader 启动<br />
<a
href="http://blog.csdn.net/yili_xie/archive/2010/05/14/5592276.aspx">http://blog.csdn.net/yili_xie/archive/2010/05/14/5592276.aspx<br />
</a></p></li>
</ol>
<p>(转载请注明出处 <a
href="http://xy0811.spaces.live.com/">http://xy0811.spaces.live.com/</a>
)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android权限的实现</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/android%E6%9D%83%E9%99%90%E7%9A%84%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="android-权限的实现">android 权限的实现</h1>
<p>#移动开发 #android</p>
<p>1. 权限<br />
每个程序在安装时都有建立一个系统 ID ，如 app_15
，用以保护数据不被其它应用获取。 Android<br />
根据不同的用户和组，分配不同权限，比如访问 SD
卡，访问网络等等。底层映射为 Linux 权限。</p>
<p>2. 应用申请权限</p>
<ol type="1">
<li><p>应用开发者通过 AndroidManifest.xml 中 <uses-permission><br />
指定对应权限，再映射到底层的用户和组，默认情况下不设定特殊的权限。
AndroidManifest 加入权限后系统安装程序时会在图形界面中提示权限</p></li>
<li><p>如果是缺少某个权限（程序中使用的某种权限而在 AndroidManifest.xml
中并未声名），程序运行时会在 logcat<br />
中打印出错误信息 requires <permission></p></li>
<li><p>与某个进程使用相同的用户 ID<br />
应用程序可与系统中已存在的用户使用同一权限，需要在 AndroidManifest.xml
中设置 sharedUserId ，如<br />
android:sharedUserId="android.uid.shared"
，作用是获得系统权限，但是这样的程序属性只能在 build<br />
整个系统时放进去（就是系统软件）才起作用，共享 ID
的程序必须是同一签名的</p></li>
</ol>
<p>3. Android 权限的实现</p>
<ol type="1">
<li><p>第一层：由应用设置，修改 AndroidManifest.xml ，形如：<br />
<code>&lt;uses-permission android:name=”android.permission.INTERNET”/&gt;</code></p></li>
<li><p>第二层：框架层，权限对应组，
frameworks/base/data/etc/platform.xml ，形如：</p>
<pre><code>&lt;permission name=”android.permission.INTERNET”&gt;    
&lt;group gid=inet” /&gt;    
&lt;/permission&gt;  </code></pre></li>
<li><p>第三层：系统层，系统的权限，
system/core/include/private/android_filesystem_config.h,<br />
形如：</p>
<pre><code>#define AID_INET 3003  建立  SOCKET  的权限    
……    
&#123; “inet”, AID_INET, &#125;,  </code></pre>
<p>4. 系统权限</p></li>
<li><p>特殊权限的用户</p></li>
</ol>
<ol type="a">
<li><p>system uid 1000</p></li>
<li><p>radio uid 1001</p></li>
</ol>
<ol start="2" type="1">
<li>查看可用系统的权限<br />
$ adb shell<br />
# pm list permissions</li>
</ol>
<p>5. framework 层对权限的判断</p>
<ol type="1">
<li><p>相关源码实现<br />
frameworks/base/services/java/com/android/server/PackageManagerService.java<br />
frameworks/base/services/java/com/android/server/am/ActivityManagerService.java</p></li>
<li><p>在系统层，如何查看某个应用的权限</p></li>
</ol>
<ol type="a">
<li><p>在应用进程开启时， ActivityManagerService.java 会在 logcat
中输出该应用的权限，形如：<br />
I/ActivityManager(1730): Start proc com.anbdroid.phone for restart<br />
com.android.phone:pid=2605 uid=1000 gids={3002,3001,3003}<br />
即它有 3001,3002,3003 三个权限：访问蓝牙和建立 socket</p></li>
<li><p>注意：此打印输出在应用第一次启动时。如果进程已存在，需要先把对应进程杀掉，以保证该进程重新启动，才能显示</p></li>
<li><p>具体实现，见：<br />
framewors/base/services/java/com/android/server/am/ActivityManagerService.java<br />
的函数 startProcessLocked() ，其中取其组信息的具本语句是<br />
mContext.getPackageManager().getPackageGids(app.info.packageName);</p></li>
</ol>
<p>6. 参考<br />
<a
href="http://wenku.baidu.com/view/7754a4360b4c2e3f5727634e.html">http://wenku.baidu.com/view/7754a4360b4c2e3f5727634e.html<br />
</a></p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android源码中常用于参考的代码</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/android%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E4%BA%8E%E5%8F%82%E8%80%83%E7%9A%84%E4%BB%A3%E7%A0%81/</url>
    <content><![CDATA[<h1
id="android源码中常用于参考的代码">android源码中常用于参考的代码</h1>
<p>#移动开发 #android</p>
<p>在应用开发时，常遇到有些功能不知是否能实现，不知如何实现的问题，在网上资料又不多的情况下，可以用参考已有源码的方式来解决这些问题，经常参考的目录如下</p>
<p>1、 系统控件的实现：了解有什么控件，控件的功能，功能如何实现<br />
frameworks/base/core/java/android/*</p>
<p>2、 应用程序的实现： Android
系统中所有的应用程序都在这里实现，了解它们如何实现<br />
package/apps/*</p>
<p>3、 系统提供的例程：各种类型程序的实现范例<br />
development/samples/*</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android系统支持app2sd（修改boot.img）</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/android%E7%B3%BB%E7%BB%9F%E6%94%AF%E6%8C%81app2sd%EF%BC%88%E4%BF%AE%E6%94%B9boot.img%EF%BC%89/</url>
    <content><![CDATA[<h1
id="android系统支持app2sd修改boot.img">android系统支持app2sd（修改boot.img）</h1>
<p>#移动开发 #android</p>
<p>1. app2sd 是什么<br />
app2sd 就是把应用程序放在 SD 卡上。有些 android 手机的用户数据分区
(userdata) 比较小（比如 G1 只有<br />
76 Ｍ）， dalvik 和 cache
和用户数据就占了大半，使得安装了几个软件后就没有空间了。为了安装更多软件，在
SD<br />
卡上划出部分空间用于存在新软件和数据，使我们的手机可以使用更多软件。</p>
<p>2. 原理<br />
一般情况下都 SD 卡都默认分成一个 windows 可识别的分区（ FAT ）。因为有
linux<br />
系统的权限问题，为了让它可以存放软件，需要把 SD 卡的一部分划分成 Linux
的使用的 ext2<br />
文件系统，然后在开机时把此分区挂载到某处，并通过链接的方法，让系统从 SD
卡中读取软件</p>
<p>3. 实现</p>
<ol type="1">
<li>SD 卡分区</li>
</ol>
<ol type="a">
<li><p>使用 Linux 系统中的工具 fdisk
，它是命令行工具，很快很简单</p></li>
<li><p>Windows 下的图形化工具<br />
具体步骤见 <a
href="http://www.3haoweb.cn/a/digital/mobile/2010/0609/2273.html">http://www.3haoweb.cn/a/digital/mobile/2010/0609/2273.html<br />
</a></p></li>
</ol>
<ol start="2" type="1">
<li>修改 boot.img 使得新分区在启动时被自动挂载</li>
</ol>
<ol type="a">
<li>说明：</li>
</ol>
<ol type="i">
<li><p>也可以从网上下载带 app2sd 功能的 update.zip<br />
包，升级整个系统，但是那样的话还要备份设置、数据、软件太麻烦，所以我选择修改我手机中自带的
boot.img ，以最小的修改来实现功能</p></li>
<li><p>修改 boot.img 中的 initrc （系统启动时运行的脚本，自动挂载 SD
卡的 ext2 分区）</p></li>
</ol>
<ol start="2" type="a">
<li><p>boot.img 是什么<br />
boot.img 包括了 2K 的文件头，后面紧跟着是用 gzip
压缩过的内核，再后面是一个 ramdisk<br />
内存盘（系统基本目录结构的镜像档），然后紧跟着第二阶段的载入器程序（这个载入器程序是可选的，在某些映像中或许没有这部分）</p></li>
<li><p>修改本机的 boot.img 包</p></li>
</ol>
<ol type="i">
<li><p>使用 nandroid 备份数据<br />
任何对系统的修改都要先备份系统数据</p></li>
<li><p>从机器中取出当前的 boot.img<br />
_ $ export PATH=<span
class="math inline">\(PATH:\)</span>ANDROID_DIR/out/host/linux-x86/bin/<br />
$ adb shell<br />
# cat /proc/mtd/ _ _ 查看 _ _ boot _ _ 对应的 _ _ mtdx _ _ ，一般是 _ _
mtd2<br />
# cat /dev/mtd/mtd2 &gt; /sdcard/boot.img _ _ 假设 _ _ boot _ _ 对应 _ _
mtd2<br />
# mkdir /system/sd1 _ _ 建立目录以挂载分区 _ _<br />
# exit<br />
$ adb pull /sdcard/boot.img ./ _ _ 复制到 _ _ PC _ _ 中 _</p></li>
<li><p>解包<br />
下载工具 split_boot.img.pl<br />
<a
href="http://cid-f8aecd2a067a6b17.office.live.com/self.aspx/.Public/android/reference/split%5E_bootimg.zip"><br />
http://cid-f8aecd2a067a6b17.office.live.com/self.aspx/.Public/android/reference/split^_bootimg.zip<br />
</a><br />
_<br />
$ ./split_boot.img.pl boot.img _ _ 解包，解出内核和 _ _ ramdisk _ _
包两部分 _<br />
_ $ mkdir ramdisk; cd ramdisk<br />
$ gzip -dc ../boot.img-ramdisk.gz |cpio -i _</p></li>
<li><p>修改启动脚本 _<br />
$ vi init.rc _ _ 如果是乱码，请使用 _ _ reset _ _ 命令恢复一下 _ _<br />
_ _ 在 _ _ mount _ _ 最后加入 _ _<br />
mount ext2 /dev/block/mmcblk0p2 /system/sd1 rw _</p></li>
<li><p>重新打包<br />
_ $ cd ../<br />
$ mkbootfs ramdisk |gzip &gt; ramdisk-new.gz<br />
$ mkbooting --cmdline ‘no_console_suspend=1 console=null’ --kernel
boot.img-<br />
kernel --ramdisk ramdisk-new.gz -o boot_new.img<br />
(mkbootfs _ _ ， _ _ mkbootimg _ _ 可以 _ _ android _ _ 源码包中取得，和
_ _ adb _<br />
_ 在一个目录 _ _ ) _</p></li>
<li><p>烧写新包到手机<br />
_ $ adb push boot_new.img /sdcard<br />
$ adb shell<br />
# cat /dev/zero &gt; /dev/mtd/mtd2 ( _ _ 可能找错没空间，没关系 _ _
)<br />
# flash_image boot /sdcard/boot_new.im _</p></li>
<li><p>验证是否成功<br />
然后重启手机即可，重启后用以下命令看一下是否分区是否被挂载<br />
_ $ adb shell<br />
$ df _ _ 如果看到 _ _ /system/sd1 _ _ 项就成功了 _</p></li>
</ol>
<ol start="3" type="1">
<li><p>做链接，使系统从 SD 卡读取软件<br />
建立只对软件安装目录做修改（ /data/app ），这样拨出 SD
后除了后来安装的软件不能使用之外，不影响手机基本功能的使用<br />
_ $ adb shell<br />
# mkdir /system/sd1/data/<br />
# cd /system/sd1/data/ _<br />
_ # busybox cp -a /data/app ./ _ _ 建议做 _ _<br />
# busybox cp -a /data/app-private ./ _ _ 不建议做 _ _<br />
# busybox cp -a /data/dalvik-cache ./ _ _ 不建议做 _ _<br />
# busybox cp -a /data/data ./ _ _ 不建议做 _ _<br />
# rm -r /data/app<br />
# ln -s /system/sd1/data/app /data/app _<br />
……<br />
其它目录以此类推<br />
然后重启手机即可</p></li>
<li><p>注意<br />
由于 launcher
数据库的关系，可能桌面上看不到原来的那些应用了，不过主菜单里是有的，再建一遍快捷方式即可</p></li>
</ol>
<p>4. 参考<br />
<a
href="http://kb.cnblogs.com/a/1743704/">http://kb.cnblogs.com/a/1743704/</a></p>
<p>(转载请注明作者及出处 <a
href="http://xy0811.spaces.live.com/">http://xy0811.spaces.live.com/</a><br />
)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android系统自带的Service原理与使用</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/android%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%B8%A6%E7%9A%84Service%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h1
id="android系统自带的service原理与使用">android系统自带的Service原理与使用</h1>
<p>#移动开发 #android</p>
<p>1. 说明<br />
android 的后台运行在很多 service ，它们在系统启动时被 SystemServer
开启，支持系统的正常工作，比如<br />
MountService 监听是否有 SD 卡安装及移除， ClipboardService
提供剪切板功能，<br />
PackageManagerService
提供软件包的安装移除及查看等等，应用程序可以通过系统提供的 Manager
接口来访问这些<br />
Service 提供的数据，以下将说明他们的工具流程</p>
<p>2. 举例说明基本流程<br />
以 android 系统支持 sensor （传感器）实例来说明框架层的 service 和
manager 是如何配合工作的</p>
<ol type="1">
<li><p>什么是 sensor<br />
sensor 是传感器 , 比如控制横竖屏切换利用的就是重力传感器 (gsensor), 还有
accelerator sensor 可取得<br />
x, y, z 三个轴上的加速度 ( 应用如平衡球 , 小猴吃香蕉等 )</p></li>
<li><p>应用程序调用（以下为关键代码）<br />
sensorManager=(SensorManager)getSystemService(context.SENSOR_SERVICE);<br />
lightSensor = sensorManager.getDefaultSensor(Sensor.TYPE_LIGHT);<br />
sensorManager.registerListener(sensorListener, lightSensor,<br />
SensorManager.SENSOR_DELAY_NORMAL);</p></li>
<li><p>Manager 层</p></li>
</ol>
<ol type="a">
<li>提供给应用程序调用的接口，同实与 Service 交互，实现功能<br />
frameworks/base/core/java/android/hardware/SensorManager.java</li>
</ol>
<ol start="4" type="1">
<li>Service 层</li>
</ol>
<ol type="a">
<li><p>开机时就运行的管理 Sensor 的后台服务<br />
frameworks/base/services/java/com/android/server/SensorService.java</p></li>
<li><p>snesor 后台服务需要的 JNI ，通过它与系统级交互<br />
frameworks/base/services/jni/com_android_server_SensorService.cpp</p></li>
</ol>
<ol start="5" type="1">
<li>系统层</li>
</ol>
<ol type="a">
<li><p>传感器的头文件，硬件提供商按此文件的定义实现其功能<br />
hardware/libhardware/include/hardware/sensors.h</p></li>
<li><p>传感器的系统层实现，与内核交互，此处通常是硬件提供商提供的<br />
hareware/libsensors</p></li>
</ol>
<ol start="6" type="1">
<li>内核及硬件层<br />
内核访问硬件，同时以设备文件等方式提供给上层控制接口和传感器数据</li>
</ol>
<p>3. 系统层实现</p>
<ol type="1">
<li><p>frameworks/base/core/java/android/*Manager.java
对应用的接口</p></li>
<li><p>frameworks/base/core/jni/ 对应用的接口的 JNI</p></li>
<li><p>frameworks/base/services/java/com/android/server/
后台服务</p></li>
<li><p>frameworks/base/services/jni/ JNI 与系统层接口</p></li>
<li><p>hardware/libhardware/include/ 系统层头文件</p></li>
<li><p>hardware/libxxx 系统库支持</p></li>
<li><p>内核支持</p></li>
</ol>
<p>4. 应用程序如何使用</p>
<ol type="1">
<li><p>查看系统提供哪些服务<br />
find frameworks/base/core/java/android/ -name *Manager.java<br />
此处可以看到调用系统提供服务的入口</p></li>
<li><p>一般 register listener ，事件发生时都收到回调</p></li>
</ol>
<p>5. 新建一个 service （以 froyo 为例）</p>
<ol type="1">
<li><p>接口 ： 接口供应用调用<br />
frameworks/base/core/java/android/app/ContextImpl.java 加服务名与
Manager 对应<br />
frameworks/base/core/java/android/content/Context.java
加服务名定义</p></li>
<li><p>Manager ： 提供服务对应的调用接口<br />
frameworks/base/core/java/android/app/StartXXXXManager.java
实现调用接口<br />
frameworks/base/core/java/android/app/IXXXXManager.aidl
定义调用接口<br />
frameworks/base/Android.mk 加入 aidl 的编译</p></li>
<li><p>service ： 提供后台服务支持<br />
frameworks/base/services/java/com/android/server/XXXXService.java
服务实现<br />
frameworks/base/services/java/com/android/server/SystemServer.java
启动服务</p></li>
</ol>
<p>(转载请注明出处 <a
href="http://xy0811.spaces.live.com/">http://xy0811.spaces.live.com/</a>
)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android适配硬件平台</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/android%E9%80%82%E9%85%8D%E7%A1%AC%E4%BB%B6%E5%B9%B3%E5%8F%B0/</url>
    <content><![CDATA[<h1 id="android适配硬件平台">android适配硬件平台</h1>
<p>#移动开发 #android</p>
<p>1. 相关硬件<br />
电池， RTC ，键值（普通键值， DOCKING 键值）， LED<br />
灯，背光，传感器（亮度，距离，速度，指南针等），振动，蓝牙，相机，音视频引擎，网络，显示，电话</p>
<p>2. 硬件相关的主要目录</p>
<p>kernel ， vendor ， device ， hardware ， bootable</p>
<p>3. 以 HTC G1 为例分析其主要的平台配置目录 device/htc/dream/* (froyo
源码 )</p>
<ol type="1">
<li><p>注意： froyo 以前版本在 vendor/htc 中，需要单独下载，现在都已经在
git 里包含了 g1,g2 的支持。</p></li>
<li><p>说明 ( 参见 g1,g2)</p></li>
</ol>
<ol type="a">
<li><p>AndroidProducts.mk<br />
说明产品都需要编什么东西，定义产品使用哪个 mk 文件</p></li>
<li><p>vendorsetup.sh<br />
加上某硬件的支持，以便编译前用 lunch 选择</p></li>
<li><p>full_dream.mk<br />
定义产品所要编译的项目，指定需要编译哪些应用，产品名称，设备，型号（重要）</p></li>
<li><p>BoardConfig.mk<br />
含 mtd 设备的分区，硬件相关的模块，及编译工具</p></li>
<li><p>AndroidBoard.mk<br />
编译 kernel, bootload, nandwrite, 键值定义文件 ,
开机画面的说明，重要的是 kernel 的默认配置文件<br />
KERNEL_DEFCONFIG</p></li>
<li><p>device_*.mk<br />
相关具体硬件（美国版的 G1 ），</p></li>
<li><p>overlay<br />
格式类似源码根目录，存在定制产生用到的资源</p></li>
<li><p><em>.kl, </em>.kcm<br />
键值定义</p></li>
<li><p>*.sh<br />
辅助工具的脚本，如从 update.zip 中提取库</p></li>
</ol>
<p>4. 编译某平台相关代码</p>
<ol type="1">
<li>G1/G2</li>
</ol>
<ol type="a">
<li><p>下载并编译 kernel</p></li>
<li><p>从手机或 update.zip 中提取 so 库</p></li>
<li><p>编译，烧写</p></li>
</ol>
<ol start="2" type="1">
<li>其它机型</li>
</ol>
<ol type="a">
<li><p>下载并编译 kernel</p></li>
<li><p>按 froyo 新规则添加硬件相关目录结构（ vender=&gt;device ），修改
mk 文件</p></li>
<li><p>从手机或 update.zip 中提取 so 库</p></li>
<li><p>编译，烧写</p></li>
</ol>
<p>5. 技巧</p>
<ol type="1">
<li><p>可以逐步替换 boot.img ， system.img 以定位问题</p></li>
<li><p>逐个对比新旧 system 目录，以确认问题</p></li>
<li><p>先让 adb shell 可用，以便调试</p></li>
</ol>
<ol type="a">
<li>重要的包</li>
</ol>
<ol type="i">
<li><p>boot.img ：含 kernel 和基本的文件系统<br />
理论上说，只有 boot.img 而没有 system.img 也是可以启动并连接 adb
调试的，因为 adbd 在 boot.img<br />
所含的基本文件系统中，但是需要重新定义 init.rc</p></li>
<li><p>system.img ：含主要系统，命令，库，图形界面</p></li>
<li><p>userdata.img ：放用户数据</p></li>
</ol>
<ol start="2" type="a">
<li>启动顺序为 bootloader-&gt;kernel-&gt;system-&gt;launcher</li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>修改android公共控件和后台服务</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/%E4%BF%AE%E6%94%B9android%E5%85%AC%E5%85%B1%E6%8E%A7%E4%BB%B6%E5%92%8C%E5%90%8E%E5%8F%B0%E6%9C%8D%E5%8A%A1/</url>
    <content><![CDATA[<h1
id="修改android公共控件和后台服务">修改android公共控件和后台服务</h1>
<p>#移动开发 #android</p>
<p>1． 位置<br />
公共控件的代码在源码目录 android/frameworks/base/core/java/android/
中<br />
后台服务的代码在源码目录
android/frameworks/base/services/java/android/server 中</p>
<p>2． 修改<br />
修改其中代码并执行 mm 编译<br />
形如 :<br />
** $ cd frameworks/base/services/java/com/android/server/<br />
$ vi IntentResolver.java<br />
$ mm **</p>
<p>3． 替换<br />
编译后用生成的包替换手机上 /system/framework/ 中相应的包<br />
编译后生成的文件见提示<br />
形如 :<br />
** $ cd out/target/product/general/system/framework/<br />
$ adb push services.jar /system/framework/ **</p>
<p>4． 使新的包生效</p>
<ol type="a">
<li><p>方法 1:<br />
重启手机后生效</p></li>
<li><p>方法 2:<br />
杀死 system_server 进程，使系统重新启动，这种方法速度快<br />
** $ ps<br />
** 找到 system_server 对应的 pid, 假设它为 1219<br />
** $ kill 1219 **</p></li>
</ol>
<p>5． 注意</p>
<ol type="a">
<li><p>绝大多数情况下都能成功，不过最好在替换前备份原有 jar 包</p></li>
<li><p>如果替换重要的包使机器不能启动到桌面了，可以通过重新打包
system.img ，然后重新烧写（ fastboot<br />
）到系统中解决此问题，注意 system.img 的大小<br />
** $ ./out/host/linux-x86/bin/mkyaffs2image -f<br />
out/target/product/generic/system<br />
out/target/product/generic/obj/PACKAGING/systemimage_unopt_intermediates/system.img<br />
$ out/host/linux-x86/bin/acp -fpt<br />
out/target/product/generic/obj/PACKAGING/systemimage_unopt_intermediates/system.img<br />
out/target product/generic/system.img<br />
$ fastboot flash system system.img<br />
** 此时用 fastboot 烧写方式重启手机</p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>动态改变Android控件大小</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/%E5%8A%A8%E6%80%81%E6%94%B9%E5%8F%98Android%E6%8E%A7%E4%BB%B6%E5%A4%A7%E5%B0%8F/</url>
    <content><![CDATA[<h1 id="动态改变android控件大小">动态改变Android控件大小</h1>
<p>#移动开发 #android</p>
<p>一、 方法</p>
<p>使用 getLayoutParams() 和 setLayoutParams() 方法</p>
<p>二、 示例代码<br />
** LinearLayout.LayoutParams linearParams =
(LinearLayout.LayoutParams)<br />
aaa.getLayoutParams(); ** // 取控件 aaa 当前的布局参数 **<br />
linearParams.height = 365; ** // 当控件的高强制设成 365 象素 **<br />
aaa.setLayoutParams(linearParams); ** // 使设置好的布局参数应用到控件
aaa</p>
<p>三、 原理</p>
<ol type="a">
<li><p>getLayoutParams() 和 setLayoutParams() 都是控件基类 view 的
public<br />
方法，在外部也可以直接调用</p></li>
<li><p>由于 LayoutParams<br />
一般是在加入容器中设置的，所以容易混淆我们所指定的布局属性究竟是保存在容器中，还是控件本身的属性，答案是控件本身。但是在设置时还是要注意布局属性与容器种类密切相关</p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>浅析dalvik虚拟机JIT技术的实现</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/%E6%B5%85%E6%9E%90dalvik%E8%99%9A%E6%8B%9F%E6%9C%BAJIT%E6%8A%80%E6%9C%AF%E7%9A%84%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h1
id="浅析dalvik虚拟机jit技术的实现">浅析dalvik虚拟机JIT技术的实现</h1>
<p>#移动开发 #android</p>
<p>一、 说明<br />
据说 Android 2.2 的虚拟机 dalvik 使用了 JIT 技术 ，使其运行 速度快了 5
倍 。 dalvik<br />
解释并执行程序， JIT
技术主要是对多次运行的代码进行编译，当再次调用时使用编译之后的机器码，而不是每次都解释，以节约时间。
5<br />
倍是测试程序测出的值，并不是说程序运行速度也能达到 5<br />
倍，这是因为测试程序有很多的重复调用和循环，而一般程序主要是顺序执行的，而且它是一边运行，一边编译，一开始的时候提速不多，所以真正运行程序速度提高不是特别明显。</p>
<p>二、 JAVA 虚拟机主要的优化技术</p>
<p>1. JIT （ Just In Time ）<br />
最开始指在执行前编译 ，
但是到现在已经发展成为，一开始解释执行，只有被多次调用的程序段才被编译，编译后存放在内存中，下次直接执行编译后的机器码</p>
<ol type="1">
<li><p>method 方式：以函数或方法为单位进行编译</p></li>
<li><p>trace 方式：以 trace
为单位进行编译（可以把循环中的内容作为单位编译），此方法也包含
method</p></li>
</ol>
<p>2. AOT （ Ahead Of Time ）<br />
在程序下载到本地时就编译成机器码 ， 并存储在本地存在硬盘上
，以加快运行程度，用此种方式，可执行的程序会变大四五倍</p>
<p>三、 dalvik 中 JIT 的实现<br />
每启动一个应用程序，都会相应地启动一个 dalvik 虚拟机，启动时会建立
JIT<br />
线程，一直在后台运行。当某段代码被调用时，虚拟机会判断它是否需要编译成机器码，如果需要，就做一个标记，
JIT<br />
线程不断判断此标记，如果发现被设定就把它编译成机器码，并将其机器码地址及相关信息放入
entry table<br />
中，下次执行到此就跳到机器码段执行，而不再解释执行，从而提高速度。</p>
<p>四、 dalvik JIT 部分代码分析<br />
android 2.2 代码还未发布，而 2.1 代码中已经加入 JIT
部分，只是默认未打开，以 2.1<br />
代码为例对其原理进行分析，源码位置： $ANDROID_SRC/dalvik/vm/</p>
<p>1. 核心文件</p>
<ol type="1">
<li><p>vm/interp/Jit.c<br />
供外界调用的入口</p></li>
<li><p>vm/compiler/compiler.c<br />
核心函数的实现</p></li>
<li><p>vm/compiler/Frontend.c<br />
编译 method 和 trace 的实现</p></li>
</ol>
<p>2. 全局变量</p>
<ol type="1">
<li>gDvmJit<br />
所有与 JIT 相关的数据及结构都存储于此，各个程序通过它访问 JIT 资源</li>
</ol>
<p>3. 开关</p>
<ol type="1">
<li><p>dvmCompilerStartup() (vm/compiler/Compiler.c)
在虚拟机启动时调用</p></li>
<li><p>dvmCompilerShutdown() (vm/compiler/Compiler.c)
在虚拟机关闭时调用</p></li>
</ol>
<p>4. 线程</p>
<ol type="1">
<li>compilerThreadStart() (vm/compiler/Compiler.c)<br />
被 dvmCompilerStartup() 调用 ， 在虚拟机运行过程中一直生存的线程 ，
while<br />
循环判断是否有代码需要编译，如果有，则调用 dvmCompilerDoWork()
对其进行编译</li>
</ol>
<p>5. 编译成字节码<br />
doCompilerdoWork() 又分 method 和 trace 两种情况进行编译</p>
<ol type="1">
<li><p>dvmCompilerMethod() (vm/compiler/Frongend.c)</p></li>
<li><p>dvmCompilerTrace() (vm/compiler/Frongend.c)<br />
其中的： dvmCompilerMIR2LIR() ， dvmCompilerAssembleLIR() （ MIR 和
LIR<br />
都是解释层的中间表示）逐层翻译成机器码</p></li>
</ol>
<p>6. 编译后字节码的存储</p>
<ol type="1">
<li>dvmcompilerSetupCodeCache() (vm/compiler/Compiler.c)<br />
gDvmJit.codeCache ：使用 mmap 分配（ 1024x1024
），用于存在编译后的代码<br />
gDvmJit.codeCacheByteUsed ： codeCache 的使用情况<br />
gDvmJit.codeCacheFull ： codeCache 是否已写满<br />
gDvmJit.pJitEntryTable ： entry 表，每个 trace 对应一个 entry</li>
</ol>
<p>7. 其它线程对 JIT 资源的访问<br />
以下是一个示例，说明从主函数到 JIT 的调用关系如下：<br />
AndroidRuntime::Start()-&gt;startVm()-&gt;_JNIEnv::CallStaticVoidMethod()-&gt;Check_CallStaticVoidMethodV()-&gt;CallStaticVoidMethodV()-&gt;dvmCallMethodV()-&gt;dvmInterpret()-&gt;dvmMterpStd()-&gt;dalvik_mterp()-&gt;Dalvik_java_lang_reflect_Method_invokeNative()-&gt;dvmInvokeMethod()-&gt;dvmInterpret()-&gt;dvmJitCheckTraceRequest()-&gt;dvmjitLookupAndAdd()<br />
主要函数解释如下：</p>
<ol type="1">
<li><p>dvmJitLookupAndAdd()<br />
判断是否有相对某段程序的字节码可用，如果有则返回其地址，如果没有，则做标记，以通知编译线程对其进行编译</p></li>
<li><p>dvmCheckJit()<br />
此函数被 define 成 CHECK_JIT() ，它来判断什么条件时认为需要编译</p></li>
</ol>
<p>（转载请注明出处： <a
href="http://xy0811.spaces.live.com">http://xy0811.spaces.live.com</a>
）</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>运行dalvik测试程序</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E7%B3%BB%E7%BB%9F/%E8%BF%90%E8%A1%8Cdalvik%E6%B5%8B%E8%AF%95%E7%A8%8B%E5%BA%8F/</url>
    <content><![CDATA[<h1 id="运行dalvik测试程序">运行dalvik测试程序</h1>
<p>#移动开发 #android</p>
<p>1. 说明<br />
一般在 android
平台上的程序都运行在应用框架之中，它也可以直接运行，以下介绍最简单的运行和调试方法。</p>
<p>2. 运行 dalvik 自带的 test 程序</p>
<ol type="1">
<li><p>配置 ANDROID 系统环境<br />
_ $ cd $ANDROID_SRC<br />
$ . build/envsetup.sh _</p></li>
<li><p>编辑桌面环境脚本 test_env.sh （否则 run-test
程序运行时报错）<br />
内容如下：<br />
_ #!/bin/sh<br />
base=<code>pwd</code><br />
root=<span
class="math inline">\(base/out/debug/host/linux-x86/product/sim/system
export ANDROID_ROOT=\)</span>root<br />
bootpath=<span class="math inline">\(root/framework export
BOOTCLASSPATH=\)</span>bootpath/core.jar:<span
class="math inline">\(bootpath/ext.jar:\)</span>bootpath/framework.jar:<span
class="math inline">\(bootpath/android.policy.jar:\)</span>bootpath/services.jar<br />
export ANDROID_DATA=/tmp/dalvik_$USER<br />
mkdir -p $ANDROID_DATA/dalvik-cache _<br />
并执行该脚本<br />
_ $ . test_env.sh _</p></li>
<li><p>运行测试程序 003<br />
_ $ cd dalvik/test<br />
$ ./run-test 003 _</p></li>
</ol>
<p>（转载请注明出处： http://xy0811.spaces.live.com ）</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android中对大图的处理的实现和分析</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E4%B8%AD%E5%AF%B9%E5%A4%A7%E5%9B%BE%E7%9A%84%E5%A4%84%E7%90%86%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%92%8C%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1
id="android中对大图的处理的实现和分析">Android中对大图的处理的实现和分析</h1>
<p>#移动开发 #android</p>
<p>在应用中实现图像变换相关的处理时，有时会遇到分配内存失败
(OutOfMemoryError) 的问题。比如我用 N1 拍照的分辨率是<br />
2500x1900 ，格式为 jpg 。使用 Bitmap
类将打开后，由于是从文件读取，它的属性被设为不能修改 (mutable)<br />
，如果想在大小不变的情况下修改它，只能使用 createbitmap
建立一个等大的可编辑的 bitmap<br />
。同时打开两个大文件，就会出现内存不足的提示。使用 bitmap 类的 copy
方法，同样会出现这个问题，而使用 option<br />
设置缩放参数又会影响图像的质量，降低分辨率，不能达到想要的效果。</p>
<p>试了多种方法，有一种非常不好的方法可以实现，就是把图片解码后存入一个临时文件，释放源
bitmap ，然后用 createbitmap<br />
建立一个可编辑的空图，再从数据文件中以流的方式读出数据，处理后使用
setpixel 赋值给 bitmap<br />
再保存成图片格式，但是这种方法非常慢，无法忍受。</p>
<p>最后的解决方法是使用 JNI 方法，在 C<br />
库中分配内存，将图传入库中及对图片进行处理，释放源图，建立可编辑的新图，再从库中读出编辑后的数据，赋值给新图。因为对单个应用内存的限制是在
java<br />
虚拟机中实现的，所以对 C 层面并不影响，而且在 c
库中数据处理，还可以提高处理速度。这样使用简单的函数调用方式就可以实现了，只是需要要实现<br />
JNI ，并且将 so 库编进 apk ，代码上比较麻烦，但效果很不错。</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android使用DOM方式解析XML</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E4%BD%BF%E7%94%A8DOM%E6%96%B9%E5%BC%8F%E8%A7%A3%E6%9E%90XML/</url>
    <content><![CDATA[<h1 id="android使用dom方式解析xml">Android使用DOM方式解析XML</h1>
<p>#移动开发 #android</p>
<p>1． 介绍<br />
在Android系统中很多信息及配置文件都是以xml格式存储的，Android系统也提供SAX和DOM两种方式来解析XML文件，下面介绍其中比较简单的DOM方式。</p>
<p>2． 例程</p>
<ol type="1">
<li><p>功能<br />
解析xml文件内容，并显示在程序界面上</p></li>
<li><p>关键字<br />
Android, xml, dom, 解析</p></li>
<li><p>可从此处下载可独立运行的代码<br />
<a
href="http://download.csdn.net/detail/xieyan0811/4117455">http://download.csdn.net/detail/xieyan0811/4117455<br />
</a></p></li>
<li><p>核心代码及说明</p></li>
</ol>
<p><strong>package com.demo.xml;</strong></p>
<hr />
<p><strong>import android.app.Activity;</strong></p>
<p><strong>import android.os.Bundle;</strong></p>
<p><strong>import android.widget.TextView;</strong></p>
<p><strong>import android.widget.LinearLayout;</strong></p>
<p><strong>import android.util.Log;</strong></p>
<hr />
<p><strong>import org.w3c.dom.Element;</strong></p>
<p><strong>import org.w3c.dom.NodeList;</strong></p>
<p><strong>import org.w3c.dom.Document;</strong></p>
<p><strong>import javax.xml.parsers.DocumentBuilder;</strong></p>
<p><strong>import javax.xml.parsers.DocumentBuilderFactory;</strong></p>
<p><strong>import
javax.xml.parsers.ParserConfigurationException;</strong></p>
<p><strong>import java.io.IOException;</strong></p>
<p><strong>import java.io.InputStream;</strong></p>
<hr />
<p><strong>public class MyXmlActivity extends Activity { </strong></p>
<p><strong>private String TAG ="demo";</strong></p>
<hr />
<p><strong><span class="citation"
data-cites="Override">@Override</span></strong></p>
<p><strong>public voidonCreate(Bundle savedInstanceState) {
</strong></p>
<p><strong>super.onCreate(savedInstanceState);</strong></p>
<p><strong>setContentView(R.layout.main);</strong></p>
<p><strong>parseXml();</strong></p>
<p><strong>}</strong></p>
<hr />
<p><strong>private voidparseXml() { </strong></p>
<p><strong>int i, j;</strong></p>
<p><strong>TextViewtext;</strong></p>
<p><strong>LinearLayoutlinear = new LinearLayout(this);</strong></p>
<p><strong>linear.setOrientation(LinearLayout.VERTICAL);</strong></p>
<hr />
<p><strong>DocumentBuilderFactorydocFactory =
DocumentBuilderFactory</strong></p>
<p><strong>.newInstance();</strong></p>
<p><strong>DocumentBuilderdocBuilder;</strong></p>
<p><strong>Document doc= null;</strong></p>
<p><strong>InputStreaminStream = null;</strong></p>
<p><strong>try { </strong></p>
<p><strong>docBuilder= docFactory.newDocumentBuilder();</strong></p>
<p><strong>inStream=
this.getResources().getAssets().open("test.xml");</strong></p>
<p><strong>doc= docBuilder.parse(inStream);</strong></p>
<p><strong>ElementrootEle = doc.getDocumentElement();</strong></p>
<p><strong>NodeListquestionNode =
rootEle.getElementsByTagName("submenu");</strong></p>
<p><strong>intsubCount = questionNode.getLength();</strong></p>
<p><strong>for(i = 0; i &lt; subCount; i++) { </strong></p>
<p><strong>ElementsubEle = (Element) questionNode.item(i);</strong></p>
<p><strong>StringsubTitle = subEle.getAttribute("title");</strong></p>
<p><strong>Log.e(TAG,"title = " + subTitle);</strong></p>
<p><strong>text= new TextView(this);</strong></p>
<p><strong>text.setText(subTitle);</strong></p>
<p><strong>linear.addView(text);</strong></p>
<hr />
<p><strong>NodeListitemNode =
subEle.getElementsByTagName("item");</strong></p>
<p><strong>intitemCount = itemNode.getLength();</strong></p>
<p><strong>for(j = 0; j &lt; itemCount; j++) { </strong></p>
<p><strong>ElementoptionEle = (Element) itemNode.item(j);</strong></p>
<p><strong>Stringdesc = optionEle.getAttribute("desc");</strong></p>
<p><strong>Stringpos = optionEle.getAttribute("pos");</strong></p>
<p><strong>Log.e(TAG,"desc = " + desc + ", pos = " + pos);</strong></p>
<p><strong>text= new TextView(this);</strong></p>
<p><strong>text.setText(desc+ ", " + pos);</strong></p>
<p><strong>linear.addView(text);</strong></p>
<p><strong>}</strong></p>
<p><strong>}</strong></p>
<p><strong>} catch(ParserConfigurationException e1) { </strong></p>
<p><strong>e1.printStackTrace();</strong></p>
<p><strong>} catch(IOException e) { </strong></p>
<p><strong>e.printStackTrace();</strong></p>
<p><strong>} catch(Exception e) { </strong></p>
<p><strong>e.printStackTrace();</strong></p>
<p><strong>}</strong></p>
<p><strong>setContentView(linear);</strong></p>
<p><strong>}</strong></p>
<p><strong>};</strong></p>
<hr />
<p><strong>// xml 内容</strong></p>
<p>** <?xml version="1.0" encoding="utf-8" ?> **</p>
**
<menu>
<p>**</p>
<p>** &lt;submenutitle="test1"&gt; **</p>
<p>** <item desc="item1" pos="012" /> **</p>
<p>** <item desc="item2" pos="123" /> **</p>
<p>** </submenu> **</p>
<p>** &lt;submenutitle="test2"&gt; **</p>
<p>** <item desc="item3" pos="234" /> **</p>
<p>** <item desc="item4" pos="456" /> **</p>
<p>** </submenu><br />
<submenu title="test3"> **</p>
<p>** <item desc="item5" pos="567" /> **</p>
<p>** <item desc="item6" pos="678" /> **</p>
<p>** <item desc="item7" pos="789" /> **</p>
<p>** </submenu> **</p>
**
</menu>
<p>**</p>
<p>3． 参考</p>
<ol type="1">
<li>SAX教程：http://www.2cto.com/kf/201101/81739.html</li>
</ol>
<p>(转载请注明出处)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android使用XML-RPC实现blog客户端</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E4%BD%BF%E7%94%A8XML-RPC%E5%AE%9E%E7%8E%B0blog%E5%AE%A2%E6%88%B7%E7%AB%AF/</url>
    <content><![CDATA[<h1
id="android使用xml-rpc实现blog客户端">Android使用XML-RPC实现blog客户端</h1>
<p>#移动开发 #android</p>
<p>1. 原理介绍</p>
<ol type="1">
<li><p>XML-RPC 介绍<br />
XML-RPC 的全称是 XML Remote Procedure Call ，即 XML 远程方法调用。原理是
XML-RCP<br />
工具把传入的参数组合成 XML, 然后用通过 http 协议发给服务器，服务器回复
XML 格式数据，再由工具解析给调用者。</p></li>
<li><p>Meta Weblog API<br />
一些 Blog 提供 Meta Weblog API ，用以支持通过 XML-RPC
的方法在软件中编辑及浏览 Blog 。常用的 API<br />
如下：<br />
发布新文章 (metaWeblog.newPost) 、获取分类 (metaWeblog.getCategories)
和最新文章<br />
(metaWeblog.getRecentPosts) 、新建文章分类 (wp.newCategory)
、上传图片音频或视频<br />
(metaWeblog. newMediaObject) 等。</p></li>
</ol>
<p>2. Android 的 XML-RPC 支持<br />
Android 本身并不支持 XML-RPC 协议 , 需要下载相关应的工具 , 本例中使用的
XML-RPC<br />
从以下地址下载，完整例程中包含此部分<br />
<a
href="http://code.google.com/p/android-xmlrpc/downloads/list">http://code.google.com/p/android-xmlrpc/downloads/list<br />
</a></p>
<p>3. 例程<br />
** package org.xmlrpc;</p>
<p>import java.net.URI;<br />
import java.util.HashMap;<br />
import java.util.Map;<br />
import org.apache.http.conn.HttpHostConnectException;<br />
import org.xmlrpc.android.XMLRPCClient;<br />
import org.xmlrpc.android.XMLRPCException;<br />
import org.xmlrpc.android.XMLRPCFault;<br />
import org.xmlrpc.android.XMLRPCSerializable;<br />
import android.app.Activity;<br />
import android.content.Context;<br />
import android.os.Bundle;<br />
import android.util.Log;<br />
import android.widget.EditText;<br />
import android.widget.Toast;<br />
import android.widget.Button;<br />
import android.content.DialogInterface.OnCancelListener;<br />
import android.view.View.OnClickListener;<br />
import android.view.View;</p>
<p>public class TestBlog extends Activity {<br />
private XMLRPCClient client;<br />
private URI uri;</p>
<p><span class="citation" data-cites="Override">@Override</span><br />
public void onCreate(Bundle savedInstanceState) {<br />
super.onCreate(savedInstanceState);</p>
<p>setContentView(R.layout.test_blog);<br />
Button btn = (Button) findViewById(R.id.send);<br />
btn.setOnClickListener(new OnClickListener() {<br />
public void onClick(View v) {<br />
post();<br />
}<br />
});<br />
}</p>
<p>void post() {<br />
String blogid = ((EditText)
findViewById(R.id.blogid_edit)).getText()<br />
.toString(); // ** ** 博客 ** ** ID, ** ** 有的博客支持一个用户多个 **
** ID<br />
String username = ((EditText) findViewById(R.id.username_edit))<br />
.getText().toString(); // ** ** 用户名 ** **<br />
String password = ((EditText) findViewById(R.id.password_edit))<br />
.getText().toString(); // ** ** 密码 ** **<br />
String title = ((EditText)
findViewById(R.id.title_edit)).getText()<br />
.toString(); // ** ** 标题 ** **<br />
String content = ((EditText)
findViewById(R.id.content_edit)).getText()<br />
.toString(); // ** ** 正文 ** **</p>
<p>uri = URI.create("http://blog.csdn.net/" + blogid<br />
+ "/services/metablogapi.aspx");<br />
client = new XMLRPCClient(uri);</p>
<p>Map &lt;String, Object&gt; structx = new HashMap&lt;String,
Object&gt;();<br />
structx.put("title", title);<br />
structx.put("description", content);<br />
Object[] params = new Object[] { blogid, username, password,
structx,<br />
true };</p>
<p>try {<br />
client.callEx("metaWeblog.newPost", params);<br />
Toast.makeText(this, "OK", 10000).show();<br />
} catch (XMLRPCException e) {<br />
Toast.makeText(this, "ERROR" + e, 10000).show();<br />
}<br />
}<br />
} **</p>
<p>4. 多媒体上传的介绍<br />
上传多图片视频音频方法如下<br />
** Map &lt;String, Object&gt; structx = new HashMap&lt;String,
Object&gt;();<br />
structx.put(None); // ** ** 文件名 ** **<br />
structx.put("type”, “image/jpeg”); // ** ** 格式 ** **<br />
structx.put("bits", filebytes); // ** ** 文件内容 ** ** , ** ** 需要 **
**<br />
base64 ** ** 编码 ** ** , ** ** 可使用 ** ** android.util.Base64 ** **
来编码 **<br />
**<br />
structx.put("overwrite", true); // ** ** 是否覆盖 ** **<br />
Object[] params = new Object[] { blogid, username, password,
structx};<br />
client.callEx("metaWeblog.newPost", params); **<br />
通过此方式可以实现相片视频的即片即转功能</p>
<p>5. 参考 :</p>
<ol type="1">
<li><p>wordpress 使用 Meta weblog 的接口如下<br />
<a
href="http://cn.wordpress.org/xmlrpc.php">http://cn.wordpress.org/xmlrpc.php</a></p></li>
<li><p>【 PHP 】 XML-RPC で投稿！<br />
<a
href="http://blog.studio23c.com/?p=108">http://blog.studio23c.com/?p=108</a></p></li>
<li><p>完整例程下载<br />
<a
href="http://download.csdn.net/source/2793892">http://download.csdn.net/source/2793892<br />
</a></p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android大字体软件的安装</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E5%A4%A7%E5%AD%97%E4%BD%93%E8%BD%AF%E4%BB%B6%E7%9A%84%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<h1 id="android大字体软件的安装">Android大字体软件的安装</h1>
<p>#移动开发 #android</p>
<p>2013年第一天，我爸新买的Android手机忽然不能用了，估计可能是哪个软件带的病毒设置了时间判断，一到2013立即发作。于是只好恢复出厂设置之后重装软件。重装之后问题得以解决。电话本又要重新导入，软件也又要重装。看来以后这样的麻烦还少不了。于是把常用的软件以及通讯录备份，以简化日后恢复过程。具体步骤如下：</p>
<p>1． 问题描述<br />
划动点击均不正常，重新启动后前两分钟正常，之后问题又出现，因此估计是软件问题，但用360手机卫士又查不到病毒。</p>
<p>2． 恢复出厂设置<br />
设置-&gt;个人-&gt;重置-&gt;恢复出厂设置（以上为Android<br />
4.0操作）。恢复之后问题还存在（估计是恢复出厂设置过程中启动的还是旧image），又重启了一次，系统恢复正常。</p>
<p>3． 安装常用软件<br />
因为可能经常重装，所以这次将apk安装包下载到电脑中，然后通过usb线安装，以简化重装系统的过程。选择了以下六个软件：超级短信HandcentSMS、朋来通讯录、360手机卫士、豌豆荚、百度音乐。其中的短信和通讯录字体可调得很大。<br />
安装时，先打开手机的usb调试，设置-&gt;系统-&gt;开发人员选项-&gt;usb调试，这时候用adb
shell即可连接电脑和手机，使用命令adb<br />
install即可安装（需要先安装adb相关程序）。把apk拷到sd卡上安装也可以。</p>
<p>4． 设置大字体<br />
老年人一般喜欢字大的软件，而一般Android手机设置了最大字体，看起来也不是特别大（有几款三星的机器是支持超大字体的，但比较贵）。<br />
设置系统字体：设置-&gt;显示-&gt;字体大小-&gt;大<br />
设置短信大字体：超级短信HandcentSMS-&gt;菜单-&gt;设置-&gt;设置界面显示，对各个界面都可以进行非常详细的设置（我使用的HandcentSMS版本是4.2.3）<br />
设置通讯录字体：朋来通讯录-&gt;菜单-&gt;系统配置-&gt;设置字体大小</p>
<p>5． 导入通讯录<br />
SIM卡的通讯录可存储条目有限，建议是创建google帐户(注册gmail即可)，在其中输入联系人信息（以后导出给其它系统的手机也没问题），然后导出成vcard格式，放在手机sd卡上，操作手机从联系人菜单中选择从存储设备导入即可。</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android开发_精准排布控件位置</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E5%BC%80%E5%8F%91_%E7%B2%BE%E5%87%86%E6%8E%92%E5%B8%83%E6%8E%A7%E4%BB%B6%E4%BD%8D%E7%BD%AE/</url>
    <content><![CDATA[<h1 id="android开发_精准排布控件位置">Android开发_精准排布控件位置</h1>
<p>#移动开发 #android</p>
<h2 id="简述">1. 简述</h2>
<p>在Android系统上开发程序，很多时候需要精准的排布控件的位置和大小．并且适合各种比例的屏幕（4:3，16:9…），下面分别介绍在高版本和低版本的Android中的实现方法．</p>
<h2 id="android-studio高版本android实现">2. Android
Studio／高版本Android实现</h2>
<ol type="1">
<li><p>说明<br />
使用高版本android内置的android-support-percent-lib库，通过设置百分比的方法，实现了该功能，
Demo一般都是android<br />
studio，Eclipse下需要下载支持库： <a
href="http://download.csdn.net/detail/sbsujjbcy/8857747">http://download.csdn.net/detail/sbsujjbcy/8857747<br />
</a><br />
在Layout中设置百分比：PercentRelativeLayout/PercentFrameLayout/PercentLinearLayout</p></li>
<li><p>Layout文件</p>
<p><?xml version="1.0"encoding="utf-8"?></p>
<p>&lt;android.support.percent.PercentFrameLayout<br />
xmlns:android="http://schemas.android.com/apk/res/android"<br />
xmlns:app="http://schemas.android.com/apk/res-auto"<br />
android:layout_width="match_parent"<br />
android:layout_height="match_parent"&gt;</p>
<pre><code>&lt;TextView  
    android:layout_width=&quot;0dp&quot;  
    android:layout_height=&quot;0dp&quot;  
    android:background=&quot;#44ff0000&quot;  
    android:text=&quot;width:30%,height:20%&quot;  
    app:layout_heightPercent=&quot;20%&quot;  
    app:layout_marginLeftPercent=&quot;10%&quot;  
    app:layout_marginTopPercent=&quot;40%&quot;  
    app:layout_widthPercent=&quot;30%&quot;/&gt;  </code></pre>
<p>&lt;/android.support.percent.PercentFrameLayout&gt;</p></li>
<li><p>相关属性：</p></li>
</ol>
<p>layout_widthPercent</p>
<p>layout_heightPercent</p>
<p>layout_marginPercent</p>
<p>layout_marginLeftPercent</p>
<p>layout_marginTopPercent</p>
<p>layout_marginRightPercent</p>
<p>layout_marginBottomPercent</p>
<p>layout_marginStartPercent</p>
<p>layout_marginEndPercent</p>
<ol start="4" type="1">
<li>修改build.gradle<br />
在dependencies{}加<br />
compile 'com.android.support:percent:22.2.0'</li>
</ol>
<h2 id="使用eclipse低版本android实现">3.
使用Eclipse／低版本Android实现</h2>
<ol type="1">
<li><p>说明<br />
推荐用此方法，它的通用性更强，适合各个Android版本，无需外加扩展库，对于layout按一定比例或规则排列的界面更方便使用。</p></li>
<li><p>Layout文件</p>
<p><?xml version="1.0" encoding="utf-8"?></p>
<p><RelativeLayout  
    xmlns:android="http://schemas.android.com/apk/res/android"  
    xmlns:app="http://schemas.android.com/apk/res-auto"  
    android:layout_width="match_parent"  
    android:layout_height="match_parent"></p>
<pre><code>&lt;TextView  
    android:id=&quot;@+id/txt&quot;  
    android:layout_width=&quot;0dp&quot;  
    android:layout_height=&quot;0dp&quot;  
    android:layout_gravity=&quot;left|top&quot;  
    android:background=&quot;#44ff0000&quot;  
    android:text=&quot;testme&quot;/&gt;  </code></pre>
<p></RelativeLayout></p></li>
<li><p>Java程序</p>
<p>package com.test.testme;</p>
<p>import android.app.Activity;<br />
import android.os.Bundle;<br />
import android.widget.TextView;<br />
import android.widget.RelativeLayout;</p>
<p>public class testme extends Activity {</p>
<pre><code>@Override  
public void onCreate(Bundle savedInstanceState)  
 &#123;  
    super.onCreate(savedInstanceState);  

    setContentView(R.layout.main);  
    TextView txtView = (TextView) findViewById(R.id.txt);  
    RelativeLayout.LayoutParams params =(RelativeLayout.LayoutParams)txtView.getLayoutParams();  
    params.width = 100;  
    params.height = 100;  
    params.setMargins(100,200,0,0);  
           txtView.setLayoutParams(params);  
 &#125;  </code></pre>
<p>}</p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android手机实现GPS语音导航功能(Google地图导航)</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E6%89%8B%E6%9C%BA%E5%AE%9E%E7%8E%B0GPS%E8%AF%AD%E9%9F%B3%E5%AF%BC%E8%88%AA%E5%8A%9F%E8%83%BD(Google%E5%9C%B0%E5%9B%BE%E5%AF%BC%E8%88%AA)/</url>
    <content><![CDATA[<h1
id="android手机实现gps语音导航功能google地图导航">Android手机实现GPS语音导航功能(Google地图导航)</h1>
<p>#移动开发 #android</p>
<p>Android上的Google地图现在也带导航了。简单的讲，就是输入起点和终点，它就能像普通的车载GPS一样，不但在图上提示线路，还能语音提示向东还是向西，在哪里转弯，距离等等。我在北京上地附近的测试，汉语导航，可以正常使用。用起来效果还不错。和普通GPS相比更真实（某些手机上的导航软件需要下载大量数据，还不一定能用）。在地图上可以看到航拍的马路，甚至是旁边那颗树，下面分享一下实现过程。</p>
<p><img
src="http://hi.csdn.net/attachment/201112/23/0_1324627697QO2x.gif" /></p>
<p>一、我的环境<br />
硬件：Google N1<br />
系统：Android 2.3.6<br />
软件：Google地图，易言中文语音引擎</p>
<p>二、下载及安装</p>
<p>1. Google地图<br />
从google<br />
market上更新的google地图6.03因为是测试版，中国不在导航支持的范围之内。朋友介绍了一个全球破解版，下载安装后可直接使用，我在上地附近测试一切正常。</p>
<ol type="1">
<li><p>网址<br />
<a
href="http://forum.xda-%20developers.com/showthread.php?t=1007132">http://forum.xda-developers.com/showthread.php?t=1007132</a><br />
我下载了其中提到的软件包，maps6.0.3ownhere-changepn.apk</p></li>
<li><p>安装方法<br />
<strong>$ adb install maps6.0.3ownhere-changepn.apk</strong></p></li>
<li><p>说明<br />
无需要修改任何东西，直接安装，即可使用。它与原有的google
map并不冲突，显示在桌面上时导航和地图的图标右上方都有一个绿圈。</p></li>
</ol>
<p>2. 易言中文语音引擎</p>
<ol type="1">
<li><p>网址<br />
<a
href="http://www.eoemarket.com/apps/66764">http://www.eoemarket.com/apps/66764</a></p></li>
<li><p>安装方法<br />
<strong>$ adb install xxxxxx.apk</strong></p></li>
<li><p>说明<br />
能支持中文语音的引擎并不多，svoxclassic是一个，但是要花不少钱，效果也不是特别好，偶尔有盗版，也很快被网管给删了。这里介绍“易言中文语音引擎”是免费版软件，可以从google<br />
market，掌上应用汇及eoemarket下载，它还可以支持一些读书（有声电子书）和短信软件(Handcent
Sms)。</p></li>
</ol>
<p>三、设置及使用</p>
<p>1. 语音设置</p>
<ol type="1">
<li><p>设置-
&gt;语音输入与输出-&gt;文字转语音设置，勾选下方的易言中文语音引擎，然后将其设为默认引擎，语言设为中文。</p></li>
<li><p>设置-&gt;语音和键盘-&gt;选择语言，设为中文简体</p></li>
<li><p>设置-&gt;声音-&gt;音量，将媒体音量调大（否则导航声音太小，在户外很难听见）</p></li>
</ol>
<p>2. 地图设置</p>
<ol type="1">
<li><p>点击进入google地图（我们新安装的带小绿圈的）</p></li>
<li><p>菜单-&gt;线路，输入起点，终点，选择开车或步行，然后获取线路，此时在地图上可以看到线路。</p></li>
<li><p>点击右上角的蓝色导航箭头，如果出现多个导航应用可选，则选择我们新安装的（带小绿圈的），此时它将连接GPS搜星，正常搜星后，即可发出中文语音导航（因为需要正常GPS定位后才能使用，所以需要在户外测试）</p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android模拟器调试与真机调试</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E6%A8%A1%E6%8B%9F%E5%99%A8%E8%B0%83%E8%AF%95%E4%B8%8E%E7%9C%9F%E6%9C%BA%E8%B0%83%E8%AF%95/</url>
    <content><![CDATA[<h1 id="android模拟器调试与真机调试">Android模拟器调试与真机调试</h1>
<p>#移动开发 #android</p>
<p>一、 模拟器调试与真机调试</p>
<p>1. 模拟器调试<br />
运行源码或 SDK 中的 emulator ，加参数</p>
<p>2. 真机调试</p>
<ol type="1">
<li><p>用 usb 线连接 G1 硬件和 PC</p></li>
<li><p>若是 windows 系统，则安装驱动</p></li>
<li><p>用源码或 SDK 中的 adb 命令看硬件是否连接成功<br />
** $ adb devices ** 正常调试</p></li>
<li><p>注意：</p></li>
</ol>
<ol type="a">
<li><p>在 Linux 连接真机时需使用 root 权限</p></li>
<li><p>如果之前连接过模拟器，最好连接前先杀掉 adb 后台进程<br />
** $ killall adb **</p></li>
</ol>
<p>3. Eclipse 中调试<br />
若连接真机，未打开模拟器时，直接连接真机调试<br />
若未连接真机，已打开模拟器时，在当前模拟器中调试<br />
若未连接真机，也未打开模拟器时，打开模拟器调试<br />
若只开多个真机或多个模拟器时，同时有多个可连接的设备，弹出列表供用户选择</p>
<p>4. 命令行中使用 adb 工具调试<br />
连接多个设备时，需要用命令行参数指示设备名或设备类型<br />
** $ adb –s ** ** 设备名 ** ** shell ** 设备名由 adb devices 列出<br />
** $ adb –d shell ** 与硬件设备相连<br />
** $ adb –e shell ** 与模拟器相连</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android游戏中动画的实现</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E6%B8%B8%E6%88%8F%E4%B8%AD%E5%8A%A8%E7%94%BB%E7%9A%84%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="android游戏中动画的实现">Android游戏中动画的实现</h1>
<p>#移动开发 #android</p>
<p>1． 介绍<br />
对于游戏等对界面要求较高的程序，一般需要控制View中的具体图像显示（如动画功能）下面介绍实现此功能常用的SurfaceView控制。</p>
<ol type="1">
<li>常用的绘制图像的方法</li>
</ol>
<ol type="a">
<li><p>View的invalidate()<br />
直接调用onDraw()绘图</p></li>
<li><p>View的postInvalidate()<br />
通过消息调用onDraw()绘图</p></li>
<li><p>SurfaceView<br />
画布的重绘是由一个单独的线程处理，所以不会阻塞，专门为游戏而实现的。</p></li>
</ol>
<ol start="2" type="1">
<li>SurfaceView</li>
</ol>
<ol type="a">
<li>说明</li>
</ol>
<ol type="i">
<li><p>它支持OpenGL ES，2D和3D效果都能实现</p></li>
<li><p>在游戏线程中画图（而非主线程）：冻结画布-&gt;在画布上绘图-&gt;解冻画布-&gt;次画布内容绘制到屏幕上</p></li>
<li><p>采用双缓存，避免屏幕闪烁</p></li>
</ol>
<ol start="2" type="a">
<li>实现</li>
</ol>
<ol type="i">
<li><p>需要实现Callback接口，它可以用来监听SurfaceView的状态，而从开启和销毁游戏主线程</p></li>
<li><p>需要实现Runnable接口, 它实现了游戏绘图线程</p></li>
</ol>
<ol start="3" type="1">
<li>常见问题</li>
</ol>
<ol type="a">
<li>双缓存问题</li>
</ol>
<ol type="i">
<li><p>原理：由于内存中存在着两个绘图区，每绘一次，显示其中一个绘图区(交替出现)</p></li>
<li><p>问题：容易出现以下问题：有时只清除了其中一个绘图区，造成了画面叠加。只绘制了部分图像，与之前部分出现叠加。</p></li>
<li><p>解决方法:：每次清屏后再画(canvas.drawColor(Color.BLACK))</p></li>
</ol>
<p>2． 例程</p>
<ol type="1">
<li><p>功能<br />
使用SurfaceView的方式在控件中实现动画</p></li>
<li><p>关键字<br />
Android, SurfaceView, 动画，游戏</p></li>
<li><p>可从此处下载可独立运行的代码<br />
<a
href="http://download.csdn.net/detail/xieyan0811/4117465">http://download.csdn.net/detail/xieyan0811/4117465<br />
</a></p></li>
<li><p>核心代码及说明</p></li>
</ol>
<p><strong>package com.demo.game;</strong></p>
<hr />
<p><strong>import android.graphics.Canvas;</strong></p>
<p><strong>import android.graphics.Paint;</strong></p>
<p><strong>import android.graphics.Color;</strong></p>
<p><strong>import android.os.Bundle;</strong></p>
<p><strong>import android.util.Log;</strong></p>
<p><strong>import android.view.SurfaceHolder;</strong></p>
<p><strong>import android.view.SurfaceHolder.Callback;</strong></p>
<p><strong>import android.view.SurfaceView;</strong></p>
<p><strong>import android.content.Context;</strong></p>
<p><strong>import android.util.AttributeSet;</strong></p>
<hr />
<p><strong>public class GameView extends SurfaceView implements
Callback,Runnable { </strong></p>
<p><strong>private boolean mIsRunning= false;</strong></p>
<p><strong>private Canvas mCanvas =null;</strong></p>
<p><strong>private SurfaceHoldermSurfaceHolder = null;</strong></p>
<p><strong>private Thread mThread =null;</strong></p>
<p><strong>private Paint mPaint =null;</strong></p>
<p><strong>private int mY = 0;</strong></p>
<hr />
<p><strong>public GameView(Contextcontext, AttributeSet attr) {
</strong></p>
<p><strong>super(context,attr);</strong></p>
<p><strong>mPaint = newPaint();</strong></p>
<p><strong>mPaint.setColor(0xffff0000);</strong></p>
<p><strong>mPaint.setStrokeWidth(3);</strong></p>
<p><strong>mPaint.setAntiAlias(true);</strong></p>
<hr />
<p><strong>mSurfaceHolder =getHolder();</strong></p>
<p><strong>mSurfaceHolder.addCallback(this);</strong></p>
<p><strong>}</strong></p>
<hr />
<p><strong>public voidsurfaceChanged(SurfaceHolder arg0, int arg1, int
arg2, int arg3)<br />
{ </strong></p>
<p><strong>}</strong></p>
<hr />
<p><strong>public voidsurfaceCreated(SurfaceHolder arg0) {
//控制动画开始</strong></p>
<p><strong>mIsRunning = true;</strong></p>
<p><strong>mThread = newThread(this);</strong></p>
<p><strong>mThread.start();</strong></p>
<p><strong>}</strong></p>
<hr />
<p><strong>public voidsurfaceDestroyed(SurfaceHolder arg0) {
//控制动画结束</strong></p>
<p><strong>mIsRunning =false;</strong></p>
<p><strong>try { </strong></p>
<p><strong>mThread.join();</strong></p>
<p><strong>} catch (Exceptione) { </strong></p>
<p><strong>e.printStackTrace();</strong></p>
<p><strong>}</strong></p>
<p><strong>}</strong></p>
<hr />
<p><strong>public void run() { // 绘图线程</strong></p>
<p><strong>while (mIsRunning){ </strong></p>
<p><strong>try { </strong></p>
<p><strong>Thread.sleep(40);</strong></p>
<p><strong>} catch(InterruptedException e) { </strong></p>
<p><strong>e.printStackTrace();</strong></p>
<p><strong>}</strong></p>
<p><strong>synchronized(mSurfaceHolder) { </strong></p>
<p><strong>mCanvas= mSurfaceHolder.lockCanvas();</strong></p>
<p><strong>Draw();</strong></p>
<p><strong>mSurfaceHolder.unlockCanvasAndPost(mCanvas);</strong></p>
<p><strong>}</strong></p>
<p><strong>}</strong></p>
<p><strong>}</strong></p>
<hr />
<p><strong>private void Draw() { // 绘图函数</strong></p>
<p><strong>mCanvas.drawColor(Color.BLACK); //
清空buffer，以避免图像叠加</strong></p>
<p><strong>mCanvas.drawLine(0,mY, 300, mY, mPaint);</strong></p>
<p><strong>mY++;</strong></p>
<p><strong>if (mY &gt; 300) </strong></p>
<p><strong>mY = 0;</strong></p>
<p><strong>}</strong></p>
<p><strong>};</strong></p>
<p>3． 参考<br />
<a
href="http://www.uml.org.cn/mobiledev/201110205.asp">http://www.uml.org.cn/mobiledev/201110205.asp<br />
</a></p>
<p>(转载请注明出处)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android界面开发</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E7%95%8C%E9%9D%A2%E5%BC%80%E5%8F%91/</url>
    <content><![CDATA[<h1 id="android界面开发">Android界面开发</h1>
<p>#移动开发 #android</p>
<p>一、 界面元素</p>
<p>1. 窗口： Activity<br />
应用程序中每个屏幕显示都通过继承和扩展基类 Activity 实现</p>
<p>分类：基本 Activity ，带内容的 Activity （如 ListActivity ）</p>
<p>2. 对话框： Dialog<br />
一种显示于 Activity 之上的界面元素，由 Activity
管理，用于显示一些临时信息和功能，它比 Activity 开销小</p>
<ol type="1">
<li><p>常用对话框：<br />
AlertDialog ：信息对话框<br />
DatePickerDialog ， TimePickerDialog ：时间日期选择对话框<br />
ProgressDialog ：进度对话框<br />
还可以设置对话框内容为我们自定义的 View</p></li>
<li><p>相关函数：<br />
onCreateDialog() ：创建对话框的实现<br />
showDialog() ：需要显示的时候调用<br />
onPrepareDialog() ：更改已有对话框时调用</p></li>
</ol>
<p>3. 菜单： Menu<br />
一种显示于 Activity 之上的界面元素，由 Activity
管理，用于提供用户一些额外的选项和设置</p>
<ol type="1">
<li><p>常用菜单：<br />
Options Menu ：按 Menu 键时从屏幕底部滑出的菜单<br />
Context Menu ：用户通过在按件上长按调出它<br />
Submenu
：用于给菜单分类，可被添加到其它菜单上，不能添加到子菜单上</p></li>
<li><p>相关函数：<br />
onCreateOptionMenu() ：创建菜单 （ onCreateContextMenu… ）<br />
onOptionsItemSelected() ：处理菜单项的单击事件<br />
onPrepareOptionsMenu() ：动态更新</p></li>
</ol>
<p>4. 可视化控件： View<br />
View 是可视化控件的基类</p>
<ol type="1">
<li><p>常用控件：<br />
TextView, ImageView<br />
Button, CheckBox, RadioButton, ImageButton, ToggleButton<br />
AnalogClock, DigitalClock<br />
EditText, List…</p></li>
<li><p>数据绑定： adapter<br />
adapter 将控件（如 List, GridView
）和复杂数据（如数据，键表）绑定起来</p></li>
</ol>
<p>5. 其它界面元素<br />
标题栏</p>
<p>二、 布局的实现<br />
设置控件在屏幕上如何排布</p>
<p>1. LinearLayout ：线性的布局方式<br />
最常用，上下或左右的添加控件</p>
<p>2. GridView ：网格布局<br />
控件按照顺序依次填到每个格子里就好了，使界面很整齐</p>
<p>3. TableLayout ：表格布局<br />
以行列形式管理子控件，每行为一个 TableRow ， TableRow 可添加子控件</p>
<p>4. AbsoluteLayout ：绝对坐标布局<br />
可以让子元素指定准确的 x/y 坐标值，并显示在屏幕上。 (0, 0)
为左上角。<br />
AbsoluteLayout 没有页边框，允许元素之间互相重叠（尽管不推荐）。<br />
不推荐使用，因为其在不同的设备上可能不能很好地工作。</p>
<p>5. RelativeLayout ：相对坐标布局<br />
控件可指定他们相对于其它元素或父元素的位置（通过 ID 指定）。<br />
可以以右对齐，或上下，或置于屏幕中央的形式来排列两个元素。</p>
<p>6. FrameLayout ：单帧布局<br />
所有的子元素将会固定在屏幕的左上角，后一个子元素将会直接在前一个子元素之上进行覆盖填充</p>
<p>三、 事件响应</p>
<p>1. 用注册回调函数的方式响应事件</p>
<p>2. 如果没被任何一个 View 处理，则由 Activity 处理</p>
<p>3. 常用事件处理</p>
<ol type="1">
<li><p>onKeyDown()</p></li>
<li><p>onKeyUp()</p></li>
<li><p>onTrackballEvent()</p></li>
<li><p>onTouchEvent()</p></li>
</ol>
<p>四、 应用软件代码结构</p>
<p>1. res ：资源<br />
资源是在代码中使用到的并且在编译时被打包进您的应用程序的附加文件<br />
在代码中通过 R 类调用 (R 类自动生成，形如 R.string.title)</p>
<ol type="1">
<li>layout ：存放布局用的 xml 文件</li>
</ol>
<ol type="a">
<li><p>布局就像容器，里面可以装下很多控件，每个控件又有布局，字体设定，<br />
如字体大小在 layout 的 xml 里使用：<br />
Android:textAppearance=”?android:attr/textAppearanceSmall”</p></li>
<li><p>默认的布局文件 main.xml</p></li>
</ol>
<ol start="2" type="1">
<li><p>drawable ：存放图片图标</p></li>
<li><p>values ：存放常量的 xml 文件（如字串）</p></li>
</ol>
<p>2. src ：代码</p>
<p>3. AndroidManifest.xml<br />
包含应用程序的基本信息，有哪些组件，哪些资源</p>
<ol type="1">
<li><p>应用程序的 java 包名</p></li>
<li><p>应用程序中所含组件（ Activity, Service, BroadcastReceiver,
ContentProvider ）</p></li>
<li><p>应用程序调用其它程序时的权限</p></li>
<li><p>应用程序被其它程序调用时对其它程序的权限要求</p></li>
<li><p>使用 Android API 的最低版本</p></li>
<li><p>应用程序依赖的库</p></li>
</ol>
<p>五、 国际化的支持（多语言）</p>
<p>1. 在系统中如何设置本地语言<br />
桌面 -&gt;settings-&gt;Local &amp; text-&gt;Select
locale-&gt;Chinese(China)</p>
<p>2. 在程序中如何加入多语言支持<br />
res/value 中是默认的字体<br />
把它复制一份成为 res/value-zh-rCN 文件夹，然后把其中文字改为简体中文</p>
<p>3. 在不改变系统设置的前提前，测试当前应用对某一语言的支持<br />
import java.util.Local; // 引入相关类<br />
import android.util.DisplayMetrics;</p>
<p>在 OnCreate 函数中加入以下本地化设置<br />
Resources res = getResources();<br />
Configuration conf = res.getConfiguration();<br />
conf.locale = Locale.SIMPLIFIED_CHINESE; // 设置为简体中文<br />
DisplayMetrics dm = res.getDisplayMetrics();<br />
res.updateConfiguration(conf,dm);<br />
编译后再运行程序时，读取的字串就是 res/value-zh-rCN 目录中 strings.xml
里的文字了</p>
<p>六、 常见问题及解决方法</p>
<p>1. android.app.Application<br />
创建一个属于你自己的 android.app.Application 的子类，然后在 manifest
中申明一下这个类，这是 android<br />
就为此建立一个全局可用的实例，你可以在其他任何地方使用
Context.getApplicationContext()<br />
方法获取这个实例，进而获取其中的状态</p>
<p>2. 用别人写的 java 文件改出自己的， R.xx 报错<br />
由于资源找不对，要把它的 res 文件和 AndroidManifest.xml
内容也做相应替换，注意 xml 里边要改成自己的类名</p>
<p>3. android 中可以使用 java 中的类吗<br />
一般数据结构使用它，而界面使用 android 自带的界面元素</p>
<p>4. layout 中的控件与程序中控件的关系<br />
平等的， layout 中的控件用 R.id.xxx 得到</p>
<p>5. 布局冲突<br />
requestWindowFeature 与 setContentView 冲突</p>
<p>七、 android 是重要的包<br />
android.app ：提供高层的程序模型、提供基本的运行环境<br />
android.content ：包含各种的对设备上的数据进行访问和发布的类<br />
android.database ：通过内容提供者浏览和操作数据库<br />
android.graphics
：底层的图形库，包含画布，颜色过滤，点，矩形，可以将他们直接绘制到屏幕上
.<br />
android.location ：定位和相关服务的类<br />
android.media ：提供一些类管理多种音频、视频的媒体接口<br />
android.net ：提供帮助网络访问的类，超过通常的 java.net.* 接口<br />
android.os ：提供了系统服务、消息传输、 IPC 机制<br />
android.opengl ：提供 OpenGL 的工具<br />
android.provider ：提供类访问 Android 的内容提供者<br />
android.telephony ：提供与拨打电话相关的 API 交互<br />
android.view ：提供基础的用户界面接口框架<br />
android.util ：涉及工具性的方法，例如时间日期的操作<br />
android.webkit ：默认浏览器操作接口<br />
android.widget ：包含各种 UI
元素（大部分是可见的）在应用程序的屏幕中使用</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android的传感器</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E7%9A%84%E4%BC%A0%E6%84%9F%E5%99%A8/</url>
    <content><![CDATA[<h1 id="android的传感器">Android的传感器</h1>
<p>#移动开发 #android</p>
<p>1. sensor<br />
sensor 译做感应器或传感器， android 架构支持多种 sensor
，手机硬件不一定支持每一种</p>
<p>2. android 系统支持的 sensor ，以 froyo 为例（详见 SensorManager.java
中的定义）</p>
<ol type="1">
<li><p>重力<br />
STANDARD_GRAVITY</p></li>
<li><p>加速度： XYZ 三个方向上的加速度<br />
SENSOR_ACCELEROMETER</p></li>
<li><p>温度：周围温度<br />
SENSOR_TEMPERATURE</p></li>
<li><p>磁场： XYZ 三轴上的磁场<br />
SENSOR_MAGNETIC_FIELD</p></li>
<li><p>光线：周围亮度，用于调节对应的屏幕亮度<br />
SENSOR_LIGHT</p></li>
<li><p>接近：相应传感器与物体的距离，如在接电话时，判断耳朵与手机的距离，耳朵触屏被忽略，适里黑屏<br />
SENSOR_PROXIMITY</p></li>
<li><p>角度： XYZ 轴的角度<br />
SENSOR_ORIENTATION<br />
SENSOR_ORIENTATION_RAW</p></li>
<li><p>其它<br />
与具体应用相关，比如照相模块中实现的 CAMERA SENSOR</p></li>
</ol>
<p>3. 如何访问 sensor<br />
应用通过 SensorManager 访问各个 sensor ，注册一个 Listener
即可监听相应的 sensor 事件</p>
<p>4. 参考<br />
<a
href="http://www.uuroid.com/?p=39">http://www.uuroid.com/?p=39</a><br />
<a
href="http://www.ibm.com/developerworks/cn/opensource/os-android-sensor/">http://www.ibm.com/developerworks/cn/opensource/os-android-sensor/<br />
</a></p>
<p>(转载请注明出处: <a
href="http://xy0811.spaces.live.com/">http://xy0811.spaces.live.com/</a>
)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android的键盘事件处理</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E7%9A%84%E9%94%AE%E7%9B%98%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<h1 id="android的键盘事件处理">Android的键盘事件处理</h1>
<p>#移动开发 #android</p>
<p>1. 基本流程</p>
<ol type="1">
<li><p>内核处理按键，通过设备文件的方式提供给 framework 层</p></li>
<li><p>framework 层的 KeyInputQueue.java
启动线程从设备文件中读出键码，然后把读出的键码按 kl
文件转成相应键值<br />
(JNI 调用 EventHub.cpp) ，最后写入事件队列</p></li>
<li><p>framework 层的 WindowManagerService.java
启动线程从事件队列中读出键值，然后根据当前 focus<br />
分发给相应窗口</p></li>
<li><p>UI 通过 KeyCharacterMap.java 处理 kcm 规则将用户基本按键与功能键
(Shift, Alt 等 )<br />
组合 ， 得出最终按键</p></li>
</ol>
<p>2. 两个配置文件<br />
通常更换一种新的硬件，可能其键盘布局及键码与标准版本不同，不用更改代码，只要修改以下配置文件即可（如果增加新的未定义功能的按键，则需要修改代码）</p>
<ol type="1">
<li>xxx.kl</li>
</ol>
<ol type="a">
<li><p>位置<br />
development/emulator/keymaps/<em>.kl (1.6 版本模拟器使用 )<br />
sdk/emulator/keymaps/</em>.kl (2.2 版本模拟器使用 )<br />
vendor/xxx/xxx/*.kl ( 特定硬件专用 kl)</p></li>
<li><p>功能<br />
硬件全键盘的键码与键值的对应规则文件（如 0x21 对应 A ）</p></li>
</ol>
<ol start="2" type="1">
<li>xxx.kcm</li>
</ol>
<ol type="a">
<li><p>位置<br />
development/emulator/keymaps/<em>.kcm (1.6 版本模拟器使用 )<br />
sdk/emulator/keymaps/</em>.kcm (2.2 版本模拟器使用 )<br />
vendor/xxx/xxx/*.kcm ( 特定硬件专用 kcm)</p></li>
<li><p>功能<br />
硬件全键盘的键值对应表（如按下 Alt, Shift 时按键对应的键值）</p></li>
</ol>
<p>3. 相关代码</p>
<ol type="1">
<li><p>frameworks/base/core/java/android/view/KeyEvent.java (
按键事件定义 )</p></li>
<li><p>frameworks/base/services/java/com/android/server/KeyInputQueue.java
(<br />
事件读取线程 )</p></li>
<li><p>frameworks/base/services/java/com/android/server/WindowManagerService.java<br />
（事件分发线程）</p></li>
<li><p>frameworks/base/core/java/android/view/KeyCharacterMap.java (
功能键转换 kcm)</p></li>
<li><p>frameworks/base/libs/ui/EventHub.cpp ( 键码与键值转换 )</p></li>
</ol>
<p>4. 参考</p>
<ol type="1">
<li><p><a
href="http://www.armfans.net/archiver/tid-2671.html">http://www.armfans.net/archiver/tid-2671.html<br />
</a></p></li>
<li><p>http://www.armfans.net/viewthread.php?tid=2671</p></li>
</ol>
<p>(转载请注明出处: <a
href="http://xy0811.spaces.live.com/">http://xy0811.spaces.live.com/</a>
)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android程序中使用定时器Timer</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E7%A8%8B%E5%BA%8F%E4%B8%AD%E4%BD%BF%E7%94%A8%E5%AE%9A%E6%97%B6%E5%99%A8Timer/</url>
    <content><![CDATA[<h1 id="android程序中使用定时器timer">Android程序中使用定时器Timer</h1>
<p>#移动开发 #android</p>
<p>一、 重点</p>
<p>1. 如何使用 handler 和 message</p>
<p>2. 如何延时调用</p>
<ol type="1">
<li><p>使用延迟发消息的方式</p></li>
<li><p>也可以使用android.util.Timer与handler相结合的方式<br />
见 <a
href="http://hi.baidu.com/iammuyue/blog/item/20ef6b10bbc92377cb80c467.html">http://hi.baidu.com/iammuyue/blog/item/20ef6b10bbc92377cb80c467.html<br />
</a></p></li>
</ol>
<p>二、 举例</p>
<p>1. 功能：实现一个应用界面，在用户长按触模屏两秒后，打出 Log 信息</p>
<p>2. 步骤：</p>
<ol type="1">
<li>建立 project</li>
</ol>
<ol type="a">
<li><p>在 eclipse 中点击菜单 File-&gt;New-&gt;Project ……</p></li>
<li><p>选择 Android Project 按 Next</p></li>
<li><p>填写 project 的各项内容如下<br />
Project name: test_xy // 目录名 , 它位于你设定的 workspace 之下<br />
Package name: com.android.test // 打包名称<br />
Activity name: .TestXy // 类名 ( 生成文件 TestXy.java)<br />
Application name: test_xy // 可执行程序名<br />
然后点 Finish 按钮</p></li>
</ol>
<ol start="2" type="1">
<li>修改 TestXy.java 代码如下 **<br />
package com.android.test;</li>
</ol>
<p>import android.app.Activity;<br />
import android.os.Bundle;<br />
import android.view.MotionEvent;<br />
import android.os.Handler;<br />
import android.os.Message;<br />
import android.util.Log;</p>
<p>public class TextXy extends Activity {<br />
/** Called when the activity is first created. */<br />
static final int <em>MESSAGE_LONG_PRESS</em> = 1; <strong> //
定义长按事件 ID </strong><br />
static final int <em>LONG_PRESS_TIMEOUT</em> = 2000; <strong> //
定义长按为 2 秒 </strong><br />
final Handler mHandler = new LongPressHandler(); <strong> // 定义
handler </strong></p>
<p>class LongPressHandler extends Handler { ** // handler 类的实现
**<br />
public void handleMessage(Message msg) { ** // 事件处理函数 **<br />
switch (msg.what) {<br />
case <em>MESSAGE_LONG_PRESS</em> : ** // 选择事件 ID **<br />
Log. <em>d</em> ("TEST_XY", "now long press!");<br />
break;<br />
}<br />
}<br />
}</p>
<p><span class="citation" data-cites="Override">@Override</span><br />
public void onCreate(Bundle savedInstanceState) {<br />
super.onCreate(savedInstanceState);<br />
setContentView(R.layout. <em>main</em> );<br />
}</p>
<p>public boolean onTouchEvent(MotionEvent ev) { ** // 处理触屏事件
**<br />
int action = ev.getAction(); ** // 得到触屏动作 **<br />
if (action == MotionEvent. <em>ACTION_DOWN</em> ) { ** // 手指按下
**<br />
mHandler.sendMessageDelayed(mHandler<br />
.obtainMessage( <em>MESSAGE_LONG_PRESS</em> ),<br />
<em>ONG_PRESS_TIMEOUT</em> ); ** // 延时 2 秒后发送事件 **<br />
} else if (action == MotionEvent. <em>ACTION_UP</em> ) { ** // 手指抬起
**<br />
mHandler.removeMessages( <em>MESSAGE_LONG_PRESS</em> );<br />
** // 取消延时事件 **<br />
}<br />
return false;<br />
}<br />
} **</p>
<ol start="3" type="1">
<li>运行</li>
</ol>
<ol type="a">
<li><p>在 eclipse 中点击菜单 Run- &gt;Run Configurations ……</p></li>
<li><p>双击左边的 Android Application ，产生了一个 New Configuration
，点开它填写内容如下：<br />
Name: yan_config // 随便起一个<br />
Project: test_xy // 刚才起的 project, 即目录名</p></li>
<li><p>点击 Apply ，然后点 Run ，多等一会儿就出来了</p></li>
<li><p>此时点击右上的 DDMS ，可看到 Log
信息，在长按屏幕两秒后，可看到刚才加入的 Log 信息</p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android程序中安装其它软件包</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E7%A8%8B%E5%BA%8F%E4%B8%AD%E5%AE%89%E8%A3%85%E5%85%B6%E5%AE%83%E8%BD%AF%E4%BB%B6%E5%8C%85/</url>
    <content><![CDATA[<h1 id="android程序中安装其它软件包">Android程序中安装其它软件包</h1>
<p>#移动开发 #android</p>
<p>1． 介绍<br />
应用程序中有时需要调用其它软件，但有时用户没有安装需要调用的软件，为方便用户使用，以下例程实现了半自动化的引导用户安装。</p>
<ol type="1">
<li>调用的几种可能性</li>
</ol>
<ol type="a">
<li><p>被调用的软件包已经存在</p></li>
<li><p>用户设备存在应用市场程序（如google market,
掌上应用汇等）</p></li>
<li><p>软件安装是否成功（在市场中能否找到软件包，调用市场软件时发生异常）</p></li>
</ol>
<p>2． 例程</p>
<ol type="1">
<li><p>功能<br />
判断文件管理器是否存在，如果不存在，则引导用户从应用市场安装</p></li>
<li><p>关键字<br />
应用中，安装，其它软件，apk</p></li>
<li><p>可从此处下载可独立运行的代码<br />
<a
href="http://download.csdn.net/detail/xieyan0811/4117459">http://download.csdn.net/detail/xieyan0811/4117459<br />
</a></p></li>
<li><p>核心代码及说明</p></li>
</ol>
<p><strong>package com.demo.apk;</strong></p>
<hr />
<p><strong>import android.app.Activity;</strong></p>
<p><strong>import android.app.AlertDialog;</strong></p>
<p><strong>import android.os.Bundle;</strong></p>
<p><strong>import android.content.Intent;</strong></p>
<p><strong>import android.view.View;</strong></p>
<p><strong>import android.widget.Button;</strong></p>
<p><strong>import android.widget.Toast;</strong></p>
<p><strong>import android.net.Uri;</strong></p>
<p><strong>import android.util.Log;</strong></p>
<p><strong>import android.content.pm.PackageManager;</strong></p>
<p><strong>import android.content.pm.PackageInfo;</strong></p>
<p><strong>import android.content.pm.ResolveInfo;</strong></p>
<p><strong>import android.content.DialogInterface;</strong></p>
<p><strong>import java.util.List;</strong></p>
<p><strong>import java.util.ArrayList;</strong></p>
<hr />
<p><strong>public class MyApkActivity extends Activity { </strong></p>
<p><strong>private String TAG ="demo";</strong></p>
<p><strong>private static finalString APK_NAME =
"lysesoft.andexplorer";</strong></p>
<p><strong>private static finalint REQUEST_INSTALL = 1;</strong></p>
<hr />
<p><strong><span class="citation"
data-cites="Override">@Override</span></strong></p>
<p><strong>public voidonCreate(Bundle savedInstanceState) {
</strong></p>
<p><strong>super.onCreate(savedInstanceState);</strong></p>
<p><strong>Button button= new Button(this);</strong></p>
<p><strong>button.setText("test" + APK_NAME);</strong></p>
<p><strong>button.setOnClickListener(newView.OnClickListener() {
</strong></p>
<p><strong>publicvoid onClick(View v) { </strong></p>
<p><strong>if(apkExists()) // 软件包中否存在</strong></p>
<p><strong>showExists(); // 提示用户已存在</strong></p>
<p><strong>elseif (!hasMarket()) // 是否有手机市场软件</strong></p>
<p><strong>showWithoutMarket(); // 提示用户无手机市场可用</strong></p>
<p><strong>else</strong></p>
<p><strong>runInstall(); // 安装软件</strong></p>
<p><strong>}</strong></p>
<p><strong>});</strong></p>
<p><strong>setContentView(button);</strong></p>
<p><strong>}</strong></p>
<hr />
<p><strong>private booleanapkExists() { </strong></p>
<p><strong>PackageManagerpManager = getPackageManager();</strong></p>
<p><strong>List <PackageInfo>packageInfoList =
pManager.getInstalledPackages(0); </strong></p>
<p><strong>for (int i =0; i &lt; packageInfoList.size(); i++) {
</strong></p>
<p><strong>PackageInfopkg = packageInfoList.get(i);</strong></p>
<p><strong>Log.d(TAG,"pkg name " + pkg.packageName);</strong></p>
<p><strong>if(pkg.packageName.equals(APK_NAME))</strong></p>
<p><strong>returntrue;</strong></p>
<p><strong>}</strong></p>
<p><strong>return false;</strong></p>
<p><strong>}</strong></p>
<hr />
<p><strong>public booleanhasMarket() { </strong></p>
<p><strong>List <ResolveInfo>mApps = new ArrayList<ResolveInfo>();
</strong></p>
<p><strong>Uri uri =Uri.parse("market://search?q=pname:" +
APK_NAME);</strong></p>
<p><strong>Intent intent= new Intent(Intent.ACTION_VIEW,
uri);</strong></p>
<p><strong>PackageManagerpManager = getPackageManager();</strong></p>
<p><strong>mApps =pManager.queryIntentActivities(intent,</strong></p>
<p><strong>PackageManager.COMPONENT_ENABLED_STATE_DEFAULT);</strong></p>
<p><strong>Log.d(TAG,"market count " + mApps.size());</strong></p>
<p><strong>if(mApps.size() &gt; 0) </strong></p>
<p><strong>returntrue;</strong></p>
<p><strong>else</strong></p>
<p><strong>returnfalse;</strong></p>
<p><strong>}</strong></p>
<hr />
<p><strong>private voidshowWithoutMarket() { </strong></p>
<p><strong>AlertDialog.Builderdialog = new
AlertDialog.Builder(this);</strong></p>
<p><strong>dialog.setMessage("withoutmarket on
smartphone");</strong></p>
<p><strong>dialog.setNegativeButton(android.R.string.cancel,null);</strong></p>
<p><strong>dialog.show();</strong></p>
<p><strong>}</strong></p>
<hr />
<p><strong>private voidshowExists() { </strong></p>
<p><strong>AlertDialog.Builderdialog = new
AlertDialog.Builder(this);</strong></p>
<p><strong>dialog.setMessage("apkalready exists");</strong></p>
<p><strong>dialog.setNegativeButton(android.R.string.cancel,null);</strong></p>
<p><strong>dialog.show();</strong></p>
<p><strong>}</strong></p>
<hr />
<p><strong>private voidrunInstall() { </strong></p>
<p><strong>Uri uri = Uri.parse("market://search?q=pname:"+
APK_NAME);</strong></p>
<p><strong>Intent it =new Intent(Intent.ACTION_VIEW, uri);</strong></p>
<p><strong>startActivityForResult(it,REQUEST_INSTALL);</strong></p>
<p><strong>}</strong></p>
<hr />
<p><strong>protected voidonActivityResult(int requestCode, int
resultCode,</strong></p>
<p><strong>Intentintent) { //
提示用户如果在市场上找不到软件的解决方法</strong></p>
<p><strong>if(requestCode == REQUEST_INSTALL) { </strong></p>
<p><strong>Log.d(TAG,"resultCode " + resultCode);</strong></p>
<p><strong>Toast.makeText(MyApkActivity.this,</strong></p>
<p><strong>"ifapk can't found in market, please download by
PC",</strong></p>
<p><strong>Toast.LENGTH_LONG).show();</strong></p>
<p><strong>}</strong></p>
<p><strong>}</strong></p>
<p><strong>};</strong></p>
<p>(转载请注明出处)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android缩放drawable</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E7%BC%A9%E6%94%BEdrawable/</url>
    <content><![CDATA[<h1 id="android缩放drawable">Android缩放drawable</h1>
<p>#移动开发 #android</p>
<p>一、 相关概念</p>
<p>1. Drawable 就是一个可画的对象，其可能是一张位图（ BitmapDrawable
），也可能是一个图形（ ShapeDrawable<br />
），还有可能是一个图层（ LayerDrawable
），我们根据画图的需求，创建相应的可画对象</p>
<p>2. Canvas 画布，绘制的目的区域，用于绘图</p>
<p>3. Bitmap 位图，用于图的处理</p>
<p>4. Matrix 矩阵，此例中用于操作图片</p>
<p>二、 步骤</p>
<p>1. 把 drawable 画到位图对象上</p>
<p>2. 对位图对象做缩放（或旋转等）操作</p>
<p>3. 把位图再转换成 drawable</p>
<p>** 三、 ** 示例<br />
** static Bitmap drawableToBitmap(Drawable drawable) ** // drawable
转换成<br />
bitmap **<br />
{<br />
int width = drawable.getIntrinsicWidth(); ** // 取 drawable 的长宽
**<br />
int height = drawable.getIntrinsicHeight();<br />
Bitmap.Config config = drawable.getOpacity() != PixelFormat.OPAQUE
?<br />
Bitmap.Config.ARGB_8888:Bitmap.Config.RGB_565; ** // 取 drawable
的颜色格式 **<br />
Bitmap bitmap = Bitmap.createBitmap(width, height, config); ** //
建立对应<br />
bitmap **<br />
Canvas canvas = new Canvas(bitmap); ** // 建立对应 bitmap 的画布
**<br />
drawable.setBounds(0, 0, width, height);<br />
drawable.draw(canvas); ** // 把 drawable 内容画到画布中 **<br />
return bitmap;<br />
}</p>
<p>static Drawable zoomDrawable(Drawable drawable, int w, int h)<br />
{<br />
int width = drawable.getIntrinsicWidth();<br />
int height= drawable.getIntrinsicHeight();<br />
Bitmap oldbmp = drawableToBitmap(drawable); ** // drawable 转换成 bitmap
**<br />
Matrix matrix = new Matrix(); ** // 创建操作图片用的 Matrix 对象
**<br />
float scaleWidth = ((float)w / width); ** // 计算缩放比例 **<br />
float scaleHeight = ((float)h / height);<br />
matrix.postScale(scaleWidth, scaleHeight); ** // 设置缩放比例 **<br />
Bitmap newbmp = Bitmap.createBitmap(oldbmp, 0, 0, width, height,
matrix,<br />
true); ** // 建立新的 bitmap ，其内容是对原 bitmap 的缩放后的图 **<br />
return new BitmapDrawable(newbmp); ** // 把 bitmap 转换成 drawable
并返回 **<br />
}<br />
} **</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android自带的人脸识别</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E8%87%AA%E5%B8%A6%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/</url>
    <content><![CDATA[<h1 id="android自带的人脸识别">Android自带的人脸识别</h1>
<p>#移动开发 #android</p>
<p>1. Android 自带的人脸识别<br />
Android
自带的人脸识别只能识别出人脸在画面中的位置，中点，眼间距，角度等基本特性，提供给拍照性质的应用使用。从基本功能中不能得出明显的特征数据</p>
<p>2. 底层库支持<br />
external/neven/*</p>
<p>3. 接口<br />
frameworks/base/media/java/android/media/FaceDetector.java</p>
<p>4. Android 源码参考<br />
packages/apps/Gallery/src/com/android/camera/*</p>
<p>5. 关键代码分析</p>
<p>_ package com.android.mydetect; _</p>
<p>_ _</p>
<p>_ import android.app.Activity; _</p>
<p>_ import android.widget.TextView; _</p>
<p>_ import android.os.Bundle; _</p>
<p>_ import android.media.FaceDetector; // _ _ 人脸识别接口 _ __</p>
<p>_ import android.widget.ImageView; _</p>
<p>_ import android.graphics.BitmapFactory; _</p>
<p>_ import android.graphics.Bitmap; _</p>
<p>_ import android.graphics.PointF; _</p>
<p>_ import android.graphics.Matrix; _</p>
<p>_ import android.util.Log; _</p>
<p>_ import android.graphics.Canvas; _</p>
<p>_ import android.graphics.Paint; _</p>
<p>_ _</p>
<p>_ public class MyDetectActivity extends Activity { _</p>
<p>_ private ImageView mImageView; // _ _ 图片显示控件 _ __</p>
<p>_ private Bitmap mBitmap; _</p>
<p>_ private float mScale = 1F; _</p>
<p>_ _</p>
<p>_ <span class="citation" data-cites="Override">@Override</span> _</p>
<p>_ public void onCreate(Bundle savedInstanceState) { _</p>
<p>_ super.onCreate(savedInstanceState); _</p>
<p>_ setContentView(R.layout.main); _</p>
<p>_ mImageView = (ImageView) this.findViewById(R.id.image); _</p>
<p>_ detect(); // _ _ 识别函数 _ __</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ private void handleFace(FaceDetector.Face f) { // _ _
在图片上对每张脸进行处理 _ __</p>
<p>_ PointF midPoint = new PointF(); _</p>
<p>_ int r = ((int) (f.eyesDistance() * mScale * 1.5)); // _ _
取眼睛间距离 _ __</p>
<p>_ f.getMidPoint(midPoint); // _ _ 取脸的中点 _ __</p>
<p>_ midPoint.x *= mScale; _</p>
<p>_ midPoint.y *= mScale; _</p>
<p>_ Canvas c = new Canvas(mBitmap); _</p>
<p>_ Paint p = new Paint(); _</p>
<p>_ p.setAntiAlias(true); _</p>
<p>_ p.setAlpha(0x80); _</p>
<p>_ c.drawCircle(midPoint.x, midPoint.y, r, p) // _ _
用半透明标出人脸区域 _ _ ; _</p>
<p>_ mImageView.setImageBitmap(mBitmap); // _ _ 显示图片 _ __</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ private void detect() { _</p>
<p>_ Matrix matrix = new Matrix(); _</p>
<p>_ FaceDetector.Face[] mFaces = new FaceDetector.Face[3]; // _ _
定义最多识别三张脸 _<br />
__</p>
<p>_ int mNumFaces = 0; _</p>
<p>_ _</p>
<p>_ mBitmap = BitmapFactory.decodeResource(getResources(),
R.drawable.baby); //<br />
_ _ 取原始图 _ __</p>
<p>_ if (mBitmap == null) { _</p>
<p>_ return; _</p>
<p>_ } _</p>
<p>_ if (mBitmap.getWidth() &gt; 256) { _</p>
<p>_ mScale = 256.0F / mBitmap.getWidth(); _</p>
<p>_ } _</p>
<p>_ matrix.setScale(mScale, mScale); _</p>
<p>_ Bitmap faceBitmap = Bitmap.createBitmap(mBitmap, 0, 0, mBitmap
_</p>
<p>_ .getWidth(), mBitmap.getHeight(), matrix, true); // _ _
生成缩放后的新图 _ __</p>
<p>_ _</p>
<p>_ mScale = 1.0F / mScale; _</p>
<p>_ if (faceBitmap != null) { _</p>
<p>_ FaceDetector detector = new FaceDetector(faceBitmap.getWidth(),
_</p>
<p>_ faceBitmap.getHeight(), mFaces.length); // _ _ 创建识别器 _ __</p>
<p>_ mNumFaces = detector.findFaces(faceBitmap, mFaces); // _ _ 识别 _
__</p>
<p>_ if (mNumFaces &gt; 0) { _</p>
<p>_ for (int i = 0; i &lt; mNumFaces; i++) { _</p>
<p>_ handleFace(mFaces[i]); // _ _ 调用函数对人脸画面进行处理 _ __</p>
<p>_ } _</p>
<p>_ } _</p>
<p>_ } _</p>
<p>_ } _</p>
<p>_ } _</p>
<p>6. 完整例程下载<br />
<a
href="http://download.csdn.net/source/2612476">http://download.csdn.net/source/2612476<br />
</a></p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android软件中嵌入地图之一：Sogou地图</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E8%BD%AF%E4%BB%B6%E4%B8%AD%E5%B5%8C%E5%85%A5%E5%9C%B0%E5%9B%BE%E4%B9%8B%E4%B8%80%EF%BC%9ASogou%E5%9C%B0%E5%9B%BE/</url>
    <content><![CDATA[<h1
id="android软件中嵌入地图之一sogou地图">Android软件中嵌入地图之一：Sogou地图</h1>
<p>#移动开发 #android</p>
<p>在App中加入地图功能真是让人揪结，Google地图功能强大，但是有些国内的手机厂商去掉了手机系统中Google地图的相关库，所以这类机型将无法安装调用了Google地图的软件（比如：联想s899t）。如果用百度，搜狗，这些国内地图，又没法满足其他国家用户的需求。现在看来只好出两个版本。</p>
<p>从技术上来说，搜狗地图实现起来最容易，只需：加库，改AndroidManifest.xml，修改界面即可。百度，需要用应用名生成Key。而Google<br />
Map，还需要使用发布密钥生成一个Key，在Key和密钥正确对应时，才能正常显示地图，编译时还需要配置Google
Play<br />
Service，并且对手机系统的版本也有一定要求，虽然复杂，但功能也多。</p>
<p>搜狗地图</p>
<p>一、当前版本：v1.1，支持Android1.6及以上版本</p>
<p>二、使用方法：</p>
<p>1 加入库<br />
下库开发包，将其中的jar和so导入工程</p>
<p>2 修改AndroidManifest.xml</p>
<p>**
&lt;uses-permissionandroid:name="android.permission.ACCESS_FINE_LOCATION"
/&gt;<br />
**</p>
<p>**
&lt;uses-permissionandroid:name="android.permission.ACCESS_COARSE_LOCATION"
/&gt;<br />
**</p>
<p>**
&lt;uses-permissionandroid:name="android.permission.READ_PHONE_STATE"
/&gt; **</p>
<p>**
&lt;uses-permissionandroid:name="android.permission.ACCESS_WIFI_STATE"
/&gt; **</p>
<p>**
&lt;uses-permissionandroid:name="android.permission.CHANGE_WIFI_STATE"
/&gt; **</p>
<p>** &lt;uses-permissionandroid:name="android.permission.WAKE_LOCK"
/&gt; **</p>
<p>3 修改layout中的xml<br />
** <?xmlversion="1.0" encoding="utf-8"?> **</p>
<p>**
&lt;LinearLayoutxmlns:android="http://schemas.android.com/apk/res/android"
**</p>
<p><strong>android:layout_width="fill_parent"</strong></p>
<p><strong>android:layout_height="fill_parent"</strong></p>
<p><strong>android:orientation="vertical" &gt; </strong></p>
<p>** &lt;com.go2map.mapapi.MapView **</p>
<p><strong>android:id="@+id/sogouMap"</strong></p>
<p><strong>android:layout_width="fill_parent"</strong></p>
<p><strong>android:layout_height="fill_parent"</strong></p>
<p><strong>android:layout_weight="2.17"</strong></p>
<p><strong>android:visibility="visible" / &gt; </strong></p>
<p>** </LinearLayout> **</p>
<p>4 修改Activity.java</p>
<p><strong>import android.app.Activity;</strong></p>
<p><strong>import android.os.Bundle;</strong></p>
<hr />
<p><strong>import com.go2map.mapapi.MapView;</strong></p>
<p><strong>import com.go2map.mapapi.Point;</strong></p>
<hr />
<p><strong>public class SogouMapActivity extendsActivity { </strong></p>
<p><strong>protectedvoid onCreate(Bundle savedInstanceState) {
</strong></p>
<p><strong>super.onCreate(savedInstanceState);</strong></p>
<p><strong>setContentView(R.layout.activity_sogou);</strong></p>
<p><strong>MapViewmapView = (MapView)
findViewById(R.id.sogouMap);</strong></p>
<p><strong>mapView.getController().setCenter(newPoint(12956000,
4824875), 10);</strong></p>
<p><strong>}</strong></p>
<p><strong>}</strong></p>
<p>三、相关链接：<br />
<a
href="http://map.sogou.com/api/documentation/mobile/api1.0/android/examples/">http://map.sogou.com/api/documentation/mobile/api1.0/android/examples/<br />
</a></p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android软件中嵌入地图之三：Google地图</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E8%BD%AF%E4%BB%B6%E4%B8%AD%E5%B5%8C%E5%85%A5%E5%9C%B0%E5%9B%BE%E4%B9%8B%E4%B8%89%EF%BC%9AGoogle%E5%9C%B0%E5%9B%BE/</url>
    <content><![CDATA[<h1
id="android软件中嵌入地图之三google地图">Android软件中嵌入地图之三：Google地图</h1>
<p>#移动开发 #android</p>
<p>谷歌地图</p>
<p>一、当前版本：Google Map Android v2，支持Android 2.2及以上版本</p>
<p>二、使用方法：</p>
<p>1 使用keytool工具得到签名对应的“认证指纹”<br />
keytool -list -alias 用户名 -keystore 签名文件路径 -storepass 密码</p>
<p>2 获得Google Map API Key<br />
登录： <a
href="https://code.google.com/apis/console">https://code.google.com/apis/console<br />
</a> （该网站像其它google网站一样，有时连不上，多连几次即可）<br />
点开左侧的services，选中Google Map Android API v2和Google Play Android
Developer API<br />
点开右侧的APIaccess，选择其中的Createnew Android
key，然后输入“认证指纹”，即可得到API Key</p>
<p>3 在开发环境中安装Google Play Service SDK<br />
在Eclipse中打开 Windows&gt;Android SDK Manager，下载Google Play
services<br />
SDK，下载后保存在<android-sdk-folder>/extras/google/google_play_services/。<br />
复制google_play_services/libproject/google-play-services_lib到任何地方，然后再eclipse中选择<br />
File &gt; Import, Android &gt;Existing Android Code into
Workspace.<br />
在自己工程上点击右键，选择Properties&gt;Android，点击添加按钮,把前面导入的google-play-services_lib工程加进来</p>
<p>4 修改AndroidManifest.xml</p>
<p>** <uses-permission android:name="android.permission.INTERNET"/>
**</p>
<p>**
&lt;uses-permissionandroid:name="android.permission.ACCESS_NETWORK_STATE"
/&gt;<br />
**</p>
<p>**
<uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE"/><br />
**</p>
<p>** <uses-  
permissionandroid:name="com.google.android.providers.gsf.permission.READ_GSERVICES"/><br />
**</p>
<p>**
&lt;uses-permissionandroid:name="android.permission.ACCESS_COARSE_LOCATION"
/&gt;<br />
**</p>
<p>**
&lt;uses-permissionandroid:name="android.permission.ACCESS_FINE_LOCATION"
/&gt;<br />
**</p>
<p>** &lt;permission **</p>
<p><strong>android:name="com.travel.trek.permission.MAPS_RECEIVE"</strong></p>
<p><strong>android:protectionLevel="signature" / &gt; </strong></p>
<p>**
&lt;uses-permissionandroid:name="com.example.mapdemo.permission.MAPS_RECEIVE"<br />
/&gt; **</p>
<p>** &lt;uses-feature **</p>
<p><strong>android:glEsVersion="0x00020000"</strong></p>
<p><strong>android:required="true" / &gt; </strong></p>
<p>** <!--application 中定义meta-data--> **</p>
<p>** &lt;meta-data **</p>
<p><strong>android:name="com.google.android.maps.v2.API_KEY"</strong></p>
<p><strong>android:value="认证指纹"/ &gt; </strong></p>
<p>5 修改layout中的xml</p>
<p>** <?xml version="1.0"encoding="utf-8"?> **</p>
<p>**
&lt;fragmentxmlns:android="http://schemas.android.com/apk/res/android"
**</p>
<p><strong>android:id="@+id/map"</strong></p>
<p><strong>android:layout_width="fill_parent"</strong></p>
<p><strong>android:layout_height="fill_parent"</strong></p>
<p><strong>class="com.google.android.gms.maps.SupportMapFragment" / &gt;
</strong></p>
<p>6 修改Activity.java<br />
注意：v2和v1的方法不同，v2使用fragment。如果使用不当，也不能正常显示地图</p>
<p><strong>import android.os.Bundle;</strong></p>
<p><strong>importandroid.support.v4.app.FragmentActivity;</strong></p>
<hr />
<p><strong>public class GoogleMapActivity extendsFragmentActivity {
</strong></p>
<p><strong><span class="citation"
data-cites="Override">@Override</span></strong></p>
<p><strong>publicvoid onCreate(Bundle savedInstanceState) {
</strong></p>
<p><strong>super.onCreate(savedInstanceState);</strong></p>
<p><strong>setContentView(R.layout.activity_google);</strong></p>
<p><strong>}</strong></p>
<p><strong>}</strong></p>
<p>三、问题及解决</p>
<p>1 问题1：</p>
<ol type="1">
<li><p>问题：<br />
安装时报错：INSTALL_FAILED_MISSING_SHARED_LIBRARY</p></li>
<li><p>原因：<br />
有的手机的操作系统精简掉了googlemap库，因此找不到库</p></li>
<li><p>解决：<br />
获得该手机的root权限，然后将google
map库拷进系统库目录。但对于没有root权限的普通用户来说，基本就没办法了。</p></li>
</ol>
<p>2 问题2：</p>
<ol type="1">
<li><p>问题：<br />
进入界面报错：<br />
java.lang.NoClassDefFoundError:
com.google.android.gms.R$styleable</p></li>
<li><p>原因：<br />
未将Google PlayService加入应用</p></li>
<li><p>解决：<br />
在开发环境中加入GooglePlay Service</p></li>
</ol>
<p>3 问题3：</p>
<ol type="1">
<li><p>问题：<br />
进入界面不显示地图，后台显示：Failed to contact Google servers</p></li>
<li><p>原因：<br />
API Key与当前应用不对应</p></li>
<li><p>解决：<br />
填写正确对应的API Key</p></li>
</ol>
<p>四、相关链接<br />
<a
href="http://www.blogjava.net/xmlspy/articles/393726.html">http://www.blogjava.net/xmlspy/articles/393726.html<br />
</a><br />
<a
href="https://developers.google.com/maps/documentation/javascript/tutorial?hl=zh-%20cn">https://developers.google.com/maps/documentation/javascript/tutorial?hl=zh-<br />
cn<br />
</a></p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Android软件中嵌入地图之二：百度地图</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/Android%E8%BD%AF%E4%BB%B6%E4%B8%AD%E5%B5%8C%E5%85%A5%E5%9C%B0%E5%9B%BE%E4%B9%8B%E4%BA%8C%EF%BC%9A%E7%99%BE%E5%BA%A6%E5%9C%B0%E5%9B%BE/</url>
    <content><![CDATA[<h1
id="android软件中嵌入地图之二百度地图">Android软件中嵌入地图之二：百度地图</h1>
<p>#移动开发 #android</p>
<p>百度地图</p>
<p>一、当前版本：v2.2.1，支持Android 2.1及以上版本</p>
<p>二、使用方法：</p>
<p>1 申请密钥：通过应用名称和简单介绍生成密钥<br />
<a
href="http://developer.baidu.com/map/android-mobile-apply-key.htm">http://developer.baidu.com/map/android-mobile-apply-key.htm<br />
</a></p>
<p>2 加入库<br />
下库开发包，将其中的jar和so导入工程</p>
<p>3 修改AndroidManifest.xml</p>
<p>** &lt;supports-screens **</p>
<p><strong>android:anyDensity="true"</strong></p>
<p><strong>android:largeScreens="true"</strong></p>
<p><strong>android:normalScreens="true"</strong></p>
<p><strong>android:resizeable="true"</strong></p>
<p><strong>android:smallScreens="true" / &gt; </strong></p>
<hr />
<p>**
<uses-permission android:name="android.permission.ACCESS_NETWORK_STATE"/><br />
**</p>
<p>** <uses-permission android:name="android.permission.INTERNET"/>
**</p>
<p>**
&lt;uses-permissionandroid:name="android.permission.ACCESS_WIFI_STATE"
/&gt; **</p>
<p>**
&lt;uses-permissionandroid:name="android.permission.CHANGE_WIFI_STATE"
/&gt; **</p>
<p>**
&lt;uses-permissionandroid:name="android.permission.WRITE_EXTERNAL_STORAGE"
/&gt;<br />
**</p>
<p>**
&lt;uses-permissionandroid:name="android.permission.READ_PHONE_STATE"
/&gt; **</p>
<p>** &lt;uses-permissionandroid:name="android.permission.CALL_PHONE"
/&gt; **</p>
<p>**
<uses-permission android:name="android.permission.ACCESS_FINE_LOCATION"/><br />
**</p>
<hr />
<p>**
&lt;permissionandroid:name="android.permission.BAIDU_LOCATION_SERVICE"
/&gt; **</p>
<hr />
<p>**
&lt;uses-permissionandroid:name="android.permission.BAIDU_LOCATION_SERVICE"
/&gt;<br />
**</p>
<p>**
<uses-permission android:name="android.permission.ACCESS_COARSE_LOCATION"/><br />
**</p>
<p>**
&lt;uses-permissionandroid:name="android.permission.ACCESS_MOCK_LOCATION"
/&gt;<br />
**</p>
<p>** &lt;uses-permissionandroid:name="android.permission.ACCESS_GPS"
/&gt; **</p>
<p>4 修改layout中的xml</p>
<p>** <?xml version="1.0"encoding="utf-8"?> **</p>
<p>** &lt;LinearLayout
xmlns:android="http://schemas.android.com/apk/res/android" **</p>
<p><strong>android:layout_width="fill_parent"</strong></p>
<p><strong>android:layout_height="fill_parent"</strong></p>
<p><strong>android:orientation="vertical" &gt; </strong></p>
<p>** &lt;com.baidu.mapapi.map.MapView **</p>
<p><strong>android:id="@+id/bmapsView"</strong></p>
<p><strong>android:layout_width="fill_parent"</strong></p>
<p><strong>android:layout_height="fill_parent"</strong></p>
<p><strong>android:clickable="true" / &gt; </strong></p>
<p>** </LinearLayout> **</p>
<p>5 修改Activity.java</p>
<p><strong>import android.app.Activity;</strong></p>
<p><strong>import android.os.Bundle;</strong></p>
<p><strong>import com.baidu.mapapi.BMapManager;</strong></p>
<p><strong>import com.baidu.mapapi.map.MapController;</strong></p>
<p><strong>import com.baidu.mapapi.map.MapView;</strong></p>
<p><strong>importcom.baidu.platform.comapi.basestruct.GeoPoint;</strong></p>
<hr />
<p><strong>public class BaiduMapActivity extendsActivity { </strong></p>
<p><strong>BMapManagermBMapMan = null;</strong></p>
<p><strong>MapViewmMapView = null;</strong></p>
<hr />
<p><strong><span class="citation"
data-cites="Override">@Override</span></strong></p>
<p><strong>publicvoid onCreate(Bundle savedInstanceState) {
</strong></p>
<p><strong>super.onCreate(savedInstanceState);</strong></p>
<p><strong>mBMapMan= new BMapManager(getApplication());</strong></p>
<p><strong>mBMapMan.init("申请的密钥", null);</strong></p>
<p><strong>setContentView(R.layout.activity_baidu);</strong></p>
<p><strong>mMapView= (MapView)
findViewById(R.id.bmapsView);</strong></p>
<p><strong>mMapView.setBuiltInZoomControls(true);</strong></p>
<p><strong>MapControllermMapController =
mMapView.getController();</strong></p>
<p><strong>GeoPointpoint = new GeoPoint((int) (39.915 *
1E6),</strong></p>
<p><strong>(int)(116.404 * 1E6));</strong></p>
<p><strong>mMapController.setCenter(point);</strong></p>
<p><strong>mMapController.setZoom(12);</strong></p>
<p><strong>}</strong></p>
<hr />
<p><strong><span class="citation"
data-cites="Override">@Override</span></strong></p>
<p><strong>protectedvoid onDestroy() { </strong></p>
<p><strong>mMapView.destroy();</strong></p>
<p><strong>if(mBMapMan != null) { </strong></p>
<p><strong>mBMapMan.destroy();</strong></p>
<p><strong>mBMapMan= null;</strong></p>
<p><strong>}</strong></p>
<p><strong>super.onDestroy();</strong></p>
<p><strong>}</strong></p>
<hr />
<p><strong><span class="citation"
data-cites="Override">@Override</span></strong></p>
<p><strong>protectedvoid onPause() { </strong></p>
<p><strong>mMapView.onPause();</strong></p>
<p><strong>if(mBMapMan != null) { </strong></p>
<p><strong>mBMapMan.stop();</strong></p>
<p><strong>}</strong></p>
<p><strong>super.onPause();</strong></p>
<p><strong>}</strong></p>
<hr />
<p><strong><span class="citation"
data-cites="Override">@Override</span></strong></p>
<p><strong>protectedvoid onResume() { </strong></p>
<p><strong>mMapView.onResume();</strong></p>
<p><strong>if(mBMapMan != null) { </strong></p>
<p><strong>mBMapMan.start();</strong></p>
<p><strong>}</strong></p>
<p><strong>super.onResume();</strong></p>
<p><strong>}</strong></p>
<p><strong>}</strong></p>
<p>三、相关链接<br />
<a
href="http://developer.baidu.com/map/sdk-android.htm">http://developer.baidu.com/map/sdk-android.htm<br />
</a></p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>CTS的Signature规则</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/CTS%E7%9A%84Signature%E8%A7%84%E5%88%99/</url>
    <content><![CDATA[<h1 id="cts的signature规则">CTS的Signature规则</h1>
<p>#移动开发 #android</p>
<p>1. 说明<br />
主要是对公共控件的语法检查</p>
<p>2. 测试方法<br />
_ $ make cts<br />
$ adb install -r
out/target/product/qsd8250_surf/data/app/SignatureTest.apk<br />
$ adb shell am instrument -w
android.tests.sigtest/.InstrumentationRunner _</p>
<p>3. 原理<br />
系统生成了一些 xml ，位置在：<br />
out/target/common/obj/APPS/SignatureTest_intermediates/genres/xml/*<br />
根据 xml 对类、方法、变量给出的规则对当前系统中的公共部分进行检测</p>
<p>4. 举例</p>
<ol type="1">
<li><p>用于检查的语法规则 xml 文件<br />
out/target/common/obj/APPS/SignatureTest_intermediates/genres/xml/app_widget.xml</p></li>
<li><p>被检查的代码<br />
framework/base/core/java/android/widget/*</p></li>
<li><p>检查步骤<br />
用循环的方法取 xml 中的每条 TAG ，然后用 Class.forName(classname,
false,<br />
this.getClass().getClassLoader())
取系统中对应的类，并判断它是否适合规则</p></li>
</ol>
<p>5. CTS 的 Signature 部分程序分析</p>
<ol type="1">
<li><p>代码位置<br />
cts/tests/SignatureTest/src/android/tests/sigtest/*</p></li>
<li><p>关键代码</p></li>
</ol>
<ol type="a">
<li><p>cts/tests/SignatureTest/src/android/tests/sigtest/SignatureTest.java<br />
检查的入口 (SignatureTest:start()) ，由它读入并分析 xml</p></li>
<li><p>cts/tests/SignatureTest/src/android/tests/sigtest/JDiffClassDescription.java<br />
实质的分析程序，用于根据规则找到相应的类及函数，并进行验证</p></li>
</ol>
<p>6. 检查的问题（具体见 JDiffClassDescription.java ）</p>
<ol type="1">
<li>验证问题</li>
</ol>
<ol type="a">
<li><p>访问权限： public ， protected ， private</p></li>
<li><p>参数的类型及个数</p></li>
<li><p>特性： abstract, static, final, transient, volatile,
synchronized, native</p></li>
</ol>
<ol start="2" type="1">
<li>验证条目</li>
</ol>
<ol type="a">
<li><p>变量 field ：访问权限，特性，类型，变量名</p></li>
<li><p>方法 method, constructor
：参数，返回值，异常处理，访问权限，特征，方法名，兼容性</p></li>
<li><p>类 class, implements ：访问权限，特性，类名，
class/implements</p></li>
</ol>
<p>7. Signature 在开发中的作用<br />
相关模块根据对应的 xml 文件检查自己代码是否符合规则<br />
通过运行用例发现不符合规则的代码</p>
<p>(转载请注明作者及出处: <a
href="http://xy0811.spaces.live.com">http://xy0811.spaces.live.com</a><br />
)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>JDWP命令行调试</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/JDWP%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%B0%83%E8%AF%95/</url>
    <content><![CDATA[<h1 id="jdwp命令行调试">JDWP命令行调试</h1>
<p>#移动开发 #android</p>
<p>1. JDWP 调试<br />
JDWP 用于在 java
程序层面的调试,当然也可以在eclipse中使用,或利用ddms调试</p>
<ol type="1">
<li>在某一终端运行虚拟机</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ adb forward tcp:8000 tcp:8000    </span><br><span class="line">$ adb shell    </span><br><span class="line">$ dalvikvm -agentlib:jdwp=transport=dt_socket,address=8000,server=y,suspend=y  </span><br><span class="line">-cp /sdcard/foo.jar Foo  _    </span><br><span class="line">```  </span><br><span class="line">此时挂起等待调试  </span><br><span class="line">  </span><br><span class="line">2)  在另一终端开启调试    </span><br><span class="line">```  </span><br><span class="line">$ jdb -attach localhost:8000    </span><br><span class="line">[jdb  _ _ 提示符  _ _ ] run    </span><br><span class="line">```  </span><br><span class="line">此时程序继续运行  </span><br><span class="line">  </span><br><span class="line">3)  jdb  常用命令    </span><br><span class="line">```  </span><br><span class="line">[jdb  提示符  ] threads  看当前所有线程    </span><br><span class="line">[jdb  提示符  ] trace methods 0x12aac5a00  跟踪线程号为  0x12aac5a00  的线程  (  线程号从  </span><br><span class="line">threads  得到  )    </span><br><span class="line">[jdb  提示符  ] next/step  下一步    </span><br><span class="line">[jdb  提示符  ] 40 next  执行  40  次  next  </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android代码中运行二进制程序或脚本</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E4%BB%A3%E7%A0%81%E4%B8%AD%E8%BF%90%E8%A1%8C%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%A8%8B%E5%BA%8F%E6%88%96%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<h1
id="android代码中运行二进制程序或脚本">android代码中运行二进制程序或脚本</h1>
<p>#移动开发 #android</p>
<p>1. 知识点<br />
在程序中执行 shell 脚本或程序（线程中执行），并显示进度条</p>
<p>2. 示例</p>
<ol type="a">
<li><p>功能<br />
实现在程序中运行命令 ”sleep 3” ，在线程中进行，并显示进度条</p></li>
<li><p>代码<br />
_ ……<br />
String commands = "sleep 3";<br />
sendshell(commands);<br />
……</p></li>
</ol>
<p>public void sendshell(final String commands) {<br />
String mymsg = "run " + commands;<br />
patience = ProgressDialog.show(this, "please wait", mymsg, true);<br />
Thread t = new Thread() {<br />
public void run() {<br />
try {<br />
Process process = Runtime.getRuntime().exec(commands);<br />
process.waitFor();<br />
} catch (Exception e) {<br />
e.printStackTrace();<br />
}<br />
patience.dismiss();<br />
}<br />
};<br />
t.start();<br />
} _</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android典型应用之gps</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8%E4%B9%8Bgps/</url>
    <content><![CDATA[<h1 id="android典型应用之gps">android典型应用之gps</h1>
<p>#移动开发 #android</p>
<p>1. gps 说明</p>
<ol type="a">
<li><p>原理<br />
每一卫星播发一个伪随机测距码信号，该信号大约每 1
毫秒播发一次。接收仪同时复制出一个同样结构的信号并与接收到的卫星信号进行比较，由信号的延迟时间<br />
(dT) 推算出卫星至 接收仪的距离</p></li>
<li><p>述语<br />
TTFF ：首次定位时间<br />
PRN ：伪随机码，用于辨别是哪颗卫星<br />
SNR ：信噪比</p></li>
</ol>
<p>2. android 对 gps 的内部支持</p>
<ol type="a">
<li><p>位置服务<br />
android 对卫星定位的支持名字叫位置服务 ，
可以通过设置来打开或关闭它</p></li>
<li><p>android 实现<br />
frameworks/base/location/java/android/location/LocationManager.java
接口<br />
frameworks/base/services/java/com/android/server/LocationManagerService.java<br />
服务<br />
frameworks/base/core/jni/android_location_GpsLocationProvider.cpp 等待
gps 事件<br />
， 发给 service<br />
libhardware_legacy/include/hardware_legacy/gps.h 定义了底级 gps 的实现
，<br />
不同硬件以不同方式实现它 ，它可能是对设备的访问，也可能与 modem 通过 rpc
通讯得到 gps 数据</p></li>
<li><p>应用程序调用接口<br />
frameworks/base/location/java/android/location/<em>.java<br />
LocationManager.java 是最重要的接口，通过它访问 gps 定位资源<br />
LocationListener.java 是定位的回调函数 ， 通过实现它来接收定位数据<br />
Gps</em>.java 提供了获取当前 gps 信息的接口 ， 包括捕获的卫星数 ，
信噪比等</p></li>
<li><p>调试<br />
想要调试 gps ， 可以把 /system/etc/gps.conf 中的 debug 等级调为 5 ，
此时你可以在 logcat<br />
中 看到全部的 gps 信息<br />
在室内基本没有信号，窗边效果也不好，建议在室外，至少是站在阳台上测试</p></li>
</ol>
<p>3. 例程</p>
<ol type="a">
<li><p>功能<br />
显示当前经纬度及搜到的卫星个数</p></li>
<li><p>可从此处下载可独立运行的代码<br />
<a
href="http://download.csdn.net/source/2598910">http://download.csdn.net/source/2598910<br />
</a></p></li>
<li><p>核心代码及说明</p></li>
</ol>
<p>_ package _ _ com.android.mygps; _</p>
<p>_ _</p>
<p>_ import android.app.Activity; _</p>
<p>_ import android.util.Log; _</p>
<p>_ import android.os.Bundle; _</p>
<p>_ import android.location.GpsStatus; _</p>
<p>_ import android.location.Location; _</p>
<p>_ import android.location.LocationListener; _</p>
<p>_ import android.location.LocationManager; _</p>
<p>_ import android.location.GpsSatellite; _</p>
<p>_ import android.widget.TextView; _</p>
<p>_ import android.content.Context; _</p>
<p>_ import java.util.Iterator; _</p>
<p>_ _</p>
<p>_ public class MyGpsActivity extends Activity { _</p>
<p>_ LocationManager mLocationManager; _</p>
<p>_ _</p>
<p>_ public void onCreate(Bundle savedInstanceState) { _</p>
<p>_ super.onCreate(savedInstanceState); _</p>
<p>_ setContentView(R.layout.main); _</p>
<p>_ _</p>
<p>_ mLocationManager = (LocationManager)<br />
getSystemService(Context.LOCATION_SERVICE); _</p>
<p>_ String provider = mLocationManager.GPS_PROVIDER; _</p>
<p>_ Location location =
mLocationManager.getLastKnownLocation(provider); _</p>
<p>_ mLocationManager.requestLocationUpdates(provider, 4000, 10, _</p>
<p>_ locationListener); // 4 _ _ 秒一次，开始接听 gps 数据 _</p>
<p>_ mLocationManager.addGpsStatusListener(statusListener); // _ _
注册状态信息回调 _</p>
<p>_ updateWithNewLocation(location); _</p>
<p>_ updateGpsStatus(0, null); _</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ public void onDestroy() { _</p>
<p>_ super.onDestroy(); _</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ private final GpsStatus.Listener statusListener = new
GpsStatus.Listener() {<br />
_</p>
<p>_ public void onGpsStatusChanged(int event) { _</p>
<p>_ Log.w("xieyan", "now gps status changed" + event); _</p>
<p>_ GpsStatus status = mLocationManager.getGpsStatus(null); // _ _
取当前状态 _</p>
<p>_ updateGpsStatus(event, status); _</p>
<p>_ } // GPS _ _ 状态变化时的回调，如卫星数，信号强度等 _</p>
<p>_ }; _</p>
<p>_ _</p>
<p>_ private final LocationListener locationListener = new
LocationListener() {<br />
_</p>
<p>_ public void onLocationChanged(Location location) { _</p>
<p>_ Log.w("xieyan", "now location changed"); _</p>
<p>_ updateWithNewLocation(location); _</p>
<p>_ } // _ _ 经纬度变化时的回调 _</p>
<p>_ _</p>
<p>_ public void onProviderDisabled(String provider) { _</p>
<p>_ Log.w("xieyan", "now provider disable"); _</p>
<p>_ updateWithNewLocation(null); _</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ public void onProviderEnabled(String provider) { _</p>
<p>_ Log.w("xieyan", "now provider enable"); _</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ public void onStatusChanged(String provider, int status, Bundle
extras) { _</p>
<p>_ Log.w("xieyan", "now provider status changed" + status); _</p>
<p>_ } _</p>
<p>_ }; _</p>
<p>_ _</p>
<p>_ private void updateGpsStatus(int event, GpsStatus status) { _</p>
<p>_ TextView slView = (TextView) findViewById(R.id.TextViewSatellites);
_</p>
<p>_ if (status == null) { _</p>
<p>_ slView.setText(getString(R.string.satellites) + "0"); _</p>
<p>_ } else if (event == GpsStatus.GPS_EVENT_SATELLITE_STATUS) { _</p>
<p>_ int maxSatellites = status.getMaxSatellites(); _</p>
<p>_ Iterator it = status.getSatellites().iterator(); _</p>
<p>_ int count = 0; _</p>
<p>_ while (it.hasNext() &amp;&amp; count &lt;= maxSatellites) { _</p>
<p>_ GpsSatellite s = it.next(); _</p>
<p>_ count++; _</p>
<p>_ } // _ _ 计算卫星个数，可在此打印出卫星的其它信息 _</p>
<p>_ slView.setText(getString(R.string.satellites) + count); _</p>
<p>_ } _</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ private void updateWithNewLocation(Location location) { _</p>
<p>_ if (location != null) { _</p>
<p>_ double lat = location.getLatitude(); _</p>
<p>_ double lng = location.getLongitude(); // _ _ 取经纬度 _</p>
<p>_ TextView latView = (TextView) findViewById(R.id.TextViewLng); _</p>
<p>_ TextView lngView = (TextView) findViewById(R.id.TextViewLat); _</p>
<p>_ latView.setText(getString(R.string.latitude) _</p>
<p>_ + String.format("%.5f", lat)); _</p>
<p>_ lngView.setText(getString(R.string.longitude) _</p>
<p>_ + String.format("%.5f", lng)); _</p>
<p>_ } else { _</p>
<p>_ TextView latView = (TextView) findViewById(R.id.TextViewLng); _</p>
<p>_ TextView lngView = (TextView) findViewById(R.id.TextViewLat); _</p>
<p>_ latView.setText(getString(R.string.getinfo_fail)); _</p>
<p>_ lngView.setText(""); _</p>
<p>_ } _</p>
<p>_ } _</p>
<p>_ } _</p>
<p>4. 辅助工具<br />
定位程序要么带地图很大，要么太简单不能得到足够数据。推荐 gpslogger<br />
，使用它可以看到当前的经纬度，速度，信号强度，当前搜到了几颗星（搜到小于三颗星时，定位不到经纬度），帮助进一步定位问题。<br />
<a
href="http://gpslogger.codeplex.com/">http://gpslogger.codeplex.com/</a>
可以下载到它的源码</p>
<p>5. 参考</p>
<ol type="a">
<li>gps 术语<br />
<a
href="http://www.mobile01.com/newsdetail.php?id=257">http://www.mobile01.com/newsdetail.php?id=257<br />
</a></li>
</ol>
<p>_ _</p>
<p>_ (转载请注明出处 <a
href="http://xy0811.spaces.live.com">http://xy0811.spaces.live.com</a>
)<br />
_</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android典型应用之访问网络</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8%E4%B9%8B%E8%AE%BF%E9%97%AE%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h1 id="android典型应用之访问网络">android典型应用之访问网络</h1>
<p>#移动开发 #android</p>
<p>1. android 网络<br />
android 访问网络需要设置权限， java 提供了很好的封装</p>
<p>2. 例程</p>
<ol type="1">
<li><p>功能<br />
从网上下载文本文件，并使用 textview 控件显示其内容</p></li>
<li><p>可从此处下载可独立运行的代码<br />
<a
href="http://download.csdn.net/source/2650779">http://download.csdn.net/source/2650779<br />
</a></p></li>
<li><p>权限<br />
在 AndroidManifest.xml 中需要加入访问网络的权限<br />
_ &lt; _ _ uses-permission _ _ android:name ="
android.permission.INTERNET" / &gt;<br />
_</p></li>
<li><p>核心代码及说明<br />
_ package com.android.mynet;</p></li>
</ol>
<p>import android.app.Activity;<br />
import android.os.Bundle;<br />
import java.io.<em>;<br />
import java.net.</em>;<br />
import org.apache.http.util.ByteArrayBuffer;<br />
import android.widget.TextView;<br />
_ _ import android.util.Log;</p>
<p>public class MyNetActivity extends Activity {<br />
<span class="citation" data-cites="Override">@Override</span><br />
public void onCreate(Bundle savedInstanceState) {<br />
super.onCreate(savedInstanceState);<br />
setContentView(R.layout.main);<br />
connect();<br />
}</p>
<p>public void connect()<br />
{<br />
String myString = null;<br />
try {<br />
URL myURL = new URL("http://www.google.com/robots.txt");<br />
URLConnection ucon = myURL.openConnection();<br />
InputStream is = ucon.getInputStream();<br />
BufferedInputStream bis = new BufferedInputStream(is);<br />
ByteArrayBuffer baf = new ByteArrayBuffer(50);<br />
int current = 0;<br />
while ((current = bis.read()) != -1) {<br />
baf.append((byte)current);<br />
}<br />
myString = new String(baf.toByteArray());<br />
} catch (Exception e) {<br />
myString = e.getMessage();<br />
}<br />
TextView tv;<br />
tv = (TextView) this.findViewById(R.id.tv1);<br />
tv.setText(myString);<br />
}<br />
} _</p>
<ol start="5" type="1">
<li>参考 :<br />
http://labs.chinamobile.com/mblog/103798_25897</li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android典型应用之语音合成</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8%E4%B9%8B%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90/</url>
    <content><![CDATA[<h1 id="android典型应用之语音合成">android典型应用之语音合成</h1>
<p>#移动开发 #android</p>
<p>1. android 语音合成介绍</p>
<ol type="1">
<li>语音合成引擎<br />
语音引擎是真正实现语音合成的程序，必须安装它，应用程序才能使用此功能</li>
</ol>
<ol type="a">
<li><p>pico 引擎<br />
android 2.0 之后，源码自带语音软件 pico ，其位置在
external/svox/pico*<br />
，它只支持英法西班牙等五六种文字，不包含中文支持</p></li>
<li><p>espeak 引擎<br />
如何需要支持中文，需要下载扩展支持 espeak, 下载 tts_3.0_rc05.apk(
在此下载： <a
href="http://code.google.com/p/eyes-%20free/downloads/detail?name=tts_3.0_rc05.apk&amp;can=2&amp;q"><br />
http://code.google.com/p/eyes-<br />
free/downloads/detail?name=tts_3.0_rc05.apk&amp;can=2&amp;q<br />
</a> )</p></li>
</ol>
<ol start="2" type="1">
<li><p>设置系统语音支持<br />
设置 -&gt; 语音输入输出 -&gt; 文字转语音设置<br />
选中使用我的设置 , 引擎选择 espeak, 默认引擎选择 espeak, 语言选择中文 ,
聆听示例</p></li>
<li><p>试用语音工具<br />
下读短信的工具<br />
<a
href="http://www.tigersw.cn/soft14228.html">http://www.tigersw.cn/soft14228.html<br />
</a><br />
安装后尝试其郎读短信的功能</p></li>
</ol>
<p>2. android 对 TTS 的支持<br />
应用程序调用接口<br />
frameworks/base/core/java/android/speech/tts/TextToSpeech.java</p>
<p>3. 例程</p>
<ol type="1">
<li><p>功能<br />
朗读编辑框中的文字</p></li>
<li><p>可从此处下载可独立运行的代码<br />
<a
href="http://download.csdn.net/source/2600900">http://download.csdn.net/source/2600900<br />
</a></p></li>
<li><p>核心代码及说明</p></li>
</ol>
<p>_ package com.android.mytts; _</p>
<p>_ _</p>
<p>_ import android.app.Activity; _</p>
<p>_ import android.os.Bundle; _</p>
<p>_ import android.speech.tts.TextToSpeech; _</p>
<p>_ import android.util.Log; _</p>
<p>_ import android.view.View; _</p>
<p>_ import android.widget.EditText; _</p>
<p>_ import android.widget.Button; _</p>
<p>_ import java.util.Locale; _</p>
<p>_ _</p>
<p>_ public class MyttsActivity extends Activity implements<br />
TextToSpeech.OnInitListener { _</p>
<p>_ private static final String TAG = "TextToSpeechDemo"; _</p>
<p>_ private TextToSpeech mTts; _</p>
<p>_ private Button mButton; _</p>
<p>_ _</p>
<p>_ <span class="citation" data-cites="Override">@Override</span> _</p>
<p>_ public void onCreate(Bundle savedInstanceState) { _</p>
<p>_ super.onCreate(savedInstanceState); _</p>
<p>_ setContentView(R.layout.main); _</p>
<p>_ mTts = new TextToSpeech(this, this/<em>listener</em>/); // _ _
初始化语音合成句柄 _</p>
<p>_ mButton = (Button) findViewById(R.id.again_button); _</p>
<p>_ _ _ mButton.setOnClickListener(new View.OnClickListener() { _</p>
<p>_ public void onClick(View v) { // _ _ 按钮按下时读编辑框中内容 _</p>
<p>_ EditText edit = (EditText) findViewById(R.id.EditText01); _</p>
<p>_ sayText(String.valueOf(edit.getText())); _</p>
<p>_ } _</p>
<p>_ }); _</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ <span class="citation" data-cites="Override">@Override</span> _</p>
<p>_ public void onDestroy() { _</p>
<p>_ if (mTts != null) { _</p>
<p>_ mTts.stop(); _</p>
<p>_ mTts.shutdown(); // _ _ 退出时一定要释放资源 _</p>
<p>_ } _</p>
<p>_ super.onDestroy(); _</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ public void onInit(int status) { _</p>
<p>_ if (status == TextToSpeech.SUCCESS) { _</p>
<p>_ int result = mTts.setLanguage(Locale.CHINA); // _ _
设置读中文（需安装 espeak ） _</p>
<p>_ // int result = mTts.setLanguage(Locale.US); // _ _ 设置读英文
_</p>
<p>_ if (result == TextToSpeech.LANG_MISSING_DATA || _</p>
<p>_ result == TextToSpeech.LANG_NOT_SUPPORTED) { _</p>
<p>_ Log.e(TAG, "Language is not available."); _</p>
<p>_ } else { _</p>
<p>_ mButton.setEnabled(true); // _ _ 系统支持所选语言时将按钮设为可用
_</p>
<p>_ } _</p>
<p>_ } else { _</p>
<p>_ Log.e(TAG, "Could not initialize TextToSpeech."); _</p>
<p>_ } _</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ private void sayText(String str) { _</p>
<p>_ mTts.speak(str, _</p>
<p>_ TextToSpeech.QUEUE_FLUSH, _</p>
<p>_ null); // _ _ 朗读 _</p>
<p>_ } _</p>
<p>_ } _ __</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android典型用户之多媒体播放</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E5%85%B8%E5%9E%8B%E7%94%A8%E6%88%B7%E4%B9%8B%E5%A4%9A%E5%AA%92%E4%BD%93%E6%92%AD%E6%94%BE/</url>
    <content><![CDATA[<h1 id="android典型用户之多媒体播放">android典型用户之多媒体播放</h1>
<p>#移动开发 #android</p>
<p>1. android 多媒体介绍<br />
android 的多媒体功能基于 PacketVideo 的 OpenCORE<br />
。这些库支持播放和录制许多流行的音频和视频格式，以及静态图像文件，包括
MPEG4 、 H.264 、 MP3 、 AAC 、 AMR<br />
、 JPG 、 PNG ，底级实现在源码的 external/opencore 中</p>
<p>2. android 框架对多媒体的支持<br />
应用程序调用接口<br />
frameworks/base/media/java/android/media/MediaPlayer.java</p>
<p>3. 例程</p>
<ol type="1">
<li><p>功能<br />
播放编辑框中指定的多媒体文件</p></li>
<li><p>可从此处下载可独立运行的代码<br />
<a
href="http://download.csdn.net/source/2602127">http://download.csdn.net/source/2602127<br />
</a></p></li>
<li><p>核心代码及说明<br />
</p></li>
</ol>
<pre><code>_ package com.android.mymedia;  _  
  
_ _  
  
_ import android.app.Activity;  _  
  
_ import android.os.Bundle;  _  
  
_ import android.widget.EditText;  _  
  
_ import android.widget.Button;  _  
  
_ import android.view.View.OnClickListener;  _  
  
_ import android.view.View;  _  
  
_ import android.media.MediaPlayer;  _  
  
_ import android.net.Uri;  _  
  
_ _  
  
_ public class MyMediaActivity extends Activity &#123;  _  
  
_ private Button mPlayBtn;  _  
  
_ private Button mStopBtn;  _  
  
_ private EditText mEditText;  _  
  
_ private MediaPlayer mMediaPlayer;  _  
  
_ _  
  
_ @Override  _  
  
_ public void onCreate(Bundle savedInstanceState) &#123;  _  
  
_ super.onCreate(savedInstanceState);  _  
  
_ setContentView(R.layout.main);  _  
  
_ mPlayBtn = (Button) this.findViewById(R.id.play_button);  _  
  
_ mStopBtn = (Button) this.findViewById(R.id.stop_button);  _  
  
_ mEditText = (EditText) this.findViewById(R.id.edit_text);  _  
  
_ _ _ mPlayBtn.setOnClickListener(buttonListener);  _  
  
_ mStopBtn.setOnClickListener(buttonListener);  _  
  
_ _ _ mEditText.setText(&quot;/sdcard/test.mp3&quot;);  _  
  
_ &#125;  _  
  
_ _  
  
_ @Override  _  
  
_ public void onDestroy() &#123;  _  
  
_ stopMedia();  _  
  
_ super.onDestroy();  _  
  
_ &#125;  _  
  
_ _  
  
_ private OnClickListener buttonListener = new OnClickListener() &#123;  _  
  
_ public void onClick(View v) &#123;  _  
  
_ if (mPlayBtn.equals(v)) &#123;  _  
  
_ playMedia();  _  
  
_ &#125; else if (mStopBtn.equals(v)) &#123;  _  
  
_ stopMedia();  _  
  
_ &#125;  _  
  
_ &#125;  _  
  
_ &#125;;  _  
  
_ _  
  
_ private void playMedia() &#123;  _  
  
_ stopMedia();  _  
  
_ Uri playUri = Uri.parse(String.valueOf(mEditText.getText()));  _  
  
_ mMediaPlayer = MediaPlayer.create(this, playUri);  _  
  
_ mMediaPlayer.start();  _  
  
_ &#125;  _  
  
_ _  
  
_ private void stopMedia() &#123;  _  
  
_ if (mMediaPlayer != null) &#123;  _  
  
_ if (mMediaPlayer.isPlaying())  _  
  
_ mMediaPlayer.stop();  _  
  
_ mMediaPlayer.release();  _  
  
_ mMediaPlayer = null;  _  
  
_ &#125;  _  
  
_ &#125;  _  
  
_ &#125;  _  </code></pre>
<p>4. 参考 :</p>
<ol type="1">
<li><p>Android 源码自带的多媒体播放例程<br />
development/samples/ApiDemos/src/ocm/example/android/apis/media/MediaPlayerDemo*</p></li>
<li><p>流媒体例程<br />
<a
href="http://kuikui.javaeye.com/blog/325916">http://kuikui.javaeye.com/blog/325916<br />
</a></p></li>
</ol>
<p>(转载请注明出处: <a
href="http://xy0811.spaces.live.com">http://xy0811.spaces.live.com</a>
)</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android对文件的MD5验证</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E5%AF%B9%E6%96%87%E4%BB%B6%E7%9A%84MD5%E9%AA%8C%E8%AF%81/</url>
    <content><![CDATA[<h1 id="android对文件的md5验证">android对文件的MD5验证</h1>
<p>#移动开发 #android</p>
<p>1. 说明<br />
android 自带的 MD5 校验类</p>
<p>2. 例程</p>
<ol type="1">
<li><p>功能<br />
对文件 /init.rc 做 MD5 计算，并以字串的方式显示</p></li>
<li><p>可从此处下载可独立运行的代码<br />
<a
href="http://download.csdn.net/source/2660824">http://download.csdn.net/source/2660824<br />
</a></p></li>
<li><p>使用 linux 命令得到 MD5 值<br />
** $ md5sum init.rc **</p></li>
<li><p>核心代码及说明<br />
** import java.security.MessageDigest;<br />
import java.io.FileInputStream;<br />
import java.io.InputStream;</p></li>
</ol>
<p>public class MD5 {<br />
private static final char HEX_DIGITS[] = { '0', '1', '2', '3', '4', '5',
'6',<br />
'7', '8', '9',<br />
'A', 'B', 'C', 'D', 'E', 'F' };</p>
<p>public static void main(String[] args)<br />
{<br />
System.out.println(md5sum("/init.rc"));<br />
}</p>
<p>public static String toHexString(byte[] b) {<br />
StringBuilder sb = new StringBuilder(b.length * 2);<br />
for (int i = 0; i &lt; b.length; i++) {<br />
sb.append(HEX_DIGITS[(b[i] &amp; 0xf0) &gt;&gt;&gt; 4]);<br />
sb.append(HEX_DIGITS[b[i] &amp; 0x0f]);<br />
}<br />
return sb.toString();<br />
}</p>
<p>public static String md5sum(String filename) {<br />
InputStream fis;<br />
byte[] buffer = new byte[1024];<br />
int numRead = 0;<br />
MessageDigest md5;<br />
try{<br />
fis = new FileInputStream(filename);<br />
md5 = MessageDigest.getInstance("MD5");<br />
while((numRead=fis.read(buffer)) &gt; 0) {<br />
md5.update(buffer,0,numRead);<br />
}<br />
fis.close();<br />
return toHexString(md5.digest());<br />
} catch (Exception e) {<br />
System.out.println("error");<br />
return null;<br />
}<br />
}<br />
} **</p>
<hr />
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android应用程序的签名(Signature)</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%9A%84%E7%AD%BE%E5%90%8D(Signature)/</url>
    <content><![CDATA[<h1
id="android应用程序的签名signature">android应用程序的签名(Signature)</h1>
<p>#移动开发 #android</p>
<h3 id="为什么要签名">1. 为什么要签名</h3>
<ol type="1">
<li><p>发送者的身份认证<br />
由于开发商可能通过使用相同的 Package Name
来混淆替换已经安装的程序，以此保证签名不同的包不被替换</p></li>
<li><p>保证信息传输的完整性<br />
签名对于包中的每个文件进行处理，以此确保包中内容不被替换</p></li>
<li><p>防止交易中的抵赖发生， Market 对软件的要求</p></li>
</ol>
<p>2. 签名的说明</p>
<ol type="1">
<li><p>所有的应用程序都必须有数字证书， Android
系统不会安装一个没有数字证书的应用程序</p></li>
<li><p>Android
程序包使用的数字证书可以是自签名的，不需要一个权威的数字证书机构签名认证</p></li>
<li><p>如果要正式发布一个 Android
应用，必须使用一个合适的私钥生成的数字证书来给程序签名，而不能使用 adt
插件或者 ant<br />
工具生成的调试证书来发布</p></li>
<li><p>数字证书都是有有效期的， Android<br />
只是在应用程序安装的时候才会检查证书的有效期。如果程序已经安装在系统中，即使证书过期也不会影响程序的正常功能</p></li>
<li><p>签名后需使用 zipalign 优化程序</p></li>
<li><p>Android
将数字证书用来标识应用程序的作者和在应用程序之间建立信任关系，而不是用来决定最终用户可以安装哪些应用程序</p></li>
</ol>
<p>3. 签名的方法</p>
<ol type="1">
<li>用 eclipse 插件方式签名</li>
</ol>
<ol type="a">
<li><p>调试签名<br />
eclipse 插件默认赋予程序一个 DEBUG 权限的签名，此签名的程序不能发布到
market<br />
上，此签名有效期为一年，如果过期则导致你无法生成 apk
文件，此时你只要删除 debug keystore<br />
即可，系统又会为你生成有效期为一年的新签名</p></li>
<li><p>开发者生成密钥并签名<br />
右键点击项目名，在菜单中选择 Android Tools ，然后选择 Export Signed
Application Package…<br />
，即可通过 eclipse 自定义证书并签名</p></li>
<li><p>开发者导出未签名的包<br />
右键点击项目名，在菜单中选择 Android Tools ，然后选择 Export Signed
Application Package…<br />
，即可导出未签名的包，之后可通过命令行方式签名</p></li>
</ol>
<ol start="2" type="1">
<li>用命令行方式签名<br />
使用标准的 java 工具 keytool 和 jarsigner 来生成证书和给程序签名</li>
</ol>
<ol type="a">
<li><p>生成签名<br />
_ $ keytool -genkey -keystore keyfile -keyalg RSA -validity 10000 -alias
yan<br />
_<br />
注： validity 为天数， keyfile 为生成 key 存放的文件， yan 为私钥， RSA
为指定的加密算法 ( 可用<br />
RSA 或 DSA)</p></li>
<li><p>为 apk 文件签名<br />
_ $ jarsigner -verbose -keystore keyfile -signedjar signed.apk base.apk
yan _<br />
注： keyfile 为生成 key 存放的文件， signed.apk 为签名后的 apk ，
base.apk 为未签名的 apk<br />
， yan 为私钥</p></li>
<li><p>看某个 apk 是否经过了签名<br />
_ $ jarsigner -verify my_application.apk _</p></li>
<li><p>优化（签名后需要做对齐优化处理）<br />
_ $ zipalign -v 4 your_project_name-unaligned.apk your_project_name.apk
_</p></li>
</ol>
<ol start="3" type="1">
<li>在源码中编译的签名</li>
</ol>
<ol type="a">
<li><p>使用源码中的默认签名<br />
在源码中编译一般都使用默认签名的，在某源码目录中用运行<br />
_ $ mm showcommands _ 能看到签名命令<br />
Android 提供了签名的程序 signapk.jar ，用法如下：<br />
_ $ signapk publickey.x509[.pem] privatekey.pk8 input.jar output.jar
_<br />
*.x509.pem 为 x509 格式公钥， pk8 为私钥<br />
build/target/product/security 目录中有四组默认签名可选： testkey,
platform, shared, media<br />
（具体见 README.txt ），应用程序中 Android.mk 中有一个 LOCAL_CERTIFICATE
字段，由它指定用哪个<br />
key 签名，未指定的默认用 testkey.</p></li>
<li><p>在源码中自签名<br />
Android 提供了一个脚本 mkkey.sh （
build/target/product/security/mkkey.sh<br />
），用于生成密钥，生成后在应用程序中通过 Android.mk 中的
LOCAL_CERTIFICATE 字段指名用哪个签名</p></li>
<li><p>mkkey.sh 介绍</p></li>
</ol>
<ol type="i">
<li><p>生成公钥<br />
_ openssl genrsa -3 -out testkey.pem 2048 _<br />
其中 -3 是算法的参数， 2048 是密钥长度， testkey.pem
是输出的文件</p></li>
<li><p>转成 x509 格式（含作者有效期等）<br />
_ openssl req -new -x509 -key testkey.pem -out testkey.x509.pem -days
10000<br />
-subj ‘/C=US/ST=California/L=Mountain <a
href="mailto:View/O=Android/OU=Android/CN=Android/emailAddress=android@android.com"><br />
View/O=Android/OU=Android/CN=Android/emailAddress=android@android.com<br />
</a><br />
’ _</p></li>
<li><p>生成私钥<br />
_ openssl pkcs8 -in testkey.pem -topk8 -outform DER -out testkey.pk8
-nocrypt<br />
_<br />
把的格式转换成 PKCS #8 ，这里指定了 -nocryp
，表示不加密，所以签名时不用输入密码</p></li>
</ol>
<p>4. 签名的相关文件</p>
<ol type="1">
<li><p>apk 包中签名相关的文件在 META_INF 目录下<br />
CERT.SF ：生成每个文件相对的密钥<br />
MANIFEST.MF ：数字签名信息<br />
xxx.SF ：这是 JAR 文件的签名文件，占位符 xxx 标识了签名者<br />
xxx.DSA ：对输出文件的签名和公钥</p></li>
<li><p>相关源码<br />
development/tools/jarutils/src/com.anroid.jarutils/SignedJarBuilder.java<br />
frameworks/base/services/java/com/android/server/PackageManagerService.java<br />
frameworks/base/core/java/android/content/pm/PackageManager.java<br />
frameworks/base/cmds/pm/src/com/android/commands/pm/Pm.java<br />
dalvik/libcore/security/src/main/java/java/security/Sign*<br />
build/target/product/security/platform.*<br />
build/tools/signapk/*</p></li>
</ol>
<p>5. 签名的相关问题<br />
一般在安装时提示出错：
INSTALL_PARSE_FAILED_INCONSISTENT_CERTIFICATES</p>
<ol type="1">
<li><p>两个应用，名字相同，签名不同</p></li>
<li><p>升级时前一版本签名，后一版本没签名</p></li>
<li><p>升级时前一版本为 DEBUG 签名，后一个为自定义签名</p></li>
<li><p>升级时前一版本为 Android 源码中的签名，后一个为 DEBUG
签名或自定义签名</p></li>
<li><p>安装未签名的程序</p></li>
<li><p>安装升级已过有效期的程序</p></li>
</ol>
<p>6. 相关工具</p>
<ol type="1">
<li>查看某个 x509 证书的的有效日期<br />
在 SignApk.java 中打印出 publicKey.getNotAfter() 即可</li>
</ol>
<p>7. 参考<br />
<a
href="http://developer.android.com/guide/publishing/app-signing.html">http://developer.android.com/guide/publishing/app-signing.html<br />
</a><br />
<a
href="http://www.pgcw.com.cn/Newsdetail.asp?id=257565010">http://www.pgcw.com.cn/Newsdetail.asp?id=257565010<br />
</a><br />
<a
href="http://www.eoeandroid.com/thread-23010-1-1.html">http://www.eoeandroid.com/thread-23010-1-1.html<br />
</a><br />
<a
href="http://pepa.javaeye.com/blog/250991">http://pepa.javaeye.com/blog/250991</a></p>
<p>( 转载请注明作者及出处 <a
href="http://xy0811.spaces.live.com/">http://xy0811.spaces.live.com<br />
</a> )</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android文件管理器的源码实现</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%99%A8%E7%9A%84%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="android文件管理器的源码实现">android文件管理器的源码实现</h1>
<p>#移动开发 #android</p>
<p><em>转载请注明作者及出处:<a
href="http://blog.csdn.net/xieyan0811">http://blog.csdn.net/xieyan0811<br />
</a> </em></p>
<p>1. android文件管理器介绍<br />
android系统并不自带文件管理器，但是很多情况下，我们有诸如从SD中打开文件的需要，就必须借助三方开发的资源管理器，常用的有AndExplorer等。这种情况下发布后，用户还需要安装依赖的软件，非常麻烦。下面介绍在代码中实现资源管理器，只需要一百行左右的一个类即可以最常用的文件选择功能。</p>
<p>2. 相关知识<br />
文件管理器一般以固定大小的对话框的方式出现，使用ListView作为文件目录的显示载体。点选目录测进入，点选文件则将所选择文件的Uri返回给调用它的Activity。ListView的使用是实现这个功能的重点。</p>
<p>3. 例程</p>
<ol type="1">
<li><p>功能<br />
当用户点击按钮时，调出固定大小的文件管理器，默认显示的目录是SD卡的根目录。用户选择文件后，在界面上显示该文件的路径。</p></li>
<li><p>可从此处下载可独立运行的代码<br />
<a
href="http://download.csdn.net/source/3423094">http://download.csdn.net/source/3423094<br />
</a></p></li>
<li><p>核心代码及说明</p></li>
</ol>
<ol type="a">
<li><p>调用资源管理器<br />
<em>Intent intent = new Intent();<br />
intent.putExtra("explorer_title",<br />
getString(R.string.dialog_read_from_dir)); // 设置文件管理器标题<br />
intent.setDataAndType(Uri.fromFile(new File("/sdcard")), "<em>/</em>");
//<br />
设置起始文件夹和文件类型<br />
intent.setClass(MyActivity.this, ExDialog.class);<br />
startActivityForResult(intent, REQUEST_EX); </em></p></li>
<li><p>从资源管理器接收数据<br />
<em>protected void onActivityResult(int requestCode, int
resultCode,<br />
Intent intent) {<br />
String path;<br />
if (resultCode == RESULT_OK) {<br />
if (requestCode == REQUEST_EX) {<br />
Uri uri = intent.getData(); // 接收用户所选文件的路径<br />
TextView text = (TextView) findViewById(R.id.text);<br />
text.setText("select: " + uri); // 在界面上显示路径<br />
}<br />
}<br />
} </em></p></li>
<li><p>文件管理器类的实现<br />
_public class ExDialog extends ListActivity { //
ListActivity自带List控件<br />
private List &lt;Map&lt;String, Object&gt;&gt; mData;<br />
private String mDir = "/sdcard";</p></li>
</ol>
<p><span class="citation" data-cites="Override">@Override</span><br />
protected void onCreate(Bundle savedInstanceState) {<br />
super.onCreate(savedInstanceState);</p>
<p>Intent intent = this.getIntent();<br />
Bundle bl = intent.getExtras();<br />
String title = bl.getString("explorer_title"); // 接收标题内容<br />
Uri uri = intent.getData(); // 接收起始目录<br />
mDir = uri.getPath(); // 设置起始目录<br />
setTitle(title);</p>
<p>mData = getData(); // 向链表mData填充目录的数据<br />
MyAdapter adapter = new MyAdapter(this);<br />
setListAdapter(adapter); // 设置MyAdapter类为ListView控件提供数据</p>
<p>WindowManager m = getWindowManager();<br />
Display d = m.getDefaultDisplay();<br />
LayoutParams p = getWindow().getAttributes();<br />
p.height = (int) (d.getHeight() * 0.8);<br />
p.width = (int) (d.getWidth() * 0.95);<br />
getWindow().setAttributes(p); //
设置对话框为固定大小，不因进出目录变化<br />
}</p>
<p>private List&lt;Map&lt;String, Object&gt;&gt; getData() { //
将目录数据填充到链表中<br />
List&lt;Map&lt;String, Object&gt;&gt; list = new
ArrayList&lt;Map&lt;String, Object&gt;&gt;();<br />
Map&lt;String, Object&gt; map = null;<br />
File f = new File(mDir); // 打开当前目录<br />
File[] files = f.listFiles(); // 获取当前目录中文件列表</p>
<p>if (!mDir.equals("/sdcard")) { // 不充许进入/sdcard上层目录<br />
map = new HashMap&lt;String, Object&gt;(); // 加返回上层目录项<br />
map.put("title", "Back to ../");<br />
map.put("info", f.getParent());<br />
map.put("img", R.drawable.ex_folder);<br />
list.add(map);<br />
}<br />
if (files != null) { // 将目录中文件填加到列表中<br />
for (int i = 0; i &lt; files.length; i++) {<br />
map = new HashMap&lt;String, Object&gt;();<br />
map.put("title", files[i].getName());<br />
map.put("info", files[i].getPath());<br />
if (files[i].isDirectory()) // 按不同类型显示不同图标<br />
map.put("img", R.drawable.ex_folder);<br />
else<br />
map.put("img", R.drawable.ex_doc);<br />
list.add(map);<br />
}<br />
}<br />
return list;<br />
}</p>
<p>// 响应用户点击列表项的事件<br />
<span class="citation" data-cites="Override">@Override</span><br />
protected void onListItemClick(ListView l, View v, int position, long
id) {<br />
Log.d("MyListView4-click", (String)
mData.get(position).get("info"));<br />
if ((Integer) mData.get(position).get("img") == R.drawable.ex_folder)
{<br />
mDir = (String) mData.get(position).get("info");<br />
mData = getData(); //点击目录时进入子目录<br />
MyAdapter adapter = new MyAdapter(this);<br />
setListAdapter(adapter);<br />
} else { // 点击文件时关闭文件管理器，并将选取结果返回<br />
finishWithResult((String) mData.get(position).get("info"));<br />
}<br />
}</p>
<p>public final class ViewHolder { // 定义每个列表项所含内容<br />
public ImageView img; // 显示图片ID<br />
public TextView title; // 文件目录名<br />
public TextView info; // 文件目录描述<br />
}</p>
<p>public class MyAdapter extends BaseAdapter { //
实现列表内容适配器<br />
private LayoutInflater mInflater;</p>
<p>public MyAdapter(Context context) {<br />
this.mInflater = LayoutInflater.from(context);<br />
}</p>
<p>public int getCount() { // 获取列表项个数<br />
return mData.size();<br />
}</p>
<p>public Object getItem(int arg0) {<br />
return null;<br />
}</p>
<p>public long getItemId(int arg0) {<br />
return 0;<br />
}</p>
<p>// 设置每个列表项的显示<br />
public View getView(int position, View convertView, ViewGroup parent)
{<br />
ViewHolder holder = null;<br />
if (convertView == null) {<br />
holder = new ViewHolder();<br />
convertView = mInflater.inflate(R.layout.listview, null); //
设置列表项的布局<br />
holder.img = (ImageView) convertView.findViewById(R.id.img);<br />
holder.title = (TextView) convertView.findViewById(R.id.title);<br />
holder.info = (TextView) convertView.findViewById(R.id.info);<br />
convertView.setTag(holder);<br />
} else {<br />
holder = (ViewHolder) convertView.getTag();<br />
}<br />
holder.img.setBackgroundResource((Integer) Data.get(position).get(<br />
"img")); // 根据位置position设置具体内容<br />
holder.title.setText((String) Data.get(position).get("title"));<br />
holder.info.setText((String) mData.get(position).get("info"));<br />
return convertView;<br />
}<br />
}</p>
<p>private void finishWithResult(String path) {<br />
Bundle conData = new Bundle();<br />
conData.putString("results", "Thanks Thanks");<br />
Intent intent = new Intent(); // 以intent的方式将结果返回调用类<br />
intent.putExtras(conData);<br />
Uri startDir = Uri.fromFile(new File(path));<br />
intent.setDataAndType(startDir,<br />
"vnd.android.cursor.dir/lysesoft.andexplorer.file");<br />
setResult(RESULT_OK, intent);<br />
finish();<br />
}<br />
}; _</p>
<p><em>转载请注明作者及出处:<a
href="http://blog.csdn.net/xieyan0811">http://blog.csdn.net/xieyan0811<br />
</a> </em></p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android有声电子书新版本1.61发布</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E6%9C%89%E5%A3%B0%E7%94%B5%E5%AD%90%E4%B9%A6%E6%96%B0%E7%89%88%E6%9C%AC1.61%E5%8F%91%E5%B8%83/</url>
    <content><![CDATA[<h1
id="android有声电子书新版本1.61发布">android有声电子书新版本1.61发布</h1>
<p>#移动开发 #android</p>
<p>有声电子书 ( 适用于Android 1.5 及以上版本)</p>
<p>软件支持格式为txt, umd, jpg文字及漫画书的阅读,<br />
提供用户搜索SD卡中所有图书。特别加入了文本直接转换成语音的有声阅读功能。用听书的方式解放您的眼睛。</p>
<p><em>支持TXT, UMD, JPG 格式的文本及漫画的阅读。<br />
</em>支持文本转换成语音朗读，内置中文语音合成引擎(含男/女声,
速度可调)，也支持系统自带语音。<br />
<em>提供嫂索SD卡中图书的功能。<br />
</em>支持UTF8, GBK, UNICODE等多种文本编码格式及超大文件。<br />
<em>自动保存进度，提供书签，书架功能，支持章节。<br />
</em>可调节亮度,字体大小,背景等多种显示模式。</p>
<p><img
src="http://hi.csdn.net/attachment/201201/19/0_1326959824jzzv.gif" /><br />
<img
src="http://hi.csdn.net/attachment/201201/19/0_1326959847Nhhm.gif" /><br />
<img
src="http://hi.csdn.net/attachment/201201/19/0_1326959855lZfz.gif" /></p>
<p>版本号: 1.61</p>
<p>发布日期: 2012-01-11</p>
<p>修改内容:</p>
<p>1. 加入对英文字母读音的支持<br />
2. 加入了图书文件的容错处理<br />
3. 优化朗读韵律(音长及音调)<br />
4. 化化了数字的阅读<br />
5. 默认安装到SD卡, 以节约手机内存<br />
6. 修改程序bug及部分词汇的</p>
<p>介绍视频详见: <a
href="http://xieyan0811.7ta.cn/Movie/2503971/83892/">http://xieyan0811.7ta.cn/Movie/2503971/83892/<br />
</a></p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android的KeyGuard</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E7%9A%84KeyGuard/</url>
    <content><![CDATA[<h1 id="android的keyguard">android的KeyGuard</h1>
<p>#移动开发 #android</p>
<p>1. 什么是 keyguard<br />
keyguard 译为键盘守卫 , 用于保护手机 , 包含锁屏 , 图案解锁等</p>
<p>2. 核心代码<br />
frameworks/policies/base/phone/com/android/internal/policy/impl/*</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android的intent使用方法</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E7%9A%84intent%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="android的intent使用方法">android的intent使用方法</h1>
<p>#移动开发 #android</p>
<p>android 的 intent 使用方法</p>
<p>1. 说明<br />
Android 中提供了 Intent
机制来协助应用间或者应用程序内部的交互与通讯。<br />
Intent 的两种基本用法：一种是显式的 Intent ，即在构造 Intent<br />
对象时就指定接收者，这种方式与普通的函数调用类似；另一种是隐式的 Intent
，即 Intent 的发送者在构造 Intent<br />
对象时，并不知道接收者是谁，只是指出接收者的一些特性（比如说启动音乐播放软件）</p>
<p>2. 使用方法</p>
<ol type="1">
<li>启动服务</li>
</ol>
<ol type="a">
<li><p>关键函数<br />
context.startService() 或 context.bindService()</p></li>
<li><p>示例<br />
** Intent i = new Intent(this, MyTestService.class);<br />
this.startService(i); // ** ** 启动 ** ** service **</p></li>
</ol>
<ol start="2" type="1">
<li>发送广播</li>
</ol>
<ol type="a">
<li><p>关键函数<br />
context.sendBroadcast()</p></li>
<li><p>发送方<br />
** String msg = “test”;<br />
Intent i = new Intent(“com.test.bc”);<br />
i.pubExtra(“msg”, msg);<br />
this.sendBroadcase(i); **</p></li>
<li><p>接收方<br />
** IntentFilter intentFilter = new IntentFilter();<br />
intentFilter.addAction(Intent.ACTION_MEDIA_EJECT);<br />
registerReceiver(mReceiver.interFilter); **</p></li>
</ol>
<ol start="3" type="1">
<li>启动应用程序</li>
</ol>
<ol type="a">
<li><p>关键函数<br />
context.startActivity()</p></li>
<li><p>示例<br />
** Intent intent =<br />
new Intent(“com.android.browser“,
“com.android.browser.BrowserActivity“);<br />
startActivity(intent); **</p></li>
</ol>
<p>3. Intent 的组成<br />
Intent 的参数可多可少 ，系统
根据不同的参数组合过滤出一个或多个适合规则的界面</p>
<ol type="1">
<li><p>调用方 ： 以下几个规则可以同时指定 ，
也可以指定一部分或几部分<br />
Component ： 指定包名类名来调用 ( 见上例 ) ，它是
晚绑定，不会在编译时报错<br />
Action ：指定做什么的规则 ( 比如 ACTION_DIAL 指定拨号类型应用 ) ，
以供过滤<br />
Data ： 提供的重要数据 ， 通常是 Uri ， 同时也提供数据的类型 ，
以供过滤<br />
Type ：用于指定类型，以供过滤 ( 比如 ACTION_VIEW 同时指定为 Type 为
Image ，则调出浏览图片的应用 )<br />
Category ： 指定范围<br />
Extras ：通过 Bundle 类传参 , 数据多 ，数据量大时用它传<br />
Flags ： 标志位 ( 比如 FLAG_ACTIVITY_NEW_TASK 指定新开一个任务
)</p></li>
<li><p>被调用方<br />
在 AndroidManifest.xml 中的 <intent-filter> 中声明规则<br />
例如 : 一般程序都需要在 inter-filter 中加入
android.intent.category.LAUNCHER 的声明 ,<br />
以便被程序启动器 (Launcher) 识别 , 即以点击图标的方式供用户运行</p></li>
<li><p>示例<br />
** Intent intent = new Intent();<br />
intent.setClassName(“com.android.browser“,<br />
“com.android.browser.BrowserActivity“); // ** ** 打开浏览器 ** **<br />
Uri data = Uri.parse(“http://www.google.com“);<br />
intent.setData(data); // ** ** 打开某网页 ** **<br />
intent.addFlag(Intent.FLAG_ACTIVITY_NEW_TASK); // ** **
以新建任务方式打开 ** **<br />
intent.setAction(Intent.ACTION_VIEW); // ** ** 以浏览方式打开 **
**<br />
startActivity(intent); **</p></li>
</ol>
<p>4. Intent 的源码实现</p>
<ol type="1">
<li><p>Intent 解析，过滤规则对应出具体应用<br />
frameworks/base/core/java/android/content/IntentFilter.java</p></li>
<li><p>Intent 定义，规定程序中的使用的 Define 与 xml
中字串的对应关系<br />
frameworks/base/core/java/android/content/Intent.java</p></li>
</ol>
<p>5. 参考<br />
<a
href="http://zhubin215130.javaeye.com/blog/614913">http://zhubin215130.javaeye.com/blog/614913<br />
</a></p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android的图像识别</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E7%9A%84%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/</url>
    <content><![CDATA[<h1 id="android的图像识别">android的图像识别</h1>
<p>#移动开发 #android</p>
<p>1. 什么是 opencv<br />
简单的说这是基于图像动态捕捉处理、人脸识别、机器人视觉处理、图像信息认知录入等多为一体计算机视觉库</p>
<p>2. 安装</p>
<ol type="1">
<li><p>下载 ndk<br />
<a
href="http://bbs.weiphone.com/read-htm-tid-521406.html">http://bbs.weiphone.com/read-htm-tid-521406.html<br />
</a></p></li>
<li><p>安装 ndk</p></li>
</ol>
<p>_ $ tar xvjf OpenCV-2.1.0.tar.bz2<br />
$ cd android-ndk-1.6_r1<br />
$ export NDKROOT=<code>pwd</code><br />
$ ./build/host-setup.sh _</p>
<ol start="3" type="1">
<li><p>下载 opencv<br />
<a
href="http://github.com/billmccord/OpenCV-Android/downloads">http://github.com/billmccord/OpenCV-Android/downloads<br />
</a></p></li>
<li><p>编译 opencv</p></li>
</ol>
<p>_ $ tar xvzf bill*<br />
$ cd app<br />
$ ln -s bill* opencv<br />
$ make APP=opencv _</p>
<ol start="5" type="1">
<li>安装 opencv</li>
</ol>
<p>_ $ adb push out/apps/opencv/libopencv.so /system/lib/ _</p>
<p>3. 基于 opencv 的程序</p>
<ol type="1">
<li><p>下载的 opencv 源码中 tests
目录下是几个例程，可以编译运行</p></li>
<li><p>想使用 opencv 更多功能，除需要界面程序外，还需增加 JNI
接口</p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android的文字识别OCR</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E7%9A%84%E6%96%87%E5%AD%97%E8%AF%86%E5%88%ABOCR/</url>
    <content><![CDATA[<h1 id="android的文字识别ocr">android的文字识别OCR</h1>
<p>#移动开发 #android</p>
<p>1. 功能：<br />
光学字符识别 (OCR,Optical Character Recognition)<br />
是指对文本资料进行扫描，然后对图像文件进行分析处理，获取文字及版面信息的过程</p>
<p>2. 典型应用：<br />
名片扫描</p>
<p>3. android 源码实现：<br />
external/tesseract/*</p>
<p>4. 编译：<br />
_ $ cd external/tesseract/<br />
$ mm _<br />
生成 libocr.so ， push 系统 /system/lib/
中，它也可以放在软件的安装包里</p>
<p>5. 例程下载：</p>
<ol type="1">
<li><p>在此下载<br />
<a
href="http://code.google.com/p/mezzofanti/">http://code.google.com/p/mezzofanti/<br />
</a></p></li>
<li><p>直接下载 apk 是能用的 , 在源码中编译程序运行就退出，是由于可能
libocr.so 未安装 , 把它 push<br />
到系统中即可<br />
_ $ adb push libocr.so /data/data/com.itwizard.mezzofanti/lib/
_</p></li>
<li><p>主要借鉴 OCR.java 它是对 libocr.so 库的调用（ JNI 方式）</p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android的测试工具CTS</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E7%9A%84%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7CTS/</url>
    <content><![CDATA[<h1 id="android的测试工具cts">android的测试工具CTS</h1>
<p>#移动开发 #android</p>
<p>1. 什么是 CTS<br />
兼容性测试，手机设备需要通过 Android 的兼容性测试 (CTS) ，以确保在
android 上开发的程序在手机设备上都能运行，才能使用<br />
android market</p>
<p>2. 下载及安装<br />
git 下载的源码里包含 cts ，位置在 $ANDROID/cts 目录下（ android2.1
以后版本）<br />
如果没有也可以从此处下载 git://android.git.kernel.org/platform/cts.git
（源码 70M 左右）<br />
编译<br />
<strong>_ $ build/envsetup.sh<br />
$ make cts _ </strong><br />
此时生成测试计划，测试包，测试用例，和测试报告生成的目录</p>
<p>3. 使用</p>
<ol type="a">
<li><p>方法１：一般使用的方法<br />
<strong>_ $ cts _ </strong> <strong>_ 注意如果用手机设备调试，用 _
</strong> <strong>_ root _ </strong> <strong>_ 权限执行 _ </strong>
<strong>_<br />
cts_host &gt; ls --plan _ </strong> <strong>_ 列出所有 _ </strong>
<strong>_ plan<br />
_ </strong> out/host/linux-x86/cts/android-cts/repository/plans 中有
plan 的具体内容 <strong>_<br />
cts_host &gt; start --plan VM _ </strong> <strong>_ 运行某个 _ </strong>
<strong>_ plan<br />
_ </strong> 测试结果在
out/host/linux-x86/cts/android-cts/repository/results<br />
目录下，用浏览器看时间目录下的 xml 文件即可<br />
注意在改动 cts 后，还要 make cts 重新编译，若只在 cts
目录中编译不能生效<br />
<strong>_ cts_host &gt; ls -p _ </strong> <strong>_ 看当前可用的用例包 _
</strong> <strong>_<br />
cts_host &gt; start --plan Android -p android.app _ </strong> <strong>_
只运行某个用例包，节约时间 _ </strong><br />
<strong>_<br />
cts_host &gt; start --plan Android -p android.app -t<br />
android.app.cts.AlertDialogTest#testAlertDialog _ </strong><br />
<strong>_ 只运行某个用例包中的某个用例 _ </strong></p></li>
<li><p>方法 2 ：遇到问题时方便调试的方法<br />
<strong>_ $ adb install
out/target/product/xxxx/data/app/SginatureTest.apk _ </strong>
<strong>_<br />
安装某个用例包 _ </strong> <strong>_<br />
$ adb shell pm list instrumentation pm _ </strong> <strong>_ 用于管理 _
</strong> <strong>_ package _ </strong><br />
<strong>_ ，看当前机器安装了什么用例 _ </strong> <strong>_<br />
$ adb shell am instrument -w
android.tests.sigtest/.InstrumentationRunner am<br />
_ </strong> <strong>_ 用于管理 _ </strong> <strong>_ activity _
</strong> <strong>_ 运行某一用例 _ </strong> <strong>_<br />
$ adb shell am instrument -e class<br />
android.app.cts.AlertDialogTest#testAlertDialog -w<br />
com.android.cts.app/android.test/InstrumentationCtsTestRunner _
</strong> <strong>_<br />
单独运行一个小 _ </strong> <strong>_ case _ </strong><br />
如果在一个时间很长的 plan （如 Android
）中，某处错了，而错误信息又不全，需要单独跑一个小 case ，用 -e
指明<br />
class 明就可以节约很多时间</p></li>
</ol>
<p>4. 说明</p>
<ol type="a">
<li><p>bin/cts 是一个脚本，它使用 adb 来测试，测试程序及测试用例由 java
语言编写</p></li>
<li><p>cts 主函数为
cts/tools/host/src/com/android/cts/TestHost.java</p></li>
</ol>
<p>5. 参考<br />
<a
href="http://www.kandroid.org/android_pdk/instrumentation_testing.html">http://www.kandroid.org/android_pdk/instrumentation_testing.html<br />
</a></p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android的调试工具集</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E7%9A%84%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7%E9%9B%86/</url>
    <content><![CDATA[<h1 id="android的调试工具集">android的调试工具集</h1>
<p>#移动开发 #android</p>
<p>1. 查看当前堆栈</p>
<ol type="1">
<li><p>功能：在程序中加入代码，使可以在 logcat
中看到打印出的当前函数调用关系</p></li>
<li><p>方法：<br />
</p></li>
</ol>
<pre><code>new Exception(“print trace”).printStackTrace();  </code></pre>
<p>2. MethodTracing</p>
<ol type="1">
<li><p>功能：用于热点分析和性能优化，分析每个函数占用的 CPU
时间，调用次数，函数调用关系等</p></li>
<li><p>方法：</p></li>
</ol>
<ol type="a">
<li>在程序代码中加入追踪开关<br />
</li>
</ol>
<pre><code>import android.os.Debug;    
……    
android.os.Debug.startMethodTracing(“/data/tmp/test”); //  _ _ 先建  _ _  
/data/tmp  _ _ 目录  _ _    
…… //  _ _ 被追踪的程序段  _ _    
android.os.Debug.stopMethodTracing();  _  </code></pre>
<ol start="2" type="a">
<li><p>编译，运行后，设备端生成 /data/tmp/test.trace 文件</p></li>
<li><p>把 trace 文件复制到 PC 端<br />
</p></li>
</ol>
<pre><code>$ adb pull /data/tmp/test.trace ./  _  </code></pre>
<ol start="4" type="a">
<li>使用 android 自带工具分析 trace 文件<br />
</li>
</ol>
<pre><code>$ $ANDROID_SRC/out/host/linux-x86/bin/traceview test.trace  _    </code></pre>
<p>此时可看到各个函数被调用的次数 CPU 占用率等信息</p>
<ol start="5" type="a">
<li>使用 android 自带工具分析生成调用关系类图<br />
</li>
</ol>
<pre><code>$ apt-get install graphviz #  _ _ 安装图片相关软件  _ _    
$ANDROID_SRC/out/host/linux-x86/bin/dmtracedump -g test.png test.trace   </code></pre>
<p>此时目录下生成类图 test.png</p>
<ol start="3" type="1">
<li>注意<br />
trace 文件生成与 libdvm 模块 DEBUG 版本相冲突，所以此方法只适用于对非
DEBUG 版本模拟器的调试，否则在分析<br />
trace 文件时会报错</li>
</ol>
<p>3. HProf (Heap Profile)</p>
<ol type="1">
<li><p>功能：<br />
用于 java
层面的内存分析，显示详细的内存占用信息，指出可疑的内存泄漏对象</p></li>
<li><p>方法：</p></li>
</ol>
<ol type="a">
<li>在代码中加入 dump 动作<br />
</li>
</ol>
<pre><code>import android.os.Debug;    
import java.io.IOException;    
……    
try &#123;    
android.os.Debug.dumpHprofData(“/data/tmp/input.hprof”); //  _ _ 先建  _ _  
/data/tmp  _ _ 目录  _ _    
&#125; catch (IOException ioe) &#123;    
&#125;  </code></pre>
<ol start="2" type="a">
<li><p>把 hprof 文件复制到 PC 端<br />
_ $ adb pull /data/tmp/input.hprof ./ _</p></li>
<li><p>使用命令 hprof-conv 把 hprof 转成 MAT 识别的标准的 hprof<br />
_ $ $ANDROID_SRC/out/host/linux-x86/bin/hprof-conv input.hprof
output.hprof _</p></li>
<li><p>使用ＭＡＴ工具看 hprof 信息<br />
下载 MAT 工具： <a
href="http://www.eclipse.org/mat/downloads.php">http://www.eclipse.org/mat/downloads.php<br />
</a><br />
用工具打开 output.hprof</p></li>
</ol>
<ol start="3" type="1">
<li>注意：此工具只能显示 java 层面的，而不能显示Ｃ层的内存占用信息</li>
</ol>
<p>4. SamplingProfile (android 2.0 上版本使用 )</p>
<ol type="1">
<li><p>功能<br />
每隔Ｎ毫秒对当前正在运行的函数取样，并输出到 log 中</p></li>
<li><p>在代码中加入取样设定<br />
</p></li>
</ol>
<pre><code>import dalvik.system.SamplingProfiler    
……    
SamplingProfile sp = SamplingProfiler.getInstance();    
sp.start(n); // n  _ _ 为设定每秒采样次数  _ _    
sp.logSnapshot(sp.snapshot());    
……    
sp.shutDown();  _    </code></pre>
<p>它会启一个线程监测，在 logcat 中打印信息</p>
<p>5. 用发系统信号的方式取当前堆栈情况和内存信息</p>
<ol type="1">
<li><p>原理<br />
dalvik 虚拟机对 SIGQUIT 和 SIGUSR1 信号进行处理
(dalvik/vm/SignalCatcher.c)<br />
，分别完成取当前堆栈和取当前内存情况的功能</p></li>
<li><p>用法</p></li>
</ol>
<ol type="a">
<li></li>
</ol>
<pre><code>$ chmod 777 /data/anr -R #  _ _ 把  _ _ anr  _ _ 目录权限设为可写  _ _    
$ rm /data/anr/traces.txt #  _ _ 删除之前的  _ _ trace  _ _ 信息  _ _    
$ ps #  _ _ 找到进程号  _ _    
$ kill -3  _ _ 进程号  _ _ #  _ _ 发送  _ _ SIGQUIT  _ _ 信号给该进程，此时生成  _ _ trace  _  
_ 信息  _ _    
$ cat /data/anr/traces.txt  _    
功能实现：遍历  thread list(dalvik/vm/Thread.c:dvmDumpAllThreadEx())  ，并打印当前函数调用关系  
(dalvik/vm/interp/Stack.c:dumpFrames())  </code></pre>
<ol start="2" type="a">
<li></li>
</ol>
<pre><code>$ chmod 777 /data/misc -R   </code></pre>
<p>$ ps # _ _ 找到进程号 _ _<br />
$ kill -10 _ _ 进程号 _ _ # _ _ 发送 _ _ SIGQUIT _ _
信事信号给该进程，此时生成 _ _ hprof<br />
_ _ 信息 _ _<br />
$ ls /data/misc/*.hprof _</p>
<pre><code>此时生成  hprf  文件，如何使用此文件，见第二部分  (HProf)    
注意：  hprof  文件都很大，注意用完马上删除，以免占满存储器  
  
6\.  logcat  及原理  
  
1)  android.util.Log  利用  println  的标准  java  输出词句，并加前缀  I/V/D….  
  
2)  dalvik  利用管道加线程的方式，先利用  dup2  把  stdout  和  stderr  重定向到管理中  
(vm/StdioConverter.c:dvmstdioConverterStartup)  ，然后再启动一个线程从管道另一端读出内容  
(dalvik/vm/StdioConverter.c:stdioconverterThreadStart())  ，使用  LOG  公共工具（  
system/core/liblog/logd_write.c: __android_log_print()  ）输出到  /dev/log/*  中去  
  
3)  logcat  通过加不同参数看  /dev/log/  下的不同输入信息    </code></pre>
<h1 id="logcat--b-main-_-_-显示主缓冲区中的信息-_-_">logcat -b main _ _
显示主缓冲区中的信息 _ _</h1>
<h1 id="logcat--b-radio-_-_-显示无线缓冲区中的信息-_-_">logcat -b radio
_ _ 显示无线缓冲区中的信息 _ _</h1>
<h1 id="logcat--b-events-_-_-显示事件缓冲区中的信息-_">logcat -b events
_ _ 显示事件缓冲区中的信息 _</h1>
<pre><code>  
7\.  jdwp(java debug wire protocol)  及原理  
  
1)  虚拟机（设备端）在启动时加载了  Agent JDWP  从而具备了调试功能。在调试器端（  PC  端）通过  JDWP  
协议与设备连接，通过发送命令来获取的状态和控制  Java  程序的执行。  JDWP  是通过命令（  command  ）和回复（  reply  
）进行通信的。  
  
2)  JDK  中调试工具  jdb  就是一个调试器，  DDMS  也提供调试器与设备相连。  
  
3)  dalvik  为  JDWP  提供了两种连接方式：  tcp  方式和  adb  方式，  tcp  方式可以手工指定端口，  adb  
方式自动设定为  8700  端口，通常使用  DDMS  调试就是通过  adb  方式  
  
8\.  monkey  
  
1)  monkey  是一个  android  自带的命令行工具。它向系统发送伪随机的用户事件流，实现对正在开发的应用程序进行压力测试。  
  
2)  方法    
在设备端打开  setting  界面    </code></pre>
<p>$ adb shell<br />
# monkey -p com.android.settings -v 500</p>
<pre><code>此时可以看到界面不断被切换  
  
9\.  其它小工具    
具体见  android.os.Debug  中提供的工具  
  
1)  取毫微秒级的时间，用于计算时间    </code></pre>
<p>threadCpuTimeNanos()</p>
<pre><code>  
2)  统计两点间的内存分配情况    </code></pre>
<p>startAllocCounting()<br />
stopAllocCounting()<br />
getGlobalAllocCount()<br />
get…..</p>
<pre><code>  
3)  打印当前已  load  的  class    </code></pre>
<p>_ getLoadedClassCount()<br />
printLoadedClasses() _ _ 它需要打开 _ _ NDEBUG _ _ 功能才能打开 _ _
system/core/ _ _<br />
中 _ _ Log _ _ 功能 _</p>
<pre><code>10\.  打印  debug  信息    </code></pre>
<p>_ $ adb bugreport _<br />
```</p>
<p>11. 参考</p>
<ol type="1">
<li>android 中 monkey 的用法<br />
<a
href="http://junjie0324.spaces.live.com/blog/cns!BAAE46DF931F8C64!204.entry">http://junjie0324.spaces.live.com/blog/cns!BAAE46DF931F8C64!204.entry<br />
</a></li>
</ol>
<p>（转载请注明出处： http://xy0811.spaces.live.com ）</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android程序问题及解决方法</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E7%A8%8B%E5%BA%8F%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="android程序问题及解决方法">android程序问题及解决方法</h1>
<p>#移动开发 #android</p>
<p>1. 编译报错，找不到Ｒ相关资源<br />
在源码目录下新建一个应用，或者复制其它应用时，常出现这个错误。</p>
<ol type="1">
<li><p>什么是 R.java<br />
R.java 中编译时自动生成的，工程用到所有的资源，都会用到 R.java</p></li>
<li><p>何时生成<br />
在源码根目录下 make 全部代码时，才会对每个模块生成 R.java<br />
对资源更改后也会重新成生 R.java</p></li>
<li><p>生成在哪里<br />
out/target/common/obj/APPS/ 程序名 /…../R.java ( 用 find 找一下
)</p></li>
<li><p>解决方法<br />
只要把相关的 R.java 都删掉<br />
再更新资源 (res 目录 ) 中一个资源文件（ xml ），使得 R.java
重新生成<br />
重新 mm</p></li>
</ol>
<p>2. 查看当前堆栈调用关系</p>
<pre><code>$ rm /data/anr/traces.txt  _ _ 清除之前  _ _ log  _ _ 信息，因为  _ _ log  _ _  
信息是追加到此文件中的  _ _    
$ ps  _ _ 找应用对应进程号  _ _    
$ kill -3  _ _ 进程号  _ _ _ _ 该进程当前的堆栈调用写入  _ _ traces.txt    
$ cat /data/anr/traces.txt  _ _ 查看堆栈信息  _  </code></pre>
<p>3. 修改 framework 带来的界面显示不正常<br />
重编公共控件时，新生成了 framework.jar ，常用把它复制到设备中
/system/framework/ 目录下的方法调试，有时会遇到替换<br />
framework.jar 带来的资源不对的问题，即有些文字和图片显示不正常了。<br />
这是由于 framework.jar 和 system 目录中其它的资源 ID
不统一造成的。解决办法是重做 system.img<br />
并把它烧写到系统中（参见烧写文档），以下两种方法重做 system.img</p>
<ol type="1">
<li><p>使用打包命令<br />
_ $ out/host/linux-x86/bin/mkyaffs2image -f<br />
out/target/product/qsd8250_surf/system<br />
out/target/product/qsd8250_surf/system.img _</p></li>
<li><p>在编译时加 snod 参数，以重建系统镜像（ system.img ）<br />
_ $ mm snod _</p></li>
</ol>
<p>4. 打印当前类名和包名</p>
<ol type="1">
<li><p>打印当前类名<br />
_ Log.d(“TEST”, “class “ + this); _</p></li>
<li><p>打印当前包名<br />
_ Log.d(“TEST”, “package” + context.getPackageName()); _</p></li>
</ol>
<p>5. 程序中等待的实现<br />
_ import java.lang.Thread; // sleep _ _ 属于 _ _ Thread _ _ 类 _ _</p>
<p>try { // sleep _ _ 必须使用 _ _ try<br />
Thread.sleep(50);<br />
} catch (InterruptedException e) {<br />
} _</p>
<p>_ _</p>
<p>_ （转载请注明出处： http://xy0811.spaces.live.com ） _</p>
<p>__</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android语音识别方法一：使用intent调用语音识别程序</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95%E4%B8%80%EF%BC%9A%E4%BD%BF%E7%94%A8intent%E8%B0%83%E7%94%A8%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%A8%8B%E5%BA%8F/</url>
    <content><![CDATA[<h1
id="android语音识别方法一使用intent调用语音识别程序">android语音识别方法一：使用intent调用语音识别程序</h1>
<p>#移动开发 #android</p>
<p>1. 说明<br />
以下例程功能为：在应用程序中使用 intent
来调出语言识别界面，录音并识别后将识别的字串返回给应用程序。注意：使用前需要安装语音识别程序如语音搜索。</p>
<p>2. 本例参考自 android 例程：<br />
development/samples/ApiDemos/src/com/example/android/apis/app/VoiceRecognition.java</p>
<p>3. 可从此处下载可独立运行的代码：<br />
<a
href="http://download.csdn.net/source/2591401">http://download.csdn.net/source/2591401<br />
</a></p>
<p>4. 核心代码及说明</p>
<p>_ package com.android.mystt1; _</p>
<p>_ _</p>
<p>_ import android.app.Activity; _</p>
<p>_ import android.content.Intent; _</p>
<p>_ import android.content.pm.PackageManager; _</p>
<p>_ import android.content.pm.ResolveInfo; _</p>
<p>_ import android.os.Bundle; _</p>
<p>_ import android.speech.RecognizerIntent; _</p>
<p>_ import android.view.View; _</p>
<p>_ import android.view.View.OnClickListener; _</p>
<p>_ import android.widget.ArrayAdapter; _</p>
<p>_ import android.widget.Button; _</p>
<p>_ import android.widget.ListView; _</p>
<p>_ _</p>
<p>_ import java.util.ArrayList; _</p>
<p>_ import java.util.List; _</p>
<p>_ _</p>
<p>_ public class MyStt1Activity extends Activity implements
OnClickListener { _</p>
<p>_ private static final int VOICE_RECOGNITION_REQUEST_CODE = 1234;
_</p>
<p>_ private ListView mList; // _ _ 显示识别后字串的 _ _ list _ _ 控件 _
__</p>
<p>_ _</p>
<p>_ <span class="citation" data-cites="Override">@Override</span> _</p>
<p>_ public void onCreate(Bundle savedInstanceState) { _</p>
<p>_ super.onCreate(savedInstanceState); _</p>
<p>_ setContentView(R.layout.main); _</p>
<p>_ Button speakButton = (Button) findViewById(R.id.btn_speak); // _ _
识别按钮 _<br />
_ _</p>
<p>_ mList = (ListView) findViewById(R.id.list); _</p>
<p>_ PackageManager pm = getPackageManager(); _</p>
<p>_ List activities = pm.queryIntentActivities( _</p>
<p>_ new Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH), 0); // _ _
本地识别程序 _<br />
__</p>
<p>_ // new Intent(RecognizerIntent.ACTION_WEB_SEARCH), 0); // _ _
网络识别程序 _ __</p>
<p>_ if (activities.size() != 0) { _</p>
<p>_ speakButton.setOnClickListener(this); _</p>
<p>_ } else { // _ _ 若检测不到语音识别程序在本机安装，测将扭铵置灰 _
__</p>
<p>_ speakButton.setEnabled(false); _</p>
<p>_ speakButton.setText("Recognizer not present"); _</p>
<p>_ } _</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ public void onClick(View v) { _</p>
<p>_ if (v.getId() == R.id.btn_speak) { _</p>
<p>_ startMysttActivityActivity(); _</p>
<p>_ } _</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ private void startMysttActivityActivity() { // _ _ 开始识别 _
__</p>
<p>_ Intent intent = new
Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH); _</p>
<p>_ intent.putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, _</p>
<p>_ RecognizerIntent.LANGUAGE_MODEL_FREE_FORM); _</p>
<p>_ intent.putExtra(RecognizerIntent.EXTRA_PROMPT, "Speech recognition
demo");<br />
_</p>
<p>_ startActivityForResult(intent,
VOICE_RECOGNITION_REQUEST_CODE);<br />
// _ _ 调出识别界面 _ __</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ <span class="citation" data-cites="Override">@Override</span> _</p>
<p>_ protected void onActivityResult(int requestCode, int resultCode,
Intent<br />
data) { _</p>
<p>_ if (requestCode == VOICE_RECOGNITION_REQUEST_CODE &amp;&amp;
resultCode ==<br />
RESULT_OK) { _</p>
<p>_ // Fill the list view with the strings the recognizer thought it
could have<br />
heard _</p>
<p>_ ArrayList matches = data.getStringArrayListExtra( _</p>
<p>_ RecognizerIntent.EXTRA_RESULTS); _</p>
<p>_ mList.setAdapter(new ArrayAdapter(this,
android.R.layout.simple_list_item_1,<br />
_</p>
<p>_ matches)); _</p>
<p>_ } _</p>
<p>_ // _ _ 语音识别后的回调，将识别的字串在 _ _ list _ _ 中显示 _
__</p>
<p>_ super.onActivityResult(requestCode, resultCode, data); _</p>
<p>_ } _</p>
<p>_ }<br />
_</p>
<p>_ (转载请注明出处: <a
href="http://xy0811.spaces.live.com/">http://xy0811.spaces.live.com/</a><br />
) _</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android语音识别方法二：应用程序自己调用语音识别库</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95%E4%BA%8C%EF%BC%9A%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E8%87%AA%E5%B7%B1%E8%B0%83%E7%94%A8%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%93/</url>
    <content><![CDATA[<h1
id="android语音识别方法二应用程序自己调用语音识别库">android语音识别方法二：应用程序自己调用语音识别库</h1>
<p>#移动开发 #android</p>
<p>1. 说明<br />
以下例程功能为：应用程序自身调用语言识别函数，程序以循环方式等待录音并识别后的字串。</p>
<p>2. 本例参考自 android 代码：<br />
frameworks/base/core/java/android/speech/srec/Recognizer.java
中注释部分</p>
<p>3. 可从此处下载可独立运行的代码：<br />
<a
href="http://download.csdn.net/source/2591401">http://download.csdn.net/source/2591401<br />
</a></p>
<p>4. 核心代码及说明</p>
<p>_ package com.android.mystt2; _</p>
<p>_ _</p>
<p>_ import android.app.Activity; _</p>
<p>_ import android.content.Intent; _</p>
<p>_ import android.os.Bundle; _</p>
<p>_ import android.widget.Button; _</p>
<p>_ import android.widget.TextView; _</p>
<p>_ import android.view.View; _</p>
<p>_ import android.view.View.OnClickListener; _</p>
<p>_ _</p>
<p>_ import android.speech.srec.Recognizer; _</p>
<p>_ import android.speech.srec.MicrophoneInputStream; _</p>
<p>_ import java.io.InputStream; _</p>
<p>_ import java.io.IOException; _</p>
<p>_ import android.util.Log; _</p>
<p>_ _</p>
<p>_ public class MyStt2Activity extends Activity implements
OnClickListener { _</p>
<p>_ private TextView mText; _</p>
<p>_ private static final String TAG = "MyStt3Activity"; _</p>
<p>_ _</p>
<p>_ <span class="citation" data-cites="Override">@Override</span> _</p>
<p>_ public void onCreate(Bundle savedInstanceState) { _</p>
<p>_ super.onCreate(savedInstanceState); _</p>
<p>_ setContentView(R.layout.main); _</p>
<p>_ Button speakButton = (Button) findViewById(R.id.btn_speak); // _ _
识别扭按 _<br />
__</p>
<p>_ mText = (TextView) findViewById(R.id.text); // _ _ 显示识别后的字串
_ __</p>
<p>_ speakButton.setOnClickListener(this); _</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ public void onClick(View v) { _</p>
<p>_ if (v.getId() == R.id.btn_speak) { _</p>
<p>_ test(); _</p>
<p>_ } _</p>
<p>_ } _</p>
<p>_ _</p>
<p>_ void test() { _</p>
<p>_ try { _</p>
<p>_ InputStream audio = new MicrophoneInputStream(11025, 11025 * 5); //
_ _<br />
设置输入参数 _ __</p>
<p>_ String cdir = Recognizer.getConfigDir(null); // _ _
获取语音识别配置目录 _ __</p>
<p>_ Recognizer recognizer = new Recognizer(cdir + "/baseline11k.par");
_</p>
<p>_ Recognizer.Grammar grammar = recognizer.new Grammar(cdir _</p>
<p>_ + "/grammars/VoiceDialer.g2g"); _</p>
<p>_ grammar.setupRecognizer(); _</p>
<p>_ grammar.resetAllSlots(); _</p>
<p>_ grammar.compile(); _</p>
<p>_ recognizer.start(); // _ _ 开始识别 _ __</p>
<p>_ while (true) { // _ _ 循环等待识别结果 _ __</p>
<p>_ switch (recognizer.advance()) { _</p>
<p>_ case Recognizer.EVENT_INCOMPLETE: _</p>
<p>_ case Recognizer.EVENT_STARTED: _</p>
<p>_ case Recognizer.EVENT_START_OF_VOICING: _</p>
<p>_ case Recognizer.EVENT_END_OF_VOICING: _</p>
<p>_ continue; // _ _ 未完成，继续等待识别结果 _ __</p>
<p>_ case Recognizer.EVENT_RECOGNITION_RESULT: _</p>
<p>_ for (int i = 0; i &lt; recognizer.getResultCount(); i++) { _</p>
<p>_ String result = recognizer.getResult(i, _</p>
<p>_ Recognizer.KEY_LITERAL); _</p>
<p>_ Log.d(TAG, "result " + result); _</p>
<p>_ mText.setText(result); _</p>
<p>_ } // _ _ 识别到字串，显示并退出循环 _ __</p>
<p>_ break; _</p>
<p>_ case Recognizer.EVENT_NEED_MORE_AUDIO: _</p>
<p>_ recognizer.putAudio(audio) // _ _ 需要更多音频数据 _ _ ; _</p>
<p>_ continue; _</p>
<p>_ default: _</p>
<p>_ break; _</p>
<p>_ } _</p>
<p>_ break; _</p>
<p>_ } _</p>
<p>_ recognizer.stop(); _</p>
<p>_ recognizer.destroy(); _</p>
<p>_ audio.close(); // _ _ 回收资源 _ __</p>
<p>_ } catch (IOException e) { _</p>
<p>_ Lo _ _ g.d(TAG, "error", e); _</p>
<p>_ _ _ mText.setText("error " + e); _</p>
<p>_ } _</p>
<p>_ } _</p>
<p>_ } _</p>
<p>__</p>
<p>_</p>
<p>_ (转载请注明出处: <a
href="http://xy0811.spaces.live.com/">http://xy0811.spaces.live.com/</a><br />
) _</p>
<p>_ _</p>
<p>_</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android语音识别简介</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<h1 id="android语音识别简介">android语音识别简介</h1>
<p>#移动开发 #android</p>
<p>1. 语音识别一般使用三种方式</p>
<ol type="1">
<li><p>方式一：调用语音识别库的程序做成带界面的程序，供其它程序使用
intent 调用</p></li>
<li><p>方法二：应用程序自己调用语音识别库</p></li>
<li><p>方式三：调用语音识别库的程序做成 service
，供其它应用使用</p></li>
</ol>
<p>2. android2.2 对语音识别的内部支持</p>
<ol type="1">
<li>frameworks/base/core/java/android/speech/*<br />
语音的 android 框架支持 ( 合语音合成和语音识别 )</li>
</ol>
<ol type="a">
<li><p>RecognitionListener.java 用于支持对方式三的调用</p></li>
<li><p>Recognizer*Intent 用于支持对方式一的调用</p></li>
<li><p>RecognitionService.java 用于支持对方式三的调用</p></li>
<li><p>SpeechRecognizer.java 用于支持对方式三的调用</p></li>
<li><p>srec 目录<br />
语音识别，它用于方式一二三真正功能的实现</p></li>
</ol>
<ol type="i">
<li><p>MicrophoneInputStream.java 实现录音</p></li>
<li><p>Recognizer.java 实现识别的接口</p></li>
</ol>
<ol start="6" type="a">
<li>tts 目录<br />
语音合成</li>
</ol>
<ol start="2" type="1">
<li>external/srec/*<br />
语音识别的底层实现</li>
</ol>
<p>3. 语音引擎：</p>
<ol type="1">
<li><p>srec android 自带的语音识别工具</p></li>
<li><p>simon 网上说该识别工具可移植到 android 上</p></li>
<li><p>pico android 自带的语音合成工具</p></li>
</ol>
<p>4. 参考</p>
<ol type="1">
<li>可参考语音拨号器应用的实现，源码在<br />
packages/apps/VoiceDialer/</li>
</ol>
<p>__</p>
<p>_ (转载请注明出处: <a
href="http://xy0811.spaces.live.com/">http://xy0811.spaces.live.com/</a><br />
) _</p>
<p>_ _</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>android调试技术补充</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/android%E8%B0%83%E8%AF%95%E6%8A%80%E6%9C%AF%E8%A1%A5%E5%85%85/</url>
    <content><![CDATA[<h1 id="android-调试技术补充">android 调试技术补充</h1>
<p>#移动开发 #android</p>
<p>1. 看编译信息<br />
显示编译打包命令的具体参数，以下命令看编译详情<br />
** $ make showcommands **</p>
<p>2. 源码中重编应用软件<br />
** $ cd packages/apps/xxx<br />
$ touch <code>find</code> ** ** 更新全部代码 ** **<br />
$ mm **<br />
注意： mm clean 是 clean
所有源码，不止本目录之后的，千万注意不要误操作</p>
<p>3. 查看当前的 dump 信息<br />
** $ adb shell dumpstate &gt; xxx.msg **</p>
<p>4. SDK 与手机版本不一致问题的解决<br />
注意要用与硬件对应的 eclipse 插件和 sdk
，否则可能会报很多奇怪的错误。<br />
如果在源码中编译，而被安装的手机与源码不在是同一版本，可能出现如下问题<br />
adb install 时报错<br />
Failure [INSTALL_FAILED_OLDER_SDK]<br />
此时只需改动 AndroidManifest.xml ，加入最低版本号<br />
** <uses-sdk android:minSdkVersion=”3”/> **<br />
3 对应 SDK1.5<br />
注意：如果是不同版本 API 接口不一致引起的问题，此方法不能解决</p>
<p>5. 获取当前系统的内核配置 , 可用如下方法取得内核配置文件<br />
** $ adb pull /proc/config.gz /tmp<br />
$ vi tmp/config.gz **</p>
<p>6. 设置和读取 android 的系统属性的命令<br />
** $ adb shell<br />
# getprop ** ** 属性名 ** **<br />
# setprop ** ** 属性名 ** ** ** ** 属性值 **</p>
<p>7. 在 Android.mk 中打印提示信息<br />
** $(info "xxxxxxxx") **</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>制作android的换肤包</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/%E5%88%B6%E4%BD%9Candroid%E7%9A%84%E6%8D%A2%E8%82%A4%E5%8C%85/</url>
    <content><![CDATA[<h1 id="制作android的换肤包">制作android的换肤包</h1>
<p>#移动开发 #android</p>
<p>1. 如何做换肤包</p>
<ol type="1">
<li>最简单的方法是替换源码中的资源，然后重新编译</li>
</ol>
<ol type="a">
<li><p>举例：修改系统公共资源——系统字体大小<br />
修改 framework/base/core/res/res/values*/style.xml 其中的 TexAppearance
的<br />
Large,Medium,Small 的 textSize ，它们分别对应大中小字的字号<br />
修改后，在 res 目录中重新编译 ( 使用 mm 命令 ) ，然后将生成的
framework-res.apk 拷到手机的<br />
/system/framework 目录中</p></li>
<li><p>注意：源码中的资源必须和设备中资源相对应，因在生成
framework-res.apk 的过程中生成了资源 ID 号，而各应用通过资源<br />
ID 号读取系统资源，所以如果 ID 号不一致，整个系统的资源就乱了</p></li>
</ol>
<ol start="2" type="1">
<li><p>有时候我们只想换包中的某个图片，不想重编整个包，或者从网上下载的应用程序，得不到源码不能重编，但也想对其换肤。<br />
由于 apk 是 zip
格式的压缩包，最简单的方法是解包，替换图片，然后再打包<br />
_ $ mkdir tmp; cd tmp<br />
$ unzip ../xxx.apk<br />
$ cp xxx.png res/drawable/ _ _ 替换图片 _ _<br />
$ zip -r ../xxx_new.apk * _<br />
然后安装到系统中，或替换原有包，即可。</p></li>
<li><p>有时会遇到图片不能以原有方式被拉伸的问题，这是由于某些 9patch
格式图片丢失了其格式信息，下面通过了解 apk 打包工具可以解决此问题<br />
( 直接修改 apk 包和使用 metaporgh 皮肤的原理是一样的 )</p></li>
</ol>
<p>2. 9 patch<br />
9patch 是一种特殊的文件格式，它以 ”.9.png”<br />
为扩展名，它的上下左右各有一象素留边，用以标识图片以何种方式拉伸，一般做图时留边中以黑色标识其拉伸区域，此为显式的
9patch<br />
信息，用以方便做图者编辑（ android 提供工具 draw9patch 来编辑 9patch
图），程序打包时 aapt<br />
工具把该图留边去掉，并将信息其写入 png 文件内部，使之变为隐显 9patch
信息</p>
<p>3. apk 如何打包<br />
了解打包的目的在于了解对 9patch 图及其它资源的处理过程</p>
<ol type="1">
<li><p>编译某应用 ( 以计算器为例 )<br />
_ $ cd packages/apps/Calculator<br />
$ mm showcommands _<br />
使用参数 showcommands 可以看到编译用到的具体命令，其中最核心的是
aapt</p></li>
<li><p>使用 aapt 命令打包 (aapt 源码见 framework/base/tools/aapt)<br />
为了解原理，我们建立一个最简单的只含有图片的包，用此方式，可以把图片从显式的
9patch 图变成隐式的 9patch 图，建立目录及文件如下<br />
_ $ mkdir test; cd test<br />
$ vi AndroidManifest.xml _ _ 编辑内容如下 _ _</p></li>
</ol>
<p><a
href="http://schemas.android.com/apk/res/android">http://schemas.android.com/apk/res/android<br />
</a> “<br />
package=“com.android.test“</p>
<p>$ mkdir res/drawable -p<br />
$ cp xxxx.png res/darwable/<br />
$ aapt package -S res -M AndroidManifest.xml -F test.apk -f _</p>
<p>_ 3) 浏览 apk 包中内容<br />
_ $ mkdir tmp; cd tmp<br />
$ unzip ../test.apk<br />
$ ls _<br />
此时看到 xml 文件补转换成不可读的了，产生了 resources.arsc
，其中包含资源列表 (ResTable) ，它说明了每个资源的<br />
resourceid （不同字段标明包名类型和编号） , pac, type, name, flag ， res
中某些资源也会被打入<br />
resources.arsc 中（如 string ） _</p>
<p>_</p>
<ol start="4" type="1">
<li><p>res/drawable/ 中的图片仍存在，如果它是 9patch
图，则图片会把显式的 9patch 位置打成隐式的 9patch<br />
信息</p></li>
<li><p>想看某个 apk 包的内容 , 可以编其源码目录中的 printapk.cpp,
用于打印某包的资源信息 , 它的编法是改<br />
Android.mk 为编 printapk 的 , 注意库中要加 libzipfile</p></li>
</ol>
<p>4. aapt 工具<br />
aapt 工具用于生成查看和编辑 apk 包</p>
<ol type="1">
<li>打包</li>
</ol>
<ol type="a">
<li>打包<br />
_ $ aapt package -S res -M AndroidManifest.xml -F xxt.apk -f _</li>
</ol>
<ol start="2" type="1">
<li>查看</li>
</ol>
<ol type="a">
<li><p>查看 apk 中包含哪些资源文件<br />
_ $ aapt list xxx.apk _</p></li>
<li><p>查看某个 xml 的内容<br />
_ $ aapt dump xmltree xxx.apk res/layout/main.xml _<br />
（ xml 不能是 values* 中的，因为它已被打进 resources.arsc ）</p></li>
<li><p>查看 resources.arsc 中的资源内容<br />
_ $ aapt dump --values resources xxx.apk _</p></li>
</ol>
<ol start="3" type="1">
<li>编辑<br />
用此方法编辑与 zip 解压修改再压缩的方式不同，它会编译 xml 文件和处理
9patch 图</li>
</ol>
<ol type="a">
<li><p>从包中删除某文件<br />
_ $ aapt remove xxx.apk res/layout/alert_dialog.xml _</p></li>
<li><p>将某文件加入包中<br />
_ $ aapt add xxx.apk res/layout/alert_dialog.xml _</p></li>
</ol>
<p>5. 总结<br />
换肤时，如果想替换 9patch 图，需要使用 aapt
或其它工具对图进行处理，否则如果只是简单地用 zip 工具解开 apk<br />
包，替换一个普通图片，再打包成 apk
的话，是达不到你想要的拉伸效果的，这是由于普通图不包含 9ptach 信息<br />
以上方法可以转换 9patch 图，即做好显式的 9patch
图，然后有以上方法产生隐式的 9patch 图，再将它放入包中替换原有资源</p>
<p>_</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>原创2010年android文档的整理打包的pdf档(含目录)</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/%E5%8E%9F%E5%88%9B2010%E5%B9%B4android%E6%96%87%E6%A1%A3%E7%9A%84%E6%95%B4%E7%90%86%E6%89%93%E5%8C%85%E7%9A%84pdf%E6%A1%A3(%E5%90%AB%E7%9B%AE%E5%BD%95)/</url>
    <content><![CDATA[<h1
id="原创2010年android文档的整理打包的pdf档含目录">原创2010年android文档的整理打包的pdf档(含目录)</h1>
<p>#移动开发 #android</p>
<p>原创2010年android文档的整理打包的pdf档(含目录)<br />
文档内容不能复制, 下载分5分, 介意者请慎下.<br />
大部分内容可在 <a
href="http://blog.csdn.net/xieyan0811">http://blog.csdn.net/xieyan0811</a><br />
中看到</p>
<p>文档目录如下</p>
<p>1 系统配置 1<br />
1.1 建立SDK开发环境 2<br />
1.2 Android源码的编译 6<br />
1.3 编译在G1上运行的android 2.1(eclair)代码 9<br />
1.4 编译在G1上运行的android 2.2(froyo)代码_旧方法 12<br />
1.5 编译在G1上运行的android 2.2(froyo)代码_新方法 15<br />
1.6 编译在N1上运行的android 2.3(GingerBread)代码 18<br />
1.7 系统结构 21<br />
1.8 模拟器调试与真机调试 22<br />
1.9 安装和卸载应用程序（apk包） 23<br />
1.10 系统升级 26<br />
1.11 android系统支持app2sd（修改boot.img） 27<br />
2 基本概念 30<br />
2.1 Android组件 31<br />
2.1.1 基本组件 31<br />
2.1.2 组件间的通讯 32<br />
2.1.3 intent使用方法 33<br />
2.2 界面开发 35<br />
2.2.1 界面元素 35<br />
2.2.2 布局的实现 36<br />
2.2.3 事件响应 37<br />
2.2.4 应用软件代码结构 38<br />
2.2.5 国际化的支持（多语言） 39<br />
2.2.6 常见问题及解决方法 40<br />
2.2.7 android是重要的包 41<br />
2.3 界面元素分析 42<br />
2.4 修改公共控件 43<br />
2.5 源码中常用于参考的代码 44<br />
3 程序开发 45<br />
3.1 相关工具介绍 46<br />
3.1.1 从c++到java（一） 46<br />
3.1.2 从c++到java（二） 47<br />
3.2 常用技术 49<br />
3.2.1 如何新建和使用控件 49<br />
3.2.2 使用定时器Timer及消息处理 51<br />
3.2.3 操作调试数据库与ContentProvider详解 53<br />
3.2.4 电源管理 56<br />
3.2.5 开发桌面小程序AppWidget 58<br />
3.2.6 代码中运行二进制程序或脚本 60<br />
3.2.7 Android自带的md5校验 61<br />
3.2.8 将数据打进apk包 63<br />
3.2.9 如何改变窗口的标题栏的布局 66<br />
3.2.10 动态改变控件大小 67<br />
3.2.11 缩放drawable 68<br />
3.2.12 解析apk包内容 69<br />
3.3 Java对C库的调用 70<br />
3.3.1 android中使用JNI 70<br />
3.3.2 安装使用NDK 72<br />
3.3.3 在源码中将库打进apk 73<br />
3.3.4 简单的C库调试方法 75<br />
3.4 典型应用 76<br />
3.4.1 语音合成 76<br />
3.4.2 语音识别简介 79<br />
3.4.3 语音识别方法一：使用intent调用语音识别程序 80<br />
3.4.4 语音识别方法二：应用程序自己调用语音识别库 82<br />
3.4.5 语音识别方法三：使用Service调用语音识别程序 84<br />
3.4.6 人脸识别 87<br />
3.4.7 图像识别 89<br />
3.4.8 文字识别 90<br />
3.4.9 卫星定位 91<br />
3.4.10 多媒体播放 95<br />
3.4.11 访问网络 97<br />
3.4.12 博客客户端的实现 99<br />
3.5 调试技术 102<br />
3.5.1 JDWP调试 102<br />
3.5.2 运行dalvik测试程序 103<br />
3.5.3 测试小程序 104<br />
3.5.4 dalvik提供的调试工具集 107<br />
3.5.5 c++程序的调试 110<br />
3.5.6 测试工具CTS 113<br />
3.5.7 解决eclipse无法识别API的问题 115<br />
3.5.8 调试方法补充 116<br />
3.6 换肤(theme) 118<br />
3.6.1 当前的换肤方法(theme) 118<br />
3.6.2 制作换肤包 120<br />
4 android架构层分析 122<br />
4.1 启动过程 123<br />
4.1.1 开机流程 123<br />
4.1.2 开机动画 125<br />
4.1.3 android应用的启动过程 127<br />
4.2 服务的原理与使用 128<br />
4.3 键盘事件处理 130<br />
4.4 包管理 131<br />
4.5 传感器 132<br />
4.6 浅析dalvik虚拟机JIT技术的实现 133<br />
4.7 应用程序的签名(Signature) 135<br />
4.8 应用的权限 138<br />
4.9 屏幕密度Density 140<br />
4.10 Prelink实现的源码分析 142<br />
4.11 适配硬件平台 145<br />
4.12 其他介绍 147<br />
4.12.1 手机保护Keyguard 147<br />
4.12.2 空中升级Fota 148<br />
4.12.3 Flash分区 149</p>
<p>可从csdn下载: <a
href="http://xieyan0811.download.csdn.net/">http://xieyan0811.download.csdn.net/<br />
</a></p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>各个层面的android小例程</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/%E5%90%84%E4%B8%AA%E5%B1%82%E9%9D%A2%E7%9A%84android%E5%B0%8F%E4%BE%8B%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="各个层面的android小例程">各个层面的android小例程</h1>
<p>#移动开发 #android</p>
<p>1. 说明<br />
在问题定位时，通常使用一些非常简单的程序来测试，以简化逻辑。下面介绍
android 各个层面的测试的编写：普通的 java 程序，加入<br />
android 类的 java 程序，带 android 界面的 java 程序和运行在 android
平台上的 c/c++ 程序</p>
<p>2. 配置环境</p>
<pre><code>$ cd $ANDROID_SRC_    
$ . build/envsetup.sh    
$ cd development    </code></pre>
<p>3. 普通 java 程序</p>
<ol type="1">
<li>建立 Foo.java ，内容如下<br />
</li>
</ol>
<pre><code>class Foo &#123;    
public static void main(String[] args)    
&#123;System.out.println(“Hello, world”);&#125;    
&#125;  </code></pre>
<ol start="2" type="1">
<li>编译<br />
</li>
</ol>
<pre><code>$ javac Foo.java    
$ dx --dex --output=foo.jar Foo.class # _ _ 把一个或多个  class  编成一个  jar   </code></pre>
<ol start="3" type="1">
<li>运行<br />
</li>
</ol>
<pre><code>$ adb push foo.jar /sdcard #_ _ 复制到设备的  sd  卡中    
$ adb shell dalvikvm -cp /sdcard/foo.jar Foo # 指明路径和类名   </code></pre>
<p>4. 使用 android 特定功能的 java 程序（需引入 android 库）</p>
<ol type="1">
<li>建立 Foo.java ，内容如下<br />
</li>
</ol>
<pre><code>import android.os.Debug;    
class Foo &#123;    
public static void main(String[] args)    
&#123;    
System.out.println(“Hello, world”)    
android.os.Debug.dumpHprofData(“/sdcard/test.hprof”);    
;&#125;    
&#125;  </code></pre>
<ol start="2" type="1">
<li>建立 Android.mk ，内容如下<br />
</li>
</ol>
<pre><code>LOCAL_PATH:= $(call my-dir)    
include $(CLEAR_VARS)    
LOCAL_SRC_FILES:=$(call all-subdir-java-files)    
LOCAL_MODULE:=foo    
include $(BUILD_JAVA_LIBRARY)  </code></pre>
<ol start="3" type="1">
<li>编译<br />
</li>
</ol>
<pre><code>$ mm  </code></pre>
<ol start="4" type="1">
<li>运行<br />
</li>
</ol>
<pre><code>$ adb push $ANDROID_SRC/out/target/product/xxxxxxx/system/framework foo.jar  
/sdcard #_ _ 复制到设备的 sd 卡中  
$ adb shell dalvikvm -cp /sdcard/foo.jar Foo # 指明路径和类名  </code></pre>
<p>5. 带界面的 android 程序</p>
<ol type="1">
<li>使用 eclipse 建立</li>
</ol>
<ol type="a">
<li><p>在 eclipse 中点击菜单 File- &gt;New-&gt;Project ……，选择 Android
Project</p></li>
<li><p>填写 project 的各项内容如下<br />
Project name: test_xy 目录名 , 它位于你设定的 workspace 之下<br />
Package name: com.android.testxy 打包名称<br />
Activity name: TestXy 类名 ( 生成文件 TestXy.java)<br />
Application: name:test_app_name 可执行程序名<br />
然后点 Finish 按钮</p></li>
<li><p>填写代码<br />
这时可以看到代码界面了，从左边的树中打开代码<br />
test_xy à src à com.android.testxy à _ TestXy.java _ _ à _ _ TestXy
_<br />
_ à _ _ onCreate _<br />
修改其中代码 ( 不改也行 )</p></li>
</ol>
<ol start="2" type="1">
<li>修改编译运行</li>
</ol>
<ol type="a">
<li>eclipse 中运行</li>
</ol>
<ol type="i">
<li><p>在 eclipse 中点击菜单 Run- &gt;Run Configurations ……</p></li>
<li><p>双击左边的 Android Application ，产生了一个 New Configuration
，点开它填写内容如下：<br />
Name: yan_config // 随便起一个<br />
Project: test_xy // 刚才起的 project, 即目录名</p></li>
<li><p>点击 Apply ，然后点 Run ，多等一会儿就出来了</p></li>
</ol>
<ol start="2" type="a">
<li>从命令行运行</li>
</ol>
<ol type="i">
<li>复制工程到 Android 源码目录中<br />
</li>
</ol>
<pre><code>$ cp $WORKSPACE/test_xy $ANDROID_SRC/development/ -R  </code></pre>
<ol start="2" type="i">
<li>加入 Android.mk<br />
</li>
</ol>
<pre><code>$ cd $ANDROID_SRC/development/test_xy/    
编写  Android.mk  内容如下    
LOCAL_PATH:=$(call my-dir)    
include $(CLEAR_VARS)    
LOCAL_SRC_FILES := $(call all-subdir-java-files)    
LOCAL_PACKAGE_NAME:=XyTest    
LOCAL_CERTIFICATE:=platform    
include $(BUILD_PACKAGE)  </code></pre>
<ol start="3" type="i">
<li>编译<br />
</li>
</ol>
<pre><code>$ mm  </code></pre>
<ol start="4" type="i">
<li>运行<br />
</li>
</ol>
<pre><code>$ adb install $ANDROID_SRC/out/target/product/xxxxxx/system/app/XyTest.apk    
$ adb shell am start -n com.android.testxy/com.android.testxy.TestXy  
# am start -n  类名  /  类名  .Activity  名  </code></pre>
<p>6. 简单的 c++ 程序</p>
<ol type="1">
<li>建立 main.c ，内容如下<br />
</li>
</ol>
<pre><code>#include    
int main()    
&#123;    
printf(&quot;Hello World!/n&quot;);    
return 0;    
&#125;  </code></pre>
<ol start="2" type="1">
<li>建立 Android.mk ，内容如下<br />
</li>
</ol>
<pre><code>LOCAL_PATH:= $(call my-dir)    
include $(CLEAR_VARS)    
LOCAL_SRC_FILES:= /    
main.c    
LOCAL_MODULE := helloworld    
include $(BUILD_EXECUTABLE)  </code></pre>
<ol start="3" type="1">
<li>编译<br />
</li>
</ol>
<pre><code>$ cd $(ANDROID_SRC)  &amp;&amp; make helloworld    
或    
$ mm  </code></pre>
<ol start="4" type="1">
<li>运行<br />
</li>
</ol>
<pre><code>$ adb push out/target/product/generic/system/bin/helloworld /sdcard    
$ adb shell /sdcard/helloword  </code></pre>
<p>（转载请注明出处： http://xy0811.spaces.live.com）</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>如何新建和使用Android控件</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/%E5%A6%82%E4%BD%95%E6%96%B0%E5%BB%BA%E5%92%8C%E4%BD%BF%E7%94%A8Android%E6%8E%A7%E4%BB%B6/</url>
    <content><![CDATA[<h1 id="如何新建和使用android控件">如何新建和使用Android控件</h1>
<p>#移动开发 #android</p>
<p>一、 重点</p>
<p>如何在 layout （ xml ）中使用自定义的控件</p>
<p>二、 举例</p>
<p>1. 功能：实现一个新的浏览器控件，使点击浏览器中任何位置都能打印 Log
信息</p>
<p>2. 步骤：</p>
<ol type="1">
<li>建立 project</li>
</ol>
<ol type="a">
<li><p>在 eclipse 中点击菜单 File-&gt;New-&gt;Project ……</p></li>
<li><p>选择 Android Project 按 Next</p></li>
<li><p>填写 project 的各项内容如下<br />
Project name: test_xy // 目录名 , 它位于你设定的 workspace 之下<br />
Package name: com.android.test // 打包名称<br />
Activity name: .TestXy // 类名 ( 生成文件 TestXy.java)<br />
Application name: test_xy // 可执行程序名<br />
然后点 Finish 按钮</p></li>
</ol>
<ol start="2" type="1">
<li>继承一个已有控件，加入新的属性和方法</li>
</ol>
<ol type="a">
<li><p>eclipse 左侧： test_xy-&gt;src-&gt;com.android.test 点右键
New-&gt;class</p></li>
<li><p>建立新控件： Name: MyWebView ，其它使用默认选项<br />
MyWebView.java 内容如下：<br />
** package ** ** com.android.test;</p></li>
</ol>
<p>import android.view.MotionEvent;<br />
import android.webkit.WebView;<br />
import android.content.Context;<br />
import android.util.AttributeSet;<br />
import android.util.Log;</p>
<p>public class MyWebView extends WebView {<br />
public MyWebView(Context context) {<br />
this(context, null);<br />
}<br />
public MyWebView(Context context, AttributeSet attrs){<br />
this(context, attrs, 0);<br />
}<br />
public MyWebView(Context context, AttributeSet attrs,int defStyle)
{<br />
super(context, attrs, defStyle);<br />
} ** // 注意实现带三个参数的构造函数 **<br />
public boolean onTouchEvent(MotionEvent ev) { ** // 加入新功能 **<br />
int action = ev.getAction();<br />
Log. <em>d</em> ("XY_TEST", "now recv key: " + action);<br />
return super.onTouchEvent(ev);<br />
}<br />
} **</p>
<ol start="3" type="1">
<li>修改 xml 文件</li>
</ol>
<ol type="a">
<li>eclipse 左侧： test_xy- &gt;res-&gt;layout-&gt;main.xml
修改其中内容如下<br />
** "1.0" encoding= <em>"utf-8"</em> ? &gt;<br />
<em><a
href="http://schemas.android.com/apk/res/android">http://schemas.android.com/apk/res/android<br />
</a><br />
</em> android:orientation= <em>"vertical"</em> android:layout_width=
<em>"fill_parent"<br />
</em> android:layout_height= <em>"fill_parent"</em> &gt;<br />
<em>"fill_parent"<br />
</em> android:layout_height= <em>"wrap_content"</em><br />
android:text= <em>"<span class="citation"
data-cites="string/hello">@string/hello</span>"</em> / &gt;<br />
android:id= <em>"@+id/myview"</em> android:layout_height=
<em>"fill_parent"<br />
</em> android:layout_width= <em>"fill_parent"</em> / &gt;</li>
</ol>
<p>注意使用全名 , 即 com.android.test.MyWebView, 否则找不到新控件 **</p>
<p>** 4) 运行 **</p>
<p>**</p>
<ol type="a">
<li><p>在 eclipse 中点击菜单 Run- &gt;Run Configurations ……</p></li>
<li><p>双击左边的 Android Application ，产生了一个 New Configuration
，点开它填写内容如下：<br />
Name: yan_config // 随便起一个<br />
Project: test_xy // 刚才起的 project, 即目录名</p></li>
<li><p>点击 Apply ，然后点 Run ，多等一会儿就出来了</p></li>
<li><p>此时点击右上的 DDMS ，可看到 Log 信息，在触摸 WebView
控件时，可看到刚才加入的 Log 信息</p></li>
</ol>
<p>**</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>开发android的桌面小程序AppWidget</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/%E5%BC%80%E5%8F%91android%E7%9A%84%E6%A1%8C%E9%9D%A2%E5%B0%8F%E7%A8%8B%E5%BA%8FAppWidget/</url>
    <content><![CDATA[<h1
id="开发android的桌面小程序appwidget">开发android的桌面小程序AppWidget</h1>
<p>#移动开发 #android</p>
<p>1. 什么是 AppWidget<br />
Android
系统允许某个应用把它自己的控件嵌入到其它的应用之中，这些被嵌入的控件就是
”widget” ，发布控件的应用是<br />
”:appwidget providers” ，而合成控件并显示的应用是 ”AppWidget
host”.<br />
widget 常被译作小应用，小控件，小部件。最常见的 widget<br />
是显示在桌面上时钟，日历，搜索，相框，音乐等，使用户不用进入应用，就可以方便地使用某种功能。桌面也是一个应用程序（<br />
packages/apps/Launcher ），代码中实现了 ”AppWidget host”
，而时钟，日历是分别实现了不同功能的<br />
”appwidget provider” （ packages/apps/Calendar ）</p>
<p>2. 建立第一个 AppWidget<br />
长篇大论不如立竿见影地看到效果，用以下方法，建立你的第一个 widget<br />
_ $ cd $ANDROID_SRC/development<br />
$ cp
$ANDROID_SRC/frameworks/base/tests/appwidgets/AppWidgetProviderTest<br />
MyWidget -R<br />
$ cd MyWidget<br />
$ mm<br />
$ adb install<br />
$ANDROID_SRC/out/target/product/qsd8250_surf/system/app/AppWidgetProvider.apk<br />
_ 注意：</p>
<ol type="1">
<li>android 2.1 因为加载 widget
时需要提供的图标和文字，而此例中没有，所以会在加载小控件时报错，需要修改
Android<br />
Ｍ anifest.xml 如下：<br />
把 改为</li>
</ol>
<p>并在 drawable 下放 icon.png ，作为出现在小控件列表中的图标</p>
<ol start="2" type="1">
<li>不能全部 ANDROID 代码一起编，否则会因为类重名而报错<br />
只编此项目没有问题，把文件名，目录名，类名等都改成你定义的名字即可全编</li>
</ol>
<p>3. 代码分析</p>
<ol type="1">
<li><p>AndroidManifest.xml<br />
主要描述由哪个 AppWidgetProvider 提供 Widget
，最好在其中加入图标和名字，以免 android 2.0<br />
以上系统中出问题</p></li>
<li><p>Android.mk<br />
编译规则</p></li>
<li><p>src/com/android/tests/appwidgetprovider/TestAppWidgetProvider.java<br />
实现 AppWidgetProvider （继承自 BroadcastReceiver ）或 BroadcastReceiver
，在<br />
AppWidget 应用 update, enable, disable 和 deleted 时接受通知。其中
onUpdate() （或<br />
onReceive() 中的 UPDATE
部分）最重要的方法，由它接受通知并更新，一般实现如下：<br />
<em>ComponentName thisWidget = new ComponentName(context,
MyProvider.class);<br />
AppWidgetManager appWidgetManager =
AppWidgetManager.getInstance(context);<br />
RemoteView views = new RemoteViews(context.getPackageNmae(),<br />
R.layout.provider) // </em> _ 设定布局 _ _ ;<br />
appWidgetManager.updateAppWidget(thisWidget, views); // 请求 widgethost
刷新 _<br />
真正的刷新在 widgethost 所在应用中实现
(AppWidgetHostView.updateAppWidget()) ，即在<br />
widgetprovider 中只做描述，而在 widgethost 中把描述的资源 inflate
成为真正控件。</p></li>
<li><p>res/xml/appwidget_info.xml<br />
AppWidgetProviderInfo: 描述 AppWidget
的大小，更新频率和初始界面等信息，注意 Android 1.6<br />
版本对更新频率支持有问题。</p></li>
<li><p>res/layout/xxxx.xml<br />
widget 的布局文件</p></li>
<li><p>res/values/strings.xml<br />
widget 中使用到的字串</p></li>
</ol>
<p>4. 说明</p>
<ol type="1">
<li>设置界面<br />
有时需要设置界面（ configure activity ）在第一次运行前被调出，用于设置
AppWidget ，它在<br />
res/xml/xxx.xml 中设定，示例代码见：<br />
$ANDROID_SRC/development/samples/ApiDemos/src/com/example/android/apis/appwidget/</li>
</ol>
<p>5. 参考代码</p>
<ol type="1">
<li>从 market
下了几个电量显示控件，觉得不是太大就是太小，太难看，要不就是更新有问题……，于是做了一个
Widget ，截取了<br />
iphone 的电池控件图标，大小与 icon 一致，仅供学习参考，代码及 apk
下载地址：<br />
<a
href="http://cid-f8aecd2a067a6b17.skydrive.live.com/self.aspx/.Public/android/widget%5E_demo.zip"><br />
http://cid-f8aecd2a067a6b17.skydrive.live.com/self.aspx/.Public/android/widget^_demo.zip<br />
</a></li>
</ol>
<p>（转载请注明出处： <a
href="http://xy0811.spaces.live.com/">http://xy0811.spaces.live.com</a><br />
）</p>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>简单的android中C库调试方法</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/%E7%AE%80%E5%8D%95%E7%9A%84android%E4%B8%ADC%E5%BA%93%E8%B0%83%E8%AF%95%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="简单的android中c库调试方法">简单的android中C库调试方法</h1>
<p>#移动开发 #android</p>
<p>1． 说明<br />
android 系统中调试 Java 非常容易，一般遇到错误都在 logcat
中打印出错时函数的调用关系，而 C<br />
库中出错时只看到一些二进制信息，使用 gdbserver
调试环境搭建又比较复杂。下在介绍一个简单的调试库的方法，当然需要有 so
库的源代码</p>
<p>2． 举例</p>
<ol type="a">
<li><p>错误信息如下，它表示了出错时的函数调用关系（下面调上面的）<br />
I/DEBUG ( 56): #03 pc 000008d8 /system/lib/libstdc++.so<br />
I/DEBUG ( 56): #04 pc 00003090 /system/lib/libttssynthproxy.so<br />
I/DEBUG ( 56): #05 pc 0001c174<br />
/data/data/com.xytts/lib/libttsxyttsengine.so<br />
I/DEBUG ( 56): #10 pc 0000285c /system/lib/libttssynthproxy.so<br />
I/DEBUG ( 56): #11 pc 00016e34 /system/lib/libdvm.so</p></li>
<li><p>进入源码中带符号表的 so 库所在目录<br />
$ cd out/target/product/passion/symbols/system/lib</p></li>
<li><p>用 addr2line 命令找到地址对应的程序位置，出借库为
libttsxyttsengine.so<br />
arm-eabi-addr2line 0001c174 -e libttsxyttsengine.so<br />
结果 : ，显示出对应的程序文件和行数，如果不是 debug
版本，可能有一两行偏差<br />
/exports/android/android_22/base/packages/apps/XYTts/lib/interface.cpp:35</p></li>
<li><p>注意<br />
arm-eabi_addr2line 在 prebuild/linux-x86/toolchain/arm-eabi-xxx/bin
目录下，运行<br />
build/envsetup.sh 后即可直接使用它，同目录下的 objdump, nm
也是常用调试命令</p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>解决eclipse无法识别某些API的问题</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Android/%E5%BA%94%E7%94%A8/%E8%A7%A3%E5%86%B3eclipse%E6%97%A0%E6%B3%95%E8%AF%86%E5%88%AB%E6%9F%90%E4%BA%9BAPI%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h1
id="解决eclipse无法识别某些api的问题">解决eclipse无法识别某些API的问题</h1>
<p>#移动开发 #android</p>
<p>1. 问题分析<br />
有些与系统关系紧密的应用程序，使用 eclipse 开发的时候，会出现 ”cannot be
resolved to a type”<br />
之类的提示，以至于无法正常编译调试。其原因 eclipse 中所能识别的 android
api 只是本地 Android SDK 目录中<br />
android.jar 中打包的内容，如 android-<br />
sdk_eng.root_linux-x86/platforms/android-1.6/android.jar ，可使用增加
android.jar<br />
中缺少的 api 的方法解决此问题。</p>
<p>2. 解决方法</p>
<ol type="1">
<li><p>首先要下载 SDK 相应的 android 源码，因为只有在源码中才有这些 api
的实现</p></li>
<li><p>然后按以下方法把你所需要的 api 打进 android.jar 之中<br />
_ $ mkdir android-full<br />
$ cd android-full<br />
$ jar -xvf<br />
$ANDROID_SRC_DIR/out/target/common/obj/JAVA_LIBRARIES/framework_intermediates/classes.jar<br />
$ jar -xvf<br />
$ANDROID_SRC_DIR/out/target/common/obj/JAVA_LIBRARIES/ext_intermediates/classes.jar<br />
$ jar -xvf<br />
$ANDROID_SRC_DIR/out/target/common/obj/JAVA_LIBRARIES/core_intermediates/classes.jar<br />
$ jar -xvf<br />
$ANDROID_SRC_DIR/out/target/common/obj/JAVA_LIBRARIES/android.test.runner_intermediates/classes.jar<br />
$ jar -xvf
$ANDROID_SRC_DIR/out/target/common/obj/JAVA_LIBRARIES/google-<br />
framework_intermediates/javalib.jar<br />
$ jar cvf ../android-full.jar *<br />
$ cd $ANDROID_SDK_DIR/platforms/android-1.6/<br />
$ cp /home/xieyan/test/android-full.jar ./ _</p></li>
</ol>
]]></content>
      <tags>
        <tag>移动开发</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title>Dash入门</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%A4%A7%E6%95%B0%E6%8D%AE/Dash%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h1 id="dash入门">Dash入门</h1>
<p>#大数据 #Python</p>
<h3 id="说明">1. 说明</h3>
<p> 大数据开发过程中，我们常常需要向别人展示一些统计结果，有时候还是实时的统计结果。最好能以网页方式提供，让别人在他的机器上，使用浏览器也能访问。这时候统计工具往往使用Python，而把分析图表画出来使用JavaScript，需要搭建web服务，还涉及中间过程的数据衔接。而Dash能帮我们实现以上所有的工作。</p>
<p> Dash是Python的一个库，使用pip即可安装。用它可以启动一个http server，
python调用它做图，而它内部将这些图置换成JavaScript显示，进行数据分析和展示。</p>
<h3 id="安装">2. 安装</h3>
<pre><code>$ pip install dash  
$ pip install dash-renderer  
$ pip install dash-html-components  
$ pip install dash-core-components  </code></pre>
<p> 其中html与网页相关，比如用它实现Title显示及一些与用户的交互操作，core是绘图部分，像我们常用的柱图，饼图，箱图，线图，都可以用它实现。</p>
<h3 id="简单demo">3. 简单demo</h3>
<p><strong>(1) 代码</strong></p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -*- coding: utf-8 -*-  </span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> dash  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> dash_core_components  </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> dash_html_components  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy  </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> numpy.linspace(<span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span> numpy.pi, <span class="dv">100</span>)  </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> <span class="dv">10</span> <span class="op">*</span> <span class="dv">2</span> <span class="op">*</span> numpy.cos(t)  </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>app <span class="op">=</span> dash.Dash()  </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>app.layout <span class="op">=</span> dash_html_components.Div(children<span class="op">=</span>[  </span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a> dash_html_components.H1(children<span class="op">=</span><span class="st">&#39;Testme&#39;</span>),  </span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a> dash_core_components.Graph(  </span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a> <span class="bu">id</span><span class="op">=</span><span class="st">&#39;curve&#39;</span>,  </span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a> figure<span class="op">=</span>&#123;  </span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;data&#39;</span>: [  </span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a> &#123;<span class="st">&#39;x&#39;</span>: x, <span class="st">&#39;y&#39;</span>: y, <span class="st">&#39;type&#39;</span>: <span class="st">&#39;Scatter&#39;</span>, <span class="st">&#39;name&#39;</span>: <span class="st">&#39;Testme&#39;</span>&#125;,  </span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a> ],  </span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;layout&#39;</span>: &#123;  </span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;title&#39;</span>: <span class="st">&#39;Test Curve&#39;</span>  </span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a> &#125; &#125; )  </span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>])  </span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&#39;__main__&#39;</span>:  </span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a> app.run_server(debug<span class="op">=</span><span class="va">True</span>, host<span class="op">=</span><span class="st">&#39;0.0.0.0&#39;</span>, port<span class="op">=</span><span class="dv">8051</span>)  </span></code></pre></div>
<p><strong>(2) 运行结果</strong></p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-3c60525093f9968a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p><strong>(3) 注意事项</strong><br />
 需要注意的是最后一句中的宿主机host='0.0.0.0'，默认是127.0.0.1，这样在其它机器访问本机启动的dash以及在docker启动dash时可能遇到问题，设置成0.0.0.0后，通过本机上的任意一个IPV4地址都能访问到它。</p>
<h3 id="与flask相结合支持显示多个页面">4.
与Flask相结合支持显示多个页面</h3>
<p> 用上述方法，可以提供单个网页显示，但如果需要展示的内容很多，或者需要分类展示时，就需要提供多个界面以及在各个界面间跳转。Flask是一个使用
Python 编写的轻量级 Web
应用框架，Dash的Web框架就是调用它实现的，在程序中结合二者，即可以显示一网页，还能实现Dash画图功能，还能相互调用，具体见下例。</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -*- coding: utf-8 -*-  </span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> flask <span class="im">import</span> Flask  </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> dash  </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> dash_core_components <span class="im">as</span> dcc  </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> dash_html_components <span class="im">as</span> html  </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>server <span class="op">=</span> Flask(<span class="va">__name__</span>)  </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>app1 <span class="op">=</span> dash.Dash(<span class="va">__name__</span>, server<span class="op">=</span>server, url_base_pathname<span class="op">=</span><span class="st">&#39;/dash/&#39;</span>)  </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>app1.layout <span class="op">=</span> html.Div([  </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    html.Div(  </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        children<span class="op">=</span>[html.H1(children<span class="op">=</span><span class="st">&#39;趋势 1&#39;</span>),]  </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    )      </span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    ])  </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="at">@server.route</span>(<span class="st">&#39;/test&#39;</span>)  </span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> do_test():  </span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">&quot;aaaaaaaaaaaaaaaaa&quot;</span>  </span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="at">@server.route</span>(<span class="st">&#39;/&#39;</span>)  </span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> do_main():  </span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">&quot;main&quot;</span>  </span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&#39;__main__&#39;</span>:  </span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    server.run(debug<span class="op">=</span><span class="va">True</span>, port<span class="op">=</span><span class="dv">8501</span>, host<span class="op">=</span><span class="st">&quot;0.0.0.0&quot;</span>)  </span></code></pre></div>
<p> 此时，在浏览器中分别打开：http://0.0.0.0:8501/,
http://0.0.0.0:8501/test，http://0.0.0.0:8501/dash，这时可以分别看dash生在网页和普通网页。</p>
<h3 id="各种常用图">5. 各种常用图</h3>
<p><strong>(1) 环境</strong><br />
 三个例中使用的数据库中sklearn自带的iris数据集的前30个实例，以test*方式调用每种绘图函数</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> dash  </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> dash_core_components  </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> dash_html_components  </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets  </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.figure_factory <span class="im">as</span> ff  </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>iris<span class="op">=</span>datasets.load_iris()  </span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame(iris.data, columns<span class="op">=</span>[<span class="st">&#39;SpealLength&#39;</span>, <span class="st">&#39;Spealwidth&#39;</span>,  </span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>                                        <span class="st">&#39;PetalLength&#39;</span>, <span class="st">&#39;PetalLength&#39;</span>])  </span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[:<span class="dv">30</span>]  </span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>app <span class="op">=</span> dash.Dash()  </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>test4(app, data)  </span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>app.run_server(debug<span class="op">=</span><span class="va">True</span>)  </span></code></pre></div>
<p><strong>(2) 线图</strong></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-c01357246d5ad678.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test1(app, data):  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> np.array(data[<span class="st">&#39;SpealLength&#39;</span>])  </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="bu">range</span>(<span class="bu">len</span>(y))  </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    app.layout <span class="op">=</span> dash_html_components.Div(children<span class="op">=</span>[  </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        dash_html_components.H1(children<span class="op">=</span><span class="st">&#39;Demo&#39;</span>),  </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        dash_core_components.Graph(  </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>            <span class="bu">id</span><span class="op">=</span><span class="st">&#39;line&#39;</span>,  </span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>            figure<span class="op">=</span>&#123;  </span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;data&#39;</span>: [  </span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>                    &#123;<span class="st">&#39;x&#39;</span>: x, <span class="st">&#39;y&#39;</span>: y, <span class="st">&#39;type&#39;</span>: <span class="st">&#39;Scatter&#39;</span>, <span class="st">&#39;name&#39;</span>: <span class="st">&#39;Line&#39;</span>&#125;,  </span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>                ],  </span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;layout&#39;</span>: &#123;  </span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&#39;title&#39;</span>: <span class="st">&#39;线图&#39;</span>  </span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>                &#125;  </span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>            &#125;  </span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        )  </span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    ])  </span></code></pre></div>
<p><strong>(3) 柱图</strong></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-97bf9f48da7f2967.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test2(app, data):  </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> np.array(data[<span class="st">&#39;SpealLength&#39;</span>])  </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="bu">range</span>(<span class="bu">len</span>(y))  </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    app.layout <span class="op">=</span> dash_html_components.Div(children<span class="op">=</span>[  </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        dash_html_components.H1(children<span class="op">=</span><span class="st">&#39;Demo&#39;</span>),  </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        dash_core_components.Graph(  </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>            <span class="bu">id</span><span class="op">=</span><span class="st">&#39;bar&#39;</span>,  </span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>            figure<span class="op">=</span>&#123;  </span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;data&#39;</span>: [  </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>                    &#123;<span class="st">&#39;x&#39;</span>: x, <span class="st">&#39;y&#39;</span>: y, <span class="st">&#39;type&#39;</span>: <span class="st">&#39;bar&#39;</span>, <span class="st">&#39;name&#39;</span>: <span class="st">&#39;Bar&#39;</span>&#125;,  </span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>                ],  </span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;layout&#39;</span>: &#123;  </span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&#39;title&#39;</span>: <span class="st">&#39;柱图&#39;</span>  </span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>                &#125;  </span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>            &#125;  </span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        )  </span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    ])  </span></code></pre></div>
<p><strong>(4) 直方图</strong></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-84bb04284812c498.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test3(app, data):  </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> np.array(data[<span class="st">&#39;SpealLength&#39;</span>])  </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    app.layout <span class="op">=</span> dash_html_components.Div(children<span class="op">=</span>[  </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>        dash_html_components.H1(children<span class="op">=</span><span class="st">&#39;Demo&#39;</span>),  </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        dash_core_components.Graph(  </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>            <span class="bu">id</span><span class="op">=</span><span class="st">&#39;hist&#39;</span>,  </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>            figure<span class="op">=</span>&#123;  </span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;data&#39;</span>: [  </span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">dict</span>(  </span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>                        <span class="bu">type</span><span class="op">=</span><span class="st">&#39;histogram&#39;</span>, x<span class="op">=</span>y, name<span class="op">=</span><span class="st">&#39;Hist&#39;</span>  </span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>                    )  </span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>                ],  </span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;layout&#39;</span>: &#123;  </span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&#39;title&#39;</span>: <span class="st">&#39;直方图&#39;</span>  </span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>                &#125;  </span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>            &#125;  </span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>        )  </span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    ])  </span></code></pre></div>
<p><strong>(5) 箱图</strong></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-02f0978003353abb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test4(app, data):  </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    data[<span class="st">&#39;group1&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;SpealLength&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="bu">int</span>(x <span class="op">*</span> <span class="dv">4</span>) <span class="op">/</span> <span class="fl">4.0</span>)  </span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> data[<span class="st">&#39;group1&#39;</span>] <span class="co"># 按length分类，统计width  </span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> np.array(data[<span class="st">&#39;Spealwidth&#39;</span>])  </span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    app.layout <span class="op">=</span> dash_html_components.Div(children<span class="op">=</span>[  </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        dash_html_components.H1(children<span class="op">=</span><span class="st">&#39;Demo&#39;</span>),  </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        dash_core_components.Graph(  </span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>            <span class="bu">id</span><span class="op">=</span><span class="st">&#39;box&#39;</span>,  </span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>            figure<span class="op">=</span>&#123;  </span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;data&#39;</span>: [  </span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">dict</span>(  </span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>                        <span class="bu">type</span><span class="op">=</span><span class="st">&#39;box&#39;</span>, x<span class="op">=</span>x, y<span class="op">=</span>y, name<span class="op">=</span><span class="st">&#39;Box&#39;</span>  </span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>                    )  </span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>                ],  </span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;layout&#39;</span>: &#123;  </span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&#39;title&#39;</span>: <span class="st">&#39;箱图&#39;</span>  </span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>                &#125;  </span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>            &#125;  </span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>        )  </span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    ])  </span></code></pre></div>
<p>箱图比较特殊，它是按x的unique统计y的分布。</p>
<p><strong>(6) 饼图</strong></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-7a42dd31929d6f97.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test5(app, data):      </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    data[<span class="st">&#39;group1&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;SpealLength&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="bu">int</span>(x))  </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    tmp <span class="op">=</span> data.groupby(<span class="st">&#39;group1&#39;</span>).size().to_frame()  </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    tmp <span class="op">=</span> tmp.rename(columns<span class="op">=</span>&#123;<span class="dv">0</span>: <span class="st">&#39;num&#39;</span>&#125;)  </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    tmp <span class="op">=</span> np.<span class="bu">round</span>(tmp, <span class="dv">4</span>).reset_index(drop<span class="op">=</span><span class="va">False</span>)  </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    app.layout <span class="op">=</span> dash_html_components.Div(children<span class="op">=</span>[  </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        dash_html_components.H1(children<span class="op">=</span><span class="st">&#39;Demo&#39;</span>),  </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>        dash_core_components.Graph(  </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>            <span class="bu">id</span><span class="op">=</span><span class="st">&#39;pie&#39;</span>,  </span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>            figure<span class="op">=</span>&#123;  </span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>              <span class="st">&#39;data&#39;</span>: [  </span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">dict</span>(  </span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>                        <span class="bu">type</span><span class="op">=</span><span class="st">&#39;pie&#39;</span>, name<span class="op">=</span><span class="st">&#39;Pie&#39;</span>,  </span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>                        labels<span class="op">=</span>tmp[<span class="st">&#39;group1&#39;</span>].tolist(),  </span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>                        values<span class="op">=</span>tmp[<span class="st">&#39;num&#39;</span>].tolist(),  </span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>                    )                    </span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>                ],  </span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;layout&#39;</span>: &#123;  </span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&#39;title&#39;</span>: <span class="st">&#39;饼图&#39;</span>  </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>                &#125;  </span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>            &#125;  </span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>        )  </span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    ])  </span></code></pre></div>
<p><strong>(7) 图表</strong></p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-9fb3075d6677d390.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test6(app, data):  </span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    table <span class="op">=</span> ff.create_table(data.head())   </span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(table.layout.annotations)):  </span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>        table.layout.annotations[i].font.size <span class="op">=</span> <span class="dv">15</span>  </span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    app.layout <span class="op">=</span> dash_html_components.Div(children<span class="op">=</span>[  </span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        dash_html_components.H1(children<span class="op">=</span><span class="st">&#39;Demo&#39;</span>),  </span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        dash_core_components.Graph(  </span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>            <span class="bu">id</span><span class="op">=</span><span class="st">&#39;table&#39;</span>,  </span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>            figure<span class="op">=</span>table  </span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        )  </span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    ])  </span></code></pre></div>
<h3 id="参考">6. 参考</h3>
<p><strong>(1) 官方demo</strong><br />
<a
href="https://dash.plot.ly/gallery">https://dash.plot.ly/gallery</a></p>
<p><strong>(2) 支持多个网页的另一种方法</strong><br />
<a
href="https://stackoverflow.com/questions/51946300/setting-up-a-python-dash-dashboard-inside-a-flask-app">https://stackoverflow.com/questions/51946300/setting-up-a-python-dash-dashboard-inside-a-flask-app</a></p>
<p><strong>(3) 最常用例程</strong><br />
https://dash.plot.ly/getting-started</p>
<p><strong>(4) dash各种界面交互(最后边)</strong><br />
https://dash.plot.ly/getting-started</p>
<p><strong>(5) dash交互中各种callback处理</strong><br />
https://dash.plot.ly/getting-started-part-2</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Python之DataFrame数据处理</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%A4%A7%E6%95%B0%E6%8D%AE/Python%E4%B9%8BDataFrame%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<h1 id="python之dataframe数据处理">Python之DataFrame数据处理</h1>
<p>#Python</p>
<h2 id="说明">1. 说明</h2>
<p> DataFrame是Pandas库中处理表的数据结构，可看作是python中的类似数据库的操作，是Python数据挖掘中最常用的工具。下面介绍DataFrame的一些常用方法。</p>
<h2 id="遍历">2. 遍历</h2>
<h4 id="代码">1) 代码</h4>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>pd.DataFrame(&#123;<span class="st">&#39;key&#39;</span>:[<span class="st">&#39;a&#39;</span>,<span class="st">&#39;b&#39;</span>,<span class="st">&#39;c&#39;</span>],<span class="st">&#39;data1&#39;</span>:[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>],<span class="st">&#39;data2&#39;</span>:[<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>]&#125;)    </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx,item <span class="kw">in</span> df.iterrows():  </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(idx)  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(item)  </span></code></pre></div>
<h4 id="结果">2) 结果</h4>
<pre><code>   data1  data2 key  
0      1      4   a  
1      2      5   b  
2      3      6   c  
0  
data1    1  
data2    4  
key      a  
Name: 0, dtype: object  
… 略  </code></pre>
<h2 id="同时遍历两个数据表">3. 同时遍历两个数据表</h2>
<h4 id="代码-1">1) 代码</h4>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>df1<span class="op">=</span>pd.DataFrame(&#123;<span class="st">&#39;key&#39;</span>:[<span class="st">&#39;a&#39;</span>,<span class="st">&#39;b&#39;</span>],<span class="st">&#39;data1&#39;</span>:[<span class="dv">1</span>,<span class="dv">2</span>]&#125;)    </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>df2<span class="op">=</span>pd.DataFrame(&#123;<span class="st">&#39;key&#39;</span>:[<span class="st">&#39;c&#39;</span>,<span class="st">&#39;d&#39;</span>],<span class="st">&#39;data2&#39;</span>:[<span class="dv">4</span>,<span class="dv">5</span>]&#125;)    </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (idx1,item1),(idx2,item2) <span class="kw">in</span> <span class="bu">zip</span>(df1.iterrows(),df2.iterrows()):  </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;idx1&quot;</span>,idx1)  </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(item1)  </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;idx2&quot;</span>,idx2)  </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(item2)  </span></code></pre></div>
<h4 id="结果-1">2) 结果</h4>
<pre><code>(&#39;idx1&#39;, 0)  
data1    1  
key      a  
Name: 0, dtype: object  
(&#39;idx2&#39;, 0)  
data2    4  
key      c  
Name: 0, dtype: object  
(&#39;idx1&#39;, 1)  
data1    2  
key      b  
Name: 1, dtype: object  
(&#39;idx2&#39;, 1)  
data2    5  
key      d  
Name: 1, dtype: object  </code></pre>
<h2 id="取一行或多行">4. 取一行或多行</h2>
<h4 id="代码-2">1) 代码</h4>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math  </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>df1<span class="op">=</span>pd.DataFrame(&#123;<span class="st">&#39;key&#39;</span>:[<span class="st">&#39;a&#39;</span>,<span class="st">&#39;b&#39;</span>,<span class="st">&#39;c&#39;</span>],<span class="st">&#39;data1&#39;</span>:[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>]&#125;)    </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>df2<span class="op">=</span>df1[:<span class="dv">1</span>]  </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df2)  </span></code></pre></div>
<h4 id="结果-2">2) 结果</h4>
<pre><code>   data1 key  
0      1   a  </code></pre>
<h2 id="取一列或多列">5. 取一列或多列</h2>
<h4 id="代码-3">1) 代码</h4>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math  </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>df1<span class="op">=</span>pd.DataFrame(&#123;<span class="st">&#39;key&#39;</span>:[<span class="st">&#39;a&#39;</span>,<span class="st">&#39;b&#39;</span>,<span class="st">&#39;c&#39;</span>],<span class="st">&#39;data1&#39;</span>:[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>]&#125;)    </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>df2<span class="op">=</span>pd.DataFrame()  </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>df2[<span class="st">&#39;key2&#39;</span>]<span class="op">=</span>df1[<span class="st">&#39;key&#39;</span>]  </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df2)  </span></code></pre></div>
<h4 id="结果-3">2) 结果</h4>
<pre><code>  key2  
0    a  
1    b  
2    c  </code></pre>
<h2 id="列连接横向变宽merge">6. 列连接（横向：变宽）：merge</h2>
<h4 id="代码-4">1) 代码</h4>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>df1<span class="op">=</span>pd.DataFrame(&#123;<span class="st">&#39;key&#39;</span>:[<span class="st">&#39;a&#39;</span>,<span class="st">&#39;b&#39;</span>,<span class="st">&#39;c&#39;</span>],<span class="st">&#39;data1&#39;</span>:[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>]&#125;)    </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>df2<span class="op">=</span>pd.DataFrame(&#123;<span class="st">&#39;key&#39;</span>:[<span class="st">&#39;a&#39;</span>,<span class="st">&#39;b&#39;</span>,<span class="st">&#39;c&#39;</span>],<span class="st">&#39;data2&#39;</span>:[<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>]&#125;)   </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>df3<span class="op">=</span>pd.merge(df1,df2)  </span></code></pre></div>
<h4 id="结果-4">2) 结果</h4>
<pre><code>   data1 key  
0      1   a  
1      2   b  
2      3   c  
   data2 key  
0      4   a  
1      5   b  
2      6   c  
   data1 key  data2  
0      1   a      4  
1      2   b      5  
2      3   c      6  </code></pre>
<h2 id="行连接纵向变长concat">7. 行连接（纵向：变长）：concat</h2>
<h4 id="代码-5">1) 代码</h4>
<pre><code>import pandas as pd  
  
df1=pd.DataFrame(&#123;&#39;key&#39;:[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;],&#39;data&#39;:[1,2,3]&#125;)    
df2=pd.DataFrame(&#123;&#39;key&#39;:[&#39;d&#39;,&#39;e&#39;,&#39;f&#39;],&#39;data&#39;:[4,5,6]&#125;)   
df3=pd.concat([df1,df2])  </code></pre>
<h4 id="结果-5">2) 结果</h4>
<pre><code>   data key  
0     1   a  
1     2   b  
2     3   c  
   data key  
0     4   d  
1     5   e  
2     6   f  
   data key  
0     1   a  
1     2   b  
2     3   c  
0     4   d  
1     5   e  
2     6   f  </code></pre>
<h2 id="对某列做简单变换">8. 对某列做简单变换</h2>
<h4 id="代码-6">1) 代码</h4>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>pd.DataFrame(&#123;<span class="st">&#39;key&#39;</span>:[<span class="st">&#39;a&#39;</span>,<span class="st">&#39;b&#39;</span>,<span class="st">&#39;c&#39;</span>],<span class="st">&#39;data1&#39;</span>:[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>]&#125;)    </span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)  </span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;data1&#39;</span>]<span class="op">=</span>df[<span class="st">&#39;data1&#39;</span>]<span class="op">+</span><span class="dv">1</span>  </span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)  </span></code></pre></div>
<h4 id="结果-6">2) 结果</h4>
<pre><code>   data1 key  
0      1   a  
1      2   b  
2      3   c  
   data1 key  
0      2   a  
1      3   b  
2      4   c  </code></pre>
<h2 id="对某列做复杂变换">9. 对某列做复杂变换</h2>
<h4 id="代码-7">1) 代码</h4>
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math  </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>pd.DataFrame(&#123;<span class="st">&#39;key&#39;</span>:[<span class="st">&#39;a&#39;</span>,<span class="st">&#39;b&#39;</span>,<span class="st">&#39;c&#39;</span>],<span class="st">&#39;data1&#39;</span>:[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>]&#125;)    </span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)  </span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;data1&#39;</span>]<span class="op">=</span>df[<span class="st">&#39;data1&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: math.sin(x))  </span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)  </span></code></pre></div>
<h4 id="结果-7">2) 结果</h4>
<pre><code>   data1 key  
0      1   a  
1      2   b  
2      3   c  
      data1 key  
0  0.841471   a  
1  0.909297   b  
2  0.141120   c  </code></pre>
<h2 id="对某列做函数处理">10. 对某列做函数处理</h2>
<h4 id="代码-8">1) 代码</h4>
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> testme(x):  </span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;???&quot;</span>,x)  </span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> x <span class="op">+</span> <span class="dv">3000</span>  </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y  </span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>pd.DataFrame(&#123;<span class="st">&#39;key&#39;</span>:[<span class="st">&#39;a&#39;</span>,<span class="st">&#39;b&#39;</span>,<span class="st">&#39;c&#39;</span>],<span class="st">&#39;data1&#39;</span>:[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>]&#125;)    </span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)  </span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;data1&#39;</span>]<span class="op">=</span>df[<span class="st">&#39;data1&#39;</span>].<span class="bu">apply</span>(testme)  </span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)  </span></code></pre></div>
<h4 id="结果-8">2) 结果</h4>
<pre><code>   data1 key  
0      1   a  
1      2   b  
2      3   c  
(&#39;???&#39;, 1)  
(&#39;???&#39;, 2)  
(&#39;???&#39;, 3)  
   data1 key  
0   3001   a  
1   3002   b  
2   3003   c  </code></pre>
<h2 id="用某几列计算生成新列">11. 用某几列计算生成新列</h2>
<h4 id="代码-9">1) 代码</h4>
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>pd.DataFrame(&#123;<span class="st">&#39;key&#39;</span>:[<span class="st">&#39;a&#39;</span>,<span class="st">&#39;b&#39;</span>,<span class="st">&#39;c&#39;</span>],<span class="st">&#39;data1&#39;</span>:[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>],<span class="st">&#39;data2&#39;</span>:[<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>]&#125;)    </span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)  </span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;data3&#39;</span>]<span class="op">=</span>df[<span class="st">&#39;data1&#39;</span>]<span class="op">+</span>df[<span class="st">&#39;data2&#39;</span>]  </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)  </span></code></pre></div>
<h4 id="结果-9">2) 结果</h4>
<pre><code>   data1  data2 key  
0      1      4   a  
1      2      5   b  
2      3      6   c  
   data1  data2 key  data3  
0      1      4   a      5  
1      2      5   b      7  
2      3      6   c      9  </code></pre>
<h2 id="用某几列用函数生成新列">12. 用某几列用函数生成新列</h2>
<h4 id="代码-10">1) 代码</h4>
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math  </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> testme(x):  </span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(x[<span class="st">&#39;data1&#39;</span>],x[<span class="st">&#39;data2&#39;</span>])  </span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x[<span class="st">&#39;data1&#39;</span>] <span class="op">+</span> x[<span class="st">&#39;data2&#39;</span>]  </span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>pd.DataFrame(&#123;<span class="st">&#39;key&#39;</span>:[<span class="st">&#39;a&#39;</span>,<span class="st">&#39;b&#39;</span>,<span class="st">&#39;c&#39;</span>],<span class="st">&#39;data1&#39;</span>:[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>],<span class="st">&#39;data2&#39;</span>:[<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>]&#125;)    </span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)  </span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;data3&#39;</span>]<span class="op">=</span>df.<span class="bu">apply</span>(testme, axis<span class="op">=</span><span class="dv">1</span>)  </span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)  </span></code></pre></div>
<h4 id="结果-10">2) 结果</h4>
<pre><code>   data1  data2 key  
0      1      4   a  
1      2      5   b  
2      3      6   c  
(1, 4)  
(2, 5)  
(3, 6)  
   data1  data2 key  data3  
0      1      4   a      5  
1      2      5   b      7  
2      3      6   c      9  </code></pre>
<h2 id="删除列">13. 删除列</h2>
<h4 id="代码-11">1) 代码</h4>
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math  </span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>pd.DataFrame(&#123;<span class="st">&#39;key&#39;</span>:[<span class="st">&#39;a&#39;</span>,<span class="st">&#39;b&#39;</span>,<span class="st">&#39;c&#39;</span>],<span class="st">&#39;data1&#39;</span>:[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>],<span class="st">&#39;data2&#39;</span>:[<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>]&#125;)    </span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)  </span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>df.drop([<span class="st">&#39;data2&#39;</span>],axis<span class="op">=</span><span class="dv">1</span>)  </span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)  </span></code></pre></div>
<h4 id="结果-11">2) 结果</h4>
<pre><code>   data1  data2 key  
0      1      4   a  
1      2      5   b  
2      3      6   c  
   data1 key  
0      1   a  
1      2   b  
2      3   c  </code></pre>
<h2 id="one-hot变换把一列枚举型变为多列数值型">14.
One-Hot变换（把一列枚举型变为多列数值型）</h2>
<h4 id="代码-12">1) 代码</h4>
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd  </span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math  </span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>df1<span class="op">=</span>pd.DataFrame(&#123;<span class="st">&#39;key&#39;</span>:[<span class="st">&#39;a&#39;</span>,<span class="st">&#39;b&#39;</span>,<span class="st">&#39;c&#39;</span>],<span class="st">&#39;data1&#39;</span>:[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>]&#125;)    </span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df1)  </span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>df2<span class="op">=</span>pd.get_dummies(df1[<span class="st">&#39;key&#39;</span>])  </span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df2)  </span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>df3<span class="op">=</span>pd.get_dummies(df1)  </span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df3)  </span></code></pre></div>
<h4 id="结果-12">2) 结果</h4>
<pre><code>   data1 key  
0      1   a  
1      2   b  
2      3   c  
   a  b  c  
0  1  0  0  
1  0  1  0  
2  0  0  1  
   data1  key_a  key_b  key_c  
0      1      1      0      0  
1      2      0      1      0  
2      3      0      0      1  </code></pre>
<h2 id="其它常用方法">15. 其它常用方法</h2>
<h4 id="求均值方差中位数等">1) 求均值方差，中位数等</h4>
<p>df[f].describe()</p>
<h4 id="求均值">2) 求均值</h4>
<p>df[f].mean()</p>
<h4 id="求方差">3) 求方差</h4>
<p>df[f].std()</p>
<h4 id="清除空值">4) 清除空值</h4>
<p>df.dropna()</p>
<h4 id="填充空值">5) 填充空值</h4>
<p>df.fillna()</p>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python函数绘图</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%A4%A7%E6%95%B0%E6%8D%AE/Python%E5%87%BD%E6%95%B0%E7%BB%98%E5%9B%BE/</url>
    <content><![CDATA[<h1 id="python函数绘图">Python函数绘图</h1>
<p>#Python</p>
<p>最近看数学，发现有时候画个图还真管用，对理解和展示效果都不错。尤其是三维空间和一些复杂函数，相当直观，也有助于解题。<br />
本来想用mathlab，下载安装都太费事，杀鸡不用牛刀，Python基本就能实现，三维图还可以拖动图像来回旋转。<br />
下面分别在二维三维举例说明。</p>
<h2 id="二维绘图">1. 二维绘图</h2>
<ol type="1">
<li><pre><code>   描述：  </code></pre>
绘制极坐标系中r=1和r=2cosθ的相交部分（没画的时候，确实没看出r=2cosθ也是正圆）<br />
</li>
<li><pre><code>  程序  </code></pre></li>
</ol>
<pre><code>import numpy as np  
import matplotlib.pyplot as plt  
  
plt.figure(1)  
ax = plt.subplot(111)  
x = np.linspace(0, np.pi * 2, 200)  # 在0到2pi之间，均匀产生200点的数组  
   
# r = 2cosθ  
r = 2 * np.cos(x)  # 半径  
ax.plot(r * np.cos(x), r * np.sin(x))  
  
# r = 1  
r = 1  
ax.plot(r * np.cos(x), r * np.sin(x))  
plt.show()  </code></pre>
<ol start="3" type="1">
<li><pre><code>   运行结果  </code></pre></li>
</ol>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-441050ff2aad60c0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<h2 id="三维绘图">2. 三维绘图</h2>
<ol type="1">
<li><pre><code>   描述：  </code></pre>
绘制向量函数r(t)=(sint,cost,t)的图，可将函数视为“大黄蜂”的飞行曲线，即t时刻，它在空间中的位置是（x,y,z）。即向量r的坐标x,y,z都是t的函数，分别是x(t)=sint,
y(t)=cost,
z(t)=t。并且绘制它的导数（飞行速度）r’(t)=(cost,-sint,1)<br />
</li>
<li><pre><code>  程序  </code></pre></li>
</ol>
<pre><code>import numpy as np  
import matplotlib.pyplot as plt  
from mpl_toolkits.mplot3d import Axes3D  
  
fig = plt.figure(1)  
ax = fig.add_subplot(1,1,1,projection=&#39;3d&#39;) # 指定三维空间做图   
  
t = np.linspace(0, 4, 200)  # 在0到4之间，均匀产生200点的数组  
theta = t * 2 * np.pi # 角度  
   
# r(t)=(sint,cost,t)  
z = t   
x = np.sin(theta)  
y = np.cos(theta)  
ax.plot(x, y, z, label=&#39;r(t)&#39;)  
   
# r’(t)  
z = 1   
x = np.cos(theta)  
y = -np.sin(theta)  
ax.plot(x, y, z, label=&#39;r\&#39;(t)&#39;)  
   
ax.legend()  
plt.show()  </code></pre>
<ol start="3" type="1">
<li><pre><code>   运行结果  </code></pre></li>
</ol>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-064d5258e33aac65.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<h2 id="三维曲面">3. 三维曲面</h2>
<ol type="1">
<li>描述<br />
绘制曲面 z = x^2 + y^2<br />
</li>
<li>程序<br />
</li>
</ol>
<pre><code>from matplotlib import pyplot as plt  
import numpy as np  
from mpl_toolkits.mplot3d import Axes3D  
  
fig = plt.figure()  
ax = Axes3D(fig)  
X = np.arange(-2, 2, 0.1)  
Y = np.arange(-2, 2, 0.1)  
X, Y = np.meshgrid(X, Y)  
Z = X**2 + Y**2  
  
ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=&#39;rainbow&#39;)  
plt.show()  </code></pre>
<ol start="3" type="1">
<li>运行结果</li>
</ol>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-ae3e7916e2d9e0cc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python海量数据处理之_Hadoop&amp;Spark</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%A4%A7%E6%95%B0%E6%8D%AE/Python%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%B9%8B_Hadoop&amp;Spark/</url>
    <content><![CDATA[<h1
id="python海量数据处理之_hadoopspark">Python海量数据处理之_Hadoop&amp;Spark</h1>
<p>#大数据</p>
<h2 id="说明">1. 说明</h2>
<p> 前篇介绍了安装和使用Hadoop，本篇将介绍Hadoop+Spark的安装配置及如何用Python调用Spark。<br />
 当数据以TB,PB计量时，用单机处理数据变得非常困难，于是使用Hadoop建立计算集群处理海量数据，Hadoop分为两部分，一部分是数据存储HDFS，另一部分是数据计算MapReduce。MapReduce框架将数据处理分成map,reduce两段，使用起来比较麻烦，并且有一些限制，如：数据都是流式的，且必须所有Map结束后才能开始Reduce。我们可以引入Spark加以改进。<br />
 Spark的优点在于它的中间结果保存在内存中，而非HDFS文件系统中，所以速度很快。用Scala
语言可以像操作本地集合对象一样轻松地操作分布式数据集。虽然它支持中间结果保存在内存，但集群中的多台机器仍然需要读写数据集，所以它经常与HDFS共同使用。因此，它并非完全替代Hadoop。<br />
 Spark的框架是使用Scala语言编写的，Spark的开发可以使用语言有：Scala、R语言、Java、Python。</p>
<h2 id="scala">2. Scala</h2>
<p> Scala是一种类似java的编程语言，使用Scala语言相对来说代码量更少，调用spark更方便，也可以将它和其它程序混用。<br />
 在不安装scala的情况下，启动hadoop和spark，python的基本例程也可以正常运行。但出于进一步开发的需要，最好安装scala。</p>
<h4 id="下载scala">(1) 下载scala</h4>
<p> http://www.scala-lang.org/download/<br />
 我下载的是与spark中一致的2.11版本的非源码tgz包</p>
<h4 id="安装">(2) 安装</h4>
<pre><code>$ cd /home/hadoop #用户可选择安装的文件夹  
$ tar xvzf tgz/scala-2.11.12.tgz  
$ ln -s scala-2.11.12/ scala  
  
在.bashrc中加入  
export PATH=/home/hadoop/scala/bin:$PATH  </code></pre>
<h2 id="下载安装spark">3. 下载安装Spark</h2>
<h4 id="下载spark">(1) 下载spark</h4>
<p> http://spark.apache.org/downloads.html<br />
 我下载的版本是：spark-2.2.1-bin-hadoop.2.7.tgz</p>
<h4 id="安装spark">(2) 安装spark</h4>
<pre><code>$ cd /home/hadoop #用户可选择安装的文件夹  
$ tar xvzf spark-2.2.1-bin-hadoop2.7.tgz  
$ ln -s spark-2.2.1-bin-hadoop2.7/ spark  
  
在.bashrc中加入  
export SPARK_HOME=/home/hadoop/spark  
export PATH=$SPARK_HOME/bin:$PATH  </code></pre>
<h4 id="配置文件">(3) 配置文件</h4>
<p> 不做配置，pyspark可以在本机上运行，但不能使用集群中其它机器。配置文件在$SPARK_HOME/conf/目录下。</p>
<ol type="i">
<li>配置spark-env.sh<br />
</li>
</ol>
<pre><code>$ cd $SPARK_HOME/conf/  
$ cp spark-env.sh.template spark-env.sh  
按具体配置填写内容  
export SCALA_HOME=/home/hadoop/scala  
export JAVA_HOME=/exports/android/jdk/jdk1.8.0_91/  
export SPARK_MASTER_IP=master  
export SPARK_WORKER_MEMORY=1g  
export HADOOP_CONF_DIR=/home/hadoop/hadoop/etc/hadoop/  </code></pre>
<ol start="2" type="i">
<li>设置主从服务器slave<br />
</li>
</ol>
<pre><code>$ cp slaves.template slaves   
在其中列出从服务器地址，单机不用设  </code></pre>
<ol start="3" type="i">
<li>设置spark-defaults.conf<br />
</li>
</ol>
<pre><code>$ cp conf/spark-defaults.conf.template conf/spark-defaults.conf  
按具体配置填写内容  
spark.master                     spark://master:7077  
spark.eventLog.enabled           false  
spark.serializer                 org.apache.spark.serializer.KryoSerializer  
spark.driver.memory              1g  
spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers=&quot;one two three&quot;  </code></pre>
<h4 id="启动">(4) 启动</h4>
<p> 运行spark之前，需要运行hadoop，具体见之前的Hadoop文档</p>
<pre><code>$ $SPARK_HOME/sbin/start-all.sh  </code></pre>
<p> 该脚本启动了所有master和workers，在本机用jps查看，增加了Worker和Master，</p>
<h2 id="命令行调用">4. 命令行调用</h2>
<p> 下面我们来看看从程序层面如何使用Spark</p>
<h4 id="准备工作">(1) 准备工作</h4>
<p> 在使用相对路径时，系统默认是从hdfs://localhost:9000/中读数据，因此需要先把待处理的本地文件复制到HDFS上，常用命令见之前的Hadoop有意思。</p>
<pre><code>$ hadoop fs -mkdir -p /usr/hadoop  
$ hadoop fs -copyFromLocal README.md /user/hadoop/  </code></pre>
<h4 id="spark命令行">(2) Spark命令行</h4>
<pre><code>$ pyspark  
&gt;&gt;&gt; textFile = spark.read.text(None)  
&gt;&gt;&gt; textFile.count() # 返回行数  
&gt;&gt;&gt; textFile.first() # 返回第一行  
&gt;&gt;&gt; linesWithSpark = textFile.filter(textFile.value.contains(&quot;Spark&quot;)) # 返回所有含Spark行的数据集  </code></pre>
<h2 id="程序">5. 程序</h2>
<h4 id="实现功能">(1) 实现功能</h4>
<p> 统计文件中的词频</p>
<h4 id="代码">(2) 代码</h4>
<p> 这里使用了spark自带的例程
/home/hadoop/spark/examples/src/main/python/wordcount.py，和之前介绍过的hadoop程序一样，同样是实现的针对key,value的map,reduce，一个文件就完成了，看起来更简徢更灵活，像是hadoop自带MapReduce的加强版。具体内容如下：</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> __future__ <span class="im">import</span> print_function  </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys   </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> operator <span class="im">import</span> add   </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession  </span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:  </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(sys.argv) <span class="op">!=</span> <span class="dv">2</span>:  </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Usage: wordcount &lt;file&gt;&quot;</span>, <span class="bu">file</span><span class="op">=</span>sys.stderr)  </span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        exit(<span class="op">-</span><span class="dv">1</span>)  </span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    spark <span class="op">=</span> SparkSession\  </span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>        .builder\  </span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        .appName(<span class="st">&quot;PythonWordCount&quot;</span>)\  </span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>        .getOrCreate()  </span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    lines <span class="op">=</span> spark.read.text(sys.argv[<span class="dv">1</span>]).rdd.<span class="bu">map</span>(<span class="kw">lambda</span> r: r[<span class="dv">0</span>])  </span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    counts <span class="op">=</span> lines.flatMap(<span class="kw">lambda</span> x: x.split(<span class="st">&#39; &#39;</span>)) \  </span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>                  .<span class="bu">map</span>(<span class="kw">lambda</span> x: (x, <span class="dv">1</span>)) \  </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>                  .reduceByKey(add)  </span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> counts.collect() <span class="co"># 收集结果  </span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (word, count) <span class="kw">in</span> output:  </span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;</span><span class="sc">%s</span><span class="st">: </span><span class="sc">%i</span><span class="st">&quot;</span> <span class="op">%</span> (word, count))  </span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    spark.stop()  </span></code></pre></div>
<h4 id="运行">(3) 运行</h4>
<p> spark-submit命令在$HOME_SPARK/bin目录下，之前设置了PATH，可以直接使用</p>
<pre><code>$ spark-submit $SPARK_HOME/examples/src/main/python/wordcount.py /user/hadoop/README.md  </code></pre>
<p> 参数是hdfs中的文件路径。<br />
 此时访问$SPARK_IP:8080端口，可以看到程序PythonWordCount正在hadoop中运行。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-b6bb7fb82de95704.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="多台机器上安装spark以建立集群">6.
多台机器上安装Spark以建立集群</h2>
<p> 和hadoop的集群设置类似，同样是把整个spark目录复制集群中其它的服务器上，用slaves文件设置主从关系，然后启动$SPARK_HOME/sbin/start-all.sh。正常开启后可以通过网页查看状态：SparkMaster_IP:8080</p>
<h2 id="参考">7. 参考</h2>
<ol type="1">
<li>官方帮助文档，具体见其python部分<br />
http://spark.apache.org/docs/latest/quick-start.html<br />
</li>
<li>Hadoop2.7.3+Spark2.1.0 完全分布式环境 搭建全过程<br />
https://www.cnblogs.com/purstar/p/6293605.html</li>
</ol>
]]></content>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Python海量数据处理之_Hadoop家族</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%A4%A7%E6%95%B0%E6%8D%AE/Python%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%B9%8B_Hadoop%E5%AE%B6%E6%97%8F/</url>
    <content><![CDATA[<h1
id="python海量数据处理之_hadoop家族">Python海量数据处理之_Hadoop家族</h1>
<p>#大数据</p>
<p> 本篇是hadoop部分的最后一篇，主要介绍Hadoop家族的常用工具。以及解答学习过程中的一些疑问。</p>
<h2 id="hadoop家族">hadoop家族</h2>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-db0d7ffa523be138.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> Pig是上层封装了的数据流处理工具。<br />
 Mahout是基于集群的数据挖掘工具。<br />
 Zookeeper是集群管理工具，比如配置一些备用服务器，当重要的服务宕机时，及时补救。<br />
 其中黄色部分是hadoop安装包中自带的，HDFS是文件系统支持，MapReduce是计算支持。<br />
 绿色部分都是向上层提供类似数据库的数据访问，但方式不同。Hive是基于MapReduce的封装，它向上层提供了类似SQL语言的HQL，向下通过MapReduce方式访问数据。HBase在对HDFS层的封装，它本质上是一种key/value系统，主要负责数据存储，解决的是HDFS随机存储方面的问题。</p>
<h2 id="有了mysql为什么还要hadoop">有了mysql为什么还要Hadoop?</h2>
<p> 我们之前介绍搭建比特币矿池的时候，使用zookeeper+kafka+mysql建立集群，其中用mysql建构数据服务器，集群中其它机器通过ip和端口访问其数据，配置方便，速度也不错。既然集群中可以使用mysql存储数据，那为什么还非要用hadoop系列存储工具呢？<br />
 mysql存放的是数据库，而hadoop系列存放的是数据仓库，一方面HDFS针对的是更大规模的数据，另一方面mysql的数据类型只限于数据库，而HDFS比较灵活，可以存储各种类型的数据。</p>
<h2 id="具体安装">具体安装</h2>
<p> 集群中的计算机软硬件可能有所差异，为了保证一致性，最好使用下载软件包的方式安装，而不用apt-get系列工具。一般的安装过程主要包括：下载，解包，设置环境变量，修改配置文件，启动等几个部分。</p>
]]></content>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Python海量数据处理之_Hadoop（一）集群搭建</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%A4%A7%E6%95%B0%E6%8D%AE/Python%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%B9%8B_Hadoop%EF%BC%88%E4%B8%80%EF%BC%89%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<h1
id="python海量数据处理之_hadoop一集群搭建">Python海量数据处理之_Hadoop（一）集群搭建</h1>
<p>#大数据</p>
<h2 id="说明">1. 说明</h2>
<p> 数据处理时，可能会遇到数千万以及上亿条数据的情况。如果一次性处理所有数据，就会遇到内存不够，计算时间太长等问题。上篇《Python海量数据处理之_单机优化》讲述了单机的处理大数据的解决方案。下面将讲述如何利用服务器集群处理大数据，这里使用的工具是Hadoop，内容太多，分为三部分介绍，本篇是第一部分集群搭建，后两部分分别是原理和python调用。</p>
<h2 id="hadoop简介">2. Hadoop简介</h2>
<p> 如果有多台用于数据计算的机器，可以使用Hadoop框架建立集群，统一分配布属。Hadoop是由Apache基金会所开发的分布式系统基础架构，最核心的设计是：HDFS和MapReduce。HDFS为数据提供了存储，MapReduce为数据提供了计算，其中Mapper指的就是拆分处理，Reducer指的就是将结果合并。和单机一样，核心也是拆分，处理，再合并。<br />
 多台机器同时处理数据，相对更复杂，需要考虑：数据共享，同步，冲突，资源分析，计算顺序，以及主控宕机等等问题。</p>
<h2 id="hadoop安装">3. Hadoop安装</h2>
<p> 首先，需要配置起Hadoop环境，才能进行各种实验。Hadoop有三种安装方式：单机，伪分布式和分布式，前两种都是在单机上安装使用的。伪分布式即可以用单机实现，又可以理解分布式的原理，本文主要介绍伪分布式Hadoop的安装。</p>
<h4 id="安装java">1) 安装Java</h4>
<p> Hadoop是java语言实现的，所以需要先安装java和配置相关的环境变量，一般用apt-get安装后环境就被自动配置了。</p>
<h4 id="创建hadoop用户">2) 创建hadoop用户</h4>
<p> 不一定非要创建hadoop用户，因为考虑到有删除ssh密码等操作，为了机器安全性，这里创建了hadoop用户。</p>
<pre><code>$ sudo adduser hadoop  
$ su hadoop # 之后的操作都在hadoop用户下进行  </code></pre>
<h4 id="安装配置ssh">3) 安装配置ssh</h4>
<p> 为了使本机能使用ssh登陆，需要安装ssh服务端，并关掉
PAM认证，并设用户密码为空</p>
<pre><code>$ sudo apt-get install -y openssh-server # 安装ssh服务  
$ sudo vim /etc/ssh/sshd_config # 将UsePAM设为no  
$ sudo /etc/init.d/ssh start # 启动ssh服务，如果安装时已自启动，则配置后用restart重启  
$ ssh localhost # 连接后用exit接出，此时用户目录下生成.ssh目录  
$ cd ~/.ssh # 以下几步是为了设置当前用户无密码登陆  
$ ssh-keygen -t rsa # 设置密码为空，即直接回车  
$ cat ./id_rsa.pub &gt;&gt; ./authorized_keys   </code></pre>
<h4 id="下载hadoop">4) 下载Hadoop</h4>
<p> http://www.apache.org/dyn/closer.cgi/hadoop/common/<br />
 建议下载2.6或2.7的版本，不同版本配置文件不同，而2.7前后的版本教程较多，不用下源码，下载bin包即可。</p>
<pre><code>$ cd /home/hadoop/ # 安装在哪里都行，但需要注意在配置文件中指定目录  
$ tar xvzf  hadoop-2.7.5.tar.gz  
$ ln –s hadoop-2.7.5 hadoop # 方便以后更换版本  
$ vi ~/.bashrc   
  
#加下以入内容（在/etc/profile中设置也行）。设置后，用source ./barshrc让它立即生效。  
  
export HADOOP_PREFIX=&quot;/home/hadoop/hadoop&quot;  # 具体根据安装目录设置  
export YARN_CONF_DIR=&quot;/home/hadoop/hadoop&quot;    
export HADOOP_COMMON_LIB_NATIVE_DIR=&quot;$HADOOP_PREFIX/lib/native&quot;    
export HADOOP_OPTS=&quot;-Djava.library.path=$HADOOP_PREFIX/lib&quot;    
export PATH=$PATH:$HADOOP_PREFIX/bin  </code></pre>
<h4 id="配置core-site.xml">5) 配置core-site.xml</h4>
<pre><code>$  vi hadoop/etc/hadoop/core-site.xml  
  
在configure中加入如下内容（具体根据安装目录设置）  
&lt;configuration&gt;  
        &lt;property&gt;  
             &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;  
             &lt;value&gt;file:/home/hadoop/hadoop/tmp&lt;/value&gt;  
             &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;  
        &lt;/property&gt;  
        &lt;property&gt;  
             &lt;name&gt;fs.defaultFS&lt;/name&gt;  
             &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;  
        &lt;/property&gt;  
&lt;/configuration&gt;  </code></pre>
<h4 id="配置hdfs-site.xml">6) 配置hdfs-site.xml</h4>
<pre><code>$  vi hadoop/etc/hadoop/hdfs-site.xml  
在configure中加入如下内容  
  
&lt;configuration&gt;  
        &lt;property&gt;  
             &lt;name&gt;dfs.replication&lt;/name&gt;  
             &lt;value&gt;1&lt;/value&gt;  
        &lt;/property&gt;  
        &lt;property&gt;  
             &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;  
             &lt;value&gt;file:/home/hadoop/hadoop/tmp/dfs/name&lt;/value&gt;  
        &lt;/property&gt;  
        &lt;property&gt;  
             &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;  
             &lt;value&gt;file:/home/hadoop/hadoop/tmp/dfs/data&lt;/value&gt;  
        &lt;/property&gt;  
&lt;/configuration&gt;  </code></pre>
<h4 id="配置mapered-site.xml">7) 配置mapered-site.xml</h4>
<pre><code>$ cp ./etc/hadoop/mapred-site.xml.template ./etc/hadoop/mapred-site.xml  
$ vi ./etc/hadoop/mapred-site.xml  
在configure中加入如下内容  
  
&lt;configuration&gt;  
        &lt;property&gt;  
             &lt;name&gt;mapreduce.framework.name&lt;/name&gt;  
             &lt;value&gt;yarn&lt;/value&gt;  
        &lt;/property&gt;  
&lt;/configuration&gt;  </code></pre>
<h4 id="配置yarn-site.xml">8) 配置yarn-site.xml</h4>
<pre><code>$ vi ./etc/hadoop/yarn-site.xml  
  
&lt;configuration&gt;  
        &lt;property&gt;  
             &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;  
             &lt;value&gt;mapreduce_shuffle&lt;/value&gt;  
            &lt;/property&gt;  
&lt;/configuration&gt;  </code></pre>
<h4 id="格式化namenode">9) 格式化namenode</h4>
<pre><code>$ hadoop namenode -format  </code></pre>
<p> 如果显示Exiting with status 0，则创建成功</p>
<h4 id="在etchadoop-env.sh中设置java_home">10)
在etc/hadoop/*-env.sh中设置JAVA_HOME</h4>
<p>（根据自己机器的配置）</p>
<pre><code>export JAVA_HOME=/usr/lib/jvm/java-1.9.0-openjdk-amd64/  </code></pre>
<h4 id="启动hdfs">11) 启动hdfs</h4>
<pre><code>$ hadoop/sbin/start-dfs.sh  </code></pre>
<h4 id="看当前服务启动状态">12) 看当前服务启动状态</h4>
<pre><code>$ jps  </code></pre>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-48168af3a57d5236.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 成功启动后还可以通过访问http://localhost:50070，来查看状态。</p>
<h4 id="启动所有服务">13) 启动所有服务</h4>
<pre><code>./sbin/start-all.sh  </code></pre>
<p> 成功启动后还可以通过访问http://localhost:8088/cluster，来查看状态。</p>
<h4 id="问题及解决">14) 问题及解决</h4>
<p> 我在执行start-dfs.sh时，报错util.NativeCodeLoader，意思是调用内部库时出错，内部库指的是用JNI调的C库，解决方法是用ldd看看so库链接是否正常，如果so库与当前系统不能匹配，则需要重编源码。还有一种情况，就是环境变量没设对，我这边设置了两个环境变量：</p>
<pre><code>$ export JAVA_LIBRARY_PATH=/home/hadoop/hadoop/lib/native/  
$ export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop  </code></pre>
<p>之后问题得以解决，根本原因是不同Hadoop版本环境变量名有差别，所以跟着文档做常会出现各种问题，而文档中指定的版本很可能不是主流版本，已经无法下载了。解决方法是跟进脚本，定位具体问题。</p>
<h2 id="编译hadoop源码">4. 编译Hadoop源码</h2>
<p> 如果上述可工作正常，则无需要编译源码。有些情况下，环境与二进制版本不一致，则需要下载源码编译，我下载的也是2.7.5版本的src包。重编时坑也很多。<br />
源码包解压后，目录中有BUILDING.txt文件，执行其中所有apt-get相关命令。然后编译：</p>
<pre><code>$ mvn package -Pdist,native -DskipTests –Dtar  </code></pre>
<p>mvn是编译工具maven，编译过程非常慢，编出将近4G。编译后生成文件为hadoop-dist/target/hadoop-2.7.5.tar.gz，</p>
<p>在编译过程中遇到三种报错：<br />
 一种报错是“protoc
failure”，用apt-get安装该包后又报错版本不对，最后编译了protobuf-2.5.0包（注意install后要ldconfig，否则还是找不到），得以解决。<br />
 另一个报错是“No plugin descriptor found at
META-INF”，我从csdn下载了一个，改了版本号就能用了。<br />
 还有一种报错是连不上marven服务器，于是在设置文件/etc/maven/settings.xml中加入了国内的镜像地址。</p>
]]></content>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Python海量数据处理之_Hadoop（三）程序调用</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%A4%A7%E6%95%B0%E6%8D%AE/Python%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%B9%8B_Hadoop%EF%BC%88%E4%B8%89%EF%BC%89%E7%A8%8B%E5%BA%8F%E8%B0%83%E7%94%A8/</url>
    <content><![CDATA[<h1
id="python海量数据处理之_hadoop三程序调用">Python海量数据处理之_Hadoop（三）程序调用</h1>
<p>#大数据 #Python</p>
<h2 id="说明">1. 说明</h2>
<p> 前两篇分别介绍了Hadoop的配置方法和基本原理，本篇将介绍如何让程序借助Hadoop调用服务器集群中的算力。Hadoop是Java语言实现的，它不仅支持Java，还支持C++，Python等程序的分布计算。下面以Python为例介绍如何使用Hadoop的MapReduce功能。</p>
<h2 id="工作过程">2. 工作过程</h2>
<p> 在原理部分介绍过，Hadoop分为两部分，一部分是存储，一部分是运算，而各个部分又可分为主控和局部实现。这里忽略细节，主要说明运算的主控部分是如何运作的。<br />
 从程序调用的角度看，程序员首先需要把待处理的文件复制到HDFS文件系统之中，然后调Hadoop提供的java程序执行分布计算，具体需要执行的python代码用参数的形式提供；最后在HDFS生成输出文件，程序员再将其拷回本地即可。<br />
 这里的分布计算主要指MapReduce，MapReduce框架将输入数据分割成数据块，传给Mapper，然后Map任务在各个服务器上以完全并行的方式处理，接着MapReduce框架对Map任务的输出进行排序，并将结果做为Reduce任务的输入，最后由Reduce任务输出最终的结果。请注意，在Map和Reduce中有个排序的过程，因为必须完成所有map后才能reduce，这也局限了MapReduce的工作场景。<br />
 MapReduce的核心数据是&lt;key,value&gt;键值对，Mapper处理完数据输出的是键值对（如果不输出，则起到了过滤的作用），框架对键值对排序（后面在具体例子中介绍排序的原因），再输出给Reducer继续处理。Mapper的数量由输入文件的大小确定，Reducer的数量由程序员指定.</p>
<h2 id="hdfs文件系统操作">3. HDFS文件系统操作</h2>
<p> Hadoop集群中的服务器处理的是HDFS中的数据，因此需要在本地和HDFS之间复制文件，常用命令如下：</p>
<pre><code>$ hadoop fs -mkdir /tmp/input # 建立目录  
$ hadoop fs -ls /tmp/ # 查看目录中文件  
$ hadoop fs -copyFromLocal /tmp/test_items.txt /tmp/input/ # 复制本地文件到HDFS  
$ hadoop fs -cat /tmp/input/test_items.txt # 查看文件内容  
$ hadoop fs -copyToLocal /tmp/input . # 将HDFS中文件夹复制到本地  </code></pre>
<p> 更多命令见：http://hadoop.apache.org/docs/r1.0.4/file_system_shell.html</p>
<h2 id="例程">4. 例程</h2>
<h4 id="实现功能">1) 实现功能</h4>
<p> 统计文件中单词出现的次数。</p>
<h4 id="程序mapper.py">2) 程序mapper.py</h4>
<p> 注意将程序设置为可执行权限</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/usr/bin/env python  </span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># -*- coding: utf-8 -*-  </span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys  </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> line <span class="kw">in</span> sys.stdin:  <span class="co"># 从标准输入中按行读数据  </span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    line <span class="op">=</span> line.strip()  <span class="co"># 将行尾行首的空格去除  </span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> line.split()  <span class="co">#按空格将句子分割成单个单词  </span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word <span class="kw">in</span> words:  </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span> <span class="st">&#39;</span><span class="sc">%s</span><span class="ch">\t</span><span class="sc">%s</span><span class="st">&#39;</span> <span class="op">%</span>(word, <span class="dv">1</span>) <span class="co"># 输出键值对，每单词出现1次  </span></span></code></pre></div>
<h4 id="程序reducer.py">3) 程序reducer.py</h4>
<p> 注意将程序设置为可执行权限</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/usr/bin/env python  </span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># -*- coding: utf-8 -*-  </span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys  </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>current_word <span class="op">=</span> <span class="va">None</span>  <span class="co"># 当前单词  </span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>current_count <span class="op">=</span> <span class="dv">0</span>  <span class="co"># 当前单词频数  </span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>word <span class="op">=</span> <span class="va">None</span>  </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> line <span class="kw">in</span> sys.stdin:  </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> line.strip()   </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    word, count <span class="op">=</span> words.split(<span class="st">&#39;</span><span class="ch">\t</span><span class="st">&#39;</span>)  <span class="co"># 按照制表符分隔单词和数量  </span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:  </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        count <span class="op">=</span> <span class="bu">int</span>(count)  <span class="co"># 将字符串类型的‘1’转换为整型1  </span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">ValueError</span>:  </span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span>  </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> current_word <span class="op">==</span> word:  <span class="co"># 如果当前的单词等于读入的单词  </span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        current_count <span class="op">+=</span> count  <span class="co"># 单词频数加1  </span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:  </span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> current_word:  <span class="co"># 如果当前的单词不为空则打印其单词和频数  </span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span> <span class="st">&#39;</span><span class="sc">%s</span><span class="ch">\t</span><span class="sc">%s</span><span class="st">&#39;</span> <span class="op">%</span>(current_word, current_count)    </span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        current_count <span class="op">=</span> count  <span class="co"># 否则将读入的单词赋值给当前单词，且更新频数  </span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>        current_word <span class="op">=</span> word  </span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> current_word <span class="op">==</span> word:  </span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span> <span class="st">&#39;</span><span class="sc">%s</span><span class="ch">\t</span><span class="sc">%s</span><span class="st">&#39;</span> <span class="op">%</span>(current_word, current_count)  </span></code></pre></div>
<h4 id="在本地实验">4) 在本地实验</h4>
<p> 程序在Hadoop上运行前，先在本地运行，以保证其正确性，运行命令：</p>
<pre><code>$ echo &quot;Dear Bear River Car Car River Dear Car Bear&quot; | ./mapper.py | sort -k 1,1 | ./reducer.py  </code></pre>
<p> 可以看到命令用管道的方式将map,reduce和数据连接到了一起，中间还有sort命令用于排序，排序原因从reducer.py程序中可以看到。也可参见下图：</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-86c2d43486b03e94.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> Hadoop将三行数据分成三份，mapper.py处理后如第三列所示，排序后变为第四列，它把同样的单词都放在一起了，使得在reducer.py在处理时只要判断连续单词是否相同，而无需从头到尾搜索单词。</p>
<h4 id="hadoop实验">5) Hadoop实验</h4>
<pre><code>$ hadoop jar /home/hadoop/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.5.jar  -files ./mapper.py,./reducer.py -mapper ./mapper.py -reducer ./reducer.py -input /tmp/input/*.txt -output /tmp/output/  </code></pre>
<p> 这里py文件被指定了两次，files指定的是上传两个py文件，这里还可以上传配置文件等，后面是分别指定作为mapper和reducer的程序，然后是指定输入输出。非常简单，甚至不需要在python文件中加任何的支持库，只要读写输入输出却可。</p>
<h2 id="应用场景">5. 应用场景</h2>
<p> Hadoop主要是针对海量数据处理的，试想当数据以TB,PB计量的时候，我们不可能用单机一次性打开所有数据。Hadoop方式可用多台便宜PC组合的方式处理海量数据。<br />
 看了一些典型的Hadoop应用场景，觉得现在使用Hadoop主要以HDFS加数据库的共享数据为主，更多的时候是被其它上层工具封装后调用。</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Python海量数据处理之_Hadoop（二）概念和原理</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%A4%A7%E6%95%B0%E6%8D%AE/Python%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%B9%8B_Hadoop%EF%BC%88%E4%BA%8C%EF%BC%89%E6%A6%82%E5%BF%B5%E5%92%8C%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<h1
id="python海量数据处理之_hadoop二概念和原理">Python海量数据处理之_Hadoop（二）概念和原理</h1>
<p>#大数据</p>
<h4 id="说明">1. 说明</h4>
<p> Hadoop是个分布式的架构，它将海量数据处理工作分配到集群中的多个机器上运行。前篇介绍了Hadoop的安装，在安装过程中会产生一些疑问，比如NameNode是什么东西？本篇就以问题&amp;解答的方式介绍Hadoop的相关概念及其原理。</p>
<h4 id="namenodedatanode以及secondary-namenode">2.
NameNode，DataNode，以及Secondary NameNode</h4>
<p> 把Hadoop分为HDFS和MapReduce。HDFS为数据提供了存储，MapReduce为数据提供了计算。<br />
 NameNode，DataNode以及Secondary
NameNode都是属于存储部分，NameNode主要负责管理元信息，如文件名，目录结构，属性，数据块存储位置等等。DataNode负责数据块的具体存取。SecondaryNameNode是NameNode的辅助工具，有两个作用，一是镜像备份，二是日志与镜像的定期合并，注意：它并不是NameNode的备份。</p>
<h4 id="resourcemanager与nodemanager">3.
ResourceManager与NodeManager</h4>
<p> ResourceManager和NodeManager属于计算部分，ResourceManager负责集群中所有算力的统一管理和分配，NodeManager是每台机器上的代理，负责容器管理，并监控它们的资源使用情况，以及向ResourceManager提供资源使用报告。</p>
<h4 id="mapreduce与yarn">4. MapReduce与YARN</h4>
<p> Hadoop将MapReduce框架升级到YARN（也叫MapRecudeV2）。原来MapReduce分为JobTracker和NodeTracker，分别用于分配集群中所有任务和管理单机任务；而YARN改为ResourceManager和NodeManager，也分别针对主按和单机，但YARN对每个应用都建立了ApplicationMaster，它可以分布在ResourceManager以外的机器上，从而缓解了主控的压力。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-1bf342c102f95510.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="master与slave">5. Master与slave</h4>
<p> Master和salve指的是集群中各台主机主控或从属的特性，即它们在hadoop中扮演的角色（每台主机就好比一个人），一个集群中只有一个master（领导小组），它可以分布在一台或多台机器上（好比主管存储的领导和主管计算的领导可以同一个人，也可以是不同的人），<br />
 Salve（群众）可以有很多，slave机器上主要部署NodeManager和DataNode（作为群众干具体活，一个群众可以干一样或多样工作，全部工作由群众分担），而在Master上部署NameNode和ResourceManager（作为领导分配任务），master如有多余算力，也可部署NodeManager和DataNode（领导也可以干点具体活）。<br />
 如果只有一台机器，可以把所有功能都让它实现，这就是伪分布式，如果机器多负荷大，可以把每种工作分配给专门的机器。需要注意的是管理的角色NameNode和ResourceManager只能各有一个。就好像一样事儿好几个领导同时管就乱了。</p>
<h4 id="集群中多台服务器如何配置">6. 集群中多台服务器如何配置</h4>
<p> 无论是master还是slave都需要安装JDK和Hadoop，以及配置ssh及环境变量，但配置文件和启动方式不同；并且只在master上做格式化。</p>
<h4 id="程序如何读取数据">7. 程序如何读取数据</h4>
<p> 分布式文件系统，算力和存储都分布在多个机器上。NameNode为数据存储提供统一的接口以便读写，具体在core-site.xml中设置。<br />
 在程序层面，通过Hadoop的数据流(streaming)进行流式处理，它有点像linux的管道机制，程序从标准输入stdin读入，写入标准输出stdout（在处理过程中请尽量保持流式，不要一次load太多到内存）。相对来说它更适合处理像字符串一样的流式数据，而非大规律数据的统计。除了直接读数据流，Python还提供封装工具，如mrjob，dumbo，hadoopy，pydoop等等，使读写更加方便。</p>
<h4 id="程序如何切分运算量">8. 程序如何切分运算量</h4>
<p> Map可以开一个到多个，reduce也可以开一个到多个，具体根据业务逻辑分配。</p>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-71bace66756f925d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="数据挖掘可否分布计算">9. 数据挖掘可否分布计算</h4>
<p> Mahout是Hadoop家族中的成员，是基于一个Hadoop的机器学习和数据挖掘的分布式计算框架。</p>
<h4 id="hadoop与spark">10. Hadoop与Spark</h4>
<p> Hadoop是分布式数据处理的低层次抽象，通用，强壮，且保守，它使用HDFS存储，支持复杂的大规模数据。<br />
 Spark是一个新兴的大数据处理的引擎，是分布式大数据处理的高层次抽象。提供了除map和reduce之外更多的运算符，这些操作是通过一个称作弹性分布式数据集(resilient
distributed datasets,
RDDs)的分布式数据框架进行的。它主要使用内存存储，用于快速处理。<br />
 Hadoop的YARN还可与Spark结合使用。</p>
<h4 id="hadoop与zookeeper">11. Hadoop与Zookeeper</h4>
<p> 在集群的管理中Zookeeper负责分布式系统的协调工作。不仅适用于Hadoop集群，在其他的集群中也常被用到，比如此前介绍过的实现矿机集群的Zookeeper&amp;Kafka。Zookeeper主要解决处理分布式应用的“部分失败”问题（比如某个关链节点宕机了），使集群更加稳定地工作。</p>
]]></content>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Python海量数据处理之_单机优化</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%A4%A7%E6%95%B0%E6%8D%AE/Python%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%B9%8B_%E5%8D%95%E6%9C%BA%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h1
id="python海量数据处理之_单机优化">Python海量数据处理之_单机优化</h1>
<p>#大数据 #Python</p>
<h2 id="说明">1. 说明</h2>
<p> 数据处理时，可能会遇到数千万以及上亿条数据的情况。一次处理所有数据，会遇到内存不够，计算时间太长等问题。一般的解法是：先拆分，再处理，最后将处理的结果合并（当然数据少的时候不需要这么麻烦）。本文将介绍在单机上，只使用Python如何处理大量数据。</p>
<h2 id="实例">2. 实例</h2>
<p> 本例是天池大数据竞赛中的“淘宝穿衣搭配”比赛，这是一个新人赛，只要注册参赛，即可下载数据。目标是根据商品信息，专家推荐，用户购物信息，计算出最佳商品组合。<br />
 本例中处理的是用户购物信息“表1”：每条记录包含用户号uid，商品号mid，购物时间time。</p>
<pre><code>uid,mid,time  
4371603,8,20150418  
8034236,8,20150516  
6135829,8,20150405  </code></pre>
<p>需要统计每个用户都购买了什么物品，即生成“表2”：记录包含用户号uid，商品组合mids。</p>
<pre><code>uid,mids  
15  &quot;1795974,1852545,98106,654166&quot;  
20  &quot;2639977,79267&quot;  </code></pre>
<p> 赛题提供了千万级的购物数据，其中含有百万级的用户，全部load到内存再计算生成新的结构，虽然能运行，但内存占用让机器变得非常慢，普通计算只用到单CPU，我的机器用10个小时才处理了200多万条数据，优化之后半小时以内处理完所有数据。下面看看具体实现。</p>
<h2 id="切分数据">3. 切分数据</h2>
<h4 id="目标">(1) 目标</h4>
<p> 把数据切分成十份，分别存入文件</p>
<h4 id="代码">(2) 代码</h4>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>user <span class="op">=</span> pd.read_csv(<span class="st">&quot;../../data/user_bought_history.txt&quot;</span>, sep<span class="op">=</span><span class="st">&quot; &quot;</span>)  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>user.columns <span class="op">=</span> [<span class="st">&#39;uid&#39;</span>,<span class="st">&#39;mid&#39;</span>,<span class="st">&#39;time&#39;</span>]  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>dur <span class="op">=</span> <span class="bu">len</span>(user)<span class="op">/</span><span class="dv">10</span>  </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>ifrom <span class="op">=</span> <span class="dv">0</span>  </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> <span class="dv">0</span>  </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> ifrom <span class="op">&lt;</span> <span class="bu">len</span>(user):  </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    ito <span class="op">=</span> ifrom <span class="op">+</span> dur  </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> user[ifrom:ito]  </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;from &quot;</span>, ifrom, <span class="st">&quot;to &quot;</span>, (ito<span class="op">-</span><span class="dv">1</span>), <span class="st">&quot;total&quot;</span>, <span class="bu">len</span>(data))  </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    data.to_csv(<span class="st">&#39;../../data/user_bought_&#39;</span> <span class="op">+</span> <span class="bu">str</span>(idx) <span class="op">+</span> <span class="st">&#39;.csv&#39;</span>, index<span class="op">=</span><span class="va">False</span>)  </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    ifrom <span class="op">=</span> ito  </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>idx <span class="op">+=</span> <span class="dv">1</span>  </span></code></pre></div>
<h2 id="处理数据">4. 处理数据</h2>
<h4 id="目标-1">(1) 目标</h4>
<p> 用多线程方式处理切分后的数据，将表1转换成表2格式</p>
<h4 id="代码-1">(1) 代码</h4>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> do_conv(index):  </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    path <span class="op">=</span> <span class="st">&quot;../../data/user_bought_&quot;</span> <span class="op">+</span> <span class="bu">str</span>(index) <span class="op">+</span> <span class="st">&quot;.csv&quot;</span>  </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(path):  </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span>  </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    user <span class="op">=</span> pd.read_csv(path)  </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    user[<span class="st">&#39;mid&#39;</span>]<span class="op">=</span>user[<span class="st">&#39;mid&#39;</span>].astype(<span class="bu">str</span>)  </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    grp<span class="op">=</span>user.groupby(<span class="st">&#39;uid&#39;</span>)  </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(index, <span class="bu">len</span>(grp))  </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    user_buy_count_data <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">&#39;uid&#39;</span>,<span class="st">&#39;mids&#39;</span>])  </span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    idx<span class="op">=</span><span class="dv">0</span>  </span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    arr_uid<span class="op">=</span>[]  </span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    arr_mid<span class="op">=</span>[]  </span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, group <span class="kw">in</span> grp:  </span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        mids <span class="op">=</span> <span class="st">&quot;,&quot;</span>.join(group[<span class="st">&#39;mid&#39;</span>])  </span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        arr_uid.append(name)  </span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        arr_mid.append(mids)  </span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">%</span> <span class="dv">10000</span> <span class="op">==</span> <span class="dv">0</span>:  </span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>            show_info.show_time(<span class="bu">str</span>(index) <span class="op">+</span> <span class="st">&quot; : &quot;</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">len</span>(arr_uid)))  </span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        idx<span class="op">+=</span><span class="dv">1</span>  </span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    user_buy_count_data[<span class="st">&#39;uid&#39;</span>]<span class="op">=</span>arr_uid  </span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    user_buy_count_data[<span class="st">&#39;mids&#39;</span>]<span class="op">=</span>arr_mid  </span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    user_buy_count_data.to_csv(<span class="st">&quot;../../data/user_&quot;</span> <span class="op">+</span> <span class="bu">str</span>(index) <span class="op">+</span> <span class="st">&quot;.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)  </span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&#39;__main__&#39;</span>:  </span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>    param_list <span class="op">=</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">11</span>) <span class="co"># 线程参数  </span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>    pool <span class="op">=</span> threadpool.ThreadPool(<span class="dv">3</span>) <span class="co"># 同时最多开3个线程  </span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>    requests <span class="op">=</span> threadpool.makeRequests(do_conv, param_list)   </span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    [pool.putRequest(req) <span class="cf">for</span> req <span class="kw">in</span> requests]   </span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    pool.wait() <span class="co"># 等待所有线程结束  </span></span></code></pre></div>
<h4 id="技术点">(3) 技术点</h4>
<ol type="i">
<li><p>统一处理数据格式<br />
从文件中读出的数据默认为int型，用astype函数将整个数据表的mid字段变为str型，相对于每次处理时再转换更节约时间。</p></li>
<li><p>使用groupby<br />
groupby函数将数据按不同的uid划分为成多个表格，groupby还带有多种统计功能，相对于用字典方式统计数据效率高得多。</p></li>
<li><p>多线程<br />
现在的机器都是多核的，能明显提高计算速度。python中提供了几种不同的多线程方式，这时使用了线程池，它可以控制线程的数量，以免本例中太多线程占用大量内存让机器变慢。使用之前需要安装threadpool库。<br />
</p></li>
</ol>
<pre><code>sudo pip install threadpool  </code></pre>
<h2 id="合并数据">5. 合并数据</h2>
<h4 id="目标-2">(1) 目标</h4>
<p> 将转换完的数据合并，当同一个user在两个表中同时出现时，将mids累加在一起。</p>
<h4 id="代码-2">(2) 代码</h4>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> do_add(x):  </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x.m <span class="op">==</span> <span class="st">&#39;nan&#39;</span>:  </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x.mids  </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x.mids <span class="op">==</span> <span class="st">&#39;nan&#39;</span>:  </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x.m  </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">str</span>(x.mids) <span class="op">+</span> <span class="st">&quot;,&quot;</span> <span class="op">+</span> <span class="bu">str</span>(x.m)  </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> do_merge(data, path):  </span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(path):  </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> data  </span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    data.columns <span class="op">=</span> [<span class="st">&#39;uid&#39;</span>,<span class="st">&#39;m&#39;</span>]  </span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    ex <span class="op">=</span> pd.read_csv(path)  </span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="bu">len</span>(data),<span class="bu">len</span>(ex))  </span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> pd.merge(data, ex, how<span class="op">=</span><span class="st">&#39;outer&#39;</span>)  </span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    data[<span class="st">&#39;m&#39;</span>]<span class="op">=</span>data[<span class="st">&#39;m&#39;</span>].astype(<span class="bu">str</span>)  </span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    data[<span class="st">&#39;mids&#39;</span>]<span class="op">=</span>data[<span class="st">&#39;mids&#39;</span>].astype(<span class="bu">str</span>)  </span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    data[<span class="st">&#39;mids&#39;</span>]<span class="op">=</span>data.<span class="bu">apply</span>(do_add, axis<span class="op">=</span><span class="dv">1</span>)  </span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> data.drop(<span class="st">&#39;m&#39;</span>,axis<span class="op">=</span><span class="dv">1</span>)  </span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(data.head())   </span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data  </span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">&#39;uid&#39;</span>,<span class="st">&#39;mids&#39;</span>])  </span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> index <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">11</span>):  </span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> do_merge(data, <span class="st">&quot;../../data/user_&quot;</span> <span class="op">+</span> <span class="bu">str</span>(index) <span class="op">+</span> <span class="st">&quot;.csv&quot;</span>)  </span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    show_info.show_time(<span class="st">&quot;&quot;</span>)  </span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;after merge &quot;</span>, index, <span class="st">&quot;len&quot;</span>, <span class="bu">len</span>(data))  </span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    data.to_csv(<span class="st">&#39;../../data/user_all.csv&#39;</span>,index<span class="op">=</span><span class="va">False</span>)  </span></code></pre></div>
<h2 id="相关工具">6. 相关工具</h2>
<ol type="1">
<li>top命令<br />
 top是linux系统中统计系统资源占用的工具，默认为每秒统计一次，打开后按1键，可看到多核的占用情况。</li>
</ol>
<h2 id="总结">7. 总结</h2>
<p> 在特征工程和算法的计算过程中，都可以使用先拆分再组合的方式，但前提是切分数据不会造成数据意义的变化。本文介绍了单机处理大数据的优化方式，下篇将介绍用Hadoop集群方案处理海量数据。</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Python编程_在Matplotlib图中显示中文字体</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%A4%A7%E6%95%B0%E6%8D%AE/Python%E7%BC%96%E7%A8%8B_%E5%9C%A8Matplotlib%E5%9B%BE%E4%B8%AD%E6%98%BE%E7%A4%BA%E4%B8%AD%E6%96%87%E5%AD%97%E4%BD%93/</url>
    <content><![CDATA[<h1
id="python编程_在matplotlib图中显示中文字体">Python编程_在Matplotlib图中显示中文字体</h1>
<p>#Python</p>
<h2 id="说明">1. 说明</h2>
<p> 本篇主要针对在Ubuntu系统中，matplotlib显示不了中文的问题，尤其是在无法安装系统字体的情况下，解决Python绘图时中文显示的问题。</p>
<h2 id="在系统中安装字体">2. 在系统中安装字体</h2>
<pre><code>$ fc-list :lang=zh　# 查看中文字体名称及其安装路径，相对于英文字体，中文字体文件一般较大。  </code></pre>
<p>如果无中文字体，可使用apt-get安装，具体方法如下：</p>
<pre><code>$ apt-cache search font|grep Chinese # 查看可安装的中文字体  
$ sudo apt-get install fonts-wqy-zenhei # 安装字体, 一般字体会被安装到/usr/share/fonts/的某个子目录下，也可以从windows中把ttf,ttc复制到fonts目录下。  
$ cd /usr/share/fonts/truetype/xxx/ # cd到字体安装目录下  
$ sudo mkfontscale  
$ sudo mkfontdir  
$ fc-cache -v # 更新字体  
$ fc-list :lang=zh # 此时就可以看到新装的字体  </code></pre>
<h2 id="在python中指定字体">3. 在Python中指定字体</h2>
<p> 此时python就可以使用新安装的字体了，方法是在Python中设置默认字体.</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">&#39;font.sans-serif&#39;</span>] <span class="op">=</span> [<span class="st">&#39;Droid Sans Japanese&#39;</span>]  </span></code></pre></div>
<p> 用以下方法可列出Python可用的系统字体名称及路径。</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> os <span class="im">import</span> path  </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.font_manager <span class="im">import</span> fontManager  </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> fontManager.ttflist:  </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(i.fname, i.name)  </span></code></pre></div>
<h2 id="在程序中指定字体文件">4. 在程序中指定字体文件</h2>
<p> 如果由于权限的限制，无法安装系统字体，也可以在程序中直接指定程序路径load字体，具体方法如下：</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>zhfont <span class="op">=</span> mpl.font_manager.FontProperties(fname<span class="op">=</span><span class="st">&#39;../../font/wqy-zenhei.ttc&#39;</span>)  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">u&#39;测试一下 &#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>, fontproperties<span class="op">=</span>zhfont)  </span></code></pre></div>
<p>注意：用docker+notebook写程序时，需要把字体存放在有权访问的路径之下。</p>
<h2 id="为python安装新字体">5. 为Python安装新字体</h2>
<p>把字体复制到
/usr/local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/目录下，然后删除
/root/.cache/matplotlib/，就可以使用新的字体了。</p>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Seaborn多图组合</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%A4%A7%E6%95%B0%E6%8D%AE/Seaborn%E5%A4%9A%E5%9B%BE%E7%BB%84%E5%90%88/</url>
    <content><![CDATA[<h1 id="seaborn多图组合">Seaborn多图组合</h1>
<p>#Python</p>
<p><strong>1. jointplot 两变量图</strong></p>
<p> 数据分析中常用做图的方式实现相关性分析，即X轴设置为变量A，Y轴设置为变量B，做散点图，由于散点图中点的叠加显示，往往还需要关注每个变量自身的分布情况，jointplot把描述变量的分布图和变量相关的散点图组合在一起，是相关性分析最常用的工具，图片上还能展示回归曲线，以及相关系数。</p>
<pre><code>import statsmodels.api as sm  
import seaborn as sns  
sns.set(style=&quot;darkgrid&quot;)  
data = sm.datasets.ccard.load_pandas().data  
g = sns.jointplot(&#39;AVGEXP&#39;, &#39;AGE&#39;, data=data, kind=&quot;reg&quot;,  
                 xlim=(0, 1000), ylim=(0, 50), color=&quot;m&quot;)  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-90f7dd302f40b929.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 本例中使用statsmodels库的ccard数据，分析了其中两个数值类型变量的相关性，使用xlim和ylim设置了图片显示范围，忽略了离群点，kind参数可设置做图方式：scatter散点图，kde密度图，hex六边形图等，本例中选择reg画出了线性回归图。</p>
<p><strong>2. pairplot多变量图</strong></p>
<p> 如果用对N个变量的相关性做散点图，用maplotlib需要做NxN个图，用pairplot函数调用一次即可实现，其对角线上是直方图，其余都是两两变量的散点图，不仅简单，还能组合在一起作对比。</p>
<pre><code>data = sm.datasets.ccard.load_pandas().data  
sns.pairplot(data, vars=[&#39;AGE&#39;,&#39;INCOME&#39;, &#39;INCOMESQ&#39;,&#39;OWNRENT&#39;])  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-551e024de48413f6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /><br />
 图中可以看到，数据类型INCOME与INCOMESQ呈强相关，AGE与INCOME也有一定相关趋势，对角线上的图对应的是每个因素与其自身的对比，图中以直方图显示了该变量的分布。</p>
<p><strong>3. factorplot两变量关系图</strong></p>
<p> factorplot用于绘制两维变量的关系图，用kind可指定其作图类型，包括：point,
bar, count, box, violin, strip等。</p>
<pre><code>data = sm.datasets.fair.load_pandas().data  
sns.factorplot(x=&#39;occupation&#39;, y=&#39;affairs&#39;, hue=&#39;religious&#39;, data=data)  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-de5ed46cb3a0a5be.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><strong>4. FacetGrid结构化绘图网格</strong></p>
<p> FacetGrid可以选择任意的做图方式，以及自定义的做图函数，通常包含两部分，FacetGrid部分指定了数据集，行，列，map部分指定做图方式，以及相应参数。</p>
<pre><code>g = sns.FacetGrid(tips, col = &#39;time&#39;, row = &#39;smoker&#39;) # 按行和列的分类做N个图  
g.map(plt.hist, &#39;total_bill&#39;, bins = 10) # 指定做图方式  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-cb6fa830e7835356.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 可以看到无论是连续图，还是分类图，无论是用FacetGrid还是barplot都是将多个特征放在同一张图片上展示，其差别一方面在于观察角度不同，另一方面也取决于数据自身的类型。</p>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>一些零碎的mathplotlib小技巧</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E4%B8%80%E4%BA%9B%E9%9B%B6%E7%A2%8E%E7%9A%84mathplotlib%E5%B0%8F%E6%8A%80%E5%B7%A7/</url>
    <content><![CDATA[<h1 id="一些零碎的mathplotlib小技巧">一些零碎的mathplotlib小技巧</h1>
<p>#Python</p>
<ol type="1">
<li><p>说明<br />
一些零碎的mathplotlib小技巧</p></li>
<li><p>怎么让图显得更高级<br />
1.
改字体大小：标题，子标题，标注分别不用同大小的字体，一遍文章中所有图都有相同的style。<br />
2. 注意子图的间距<br />
3. 注意对齐方向：居中，居左<br />
4. 注意配色：不使用红绿蓝等纯色<br />
5. 柱图，线图，饼图使用至少两种以上<br />
6. 对一组图使用相同的X,Y轴范围<br />
7. 注意线的粗细，点的大小<br />
</p></li>
<li><p>线的粗细点的大小<br />
plt.plot(xx, linewidth=1.0)<br />
plt.plot(xx, 'o', markersize=1)</p></li>
<li><p>横轴显示时间日期<br />
df['datetime'] = df['datestr'].apply(lambda x:
datetime.datetime.strptime(x,<br />
"%Y-%m-%d"))</p></li>
<li><p>字体大小<br />
figure.suptitle('xxxx', fontsize=15)<br />
plt.tick_params(labelsize=6)</p></li>
<li><p>显示高分辨率<br />
figure = plt.figure(figsize=(8,6), dpi=300)<br />
其中8,6设定的图像大小及其长宽比</p></li>
<li><p>保存高分辨图片<br />
foo_fig = plt.gcf()<br />
foo_fig.savefig(None)<br />
这里选择的是png图，因为其它图片格式都比较小众</p></li>
<li><p>饼图<br />
values = [100, 200]<br />
labels = ['lab1', 'lab1']<br />
colors = ['#9999ff', '#ff9999']<br />
explode = [0, 0.1] # 哪个突出显示，突出多少<br />
plt.pie(values, labels = labels, colors=colors, explode=explode,
shadow=True,<br />
autopct='%1.1f%%') # 好看的饼图加阴影<br />
plt.show()</p></li>
<li><p>Subplot布局<br />
plt.subplot(121) #
前面的1是行数，2就列数，后面的1是画在第一个位置上<br />
plt.subplot(212) # 前面的2是行数，1是列数，后面的2是在第二行上画<br />
plt.subplot(224) #
前面的2是行数，中间的2是列数，后面的4是在第四个位置上画（右下角）<br />
当然还有一些比较复杂的，不过一般也用不上</p></li>
<li><p>设定显示范围<br />
plt.xlim(min, max)<br />
plt.ylim(min, max)</p></li>
<li><p>总标题与子标题<br />
主标题figure.suptitle()<br />
子标题plt.title()</p></li>
<li><p>间距<br />
plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.8,
hspace=0.3,<br />
wspace=0.3)<br />
注意用0-1间的小数指定百分比</p></li>
<li><p>参考<br />
1. python中matplotlib的颜色及线条控制<br />
https://www.cnblogs.com/darkknightzh/p/6117528.html<br />
主中指定的很多色板及对应颜色名，其实我还是觉得最方便的是找一个满意的配色方案，然后用photoshop采到它的颜色值，直接往color里填效果最好。</p></li>
</ol>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>做图工具pyecharts</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%81%9A%E5%9B%BE%E5%B7%A5%E5%85%B7pyecharts/</url>
    <content><![CDATA[<h1 id="做图工具pyecharts">做图工具pyecharts</h1>
<p>#大数据 #Python</p>
<h2 id="说明">1. 说明</h2>
<p> 上次分享了Flask+Dash做图，WXXCX师兄给我留言说：感觉dash不如pyecharts好用，于是我学习了一下pyecharts。</p>
<p> ECharts，缩写来自Enterprise
Charts，商业级数据图表，一个纯Javascript的图表库，可以流畅的运行在PC和移动设备上，兼容当前绝大部分浏览器（IE6/7/8/9/10/11，chrome，firefox，Safari等）。Pyecharts是python版本的echarts，与Dash相比，我个人更喜欢它的图片配色；在使用上它相似于matplotlib，不需要像Dash一样再去熟悉新的API和callback的逻辑；最喜欢的地方在于notebook可以调，flask也可以调，调试时和显示在网页上的图完全一样；它还支持地图显示，以及雷达图等等（Dash是否支持我没试过）。果然更加好用，整理如下。</p>
<h2 id="准备数据">2. 准备数据</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pyecharts  </span><br><span class="line">  </span><br><span class="line">attr = [<span class="string">&quot;Jan&quot;</span>, <span class="string">&quot;Feb&quot;</span>, <span class="string">&quot;Mar&quot;</span>, <span class="string">&quot;Apr&quot;</span>, <span class="string">&quot;May&quot;</span>, <span class="string">&quot;Jun&quot;</span>, <span class="string">&quot;Jul&quot;</span>, <span class="string">&quot;Aug&quot;</span>, <span class="string">&quot;Sep&quot;</span>, <span class="string">&quot;Oct&quot;</span>, <span class="string">&quot;Nov&quot;</span>, <span class="string">&quot;Dec&quot;</span>]  </span><br><span class="line">v1 = [<span class="number">2.0</span>, <span class="number">4.9</span>, <span class="number">7.0</span>, <span class="number">23.2</span>, <span class="number">25.6</span>, <span class="number">76.7</span>, <span class="number">135.6</span>, <span class="number">162.2</span>, <span class="number">32.6</span>, <span class="number">20.0</span>, <span class="number">6.4</span>, <span class="number">3.3</span>]  </span><br><span class="line">v2 = [<span class="number">2.6</span>, <span class="number">5.9</span>, <span class="number">9.0</span>, <span class="number">26.4</span>, <span class="number">28.7</span>, <span class="number">70.7</span>, <span class="number">175.6</span>, <span class="number">182.2</span>, <span class="number">48.7</span>, <span class="number">18.8</span>, <span class="number">6.0</span>, <span class="number">2.3</span>]  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 3. 柱图  </span></span><br><span class="line">  </span><br><span class="line">``` python  </span><br><span class="line">bar = pyecharts.Bar(<span class="string">&quot;Title1&quot;</span>, <span class="string">&quot;Title2&quot;</span>)  </span><br><span class="line">bar.add(<span class="string">&quot;v1&quot;</span>, attr, v1, mark_line=[<span class="string">&quot;average&quot;</span>], mark_point=[<span class="string">&quot;max&quot;</span>, <span class="string">&quot;min&quot;</span>])  </span><br><span class="line">bar.add(<span class="string">&quot;v2&quot;</span>, attr, v2, mark_line=[<span class="string">&quot;average&quot;</span>], mark_point=[<span class="string">&quot;max&quot;</span>, <span class="string">&quot;min&quot;</span>])  </span><br><span class="line">bar.render(<span class="string">&#x27;test.html&#x27;</span>)  </span><br><span class="line">bar  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">![image.png](https://upload-images.jianshu.io/upload_images/<span class="number">5357893</span>-c5c523e2097d3d4b.png?imageMogr2/auto-orient/strip%7CimageView2/<span class="number">2</span>/w/<span class="number">1240</span>)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 4. 直方图  </span></span><br><span class="line">``` python  </span><br><span class="line">bar = pyecharts.Bar(<span class="string">&#x27;Title1&#x27;</span>, <span class="string">&#x27;Title2&#x27;</span>)  </span><br><span class="line">bar.add(name = <span class="string">&#x27;v1&#x27;</span>, x_axis = attr, y_axis = v1, bar_category_gap = <span class="number">0</span>)  </span><br><span class="line">bar.render(<span class="string">&#x27;test.html&#x27;</span>)  </span><br><span class="line">bar  </span><br><span class="line">```  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/<span class="number">5357893</span>-8b6fc12318626eac.png?imageMogr2/auto-orient/strip%7CimageView2/<span class="number">2</span>/w/<span class="number">1240</span>)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 5. 堆叠柱图  </span></span><br><span class="line">``` python  </span><br><span class="line">bar = pyecharts.Bar(<span class="string">&quot;Title1&quot;</span>, <span class="string">&quot;Title2&quot;</span>)   </span><br><span class="line">bar.add(<span class="string">&#x27;v1&#x27;</span>,attr,v1,is_stack = <span class="literal">True</span>) <span class="comment"># is_stack = True才表示堆叠在一起   </span></span><br><span class="line">bar.add(<span class="string">&#x27;v2&#x27;</span>,attr,v2,is_stack = <span class="literal">True</span>)   </span><br><span class="line">bar.render(<span class="string">&#x27;test.html&#x27;</span>)   </span><br><span class="line">bar  </span><br><span class="line">```  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/<span class="number">5357893</span>-66415723a4ef724d.png?imageMogr2/auto-orient/strip%7CimageView2/<span class="number">2</span>/w/<span class="number">1240</span>)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 6. 散点图  </span></span><br><span class="line">``` python  </span><br><span class="line">scatter = pyecharts.Scatter(<span class="string">&#x27;Title1&#x27;</span>, <span class="string">&#x27;Title2&#x27;</span>)  </span><br><span class="line">x = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(attr))]  </span><br><span class="line">scatter.add(<span class="string">&quot;v1&quot;</span>, x, v1)  </span><br><span class="line">scatter.add(<span class="string">&quot;v2&quot;</span>, x, v2)  </span><br><span class="line">scatter.render(<span class="string">&#x27;test.html&#x27;</span>)  </span><br><span class="line">scatter  </span><br><span class="line">```  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/<span class="number">5357893</span>-88ed6839262a249d.png?imageMogr2/auto-orient/strip%7CimageView2/<span class="number">2</span>/w/<span class="number">1240</span>)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 7. 特效散点图  </span></span><br><span class="line">  </span><br><span class="line">``` python  </span><br><span class="line">es = pyecharts.EffectScatter(<span class="string">&quot;Title1&quot;</span>, <span class="string">&quot;Title2&quot;</span>)  </span><br><span class="line">es.add(<span class="string">&quot;v1&quot;</span>, <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(attr)), v1, legend_pos=<span class="string">&#x27;center&#x27;</span>,   </span><br><span class="line">       effect_period=<span class="number">3</span>, effect_scale=<span class="number">3.5</span>, symbol=<span class="string">&#x27;pin&#x27;</span>, is_label_show=<span class="literal">True</span>)  </span><br><span class="line">es.render(<span class="string">&quot;test.html&quot;</span>)  </span><br><span class="line">es  </span><br><span class="line">```  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/<span class="number">5357893</span>-ca7019889691e4fa.png?imageMogr2/auto-orient/strip%7CimageView2/<span class="number">2</span>/w/<span class="number">1240</span>)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 8. 折线图  </span></span><br><span class="line">  </span><br><span class="line">``` python  </span><br><span class="line">line = pyecharts.Line(<span class="string">&quot;Title1&quot;</span>, <span class="string">&quot;Title2&quot;</span>)  </span><br><span class="line">line.add(<span class="string">&quot;v1&quot;</span>, attr, v1, mark_point=[<span class="string">&#x27;average&#x27;</span>])  </span><br><span class="line">line.add(<span class="string">&quot;v2&quot;</span>, attr, v2, mark_line=[<span class="string">&#x27;average&#x27;</span>], is_smooth=<span class="literal">True</span>)  </span><br><span class="line">line.render(<span class="string">&#x27;test.html&#x27;</span>)  </span><br><span class="line">line  </span><br><span class="line">```  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/<span class="number">5357893</span>-db8ac7e7b261ec57.png?imageMogr2/auto-orient/strip%7CimageView2/<span class="number">2</span>/w/<span class="number">1240</span>)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 9. 饼图  </span></span><br><span class="line">  </span><br><span class="line">``` python  </span><br><span class="line">pie = pyecharts.Pie(<span class="string">&quot;Title1&quot;</span>, <span class="string">&quot;Title2&quot;</span>)  </span><br><span class="line">pie.add(<span class="string">&#x27;v1&#x27;</span>, attr, v1, is_label_show=<span class="literal">True</span>, legend_pos=<span class="string">&#x27;right&#x27;</span>,  </span><br><span class="line">        label_text_color=<span class="literal">None</span>, legend_orient=<span class="string">&#x27;vertical&#x27;</span>, radius=[<span class="number">30</span>, <span class="number">75</span>])  </span><br><span class="line">pie.render(<span class="string">&#x27;test.html&#x27;</span>)  </span><br><span class="line">pie  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/<span class="number">5357893</span>-d57511948d85a9f3.png?imageMogr2/auto-orient/strip%7CimageView2/<span class="number">2</span>/w/<span class="number">1240</span>)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 10. 箱图  </span></span><br><span class="line">  </span><br><span class="line">``` python  </span><br><span class="line">boxplot = pyecharts.Boxplot(<span class="string">&#x27;Title1&#x27;</span>, <span class="string">&#x27;Title2&#x27;</span>)  </span><br><span class="line">x_axis = [<span class="string">&#x27;v1&#x27;</span>,<span class="string">&#x27;v2&#x27;</span>]  </span><br><span class="line">y_axis = [v1, v2]  </span><br><span class="line">yaxis = boxplot.prepare_data(y_axis)  </span><br><span class="line">boxplot.add(<span class="string">&quot;value&quot;</span>, x_axis, y_axis)  </span><br><span class="line">boxplot.render(<span class="string">&#x27;test.html&#x27;</span>)  </span><br><span class="line">boxplot  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/<span class="number">5357893</span>-f1c8fb05af428d2f.png?imageMogr2/auto-orient/strip%7CimageView2/<span class="number">2</span>/w/<span class="number">1240</span>)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 11. 多种类型图叠加  </span></span><br><span class="line">  </span><br><span class="line">``` python  </span><br><span class="line">bar = pyecharts.Bar(<span class="string">&#x27;Title1&#x27;</span>, <span class="string">&#x27;Title2&#x27;</span>)   </span><br><span class="line">bar.add(<span class="string">&#x27;v1&#x27;</span>,attr,v1)   </span><br><span class="line">line = pyecharts.Line()   </span><br><span class="line">line.add(<span class="string">&#x27;v2&#x27;</span>,attr,v2)   </span><br><span class="line">overlop = pyecharts.Overlap()   </span><br><span class="line">overlop.add(bar)   </span><br><span class="line">overlop.add(line)   </span><br><span class="line">overlop.render(<span class="string">&#x27;test.html&#x27;</span>)  </span><br><span class="line">overlop  </span><br><span class="line">```  </span><br><span class="line">![](https://upload-images.jianshu.io/upload_images/<span class="number">5357893</span>-bb0617c9fddef53f.png?imageMogr2/auto-orient/strip%7CimageView2/<span class="number">2</span>/w/<span class="number">1240</span>)  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 12. 在网页中显示图表  </span></span><br><span class="line">&amp;emsp;与flask框架结合，pythechart将图存成网页，再用flask显示该网页，注意运行前先建立templates目录，flask默认从该目录读取网页。如果运行以下程序没有问题，则在浏览器打开 http://localhost:<span class="number">9993</span> 即可看到图片。  </span><br><span class="line">  </span><br><span class="line">``` python  </span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask  </span><br><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib  </span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask,render_template,url_for  </span><br><span class="line"><span class="keyword">import</span> pyecharts  </span><br><span class="line">  </span><br><span class="line">server = Flask(__name__)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">render_test_1</span>():  </span><br><span class="line">    attr = [<span class="string">&quot;Jan&quot;</span>, <span class="string">&quot;Feb&quot;</span>, <span class="string">&quot;Mar&quot;</span>, <span class="string">&quot;Apr&quot;</span>, <span class="string">&quot;May&quot;</span>, <span class="string">&quot;Jun&quot;</span>, <span class="string">&quot;Jul&quot;</span>, <span class="string">&quot;Aug&quot;</span>, <span class="string">&quot;Sep&quot;</span>, <span class="string">&quot;Oct&quot;</span>, <span class="string">&quot;Nov&quot;</span>, <span class="string">&quot;Dec&quot;</span>]  </span><br><span class="line">    v1 = [<span class="number">2.0</span>, <span class="number">4.9</span>, <span class="number">7.0</span>, <span class="number">23.2</span>, <span class="number">25.6</span>, <span class="number">76.7</span>, <span class="number">135.6</span>, <span class="number">162.2</span>, <span class="number">32.6</span>, <span class="number">20.0</span>, <span class="number">6.4</span>, <span class="number">3.3</span>]  </span><br><span class="line">    v2 = [<span class="number">2.6</span>, <span class="number">5.9</span>, <span class="number">9.0</span>, <span class="number">26.4</span>, <span class="number">28.7</span>, <span class="number">70.7</span>, <span class="number">175.6</span>, <span class="number">182.2</span>, <span class="number">48.7</span>, <span class="number">18.8</span>, <span class="number">6.0</span>, <span class="number">2.3</span>]  </span><br><span class="line">    line = pyecharts.Line(<span class="string">&quot;Title1&quot;</span>, <span class="string">&quot;Title2&quot;</span>)  </span><br><span class="line">    line.add(<span class="string">&quot;v1&quot;</span>, attr, v1, mark_point=[<span class="string">&#x27;average&#x27;</span>])  </span><br><span class="line">    line.add(<span class="string">&quot;v2&quot;</span>, attr, v2, mark_line=[<span class="string">&#x27;average&#x27;</span>], is_smooth=<span class="literal">True</span>)  </span><br><span class="line">    line.render(<span class="string">&#x27;templates/bar01.html&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="meta">@server.route(<span class="params"><span class="string">&#x27;/&#x27;</span></span>)  </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_main</span>():  </span><br><span class="line">    render_test_1()  </span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">&#x27;bar01.html&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  </span><br><span class="line">    server.run(debug=<span class="literal">True</span>, port=<span class="number">9993</span>, host=<span class="string">&quot;0.0.0.0&quot;</span>)  </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Notebook左侧开启导航</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%B7%A5%E5%85%B7/Notebook%E5%B7%A6%E4%BE%A7%E5%BC%80%E5%90%AF%E5%AF%BC%E8%88%AA/</url>
    <content><![CDATA[<h1 id="notebook左侧开启导航">Notebook左侧开启导航</h1>
<h2 id="python">Python</h2>
<p>有时候使用 Notebook
编写较长代码，或者有很多Cell，定位某一段代码时需要不断拖动，非常麻烦，使用
Notebook 插件提供的导航功能可以很好地解决这一问题。</p>
<p>首先，安装插件：</p>
<h3 id="方法一">方法一</h3>
<pre class="shell"><code>$ pip install jupyter_nbextensions_configurator jupyter_contrib_nbextensions  
$ jupyter contrib nbextension install --user  
$ jupyter nbextensions_configurator enable –user  </code></pre>
<h3 id="方法二">方法二</h3>
<pre class="shell"><code>$ pip install jupyter_contrib_nbextensions  
$ jupyter contrib nbextension install --user  
$ pip install jupyter_nbextensions_configurator  </code></pre>
<p>然后在 Notebook <strong>目录界面</strong>打开插件设置标签页
Nbextensions，选中其中的 Table of contents (2)。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-3ae4fa8e11b92054.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>在<strong>程序界面</strong>点击右上方的 Table of contents
按钮，此时左边出现导航栏。将Cell设置为标签后，其中用 Markdown
方式设置的标题将出现在左边，点击该项即可跳转到程序相应的位置。</p>
<figure>
<img
src="https://upload-images.jianshu.io/upload_images/5357893-0e0b0585fdc06d12.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>PythonNotebook(JupyterNotebook)介绍</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%B7%A5%E5%85%B7/PythonNotebook(JupyterNotebook)%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h1 id="python-notebook-jupyter-notebook-介绍">Python Notebook (Jupyter
Notebook) 介绍</h1>
<p>#Python</p>
<h2 id="介绍">1. 介绍</h2>
<p> 前一段跑别人的python代码，扩展名是ipynb，不能直接用python命令执行，于是只好安装了Jupyter
notebook软件，然后发现它是一个非常好用的程序写作工具。<br />
 对我来说，它最大的好处就是文档和程序可以写在一起了。在写程序的时候往往会有一些思路，解释，分析，运行结果等等，需要记下来，比较长的就不太适合在程序里面注释，记在其它地方又容易忘掉。Notebook完美地解决了这个问题。当然它还有很多其它优点，下面简单介绍一下。</p>
<h2 id="jupyter-notebook">2. Jupyter Notebook</h2>
<p> IPYNB是ipython
notebook的缩写，它开始只支持python，后来又支持了其它40多种编辑语言，就改名叫Jupyter
notebook。<br />
 Notebook存储python程序的文件是ipynb，ipynb一种文本文件，可以用vi直接打开，文件中除了程序和说明还有一些结构信息，不能直接用python执行，但在notebook界面中可以被导出成.py程序，还可以导出成html,
pdf等格式，像Kaggle上面的程序及说明都是这种格式的，Github也支持该格式的完美显示，即：在Github中打开.pynb文件看到的就是分块的代码。<br />
 Notebook是用网页访问的，你可以在网页中编写和执行程序。并且可以在其它机器上远程调用它，这种环境也屏蔽了不同系统的显示差异。在分享示例代码的时候，也非常方便，完全不用再去考虑格式的问题。</p>
<h2 id="安装">3. 安装</h2>
<pre><code>$ sudo pip3 install ipython  
$ sudo pip3 install jupyter 　#用pip命令自动安装相关的依赖包  </code></pre>
<h2 id="运行">4. 运行</h2>
<pre><code>$ ipython3 notebook  </code></pre>
<p> 此时浏览器被打开，本机开启了8888端口，浏览器通过访问该端口，列出了当前目录下的ipynb文件。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-6c2eb2f95e86261b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 此时可以在浏览器中编辑和运行已存在的程序，如果还没有ipynb文件，可点击右上的new新建程序。在编写和调试程序的过程中，错误提示和运行结果也都显示在浏览器中。</p>
<h2 id="单元">5. 单元</h2>
<p> Notebook中的基本元素是“Cell”即单元。主要有两种形式的单元：
代码单元：代码单元左边有 In [ ]:
这样的序列标记，方便查看代码的执行次序。其结果显示在本单元下方。<br />
 Markdown 单元：在这里可以编辑文本，采用 markdown
的语法规范，可以设置文本格式、插入链接、图片甚至数学公式。
单元通过Insert菜单添加，在Cell菜单中可以选择运行全部代码或者某个代码单元，这有点像单步调试，也方便也省时。习惯了这种方式之后，代码分块也是对代码的功能划分。有时也可以把完全不同的几种思路写在一份代码里，只要运行不同单元即可，在调试过程中非常方便。<br />
 与VI类似，Notebook也有编辑模式和命令模式，命令模式时单元左侧显示蓝线，编辑模式时左侧显示绿线。通过Esc键可切换到命令模式。在命令模式可以使用一些快捷键，比如用Shift+L控制是否显示行号。</p>
<h2 id="导出各种格式文件">6. 导出各种格式文件</h2>
<p> Notebook支持导出Python, Html，PDF等格式文件，具体方法是：<br />
notebook菜单-&gt;File-&gt;Download as-&gt;xx</p>
<h2 id="参考">7. 参考</h2>
<ol type="1">
<li>左手程序员，右手作家：你必须会的Jupyter Notebook<br />
http://python.jobbole.com/87527/</li>
</ol>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python写日志文件</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%B7%A5%E5%85%B7/Python%E5%86%99%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<h1 id="python写日志文件">Python写日志文件</h1>
<p>#Python</p>
<p> 日志文件是记录程序操作及事件的记录文件或记录文件的集合。一般由程序开发人员编写，开发、运维人员共同使用，开发人员可以通过日志调试程序，运维人员通过日志检查程序近期是否正常运行，如果出现异常，则可通过日志快速定位问题。因此，用日志记录程序流程，事件，以及异常时的详细信息非常重要，尤其是对于部署在客户场地的程序。另外，日志有时也用于记录用户操作、程序运行地理位置等跟踪信息，用于后台的用户研究和数据挖掘。</p>
<p> 日志文件需要详细、清晰、且具有高可读性，以便减少开发与运维人员后期的沟通成本，有时候我们也使用程序来检测和分析日志，因此，定义关键字和格式也很重要。</p>
<p> Python使用logging工具管理日志，日志可以在终端显示，也可以记录成文件，每条日志都用级别号标志其严重程度，一般通过级别过滤选择性地记录和显示日志，级别定义如表5-1所示：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-90852bf7b34fe232.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p>(谢彦技术博客)</p>
<p> 本例展示了以屏幕输出和文件输出两种方式记录日志信息，日志文件为当前目录下的log.txt，格式为文本文件。例程中设置了三次日志级别，第一次对程序中所有日志设置，级别为DEBUG，即显示全部日志，第二次设置日志文件的级别为INFO，它将INFO及INFO以上的日志记录在文件中，第三次是设置屏幕显示日志级别为WARNING，相当于先用第一次设置的DEBUG过滤一遍，再用WARNING过滤一遍，最终输出的是WARNING及以上的日志信息。</p>
<pre><code>import logging  
  
# 获取logger对象,取名mylog  
logger = logging.getLogger(&quot;mylog&quot;)  
# 输出DEBUG及以上级别的信息，针对所有输出的第一层过滤  
logger.setLevel(level=logging.DEBUG)  
  
# 获取文件日志句柄并设置日志级别，第二层过滤  
handler = logging.FileHandler(&quot;log.txt&quot;)  
handler.setLevel(logging.INFO)    
  
# 生成并设置文件日志格式，其中name为上面设置的mylog  
formatter = logging.Formatter(&#39;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#39;)  
handler.setFormatter(formatter)  
  
# 获取流句柄并设置日志级别，第二层过滤  
console = logging.StreamHandler()  
console.setLevel(logging.WARNING)  
  
# 为logger对象添加句柄  
logger.addHandler(handler)  
logger.addHandler(console)  
  
# 记录日志  
logger.info(&quot;show info&quot;)  
logger.debug(&quot;show debug&quot;)  
logger.warning(&quot;show warning&quot;)  </code></pre>
<p>(谢彦技术博客)</p>
<p> 需要注意的是程序用addHandler函数添加了两个句柄，一个用来显示输出，一个用来记录日志文件，之后输出的log信息会通过句柄调用对应的输出，同一个输出如果addHandler多次，又没有removeHandler，同一条日志就会被记录多次。因此注意不要重复调用，尤其在用Jupyter
Notebook调试时，不要重复运行该代码段。</p>
<p>转载请注明出处：https://www.jianshu.com/p/10d81d4fb050</p>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python声音和弹框提示</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%B7%A5%E5%85%B7/Python%E5%A3%B0%E9%9F%B3%E5%92%8C%E5%BC%B9%E6%A1%86%E6%8F%90%E7%A4%BA/</url>
    <content><![CDATA[<h1 id="python声音和弹框提示">Python声音和弹框提示</h1>
<p>#Python #Linux</p>
<p>写后台监控程序，有时需要响铃或弹框提示用户。下面介绍Python在Linux系统中的提示方法
：</p>
<p>1. 使用系统工具paplay播放当前目录下的音效文件ring.wav实现响铃</p>
<p>2. 用tkinter界面工具实现弹框</p>
<pre><code>import tkinter as tk  
import os  
  
def show_messagebox(string):  
    os.environ[&quot;DISPLAY&quot;]=&quot;:0.0&quot;  
    root = tk.Tk()  
    root.title(&#39;消息框&#39;)  
    root.geometry(&#39;190x80+300+300&#39;)  
    label = tk.Label(root, text=string, font=&#39;宋体 -14&#39;, pady=8)  
    label.pack()  
    tk.mainloop()  
          
def do_ring(times):  
    for i in range(0,times):  
        os.system(&quot;paplay &#123;&#125; --volume=32768&quot;.format(&#39;ring.wav&#39;))  
  
def warning(string):  
    print(&quot;do warning&quot;)  
    do_ring(10)  
    show_messagebox(string)  
  
warning(&quot;测试一下&quot;)</code></pre>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Python强制杀死线程</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%B7%A5%E5%85%B7/Python%E5%BC%BA%E5%88%B6%E6%9D%80%E6%AD%BB%E7%BA%BF%E7%A8%8B/</url>
    <content><![CDATA[<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> ctypes  </span><br><span class="line"><span class="keyword">import</span> inspect  </span><br><span class="line"><span class="keyword">import</span> time  </span><br><span class="line"><span class="keyword">from</span> threading <span class="keyword">import</span> Thread  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_async_raise</span>(<span class="params">tid, exctype</span>):  </span><br><span class="line">    tid = ctypes.c_long(tid)  </span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> inspect.isclass(exctype):  </span><br><span class="line">        exctype = <span class="built_in">type</span>(exctype)  </span><br><span class="line">    res = ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, ctypes.py_object(exctype))  </span><br><span class="line">    <span class="keyword">if</span> res == <span class="number">0</span>:  </span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;invalid thread id&quot;</span>)  </span><br><span class="line">    <span class="keyword">elif</span> res != <span class="number">1</span>:  </span><br><span class="line">        ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, <span class="literal">None</span>)  </span><br><span class="line">        <span class="keyword">raise</span> SystemError(<span class="string">&quot;PyThreadState_SetAsyncExc failed&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stop_thread</span>(<span class="params">thread</span>):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;\nt -&gt; <span class="subst">&#123;thread&#125;</span>&#x27;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;\nthread.ident -&gt; <span class="subst">&#123;thread.ident&#125;</span>&#x27;</span>)  </span><br><span class="line">    _async_raise(thread.ident, SystemExit)  </span><br><span class="line">    thread.join()  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func1</span>():  </span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:  </span><br><span class="line">        <span class="keyword">try</span>:  </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;func1&#x27;</span>)  </span><br><span class="line">            time.sleep(<span class="number">1</span>)  </span><br><span class="line">        <span class="keyword">except</span> SystemExit:  </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;!!!!&quot;</span>)  </span><br><span class="line">            sys.exit()  </span><br><span class="line">        <span class="keyword">except</span>:  </span><br><span class="line">            <span class="built_in">print</span>(traceback.format_exc())  </span><br><span class="line">  </span><br><span class="line">i = Thread(target=func1, args=())  </span><br><span class="line">i.start()  </span><br><span class="line">time.sleep(<span class="number">3</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;线程<span class="subst">&#123;i&#125;</span>的状态<span class="subst">&#123;i.is_alive()&#125;</span>, 线程<span class="subst">&#123;i&#125;</span>的名字<span class="subst">&#123;i.name&#125;</span>, 线程的方法<span class="subst">&#123;i.ident&#125;</span>&#x27;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(i.name), i.name)  </span><br><span class="line">stop_thread(i)  </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python日志工具loguru</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%B7%A5%E5%85%B7/Python%E6%97%A5%E5%BF%97%E5%B7%A5%E5%85%B7loguru/</url>
    <content><![CDATA[<h1 id="python日志工具-loguru">Python日志工具 loguru</h1>
<p>#Python #日志</p>
<h2 id="错误级别">错误级别</h2>
<table>
<thead>
<tr class="header">
<th>level name</th>
<th>Severity value</th>
<th>Logger method</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>TRACE</td>
<td>5</td>
<td>logger.trace()</td>
</tr>
<tr class="even">
<td>DEBUG</td>
<td>10</td>
<td>logger.debug()</td>
</tr>
<tr class="odd">
<td>INFO</td>
<td>20</td>
<td>logger.info()</td>
</tr>
<tr class="even">
<td>SUCCESS</td>
<td>25</td>
<td>logger.success()</td>
</tr>
<tr class="odd">
<td>WARNING</td>
<td>30</td>
<td>logger.warning()</td>
</tr>
<tr class="even">
<td>ERROR</td>
<td>40</td>
<td>logger.error()</td>
</tr>
<tr class="odd">
<td>CRITICAL</td>
<td>50</td>
<td>logger.critical()</td>
</tr>
</tbody>
</table>
<h2 id="代码">代码</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> loguru <span class="keyword">import</span> logger  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 设置输出级别, 只显示 INFO 及以上级别  </span></span><br><span class="line">logger.remove()  </span><br><span class="line">handler_id = logger.add(sys.stderr, level=<span class="string">&quot;INFO&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 日志输出  </span></span><br><span class="line">logger.debug(<span class="string">&quot;xxxxx&quot;</span>)  </span><br><span class="line">logger.info(<span class="string">&quot;xxxxx&quot;</span>)  </span><br><span class="line">logger.warning(<span class="string">&quot;xxxxx&quot;</span>)  </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title>Python的正则表达式</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%B7%A5%E5%85%B7/Python%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="python的正则表达式">Python的正则表达式</h1>
<p>#Python</p>
<h2 id="基本用法">1 基本用法</h2>
<h4 id="匹配字符串的开头">1.1.1 匹配字符串的开头</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">^很  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 1.1.2 匹配字符串的末尾  </span><br><span class="line">```  </span><br><span class="line">蓝＄  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 1.1.3 匹配除了换行符外的任意字符  </span><br><span class="line">指定re.S(re.DOTALL)时,可包括换行符  </span><br><span class="line">```  </span><br><span class="line">.  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 1.1.4 匹配方括号中任意一个字符  </span><br><span class="line">```  </span><br><span class="line">\[Pp\]`,`\[0-9\]  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 1.1.5 : 匹配不在中括号中的字符  </span><br><span class="line">```  </span><br><span class="line">\[^...]  </span><br><span class="line">  </span><br><span class="line">可匹配除了a,b,c之外的字符  </span><br><span class="line">[^abc]  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 1.1.6 \: 匹配其前面的字符出现0次或多次,  </span><br><span class="line">```  </span><br><span class="line">可匹配 helll,he  </span><br><span class="line">hel*  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 1.1.7 匹配其前面的字符出现1次或多次,如  </span><br><span class="line">```  </span><br><span class="line">+  </span><br><span class="line">  </span><br><span class="line">可匹配 helll,hel,但无法匹配he  </span><br><span class="line">hel+  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 1.1.8 匹配其前面的字符出现0次或1次,  </span><br><span class="line">```  </span><br><span class="line">?  </span><br><span class="line">  </span><br><span class="line">可匹配hel,he,但无法匹配hell  </span><br><span class="line">hel?  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 1.1.9 匹配其前面的表达式出现n次，  </span><br><span class="line">```  </span><br><span class="line">&#123;n&#125;  </span><br><span class="line">  </span><br><span class="line">可匹配food,但无法匹配pow  </span><br><span class="line">o&#123;2&#125;  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 1.1.10 匹配其前面的表达式出现n次以上,  </span><br><span class="line">```  </span><br><span class="line">&#123;n,&#125;  </span><br><span class="line">  </span><br><span class="line">可匹配food,fooooood,无法匹配pow,`o&#123;1,&#125;`,等价于`o+`，`o&#123;0,&#125;`,`o*`  </span><br><span class="line">o&#123;2,&#125;  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 1.1.11 匹配其前面的表达式最少出现n次最多出现m次  </span><br><span class="line">```  </span><br><span class="line">&#123;n,m&#125;  </span><br><span class="line">  </span><br><span class="line">可匹配food,foooood,无法匹配pow,fooooood,`o&#123;0,1&#125;`,等价于`o?`  </span><br><span class="line">o&#123;2,5&#125;  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 1.1.12 匹配a或b  </span><br><span class="line">```  </span><br><span class="line">a|b  </span><br><span class="line">  </span><br><span class="line">可匹配pack,pbck  </span><br><span class="line">p[a|b]ck  </span><br><span class="line">```  </span><br><span class="line">	  </span><br><span class="line"></span><br><span class="line">## 2 分组  </span><br><span class="line"></span><br><span class="line">#### 2.1.1 对正则表达式分组,并返回括号中的内容  </span><br><span class="line">```  </span><br><span class="line">()  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 2.1.2 正则表达式包含三种可选标志：i, m, 或 x ,只影响括号内的区域  </span><br><span class="line">```  </span><br><span class="line">(?imx)  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 2.1.3 正则表达式关闭 i, m, 或 x 可选标志,只影响括号内的区域  </span><br><span class="line">```  </span><br><span class="line">(?-imx)  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 2.1.4 类似 (), 但不表示一个组  </span><br><span class="line">```  </span><br><span class="line">(?: re)  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 2.1.5 在括号中使用i, m, 或 x 可选标志  </span><br><span class="line">```  </span><br><span class="line">(?imx: re)  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 2.1.6 在括号中不使用i, m, 或 x 可选标志  </span><br><span class="line">```  </span><br><span class="line">(?-imx: re)   </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 2.1.7 注释  </span><br><span class="line">```  </span><br><span class="line">\(?#...)  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 2.1.8 前向肯定界定符    </span><br><span class="line">``` python  </span><br><span class="line">(?=re):   </span><br><span class="line">  </span><br><span class="line"># 只抽取数字,且该数字后面跟的字符是abc  </span><br><span class="line">re.findall(r&#x27;\d+(?=abc)&#x27;,&quot;1abc&quot;)  </span><br><span class="line"># 抽取规则： 伴随头晕的过敏   </span><br><span class="line">rule_detail = &#x27;^(?=.*头晕).*(过敏)&#x27;   </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 2.1.9 前向否定界定符。  </span><br><span class="line">``` python  </span><br><span class="line">(?!re)  </span><br><span class="line">  </span><br><span class="line"># 只抽取数字,且该数字后面跟的字符不是abc  </span><br><span class="line">re.findall(r&#x27;\d+(?!abc)&#x27;,&quot;1abf&quot;)  </span><br><span class="line">  </span><br><span class="line"># 不伴随头晕的过敏  </span><br><span class="line">rule_detail = &#x27;^(?!.*头晕).*(过敏)&#x27;  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 2.1.10 后向否定界定符  </span><br><span class="line">```  </span><br><span class="line">\(?&lt;!re)  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 2.1.11 后向肯定界定符  </span><br><span class="line">```  </span><br><span class="line">\(?&gt;ew)  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">## 3 特殊符号  </span><br><span class="line"></span><br><span class="line">#### 3.1.1 \w: 匹配字母数字及下划线,等价于 \[A-Za-z0-9_]  </span><br><span class="line"></span><br><span class="line">#### 3.1.2 \W: 匹配非字母数字及下划线,等价于 \[^A-Za-z0-9_]  </span><br><span class="line"></span><br><span class="line">#### 3.1.3 \s: 匹配任意空白字符,等价于 \[ \f\n\r\t\v]  </span><br><span class="line"></span><br><span class="line">#### 3.1.4 \S: 匹配任意非空字符,等价于 \[^ \f\n\r\t\v]  </span><br><span class="line"></span><br><span class="line">#### 3.1.5 \d: 匹配任意数字,等价于 \[0-9]  </span><br><span class="line"></span><br><span class="line">#### 3.1.6 \D: 匹配任意非数字,等价于 \[^0-9]  </span><br><span class="line"></span><br><span class="line">#### 3.1.7 \A: 匹配字符串开始  </span><br><span class="line"></span><br><span class="line">#### 3.1.8 \z: 匹配字符串结束  </span><br><span class="line"></span><br><span class="line">#### 3.1.9 \Z: 匹配字符串结束,如果存在换行,只匹配到换行前的结束字符串  </span><br><span class="line"></span><br><span class="line">#### 3.1.10 \G: 匹配最后匹配完成的位置  </span><br><span class="line"></span><br><span class="line">#### 3.1.11 \b: 匹配单词边界,即单词和空格间的位置 ,如：`er\b`,可匹配&quot;never&quot; 中的 &#x27;er&#x27;,但不能匹配 &quot;verb&quot; 中的 &#x27;er&#x27;  </span><br><span class="line"></span><br><span class="line">#### 3.1.12 \B: 匹配非单词边界,如：`er\B`,可匹配 &quot;verb&quot; 中的 &#x27;er&#x27;,但不能匹配 &quot;never&quot; 中的 &#x27;er&#x27;  </span><br><span class="line"></span><br><span class="line">#### 3.1.13 \n, \t, 等: 匹配换行符,制表符等  </span><br><span class="line"></span><br><span class="line">#### 3.1.14 \1...\9: 匹配第n个分组的内容  </span><br><span class="line"></span><br><span class="line">#### 3.1.15 \[\u4e00-\u9fa5]: 可以匹配任意UTF-8编码下的中文字符  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">## 4 修饰符  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 4.1.1 re.I 忽略大小写  </span><br><span class="line"></span><br><span class="line">#### 4.1.2 re.L 表示特殊字符集 \w, \W, \b, \B, \s, \S 依赖于当前环境  </span><br><span class="line"></span><br><span class="line">#### 4.1.3 re.M 多行模式,影响 ^ 和 ＄  </span><br><span class="line"></span><br><span class="line">#### 4.1.4 re.S 匹配包括换行在内的所有字符  </span><br><span class="line"></span><br><span class="line">#### 4.1.5 re.U 表示特殊字符集 \w, \W, \b, \B, \d, \D, \s, \S 依赖于 Unicode 字符属性数据库  </span><br><span class="line"></span><br><span class="line">#### 4.1.6 re.X 为了增加可读性,忽略空格和 # 后面的注释  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">## 5 匹配对象方法  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 5.1.1 group(num=0): 输入可为多个组号,获取包含组所对应值的元组  </span><br><span class="line"></span><br><span class="line">#### 5.1.2 groups(): 获取包含所有小组字符串的元组  </span><br><span class="line"></span><br><span class="line">#### 5.1.3 group(\[group1, …\]):获取一个或多个分组匹配字符串  </span><br><span class="line"></span><br><span class="line">#### 5.1.4 start(\[group]):获取分组匹配的子串在整个字符串中的起始位置（子串第一个字符的索引）,参数默认值为 0  </span><br><span class="line"></span><br><span class="line">#### 5.1.5 end(\[group]):获取分组匹配的子串在整个字符串中的结束位置（子串最后一个字符的索引+1）,参数默认值为 0  </span><br><span class="line"></span><br><span class="line">#### 5.1.6 span(\[group]):获取 (start(group), end(group))  </span><br><span class="line"></span><br><span class="line">#### 5.1.7 groupdict():以字典方式返回字符串中多项内容  </span><br><span class="line">``` python  </span><br><span class="line">m = re.match(r&#x27;(?P&lt;user&gt;\w+)@(?P&lt;website&gt;\w+)\.(?P&lt;extension&gt;\w+)&#x27;,&#x27;myname@hackerrank.com&#x27;)  </span><br><span class="line">m.groupdict()  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">## 6 函数  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 6.1.1 从起始位置查找  </span><br><span class="line">re.match(pattern, string, flags=0):从字符串的起始位置匹配模式,可以使用group(num) 或 groups() 获取匹配表达式  </span><br><span class="line">pattern:匹配的正则表达式  </span><br><span class="line">string:要匹配的字符串  </span><br><span class="line">flags:标志位,表示匹配模式,具体参数如下:  </span><br><span class="line">``` python  </span><br><span class="line">re.match(&#x27;www&#x27;, &#x27;www.baidu.com&#x27;).span()   </span><br><span class="line">#返回：(0,3)  </span><br><span class="line">re.match(&#x27;com&#x27;, &#x27;www.baidu.com&#x27;)   </span><br><span class="line">#返回：None  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 6.1.2 查找匹配字符串  </span><br><span class="line">re.search(pattern, string, flags=0):扫描整个字符串并返回第一个成功的匹配,可以使用group(num) 或 groups() 获取匹配表达式  </span><br><span class="line">``` python  </span><br><span class="line">re.search(&#x27;www&#x27;, &#x27;www.baidu.com&#x27;).span()   </span><br><span class="line">#返回：(0,3)  </span><br><span class="line">re.search(&#x27;com&#x27;, &#x27;www.baidu.com&#x27;).span()   </span><br><span class="line">#返回：(11,14)  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 6.1.3 替换字符串  </span><br><span class="line">re.sub(pattern, repl, string, count=0, flags=0):替换字符串中的匹配项  </span><br><span class="line">repl:替换的字符串,也可为一个函数  </span><br><span class="line">count:模式匹配后替换的最大次数,默认0表示替换所有的匹配  </span><br><span class="line">``` python  </span><br><span class="line">re.sub(r&#x27;#.*＄&#x27;, &quot;&quot;, &quot;2004-959-559 # 这是电话号码&quot;)   </span><br><span class="line">#返回：2004-959-559  </span><br><span class="line">re.sub(r&#x27;\D&#x27;, &quot;&quot;, &quot;2004-959-559 # 这是电话号码&quot;)   </span><br><span class="line">#返回：2004959559  </span><br><span class="line">```  </span><br><span class="line">repl特殊写法：  </span><br><span class="line">sub可支持部分替换描述的字符串，当使用括号分组时，用  </span><br><span class="line">```  </span><br><span class="line">\g&lt;n&gt;  </span><br><span class="line">```  </span><br><span class="line">可指定保留第n组，  </span><br><span class="line">例如，下面语句用于插入数据库前的引号处理：在引号前方加入两个反斜杠，对于已加入反斜杠的引号不做处理。  </span><br><span class="line">``` python  </span><br><span class="line">string = &quot;直肠肿物Mile&#x27;s手术&quot;  </span><br><span class="line">re.sub(r&quot;([^\\])(&#x27;)&quot;,&quot;\g&lt;1&gt;\\&#x27;&quot;, string)  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 6.1.4 编译正则表达式  </span><br><span class="line">re.compile(pattern\[, flags]):用于编译正则表达式,生成正则表达式对象,使运行速度更快,可供 match() 和 search() 这两个函数使用  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 6.1.5 查询子串（返回列表）  </span><br><span class="line">re.findall(pattern, string\[, pos\[, endpos]]):在字符串中找到正则表达式所匹配的所有子串,并返回一个列表,如果无匹配项,则返回空列表  </span><br><span class="line">pos:指定字符串的起始位置,默认为 0  </span><br><span class="line">endpos:指定字符串的结束位置,默认为字符串的长度  </span><br><span class="line">``` python  </span><br><span class="line">result1 = re.findall(r&#x27;\d+&#x27;, &#x27;baidu 123 google 456&#x27;)   </span><br><span class="line">#返回：\[&#x27;123&#x27;, &#x27;456&#x27;]  </span><br><span class="line">result2 = re.findall(r&#x27;\d+&#x27;, &#x27;bai88du123google456&#x27;, 0, 10)  </span><br><span class="line">#返回：\[&#x27;88&#x27;, &#x27;12&#x27;]  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 6.1.6 查询子串（返回迭代器）  </span><br><span class="line">re.finditer(pattern, string, flags=0):在字符串中找到正则表达式匹配的所有子串,并把它们作为一个迭代器返回  </span><br><span class="line">``` python  </span><br><span class="line">it = re.finditer(r&quot;\d+&quot;,&quot;12a32bc43jf3&quot;)   </span><br><span class="line">for match in it:  </span><br><span class="line">	print(match.group())   </span><br><span class="line">#返回：12,32,43,3  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 6.1.7 切分字符串  </span><br><span class="line">re.split(pattern, string\[, maxsplit=0, flags=0]):按照能够匹配的子串将字符串分割后返回列表  </span><br><span class="line">maxsplit:分隔次数,maxsplit=1 分隔一次,默认为 0,不限制次数  </span><br><span class="line">``` python  </span><br><span class="line">re.split(&#x27;\W+&#x27;, &#x27;baidu, baidu, baidu.&#x27;)   </span><br><span class="line">#返回：\[&#x27;baidu&#x27;, &#x27;baidu&#x27;, &#x27;baidu&#x27;, &#x27;&#x27;]  </span><br><span class="line">re.split(&#x27;(\W+)&#x27;, &#x27; baidu, baidu, baidu.&#x27;)   </span><br><span class="line">#返回：\[&#x27;&#x27;, &#x27; &#x27;, &#x27;baidu&#x27;, &#x27;, &#x27;, &#x27;baidu&#x27;, &#x27;, &#x27;, &#x27;baidu&#x27;, &#x27;.&#x27;, &#x27;&#x27;]  </span><br><span class="line">re.split(&#x27;\W+&#x27;, &#x27; baidu, baidu, baidu.&#x27;, 1)   </span><br><span class="line">#返回：\[&#x27;&#x27;, &#x27;baidu, baidu, baidu.&#x27;]  </span><br><span class="line">re.split(&#x27;a*&#x27;, &#x27;hello world&#x27;)   </span><br><span class="line">#返回：\[&#x27;hello world&#x27;]  </span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">## 7 常用正测  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">#### 7.1.1 去掉括号中内容  </span><br><span class="line">``` python  </span><br><span class="line">re.sub(u&quot;\\(.*?\\)|\\&#123;.*?&#125;|\\[.*?]&quot;, &quot;&quot;, s)  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 7.1.2 找中文  </span><br><span class="line">```  </span><br><span class="line">re.findall(&#x27;[\u4e00-\u9fa5]&#x27;, string)  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 7.1.3 切分中英文  </span><br><span class="line">```  </span><br><span class="line">[x for x in re.split(&#x27;([\u4e00-\u9fa5]+)&#x27;,&#x27;中文_en拆分&#x27;) if x != &#x27;&#x27;]  </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python的Debug工具</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%B7%A5%E5%85%B7/Python%E7%9A%84Debug%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<h1 id="python的debug工具">Python的Debug工具</h1>
<p>#Python</p>
<h2 id="命令行使用pdb">1. 命令行使用pdb</h2>
<h4 id="我们先写个简单的python程序a.py如下">(1)
我们先写个简单的python程序a.py如下：</h4>
<pre><code>for i in range(0,3):  
    print(i)  
    print(&quot;@@@@&quot;)  
    print(&quot;###&quot;)  </code></pre>
<h4 id="用pdb调试">(2) 用pdb调试</h4>
<pre><code>$ pdb a.py  # 此后看到 &gt; 提示符，即可以输入命令调试  </code></pre>
<h2 id="常用pdb命令">2. 常用pdb命令</h2>
<p>pdb命令和gdb差不多，最常用的命令如下：<br />
(1) 单步调试（进入函数）：s(tep)<br />
(2) 单步调试（不进入函数）：n(ext)<br />
(3) 继续往后执行，直到下个断点：c(ont(inue))<br />
(4) 运行到函数结束：r(eturn)<br />
(5) 运行到当前循环结束：unt(il)<br />
(6) 设置断点：b(reak) 文件名:行号（或行号，或函数名）<br />
(7) 显示当前调用关系：w(here)<br />
(8) 显示当前代码段：l(ist)<br />
(9) 显示变量：p(rint) 变量名<br />
(10) 显示当前函数的参数：a(rgs)<br />
(11) 显示帮助信息：h(elp)<br />
(12) 退出：q(uit)</p>
<h2 id="notebook使用pdb">3. Notebook使用pdb</h2>
<h4 id="单步调试">(1) 单步调试</h4>
<p> 用Notebook开发时，常把功能分块写入Cell分别调试，类似单步调试，但有时需要在现有函数内部调试，或者单步运行，此时可以直接在程序中打断点：想在哪儿打断点，就在该处输入：</p>
<pre><code>import pdb; pdb.set_trace()  </code></pre>
<p> 运行到此处时就出现了pdb的命令行，此时我们可以输入上方的pdb命令单步调试，也可以在输入框中运行python语句。</p>
<h4 id="程序报错时调出pdb">(2) 程序报错时调出pdb</h4>
<p> 在程序中加入%pdb即可</p>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python设置三方库路径</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%B7%A5%E5%85%B7/Python%E8%AE%BE%E7%BD%AE%E4%B8%89%E6%96%B9%E5%BA%93%E8%B7%AF%E5%BE%84/</url>
    <content><![CDATA[<h1 id="python设置三方库路径">Python设置三方库路径</h1>
<p>#Python</p>
<p>一般安装Python的三方库，直接使用Python的包管理工具pip，或者下载源码包后，使用其中的setup.py安装，就可以直接安装在Python的系统库目录中了．</p>
<p>如果想使用一个三方库，又不想安装在Python的默认库目录中，可以程序中使用
”sys.path.append("具体路径")”<br />
将三方库路径暂时加入库路径．如果想操作一次，之后任何程序都可以直接使用，比如自己写的库，以Ubuntu系统为例，示例如下：</p>
<h2 id="建立自己的库">1. 建立自己的库</h2>
<pre><code><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    $ mkdir /tmp/8888  # 建自己的库目录，此处只是试验，/tmp目录一重启就清除了  </span><br><span class="line">    $ vi /tmp/8888/x888.py   # 编写库文件，内容如下  </span><br><span class="line">    def testme():  </span><br><span class="line">        print &#x27;hahahaha&#x27;  </span><br><span class="line">    ```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">##  2\. 看一下python的默认库路径  </span><br><span class="line">  </span><br><span class="line">    ```  </span><br><span class="line">    $ python  </span><br><span class="line">    &gt;&gt;&gt; import sys  </span><br><span class="line">    &gt;&gt;&gt; sys.path # 此时会显示python的库路径，一般有很多个，在ubuntu下一般包括/usr/local/lib/python2.7/dist-packages/等  </span><br><span class="line">   	```   </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">##  3\. 把三方库路径写入”.pth”文件  </span><br><span class="line">  </span><br><span class="line">    ```  </span><br><span class="line">    $ sudo vi /usr/local/lib/python2.7/dist-packages/testme.pth # 在默认的库路径中建立一个x.pth文件，写入内容如下:  </span><br><span class="line">    /tmp/8888  </span><br><span class="line">	```  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">##  4\. 调用三方库  </span><br><span class="line">  </span><br><span class="line">    ```  </span><br><span class="line">	$ python  </span><br><span class="line">    &gt;&gt;&gt; import x888  </span><br><span class="line">    &gt;&gt;&gt; x888.testme()  </span><br></pre></td></tr></table></figure></code></pre>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>常用的色板</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E5%B7%A5%E5%85%B7/%E5%B8%B8%E7%94%A8%E7%9A%84%E8%89%B2%E6%9D%BF/</url>
    <content><![CDATA[<h1 id="常用的色板">常用的色板</h1>
<p>#图形图像 #Python</p>
<h3 id="说明">1. 说明</h3>
<p>有时候需要从图像中判断某种颜色，或者获取某个颜色区域，此时常用HSV色板判断。因为在HSV的色彩空间中，只需要判断颜色通道即可。本篇介绍HSV色板，及其在python中的转换和使用方法。</p>
<h3 id="色板">2. 色板</h3>
<p><strong>(1) RGB</strong></p>
<p>三个通道，红色Red, 绿色Green,
蓝色Blue，值越大颜色越大，当三个值都大时为白色，三个值都为0时为黑色。</p>
<p><strong>(1) HSV</strong></p>
<p>三个通道，HSV(Hue, Saturation,
Value)是根据颜色的直观特性创建的一种颜色空间,
也称六角锥体模型(Hexcone<br />
Model)。这个模型中颜色的参数分别是：色调（H），饱和度（S），明度（V）。</p>
<p><img
src="https://upload-%20images.jianshu.io/upload_images/5357893-5e3dce368c7a1cfb.png?imageMogr2/auto-%20orient/strip%7CimageView2/2/w/217" /></p>
<p><strong>(1) GRAY</strong><br />
灰度图，只有一个通道。</p>
<h3 id="图示代码">3. 图示代码</h3>
<pre><code>```  
import cv2 as cv  
from matplotlib import pyplot as plt  
% matplotlib inline  
  
img = cv.imread(None)  
rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)  
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)  
  
hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)  
plt.figure(figsize=(9,7), dpi=800)  
plt.subplot(3, 3, 1), plt.imshow(rgb), plt.title(&quot;base&quot;)  
plt.subplot(3, 3, 2), plt.imshow(rgb[:,:,0],&#39;gray&#39;), plt.title(&quot;red&quot;)  
plt.subplot(3, 3, 3), plt.imshow(rgb[:,:,1],&#39;gray&#39;), plt.title(&quot;green&quot;)  
plt.subplot(3, 3, 4), plt.imshow(rgb[:,:,2],&#39;gray&#39;), plt.title(&quot;blue&quot;)  
plt.subplot(3, 3, 5), plt.imshow(gray,&#39;gray&#39;), plt.title(&quot;gray&quot;)  
plt.subplot(3, 3, 6), plt.imshow(hsv[:,:,0],&#39;gray&#39;), plt.title(&quot;H&quot;)  
plt.subplot(3, 3, 7), plt.imshow(hsv[:,:,1],&#39;gray&#39;), plt.title(&quot;S&quot;)  
plt.subplot(3, 3, 8), plt.imshow(hsv[:,:,2],&#39;gray&#39;), plt.title(&quot;V&quot;)  
plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, hspace=0.1, wspace=0.3)  
  
plt.show()  
```  </code></pre>
<h3 id="图示效果">4. 图示效果</h3>
<p><img
src="https://upload-%20images.jianshu.io/upload_images/5357893-78c9cb9f710195c1.png?imageMogr2/auto-%20orient/strip%7CimageView2/2/w/558" /></p>
<h3 id="分析">5. 分析</h3>
<p>这里大多数的图和想象中差不多，比较特别的是H图，可以看到同样的底色白色，在H图中显示出很大差异。</p>
<p>在判断一些图像成份时，可以采取多种标准，比如用灰度图(gray)或者亮度图(V)判断其是否为白色或浅色，而在颜色较深的区域再去判断其具体然调(H)</p>
<p>当V大而S小时，即是白色。</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>图形图像</tag>
      </tags>
  </entry>
  <entry>
    <title>Bootstrap、Python、Flask做简单的前端</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E7%BD%91%E7%BB%9C/Bootstrap%E3%80%81Python%E3%80%81Flask%E5%81%9A%E7%AE%80%E5%8D%95%E7%9A%84%E5%89%8D%E7%AB%AF/</url>
    <content><![CDATA[<h1 id="bootstrappythonflask-做简单的前端">Bootstrap、Python、Flask
做简单的前端</h1>
<p>#Python</p>
<h3 id="说明">1. 说明</h3>
<p> 无论做什么类型的程序，都难免需要给别人展示一下。Web展示是个很好的方案，做起来省事，效果好，可交互，无需安装，跨平台，等等等等，算是个必备技能，与做PPT比肩。
前一阵用pyecharts做网页统计图，发现自己做的界面实在太丑，同时又想引用一些现成的风格和控件，于是学习了一下Web前端框架，顺带熟悉一下JS。菜鸟入门，记录如下，仅供参考。</p>
<h3 id="前端流行框架">2. 前端流行框架</h3>
<p> 先看看几种流行的前端框架：BootStrap, React, Vue。<br />
 BootStrap容易上手，学习成本低，它提供了一些常用的css和js，拿来就能用。<br />
 React是数据单向响应的，数据发生变化时，前端UI即可随之变化。React可管理Dom树的变化，使页面呈现更快。<br />
 Vue站在了React的肩膀上,
许多方面更出色，如数据的双向绑定，速度更快，组件化，方便打包和发布等等，但相对来说上手的难度较大。<br />
 长远考虑, 建议使用Vue+node.js. 短期简单使用,
BootStrap是个不错的选择。因此在这里选择了Bootstrap。</p>
<h3 id="下载">3. 下载</h3>
<p><strong>(1) 下载软件包</strong><br />
<a
href="https://v3.bootcss.com/getting-started/#download">https://v3.bootcss.com/getting-started/#download</a><br />
 在此可以直接下载用于生产环境的bootstrap，解压后看到，有css, fonts,
js三个目录，总共1.7M。剩下的就是看看怎么在html里面引用它们。</p>
<p><strong>(2) 下载最新源码</strong><br />
  更建议下源码，里面有些测试程序和demo，学习和调试更方便。</p>
<pre><code>$ git clone https://github.com/twbs/bootstrap.git  </code></pre>
<p><strong>(3) 其它组件</strong><br />
 我还下载了bootstrap的日期时间控件，它的支持比较强大，比如进行月级别的选择。使用它，在不支持html5的浏览器中也可以正常使用时间日期控件了。</p>
<pre><code>$ git clone git://github.com/smalot/bootstrap-datetimepicker.git  </code></pre>
<h3 id="实例">4. 实例</h3>
<p><strong>(1) 目录结构</strong></p>
<p> 我只写了index.html和run.py两个文件，使用了python的flask框架支持http服务。其它内容都是从刚下载bootstrap目录下复制过来的（拷进来直接用即可，无需安装），具体的存放位置随意，只要在html文件指定好路径即可。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-8663e5b669c6feb5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><strong>(2) run.py</strong></p>
<pre><code>from flask import Flask  
from flask import render_template  
  
app = Flask(__name__)  
@app.route(&#39;/&#39;, methods=[&#39;GET&#39;, &#39;POST&#39;])  
def index():  
 return render_template(&#39;index.html&#39;)  
app.run(debug=True)  </code></pre>
<p><strong>(3) index.html</strong></p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode javascript"><code class="sourceCode javascript"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;!</span>DOCTYPE html<span class="op">&gt;</span>  </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>html<span class="op">&gt;</span>  </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>head<span class="op">&gt;</span>  </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a> <span class="op">&lt;</span>title<span class="op">&gt;&lt;/</span>title<span class="op">&gt;</span>  </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a> <span class="op">&lt;</span>link href<span class="op">=</span><span class="st">&quot;/static/bootstrap/css/bootstrap.css&quot;</span> rel<span class="op">=</span><span class="st">&quot;stylesheet&quot;</span> media<span class="op">=</span><span class="st">&quot;screen&quot;</span><span class="op">&gt;</span>  </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a> <span class="op">&lt;</span>link href<span class="op">=</span><span class="st">&quot;/static/bootstrap-datetime/css/bootstrap-datetimepicker.css&quot;</span> rel<span class="op">=</span><span class="st">&quot;stylesheet&quot;</span> media<span class="op">=</span><span class="st">&quot;screen&quot;</span><span class="op">&gt;</span>  </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;/</span>head<span class="op">&gt;</span>  </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>body<span class="op">&gt;</span>  </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a> <span class="op">&lt;</span>input size<span class="op">=</span><span class="st">&quot;16&quot;</span> type<span class="op">=</span><span class="st">&quot;text&quot;</span> value<span class="op">=</span><span class="st">&quot;2012-06-15 14:45&quot;</span> readonly <span class="kw">class</span><span class="op">=</span><span class="st">&quot;form_datetime&quot;</span><span class="op">&gt;</span>  </span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>script type<span class="op">=</span><span class="st">&quot;text/javascript&quot;</span> src<span class="op">=</span><span class="st">&quot;/static/jquery/js/jquery.js&quot;</span> charset<span class="op">=</span><span class="st">&quot;UTF-8&quot;</span><span class="op">&gt;&lt;/</span>script<span class="op">&gt;</span>  </span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>script type<span class="op">=</span><span class="st">&quot;text/javascript&quot;</span> src<span class="op">=</span><span class="st">&quot;/static/bootstrap/js/bootstrap.min.js&quot;</span><span class="op">&gt;&lt;/</span>script<span class="op">&gt;</span>  </span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>script type<span class="op">=</span><span class="st">&quot;text/javascript&quot;</span> src<span class="op">=</span><span class="st">&quot;/static/bootstrap-datetime/js/bootstrap-datetimepicker.js&quot;</span> charset<span class="op">=</span><span class="st">&quot;UTF-8&quot;</span><span class="op">&gt;&lt;/</span>script<span class="op">&gt;</span>  </span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>script type<span class="op">=</span><span class="st">&quot;text/javascript&quot;</span><span class="op">&gt;</span>  </span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a> <span class="fu">$</span>(<span class="st">&#39;.form_datetime&#39;</span>)<span class="op">.</span><span class="fu">datetimepicker</span>(&#123;  </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a> <span class="dt">weekStart</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span>  </span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a> <span class="dt">todayBtn</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span>  </span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a> <span class="dt">autoclose</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span>  </span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a> <span class="dt">todayHighlight</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span>  </span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a> <span class="dt">startView</span><span class="op">:</span> <span class="dv">2</span><span class="op">,</span>  </span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a> <span class="dt">forceParse</span><span class="op">:</span> <span class="dv">0</span><span class="op">,</span>  </span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a> <span class="dt">showMeridian</span><span class="op">:</span> <span class="dv">1</span>  </span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a> &#125;)<span class="op">;</span>  </span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;/</span>script<span class="op">&gt;</span>  </span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;/</span>body<span class="op">&gt;</span>  </span></code></pre></div>
</html>
<p>运行效果如下：</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-a67c249ec0eaf89f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="问题与解答">5. 问题与解答</h3>
<p> 在使用中遇到一些问题，整理如下：</p>
<p><strong>(1) 在html中何处加入css和js的引用？</strong><br />
 在html中，一般把css写上边，把js写下边，因为如果js较大，load时间较长时，会影响网页显示速度，而css不占load时间，比如有时候我们网速慢，load网页时，字虽然出来了，但一开始风格显示不对，这就是因为css还没load完，也间接地说明css并未在开始load。</p>
<p><strong>(2)
Html中的<code>&#123;% xxx %&#125;</code>是干什么用的？</strong><br />
 <code>&lt;% %&gt;</code> 里面可以添加java代码片段</p>
<p><strong>(3) 加入日期时间控件是不是还需要下其它的包？</strong><br />
  需要另外安装bootstrap-datetimepicker
项目，它包括了年视图，月视图，小时视图，很好用的。</p>
<p><strong>(4) bootstrap需要安装，还是解包后直接使用？</strong><br />
 解包后直接使用</p>
<p><strong>(5) 对js和css存放的目录有什么特殊要求？</strong><br />
  对于js和css的目录，怎么放都行，只要在程序里指对位置就可以。</p>
<p><strong>(6) Xx.min.js与xx.js有什么区别？</strong><br />
 min.js是js的压缩格式</p>
<p><strong>(7) Javascript怎么用在html中？</strong><br />
  &lt;script&gt;xxxx&lt;script&gt;可以有多个script标签</p>
<p><strong>(8) Div是干什么用的</strong><br />
  Div在html中定义了块，可以通过 &lt;div&gt; 的 class 或 id
应用单独的样式。</p>
<p><strong>(9) 怎么让div不换行</strong><br />
  每个Div默认换行，如果不想换行，在head中加&lt;style&gt; div{
float:left}
&lt;/style&gt;，但它会把所有div都变成不换行，一般设完后layout就会乱掉。
实际上，换行是 &lt;div&gt; 固有的格式表现，想不换行用&lt;span&gt;</p>
<p><strong>(10) 怎么让几个控件横排，并指定显示比例为1/n</strong><br />
用&lt;div class=”row”&gt;</p>
<p><strong>(11) 怎么让一组控件整体居中</strong><br />
外边加一个&lt;div class=’container’&gt;</p>
<p><strong>(12) 如何改变元素的值</strong><br />
 
在javascript中设定，形如：document.getElementById('draw').value='1'</p>
<h3 id="参考">6. 参考</h3>
<p><strong>(1) BootStrap, React, Vue</strong><br />
<a
href="http://blog.51cto.com/12444007/1967291">http://blog.51cto.com/12444007/1967291</a></p>
<p><strong>(2) Flask 项目中使用 bootstrap</strong><br />
<a
href="https://blog.csdn.net/os373/article/details/79620450">https://blog.csdn.net/os373/article/details/79620450</a></p>
<p><strong>(3) Bootstrap网站</strong><br />
<a href="https://v3.bootcss.com/">https://v3.bootcss.com/</a></p>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python爬虫</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E7%BD%91%E7%BB%9C/Python%E7%88%AC%E8%99%AB/</url>
    <content><![CDATA[<h1 id="python爬虫">Python爬虫</h1>
<p>#Python #爬虫</p>
<h2 id="说明">1. 说明</h2>
<p> 做数据挖掘常常需要抓取网页内容，有些工具能通过分析url中的链接，把整个网站抓下来，也就是我们常说的爬虫工具。</p>
<p> 有时候需要把交互网页的内容抓下来，比如：在input框中输入想查的内容，服务器端实时计算结果，或者从数据库中查询后返回结果。像整句翻译功能，查询食物的热量等等。下面介绍Python用GET和POST方式抓取实时内容的方法。</p>
<h2 id="get方式">2. GET方式</h2>
<p> GET方式把要查询的参数放在url地址中，非常简单。下例用Python程序，查询运单信息，写法如下：</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> urllib.request    </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">&#39;http://cha.xxx.cn/?stype=kd&amp;q=123456&#39;</span>  </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>req <span class="op">=</span> urllib.request.Request(url)    </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>html <span class="op">=</span> urllib.request.urlopen(req).read()  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(html.decode(<span class="st">&quot;utf8&quot;</span>))  </span></code></pre></div>
<p> GET方式，用问号和等号“addr?key=value”的方式，以明文的方式，向服务器传送要查询的内容。此时，就能打印出html网页的内容了。由此可见python的网络工具真的很方便。</p>
<p> 有时候需要查询一些中文信息，比如查询樱桃的卡路里，需要字换中文字符，可使用以下方法：</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#-*- coding:utf-8 -*-  </span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> urllib.request    </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> urllib.parse    </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">&quot;http://www.xxx.com/food/search&quot;</span>  </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>postdata <span class="op">=</span> urllib.parse.urlencode(&#123;    </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;keyword&quot;</span>:<span class="st">&quot;樱桃&quot;</span>    </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>&#125;).encode(<span class="st">&quot;utf-8&quot;</span>)  </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>req <span class="op">=</span> urllib.request.Request(url,postdata)    </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>html <span class="op">=</span> urllib.request.urlopen(req).read()  </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(html.decode(<span class="st">&quot;utf8&quot;</span>))  </span></code></pre></div>
<h2 id="post方式">3. POST方式</h2>
<p> POST方法相对复杂一些，常用它传送用户名，密码等不可见的参数，使用它的主要问题是：不知道程序定义的关键字key是什么。一般可以通过查看页源码，看它表单的input中如何定义，但有时候源码中调用其它程序实现，不能直接看到关键字，下面介绍如何使用浏览器提供的工具，查看本地与服务器的交互信息，以确定关键字。</p>
<p> 在浏览器中打开翻译网站（最好使用chrome或chromium），按F12打开调试工具。选择其中的Netword选项卡。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-2146c91cde5f5056.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 在输入框中输入要翻译的内容“樱桃”，点“翻译”按钮时，查看调试工具中最核心的步骤是检测当前语言”langdetect”和翻译”v2transapi”，点击该项，即可以查看请求的具体内容和返回值。以检测当前语言为例，其中请求内容中就有其request
url(http://fanyi.baidu.com/langdetect)，以及关键字(post参数query）。把它们设置在Python中即可，具体方法如下：</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># coding:utf-8    </span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests  </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">&quot;http://fanyi.xxx.com/langdetect&quot;</span>   </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> &#123;<span class="st">&quot;query&quot;</span>:<span class="st">&quot;樱桃&quot;</span>&#125;  </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> requests.post(url, data<span class="op">=</span>d)  </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r.text)     </span></code></pre></div>
<p> 此时，返回的是json串，数据少容易解析。</p>
<h2 id="参考">4. 参考</h2>
<p> Python网络爬虫（Get、Post抓取方式）<br />
https://blog.csdn.net/fly_yr/article/details/49005033</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>SOAP协议及Python调用</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E7%BD%91%E7%BB%9C/SOAP%E5%8D%8F%E8%AE%AE%E5%8F%8APython%E8%B0%83%E7%94%A8/</url>
    <content><![CDATA[<h1 id="soap协议及python调用">SOAP协议及Python调用</h1>
<p>#Python</p>
<h2 id="什么是soap协议">1. 什么是SOAP协议</h2>
<p> SOAP 是一种简单的基于 XML 的协议，它底层通过 HTTP
来交换信息。SOAP的优点是可以传递结构化的数据。<br />
 客户生成的SOAP请求会被嵌入在一个HTTP
POST请求中，发送到Web服务器。Web服务器再把这些请求转发给Web
service请求处理器，它解析收到的SOAP请求，调用Web
service，处理后再生成相应的SOAP应答。Web服务器得到SOAP应答后，会再通过HTTP应答的方式把它送回到客户端。<br />
 从HTTP协议的角度看，最基本的四种操作是GET（查），POST（改），PUT（增），DELETE（删），我们用的比较多的是POST和GET方式。而SOAP
可视为POST的一个专用版本，遵循一种特殊的XML消息格式。<br />
 最常见的场景是：Server端使用了SOAP协议，而Client端也必须遵从该协议才能交互，本文介绍一下，如何在Client端使用SOAP协议，以及如何配置SOAP测试环境。</p>
<h2 id="什么是wsdl">2. 什么是WSDL</h2>
<p> 网络服务描述语言，Web Services Description Language)是一门基于 XML
的语言，用于描述 Web Services 以及如何对它们进行访问。<br />
 简单的说，它就是一个Web Services的使用说明书。来看一个实例：<br />
http://ws.webxml.com.cn/WebServices/MobileCodeWS.asmx?wsdl<br />
这是一个查询电话号码的接口描述，WSDL教程详见参考部分。</p>
<h2 id="python使用soap协议">3. Python使用SOAP协议</h2>
<h4 id="安装支持库">(1) 安装支持库</h4>
<p> 如果开发服务端，可使用soaplib，SOAPpy等库，本文主要介绍开发客户端，使用suds库。<br />
 在python2中使用以下命令安装：</p>
<pre><code>$ sudo pip install suds  </code></pre>
<p> 在python3中使用以下命令安装：</p>
<pre><code>$ sudo pip install suds-py3  </code></pre>
<h4 id="程序调用">(2) 程序调用</h4>
<pre><code>from suds.client import Client  
  
client = Client(&#39;http://ws.webxml.com.cn/WebServices/MobileCodeWS.asmx?wsdl&#39;)  
print(client.service.getMobileCodeInfo(&#39;13581855347&#39;,&#39;&#39;))  </code></pre>
<p> 这是一个查询电话号码所在地的程序。</p>
<h2 id="搭建测试环境soapuiwsdl">4. 搭建测试环境SOAPUI+WSDL</h2>
<p> SoapUI是专门针对webservice接口的测试工具，它即可以模拟Client，也可以模拟Server。下面是在Ubuntu上安装SOAPUI的方法。</p>
<h4 id="下载soapui">(1) 下载SOAPUI</h4>
<p>https://www.soapui.org/downloads/latest-release.html</p>
<h4 id="安装">(2) 安装</h4>
<pre><code>$ sudo ./SoapUI-x64-5.4.0.sh  
$ sudo SoapUI-5.4.0 # 运行  </code></pre>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-767dd86d188e8b08.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h4 id="作为server端测试">(3) 作为Server端测试</h4>
<p> 在Projects上点右键，选择New SOAP Project，Project
Name启一个名字，Initial
WSDL中填写http://ws.webxml.com.cn/WebServices/MobileCodeWS.asmx?wsdl新建一个Project，当然也可以参考例子编写自己的接口。<br />
 在MobileCodeWSSoap12上，点右键Generate SOAP Mock
Service，按提示建立Service，然后点绿色键头运行。</p>
<p><img
src="https://upload-images.jianshu.io/upload_images/5357893-7ca0f71fa53e369f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p> 此时，打开http://127.0.0.1:8088/，能看到Service已被启动，把上面python上的测试的IP换成本机地址，也可正常运行了。</p>
<h2 id="参考">5. 参考</h2>
<h4 id="suds调用webserive时出现suds.typenotfound错误">(1)
suds调用webserive时出现suds.TypeNotFound错误</h4>
<p>http://www.mamicode.com/info-detail-2324352.html</p>
<h4 id="wsdl-教程">(2) WSDL 教程</h4>
<p>http://www.w3school.com.cn/wsdl/</p>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Swagger和Python配合使用</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E7%BD%91%E7%BB%9C/Swagger%E5%92%8CPython%E9%85%8D%E5%90%88%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h1 id="swagger和python配合使用">Swagger和Python配合使用</h1>
<p>#Python</p>
<h2 id="说明">1. 说明</h2>
<p> 先来看一个应用场景：<br />
 我写了一段功能性的程序（可能是Java的，也可能是Python的），供他人调用（调我程序可能是其它编程语言，或者直接运行，如果调用者对我使用的工具不熟悉，直接调用可能很麻烦），这个程序需要传入多个参数，需要结构化的输出，我以什么方式提供给比较好呢？<br />
 我们可能会选择BS的结构，建立一个Web-Server，然后把功能性的程序放在Web-Server上并向外暴露接口，其它程序用Http协议调用该接口，以POST或GET的方式转入参数，然后得到返回结果。<br />
 于是我们就需要定义一些交互协议，写接口描述文档，在调用出错时，联调是哪一端的问题，总之，沟通成本很高。<br />
 Swagger可以很好地解这一问题，一方面，它能按规范自动生成接口文档（以网页形式提供），这样编写API和编写文档同时完成，几乎不用考虑文本和代码版本不同步的问题；另一方面，它能提供测试界面，我们只需要在网页上填写相应的参数，点击调用（网页由swagger生成），就可以轻松调用接口，使得服务端的开发者，不使用客户端，就可以完整地调试代码。</p>
<h2 id="python-flask-swagger实现">2. Python &amp; Flask &amp;
Swagger实现</h2>
<h4 id="工具介绍">(1) 工具介绍</h4>
<ol type="i">
<li><p>Python<br />
 在这里选择介绍Python+Swagger，因为Python真的非常简单，不需要关心太多的代码，库，复杂的环境，只要关注流程本身即可。<br />
另外，我这里的开发环境是python 2.7。</p></li>
<li><p>Flask<br />
 Flask是Python的Web框架，Python的Web框架还有Django，Tornado，Bottle等等，Flask功能虽然不及Django和Tornado强大，但它是个轻量级的工具，三方开源组件也比较丰富。</p></li>
<li><p>Swagger<br />
 支持Python+Flask的Swagger库不少，有flask-swag，flask-swagger，flasgger，本例中选用的是flasgger，它的软件包中包括了Swagger-UI，除了安装工具包，几乎不需要配置其它环境。</p></li>
<li><p>Nodejs与npm<br />
 Nodejs是服务器后端的JavaScript的工具。<br />
 Npm是一个JavaScript的包管理程序，它就像python中的pip，用于下载和管理三方工具。<br />
 Swagger主要是用javascript实现的，因此依赖node工具集。</p></li>
</ol>
<h4 id="安装node工具集">(2) 安装Node工具集</h4>
<p> 虽然node能用apt-get方式安装，但最好下载使用最新版本的node，版本太旧可能遇到各种问题。<br />
 我下载的是http://nodejs.cn/download/
中64位的linux版本，这里面也包括NPM工具，不用另外安装。解压之后，将其中的bin,
lib等目录复制到/usr/local/的对应目录下即可使用。</p>
<h4 id="安装python的三方工具包">(3) 安装Python的三方工具包</h4>
<pre><code>$ sudo pip install flask  
$ sudo pip install flasgger  </code></pre>
<h4 id="编写test.py程序">(4) 编写test.py程序</h4>
<pre><code>#coding:utf8  
  
import sys  
import random  
reload(sys)  
sys.setdefaultencoding(&#39;utf8&#39;)  
from flask import Flask,Blueprint,render_template,request,redirect,jsonify  
from flasgger import Swagger,swag_from  
  
app = Flask(__name__)  
Swagger(app)  
  
@app.route(&#39;/api/&lt;string:language&gt;/&#39;, methods=[&#39;GET&#39;])  
def index(language):  
    &quot;&quot;&quot;  
    This is the language awesomeness API  
    Call this api passing a language name and get back its features  
    ---  
    tags:  
      - Awesomeness Language API  
    parameters:  
      - name: language  
        in: path  
        type: string  
        required: true  
        description: The language name  
      - name: size  
        in: query  
        type: integer  
        description: size of awesomeness  
    responses:  
      500:  
        description: Error The language is not awesome!  
      200:  
        description: A language with its awesomeness  
        schema:  
          id: awesome  
          properties:  
            language:  
              type: string  
              description: The language name  
              default: Lua  
            features:  
              type: array  
              description: The awesomeness list  
              items:  
                type: string  
              default: [&quot;perfect&quot;, &quot;simple&quot;, &quot;lovely&quot;]  
  
    &quot;&quot;&quot;  
  
    language = language.lower().strip()  
    features = [  
        &quot;awesome&quot;, &quot;great&quot;, &quot;dynamic&quot;,   
        &quot;simple&quot;, &quot;powerful&quot;, &quot;amazing&quot;,   
        &quot;perfect&quot;, &quot;beauty&quot;, &quot;lovely&quot;  
    ]  
    size = int(request.args.get(&#39;size&#39;, 1))  
    if language in [&#39;php&#39;, &#39;vb&#39;, &#39;visualbasic&#39;, &#39;actionscript&#39;]:  
        return &quot;An error occurred, invalid language for awesomeness&quot;, 500  
    return jsonify(  
        language=language,  
        features=random.sample(features, size)  
    )  
  
app.run(debug=True)  </code></pre>
<h4 id="运行test.py程序">(5) 运行test.py程序</h4>
<pre><code>$ python test.py  </code></pre>
<p> 此时，用浏览器访问：http://localhost:5000/apidocs/，就可以看到Swagger界面了，程序中双引号内是一个非常简单的接口描述，我们可以把它写程序中，或者用@swag_from('index.yml')的方式，将描述文件yml引入程序。<br />
在该界面上点“try it out”，按钮就可以在网页上测试该接口。</p>
<h2 id="其它工具和方法">3. 其它工具和方法</h2>
<p> 在网上看到一般安装swagger方法，是从git下载swagger-edit，swagger-ui：</p>
<pre><code>$ git clone https://github.com/swagger-api/swagger-editor  
$ git clone https://github.com/swagger-api/swagger-ui  </code></pre>
<p> 然后用工具http-server通过调用其目录中的index.html提供Web界面，其中的接口在yml文件中定义，yml接口一般是在编写API时程序时，通过引入swagger相关库，按照规则，自动生成的，手动编写yml文件的比较少。步骤也相对比较复杂。</p>
<h2 id="参考">4. 参考</h2>
<h4 id="flasgger使用心得">(1) Flasgger使用心得</h4>
<p>https://changsiyuan.github.io/2017/05/20/2017-5-20-flasgger/</p>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python获取国内股票数据</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E8%82%A1%E7%A5%A8/Python%E8%82%A1%E7%A5%A8%E5%A4%84%E7%90%86%E4%B9%8B%E4%B8%80_%E8%8E%B7%E5%8F%96%E5%9B%BD%E5%86%85%E8%82%A1%E7%A5%A8%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<h1 id="python获取国内股票数据">Python获取国内股票数据</h1>
<p>#Python #股票</p>
<h2 id="安装支持库">1 安装支持库</h2>
<pre><code>$ pip install panda  
$ pip install tushare  </code></pre>
<h2 id="说明">2 说明</h2>
<p>Pandas是数据分析工具包<br />
TuShare是国内股票数据抓取工具，除了股票的实时和历史数据，还有基本面数据，加上自然语言处理（比如情绪分析），或者机器学习，就比较有趣了。</p>
<h2 id="程序">3 程序</h2>
<h3 id="代码">3.1 代码</h3>
<pre><code>import tushare as ts  
d = ts.get_tick_data(&#39;601318&#39;,date=&#39;2017-06-26&#39;)  
print d  
e = ts.get_hist_data(&#39;601318&#39;,start=&#39;2017-06-23&#39;,end=&#39;2017-06-26  
&#39;)  
print e  </code></pre>
<h3 id="执行结果">3.2 执行结果</h3>
<pre><code>…  
4758  09:30:01  50.02  0.03    1044   5226339  买盘  
4759  09:28:45  49.99    --       0         0  卖盘  
4760  09:25:02  49.99 49.99    7370  36843929  买盘  
…  
date open   high  close   low      volume price_change  p_change    
2017-06-26  49.99  50.77 49.72  49.35   53192.56          0.00      0.00    
2017-06-23  49.24  49.90 49.72  48.79   73719.62          0.58      1.18    
ma5    ma10    ma20     v_ma5     v_ma10     v_ma20 turnover    
49.222  48.320  47.288 887897.74  860166.06  857338.21     0.88    
48.990  48.241  47.076 858955.61  850806.49  879173.58     0.81    </code></pre>
<p>返回蜡烛图数据，成交量，以及5,10,20日均线</p>
<h2 id="更新">4 更新</h2>
<p>2022年2月测试，以下接口暂时可用</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tushare <span class="im">as</span> ts  </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>ts.get_hist_data(<span class="st">&#39;600848&#39;</span>)   </span></code></pre></div>
<h2 id="参考">5 参考</h2>
<h3 id="tushare详细用法">5.1 TuShare详细用法</h3>
<p>http://tushare.waditu.com/trading.html</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>股票</tag>
      </tags>
  </entry>
  <entry>
    <title>Python股票处理之七_数据库存储</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E8%82%A1%E7%A5%A8/Python%E8%82%A1%E7%A5%A8%E5%A4%84%E7%90%86%E4%B9%8B%E4%B8%83_%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%98%E5%82%A8/</url>
    <content><![CDATA[<h1
id="python股票处理之七_数据库存储">Python股票处理之七_数据库存储</h1>
<p>#股票 #Python</p>
<h2 id="说明">1. 说明</h2>
<p>股票数据无需每次都从网上下载，像日线级别的历史数据会常常用到，使用多线程下载一般也需要几个小时，最好存储到本地，除了已有的特征值，还有清洗后的数据，和计算出的新特征值，以及需要与其它程序共享数据。相对于数据文件，使用数据库更合适。<br />
本文介绍pandas（数据结构支持）通过sqlalchemy与数据库连接，存储tushare下载的日线数据，用一套代码操作不同数据库（Mysql/sqlite）。</p>
<h2 id="安装数据库">2. 安装数据库</h2>
<h4 id="sqlalchemy工具">1) Sqlalchemy工具</h4>
<pre><code>$ pip install sqlalchemy  </code></pre>
<h4 id="mysql数据库">2) Mysql数据库</h4>
<pre><code>$ sudo apt-get install mysql-server  
$ sudo apt-get install mysql-client  
$ mysql -u root –p  
mysql&gt; create database stock    # 建立名为stock的数据库，之后程序中会用到  
mysql&gt; show databases;  # 显示已有的数据库  </code></pre>
<h4 id="sqlite数据库">3) Sqlite数据库</h4>
<pre><code>$ sudo apt install sqlite3    
$ sqlite stock.db   # stock.db是数据库文件，将在运行示例程序时生成  
sqlite &gt; .tables        # 查看数据表  
sqlite &gt; select * from s002230; # 遍历表s002230中的数据  </code></pre>
<p>（也可使用图形界面工具sqliteman查看数据库）</p>
<h2 id="程序">3. 程序</h2>
<pre><code># -*- coding: utf-8 -*-  
  
import tushare as ts  
from sqlalchemy import create_engine  
import pandas as pd  
  
#ADDR = &#39;mysql://root:1234@localhost:3306/stock?charset=utf8&#39;   # 使用mysql，用户名root,密码1234，库名为stock，端口3306为mysql默认端口  
ADDR = &#39;sqlite:///stock.db&#39;     # 使用sqlite，当前目录的stock.db作为数据库文件  
  
engine = create_engine(ADDR)  
stocklist = [&#39;002230&#39;,&#39;601318&#39;]  
  
def save(code):  
    print &quot;save code:&quot;,code  
    try:  
        df = ts.get_h_data(code, start=&#39;1990-01-01&#39;, retry_count = 5)  
        df = df.sort_index(ascending=True)  
        name = &#39;s&#39;+code  
        df.to_sql(name, engine, if_exists=&#39;fail&#39;)  
    except:  
        print code, &quot; save failed&quot;  
  
for i in range(0, len(stocklist)):  
    save(stocklist[i])  </code></pre>
<h2 id="其它">4. 其它</h2>
<h4 id="运行sql语句">1) 运行SQL语句</h4>
<p>sqlalchemy也支持直接运行SQL语句，形如：</p>
<pre><code>result = engine.execute(‘select * from stock’)  </code></pre>
<p>使用sqlalchemy后，除了方便与pandas中的数据对接以外，也基本屏蔽了不同数据库之间的差异，换库时无需大量调整代码，十分方便。</p>
<h4 id="多线程下载">2) 多线程下载</h4>
<p>历史日线数据量较大，可使用python中的multiprocessing.dummy.Pool多线程下载。</p>
<h4 id="从数据库中读出数据">3) 从数据库中读出数据</h4>
<p>和to_sql相对的是read_sql，它可以从数据库中读出数据，并转换成DataFrame的格式。具体使用形如：<br />
stocklist = pd.read_sql('table1',engine) #
其中stocklist是DataFrame格式数据，pd是import pandas as
pd，table1是库名，engine同上例一样，指向数据库。</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>股票</tag>
      </tags>
  </entry>
  <entry>
    <title>Python股票处理之三_实时监测</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E8%82%A1%E7%A5%A8/Python%E8%82%A1%E7%A5%A8%E5%A4%84%E7%90%86%E4%B9%8B%E4%B8%89_%E5%AE%9E%E6%97%B6%E7%9B%91%E6%B5%8B/</url>
    <content><![CDATA[<h1 id="python股票处理之三_实时监测">Python股票处理之三_实时监测</h1>
<p>#Python #股票</p>
<h2 id="说明">1. 说明</h2>
<p>写个脚本帮你每天盯着某几支股票，达到预设值时响铃提醒。这是最简单的股票应用，虽然谈不上智能，但是自动化――老盯着就容易冲动操作。<br />
本例中实现了每5秒取一次股票数据，并在上证指数高于3200点，或601318低于49元时响提醒。</p>
<h2 id="程序">2. 程序</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import os  </span><br><span class="line">import time  </span><br><span class="line">import tushare as ts  </span><br><span class="line">import pandas as pd  </span><br><span class="line">  </span><br><span class="line">def check(code, low, high):  </span><br><span class="line">	df = ts.get_realtime_quotes(code)  </span><br><span class="line">	e = df[[&#x27;code&#x27;,&#x27;name&#x27;,&#x27;price&#x27;,&#x27;time&#x27;]]  </span><br><span class="line">	p = df[u&#x27;price&#x27;]  </span><br><span class="line">	print e   </span><br><span class="line">	if float(p[0]) &gt; low and float(p[0]) &lt; high:  </span><br><span class="line">		return True  </span><br><span class="line">	else :  </span><br><span class="line">		return False  </span><br><span class="line">	  </span><br><span class="line">while True:  </span><br><span class="line">	if check(&#x27;sh&#x27;, 3200, 10000) or check(&#x27;601318&#x27;,0,49):  </span><br><span class="line">		os.system(&#x27;play bell.wav&#x27;)  </span><br><span class="line">		exit()  </span><br><span class="line">	time.sleep(5)  </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>股票</tag>
      </tags>
  </entry>
  <entry>
    <title>Python股票处理之二_数据存盘</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E8%82%A1%E7%A5%A8/Python%E8%82%A1%E7%A5%A8%E5%A4%84%E7%90%86%E4%B9%8B%E4%BA%8C_%E6%95%B0%E6%8D%AE%E5%AD%98%E7%9B%98/</url>
    <content><![CDATA[<h1 id="python股票处理之二_数据存盘">Python股票处理之二_数据存盘</h1>
<p>#Python #股票</p>
<h2 id="说明">1. 说明</h2>
<p>有些历史数据不用每次下载，可以存储到本地。尤其在调试阶段，省去了每测一遍都要下载数据的时间和流量。<br />
Python存储数据非常方便，完全不用考虑数据库的格式，存进去是那个结构，取出来还是那个结构，屏蔽了所有细节。<br />
具体使用HDF格式，该格式可以存储不同类型的图像和数码数据的文件格式。</p>
<h2 id="安装相关库">2. 安装相关库</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install libhdf5-dev  </span><br><span class="line">$ sudo pip install h5py  </span><br><span class="line">$ sudo pip install --upgrade tables  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">## 3.	程序  </span><br><span class="line"></span><br><span class="line">#### 1)	存储  </span><br><span class="line">```  </span><br><span class="line">import tushare as ts  </span><br><span class="line">import pandas as pd  </span><br><span class="line">  </span><br><span class="line">e = ts.get_today_all()  </span><br><span class="line">print e  </span><br><span class="line">h5 = pd.HDFStore(&#x27;data/tmp.h5&#x27;,&#x27;w&#x27;)  </span><br><span class="line">h5[&#x27;data&#x27;] = e   </span><br><span class="line">h5.close()  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">#### 2)	读取  </span><br><span class="line">```  </span><br><span class="line">import pandas as pd  </span><br><span class="line">  </span><br><span class="line">h5 = pd.HDFStore(&#x27;data/tmp.h5&#x27;,&#x27;r&#x27;)  </span><br><span class="line">e = h5[&#x27;data&#x27;]  </span><br><span class="line">h5.close()  </span><br><span class="line">print e  </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>股票</tag>
      </tags>
  </entry>
  <entry>
    <title>Python股票处理之五_直方图统计</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E8%82%A1%E7%A5%A8/Python%E8%82%A1%E7%A5%A8%E5%A4%84%E7%90%86%E4%B9%8B%E4%BA%94_%E7%9B%B4%E6%96%B9%E5%9B%BE%E7%BB%9F%E8%AE%A1/</url>
    <content><![CDATA[<h1
id="python股票处理之五_直方图统计">Python股票处理之五_直方图统计</h1>
<p>#Python #股票</p>
<h2 id="说明">1. 说明</h2>
<p>直方图(Histogram)又称质量分布图。是一种统计报告图，由一系列高度不等的纵向条纹或线段表示数据分布的情况（见下图）。<br />
直方图是统计中的常用工具，在图像处理中，经常通过边缘或者颜色统计计算直方图，并通过直方图匹配实现图像识别；也可以据此判断颜色分布，以调节色彩均衡；还可以筛选出感兴趣的区域，并做进一步处理。<br />
在股票数据处理中，也同理，统计出直方图后，可利用它和以往数据匹配，寻找近似的情况；统计有效数据集中区域，并聚焦于该区域进一步处理。<br />
下面是一个最简单的实例：每天我们能看出大盘的整体涨跌，但并不了解各股涨跌情况的分布（比如：是普涨还是二八行情），下例分析并显示了昨天各股涨跌幅主要分布在哪些区间内。</p>
<h2 id="程序">2. 程序</h2>
<h4 id="代码">1) 代码</h4>
<pre><code># -*- coding:utf-8 -*-    
   
  
import tushare as ts  
import numpy as np    
import matplotlib.pyplot as plt    
   
  
e = ts.get_today_all()  
cc = e[u&#39;changepercent&#39;]# 涨跌幅  
plt.hist(cc,int(np.sqrt(len(cc))+0.5))  
plt.show()   </code></pre>
<h4 id="运行结果">2) 运行结果</h4>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-cea40dd1bd8e440f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<p>（此处直方图主要分布在0附近，提供的信息并不多，下篇：《数据预处理》将对直方图结果进行进一步的处理）</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>股票</tag>
      </tags>
  </entry>
  <entry>
    <title>Python股票处理之八_大数定律</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E8%82%A1%E7%A5%A8/Python%E8%82%A1%E7%A5%A8%E5%A4%84%E7%90%86%E4%B9%8B%E5%85%AB_%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B/</url>
    <content><![CDATA[<h1 id="python股票处理之八_大数定律">Python股票处理之八_大数定律</h1>
<p>#Python #股票</p>
<h2 id="引子">1. 引子</h2>
<p>有一天，我看见一个预测日涨跌的程序，成功率在百分之七十几，于是分享给X同学。结果人家说“70%多，这准确率高么？瞎蒙的准确率也有50%”<br />
这准确率高么？只靠对技术形态的判断，好像也还行吧？如果有70%的正确率，到底怎么做赢的机会比较大？达到多少百分比，才能够满意？<br />
看《程序员的数学2：概率统计》中有一道类似的习题：设结果甲出现概率为0.7，结果乙出现概述为0.3，且不论甲还是乙，只要猜中，就能获得下注同等的金额，猜不中则输掉赌资。显然选择甲是明智的做法。假设你每天都会参与这场赌博，你会将占总资产比例p的金额投给甲，p在整个过程中保持不变，请问应该如何设定p值？（我把该题简化了，大概是这个意思）<br />
如果只考虑一天，显然把所有资产都投给甲p=1是最佳选择，然而不断重复赌局时，总会出现没有中奖而失去所有财产的情况。下面写一个程序模拟这个赌局：</p>
<h2 id="程序">2.程序</h2>
<pre><code># -*- coding: utf-8 -*-  
  
import random  
import math  
import matplotlib.pyplot as plt  
  
TIMES = 50  # 赌博总数50次  
BASE_MONEY=100  # 本金100元  
  
def test(p):    # p是赌资占资产的比例，在0-1之间  
    money = BASE_MONEY  # 当前资产  
    for i in range(1,TIMES):  
        r = random.randint(1,10)    # 在1-10中取随机数r  
        val = money * p # 计算本次赌资val  
        if r &gt; 3:   # 有70%的可能性r&gt;3  
            money += val    # 赢val元  
        else:  
            money -= val    # 亏val元  
        if money &lt;= 0:  # 如果输光，则提前出局  
            money = 0.000001   
            break  
    return money / BASE_MONEY   # 此次操作的赢亏，&gt;1为赢  
  
for idx in range(0,9):  
    p = 0.1 * (idx + 1) # 投资比例占总资产的比例为0.1,0.2...0.9  
    plt.subplot(331+idx)    # 设定做图位置  
    array = []  
    lose = 0  
    for i in range(1, 100): # 每个p值试验100次  
        v = test(p)  
        if v &lt; 1:   # 亏本的次数  
            lose += 1  
        array.append(math.log10(v)) # 因数值跨度太大，以10底取对数  
    print &quot;percent &quot;, p, &quot;, lose &quot;, lose  
    plt.ylim(-1, 10)    # y轴坐标设定为-1到10做图  
    plt.plot(array)  
plt.show()  </code></pre>
<h2 id="执行结果">3.执行结果</h2>
<h4 id="原程序单次胜算为70">(1) 原程序，单次胜算为70%</h4>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-dc8e39121b48c96c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="pp.png" /><br />
percent 0.1 , lose 1<br />
percent 0.2 , lose 1<br />
percent 0.3 , lose 5<br />
percent 0.4 , lose 6<br />
percent 0.5 , lose 12<br />
percent 0.6 , lose 30<br />
percent 0.7 , lose 59<br />
percent 0.8 , lose 64<br />
percent 0.9 , lose 86<br />
(每次运行结果稍有差别，但差别不大)<br />
从结果可以看出，如果用少量的比例投资，亏的机会很小，但挣大钱的机会也小。同时投入资金比例超过0.7之后，亏本的可能性50%以上。尽管单次胜算是70%（独立同分布）。从图上看，合理的配置是资产的0.4-0.5左右。</p>
<h4 id="变化一个参数将单次胜算设为50">(2)
变化一个参数，将单次胜算设为50%</h4>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-e683dd426226d1f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="p2.png" /><br />
percent 0.1 , lose 66<br />
percent 0.2 , lose 72<br />
percent 0.3 , lose 89<br />
percent 0.4 , lose 94<br />
percent 0.5 , lose 97<br />
percent 0.6 , lose 98<br />
percent 0.7 , lose 98<br />
percent 0.8 , lose 99<br />
percent 0.9 , lose 99<br />
可见，如果单次正确率为50%，即瞎蒙，即使只投入全部资产的0.1，也会亏本，如果配置到资产的0.4以上，从图上看，基本就是血本无归了。合理的选择是：别参与。</p>
<h4 id="再变化一个参数将单次胜算设为90">(3)
再变化一个参数，将单次胜算设为90%</h4>
<p><img
src="http://upload-images.jianshu.io/upload_images/5357893-8d639a3a91895dc1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="p3.png" /><br />
percent 0.1 , lose 0<br />
percent 0.2 , lose 0<br />
percent 0.3 , lose 0<br />
percent 0.4 , lose 0<br />
percent 0.5 , lose 0<br />
percent 0.6 , lose 0<br />
percent 0.7 , lose 0<br />
percent 0.8 , lose 0<br />
percent 0.9 , lose 0<br />
把单次正确率设为90%时，几乎没有亏本的可能性，投入越多，挣得越多，但是从图中可见，投入0.9以上时也不是明智的选择。从图上看，合理的选择是0.7-0.8。</p>
<h2 id="分析">4.分析</h2>
<p>在这种利滚利的环境下，单次胜算越大，越应该果断投入；反之，保证不了正确率千万别碰。与事先想象不同的是：<br />
(1)
如果胜算在50%左右，多次操作，结果并不是胜负各半，而是血本无归。<br />
(2) 根据胜算比例，可计算出最适合的资产配置比例。<br />
(3)
操作一次，结果是随机的，操作Ｎ多次，大量随机结果的平均值（以及分布）却相对恒定，这就是传说中的“大数定律”。因此，即使有较大胜算，也需要多次操作才能体现出来（即不怕一万，只怕万一）</p>
<h2 id="联想">5. 联想</h2>
<p>比如买股票，我们可以选择某个胜算较高（胜算比例可从历史数据中算出）的技术形态，然后计算出合适的资产配置比例（见上例），按这个比例多次地买卖。在Ｎ次操作之后，收益范围基本是确定的。这个假设可以用历史的股票数据测试，我还没试过，就是随便一想，呵呵。<br />
如果这个假设成立，在单次胜算90%的情况下，怎么买基本都是赚钱的，只是赚多赚少的问题，在单次胜算70%的情况下，也能找到一个利益和风险的平衡点。Ｘ同学，你怎么看？</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>股票</tag>
      </tags>
  </entry>
  <entry>
    <title>Python股票处理之六_数据预处理A</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E8%82%A1%E7%A5%A8/Python%E8%82%A1%E7%A5%A8%E5%A4%84%E7%90%86%E4%B9%8B%E5%85%AD_%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86A/</url>
    <content><![CDATA[<h1
id="python股票处理之六_数据预处理a">Python股票处理之六_数据预处理A</h1>
<p>#Python #股票</p>
<h2 id="说明">1. 说明</h2>
<p>在数据统计和预测的过程中，工程师基本都使用现成的算法，工程师的主要工作是根据具体业务逻辑预处理数据和选择算法。<br />
首先要对数据预处理（数据清洗），包括数据的归一化，去除重复数据，修改错误数据，填充无效数据，抽象数据表示，筛选特征值，分配权重等等，以得到更准确的数据和更有效的结果。<br />
继续上次关于股票直方图的话题，来看看简单的股票数据预处理。左图是昨天股票涨跌的直方图，从中看出，涨跌幅分布在-10到50的区间内。<br />
涨幅超过10%是因为计入了新股的首日涨幅，跌涨超过-10%，可能由于分红配送等原因引起。下面程序中将对此区域进行特殊处理。<br />
对于当日停牌的数据，它的开盘价收盘价最高价最低价都是同一个值，如果加入统计，会在0附近形成一个无意义的峰值，在预处理中也把它去掉。<br />
如果用左图结果做一个从(-10,10)共计20个区间的分类器，那么结果多半会落入(-1,1)的区间内，这并不是我们想要的。我们更希望看到的是将3000多支股票平均分布在这20个区域，每个区域股票数量相同，但是各区域大小不同。根据区域得到更合理的分类结果。（假设我们之后将要通过现有股票的各个特征，预测涨跌最有可能分布在哪个区域，这是一个对结果的分类问题，暂不考虑回归）</p>
<h2 id="程序">2. 程序</h2>
<h4 id="代码">1) 代码</h4>
<pre><code># -*- coding:utf-8 -*-    
   
  
import tushare as ts  
import numpy as np    
import matplotlib.pyplot as plt    
   
  
e = ts.get_today_all()  
size = 20 #把区间分成20份  
array = []  
   
  
ll = e[u&#39;high&#39;]  # 最高价  
hh = e[u&#39;low&#39;] # 最低价  
cc = e[u&#39;changepercent&#39;]# 涨跌幅  
for i in range(0, len(e)):  
       ifll[i] != hh[i]:      # 最高价与最低价相同说明停牌  
              ifcc[i] &gt; 10:   # 涨幅大于10%的股票归为10%  
                     array.append(10)  
              elifcc[i] &lt; -10:      # 跌幅大于-10%的股票归为-10%  
                     array.append(-10)  
              else:  
                     array.append(cc[i])  
   
  
print &quot;Total:&quot;,len(array)  
array=np.sort(array)      # 排序  
   
  
bin_arr = []  
bin_arr.append(-10)       # 加入区间的左侧值  
count = 0 #区域计数  
for i in range(0, len(array)):  
       count+=1   
       ifcount &gt; len(array) / size:  
              printarray[i]  
              count= 0  
              bin_arr.append(array[i])  
bin_arr.append(10) # 加入区间右侧值  
   
  
hist, bins = np.histogram(array,bins=bin_arr)     # 按bin_arr给定的区域计算直方图  
width = np.diff(bins)  
center = (bins[:-1] + bins[1:]) / 2  
plt.bar(center, hist, align=&#39;center&#39;,width=width)  
plt.show()   </code></pre>
<h4 id="运行结果">2) 运行结果</h4>
<figure>
<img
src="http://upload-images.jianshu.io/upload_images/5357893-94490d23ad8c74e8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
alt="图片.png" />
<figcaption aria-hidden="true">图片.png</figcaption>
</figure>
<pre><code>Total: 3010  
-1.271     -0.667     -0.289     -0.098     0.061      0.219      0.348      0.482      0.599      0.719      0.873      1.021      1.16       1.312      1.505      1.786      2.133      2.713      3.74  </code></pre>
<h4 id="分析">3) 分析</h4>
<p>从结果可以看出，总共筛选出了3010支股票，将其分成20个区间，其中每个区间的股票数基本相等（最后一个不足1/20），此处只使用了一天的数据，当天微涨；实际处理时，需要使用更多数据来划分区域，20个区域可能也有点多。此处只是抛砖引玉，程序写得并不严谨，大家领会精神即可。以上计算用到了直方图均衡化的原理，在频域上划分，替代按值域划分，让我们聚焦于数据更集中的区域。</p>
<h2 id="参考">3. 参考</h2>
<h4 id="直方图均衡化的数学原理">1) 直方图均衡化的数学原理</h4>
<p>http://blog.csdn.net/superjunenaruto/article/details/52431941</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>股票</tag>
      </tags>
  </entry>
  <entry>
    <title>Python股票处理之四_股票筛选</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E8%82%A1%E7%A5%A8/Python%E8%82%A1%E7%A5%A8%E5%A4%84%E7%90%86%E4%B9%8B%E5%9B%9B_%E8%82%A1%E7%A5%A8%E7%AD%9B%E9%80%89/</url>
    <content><![CDATA[<h1 id="python股票处理之四_股票筛选">Python股票处理之四_股票筛选</h1>
<p>#Python #股票</p>
<h2 id="一-说明">一、 说明</h2>
<p>本例实现了股票筛选功能。<br />
前一半是过滤出市盈率在0-30倍之间，且今日换手率&gt;1%，涨幅超2%的股票。<br />
后一半统计今日涨停和接近涨停的股票。</p>
<h2 id="二-程序">二、 程序</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#! usr/bin/python #coding=utf-8  </span><br><span class="line">  </span><br><span class="line">import pandas as pd  </span><br><span class="line">import tushare as ts  </span><br><span class="line">  </span><br><span class="line">e = ts.get_today_all()  </span><br><span class="line">code = e[u&#x27;code&#x27;]  </span><br><span class="line">name = e[u&#x27;name&#x27;]  </span><br><span class="line">per = e[u&#x27;per&#x27;] # 市盈率  </span><br><span class="line">tt = e[u&#x27;turnoverratio&#x27;]	# 换手率  </span><br><span class="line">cc = e[u&#x27;changepercent&#x27;]	# 涨跌幅  </span><br><span class="line">mm = e[u&#x27;mktcap&#x27;]	# 总市值  </span><br><span class="line">  </span><br><span class="line">idx = len(name)  </span><br><span class="line">total = 0  </span><br><span class="line">while idx &gt; 0:  </span><br><span class="line">	idx -= 1  </span><br><span class="line">    # 市盈率在0-30倍之间，且今日换手率&gt;1%，涨幅超2%的  </span><br><span class="line">	if per[idx] &lt; 30 and per[idx] &gt; 0 and tt[idx] &gt; 1 and cc[idx] &gt; 2:  </span><br><span class="line">		print name[idx],&quot;:&quot;,per[idx],&quot;:&quot;,tt[idx],&quot;:&quot;,cc[idx],&quot;:&quot;,mm[idx]/10000  </span><br><span class="line">		total += 1  </span><br><span class="line">print &quot;total:&quot;,total,&quot;/&quot;,len(name)  </span><br><span class="line">  </span><br><span class="line">idx = len(name)  </span><br><span class="line">total = 0  </span><br><span class="line">while idx &gt; 0:  </span><br><span class="line">	idx -= 1  </span><br><span class="line">	# 涨停股票  </span><br><span class="line">	if cc[idx] &gt; 9.5:  </span><br><span class="line">		total += 1  </span><br><span class="line">		print &quot;@@@@:&quot;,code[idx],&quot;:&quot;,name[idx],&quot;:&quot;,cc[idx]  </span><br><span class="line">print &quot;total:&quot;,total,&quot;/&quot;,len(name)  </span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>股票</tag>
      </tags>
  </entry>
  <entry>
    <title>Python量化交易之四_聚宽数据</title>
    <url>/1_Note/3_%E7%BC%96%E7%A8%8B/Python/%E8%82%A1%E7%A5%A8/Python%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93%E4%B9%8B%E5%9B%9B_%E8%81%9A%E5%AE%BD%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<h1 id="python量化交易之四_聚宽数据">Python量化交易之四_聚宽数据</h1>
<p>#股票 #Python</p>
<h3 id="介绍">介绍</h3>
<p>之前测试过一些免费API，比如tushare现在只能下载两年半数据，163有的股票数据无法下载，pandas_reader速度很慢，并且只能下载A股的各股数据，对基金和指数支持不佳。这两天尝试了聚宽平台提供的API，它提供的功能基本够用，总结如下。</p>
<p>聚宽平台提供自2005年至今的股票相关数据（包含各股数据、指数、基金等等），需要申请一个免费试用帐号，使用期为一年，每天可下载最多100万条数据（所有A股历史数据不到200万条）。一天内不能下载所有数据，用两三天时间下载所有，然后每天更新数据肯定够用，而且速度较快。</p>
<p>聚宽数据以Python三方库方式提供，一直在更新维护中，最近一次SDK升级时间为2019年5月。<br />
建议读者封装数据获取模块，下载后转换成自定义数据格式，这样数据源变化了，也不影响整体软件框架。</p>
<h3 id="安装">安装</h3>
<p>安装方法如下：</p>
<pre><code>$ pip install git+https://github.com/JoinQuant/jqdatasdk.git  </code></pre>
<p>(需要python3.6以上支持)</p>
<h3 id="用法">用法</h3>
<p><strong>1. 登录</strong></p>
<pre><code>import jqdatasdk  
jqdatasdk.auth(&quot;用户名&quot;,&quot;密码&quot;)   </code></pre>
<p>从网站https://www.joinquant.com/ 注册。</p>
<p><strong>2. 获取K线数据</strong></p>
<pre><code>get_price(security=&quot;000001.XSHE&quot;, frequency=&#39;daily&#39;)  </code></pre>
<p>用security股票或者指数的代码，frequency指定频率，默认为日K线，还可以指定开始结束时间。</p>
<p><strong>3. 获取股票或基金列表</strong></p>
<pre><code>get_all_securities(types=[‘stock’])  </code></pre>
<p>用types指定需要获取的类型，stock为获取股票列表，fund为基金列表，index指数列表，futures期货列表……</p>
<p><strong>4. 获取指数成份股</strong></p>
<pre><code>jqdatasdk.get_index_stocks(&#39;000300.XSHG&#39;)  </code></pre>
<p>上例为获取沪深300成份股的股票列表。</p>
<p><strong>5. 获取股票所在的行业</strong></p>
<pre><code>jqdatasdk.get_industry(&quot;600519.XSHG&quot;,date=&quot;2018-06-01&quot;)  </code></pre>
<p>行业包括申万三级行业分类，聚宽二级行业分类，证监会行业分类，参数可通过列表，一次取多支股票。</p>
<p><strong>6．查询财务数据</strong></p>
<pre><code>get_fundamentals(query_object)  </code></pre>
<p>query_object是一个sqlalchemy.orm.query.Query对象，用于指定具体的查询内容，还可以用参数statDate指定查询财报的具体年份和季度。</p>
<p><strong>7．查看还剩下多少条</strong></p>
<pre><code>jqdatasdk.get_query_count()   </code></pre>
<p>免费账号限制每日最多下载100万条，查看当日剩余可调用条数。</p>
<p><strong>8．将股票代码转化成标准格式</strong></p>
<pre><code>jqdatasdk.normalize_code(&#39;000001&#39;)  </code></pre>
<p>转换结果为 '000001.XSHE'</p>
<h3 id="参考">参考</h3>
<p>说明文档具体见：https://www.joinquant.com/data/dict/jqDataSdk</p>
]]></content>
      <tags>
        <tag>Python</tag>
        <tag>股票</tag>
      </tags>
  </entry>
</search>

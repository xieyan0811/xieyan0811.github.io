<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>论文阅读_KnowPrompt知识抽取 | Yan 的杂物志_个人主页分享</title><meta name="author" content="Yan.xie"><meta name="copyright" content="Yan.xie"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="读后感  针对问题：few-shot 场景下从文本中抽取关系（知识检索、对话、问答）。 结果：在 5 个数据集，及少量标注情况下，测试效果优于之前模型 核心方法：希望在 pretrain 后不再 fine-tuning，于是引入了提示 prompt，通过构建提问（提问方法&#x2F;答案范围）来实现类似 tuning 的效果。 难点：之前对知识抽取和提示学习都不太了解；后来读了代码才了解，文中指的知识不是来">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读_KnowPrompt知识抽取">
<meta property="og:url" content="http://xyan666.com/posts/3343696737/index.html">
<meta property="og:site_name" content="Yan 的杂物志_个人主页分享">
<meta property="og:description" content="读后感  针对问题：few-shot 场景下从文本中抽取关系（知识检索、对话、问答）。 结果：在 5 个数据集，及少量标注情况下，测试效果优于之前模型 核心方法：希望在 pretrain 后不再 fine-tuning，于是引入了提示 prompt，通过构建提问（提问方法&#x2F;答案范围）来实现类似 tuning 的效果。 难点：之前对知识抽取和提示学习都不太了解；后来读了代码才了解，文中指的知识不是来">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://xyan666.com/img/blog_logo.png">
<meta property="article:published_time" content="2022-04-17T00:00:00.000Z">
<meta property="article:modified_time" content="2022-04-17T00:00:00.000Z">
<meta property="article:author" content="Yan.xie">
<meta property="article:tag" content="自然语言处理">
<meta property="article:tag" content="关系抽取">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://xyan666.com/img/blog_logo.png"><link rel="shortcut icon" href="/img/blog_logo.png"><link rel="canonical" href="http://xyan666.com/posts/3343696737/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '论文阅读_KnowPrompt知识抽取',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-04-17 00:00:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="referrer" content="no-referrer"/><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/blog_logo.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">736</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">98</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">149</div></a></div><hr class="custom-hr"/></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Yan 的杂物志_个人主页分享"><span class="site-name">Yan 的杂物志_个人主页分享</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">论文阅读_KnowPrompt知识抽取</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-04-17T00:00:00.000Z" title="Created 2022-04-17 00:00:00">2022-04-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-04-17T00:00:00.000Z" title="Updated 2022-04-17 00:00:00">2022-04-17</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/2-Note/">2_Note</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/2-Note/0-Technic/">0_Technic</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/2-Note/0-Technic/2-%E7%AE%97%E6%B3%95/">2_算法</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/2-Note/0-Technic/2-%E7%AE%97%E6%B3%95/6-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/">6_自然语言</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/2-Note/0-Technic/2-%E7%AE%97%E6%B3%95/6-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80/%E7%89%B9%E5%AE%9A%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9E%8B/">特定功能模型</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">3.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>12min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="论文阅读_KnowPrompt知识抽取"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><h1 id="读后感">读后感</h1>
<ul>
<li>针对问题：few-shot
场景下从文本中抽取关系（知识检索、对话、问答）。</li>
<li>结果：在 5 个数据集，及少量标注情况下，测试效果优于之前模型</li>
<li>核心方法：希望在 pretrain 后不再 fine-tuning，于是引入了提示
prompt，<strong>通过构建提问（提问方法/答案范围）来实现类似 tuning
的效果</strong>。</li>
<li>难点：之前对知识抽取和提示学习都不太了解；后来读了代码才了解，文中指的知识不是来自外界引入，而是<strong>将词嵌入作为知识</strong>。</li>
<li>泛读后理解程度：60%</li>
</ul>
<p>（看完题目、摘要、结论、图表及小标题）</p>
<p><strong><em>围绕句子的逻辑，利用之前定义好的模板提问，回答</em></strong></p>
<h1 id="基于知识的提示学习-knowprompt">基于知识的提示学习
KnowPrompt</h1>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">英文题目：KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimizationfor Relation Extraction</span><br><span class="line">中文题目：KnowPrompt: 基于协同优化的知识感知快速调优**关系提取**</span><br><span class="line">论文地址：https://arxiv.org/pdf/2104.07650.pdf</span><br><span class="line">领域：自然语言处理，关系提取</span><br><span class="line">发表时间：2021</span><br><span class="line">作者：Xiang Chen（浙江大学&amp;阿里巴巴）</span><br><span class="line">出处：TheWebConf(WWW)</span><br><span class="line">被引量：13</span><br><span class="line">代码和数据：https://github.com/zjunlp/KnowPrompt</span><br><span class="line">阅读时间：2022.04.15</span><br></pre></td></tr></table></figure>
<h1 id="精读">精读</h1>
<h2 id="摘要">摘要</h2>
<p>最近，<strong>提示调优</strong>(Prompt-tuning) 在一些 few-shot
分类任务中取得了令人满意的结果。它的核心思想是通过插入文本，将分类任务转化为
MASK 语言模型（MASK 原理详见
BERT）。对于关系抽取问题，选择提示模板需要较多的领域知识和较大工作量，且在实体和边之间蕴藏的大量知识也不应该被忽略。文中提出了一种<strong>基于知识协同优化的调优方法
(KnowPrompt)</strong>。通过学习<strong>模板词</strong>和<strong>答案词</strong>，将实体和关系的知识注入模型，并在知识约束下协同优化它们的表示。</p>
<h2 id="介绍">1. 介绍</h2>
<p>关系抽取 (RE) 是文件抽取中的一个重要任务，抽取后的信息可供更多下游
NLP 任务使用，比如：信息检索、对话生成和问答。</p>
<p>之前自监督的自然语言模型（PLM）如
BERT，它可以学习到带有上下文的表征，在很多 RE 任务中表现很好，而精调
(fine-tuning)
需要在模型顶部加层并需要额外的训练。它的效果依赖于耗时费力的大量标注，且不容易泛化到其它任务中。为解决此问题，出现了
prompt-tuning：使用预训练的语言模型作为预测器实现完型填空任务。它在
few-shot 任务中表现良好。如图 -1 所示：</p>
<figure>
<img src="/support/attachments_2022/Pasted%20image%2020220416135611.png"
alt="Pasted image 20220416135611.png" />
<figcaption aria-hidden="true">Pasted image
20220416135611.png</figcaption>
</figure>
<ul>
<li>模型的原始输入是“Hamilton is the first British champion”</li>
<li>模型在原始输入后，加了一个模板 "Mamilton [MASK]
British"，同时给定了一组标签词“country,city,residenct...”作为 MASK
的可选项</li>
</ul>
<p>（Hamilton 可能是人名，也可能是品牌）</p>
<ul>
<li>模型将原始输入和模板作为条件，预测 MASK
为某选项的概率，从而抽取模板中主语 Hamilton 和宾语 British 的关系。</li>
</ul>
<p>总之，Prompt-tuning
的目标是找到合适的模板和答案空间。而此工作常需要领域知识，以及复杂而大量的计算。而且关系标签不一定能在词典中找到合适的词。另外，实体、关系、三元组中包含的词义也不应被忽略，如图
-1 的例子中，如果主语和宾语都是人，则 "org:city_of_headquters"
就不太可能成立。相对的，关系也可以约束主语和宾语的类型。</p>
<p>文中提出的解决方法是：先将知识注入提示，然后用提示调优模型实现知识抽取。具体方法是使用学习“虚拟模板词”和“虚拟答案词”。具体的方法是：使用集合实体嵌入初始化的实体周围的类型标记，作为可学习的虚拟模板词来注入实体类型知识。同时使用标签计算平均嵌入作为虚拟答案来注入关系知识。在这个结构中，实体和关系相互约束，虚拟词需要与上下文保持一致性，文中引入了协同优化来校正模板和答案词。</p>
<p>文章主要贡献如下：</p>
<ul>
<li>提出了知识提示（KnowPrompt）方法，将知识注中提示模板的设计和答案构建，以解决关系抽取问题。</li>
<li>使用知识约束，联合优化提示模板和带有答案的表示。第一次提出在连续空间内，联合优化提示模板和答案。</li>
<li>在五个 RE 基准数据集上实验表明，KnowPrompt
在标准和低资源环境下都是有效的。</li>
</ul>
<h2 id="相关工作">2. 相关工作</h2>
<h3 id="知识抽取">2.1 知识抽取</h3>
<p>知识抽取，早期使用基于模式的方法，基于 CNN/RNN
的方法，以及基于图的方法，后来，将预训练语言模型作为基础的知识提取成为主流，尤其是基于
BERT 的模型显示出比之前模型更好的效果。最近 Xue 等提出的基出 BERT
的多视图方法达到了目前最高水平。由于标注的限制，few-shot
任务受到关注。</p>
<h3 id="提示学习">2.2 提示学习</h3>
<p>提示学习方法源于 GPT-3（2020 年），其在很多 NLP
任务中达到更好的效果。有些研究基于人工构建提示；2021 年 Hu
提出引入外部知识；2021 年 Ding
使用实体类型学习，来构建面向实体的词生成器和模板；为避免大量的人工构建提示，2020
年 Gao 等首次提出了自动构建模板和答案词，Shin
又进一步提出了梯度自动搜索，来自动生成模板和打标签。最近，有人直接利用可学习的连续嵌入作为提示模板。</p>
<p>在知识抽取方面，2021 年 Han 提出
PTR，使用逻辑规则构建子提示。本文中方法的先进性在于：使用知识注入方法，学习虚拟模板和模拟答案来代替人工定义规则，可以泛化到多种任务之中。另外，使用知识约束协同优化模板和答案词，使嵌入相互关联。</p>
<h2 id="背景知识">3. 背景知识</h2>
<p>定义 D={X,Y}，X 是实例（句子），Y
是关系标签，每个实例由词组成：x={w1,w2,ws...wo...wn}，RE
的目标是预测主语 ws 与宾语 wo 之间的关系 y ∈ Y。</p>
<figure>
<img src="/support/attachments_2022/Pasted%20image%2020220416154625.png"
alt="Pasted image 20220416154625.png" />
<figcaption aria-hidden="true">Pasted image
20220416154625.png</figcaption>
</figure>
<h3 id="精调语言模型">3.1 精调语言模型</h3>
<p>预训练的自然语言模型是 L，之前的 fine-tuning 模型将 x
作为模型的输入，加入类别[CLS] 和分隔符[SEP]，见图 -2(a)，其输出是隐藏层
h，最后用 h 预测该实例属于各个类别 CLS
的概率，使用交叉熵作为多分类的损失函数，在训练过程中自然语言模型参数 L
和用于最终分类的参数 W 被训练。</p>
<h3 id="提示调优语言模型">3.2 提示调优语言模型</h3>
<p>提示调优的目标是在预测模型和下游任务间建立桥梁，主要挑战是如何建立问题模板
T(.) 和可选答案标签 V，将它们统称为提示 P。对于每个实例
x，模型构建它新的输入：xprompt=T(x)。它一般包含原始文本和附加文本；V
使用自然语言模型 L 词表中词作为标签，定义 M：Y-&gt;V
作为注入映射表，连接任务标签 Y（最终抽取的关系）和标签词
V（用于回答提示问题）。</p>
<p>在保留了原有文本 x 的基础上，遮蔽 (MASK) 了 xprompt
中的一个或几个词，并用标签词替换，用模型 L 预测遮蔽位置的词，p 用于描述
V 在 MASK 处的分布：</p>
<p><span class="math display">\[
p(y|x)=p([MASK]=M(y)|x_{prompt})
\]</span></p>
<p>如图 -2(b) 所示，在原始文本后又加了一段带有 MASK
的文本，此时，可以通过模型 L 计算 MASK 对应的向量，并计算概率分布
p，用于描述 V 中各个可选项对于 MASK 位置的匹配程度，M
映射对于两个可选项分别有：M(y = “per:data_of_birth”) → “birth”（当 y
分类 per:data_of_birth，V 是 birth），M(y = “org:founded_by”)
→“founder”（当 y 为 org:founded_by，V 为
founder），然后判定哪个选项更合适。</p>
<h2 id="方法">4. 方法</h2>
<p>此部分主要介绍 KnowPrompt
协同优化方法的实现，将实体类型和关系标签中的知识用于关系提取。4.1
阐述构建方法，4.2 阐述优化方法。</p>
<h3 id="利用知识注入构建提示">4.1 利用知识注入构建提示</h3>
<p>典型的提示包括两部分：构建模板和答案集。本文目标是利用知识注入构建虚拟模板词和模拟答案词，以实现知识抽取任务。</p>
<h4 id="实体知识注入">实体知识注入</h4>
<p>2021 年 Zhou 提出了实体类型标注，他在实体前后加入了特征的标记[E]
和[/E]，详见图
-2(a)，这一技术在关系抽取中得到广泛使用。它用实体的类别信息提升模型效果，但是需要对类型进行额外的标注。然而，我们可以利用关系对实体的限制得到主语和宾语的大概范围，比如：当关系是““per:country_of_birth”时，主语是人，宾语是国家。此时可以得到主语和宾语候选集合
Csub={"person","organization",...}和
Cobj={"organization","data",...}，及其中元素的分布φsub 和φobj。</p>
<p>如图 -2
所示，用可学习的连续数据来描述实体类别，具体来说，是利用加权平均实体类型作为嵌入来初始化虚拟模板词：</p>
<figure>
<img src="/support/attachments_2022/Pasted%20image%2020220416164748.png"
alt="Pasted image 20220416164748.png" />
<figcaption aria-hidden="true">Pasted image
20220416164748.png</figcaption>
</figure>
<p>式中的 e^sub 和 e^obj
也是嵌入，用于描述主语和宾语的类型（它不是一种具体的类型，而是一种综合类型，因此是虚拟的），它被插入到主语和宾语的前后（图
-2 中绿色框），而 e()
从语言模型的词嵌入层提取词嵌入。使用上述方法可以从知识中自动学习更丰富的实体类型，其效果与之前方法差不多，但不需要额外标注。</p>
<p>简言之，这里的模板，就是后加的那半句话，需要分别确定其 主语 和 谓语
的类型，而通过 谓语 可以大概估计出主语和宾语是什么类型。</p>
<h4 id="关系知识注入">关系知识注入</h4>
<p>之前提示调优的研究主要是构建标签词和任务标签的一对一映射表，它不能表达关系标签中丰富的语义知识。我们设置虚拟答案词
v′∈V′，它能表达关系的语义，在模型 L
之后再加一层，用于学习关系嵌入，用虚拟答案集 V' 完全表示关系标签 Y。用
p(y|x) 来表示 V' 在 MASK 位置的分布。</p>
<p>和实体类型嵌入类似，使用 Crel 来表示可能的关系集合，φrel
表示其中各项的概率分布。通过对关系类型的分解，在关系语义词的候选集 Crel
上设置了概率分布φRel。具体方法是，计算关系中每个 token
的加权平均作为初始化嵌入，以此注入语义信息。比如：y1 =per:
countries_of_residence，集合 Crel1 = {“person”,“countries”, “residence”
}，具体方法如下：。</p>
<figure>
<img src="/support/attachments_2022/Pasted%20image%2020220416173528.png"
alt="Pasted image 20220416173528.png" />
<figcaption aria-hidden="true">Pasted image
20220416173528.png</figcaption>
</figure>
<h3 id="使用知识约束实现协同优化">4.2 使用知识约束实现协同优化</h3>
<p>实体类型和关系标签之间存在着丰富的交互和联系，且这些虚拟模板词和答案词应该与周围的上下文相关联。因此进一步协同优化虚拟模板词和虚拟答案词的参数集：</p>
<figure>
<img src="/support/attachments_2022/Pasted%20image%2020220416180024.png"
alt="Pasted image 20220416180024.png" />
<figcaption aria-hidden="true">Pasted image
20220416180024.png</figcaption>
</figure>
<h4 id="根据上下文校准提示">根据上下文校准提示</h4>
<p>尽管模拟模型和答案都基于语义信息初始化，但是它们可能不是最优的，且与上下文相关。因此，可用上下文进一步优化其表征。通过计算真实关系
y 和 p(y|x)
之间的交叉熵的损失函数来优化虚拟模板词和答案词，如下所示：</p>
<figure>
<img src="/support/attachments_2022/Pasted%20image%2020220416180742.png"
alt="Pasted image 20220416180742.png" />
<figcaption aria-hidden="true">Pasted image
20220416180742.png</figcaption>
</figure>
<p>此处的|X|是训练集中的实例个数，可学习的连续表征可以通过模板和答案的协同优化，自适应地学习最优表征。</p>
<p>简言之，就是通过预测的关系和真实的关系计算损失优化模型。</p>
<h4 id="隐含的结构约束">隐含的结构约束</h4>
<p>为注入结构信息，我们采用了知识嵌入 (KE) 目标函数作为约束。使用三元组
(s,r,o) 描述关系，s,o 描述主和宾的类别，r 是预定义的答案
V‘的关系标签。我们直接用虚拟模板和虚拟答案输出的嵌入通过语言模型参与计算。损失函数定义如下：</p>
<figure>
<img src="/support/attachments_2022/Pasted%20image%2020220416182217.png"
alt="Pasted image 20220416182217.png" />
<figcaption aria-hidden="true">Pasted image
20220416182217.png</figcaption>
</figure>
<p>带 ' 的是负例；γ是边界；dr 用于衡量头实体尾实体及关系（算法同
TransE），三元组成立时其值趋于 0，不成立时其值较大；n
表示所有负采样。负采样时，使用正确的答案填充 MASK
位置，随机取主语和宾语，替换为不相关的类型以构造损坏的三元组。（这里更多细节请见代码）</p>
<p>y=-log(sigmoid(x)) 如下图所示：</p>
<figure>
<img src="/support/attachments_2022/Pasted%20image%2020220416185125.png"
alt="Pasted image 20220416185125.png" />
<figcaption aria-hidden="true">Pasted image
20220416185125.png</figcaption>
</figure>
<p>括号里的值越大，最终损失函数越小；对于正例，d
相对边界值γ越小越好，对于负例，d 相对γ越大越好。</p>
<h3 id="训练细节">4.3 训练细节</h3>
<p>训练分为两个阶段，第一阶段使用大学习率协同优化虚拟模板词和模拟答案词：</p>
<figure>
<img src="/support/attachments_2022/Pasted%20image%2020220416190031.png"
alt="Pasted image 20220416190031.png" />
<figcaption aria-hidden="true">Pasted image
20220416190031.png</figcaption>
</figure>
<p>其中 λ是用于权衡两个损失函数的超参数。</p>
<p>第二阶段基于被优化的虚拟模板词和模拟答案词，仅利用 J[MASK]
损失函数为语言模型调参，用较小的学习率优化所有参数。</p>
<h2 id="实验">5. 实验</h2>
<h3 id="数据集">5.1 数据集</h3>
<p>为全面测试，使用了表 -1 中列出的 5 个数据集</p>
<figure>
<img src="/support/attachments_2022/Pasted%20image%2020220416192059.png"
alt="Pasted image 20220416192059.png" />
<figcaption aria-hidden="true">Pasted image
20220416192059.png</figcaption>
</figure>
<h3 id="实验设置">5.2 实验设置</h3>
<p>使用 BERT_LARGE 作为基础模型。</p>
<h4 id="基本配置">基本配置</h4>
<p>使用全部训练数据训练，与之前的四个模型对比。</p>
<h4 id="低资源配置">低资源配置</h4>
<p>使用 LM-BFF 提出的 8-, 16-, 32- (n 为每种类别的样例个数)
方法采样，从初始训练和验证集中抽取每个类的 k 个实例，以形成 few-shot
的训练和验证集。</p>
<h3 id="实验结果">5.3 实验结果</h3>
<h4 id="基本配置-1">基本配置</h4>
<figure>
<img src="/support/attachments_2022/Pasted%20image%2020220416194220.png"
alt="Pasted image 20220416194220.png" />
<figcaption aria-hidden="true">Pasted image
20220416194220.png</figcaption>
</figure>
<h4 id="低资源配置-1">低资源配置</h4>
<figure>
<img src="/support/attachments_2022/Pasted%20image%2020220416194454.png"
alt="Pasted image 20220416194454.png" />
<figcaption aria-hidden="true">Pasted image
20220416194454.png</figcaption>
</figure>
<p>可以看到，样例越少，KnowPrompt 相对其它模型效果越好。</p>
<h3 id="消融研究">5.4 消融研究</h3>
<figure>
<img src="/support/attachments_2022/Pasted%20image%2020220416194858.png"
alt="Pasted image 20220416194858.png" />
<figcaption aria-hidden="true">Pasted image
20220416194858.png</figcaption>
</figure>
<h1 id="代码解析">代码解析</h1>
<h3 id="数据">数据</h3>
<p>dataset/*</p>
<ul>
<li>代码中包含五个数据集的数据，分为两种格式，dialogue
为对话数据；其它数据格式均为同一种</li>
<li>数据集包含几千到几万条训练数据不等，除 dialogure
外的其它数据模式为：每条数据包含一个原始字符串，和一个头实体、尾实体、关系的三元组，用于训练和评测模型。</li>
<li>每个数据目标下都包含 rel2id.json
文件，它定义了可被抽取的关系及其对应 id，可以看到，“答案”(或称标签)
是有限的。</li>
</ul>
<h3 id="代码">代码</h3>
<ul>
<li>data/* 用于解析数据</li>
<li>dataset/* 供训练和测试的数据</li>
<li>scripts/* 训练各种模型使用的示例脚本</li>
<li>models/* 各种底层的预训练模型</li>
<li>lit_models/* 核心函数
<ul>
<li>lit_models/transformer.py 文中模型的具体实现
<ul>
<li>_init_label_word(), 140 行，初始化各种权重</li>
<li>training_step()，185 行，主要流程</li>
<li>ke_loss()，262 行</li>
</ul>
上述几个函数几乎实现了文中所有公式</li>
</ul></li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="http://xyan666.com">Yan.xie</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://xyan666.com/posts/3343696737/">http://xyan666.com/posts/3343696737/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a><a class="post-meta__tags" href="/tags/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/">关系抽取</a></div><div class="post_share"><div class="social-share" data-image="/img/blog_logo.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/37983/" title="论文阅读_GCN知识图对齐"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">论文阅读_GCN知识图对齐</div></div></a></div><div class="next-post pull-right"><a href="/posts/61432/" title="论文阅读_知识图对齐PRASE"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">论文阅读_知识图对齐PRASE</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/posts/2945279824/" title="论文阅读_关系抽取_CASREL"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-19</div><div class="title">论文阅读_关系抽取_CASREL</div></div></a></div><div><a href="/posts/4322/" title="主题笔记_模型压缩"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-24</div><div class="title">主题笔记_模型压缩</div></div></a></div><div><a href="/posts/53499/" title="读懂英文文章所需的单词量"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-27</div><div class="title">读懂英文文章所需的单词量</div></div></a></div><div><a href="/posts/36040/" title="论文阅读_ICD编码_BERT"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-20</div><div class="title">论文阅读_ICD编码_BERT</div></div></a></div><div><a href="/posts/21052/" title="论文阅读_ICD编码_MSATT-KG"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-16</div><div class="title">论文阅读_ICD编码_MSATT-KG</div></div></a></div><div><a href="/posts/42915/" title="论文阅读_ICD编码_MSMN"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-14</div><div class="title">论文阅读_ICD编码_MSMN</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/blog_logo.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Yan.xie</div><div class="author-info__description">顺流而下还是逆流而上？</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">736</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">98</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">149</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AF%BB%E5%90%8E%E6%84%9F"><span class="toc-number">1.</span> <span class="toc-text">读后感</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%9F%A5%E8%AF%86%E7%9A%84%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0-knowprompt"><span class="toc-number">2.</span> <span class="toc-text">基于知识的提示学习
KnowPrompt</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%B2%BE%E8%AF%BB"><span class="toc-number">3.</span> <span class="toc-text">精读</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">3.1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">3.2.</span> <span class="toc-text">1. 介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-number">3.3.</span> <span class="toc-text">2. 相关工作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96"><span class="toc-number">3.3.1.</span> <span class="toc-text">2.1 知识抽取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0"><span class="toc-number">3.3.2.</span> <span class="toc-text">2.2 提示学习</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86"><span class="toc-number">3.4.</span> <span class="toc-text">3. 背景知识</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B2%BE%E8%B0%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.4.1.</span> <span class="toc-text">3.1 精调语言模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%90%E7%A4%BA%E8%B0%83%E4%BC%98%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.4.2.</span> <span class="toc-text">3.2 提示调优语言模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-number">3.5.</span> <span class="toc-text">4. 方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E7%9F%A5%E8%AF%86%E6%B3%A8%E5%85%A5%E6%9E%84%E5%BB%BA%E6%8F%90%E7%A4%BA"><span class="toc-number">3.5.1.</span> <span class="toc-text">4.1 利用知识注入构建提示</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E4%BD%93%E7%9F%A5%E8%AF%86%E6%B3%A8%E5%85%A5"><span class="toc-number">3.5.1.1.</span> <span class="toc-text">实体知识注入</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E7%B3%BB%E7%9F%A5%E8%AF%86%E6%B3%A8%E5%85%A5"><span class="toc-number">3.5.1.2.</span> <span class="toc-text">关系知识注入</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E7%9F%A5%E8%AF%86%E7%BA%A6%E6%9D%9F%E5%AE%9E%E7%8E%B0%E5%8D%8F%E5%90%8C%E4%BC%98%E5%8C%96"><span class="toc-number">3.5.2.</span> <span class="toc-text">4.2 使用知识约束实现协同优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B9%E6%8D%AE%E4%B8%8A%E4%B8%8B%E6%96%87%E6%A0%A1%E5%87%86%E6%8F%90%E7%A4%BA"><span class="toc-number">3.5.2.1.</span> <span class="toc-text">根据上下文校准提示</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%90%E5%90%AB%E7%9A%84%E7%BB%93%E6%9E%84%E7%BA%A6%E6%9D%9F"><span class="toc-number">3.5.2.2.</span> <span class="toc-text">隐含的结构约束</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82"><span class="toc-number">3.5.3.</span> <span class="toc-text">4.3 训练细节</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-number">3.6.</span> <span class="toc-text">5. 实验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.6.1.</span> <span class="toc-text">5.1 数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E8%AE%BE%E7%BD%AE"><span class="toc-number">3.6.2.</span> <span class="toc-text">5.2 实验设置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE"><span class="toc-number">3.6.2.1.</span> <span class="toc-text">基本配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%8E%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE"><span class="toc-number">3.6.2.2.</span> <span class="toc-text">低资源配置</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-number">3.6.3.</span> <span class="toc-text">5.3 实验结果</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE-1"><span class="toc-number">3.6.3.1.</span> <span class="toc-text">基本配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%8E%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE-1"><span class="toc-number">3.6.3.2.</span> <span class="toc-text">低资源配置</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%9E%8D%E7%A0%94%E7%A9%B6"><span class="toc-number">3.6.4.</span> <span class="toc-text">5.4 消融研究</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90"><span class="toc-number">4.</span> <span class="toc-text">代码解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE"><span class="toc-number">4.0.1.</span> <span class="toc-text">数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-number">4.0.2.</span> <span class="toc-text">代码</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/1398427745/" title="对谈_250304_礼物&amp;关系">对谈_250304_礼物&amp;关系</a><time datetime="2025-03-18T00:00:00.000Z" title="Created 2025-03-18 00:00:00">2025-03-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/2596569319/" title="对谈_250305_虚伪">对谈_250305_虚伪</a><time datetime="2025-03-18T00:00:00.000Z" title="Created 2025-03-18 00:00:00">2025-03-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/4168040379/" title="对谈_250315_不畏艰险vs资源优化">对谈_250315_不畏艰险vs资源优化</a><time datetime="2025-03-18T00:00:00.000Z" title="Created 2025-03-18 00:00:00">2025-03-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/2912859842/" title="对谈_250306_社会化和完整人格">对谈_250306_社会化和完整人格</a><time datetime="2025-03-18T00:00:00.000Z" title="Created 2025-03-18 00:00:00">2025-03-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/3015950793/" title="对谈_250315_被动利他">对谈_250315_被动利他</a><time datetime="2025-03-18T00:00:00.000Z" title="Created 2025-03-18 00:00:00">2025-03-18</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Yan.xie</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></br>
<img class="img-circle profile-img" src="/img/beian.png" alt="">
<a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11010802043346">京公网安备11010802043346号</a>
</br>
<a href="https://beian.miit.gov.cn/" rel="nofollow" target="_blank">京ICP备2023029600号-1</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>